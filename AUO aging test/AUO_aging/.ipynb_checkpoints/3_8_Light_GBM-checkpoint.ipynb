{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-22T01:44:36.220211Z",
     "start_time": "2021-08-22T01:44:34.191155Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import itertools\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from tqdm.auto import tqdm\n",
    "import plotly\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import lightgbm as lgb\n",
    "from lightgbm import LGBMClassifier, LGBMRegressor\n",
    "import optuna\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "import skopt\n",
    "import skopt.plots\n",
    "\n",
    "from Dataset_Construction import Balance_Ratio \n",
    "from Sampling import label_divide\n",
    "from AdaClassifier import train_set, multiple_set, print_badC, bad_plot, line_chart, cf_matrix\n",
    "from AdaRegressor import AUC, PR_curve, multiple_curve, PR_matrix, best_threshold \n",
    "from Aging_Score import score1\n",
    "from XGBoost import optuna_history, all_optuna\n",
    "\n",
    "os.chdir('C:/Users/user/Desktop/Darui_R08621110')  \n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Boosting model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-22T01:44:36.349313Z",
     "start_time": "2021-08-22T01:44:36.326642Z"
    }
   },
   "outputs": [],
   "source": [
    "def LightGBMC(train_x, test_x, train_y, test_y, config):\n",
    "    \n",
    "    clf = LGBMClassifier(**config)\n",
    "    clf.fit(train_x, train_y)\n",
    "    predict_y = clf.predict(test_x)\n",
    "    result = pd.DataFrame({'truth': test_y, 'predict': predict_y})\n",
    "    \n",
    "    return result\n",
    "\n",
    "\n",
    "def LightGBMR(train_x, test_x, train_y, test_y, config):\n",
    "    \n",
    "    reg = LGBMRegressor(**config)\n",
    "    reg.fit(train_x, train_y)\n",
    "    predict_y = reg.predict(test_x)\n",
    "    result = pd.DataFrame({'truth': test_y, 'predict': predict_y})\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run all dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-22T01:44:36.464209Z",
     "start_time": "2021-08-22T01:44:36.445192Z"
    }
   },
   "outputs": [],
   "source": [
    "def runall_LightGBMC(num_set, trainset_x, test_x, trainset_y, test_y, config, record_bad = True):\n",
    "    \n",
    "    table_set = pd.DataFrame()\n",
    "    bad_set = pd.DataFrame()\n",
    "    judge = list(config.keys())[0]\n",
    "\n",
    "    for i in range(num_set):\n",
    "        print('\\n', f'Dataset {i}:')\n",
    "        \n",
    "        if isinstance(config[judge], dict) :\n",
    "            best_config = config[f'set{i}']\n",
    "        else :\n",
    "            best_config = config\n",
    "        \n",
    "        result = LightGBMC(trainset_x[f'set{i}'], test_x, trainset_y[f'set{i}'], test_y, best_config)\n",
    "        table = cf_matrix(result, trainset_y[f'set{i}'])\n",
    "        table_set = pd.concat([table_set, table]).rename(index = {0: f'dataset {i}'})\n",
    "        \n",
    "        if record_bad:\n",
    "            bad_table = print_badC(result, test_x, Bad_Types) \n",
    "            bad_set = pd.concat([bad_set, bad_table]).rename(index = {0: f'dataset {i}'})\n",
    "\n",
    "    if record_bad:\n",
    "        return table_set, bad_set\n",
    "    else:\n",
    "        return table_set\n",
    "    \n",
    "    \n",
    "def runall_LightGBMR(num_set, trainset_x, test_x, trainset_y, test_y, config, thres_target = 'Recall', threshold = 0.8, \n",
    "                     record_bad = True):\n",
    "    \n",
    "    table_set = pd.DataFrame()\n",
    "    bad_set = pd.DataFrame()\n",
    "    pr_dict = {}\n",
    "    judge = list(config.keys())[0]\n",
    "\n",
    "    for i in range(num_set):\n",
    "        print('\\n', f'Dataset {i}:')\n",
    "        \n",
    "        if isinstance(config[judge], dict) :\n",
    "            best_config = config[f'set{i}']\n",
    "        else :\n",
    "            best_config = config\n",
    "\n",
    "        predict = LightGBMR(trainset_x[f'set{i}'], test_x, trainset_y[f'set{i}'], test_y, best_config)\n",
    "        pr_matrix = PR_matrix(predict, trainset_y[f'set{i}'])\n",
    "        pr_dict[f'set{i}'] = pr_matrix\n",
    "        \n",
    "        best_data, best_thres = best_threshold(pr_matrix, target = thres_target, threshold = threshold)\n",
    "        table_set = pd.concat([table_set, best_data]).rename(index = {best_data.index.values[0]: f'dataset {i}'})\n",
    "        \n",
    "        if record_bad:\n",
    "            bad_table = print_badC(predict, test_x, Bad_Types, threshold = best_thres)\n",
    "            bad_set = pd.concat([bad_set, bad_table]).rename(index = {0: f'dataset {i}'})\n",
    "    \n",
    "    if record_bad:\n",
    "        return pr_dict, table_set, bad_set\n",
    "    else:\n",
    "        return pr_dict, table_set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-22T01:44:45.846165Z",
     "start_time": "2021-08-22T01:44:37.588606Z"
    }
   },
   "outputs": [],
   "source": [
    "###bad types###\n",
    "bad = pd.read_csv('event/Bad_Types.csv').iloc[:, 1:]\n",
    "Bad_Types = {bad.cb[i]:i for i in range (len(bad))}\n",
    "print('Total bad types:', len(bad))\n",
    "\n",
    "###single dataset###\n",
    "test = pd.read_csv('event/TestingSet_0.csv').iloc[:, 2:]\n",
    "train = pd.read_csv('event/TrainingSet_new.csv').iloc[:, 2:]\n",
    "print('\\ntraining data:', train.shape, '\\nBalance Ratio:', Balance_Ratio(train))\n",
    "print('\\ntesting data:', test.shape, '\\nBalance Ratio:', Balance_Ratio(test))\n",
    "\n",
    "train_x, train_y, test_x, test_y = label_divide(train, test, 'GB')\n",
    "\n",
    "###multiple dataset###\n",
    "data_dict = multiple_set(num_set = 10)\n",
    "trainset_x, trainset_y = train_set(data_dict, num_set = 10, label = 'GB')\n",
    "test_x, test_y = label_divide(test, None, 'GB', train_only = True)\n",
    "\n",
    "\n",
    "#####for runhist dataset#####\n",
    "# bad = pd.read_csv('run_bad_types.csv').iloc[:, 1:]\n",
    "# Bad_Types = {bad.cb[i]:i for i in range (len(bad))}\n",
    "# print('Total bad types:', len(bad))\n",
    "\n",
    "run_test = pd.read_csv('test_runhist.csv').iloc[:, 2:]\n",
    "run_test_x, run_test_y = label_divide(run_test, None, 'GB', train_only = True)\n",
    "print('\\n', 'Dimension of run test:', run_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-22T01:43:11.595337Z",
     "start_time": "2021-08-22T01:42:49.250082Z"
    }
   },
   "outputs": [],
   "source": [
    "# run_clf_param = {\n",
    "#         'objective': 'binary',\n",
    "#         'metric': 'binary_logloss',\n",
    "#         'boosting_type': 'goss',\n",
    "#         'num_iterations': 100,\n",
    "#         'subsample': 0.7,\n",
    "#         'num_leaves': 20,\n",
    "#         'min_child_samples': 3,\n",
    "#         'max_depth': 7,\n",
    "#         'learning_rate': 0.125,\n",
    "#         'lambda_l1': 0.0006,\n",
    "\n",
    "#         'lambda_l2': 0.003\n",
    "# } #tpe/recall-0.1*aging/set6\n",
    "\n",
    "#table_set1, bad_set1 = runall_LightGBMC(9, trainset_x, test_x, trainset_y, test_y, event_clf_param)\n",
    "table_set1 = runall_LightGBMC(10, trainset_x, run_test_x, trainset_y, run_test_y, best_paramC, record_bad = False)\n",
    "line_chart(table_set1, title = 'LightGBM Classifier')\n",
    "#bad_plot(bad_set1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-22T01:43:33.126738Z",
     "start_time": "2021-08-22T01:43:33.095301Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "table_set1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-22T15:20:28.903472Z",
     "start_time": "2021-08-22T15:20:03.701673Z"
    }
   },
   "outputs": [],
   "source": [
    "# run_reg_param = {\n",
    "#         'objective': 'binary',\n",
    "#         'metric': 'binary_logloss',\n",
    "#         'boosting_type': 'gbdt',\n",
    "#         'num_iterations': 150,\n",
    "#         'subsample': 0.9,\n",
    "#         'num_leaves': 20,\n",
    "#         'min_child_samples': 9,\n",
    "#         'max_depth': 5,\n",
    "#         'learning_rate': 0.475,\n",
    "#         'lambda_l1': 0.0003,\n",
    "#         'lambda_l2': 0.0006\n",
    "# }\n",
    "\n",
    "# pr_dict, table_set2, bad_set2 = runall_LightGBMR(9, trainset_x, test_x, trainset_y, test_y, event_reg_param, \n",
    "#                                                  thres_target = 'Recall', threshold = 0.8)\n",
    "pr_dict, table_set2 = runall_LightGBMR(10, trainset_x, run_test_x, trainset_y, run_test_y, best_paramR, \n",
    "                                       thres_target = 'Recall', threshold = 0.8, record_bad = False)\n",
    "line_chart(table_set2, title = 'LightGBM Regressor')\n",
    "#bad_plot(bad_set2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-21T16:27:12.595325Z",
     "start_time": "2021-08-21T16:27:11.906855Z"
    }
   },
   "outputs": [],
   "source": [
    "multiple_curve(3, 3, pr_dict, table_set2, target = 'Aging Rate')\n",
    "multiple_curve(3, 3, pr_dict, table_set2, target = 'Precision')\n",
    "table_set2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-22T01:44:48.641680Z",
     "start_time": "2021-08-22T01:44:48.627717Z"
    }
   },
   "outputs": [],
   "source": [
    "def objective_creator(train_data, mode, num_valid = 3, label = 'GB') :\n",
    "\n",
    "    def objective(trial) :\n",
    "    \n",
    "        param = {\n",
    "            'objective': trial.suggest_categorical('objective', ['binary', 'cross_entropy']),\n",
    "            'boosting_type': trial.suggest_categorical('boosting_type', ['gbdt', 'goss']),\n",
    "            'num_iterations': trial.suggest_int('num_iterations', 100, 300, step = 50),\n",
    "            'subsample': trial.suggest_float('subsample', 0.5, 0.9, step = 0.2),\n",
    "            'num_leaves': trial.suggest_int('num_leaves', 5, 40, step = 5),\n",
    "            'min_child_samples': trial.suggest_int('min_child_samples', 3, 24, step = 3),\n",
    "            'max_depth': trial.suggest_int('max_depth', 3, 15, step = 2),\n",
    "            'learning_rate': trial.suggest_float('learning_rate', 0.025, 0.425, step = 0.05),\n",
    "            'reg_alpha': trial.suggest_loguniform('reg_alpha', 1e-4, 5), # alpha\n",
    "            'reg_lambda': trial.suggest_loguniform('reg_lambda', 1e-4, 5) # lambda\n",
    "        }\n",
    "\n",
    "        result_list = []\n",
    "        for i in range(num_valid):\n",
    "\n",
    "            train_x, train_y = label_divide(train_data, None, label, train_only = True)\n",
    "            train_x, valid_x, train_y, valid_y = train_test_split(train_x, train_y, test_size = 0.25)\n",
    "\n",
    "            if mode == 'C':\n",
    "                result = LightGBMC(train_x, valid_x, train_y, valid_y, param)\n",
    "                table = cf_matrix(result, valid_y)\n",
    "                recall = table['Recall']\n",
    "                aging = table['Aging Rate']\n",
    "                effi = table['Efficiency']\n",
    "            \n",
    "                #result_list.append(effi)\n",
    "                result_list.append(recall - 0.1*aging)\n",
    "\n",
    "            elif mode == 'R':\n",
    "                result = LightGBMR(train_x, valid_x, train_y, valid_y, param)\n",
    "                pr_matrix = PR_matrix(result, valid_y)\n",
    "\n",
    "                #best_data, _ = best_threshold(pr_matrix, target = 'Recall', threshold = 0.8)\n",
    "                #aging = best_data['Aging Rate']\n",
    "                #result_list.append((-1)*aging)\n",
    "\n",
    "                auc = AUC(pr_matrix['Recall'], pr_matrix['Aging Rate'])\n",
    "                result_list.append((-1)*auc)\n",
    "\n",
    "        return np.mean(result_list)\n",
    "\n",
    "    return objective"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-21T22:05:45.342729Z",
     "start_time": "2021-08-21T16:39:37.298053Z"
    }
   },
   "outputs": [],
   "source": [
    "best_paramC, all_scoreC = all_optuna(num_set = 10, \n",
    "                                     all_data = data_dict, \n",
    "                                     mode = 'C', \n",
    "                                     TPE_multi = True, \n",
    "                                     n_iter = 250,\n",
    "                                     filename = 'runhist_array_m8m7_LightGBM',\n",
    "                                     creator = objective_creator\n",
    "                                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-22T08:42:59.499000Z",
     "start_time": "2021-08-22T01:44:53.198956Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "best_paramR, all_scoreR = all_optuna(num_set = 10, \n",
    "                                     all_data = data_dict, \n",
    "                                     mode = 'R', \n",
    "                                     TPE_multi = True, \n",
    "                                     n_iter = 250,\n",
    "                                     filename = 'runhist_array_m8m7_LightGBM',\n",
    "                                     creator = objective_creator\n",
    "                                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-12T04:11:18.150099Z",
     "start_time": "2021-08-12T04:11:17.467403Z"
    }
   },
   "outputs": [],
   "source": [
    "##### optimization history plot #####\n",
    "optuna_history(best_paramC, all_scoreC, model = 'LightGBM Classifier')\n",
    "            \n",
    "##### best hyperparameter table #####\n",
    "param_table = pd.DataFrame(best_paramC).T\n",
    "param_table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scikit Optimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-02T01:47:18.926728Z",
     "start_time": "2021-08-02T01:47:18.914357Z"
    }
   },
   "outputs": [],
   "source": [
    "def skopt_creator(train_data, mode, num_valid = 3, label = 'GB') :\n",
    "    \n",
    "    def skopt_objective(param) :\n",
    "\n",
    "        param_dict = {\n",
    "            'objective': 'binary',\n",
    "            'metric': 'binary_loss',\n",
    "            'boosting_type': param[0],\n",
    "            'num_iterations': param[1],\n",
    "            'subsample': param[2],\n",
    "            'num_leaves': param[3],\n",
    "            'min_child_samples': param[4],\n",
    "            'max_depth': param[5],\n",
    "            'learning_rate': param[6],\n",
    "            'reg_alpha': param[7],\n",
    "            'reg_lambda': param[8]\n",
    "        }\n",
    "        \n",
    "        result_list = []\n",
    "        for i in range(num_valid):\n",
    "\n",
    "            train_x, train_y = label_divide(train_data, None, label, train_only = True)\n",
    "            train_x, valid_x, train_y, valid_y = train_test_split(train_x, train_y, test_size = 0.25)\n",
    "\n",
    "            if mode == 'C':\n",
    "                result = LightGBMC(train_x, valid_x, train_y, valid_y, param_dict)\n",
    "                table = cf_matrix(result, valid_y)\n",
    "                recall = table['Recall']\n",
    "                aging = table['Aging Rate']\n",
    "\n",
    "                result_list.append(0.1*aging - recall)\n",
    "\n",
    "            elif mode == 'R':\n",
    "                result = LightGBMR(train_x, valid_x, train_y, valid_y, param_dict)\n",
    "                pr_matrix = PR_matrix(result, valid_y)\n",
    "                auc = AUC(pr_matrix['Recall'], pr_matrix['Aging Rate'])\n",
    "\n",
    "                result_list.append(auc)\n",
    "\n",
    "        return np.mean(result_list)\n",
    "        ##### minimize\n",
    "    \n",
    "    return skopt_objective\n",
    "\n",
    "\n",
    "def all_skopt(num_set, all_data, mode, n_iter, optimizer, sel_func, num_valid = 3, record_addition = True) :\n",
    "    \n",
    "    skopt_param = [\n",
    "        skopt.space.space.Categorical(name = 'boosting_type', categories = ['gbdt', 'goss']),\n",
    "        skopt.space.space.Categorical(name = 'num_iterations', categories = [100, 150, 200, 250, 300]),\n",
    "        skopt.space.space.Categorical(name = 'subsample', categories = [0.5, 0.7, 0.9]),\n",
    "        skopt.space.space.Integer(name = 'num_leaves', low = 5, high = 40),\n",
    "        skopt.space.space.Integer(name = 'min_child_samples', low = 3, high = 24),\n",
    "        skopt.space.space.Integer(name = 'max_depth', low = 3, high = 15),\n",
    "        skopt.space.space.Real(name = 'learning_rate', low = 0.01, high = 0.4, prior = 'uniform'),\n",
    "        skopt.space.space.Real(name = 'reg_alpha', low = 1e-4, high = 5, prior = 'log-uniform'), # alpha\n",
    "        skopt.space.space.Real(name = 'reg_lambda', low = 1e-4, high = 5, prior = 'log-uniform') # lambda\n",
    "    ]\n",
    "    \n",
    "    opt_list = ['GauP', 'forest', 'gbrt']\n",
    "    \n",
    "    best_param = {}\n",
    "    record_studies = {}\n",
    "    for i in tqdm(range(num_set)) :\n",
    "        \n",
    "        skopt_objective = skopt_creator(all_data[f'set{i}'], mode = mode)\n",
    "        if optimizer == opt_list[0] :\n",
    "            result = skopt.gp_minimize(skopt_objective, skopt_param, n_calls = n_iter, acq_func = sel_func, n_jobs = -1)\n",
    "        elif optimizer == opt_list[1] :\n",
    "            result = skopt.forest_minimize(skopt_objective, skopt_param, n_calls = n_iter, acq_func = sel_func, \n",
    "                                           n_jobs = -1)\n",
    "        elif optimizer == opt_list[2] :\n",
    "            result = skopt.gbrt_minimize(skopt_objective, skopt_param, n_calls = n_iter, acq_func = sel_func, \n",
    "                                           n_jobs = -1)\n",
    "        \n",
    "        # return to dictionary\n",
    "        record_param = result.x\n",
    "        dict_param = {\n",
    "            'objective': 'binary',\n",
    "            'metric': 'binary_loss',\n",
    "            'boosting_type': record_param[0],\n",
    "            'num_iterations': record_param[1],\n",
    "            'subsample': record_param[2],\n",
    "            'num_leaves': record_param[3],\n",
    "            'min_child_samples': record_param[4],\n",
    "            'max_depth': record_param[5],\n",
    "            'learning_rate': record_param[6],\n",
    "            'reg_alpha': record_param[7],\n",
    "            'reg_lambda': record_param[8]\n",
    "        }\n",
    "        \n",
    "        best_param[f'set{i}'] = dict_param\n",
    "        if record_addition :\n",
    "            record_studies[f'set{i}'] = result\n",
    "        \n",
    "    # save the hyperparameter dictionary\n",
    "    with open(f'runhist_array_label_LightGBM{mode}_{optimizer}_{n_iter}.data', 'wb') as f :\n",
    "        pickle.dump(best_param, f)\n",
    "\n",
    "    return best_param, record_studies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-08-02T01:47:44.867Z"
    }
   },
   "outputs": [],
   "source": [
    "best_paramC, all_studiesC = all_skopt(num_set = 9, all_data = data_dict, mode = 'C', n_iter = 500, \n",
    "                                      optimizer = 'GauP', sel_func = 'EI', num_valid = 3)\n",
    "best_paramR, all_studiesR = all_skopt(num_set = 9, all_data = data_dict, mode = 'R', n_iter = 250, \n",
    "                                      optimizer = 'GauP', sel_func = 'EI', num_valid = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-01T06:44:14.189717Z",
     "start_time": "2021-08-01T06:44:13.999860Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "##### convergence plot #####\n",
    "all_studies  = all_studiesC\n",
    "\n",
    "plt.figure(figsize = (12, 8))\n",
    "convergence = skopt.plots.plot_convergence(\n",
    "    ('dataset 0', all_studies['set0']),\n",
    "    ('dataset 1', all_studies['set1']),\n",
    "    ('dataset 2', all_studies['set2']),\n",
    "    ('dataset 3', all_studies['set3']),\n",
    "    ('dataset 4', all_studies['set4']),\n",
    "    ('dataset 5', all_studies['set5']),\n",
    "    ('dataset 6', all_studies['set6']),\n",
    "    ('dataset 7', all_studies['set7']),\n",
    "    ('dataset 8', all_studies['set8'])\n",
    ")\n",
    "convergence.legend(loc = \"upper right\", prop = {'size': 8})\n",
    "convergence.set_title('Convergence Plot of LightGBM Classifier (gradient boost)')\n",
    "convergence.set_xlabel('Iterations')\n",
    "convergence.set_ylabel('Objective Values')"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python [conda env:aging]",
   "language": "python",
   "name": "conda-env-aging-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
