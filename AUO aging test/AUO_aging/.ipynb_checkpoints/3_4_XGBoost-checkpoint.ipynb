{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import itertools\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import plotly\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import xgboost as xgb\n",
    "import optuna\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "\n",
    "from Dataset_Construction import Balance_Ratio \n",
    "from Sampling import label_divide\n",
    "from AdaClassifier import train_set, multiple_set, print_badC, bad_plot, line_chart, cf_matrix\n",
    "from AdaRegressor import AUC, PR_curve, multiple_curve, PR_matrix, best_threshold \n",
    "from Aging_Score import score1\n",
    "\n",
    "#os.chdir('C:/Users/Darui Yen/OneDrive/桌面/data_after_mid') \n",
    "#os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Boosting model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def XGBoostC(train_x, test_x, train_y, test_y, config):\n",
    "    \n",
    "    clf = xgb.XGBClassifier(**config, n_jobs = -1)\n",
    "    clf.fit(train_x, train_y)\n",
    "    predict_y = clf.predict(test_x)\n",
    "    result = pd.DataFrame({'truth': test_y, 'predict': predict_y})\n",
    "    \n",
    "    return result\n",
    "    \n",
    "    \n",
    "def XGBoostR(train_x, test_x, train_y, test_y, config):\n",
    "    \n",
    "    reg = xgb.XGBRegressor(**config, n_jobs = -1)\n",
    "    reg.fit(train_x, train_y)\n",
    "    predict_y = reg.predict(test_x)\n",
    "    result = pd.DataFrame({'truth': test_y, 'predict': predict_y})\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run all dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def runall_XGBoostC(num_set, trainset_x, test_x, trainset_y, test_y, config, record_bad = True):\n",
    "    \n",
    "    table_set = pd.DataFrame()\n",
    "    bad_set = pd.DataFrame()\n",
    "\n",
    "    for i in range(num_set):\n",
    "        print('\\n', f'Dataset {i}:')\n",
    "        \n",
    "        result = XGBoostC(trainset_x[f'set{i}'], test_x, trainset_y[f'set{i}'], test_y, config)\n",
    "        table = cf_matrix(result, trainset_y[f'set{i}'])\n",
    "        table_set = pd.concat([table_set, table]).rename(index = {0: f'dataset {i}'})\n",
    "        \n",
    "        if record_bad:\n",
    "            bad_table = print_badC(result, test_x, Bad_Types) \n",
    "            bad_set = pd.concat([bad_set, bad_table]).rename(index = {0: f'dataset {i}'})\n",
    "\n",
    "    if record_bad:\n",
    "        return table_set, bad_set\n",
    "    else:\n",
    "        return table_set\n",
    "    \n",
    "    \n",
    "def runall_XGBoostR(num_set, trainset_x, test_x, trainset_y, test_y, config, thres_target = 'Recall', threshold = 0.8, \n",
    "                          record_bad = True):\n",
    "    \n",
    "    table_set = pd.DataFrame()\n",
    "    bad_set = pd.DataFrame()\n",
    "    pr_dict = {}\n",
    "\n",
    "    for i in range(num_set):\n",
    "        print('\\n', f'Dataset {i}:')\n",
    "\n",
    "        predict = XGBoostR(trainset_x[f'set{i}'], test_x, trainset_y[f'set{i}'], test_y, config)\n",
    "        pr_matrix = PR_matrix(predict, trainset_y[f'set{i}'])\n",
    "        pr_dict[f'set{i}'] = pr_matrix\n",
    "        \n",
    "        best_data, best_thres = best_threshold(pr_matrix, target = thres_target, threshold = threshold)\n",
    "        table_set = pd.concat([table_set, best_data]).rename(index = {best_data.index.values[0]: f'dataset {i}'})\n",
    "        \n",
    "        if record_bad:\n",
    "            bad_table = print_badC(predict, test_x, Bad_Types, threshold = best_thres)\n",
    "            bad_set = pd.concat([bad_set, bad_table]).rename(index = {0: f'dataset {i}'})\n",
    "    \n",
    "    if record_bad:\n",
    "        return pr_dict, table_set, bad_set\n",
    "    else:\n",
    "        return pr_dict, table_set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial, train_data = data_dict['set6'], mode = 'C', num_valid = 3):\n",
    "    \n",
    "    param = {\n",
    "        'objective': 'binary:logistic',\n",
    "        'eval_metric': 'logloss',\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 100, 300, step = 50),\n",
    "        'subsample': trial.suggest_float('subsample', 0.5, 0.9, step = 0.2),\n",
    "        'min_child_weight': trial.suggest_int('min_child_weight', 3, 24, step = 3),\n",
    "        'max_depth': trial.suggest_int('max_depth', 3, 13, step = 2),\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.025, 0.425, step = 0.05),\n",
    "        'reg_alpha': trial.suggest_loguniform('reg_alpha', 1e-4, 5), # alpha\n",
    "        'reg_lambda': trial.suggest_loguniform('reg_lambda', 1e-4, 5) # lambda\n",
    "    }\n",
    "\n",
    "    result_list = []\n",
    "    for i in range(num_valid):\n",
    "        \n",
    "        train_x, train_y = label_divide(train_data, None, 'GB', train_only = True)\n",
    "        train_x, valid_x, train_y, valid_y = train_test_split(train_x, train_y, test_size = 0.25)\n",
    "\n",
    "        if mode == 'C':\n",
    "            result = XGBoostC(train_x, valid_x, train_y, valid_y, param)\n",
    "            table = cf_matrix(result, valid_y)\n",
    "            recall = table['Recall']\n",
    "            aging = table['Aging Rate']\n",
    "            effi = table['Efficiency']\n",
    "            \n",
    "            #result_list.append(effi)\n",
    "            result_list.append(recall - 0.1*aging)\n",
    "\n",
    "        elif mode == 'R':\n",
    "            result = XGBoostR(train_x, valid_x, train_y, valid_y, param)\n",
    "            pr_matrix = PR_matrix(result, valid_y)\n",
    "            \n",
    "            best_data, _ = best_threshold(pr_matrix, target = 'Recall', threshold = 0.8)\n",
    "            aging = best_data['Aging Rate']\n",
    "            result_list.append((-1)*aging)\n",
    "            \n",
    "            #auc = AUC(pr_matrix.Recall, pr_matrix.Precision)\n",
    "            #result_list.append((-1)*auc)\n",
    "\n",
    "            \n",
    "    return np.mean(result_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###bad types###\n",
    "bad = pd.read_csv('original_data/Bad_Types.csv').iloc[:, 1:]\n",
    "Bad_Types = {bad.cb[i]:i for i in range (len(bad))}\n",
    "print('Total bad types:', len(bad))\n",
    "\n",
    "###single dataset###\n",
    "test = pd.read_csv('original_data/TestingSet_0.csv').iloc[:, 2:]\n",
    "train = pd.read_csv('original_data/TrainingSet_new.csv').iloc[:, 2:]\n",
    "print('\\ntraining data:', train.shape, '\\nBalance Ratio:', Balance_Ratio(train))\n",
    "print('\\ntesting data:', test.shape, '\\nBalance Ratio:', Balance_Ratio(test))\n",
    "\n",
    "train_x, train_y, test_x, test_y = label_divide(train, test, 'GB')\n",
    "\n",
    "###multiple dataset###\n",
    "data_dict = multiple_set(num_set = 9)\n",
    "trainset_x, trainset_y = train_set(data_dict, num_set = 9, label = 'GB')\n",
    "test_x, test_y = label_divide(test, None, 'GB', train_only = True)\n",
    "\n",
    "\n",
    "#####for runhist dataset#####\n",
    "# bad = pd.read_csv('run_bad_types.csv').iloc[:, 1:]\n",
    "# Bad_Types = {bad.cb[i]:i for i in range (len(bad))}\n",
    "# print('Total bad types:', len(bad))\n",
    "\n",
    "run_test = pd.read_csv('test_runhist.csv').iloc[:, 2:]\n",
    "run_test_x, run_test_y = label_divide(run_test, None, 'GB', train_only = True)\n",
    "print('\\n', 'Dimension of run test:', run_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "\n",
    "# run_clf_param = {\n",
    "#         'objective': 'binary:logistic',\n",
    "#         'eval_metric': 'logloss',\n",
    "#         'n_estimators': 100,\n",
    "#         'subsample': 0.8,\n",
    "#         'min_child_weight': 3,\n",
    "#         'max_depth': 11,\n",
    "#         'learning_rate': 0.075,\n",
    "#         'reg_alpha': 0.0003,\n",
    "#         'reg_lambda': 0.003,\n",
    "# }\n",
    "\n",
    "run_clf_param = {\n",
    "        'objective': 'binary:logistic',\n",
    "        'eval_metric': 'logloss',\n",
    "        'n_estimators': 250,\n",
    "        'subsample': 0.9,\n",
    "        'min_child_weight': 6,\n",
    "        'max_depth': 5,\n",
    "        'learning_rate': 0.025,\n",
    "        'reg_alpha': 0.15,\n",
    "        'reg_lambda': 0.0004,\n",
    "}\n",
    "\n",
    "#table_set1, bad_set1 = runall_XGBoostC(9, trainset_x, test_x, trainset_y, test_y, event_clf_param)\n",
    "table_set1 = runall_XGBoostC(9, trainset_x, run_test_x, trainset_y, run_test_y, run_clf_param, record_bad = False)\n",
    "line_chart(table_set1, title = 'XGBoost Classfifer')\n",
    "#bad_plot(bad_set1)\n",
    "\n",
    "end = time.time()\n",
    "print(\"\\nRun Time：%f seconds\" % (end - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table_set1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####Optimization#####\n",
    "start = time.time()\n",
    "\n",
    "study = optuna.create_study(sampler = optuna.samplers.TPESampler(multivariate = False), direction = 'maximize') \n",
    "#TPE, Random, Grid, CmaEs\n",
    "study.optimize(objective, n_trials = 7500, show_progress_bar = True, gc_after_trial = True) #n_trials or timeout\n",
    " \n",
    "print(f\"Sampler is {study.sampler.__class__.__name__}\")\n",
    "print('Number of finished trials:', len(study.trials))\n",
    "print('Best trial:', study.best_trial.params)\n",
    "\n",
    "with open('tmp.data', 'wb') as f:\n",
    "    pickle.dump(study, f)\n",
    "\n",
    "end = time.time()\n",
    "print(\"\\nRun Time：%f seconds\" % (end - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### top 50 hyper-parameters#####\n",
    "all_value = []\n",
    "[all_value.append(x.values) for x in study.trials]\n",
    "val = np.array(all_value)\n",
    "best_val = np.flip(val.argsort(axis = 0))[0:25]\n",
    "val_table = pd.DataFrame()\n",
    "for i in best_val:\n",
    "    temp_table = pd.DataFrame(pd.Series(study.trials[i[0]].params)).T\n",
    "    temp_table['value'] = study.trials[i[0]].value\n",
    "    val_table = pd.concat([val_table, temp_table])\n",
    "\n",
    "val_table = val_table.reset_index(drop = True)\n",
    "val_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####value loss plot#####\n",
    "val_tpe = val\n",
    "#val_mtpe = val\n",
    "\n",
    "fig = plt.figure(figsize = (15,8))\n",
    "plt.plot(val_tpe, 'b--', linewidth = 0.1, label = 'TPE')\n",
    "#plt.plot(val_mtpe, 'r-', linewidth = 0.1, label = 'MTPE')\n",
    "plt.title('Optimized Values of XGBoost Classifier (recall - 0.1*aging rate)')\n",
    "plt.xlabel('Iterations')\n",
    "plt.ylabel('Values')\n",
    "plt.legend(loc = 'lower right', frameon = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### hyperparameter importance #####\n",
    "start = time.time()\n",
    "\n",
    "#importances = optuna.importance.get_param_importances(study)\n",
    "#importances.optuna.importance.get_param_importances(study, evaluator = optuna.importance.FanovaImportanceEvaluator())\n",
    "\n",
    "optuna.visualization.plot_param_importances(study)\n",
    "\n",
    "end = time.time()\n",
    "print(\"\\nRun Time：%f seconds\" % (end - start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "\n",
    "run_reg_param = {\n",
    "        'objective': 'binary:logistic',\n",
    "        'eval_metric': 'logloss',\n",
    "        'n_estimators': 50,\n",
    "        'subsample': 0.7,\n",
    "        'min_child_weight': 4,\n",
    "        'max_depth': 9,\n",
    "        'learning_rate': 0.1,\n",
    "        'reg_alpha': 0,\n",
    "        'reg_lambda': 0.2,\n",
    "}\n",
    "\n",
    "# pr_dict, table_set2, bad_set2 = runall_XGBoostR(9, trainset_x, test_x, trainset_y, test_y, event_reg_param, \n",
    "#                                                 thres_target = 'Recall', threshold = 0.8)\n",
    "pr_dict, table_set2 = runall_XGBoostR(9, trainset_x, run_test_x, trainset_y, run_test_y, run_reg_param, \n",
    "                                       thres_target = 'Recall', threshold = 0.8, record_bad = False)\n",
    "line_chart(table_set2, title = 'XGBoost Regressor')\n",
    "#bad_plot(bad_set2)\n",
    "\n",
    "end = time.time()\n",
    "print(\"\\nRun Time：%f seconds\" % (end - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multiple_curve(3, 3, pr_dict, table_set2, target = 'Aging Rate')\n",
    "multiple_curve(3, 3, pr_dict, table_set2, target = 'Precision')\n",
    "table_set2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "\n",
    "clf = xgb.XGBClassifier(n_estimators = 50, \n",
    "                        learning_rate = 0.1, \n",
    "                        min_child_weight = 4, \n",
    "                        subsample = 0.7, \n",
    "                        max_depth = 9, \n",
    "                        reg_lambda = 0.2\n",
    "                       )\n",
    "\n",
    "reg = xgb.XGBRegressor(n_estimators = 200, \n",
    "                        learning_rate = 0.1, \n",
    "                        min_child_weight = 4, \n",
    "                        subsample = 0.7, \n",
    "                        max_depth = 7, \n",
    "                        reg_lambda = 0.2\n",
    "                       )\n",
    "\n",
    "param_dict = {\n",
    "            'n_estimators': [100, 150,200],\n",
    "            'learning_rate': [0.1, 0.2],\n",
    "            'min_child_weight': [4, 5, 6, 7, 8],\n",
    "            'subsample': [0.7],\n",
    "            'max_depth': [3, 5, 7, 9],\n",
    "            'reg_lambda':np.array([0.2])\n",
    "            }\n",
    "\n",
    "fit_params = {'early_stopping_rounds': 10}\n",
    "\n",
    "grid_search = GridSearchCV(clf, param_grid = param_dict, scoring = 'precision', cv = 3, verbose = 10, n_jobs = -1)\n",
    "\n",
    "train_x, train_y = label_divide(data_dict['set5'], None, train_only = True)\n",
    "result = grid_search.fit(train_x, train_y)\n",
    "\n",
    "end = time.time()\n",
    "print(\"\\nRun Time：%f seconds\" % (end - start))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
