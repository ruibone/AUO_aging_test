{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-18T08:03:45.921419Z",
     "start_time": "2021-08-18T08:03:44.668970Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\user\\\\Desktop\\\\Darui_R08621110'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import itertools\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression, RidgeCV\n",
    "from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor\n",
    "from catboost import CatBoostClassifier, CatBoostRegressor\n",
    "import optuna\n",
    "\n",
    "from Dataset_Construction import Balance_Ratio \n",
    "from Sampling import label_divide\n",
    "from AdaClassifier import train_set, multiple_set, print_badC, bad_plot, line_chart, cf_matrix, runall_AdaBoostC\n",
    "from AdaRegressor import AUC, PR_curve, multiple_curve, PR_matrix, best_threshold, runall_AdaBoostR\n",
    "from Aging_Score import score1\n",
    "from XGBoost import optuna_history, all_optuna, runall_XGBoostC, runall_XGBoostR\n",
    "from CatBoost import runall_CatBoostC, runall_CatBoostR\n",
    "from Light_GBM import runall_LightGBMC, runall_LightGBMR\n",
    "\n",
    "os.chdir('C:/Users/user/Desktop/Darui_R08621110')  \n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load all hyperparamters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-18T08:03:46.029511Z",
     "start_time": "2021-08-18T08:03:46.011002Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def load_hyper(num_set, date, model_list, iter_list, filename, mode, sampler) :\n",
    "    \n",
    "    allset_dict = {}\n",
    "    for j in range(num_set) :\n",
    "\n",
    "        oneset_dict = {}\n",
    "        for i, model in enumerate(model_list) :\n",
    "\n",
    "            with open(f'hyperparameter/{date}/{filename}_{model}{mode}_{sampler}_{iter_list[i]}.data', 'rb') as f :\n",
    "                temp_dict = pickle.load(f)\n",
    "                oneset_dict[model] = temp_dict[f'set{j}']\n",
    "        allset_dict[f'set{j}'] = oneset_dict\n",
    "        \n",
    "    return allset_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-18T16:04:17.411279Z",
     "start_time": "2021-08-18T16:04:17.382601Z"
    }
   },
   "outputs": [],
   "source": [
    "hyper_info = {\n",
    "    'num_set': 10,\n",
    "    'date' = '20210802',\n",
    "    'model_list': ['LightGBM', 'XGBoost'],\n",
    "    'iter_listC': [1000, 1000],\n",
    "    'filename': 'runhist_array_label',\n",
    "    'mode': 'R',\n",
    "    'sampler': 'multivaraite-TPE'\n",
    "}\n",
    "\n",
    "all_hyper = load_hyper(**hyper_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-19T10:41:24.714144Z",
     "start_time": "2021-08-19T10:41:24.703174Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'set0': {'boosting_type': 'gbdt',\n",
       "  'num_iterations': 150,\n",
       "  'subsample': 0.7,\n",
       "  'num_leaves': 10,\n",
       "  'min_child_samples': 6,\n",
       "  'max_depth': 15,\n",
       "  'learning_rate': 0.125,\n",
       "  'lambda_l1': 0.0002429249667917133,\n",
       "  'lambda_l2': 0.1068127782917783},\n",
       " 'set1': {'boosting_type': 'goss',\n",
       "  'num_iterations': 150,\n",
       "  'subsample': 0.5,\n",
       "  'num_leaves': 25,\n",
       "  'min_child_samples': 3,\n",
       "  'max_depth': 11,\n",
       "  'learning_rate': 0.425,\n",
       "  'lambda_l1': 0.00023689666839152366,\n",
       "  'lambda_l2': 0.11260668391396508},\n",
       " 'set2': {'boosting_type': 'goss',\n",
       "  'num_iterations': 300,\n",
       "  'subsample': 0.9,\n",
       "  'num_leaves': 30,\n",
       "  'min_child_samples': 12,\n",
       "  'max_depth': 5,\n",
       "  'learning_rate': 0.37500000000000006,\n",
       "  'lambda_l1': 1.3617102824283553,\n",
       "  'lambda_l2': 0.1530279986362752},\n",
       " 'set3': {'boosting_type': 'goss',\n",
       "  'num_iterations': 150,\n",
       "  'subsample': 0.5,\n",
       "  'num_leaves': 15,\n",
       "  'min_child_samples': 6,\n",
       "  'max_depth': 13,\n",
       "  'learning_rate': 0.425,\n",
       "  'lambda_l1': 0.7320668921292203,\n",
       "  'lambda_l2': 0.0693182530107957},\n",
       " 'set4': {'boosting_type': 'gbdt',\n",
       "  'num_iterations': 100,\n",
       "  'subsample': 0.9,\n",
       "  'num_leaves': 35,\n",
       "  'min_child_samples': 15,\n",
       "  'max_depth': 11,\n",
       "  'learning_rate': 0.37500000000000006,\n",
       "  'lambda_l1': 0.0001206053488998816,\n",
       "  'lambda_l2': 0.0031293722281084332},\n",
       " 'set5': {'boosting_type': 'gbdt',\n",
       "  'num_iterations': 150,\n",
       "  'subsample': 0.9,\n",
       "  'num_leaves': 40,\n",
       "  'min_child_samples': 12,\n",
       "  'max_depth': 9,\n",
       "  'learning_rate': 0.17500000000000002,\n",
       "  'lambda_l1': 0.00017779630877615355,\n",
       "  'lambda_l2': 0.0025242411359167375},\n",
       " 'set6': {'boosting_type': 'gbdt',\n",
       "  'num_iterations': 300,\n",
       "  'subsample': 0.9,\n",
       "  'num_leaves': 35,\n",
       "  'min_child_samples': 12,\n",
       "  'max_depth': 11,\n",
       "  'learning_rate': 0.275,\n",
       "  'lambda_l1': 0.0017928761143631987,\n",
       "  'lambda_l2': 2.8244503130530556},\n",
       " 'set7': {'boosting_type': 'goss',\n",
       "  'num_iterations': 150,\n",
       "  'subsample': 0.7,\n",
       "  'num_leaves': 40,\n",
       "  'min_child_samples': 9,\n",
       "  'max_depth': 9,\n",
       "  'learning_rate': 0.07500000000000001,\n",
       "  'lambda_l1': 0.00018227243820862567,\n",
       "  'lambda_l2': 0.013534353068807918},\n",
       " 'set8': {'boosting_type': 'goss',\n",
       "  'num_iterations': 250,\n",
       "  'subsample': 0.9,\n",
       "  'num_leaves': 25,\n",
       "  'min_child_samples': 24,\n",
       "  'max_depth': 13,\n",
       "  'learning_rate': 0.025,\n",
       "  'lambda_l1': 0.07004581827528544,\n",
       "  'lambda_l2': 0.00010618892244093734},\n",
       " 'set9': {'boosting_type': 'goss',\n",
       "  'num_iterations': 250,\n",
       "  'subsample': 0.9,\n",
       "  'num_leaves': 25,\n",
       "  'min_child_samples': 24,\n",
       "  'max_depth': 13,\n",
       "  'learning_rate': 0.025,\n",
       "  'lambda_l1': 0.07004581827528544,\n",
       "  'lambda_l2': 0.00010618892244093734}}"
      ]
     },
     "execution_count": 284,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('hyperparameter/20210802/runhist_array_label_LightGBMR_multivariate-TPE_1000.data', 'rb') as f :\n",
    "    temp_dict = pickle.load(f)\n",
    "temp_dict['set9'] = temp_dict['set8']\n",
    "temp_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-19T09:39:49.195435Z",
     "start_time": "2021-08-19T09:39:45.815710Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimension of dataset 0 : (120255, 176)  balance ratio: 1063.20354\n",
      "Dimension of dataset 1 : (2446, 176)  balance ratio: 1.0\n",
      "Dimension of dataset 2 : (2158, 176)  balance ratio: 1.0\n",
      "Dimension of dataset 3 : (2626, 176)  balance ratio: 1.0\n",
      "Dimension of dataset 4 : (2402, 176)  balance ratio: 1.0\n",
      "Dimension of dataset 5 : (2242, 176)  balance ratio: 1.01619\n",
      "Dimension of dataset 6 : (2210, 176)  balance ratio: 1.0463\n",
      "Dimension of dataset 7 : (2260, 176)  balance ratio: 1.0\n",
      "Dimension of dataset 8 : (2260, 176)  balance ratio: 1.0\n",
      "Dimension of dataset 9 : (1243, 176)  balance ratio: 10.0\n",
      "\n",
      " 10 datasets are loaded.\n",
      "\n",
      "Labels of  10 datasets are divided.\n",
      "Dimension of run test_1: (99400, 175)\n",
      "Dimension of run test_2: (106392, 175)\n",
      "Dimension of run test_3: (51035, 175)\n",
      "Dimension of run test_4: (47725, 175)\n",
      "Dimension of run test_5: (67071, 175)\n",
      "Dimension of run test_6: (33409, 175)\n"
     ]
    }
   ],
   "source": [
    "##### test different time series data on boosting models #####\n",
    "#####for runhist dataset#####\n",
    "# bad = pd.read_csv('run_bad_types.csv').iloc[:, 1:]\n",
    "# Bad_Types = {bad.cb[i]:i for i in range (len(bad))}\n",
    "# print('Total bad types:', len(bad))\n",
    "\n",
    "data_dict = multiple_set(num_set = 10)\n",
    "trainset_x, trainset_y = train_set(data_dict, num_set = 10, label = 'GB')\n",
    "\n",
    "# merge with module\n",
    "test_m23 = pd.read_csv('array_m2_m3.csv').iloc[:, 2:]\n",
    "test_m45 = pd.read_csv('array_m4_m5.csv').iloc[:, 2:]\n",
    "test_m67 = pd.read_csv('array_m6_m7.csv').iloc[:, 2:]\n",
    "testm23_x, testm23_y = label_divide(test_m23, None, 'GB', train_only = True)\n",
    "testm45_x, testm45_y = label_divide(test_m45, None, 'GB', train_only = True)\n",
    "testm67_x, testm67_y = label_divide(test_m67, None, 'GB', train_only = True)\n",
    "\n",
    "# merge with DataSet\n",
    "test_m23_dset = pd.read_csv('array_m23_dset.csv').iloc[:, 2:]\n",
    "test_m45_dset = pd.read_csv('array_m45_dset.csv').iloc[:, 2:]\n",
    "test_m67_dset = pd.read_csv('array_m67_dset.csv').iloc[:, 2:]\n",
    "dsetm23_x, dsetm23_y = label_divide(test_m23_dset, None, 'GB', train_only = True)\n",
    "dsetm45_x, dsetm45_y = label_divide(test_m45_dset, None, 'GB', train_only = True)\n",
    "dsetm67_x, dsetm67_y = label_divide(test_m67_dset, None, 'GB', train_only = True)\n",
    "\n",
    "print('Dimension of run test_1:', testm23_x.shape)\n",
    "print('Dimension of run test_2:', testm45_x.shape)\n",
    "print('Dimension of run test_3:', testm67_x.shape)\n",
    "print('Dimension of run test_4:', dsetm23_x.shape)\n",
    "print('Dimension of run test_5:', dsetm45_x.shape)\n",
    "print('Dimension of run test_6:', dsetm67_x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-19T09:42:25.178657Z",
     "start_time": "2021-08-19T09:42:24.830942Z"
    }
   },
   "outputs": [],
   "source": [
    "ohno = pd.read_csv('ohno.csv').iloc[:, 2:]\n",
    "ohno_x, ohno_y = label_divide(ohno, None, 'GB', train_only = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-19T10:29:17.882966Z",
     "start_time": "2021-08-19T10:28:56.290105Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Dataset 0:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\envs\\aging\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[18:28:56] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Precision: 0.0 \n",
      "Recall: 0.0 \n",
      "Aging Rate: 1.7596959245442388e-05\n",
      "\n",
      " Dataset 1:\n",
      "[18:29:14] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Precision: 0.00036735443580481234 \n",
      "Recall: 0.7058823529411765 \n",
      "Aging Rate: 0.5748222707116211\n",
      "\n",
      " Dataset 2:\n",
      "[18:29:15] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Precision: 0.00025687130747495504 \n",
      "Recall: 0.7058823529411765 \n",
      "Aging Rate: 0.8220595481100865\n",
      "\n",
      " Dataset 3:\n",
      "[18:29:15] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Precision: 0.0003358038905279317 \n",
      "Recall: 0.8235294117647058 \n",
      "Aging Rate: 0.7336348279017386\n",
      "\n",
      " Dataset 4:\n",
      "[18:29:16] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Precision: 0.00034277879341864715 \n",
      "Recall: 0.7058823529411765 \n",
      "Aging Rate: 0.6160343492644471\n",
      "\n",
      " Dataset 5:\n",
      "[18:29:16] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Precision: 0.00037288587028898654 \n",
      "Recall: 0.8235294117647058 \n",
      "Aging Rate: 0.6606778348701344\n",
      "\n",
      " Dataset 6:\n",
      "[18:29:16] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Precision: 0.000301229564312512 \n",
      "Recall: 0.6470588235294118 \n",
      "Aging Rate: 0.6425881607658197\n",
      "\n",
      " Dataset 7:\n",
      "[18:29:17] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Precision: 0.00036263636638360884 \n",
      "Recall: 0.7058823529411765 \n",
      "Aging Rate: 0.5823009783909341\n",
      "\n",
      " Dataset 8:\n",
      "[18:29:17] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Precision: 0.0003639315808627978 \n",
      "Recall: 0.7647058823529411 \n",
      "Aging Rate: 0.6285809812064476\n",
      "\n",
      " Dataset 9:\n",
      "[18:29:17] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Precision: 0.0003161737230893047 \n",
      "Recall: 0.6470588235294118 \n",
      "Aging Rate: 0.6122158091081861\n"
     ]
    }
   ],
   "source": [
    "xgb_tableC = runall_XGBoostC(10, trainset_x, ohno_x, trainset_y, ohno_y, temp_dict, record_bad = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-19T10:35:12.491113Z",
     "start_time": "2021-08-19T10:34:56.137028Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Dataset 0:\n",
      "Best Threshold: -0.00752921961247921 \n",
      "\n",
      "Recall: [0.82352941] ,   Precision: [0.00026384] ,   Aging Rate: [0.93374745]\n",
      "\n",
      " Dataset 1:\n",
      "Best Threshold: 0.465803861618042 \n",
      "\n",
      "Recall: [0.82352941] ,   Precision: [0.00044536] ,   Aging Rate: [0.55316041]\n",
      "\n",
      " Dataset 2:\n",
      "Best Threshold: 0.474698930978775 \n",
      "\n",
      "Recall: [0.82352941] ,   Precision: [0.00033404] ,   Aging Rate: [0.73750616]\n",
      "\n",
      " Dataset 3:\n",
      "Best Threshold: 0.29873254895210266 \n",
      "\n",
      "Recall: [0.82352941] ,   Precision: [0.00029693] ,   Aging Rate: [0.82967903]\n",
      "\n",
      " Dataset 4:\n",
      "Best Threshold: 0.416493684053421 \n",
      "\n",
      "Recall: [0.82352941] ,   Precision: [0.00041382] ,   Aging Rate: [0.59532273]\n",
      "\n",
      " Dataset 5:\n",
      "Best Threshold: 0.400826632976532 \n",
      "\n",
      "Recall: [0.82352941] ,   Precision: [0.00040252] ,   Aging Rate: [0.61203984]\n",
      "\n",
      " Dataset 6:\n",
      "Best Threshold: 0.32208555936813354 \n",
      "\n",
      "Recall: [0.82352941] ,   Precision: [0.00032903] ,   Aging Rate: [0.74873302]\n",
      "\n",
      " Dataset 7:\n",
      "Best Threshold: 0.4086665213108063 \n",
      "\n",
      "Recall: [0.82352941] ,   Precision: [0.0003482] ,   Aging Rate: [0.70752094]\n",
      "\n",
      " Dataset 8:\n",
      "Best Threshold: 0.34452760219573975 \n",
      "\n",
      "Recall: [0.82352941] ,   Precision: [0.00039041] ,   Aging Rate: [0.63102696]\n",
      "\n",
      " Dataset 9:\n",
      "Best Threshold: 0.1382046788930893 \n",
      "\n",
      "Recall: [0.82352941] ,   Precision: [0.00029506] ,   Aging Rate: [0.83494052]\n"
     ]
    }
   ],
   "source": [
    "xgb_pr, xgb_tableR = runall_XGBoostR(10, trainset_x, ohno_x, trainset_y, ohno_y, temp_dict, thres_target = 'Recall', \n",
    "                                      threshold = 0.8, record_bad = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-19T10:38:04.539369Z",
     "start_time": "2021-08-19T10:38:01.994669Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Dataset 0:\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.03265531301286261, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.03265531301286261\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.150179864427085, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.150179864427085\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\envs\\aging\\lib\\site-packages\\lightgbm\\engine.py:148: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.0 \n",
      "Recall: 0.0 \n",
      "Aging Rate: 3.5193918490884776e-05\n",
      "\n",
      " Dataset 1:\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.02013689878809467, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.02013689878809467\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.3386848304795381, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.3386848304795381\n",
      "Precision: 0.00033466268789915496 \n",
      "Recall: 0.7058823529411765 \n",
      "Aging Rate: 0.6309741676638277\n",
      "\n",
      " Dataset 2:\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.06215139908328629, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.06215139908328629\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.14310123024206844, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.14310123024206844\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\envs\\aging\\lib\\site-packages\\lightgbm\\engine.py:148: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "C:\\Users\\user\\anaconda3\\envs\\aging\\lib\\site-packages\\lightgbm\\engine.py:148: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.0002897387893376126 \n",
      "Recall: 0.7647058823529411 \n",
      "Aging Rate: 0.7895403674245091\n",
      "\n",
      " Dataset 3:\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.00011052589691180843, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.00011052589691180843\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.01134617772508088, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.01134617772508088\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\envs\\aging\\lib\\site-packages\\lightgbm\\engine.py:148: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.00032256463699072006 \n",
      "Recall: 0.7647058823529411 \n",
      "Aging Rate: 0.7091926515098191\n",
      "\n",
      " Dataset 4:\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.03002282191623749, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.03002282191623749\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.5567812011448332, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.5567812011448332\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\envs\\aging\\lib\\site-packages\\lightgbm\\engine.py:148: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.0004124683283247893 \n",
      "Recall: 0.8235294117647058 \n",
      "Aging Rate: 0.5972759907088055\n",
      "\n",
      " Dataset 5:\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0001255438606755358, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0001255438606755358\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0028684855553975856, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0028684855553975856\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\envs\\aging\\lib\\site-packages\\lightgbm\\engine.py:148: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.0003954011801204453 \n",
      "Recall: 0.7647058823529411 \n",
      "Aging Rate: 0.5785528260716548\n",
      "\n",
      " Dataset 6:\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.00010774222769323541, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.00010774222769323541\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.039805701972297, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.039805701972297\n",
      "Precision: 0.00034027850486860017 \n",
      "Recall: 0.7647058823529411 \n",
      "Aging Rate: 0.672274231012881\n",
      "\n",
      " Dataset 7:\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.015213315135949998, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.015213315135949998\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.042570427717632905, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.042570427717632905\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\envs\\aging\\lib\\site-packages\\lightgbm\\engine.py:148: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "C:\\Users\\user\\anaconda3\\envs\\aging\\lib\\site-packages\\lightgbm\\engine.py:148: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.0003411275817155616 \n",
      "Recall: 0.6470588235294118 \n",
      "Aging Rate: 0.5674315478285352\n",
      "\n",
      " Dataset 8:\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0003078738015532879, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0003078738015532879\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0019412207442328546, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0019412207442328546\n",
      "Precision: 0.000362844702467344 \n",
      "Recall: 0.7058823529411765 \n",
      "Aging Rate: 0.5819666361652707\n",
      "\n",
      " Dataset 9:\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0003078738015532879, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0003078738015532879\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0019412207442328546, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0019412207442328546\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\envs\\aging\\lib\\site-packages\\lightgbm\\engine.py:148: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "C:\\Users\\user\\anaconda3\\envs\\aging\\lib\\site-packages\\lightgbm\\engine.py:148: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.0003239041243791838 \n",
      "Recall: 0.7058823529411765 \n",
      "Aging Rate: 0.6519321461251496\n"
     ]
    }
   ],
   "source": [
    "lgb_tableC = runall_LightGBMC(10, trainset_x, ohno_x, trainset_y, ohno_y, temp_dict, record_bad = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-19T10:42:27.398153Z",
     "start_time": "2021-08-19T10:42:24.561792Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Dataset 0:\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0002429249667917133, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0002429249667917133\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.1068127782917783, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.1068127782917783\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\envs\\aging\\lib\\site-packages\\lightgbm\\engine.py:148: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Threshold: -0.00010362633828748315 \n",
      "\n",
      "Recall: [0.82352941] ,   Precision: [0.00031831] ,   Aging Rate: [0.77394946]\n",
      "\n",
      " Dataset 1:\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.00023689666839152366, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.00023689666839152366\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.11260668391396508, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.11260668391396508\n",
      "Best Threshold: 0.41300879302096627 \n",
      "\n",
      "Recall: [0.82352941] ,   Precision: [0.00042091] ,   Aging Rate: [0.58529246]\n",
      "\n",
      " Dataset 2:\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.3617102824283553, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.3617102824283553\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.1530279986362752, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.1530279986362752\n",
      "Best Threshold: 0.3919229333414923 \n",
      "\n",
      "Recall: [0.82352941] ,   Precision: [0.00032627] ,   Aging Rate: [0.75506792]\n",
      "\n",
      " Dataset 3:\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.7320668921292203, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.7320668921292203\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0693182530107957, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0693182530107957\n",
      "Best Threshold: 0.17065852609249646 \n",
      "\n",
      "Recall: [0.82352941] ,   Precision: [0.00027855] ,   Aging Rate: [0.88444077]\n",
      "\n",
      " Dataset 4:\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0001206053488998816, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0001206053488998816\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0031293722281084332, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0031293722281084332\n",
      "Best Threshold: 0.5682245108103473 \n",
      "\n",
      "Recall: [0.82352941] ,   Precision: [0.00052323] ,   Aging Rate: [0.47084184]\n",
      "\n",
      " Dataset 5:\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.00017779630877615355, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.00017779630877615355\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0025242411359167375, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0025242411359167375\n",
      "Best Threshold: 0.22101899277914808 \n",
      "\n",
      "Recall: [0.82352941] ,   Precision: [0.00032504] ,   Aging Rate: [0.75793623]\n",
      "\n",
      " Dataset 6:\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0017928761143631987, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0017928761143631987\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.8244503130530556, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.8244503130530556\n",
      "Best Threshold: 0.3397129800365034 \n",
      "\n",
      "Recall: [0.82352941] ,   Precision: [0.00035681] ,   Aging Rate: [0.69045189]\n",
      "\n",
      " Dataset 7:\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.00018227243820862567, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.00018227243820862567\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.013534353068807918, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.013534353068807918\n",
      "Best Threshold: 0.29657056403514664 \n",
      "\n",
      "Recall: [0.82352941] ,   Precision: [0.00035257] ,   Aging Rate: [0.69874006]\n",
      "\n",
      " Dataset 8:\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.07004581827528544, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.07004581827528544\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.00010618892244093734, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.00010618892244093734\n",
      "Best Threshold: 0.33700299395747774 \n",
      "\n",
      "Recall: [0.82352941] ,   Precision: [0.00041247] ,   Aging Rate: [0.59727599]\n",
      "\n",
      " Dataset 9:\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.07004581827528544, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.07004581827528544\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.00010618892244093734, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.00010618892244093734\n",
      "Best Threshold: 0.28720850071030196 \n",
      "\n",
      "Recall: [0.82352941] ,   Precision: [0.00037699] ,   Aging Rate: [0.65348068]\n"
     ]
    }
   ],
   "source": [
    "lgb_pr, lgb_tableR = runall_LightGBMR(10, trainset_x, ohno_x, trainset_y, ohno_y, temp_dict, thres_target = 'Recall', \n",
    "                                      threshold = 0.8, record_bad = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-20T12:42:02.959464Z",
     "start_time": "2021-08-20T12:42:02.949491Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function Dataset_Construction.Balance_Ratio(data, label='GB', n=5)>"
      ]
     },
     "execution_count": 289,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Balance_Ratio"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python [conda env:aging]",
   "language": "python",
   "name": "conda-env-aging-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
