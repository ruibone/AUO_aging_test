{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-23T05:46:39.650200Z",
     "start_time": "2021-08-23T05:46:37.808325Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import itertools\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.auto import tqdm\n",
    "import pickle\n",
    "\n",
    "from sklearn.ensemble import AdaBoostClassifier \n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import optuna\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from Dataset_Construction import Balance_Ratio\n",
    "from Sampling import label_divide\n",
    "from Aging_Score import score1\n",
    "from XGBoost import optuna_history, all_optuna\n",
    "\n",
    "os.chdir('C:/Users/user/Desktop/Darui_R08621110')  \n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load multiple dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-23T05:46:42.152212Z",
     "start_time": "2021-08-23T05:46:42.144233Z"
    }
   },
   "outputs": [],
   "source": [
    "def multiple_set(num_set):\n",
    "    \n",
    "    data_dict = {}\n",
    "    for i in range(num_set):\n",
    "        data_dict[f'set{i}'] = pd.read_csv(f'dataset_{i}.csv').iloc[:, 1:]\n",
    "        print('Dimension of dataset', i, ':', data_dict[f'set{i}'].shape, ' balance ratio:', \\\n",
    "              Balance_Ratio(data_dict[f'set{i}']))\n",
    "    \n",
    "    print('\\n', num_set, 'datasets are loaded.')\n",
    "    return data_dict\n",
    "\n",
    "\n",
    "def train_set(data_dict, num_set, label = 'GB'):\n",
    "    \n",
    "    trainset_x = {}\n",
    "    trainset_y = {}\n",
    "    \n",
    "    for i in range(num_set):\n",
    "        X, Y = label_divide(data_dict[f'set{i}'], None, label, train_only = True)\n",
    "        trainset_x[f'set{i}'] = X\n",
    "        trainset_y[f'set{i}'] = Y\n",
    "        \n",
    "    print('\\nLabels of ', num_set, 'datasets are divided.')\n",
    "    return trainset_x, trainset_y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Boosting Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-23T05:46:44.853834Z",
     "start_time": "2021-08-23T05:46:44.848847Z"
    }
   },
   "outputs": [],
   "source": [
    "def AdaBoostC(train_x, test_x, train_y, test_y, config):\n",
    "    \n",
    "    clf = AdaBoostClassifier(**config)\n",
    "    clf.fit(train_x, train_y)\n",
    "    predict_y = clf.predict(test_x)\n",
    "    result = pd.DataFrame({'truth': test_y, 'predict': predict_y})\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recall & Precision for Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-23T05:46:45.886417Z",
     "start_time": "2021-08-23T05:46:45.870795Z"
    }
   },
   "outputs": [],
   "source": [
    "def cf_matrix(predict, train_y):\n",
    "    \n",
    "    # confusion matrix\n",
    "    mask_FP = predict['predict'] > predict['truth']\n",
    "    mask_FN = predict['predict'] < predict['truth']\n",
    "    mask_TP = (predict['predict'] == predict['truth']) * (predict['predict'] == 1)\n",
    "    mask_TN = (predict['predict'] == predict['truth']) * (predict['predict'] == 0)\n",
    "    TP = mask_TP.sum()\n",
    "    FP = mask_FP.sum()\n",
    "    FN = mask_FN.sum()\n",
    "    TN = mask_TN.sum()\n",
    "    \n",
    "    #balance ratio, train OK & NG\n",
    "    train_OK = sum(train_y < 0.5)\n",
    "    train_NG = len(train_y) - train_OK\n",
    "    br = train_OK / train_NG\n",
    "    \n",
    "    #precision, recall, aging rate, efficiency, score\n",
    "    num_pd = TP + FP\n",
    "    if num_pd != 0:\n",
    "        precision = TP / num_pd\n",
    "    else:\n",
    "        precision = 0\n",
    "    \n",
    "    recall = TP / (TP + FN)\n",
    "    ar = (TP + FP) / (TP + FP + FN + TN)\n",
    "    eff = recall / ar\n",
    "    score = score1(recall, ar)\n",
    "    \n",
    "    table = pd.Series({'Balance Ratio': br, 'Train_OK': train_OK, 'Train_NG': train_NG, 'TP': TP, 'FP': FP, 'FN': FN, \\\n",
    "                       'TN': TN, 'Precision': precision, 'Recall': recall, 'Aging Rate': ar, 'Efficiency': eff, 'Score': score})\n",
    "    table = pd.DataFrame(table).T\n",
    "    \n",
    "    print('Precision:', precision, '\\nRecall:', recall, '\\nAging Rate:', ar)\n",
    "    return  table\n",
    "\n",
    "\n",
    "def print_badC(predict, test_x, Bad_Types, threshold = 1):\n",
    "    \n",
    "    Bad = []\n",
    "    Bad_miss = []\n",
    "    TP = predict[(predict['truth'] == 1) & (predict['predict'] >= threshold)].index\n",
    "    FN = predict[(predict['truth'] == 1) & (predict['predict'] < threshold)].index\n",
    "    for j in range(len(TP)):\n",
    "        Index = TP[j]\n",
    "        Key = test_x.values[Index]\n",
    "        Key = pd.DataFrame(Key).T.apply(lambda x:'_'.join(x.astype(str)), axis = 1)\n",
    "        Bad.append(Bad_Types[Key[0]])\n",
    "        Bad.sort()\n",
    "    print('Types of Bad found:', Bad) \n",
    "    \n",
    "    for j in range(len(FN)):\n",
    "        Index = FN[j]\n",
    "        Key = test_x.values[Index]\n",
    "        Key = pd.DataFrame(Key).T.apply(lambda x:'_'.join(x.astype(str)),axis=1)\n",
    "        Bad_miss.append(Bad_Types[Key[0]])\n",
    "        Bad_miss.sort()\n",
    "    print('Types of Bad not found:', Bad_miss)\n",
    "    \n",
    "    bad_table = pd.Series({'Bad_Found': set(Bad), 'Bad_Missed': set(Bad_miss)})\n",
    "    bad_table = pd.DataFrame(bad_table).T\n",
    "    bad_table['Detect Ratio'] = len(Bad) / (len(Bad) + len(Bad_miss))\n",
    "    \n",
    "    return bad_table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run all dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-23T05:46:46.916392Z",
     "start_time": "2021-08-23T05:46:46.902430Z"
    }
   },
   "outputs": [],
   "source": [
    "def runall_AdaBoostC(num_set, trainset_x, test_x, trainset_y, test_y, config, record_bad = True):\n",
    "    \n",
    "    table_set = pd.DataFrame()\n",
    "    bad_set = pd.DataFrame()\n",
    "    judge = list(config.keys())[0]\n",
    "\n",
    "    for i in tqdm(range(num_set)):\n",
    "        print('\\n', f'Dataset {i}:')\n",
    "        \n",
    "        if isinstance(config[judge], dict) :\n",
    "            best_config = config[f'set{i}']\n",
    "        else :\n",
    "            best_config = config\n",
    "            \n",
    "        # seperate the decision tree hyperparameter and adaboost hyperparameter\n",
    "        tree_param = {'base_estimator': DecisionTreeClassifier(max_depth = best_config['max_depth'])}\n",
    "        boost_param = dict((key, best_config[key]) for key in ['learning_rate', 'n_estimators'] if key in best_config)\n",
    "        boost_param.update(tree_param)\n",
    "\n",
    "        result = AdaBoostC(trainset_x[f'set{i}'], test_x, trainset_y[f'set{i}'], test_y, boost_param)\n",
    "        table = cf_matrix(result, trainset_y[f'set{i}'])\n",
    "        table_set = pd.concat([table_set, table]).rename(index = {0: f'dataset {i}'})\n",
    "        \n",
    "        if record_bad:\n",
    "            bad_table = print_badC(result, test_x, Bad_Types) \n",
    "            bad_set = pd.concat([bad_set, bad_table]).rename(index = {0: f'dataset {i}'})\n",
    "\n",
    "    if record_bad:\n",
    "        return table_set, bad_set\n",
    "    else:\n",
    "        return table_set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot all dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-23T05:46:48.179171Z",
     "start_time": "2021-08-23T05:46:48.087691Z"
    }
   },
   "outputs": [],
   "source": [
    "def bad_plot(bad_set):\n",
    "    \n",
    "    # record all bad types\n",
    "    bad_list = []\n",
    "    [bad_list.append(x) for x in bad_set.loc['dataset 1'][0]]\n",
    "    [bad_list.append(x) for x in bad_set.loc['dataset 1'][1]]\n",
    "    bad_list.sort()\n",
    "    \n",
    "    bad_array = np.empty([len(bad_set), len(bad_list)])\n",
    "    for j in range(len(bad_set)):\n",
    "        for i in range(len(bad_list)):\n",
    "            if bad_list[i] in bad_set.iloc[j, 0]:\n",
    "                bad_array[j, i] = 1\n",
    "            else:\n",
    "                bad_array[j ,i] = 0\n",
    "                          \n",
    "    bad_df = pd.DataFrame(bad_array)\n",
    "    bad_df.columns = bad_list\n",
    "    \n",
    "    plt.pcolor(bad_df, cmap = 'Reds')\n",
    "    plt.title(\"Bad Types Detection across All Datasets\")\n",
    "    plt.yticks(np.arange(0.5, len(bad_df.index), 1), bad_df.index)\n",
    "    plt.xticks(np.arange(0.5, len(bad_df.columns), 1), bad_df.columns.astype(int))\n",
    "    plt.xlabel(\"ID of Bad Types\", size = 12)\n",
    "    plt.ylabel(\"Dataset\", size = 12)\n",
    "    \n",
    "    plt.savefig('Bad Types Detection across All Datasets.jpg')\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "def line_chart(table_set, title):\n",
    "    \n",
    "    plt.style.use('seaborn-dark-palette')\n",
    "    \n",
    "    x = list(range(len(table_set)))\n",
    "    fig, ax1 = plt.subplots(figsize = (15,8))\n",
    "    ax2 = ax1.twinx()\n",
    "    \n",
    "    plt.title(title, fontsize = 16)\n",
    "    plt.xticks(range(1,13,1))\n",
    "    ax1.plot(x, table_set['Aging Rate'], 'b--', linewidth = 1, label = 'Aging Rate')\n",
    "    ax1.plot(x, table_set['Aging Rate'], 'b.', markersize = 15)\n",
    "    ax1.plot(x, table_set['Recall'], 'r-', linewidth = 1, label = 'Recall')\n",
    "    ax1.plot(x, table_set['Recall'], 'r.', markersize = 15)\n",
    "    ax2.plot(x, table_set['Precision'], 'g--', linewidth = 1, label = 'Precision')\n",
    "    ax2.plot(x, table_set['Precision'], 'g.', markersize = 15)\n",
    "    ax1.set_xlabel('\\nDataset', fontsize = 12)\n",
    "    ax1.set_ylabel('Recall & Aging Rate', color = 'b')\n",
    "    ax2.set_ylabel('Precision', color = 'g')\n",
    "    \n",
    "    ax1.legend(loc = 'upper left', frameon = False)\n",
    "    ax2.legend(loc = 'upper right', frameon = False)\n",
    "    \n",
    "    #plt.savefig(f'{title}.jpg')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Processing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-23T05:46:56.729682Z",
     "start_time": "2021-08-23T05:46:49.311438Z"
    }
   },
   "outputs": [],
   "source": [
    "###bad types###\n",
    "bad = pd.read_csv('event/Bad_Types.csv').iloc[:, 1:]\n",
    "Bad_Types = {bad.cb[i]:i for i in range (len(bad))}\n",
    "print('Total bad types:', len(bad))\n",
    "\n",
    "###single dataset###\n",
    "test = pd.read_csv('event/TestingSet_0.csv').iloc[:, 2:]\n",
    "train = pd.read_csv('event/TrainingSet_new.csv').iloc[:, 2:]\n",
    "print('\\ntraining data:', train.shape, '\\nBalance Ratio:', Balance_Ratio(train))\n",
    "print('\\ntesting data:', test.shape, '\\nBalance Ratio:', Balance_Ratio(test), '\\n')\n",
    "\n",
    "train_x, train_y, test_x, test_y = label_divide(train, test, 'GB')\n",
    "\n",
    "###multiple dataset###\n",
    "data_dict = multiple_set(num_set = 10)\n",
    "trainset_x, trainset_y = train_set(data_dict, num_set = 10, label = 'GB')\n",
    "test_x, test_y = label_divide(test, None, 'GB', train_only = True)\n",
    "\n",
    "\n",
    "#####for runhist dataset#####\n",
    "# bad = pd.read_csv('run_bad_types.csv').iloc[:, 1:]\n",
    "# Bad_Types = {bad.cb[i]:i for i in range (len(bad))}\n",
    "# print('Total bad types:', len(bad))\n",
    "\n",
    "run_test = pd.read_csv('test_runhist.csv').iloc[:, 2:]\n",
    "run_test_x, run_test_y = label_divide(run_test, None, 'GB', train_only = True)\n",
    "print('\\n', 'Dimension of run test:', run_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-23T13:41:08.903981Z",
     "start_time": "2021-08-23T13:33:33.936763Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#table_set, bad_set = runall_AdaBoostC(9, trainset_x, test_x, trainset_y, test_y)\n",
    "table_set = runall_AdaBoostC(10, trainset_x, run_test_x, trainset_y, run_test_y, best_paramC, record_bad = False)\n",
    "line_chart(table_set, title = 'AdaBoost Classifier')\n",
    "#bad_plot(bad_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-23T13:42:47.453339Z",
     "start_time": "2021-08-23T13:42:47.429748Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "table_set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-23T05:52:26.526525Z",
     "start_time": "2021-08-23T05:52:26.506578Z"
    }
   },
   "outputs": [],
   "source": [
    "def objective_creator(train_data, mode, num_valid = 3) :\n",
    "    \n",
    "    def objective(trial) :\n",
    "\n",
    "        tree_param = {\n",
    "            'max_depth': trial.suggest_int('max_depth', 1, 3)\n",
    "        }\n",
    "        \n",
    "        param = {\n",
    "            'base_estimator': DecisionTreeClassifier(**tree_param),\n",
    "            'n_estimators': trial.suggest_int('n_estimators', 100, 300, step = 50),\n",
    "            'learning_rate': trial.suggest_float('learning_rate', 0.025, 0.825, step = 0.05),\n",
    "        }\n",
    "\n",
    "\n",
    "        result_list = []\n",
    "        for i in range(num_valid):\n",
    "\n",
    "            train_x, train_y = label_divide(train_data, None, 'GB', train_only = True)\n",
    "            train_x, valid_x, train_y, valid_y = train_test_split(train_x, train_y, test_size = 0.25)\n",
    "\n",
    "            if mode == 'C':\n",
    "                result = AdaBoostC(train_x, valid_x, train_y, valid_y, param)\n",
    "                table = cf_matrix(result, valid_y)\n",
    "                recall = table['Recall']\n",
    "                aging = table['Aging Rate']\n",
    "                effi = table['Efficiency']\n",
    "\n",
    "                #result_list.append(effi)\n",
    "                result_list.append(recall - 0.1*aging)\n",
    "\n",
    "        return np.mean(result_list)\n",
    "    \n",
    "    return objective"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-23T13:28:48.706959Z",
     "start_time": "2021-08-23T05:52:38.825987Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "best_paramC, all_scoreC = all_optuna(num_set = 10, \n",
    "                                     all_data = data_dict, \n",
    "                                     mode = 'C', \n",
    "                                     TPE_multi = True, \n",
    "                                     n_iter = 30, \n",
    "                                     filename = 'runhist_array_m8m7_AdaBoost',\n",
    "                                     creator = objective_creator\n",
    "                                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-16T14:07:56.595812Z",
     "start_time": "2021-08-16T14:07:55.955666Z"
    }
   },
   "outputs": [],
   "source": [
    "##### optimization history plot #####\n",
    "optuna_history(best_paramC, all_scoreC, model = 'AdaBoost Classifier')\n",
    "            \n",
    "##### best hyperparameter table #####\n",
    "param_table = pd.DataFrame(best_paramC).T\n",
    "param_table"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python [conda env:aging]",
   "language": "python",
   "name": "conda-env-aging-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
