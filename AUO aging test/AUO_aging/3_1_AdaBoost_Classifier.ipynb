{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-15T14:29:24.258224Z",
     "start_time": "2021-08-15T14:29:22.174597Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\user\\\\Desktop\\\\Darui_R08621110'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import itertools\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.auto import tqdm\n",
    "import pickle\n",
    "\n",
    "from sklearn.ensemble import AdaBoostClassifier \n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import optuna\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from Dataset_Construction import Balance_Ratio\n",
    "from Sampling import label_divide\n",
    "from Aging_Score import score1\n",
    "from XGBoost import optuna_history\n",
    "\n",
    "os.chdir('C:/Users/user/Desktop/Darui_R08621110')  \n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load multiple dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-15T14:29:24.321711Z",
     "start_time": "2021-08-15T14:29:24.308657Z"
    }
   },
   "outputs": [],
   "source": [
    "def multiple_set(num_set):\n",
    "    \n",
    "    data_dict = {}\n",
    "    for i in range(num_set):\n",
    "        data_dict[f'set{i}'] = pd.read_csv(f'dataset_{i}.csv').iloc[:, 1:]\n",
    "        print('Dimension of dataset', i, ':', data_dict[f'set{i}'].shape, ' balance ratio:', \\\n",
    "              Balance_Ratio(data_dict[f'set{i}']))\n",
    "    \n",
    "    print('\\n', num_set, 'datasets are loaded.')\n",
    "    return data_dict\n",
    "\n",
    "\n",
    "def train_set(data_dict, num_set, label = 'GB'):\n",
    "    \n",
    "    trainset_x = {}\n",
    "    trainset_y = {}\n",
    "    \n",
    "    for i in range(num_set):\n",
    "        X, Y = label_divide(data_dict[f'set{i}'], None, label, train_only = True)\n",
    "        trainset_x[f'set{i}'] = X\n",
    "        trainset_y[f'set{i}'] = Y\n",
    "        \n",
    "    print('\\nLabels of ', num_set, 'datasets are divided.')\n",
    "    return trainset_x, trainset_y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Boosting Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-15T14:29:24.897353Z",
     "start_time": "2021-08-15T14:29:24.878403Z"
    }
   },
   "outputs": [],
   "source": [
    "def AdaBoostC(train_x, test_x, train_y, test_y, config):\n",
    "    \n",
    "    clf = AdaBoostClassifier(**config)\n",
    "    clf.fit(train_x, train_y)\n",
    "    predict_y = clf.predict(test_x)\n",
    "    result = pd.DataFrame({'truth': test_y, 'predict': predict_y})\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recall & Precision for Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-15T14:29:26.254487Z",
     "start_time": "2021-08-15T14:29:26.227485Z"
    }
   },
   "outputs": [],
   "source": [
    "def cf_matrix(predict, train_y):\n",
    "    \n",
    "    # confusion matrix\n",
    "    mask_FP = predict['predict'] > predict['truth']\n",
    "    mask_FN = predict['predict'] < predict['truth']\n",
    "    mask_TP = (predict['predict'] == predict['truth']) * (predict['predict'] == 1)\n",
    "    mask_TN = (predict['predict'] == predict['truth']) * (predict['predict'] == 0)\n",
    "    TP = mask_TP.sum()\n",
    "    FP = mask_FP.sum()\n",
    "    FN = mask_FN.sum()\n",
    "    TN = mask_TN.sum()\n",
    "    \n",
    "    #balance ratio, train OK & NG\n",
    "    train_OK = sum(train_y < 0.5)\n",
    "    train_NG = len(train_y) - train_OK\n",
    "    br = train_OK / train_NG\n",
    "    \n",
    "    #precision, recall, aging rate, efficiency, score\n",
    "    num_pd = TP + FP\n",
    "    if num_pd != 0:\n",
    "        precision = TP / num_pd\n",
    "    else:\n",
    "        precision = 0\n",
    "    \n",
    "    recall = TP / (TP + FN)\n",
    "    ar = (TP + FP) / (TP + FP + FN + TN)\n",
    "    eff = recall / ar\n",
    "    score = score1(recall, ar)\n",
    "    \n",
    "    table = pd.Series({'Balance Ratio': br, 'Train_OK': train_OK, 'Train_NG': train_NG, 'TP': TP, 'FP': FP, 'FN': FN, \\\n",
    "                       'TN': TN, 'Precision': precision, 'Recall': recall, 'Aging Rate': ar, 'Efficiency': eff, 'Score': score})\n",
    "    table = pd.DataFrame(table).T\n",
    "    \n",
    "    print('Precision:', precision, '\\nRecall:', recall, '\\nAging Rate:', ar)\n",
    "    return  table\n",
    "\n",
    "\n",
    "def print_badC(predict, test_x, Bad_Types, threshold = 1):\n",
    "    \n",
    "    Bad = []\n",
    "    Bad_miss = []\n",
    "    TP = predict[(predict['truth'] == 1) & (predict['predict'] >= threshold)].index\n",
    "    FN = predict[(predict['truth'] == 1) & (predict['predict'] < threshold)].index\n",
    "    for j in range(len(TP)):\n",
    "        Index = TP[j]\n",
    "        Key = test_x.values[Index]\n",
    "        Key = pd.DataFrame(Key).T.apply(lambda x:'_'.join(x.astype(str)), axis = 1)\n",
    "        Bad.append(Bad_Types[Key[0]])\n",
    "        Bad.sort()\n",
    "    print('Types of Bad found:', Bad) \n",
    "    \n",
    "    for j in range(len(FN)):\n",
    "        Index = FN[j]\n",
    "        Key = test_x.values[Index]\n",
    "        Key = pd.DataFrame(Key).T.apply(lambda x:'_'.join(x.astype(str)),axis=1)\n",
    "        Bad_miss.append(Bad_Types[Key[0]])\n",
    "        Bad_miss.sort()\n",
    "    print('Types of Bad not found:', Bad_miss)\n",
    "    \n",
    "    bad_table = pd.Series({'Bad_Found': set(Bad), 'Bad_Missed': set(Bad_miss)})\n",
    "    bad_table = pd.DataFrame(bad_table).T\n",
    "    bad_table['Detect Ratio'] = len(Bad) / (len(Bad) + len(Bad_miss))\n",
    "    \n",
    "    return bad_table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run all dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-15T14:29:27.792277Z",
     "start_time": "2021-08-15T14:29:27.775119Z"
    }
   },
   "outputs": [],
   "source": [
    "def runall_AdaBoostC(num_set, trainset_x, test_x, trainset_y, test_y, config, record_bad = True):\n",
    "    \n",
    "    table_set = pd.DataFrame()\n",
    "    bad_set = pd.DataFrame()\n",
    "    judge = list(config.keys())[0]\n",
    "\n",
    "    for i in tqdm(range(num_set)):\n",
    "        print('\\n', f'Dataset {i}:')\n",
    "        \n",
    "        if isinstance(config[judge], dict) :\n",
    "            best_config = config[f'set{i}']\n",
    "        else :\n",
    "            best_config = config\n",
    "            \n",
    "        # seperate the decision tree hyperparameter and adaboost hyperparameter\n",
    "        tree_param = {'base_estimator': DecisionTreeClassifier(max_depth = best_config['max_depth'])}\n",
    "        boost_param = dict((key, best_config[key]) for key in ['learning_rate', 'n_estimators'] if key in best_config)\n",
    "        boost_param.update(tree_param)\n",
    "\n",
    "        result = AdaBoostC(trainset_x[f'set{i}'], test_x, trainset_y[f'set{i}'], test_y, boost_param)\n",
    "        table = cf_matrix(result, trainset_y[f'set{i}'])\n",
    "        table_set = pd.concat([table_set, table]).rename(index = {0: f'dataset {i}'})\n",
    "        \n",
    "        if record_bad:\n",
    "            bad_table = print_badC(result, test_x, Bad_Types) \n",
    "            bad_set = pd.concat([bad_set, bad_table]).rename(index = {0: f'dataset {i}'})\n",
    "\n",
    "    if record_bad:\n",
    "        return table_set, bad_set\n",
    "    else:\n",
    "        return table_set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot all dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-15T14:29:30.635393Z",
     "start_time": "2021-08-15T14:29:30.607467Z"
    }
   },
   "outputs": [],
   "source": [
    "def bad_plot(bad_set):\n",
    "    \n",
    "    # record all bad types\n",
    "    bad_list = []\n",
    "    [bad_list.append(x) for x in bad_set.loc['dataset 1'][0]]\n",
    "    [bad_list.append(x) for x in bad_set.loc['dataset 1'][1]]\n",
    "    bad_list.sort()\n",
    "    \n",
    "    bad_array = np.empty([len(bad_set), len(bad_list)])\n",
    "    for j in range(len(bad_set)):\n",
    "        for i in range(len(bad_list)):\n",
    "            if bad_list[i] in bad_set.iloc[j, 0]:\n",
    "                bad_array[j, i] = 1\n",
    "            else:\n",
    "                bad_array[j ,i] = 0\n",
    "                          \n",
    "    bad_df = pd.DataFrame(bad_array)\n",
    "    bad_df.columns = bad_list\n",
    "    \n",
    "    plt.pcolor(bad_df, cmap = 'Reds')\n",
    "    plt.title(\"Bad Types Detection across All Datasets\")\n",
    "    plt.yticks(np.arange(0.5, len(bad_df.index), 1), bad_df.index)\n",
    "    plt.xticks(np.arange(0.5, len(bad_df.columns), 1), bad_df.columns.astype(int))\n",
    "    plt.xlabel(\"ID of Bad Types\", size = 12)\n",
    "    plt.ylabel(\"Dataset\", size = 12)\n",
    "    \n",
    "    plt.savefig('Bad Types Detection across All Datasets.jpg')\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "def line_chart(table_set, title):\n",
    "    \n",
    "    plt.style.use('seaborn-dark-palette')\n",
    "    \n",
    "    x = list(range(len(table_set)))\n",
    "    fig, ax1 = plt.subplots(figsize = (15,8))\n",
    "    ax2 = ax1.twinx()\n",
    "    \n",
    "    plt.title(title, fontsize = 16)\n",
    "    plt.xticks(range(1,13,1))\n",
    "    ax1.plot(x, table_set['Aging Rate'], 'b--', linewidth = 1, label = 'Aging Rate')\n",
    "    ax1.plot(x, table_set['Aging Rate'], 'b.', markersize = 15)\n",
    "    ax1.plot(x, table_set['Recall'], 'r-', linewidth = 1, label = 'Recall')\n",
    "    ax1.plot(x, table_set['Recall'], 'r.', markersize = 15)\n",
    "    ax2.plot(x, table_set['Precision'], 'g--', linewidth = 1, label = 'Precision')\n",
    "    ax2.plot(x, table_set['Precision'], 'g.', markersize = 15)\n",
    "    ax1.set_xlabel('\\nDataset', fontsize = 12)\n",
    "    ax1.set_ylabel('Recall & Aging Rate', color = 'b')\n",
    "    ax2.set_ylabel('Precision', color = 'g')\n",
    "    \n",
    "    ax1.legend(loc = 'upper left', frameon = False)\n",
    "    ax2.legend(loc = 'upper right', frameon = False)\n",
    "    \n",
    "    #plt.savefig(f'{title}.jpg')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Processing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-15T14:29:42.945134Z",
     "start_time": "2021-08-15T14:29:35.128408Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total bad types: 62\n",
      "\n",
      "training data: (77138, 83) \n",
      "Balance Ratio: 18.17902\n",
      "\n",
      "testing data: (55903, 83) \n",
      "Balance Ratio: 3104.72222 \n",
      "\n",
      "Dimension of dataset 0 : (157140, 234)  balance ratio: 630.08434\n",
      "Dimension of dataset 1 : (4904, 234)  balance ratio: 1.0\n",
      "Dimension of dataset 2 : (4648, 234)  balance ratio: 1.0\n",
      "Dimension of dataset 3 : (5196, 234)  balance ratio: 1.0\n",
      "Dimension of dataset 4 : (4706, 234)  balance ratio: 1.0\n",
      "Dimension of dataset 5 : (4985, 234)  balance ratio: 0.998\n",
      "Dimension of dataset 6 : (4816, 234)  balance ratio: 1.07051\n",
      "Dimension of dataset 7 : (4980, 234)  balance ratio: 1.0\n",
      "Dimension of dataset 8 : (4980, 234)  balance ratio: 1.0\n",
      "Dimension of dataset 9 : (1079, 234)  balance ratio: 3.33333\n",
      "\n",
      " 10 datasets are loaded.\n",
      "\n",
      "Labels of  10 datasets are divided.\n",
      "\n",
      " Dimension of run test: (48650, 234)\n"
     ]
    }
   ],
   "source": [
    "###bad types###\n",
    "bad = pd.read_csv('event/Bad_Types.csv').iloc[:, 1:]\n",
    "Bad_Types = {bad.cb[i]:i for i in range (len(bad))}\n",
    "print('Total bad types:', len(bad))\n",
    "\n",
    "###single dataset###\n",
    "test = pd.read_csv('event/TestingSet_0.csv').iloc[:, 2:]\n",
    "train = pd.read_csv('event/TrainingSet_new.csv').iloc[:, 2:]\n",
    "print('\\ntraining data:', train.shape, '\\nBalance Ratio:', Balance_Ratio(train))\n",
    "print('\\ntesting data:', test.shape, '\\nBalance Ratio:', Balance_Ratio(test), '\\n')\n",
    "\n",
    "train_x, train_y, test_x, test_y = label_divide(train, test, 'GB')\n",
    "\n",
    "###multiple dataset###\n",
    "data_dict = multiple_set(num_set = 10)\n",
    "trainset_x, trainset_y = train_set(data_dict, num_set = 10, label = 'GB')\n",
    "test_x, test_y = label_divide(test, None, 'GB', train_only = True)\n",
    "\n",
    "\n",
    "#####for runhist dataset#####\n",
    "# bad = pd.read_csv('run_bad_types.csv').iloc[:, 1:]\n",
    "# Bad_Types = {bad.cb[i]:i for i in range (len(bad))}\n",
    "# print('Total bad types:', len(bad))\n",
    "\n",
    "run_test = pd.read_csv('test_runhist.csv').iloc[:, 2:]\n",
    "run_test_x, run_test_y = label_divide(run_test, None, 'GB', train_only = True)\n",
    "print('\\n', 'Dimension of run test:', run_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-15T13:54:58.867561Z",
     "start_time": "2021-08-15T13:47:07.931859Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#table_set, bad_set = runall_AdaBoostC(9, trainset_x, test_x, trainset_y, test_y)\n",
    "table_set = runall_AdaBoostC(10, trainset_x, run_test_x, trainset_y, run_test_y, best_paramC, record_bad = False)\n",
    "line_chart(table_set, title = 'AdaBoost Classifier')\n",
    "#bad_plot(bad_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-15T13:55:15.101284Z",
     "start_time": "2021-08-15T13:55:15.070041Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "table_set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-15T14:29:46.947808Z",
     "start_time": "2021-08-15T14:29:46.922111Z"
    }
   },
   "outputs": [],
   "source": [
    "def objective_creator(train_data, mode, num_valid = 3) :\n",
    "    \n",
    "    def objective(trial) :\n",
    "\n",
    "        tree_param = {\n",
    "            'max_depth': trial.suggest_int('max_depth', 1, 3)\n",
    "        }\n",
    "        \n",
    "        param = {\n",
    "            'base_estimator': DecisionTreeClassifier(**tree_param),\n",
    "            'n_estimators': trial.suggest_int('n_estimators', 100, 300, step = 50),\n",
    "            'learning_rate': trial.suggest_float('learning_rate', 0.025, 0.825, step = 0.05),\n",
    "        }\n",
    "\n",
    "\n",
    "        result_list = []\n",
    "        for i in range(num_valid):\n",
    "\n",
    "            train_x, train_y = label_divide(train_data, None, 'GB', train_only = True)\n",
    "            train_x, valid_x, train_y, valid_y = train_test_split(train_x, train_y, test_size = 0.25)\n",
    "\n",
    "            if mode == 'C':\n",
    "                result = AdaBoostC(train_x, valid_x, train_y, valid_y, param)\n",
    "                table = cf_matrix(result, valid_y)\n",
    "                recall = table['Recall']\n",
    "                aging = table['Aging Rate']\n",
    "                effi = table['Efficiency']\n",
    "\n",
    "                #result_list.append(effi)\n",
    "                result_list.append(recall - 0.1*aging)\n",
    "\n",
    "        return np.mean(result_list)\n",
    "    \n",
    "    return objective\n",
    "\n",
    "\n",
    "def all_optuna(num_set, all_data, mode, TPE_multi, n_iter, num_valid = 3, return_addition = True) :\n",
    "\n",
    "    best_param = {}\n",
    "    #all_study = {}\n",
    "    all_score = {}\n",
    "    for i in tqdm(range(num_set)) :\n",
    "        \n",
    "        ##### define objective function and change optimized target dataset in each loop #####\n",
    "        objective = objective_creator(train_data = data_dict[f'set{i}'], mode = mode, num_valid = num_valid)\n",
    "        \n",
    "        ##### optimize one dataset in each loop #####\n",
    "        print(f'Dataset{i} :')\n",
    "        \n",
    "        study = optuna.create_study(sampler = optuna.samplers.TPESampler(multivariate = TPE_multi), \n",
    "                                       direction = 'maximize')\n",
    "        study.optimize(objective, n_trials = n_iter, show_progress_bar = True, gc_after_trial = True)\n",
    "        #n_trials or timeout\n",
    "        best_param[f'set{i}'] = study.best_trial.params\n",
    "        \n",
    "        ##### return score and entire params for score plot or feature importance\n",
    "        if return_addition :\n",
    "            collect_score = []\n",
    "            [collect_score.append(x.values) for x in study.trials]\n",
    "            #all_study[f'set{i}'] = study\n",
    "            all_score[f'set{i}'] = collect_score \n",
    "        \n",
    "        print(f\"Sampler is {study.sampler.__class__.__name__}\")\n",
    "    \n",
    "    ##### store the best hyperparameters #####\n",
    "    multi_mode = 'multivariate' if TPE_multi else 'univariate'\n",
    "    with open(f'runhist_array_m2m5_AdaBoost{mode}_{multi_mode}-TPE_{n_iter}.data', 'wb') as f:\n",
    "        pickle.dump(best_param, f)\n",
    "    \n",
    "    if return_addition :\n",
    "        return best_param, all_score#, all_study\n",
    "    else :\n",
    "        return best_param"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-08-15T14:30:03.922Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd90dc5bf63048deab8680d9603031d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-08-15 22:30:03,929]\u001b[0m A new study created in memory with name: no-name-1f76f70d-b888-4932-a6da-a6bab957deb7\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset0 :\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\envs\\aging\\lib\\site-packages\\optuna\\progress_bar.py:47: ExperimentalWarning: Progress bar is experimental (supported from v1.2.0). The interface can change in the future.\n",
      "  self._init_valid()\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "93cb4e46af4d48aeb8608e959f719c6c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\envs\\aging\\lib\\site-packages\\ipykernel_launcher.py:27: RuntimeWarning: invalid value encountered in double_scalars\n",
      "C:\\Users\\user\\Desktop\\Darui_R08621110\\Master_Thesis\\AUO aging test\\AUO_aging\\Aging_Score.py:21: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  eff = r/ag\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0 \n",
      "Recall: 0.0 \n",
      "Aging Rate: 0.0\n",
      "Precision: 0.0 \n",
      "Recall: 0.0 \n",
      "Aging Rate: 2.545500827287769e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\envs\\aging\\lib\\site-packages\\ipykernel_launcher.py:27: RuntimeWarning: invalid value encountered in double_scalars\n",
      "C:\\Users\\user\\Desktop\\Darui_R08621110\\Master_Thesis\\AUO aging test\\AUO_aging\\Aging_Score.py:21: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  eff = r/ag\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0 \n",
      "Recall: 0.0 \n",
      "Aging Rate: 0.0\n",
      "\u001b[32m[I 2021-08-15 22:35:35,737]\u001b[0m Trial 0 finished with value: -8.485002757625896e-07 and parameters: {'max_depth': 1, 'n_estimators': 250, 'learning_rate': 0.825}. Best is trial 0 with value: -8.485002757625896e-07.\u001b[0m\n",
      "Precision: 0.8813559322033898 \n",
      "Recall: 0.7323943661971831 \n",
      "Aging Rate: 0.0015018454880997836\n",
      "Precision: 0.9361702127659575 \n",
      "Recall: 0.7333333333333333 \n",
      "Aging Rate: 0.0011963853888252514\n",
      "Precision: 0.8 \n",
      "Recall: 0.6896551724137931 \n",
      "Aging Rate: 0.0012727504136438843\n",
      "\u001b[32m[I 2021-08-15 22:48:32,648]\u001b[0m Trial 1 finished with value: 0.7183285912717509 and parameters: {'max_depth': 3, 'n_estimators': 300, 'learning_rate': 0.675}. Best is trial 1 with value: 0.7183285912717509.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\envs\\aging\\lib\\site-packages\\ipykernel_launcher.py:27: RuntimeWarning: invalid value encountered in double_scalars\n",
      "C:\\Users\\user\\Desktop\\Darui_R08621110\\Master_Thesis\\AUO aging test\\AUO_aging\\Aging_Score.py:21: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  eff = r/ag\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0 \n",
      "Recall: 0.0 \n",
      "Aging Rate: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\envs\\aging\\lib\\site-packages\\ipykernel_launcher.py:27: RuntimeWarning: invalid value encountered in double_scalars\n",
      "C:\\Users\\user\\Desktop\\Darui_R08621110\\Master_Thesis\\AUO aging test\\AUO_aging\\Aging_Score.py:21: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  eff = r/ag\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0 \n",
      "Recall: 0.0 \n",
      "Aging Rate: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\envs\\aging\\lib\\site-packages\\ipykernel_launcher.py:27: RuntimeWarning: invalid value encountered in double_scalars\n",
      "C:\\Users\\user\\Desktop\\Darui_R08621110\\Master_Thesis\\AUO aging test\\AUO_aging\\Aging_Score.py:21: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  eff = r/ag\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0 \n",
      "Recall: 0.0 \n",
      "Aging Rate: 0.0\n",
      "\u001b[32m[I 2021-08-15 22:55:36,105]\u001b[0m Trial 2 finished with value: 0.0 and parameters: {'max_depth': 1, 'n_estimators': 300, 'learning_rate': 0.525}. Best is trial 1 with value: 0.7183285912717509.\u001b[0m\n",
      "Precision: 0.7391304347826086 \n",
      "Recall: 0.25757575757575757 \n",
      "Aging Rate: 0.0005854651902761868\n",
      "Precision: 0.9722222222222222 \n",
      "Recall: 0.4861111111111111 \n",
      "Aging Rate: 0.0009163802978235968\n",
      "Precision: 0.75 \n",
      "Recall: 0.3 \n",
      "Aging Rate: 0.0006109201985490645\n",
      "\u001b[32m[I 2021-08-15 23:11:56,325]\u001b[0m Trial 3 finished with value: 0.3478251973727346 and parameters: {'max_depth': 3, 'n_estimators': 150, 'learning_rate': 0.37500000000000006}. Best is trial 1 with value: 0.7183285912717509.\u001b[0m\n",
      "Precision: 0.7647058823529411 \n",
      "Recall: 0.19402985074626866 \n",
      "Aging Rate: 0.0004327351406389207\n",
      "Precision: 0.875 \n",
      "Recall: 0.14893617021276595 \n",
      "Aging Rate: 0.00020364006618302151\n",
      "Precision: 0.9 \n",
      "Recall: 0.14285714285714285 \n",
      "Aging Rate: 0.0002545500827287769\n",
      "\u001b[32m[I 2021-08-15 23:18:31,971]\u001b[0m Trial 4 finished with value: 0.1619113570957408 and parameters: {'max_depth': 3, 'n_estimators': 100, 'learning_rate': 0.37500000000000006}. Best is trial 1 with value: 0.7183285912717509.\u001b[0m\n",
      "Precision: 0.875 \n",
      "Recall: 0.11290322580645161 \n",
      "Aging Rate: 0.00020364006618302151\n",
      "Precision: 0.7777777777777778 \n",
      "Recall: 0.09090909090909091 \n",
      "Aging Rate: 0.0002290950744558992\n",
      "Precision: 0.8571428571428571 \n",
      "Recall: 0.10526315789473684 \n",
      "Aging Rate: 0.00017818505791014383\n",
      "\u001b[32m[I 2021-08-15 23:26:31,286]\u001b[0m Trial 5 finished with value: 0.10300479419680815 and parameters: {'max_depth': 2, 'n_estimators': 150, 'learning_rate': 0.47500000000000003}. Best is trial 1 with value: 0.7183285912717509.\u001b[0m\n",
      "Precision: 0.9333333333333333 \n",
      "Recall: 0.7368421052631579 \n",
      "Aging Rate: 0.001145475372279496\n",
      "Precision: 0.8333333333333334 \n",
      "Recall: 0.625 \n",
      "Aging Rate: 0.0010691103474608629\n",
      "Precision: 0.9347826086956522 \n",
      "Recall: 0.6056338028169014 \n",
      "Aging Rate: 0.0011709303805523736\n",
      "\u001b[32m[I 2021-08-15 23:42:34,700]\u001b[0m Trial 6 finished with value: 0.6557124521566767 and parameters: {'max_depth': 3, 'n_estimators': 200, 'learning_rate': 0.6250000000000001}. Best is trial 1 with value: 0.7183285912717509.\u001b[0m\n",
      "Precision: 0.6666666666666666 \n",
      "Recall: 0.23333333333333334 \n",
      "Aging Rate: 0.0005345551737304314\n",
      "Precision: 0.6086956521739131 \n",
      "Recall: 0.208955223880597 \n",
      "Aging Rate: 0.0005854651902761868\n",
      "Precision: 0.5294117647058824 \n",
      "Recall: 0.16363636363636364 \n",
      "Aging Rate: 0.0004327351406389207\n",
      "\u001b[32m[I 2021-08-15 23:57:10,882]\u001b[0m Trial 7 finished with value: 0.20192321509994315 and parameters: {'max_depth': 2, 'n_estimators': 300, 'learning_rate': 0.47500000000000003}. Best is trial 1 with value: 0.7183285912717509.\u001b[0m\n",
      "Precision: 0.5714285714285714 \n",
      "Recall: 0.05263157894736842 \n",
      "Aging Rate: 0.00017818505791014383\n",
      "Precision: 0.45454545454545453 \n",
      "Recall: 0.07462686567164178 \n",
      "Aging Rate: 0.00028000509100165456\n",
      "Precision: 0.8333333333333334 \n",
      "Recall: 0.14925373134328357 \n",
      "Aging Rate: 0.00030546009927453225\n",
      "\u001b[32m[I 2021-08-16 00:06:09,820]\u001b[0m Trial 8 finished with value: 0.09214527031249171 and parameters: {'max_depth': 2, 'n_estimators': 200, 'learning_rate': 0.47500000000000003}. Best is trial 1 with value: 0.7183285912717509.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\envs\\aging\\lib\\site-packages\\ipykernel_launcher.py:27: RuntimeWarning: invalid value encountered in double_scalars\n",
      "C:\\Users\\user\\Desktop\\Darui_R08621110\\Master_Thesis\\AUO aging test\\AUO_aging\\Aging_Score.py:21: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  eff = r/ag\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0 \n",
      "Recall: 0.0 \n",
      "Aging Rate: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\envs\\aging\\lib\\site-packages\\ipykernel_launcher.py:27: RuntimeWarning: invalid value encountered in double_scalars\n",
      "C:\\Users\\user\\Desktop\\Darui_R08621110\\Master_Thesis\\AUO aging test\\AUO_aging\\Aging_Score.py:21: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  eff = r/ag\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0 \n",
      "Recall: 0.0 \n",
      "Aging Rate: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\envs\\aging\\lib\\site-packages\\ipykernel_launcher.py:27: RuntimeWarning: invalid value encountered in double_scalars\n",
      "C:\\Users\\user\\Desktop\\Darui_R08621110\\Master_Thesis\\AUO aging test\\AUO_aging\\Aging_Score.py:21: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  eff = r/ag\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0 \n",
      "Recall: 0.0 \n",
      "Aging Rate: 0.0\n",
      "\u001b[32m[I 2021-08-16 00:10:17,742]\u001b[0m Trial 9 finished with value: 0.0 and parameters: {'max_depth': 1, 'n_estimators': 150, 'learning_rate': 0.6250000000000001}. Best is trial 1 with value: 0.7183285912717509.\u001b[0m\n",
      "Precision: 1.0 \n",
      "Recall: 0.11764705882352941 \n",
      "Aging Rate: 0.00020364006618302151\n",
      "Precision: 1.0 \n",
      "Recall: 0.07692307692307693 \n",
      "Aging Rate: 0.00012727504136438844\n",
      "Precision: 1.0 \n",
      "Recall: 0.09230769230769231 \n",
      "Aging Rate: 0.00015273004963726612\n",
      "\u001b[32m[I 2021-08-16 00:35:50,251]\u001b[0m Trial 10 finished with value: 0.09560982117952672 and parameters: {'max_depth': 3, 'n_estimators': 250, 'learning_rate': 0.07500000000000001}. Best is trial 1 with value: 0.7183285912717509.\u001b[0m\n",
      "Precision: 0.9183673469387755 \n",
      "Recall: 0.8035714285714286 \n",
      "Aging Rate: 0.0012472954053710068\n",
      "Precision: 0.8125 \n",
      "Recall: 0.65 \n",
      "Aging Rate: 0.001221840397098129\n",
      "Precision: 0.9130434782608695 \n",
      "Recall: 0.75 \n",
      "Aging Rate: 0.0011709303805523736\n",
      "\u001b[32m[I 2021-08-16 01:06:25,262]\u001b[0m Trial 11 finished with value: 0.7344024739843755 and parameters: {'max_depth': 3, 'n_estimators': 250, 'learning_rate': 0.775}. Best is trial 11 with value: 0.7344024739843755.\u001b[0m\n",
      "Precision: 0.7454545454545455 \n",
      "Recall: 0.6949152542372882 \n",
      "Aging Rate: 0.0014000254550082729\n",
      "Precision: 0.847457627118644 \n",
      "Recall: 0.7246376811594203 \n",
      "Aging Rate: 0.0015018454880997836\n",
      "Precision: 0.74 \n",
      "Recall: 0.6607142857142857 \n",
      "Aging Rate: 0.0012727504136438843\n",
      "\u001b[32m[I 2021-08-16 01:37:53,046]\u001b[0m Trial 12 finished with value: 0.693283252991773 and parameters: {'max_depth': 3, 'n_estimators': 250, 'learning_rate': 0.825}. Best is trial 11 with value: 0.7344024739843755.\u001b[0m\n",
      "Precision: 0.8333333333333334 \n",
      "Recall: 0.7142857142857143 \n",
      "Aging Rate: 0.001221840397098129\n",
      "Precision: 0.8536585365853658 \n",
      "Recall: 0.7291666666666666 \n",
      "Aging Rate: 0.0010436553391879853\n",
      "Precision: 0.7843137254901961 \n",
      "Recall: 0.7407407407407407 \n",
      "Aging Rate: 0.0012982054219167621\n",
      "\u001b[32m[I 2021-08-16 02:12:46,188]\u001b[0m Trial 13 finished with value: 0.7279455838591006 and parameters: {'max_depth': 3, 'n_estimators': 300, 'learning_rate': 0.775}. Best is trial 11 with value: 0.7344024739843755.\u001b[0m\n",
      "Precision: 0.52 \n",
      "Recall: 0.19402985074626866 \n",
      "Aging Rate: 0.0006363752068219422\n",
      "Precision: 0.7619047619047619 \n",
      "Recall: 0.2222222222222222 \n",
      "Aging Rate: 0.0005345551737304314\n",
      "Precision: 0.5 \n",
      "Recall: 0.17857142857142858 \n",
      "Aging Rate: 0.0005091001654575538\n",
      "\u001b[32m[I 2021-08-16 02:28:32,860]\u001b[0m Trial 14 finished with value: 0.19821849949510617 and parameters: {'max_depth': 2, 'n_estimators': 250, 'learning_rate': 0.775}. Best is trial 11 with value: 0.7344024739843755.\u001b[0m\n",
      "Precision: 0.8571428571428571 \n",
      "Recall: 0.6206896551724138 \n",
      "Aging Rate: 0.0010691103474608629\n",
      "Precision: 0.9767441860465116 \n",
      "Recall: 0.5753424657534246 \n",
      "Aging Rate: 0.0010945653557337407\n",
      "Precision: 0.9777777777777777 \n",
      "Recall: 0.5116279069767442 \n",
      "Aging Rate: 0.001145475372279496\n",
      "\u001b[32m[I 2021-08-16 02:55:38,383]\u001b[0m Trial 15 finished with value: 0.5691097042650117 and parameters: {'max_depth': 3, 'n_estimators': 300, 'learning_rate': 0.225}. Best is trial 11 with value: 0.7344024739843755.\u001b[0m\n",
      "Precision: 0.4782608695652174 \n",
      "Recall: 0.16417910447761194 \n",
      "Aging Rate: 0.0005854651902761868\n",
      "Precision: 0.8333333333333334 \n",
      "Recall: 0.25862068965517243 \n",
      "Aging Rate: 0.0004581901489117984\n",
      "Precision: 0.8 \n",
      "Recall: 0.12903225806451613 \n",
      "Aging Rate: 0.0002545500827287769\n",
      "\u001b[32m[I 2021-08-16 03:13:10,951]\u001b[0m Trial 16 finished with value: 0.18390074388503627 and parameters: {'max_depth': 2, 'n_estimators': 250, 'learning_rate': 0.7250000000000001}. Best is trial 11 with value: 0.7344024739843755.\u001b[0m\n",
      "Precision: 0.9512195121951219 \n",
      "Recall: 0.65 \n",
      "Aging Rate: 0.0010436553391879853\n",
      "Precision: 0.8958333333333334 \n",
      "Recall: 0.7166666666666667 \n",
      "Aging Rate: 0.001221840397098129\n",
      "Precision: 0.9607843137254902 \n",
      "Recall: 0.8166666666666667 \n",
      "Aging Rate: 0.0012982054219167621\n",
      "\u001b[32m[I 2021-08-16 03:40:39,503]\u001b[0m Trial 17 finished with value: 0.7276589877391711 and parameters: {'max_depth': 3, 'n_estimators': 300, 'learning_rate': 0.825}. Best is trial 11 with value: 0.7344024739843755.\u001b[0m\n",
      "Precision: 0.9074074074074074 \n",
      "Recall: 0.765625 \n",
      "Aging Rate: 0.0013745704467353953\n",
      "Precision: 0.8958333333333334 \n",
      "Recall: 0.7818181818181819 \n",
      "Aging Rate: 0.001221840397098129\n",
      "Precision: 0.8928571428571429 \n",
      "Recall: 0.7936507936507936 \n",
      "Aging Rate: 0.0014254804632811507\n",
      "\u001b[32m[I 2021-08-16 03:57:46,593]\u001b[0m Trial 18 finished with value: 0.7802305954460881 and parameters: {'max_depth': 3, 'n_estimators': 200, 'learning_rate': 0.5750000000000001}. Best is trial 18 with value: 0.7802305954460881.\u001b[0m\n",
      "Precision: 0.5625 \n",
      "Recall: 0.13846153846153847 \n",
      "Aging Rate: 0.00040728013236604303\n",
      "Precision: 0.5384615384615384 \n",
      "Recall: 0.11864406779661017 \n",
      "Aging Rate: 0.00033091510754740993\n",
      "Precision: 0.8888888888888888 \n",
      "Recall: 0.11764705882352941 \n",
      "Aging Rate: 0.0002290950744558992\n",
      "\u001b[32m[I 2021-08-16 04:12:57,606]\u001b[0m Trial 19 finished with value: 0.12488531201674703 and parameters: {'max_depth': 2, 'n_estimators': 200, 'learning_rate': 0.5750000000000001}. Best is trial 18 with value: 0.7802305954460881.\u001b[0m\n",
      "Precision: 0.5833333333333334 \n",
      "Recall: 0.1111111111111111 \n",
      "Aging Rate: 0.00030546009927453225\n",
      "Precision: 0.6470588235294118 \n",
      "Recall: 0.15714285714285714 \n",
      "Aging Rate: 0.0004327351406389207\n",
      "Precision: 0.46153846153846156 \n",
      "Recall: 0.08571428571428572 \n",
      "Aging Rate: 0.00033091510754740993\n",
      "\u001b[32m[I 2021-08-16 04:22:35,106]\u001b[0m Trial 20 finished with value: 0.11795378097783597 and parameters: {'max_depth': 3, 'n_estimators': 100, 'learning_rate': 0.32500000000000007}. Best is trial 18 with value: 0.7802305954460881.\u001b[0m\n",
      "Precision: 0.7872340425531915 \n",
      "Recall: 0.6491228070175439 \n",
      "Aging Rate: 0.0011963853888252514\n",
      "Precision: 0.9423076923076923 \n",
      "Recall: 0.6901408450704225 \n",
      "Aging Rate: 0.0013236604301896397\n",
      "Precision: 0.8888888888888888 \n",
      "Recall: 0.6896551724137931 \n",
      "Aging Rate: 0.001145475372279496\n",
      "\u001b[32m[I 2021-08-16 04:44:16,726]\u001b[0m Trial 21 finished with value: 0.67618409079421 and parameters: {'max_depth': 3, 'n_estimators': 200, 'learning_rate': 0.7250000000000001}. Best is trial 18 with value: 0.7802305954460881.\u001b[0m\n",
      "Precision: 0.9761904761904762 \n",
      "Recall: 0.6721311475409836 \n",
      "Aging Rate: 0.0010691103474608629\n",
      "Precision: 0.9024390243902439 \n",
      "Recall: 0.6727272727272727 \n",
      "Aging Rate: 0.0010436553391879853\n",
      "Precision: 0.8867924528301887 \n",
      "Recall: 0.7704918032786885 \n",
      "Aging Rate: 0.0013491154384625175\n",
      "\u001b[32m[I 2021-08-16 05:09:44,832]\u001b[0m Trial 22 finished with value: 0.7050013451448113 and parameters: {'max_depth': 3, 'n_estimators': 250, 'learning_rate': 0.7250000000000001}. Best is trial 18 with value: 0.7802305954460881.\u001b[0m\n",
      "Precision: 0.8367346938775511 \n",
      "Recall: 0.6507936507936508 \n",
      "Aging Rate: 0.0012472954053710068\n",
      "Precision: 0.9767441860465116 \n",
      "Recall: 0.7 \n",
      "Aging Rate: 0.0010945653557337407\n",
      "Precision: 0.9411764705882353 \n",
      "Recall: 0.7741935483870968 \n",
      "Aging Rate: 0.0012982054219167621\n",
      "\u001b[32m[I 2021-08-16 05:32:27,687]\u001b[0m Trial 23 finished with value: 0.7082077308541485 and parameters: {'max_depth': 3, 'n_estimators': 250, 'learning_rate': 0.6250000000000001}. Best is trial 18 with value: 0.7802305954460881.\u001b[0m\n",
      "Precision: 0.8695652173913043 \n",
      "Recall: 0.6779661016949152 \n",
      "Aging Rate: 0.0011709303805523736\n",
      "Precision: 0.8076923076923077 \n",
      "Recall: 0.7368421052631579 \n",
      "Aging Rate: 0.0013236604301896397\n",
      "Precision: 0.8909090909090909 \n",
      "Recall: 0.6712328767123288 \n",
      "Aging Rate: 0.0014000254550082729\n",
      "\u001b[32m[I 2021-08-16 05:48:20,914]\u001b[0m Trial 24 finished with value: 0.6952172073479423 and parameters: {'max_depth': 3, 'n_estimators': 200, 'learning_rate': 0.775}. Best is trial 18 with value: 0.7802305954460881.\u001b[0m\n",
      "Precision: 0.7948717948717948 \n",
      "Recall: 0.49206349206349204 \n",
      "Aging Rate: 0.00099274532264223\n",
      "Precision: 0.9743589743589743 \n",
      "Recall: 0.6031746031746031 \n",
      "Aging Rate: 0.00099274532264223\n",
      "Precision: 0.8181818181818182 \n",
      "Recall: 0.6 \n",
      "Aging Rate: 0.0011200203640066183\n",
      "\u001b[32m[I 2021-08-16 06:04:08,291]\u001b[0m Trial 25 finished with value: 0.564975848045722 and parameters: {'max_depth': 3, 'n_estimators': 150, 'learning_rate': 0.5750000000000001}. Best is trial 18 with value: 0.7802305954460881.\u001b[0m\n",
      "Precision: 0.6538461538461539 \n",
      "Recall: 0.265625 \n",
      "Aging Rate: 0.0006618302150948199\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.8421052631578947 \n",
      "Recall: 0.2807017543859649 \n",
      "Aging Rate: 0.0004836451571846761\n",
      "Precision: 0.52 \n",
      "Recall: 0.25 \n",
      "Aging Rate: 0.0006363752068219422\n",
      "\u001b[32m[I 2021-08-16 06:22:05,443]\u001b[0m Trial 26 finished with value: 0.26538285644268494 and parameters: {'max_depth': 2, 'n_estimators': 300, 'learning_rate': 0.675}. Best is trial 18 with value: 0.7802305954460881.\u001b[0m\n",
      "Precision: 0.8604651162790697 \n",
      "Recall: 0.6065573770491803 \n",
      "Aging Rate: 0.0010945653557337407\n",
      "Precision: 0.9130434782608695 \n",
      "Recall: 0.6666666666666666 \n",
      "Aging Rate: 0.0011709303805523736\n",
      "Precision: 1.0 \n",
      "Recall: 0.7333333333333333 \n",
      "Aging Rate: 0.0011200203640066183\n",
      "\u001b[32m[I 2021-08-16 06:48:30,707]\u001b[0m Trial 27 finished with value: 0.6687396084797169 and parameters: {'max_depth': 3, 'n_estimators': 250, 'learning_rate': 0.775}. Best is trial 18 with value: 0.7802305954460881.\u001b[0m\n",
      "Precision: 0.8372093023255814 \n",
      "Recall: 0.5901639344262295 \n",
      "Aging Rate: 0.0010945653557337407\n",
      "Precision: 0.8727272727272727 \n",
      "Recall: 0.7164179104477612 \n",
      "Aging Rate: 0.0014000254550082729\n",
      "Precision: 0.8913043478260869 \n",
      "Recall: 0.7454545454545455 \n",
      "Aging Rate: 0.0011709303805523736\n",
      "\u001b[32m[I 2021-08-16 07:09:56,716]\u001b[0m Trial 28 finished with value: 0.6838899460698022 and parameters: {'max_depth': 3, 'n_estimators': 200, 'learning_rate': 0.675}. Best is trial 18 with value: 0.7802305954460881.\u001b[0m\n",
      "Precision: 0.75 \n",
      "Recall: 0.09090909090909091 \n",
      "Aging Rate: 0.00020364006618302151\n",
      "Precision: 0.3333333333333333 \n",
      "Recall: 0.015625 \n",
      "Aging Rate: 7.636502481863306e-05\n",
      "Precision: 0.75 \n",
      "Recall: 0.039473684210526314 \n",
      "Aging Rate: 0.00010182003309151076\n",
      "\u001b[32m[I 2021-08-16 07:29:10,332]\u001b[0m Trial 29 finished with value: 0.0486565308690693 and parameters: {'max_depth': 2, 'n_estimators': 250, 'learning_rate': 0.225}. Best is trial 18 with value: 0.7802305954460881.\u001b[0m\n",
      "Precision: 0.92 \n",
      "Recall: 0.7301587301587301 \n",
      "Aging Rate: 0.0012727504136438843\n",
      "Precision: 0.875 \n",
      "Recall: 0.6086956521739131 \n",
      "Aging Rate: 0.001221840397098129\n",
      "Precision: 0.7083333333333334 \n",
      "Recall: 0.5666666666666667 \n",
      "Aging Rate: 0.001221840397098129\n",
      "\u001b[32m[I 2021-08-16 07:59:36,587]\u001b[0m Trial 30 finished with value: 0.6350498019595087 and parameters: {'max_depth': 3, 'n_estimators': 300, 'learning_rate': 0.825}. Best is trial 18 with value: 0.7802305954460881.\u001b[0m\n",
      "Precision: 0.9454545454545454 \n",
      "Recall: 0.8253968253968254 \n",
      "Aging Rate: 0.0014000254550082729\n",
      "Precision: 0.7894736842105263 \n",
      "Recall: 0.75 \n",
      "Aging Rate: 0.0014509354715540282\n",
      "Precision: 0.8360655737704918 \n",
      "Recall: 0.68 \n",
      "Aging Rate: 0.001552755504645539\n",
      "\u001b[32m[I 2021-08-16 08:32:04,438]\u001b[0m Trial 31 finished with value: 0.751652151251235 and parameters: {'max_depth': 3, 'n_estimators': 300, 'learning_rate': 0.825}. Best is trial 18 with value: 0.7802305954460881.\u001b[0m\n",
      "Precision: 0.8867924528301887 \n",
      "Recall: 0.8103448275862069 \n",
      "Aging Rate: 0.0013491154384625175\n",
      "Precision: 0.8833333333333333 \n",
      "Recall: 0.7162162162162162 \n",
      "Aging Rate: 0.0015273004963726614\n",
      "Precision: 0.8888888888888888 \n",
      "Recall: 0.5714285714285714 \n",
      "Aging Rate: 0.001145475372279496\n",
      "\u001b[32m[I 2021-08-16 09:03:08,968]\u001b[0m Trial 32 finished with value: 0.6991958087000943 and parameters: {'max_depth': 3, 'n_estimators': 300, 'learning_rate': 0.775}. Best is trial 18 with value: 0.7802305954460881.\u001b[0m\n",
      "Precision: 0.9454545454545454 \n",
      "Recall: 0.7878787878787878 \n",
      "Aging Rate: 0.0014000254550082729\n",
      "Precision: 0.8571428571428571 \n",
      "Recall: 0.7241379310344828 \n",
      "Aging Rate: 0.0012472954053710068\n",
      "Precision: 0.9545454545454546 \n",
      "Recall: 0.75 \n",
      "Aging Rate: 0.0011200203640066183\n",
      "\u001b[32m[I 2021-08-16 09:36:08,373]\u001b[0m Trial 33 finished with value: 0.7538799949302772 and parameters: {'max_depth': 3, 'n_estimators': 300, 'learning_rate': 0.825}. Best is trial 18 with value: 0.7802305954460881.\u001b[0m\n",
      "Precision: 0.9 \n",
      "Recall: 0.7627118644067796 \n",
      "Aging Rate: 0.0012727504136438843\n",
      "Precision: 0.8461538461538461 \n",
      "Recall: 0.7333333333333333 \n",
      "Aging Rate: 0.0013236604301896397\n",
      "Precision: 0.8936170212765957 \n",
      "Recall: 0.7368421052631579 \n",
      "Aging Rate: 0.0011963853888252514\n",
      "\u001b[32m[I 2021-08-16 10:05:30,795]\u001b[0m Trial 34 finished with value: 0.7441693411266682 and parameters: {'max_depth': 3, 'n_estimators': 300, 'learning_rate': 0.825}. Best is trial 18 with value: 0.7802305954460881.\u001b[0m\n",
      "Precision: 0.0 \n",
      "Recall: 0.0 \n",
      "Aging Rate: 5.091001654575538e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\envs\\aging\\lib\\site-packages\\ipykernel_launcher.py:27: RuntimeWarning: invalid value encountered in double_scalars\n",
      "C:\\Users\\user\\Desktop\\Darui_R08621110\\Master_Thesis\\AUO aging test\\AUO_aging\\Aging_Score.py:21: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  eff = r/ag\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0 \n",
      "Recall: 0.0 \n",
      "Aging Rate: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\envs\\aging\\lib\\site-packages\\ipykernel_launcher.py:27: RuntimeWarning: invalid value encountered in double_scalars\n",
      "C:\\Users\\user\\Desktop\\Darui_R08621110\\Master_Thesis\\AUO aging test\\AUO_aging\\Aging_Score.py:21: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  eff = r/ag\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0 \n",
      "Recall: 0.0 \n",
      "Aging Rate: 0.0\n",
      "\u001b[32m[I 2021-08-16 10:19:05,312]\u001b[0m Trial 35 finished with value: -1.6970005515251793e-06 and parameters: {'max_depth': 1, 'n_estimators': 300, 'learning_rate': 0.825}. Best is trial 18 with value: 0.7802305954460881.\u001b[0m\n",
      "Precision: 0.8297872340425532 \n",
      "Recall: 0.609375 \n",
      "Aging Rate: 0.0011963853888252514\n",
      "Precision: 0.9272727272727272 \n",
      "Recall: 0.7183098591549296 \n",
      "Aging Rate: 0.0014000254550082729\n",
      "Precision: 0.8305084745762712 \n",
      "Recall: 0.8166666666666667 \n",
      "Aging Rate: 0.0015018454880997836\n",
      "\u001b[32m[I 2021-08-16 10:38:44,491]\u001b[0m Trial 36 finished with value: 0.7146472333961343 and parameters: {'max_depth': 3, 'n_estimators': 300, 'learning_rate': 0.675}. Best is trial 18 with value: 0.7802305954460881.\u001b[0m\n",
      "Precision: 0.875 \n",
      "Recall: 0.3442622950819672 \n",
      "Aging Rate: 0.0006109201985490645\n",
      "Precision: 0.5714285714285714 \n",
      "Recall: 0.2711864406779661 \n",
      "Aging Rate: 0.0007127402316405753\n",
      "Precision: 0.8095238095238095 \n",
      "Recall: 0.2786885245901639 \n",
      "Aging Rate: 0.0005345551737304314\n",
      "\u001b[32m[I 2021-08-16 10:44:10,715]\u001b[0m Trial 37 finished with value: 0.2979838129299017 and parameters: {'max_depth': 3, 'n_estimators': 100, 'learning_rate': 0.525}. Best is trial 18 with value: 0.7802305954460881.\u001b[0m\n",
      "Precision: 0.7068965517241379 \n",
      "Recall: 0.6307692307692307 \n",
      "Aging Rate: 0.001476390479826906\n",
      "Precision: 0.8913043478260869 \n",
      "Recall: 0.6612903225806451 \n",
      "Aging Rate: 0.0011709303805523736\n",
      "Precision: 0.9038461538461539 \n",
      "Recall: 0.6811594202898551 \n",
      "Aging Rate: 0.0013236604301896397\n",
      "\u001b[32m[I 2021-08-16 10:59:15,277]\u001b[0m Trial 38 finished with value: 0.6576072918368915 and parameters: {'max_depth': 3, 'n_estimators': 300, 'learning_rate': 0.825}. Best is trial 18 with value: 0.7802305954460881.\u001b[0m\n",
      "Precision: 1.0 \n",
      "Recall: 0.36363636363636365 \n",
      "Aging Rate: 0.0006109201985490645\n",
      "Precision: 0.75 \n",
      "Recall: 0.24193548387096775 \n",
      "Aging Rate: 0.0005091001654575538\n",
      "Precision: 0.8518518518518519 \n",
      "Recall: 0.3382352941176471 \n",
      "Aging Rate: 0.0006872852233676976\n",
      "\u001b[32m[I 2021-08-16 11:06:17,791]\u001b[0m Trial 39 finished with value: 0.3145421370220804 and parameters: {'max_depth': 3, 'n_estimators': 150, 'learning_rate': 0.32500000000000007}. Best is trial 18 with value: 0.7802305954460881.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\envs\\aging\\lib\\site-packages\\ipykernel_launcher.py:27: RuntimeWarning: invalid value encountered in double_scalars\n",
      "C:\\Users\\user\\Desktop\\Darui_R08621110\\Master_Thesis\\AUO aging test\\AUO_aging\\Aging_Score.py:21: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  eff = r/ag\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0 \n",
      "Recall: 0.0 \n",
      "Aging Rate: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\envs\\aging\\lib\\site-packages\\ipykernel_launcher.py:27: RuntimeWarning: invalid value encountered in double_scalars\n",
      "C:\\Users\\user\\Desktop\\Darui_R08621110\\Master_Thesis\\AUO aging test\\AUO_aging\\Aging_Score.py:21: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  eff = r/ag\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0 \n",
      "Recall: 0.0 \n",
      "Aging Rate: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\envs\\aging\\lib\\site-packages\\ipykernel_launcher.py:27: RuntimeWarning: invalid value encountered in double_scalars\n",
      "C:\\Users\\user\\Desktop\\Darui_R08621110\\Master_Thesis\\AUO aging test\\AUO_aging\\Aging_Score.py:21: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  eff = r/ag\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0 \n",
      "Recall: 0.0 \n",
      "Aging Rate: 0.0\n",
      "\u001b[32m[I 2021-08-16 11:17:11,680]\u001b[0m Trial 40 finished with value: 0.0 and parameters: {'max_depth': 2, 'n_estimators': 300, 'learning_rate': 0.025}. Best is trial 18 with value: 0.7802305954460881.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "best_paramC, all_scoreC = all_optuna(num_set = 10, all_data = data_dict, mode = 'C', TPE_multi = False, n_iter = 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-15T13:27:05.525493Z",
     "start_time": "2021-08-15T13:27:04.321055Z"
    }
   },
   "outputs": [],
   "source": [
    "##### optimization history plot #####\n",
    "optuna_history(best_paramC, all_scoreC, model = 'AdaBoost Classifier')\n",
    "            \n",
    "##### best hyperparameter table #####\n",
    "param_table = pd.DataFrame(best_paramC).T\n",
    "param_table"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python [conda env:aging]",
   "language": "python",
   "name": "conda-env-aging-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
