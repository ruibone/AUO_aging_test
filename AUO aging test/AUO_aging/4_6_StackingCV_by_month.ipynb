{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-04T04:51:23.242108Z",
     "start_time": "2021-10-04T04:51:21.740151Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import itertools\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "from tqdm.auto import tqdm\n",
    "import openpyxl\n",
    "\n",
    "from mlxtend.classifier import StackingCVClassifier\n",
    "from mlxtend.regressor import StackingCVRegressor\n",
    "from sklearn.linear_model import LogisticRegression, RidgeCV, Ridge\n",
    "from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor\n",
    "from sklearn.ensemble import ExtraTreesClassifier, ExtraTreesRegressor, RandomForestClassifier, RandomForestRegressor,\\\n",
    "                                AdaBoostClassifier, AdaBoostRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from catboost import CatBoostClassifier, CatBoostRegressor\n",
    "from lightgbm import LGBMClassifier, LGBMRegressor\n",
    "from xgboost import XGBClassifier, XGBRegressor\n",
    "import optuna\n",
    "\n",
    "from Dataset_Construction import Balance_Ratio \n",
    "from Sampling import label_divide\n",
    "from AdaClassifier import train_set, multiple_set, print_badC, bad_plot, line_chart, cf_matrix, runall_AdaBoostC\n",
    "from AdaRegressor import AUC, PR_curve, multiple_curve, PR_matrix, best_threshold, runall_AdaBoostR\n",
    "from Aging_Score import score1\n",
    "from XGBoost import optuna_history, runall_XGBoostC, runall_XGBoostR\n",
    "from CatBoost import runall_CatBoostC, runall_CatBoostR\n",
    "from Light_GBM import runall_LightGBMC, runall_LightGBMR\n",
    "from Random_Forest import runall_ForestC, runall_ForestR\n",
    "from Extra_Trees import runall_ExtraTreesC, runall_ExtraTreesR\n",
    "\n",
    "os.chdir('C:/Users/user/Desktop/Darui_R08621110')  \n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load all hyperparamters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-04T04:51:24.642805Z",
     "start_time": "2021-10-04T04:51:24.617133Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def load_hyper(num_set, date, model_list, iter_list, filename, mode, sampler_list) :\n",
    "    \n",
    "    allset_dict = {}\n",
    "    for j in range(num_set) :\n",
    "\n",
    "        sampler_dict = {}\n",
    "        for sampler in sampler_list :\n",
    "        \n",
    "            model_dict = {}\n",
    "            for i, model in enumerate(model_list) :\n",
    "            \n",
    "                    with open(f'hyperparameter/{date}/{filename}_{model}{mode}_{sampler}_{iter_list[i]}.data', 'rb') as f:\n",
    "                        temp_dict = pickle.load(f)\n",
    "                        model_dict[model] = temp_dict[f'set{j}']\n",
    "            \n",
    "            sampler_dict[sampler] = model_dict\n",
    "        \n",
    "        allset_dict[f'set{j}'] = sampler_dict\n",
    "        \n",
    "    return allset_dict\n",
    "\n",
    "\n",
    "def month_hyper(num_set, date, iteration, filename_list, sampler_list, mode):\n",
    "    \n",
    "    allset_dict = {}\n",
    "    for i in range(num_set):\n",
    "        \n",
    "        sampler_dict = {}\n",
    "        for sampler in sampler_list:\n",
    "            \n",
    "            month_dict = {}\n",
    "            for j, filename in enumerate(filename_list):\n",
    "\n",
    "                with open(f'hyperparameter/{date}/{filename}{mode}_{sampler}_{iteration}.data', 'rb') as f:\n",
    "                    temp_dict = pickle.load(f)\n",
    "                    month_dict[filename] = temp_dict[f'set{i}']\n",
    "                    \n",
    "            sampler_dict[sampler] = month_dict\n",
    "            \n",
    "        allset_dict[f'set{i}'] = sampler_dict\n",
    "        \n",
    "    return allset_dict\n",
    "\n",
    "\n",
    "def tableau_hyper(num_set, date, model_list, iter_list, filename, mode, sampler_list) :\n",
    "    \n",
    "    model_dict = {}\n",
    "    for j, model in enumerate(model_list) :\n",
    "\n",
    "        sampler_dict = {}\n",
    "        for i, sampler in enumerate(sampler_list) :\n",
    "\n",
    "            with open(f'hyperparameter/{date}/{filename}_{model}{mode}_{sampler}_{iter_list[j]}.data', 'rb') as f :\n",
    "                temp_dict = pickle.load(f)\n",
    "                sampler_dict[sampler] = temp_dict\n",
    "                \n",
    "        model_dict[model] = sampler_dict\n",
    "\n",
    "    return model_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### StackingCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-04T04:51:25.648454Z",
     "start_time": "2021-10-04T04:51:25.639476Z"
    }
   },
   "outputs": [],
   "source": [
    "def month_stackingCVC(train_x, train_y, test_x, test_y, config, TPE_multi, meta_config) :\n",
    "    \n",
    "    sampler = 'multivariate-TPE' if TPE_multi else 'univariate-TPE'\n",
    "    clf_list = []\n",
    "\n",
    "    for name in config[sampler].keys():\n",
    "        \n",
    "        if 'LightGBM' in name :\n",
    "            clf = LGBMClassifier(**config[sampler][name])\n",
    "        elif 'XGBoost' in name :\n",
    "            clf = XGBClassifier(**config[sampler][name])      \n",
    "        clf_list.append(clf)\n",
    "    \n",
    "    second_config = meta_config.copy()\n",
    "    del second_config['meta_learner']\n",
    "    \n",
    "    if meta_config['meta_learner'] == 'Logistic Regression' :\n",
    "        meta_clf = LogisticRegression(**second_config)\n",
    "    elif meta_config['meta_learner'] == 'Extra Trees' :\n",
    "        meta_clf = ExtraTreesClassifier(**second_config)\n",
    "\n",
    "    sclf = StackingCVClassifier(classifiers = clf_list, \n",
    "                                meta_classifier = meta_clf, \n",
    "                                use_probas = True,\n",
    "                                drop_proba_col = 'last',\n",
    "                                cv = 5,\n",
    "                                shuffle = True,\n",
    "                                stratify = True,\n",
    "                                n_jobs = -1)\n",
    "    sclf.fit(train_x, train_y)\n",
    "    predict_y = sclf.predict(test_x)\n",
    "    result = pd.DataFrame({'truth': test_y, 'predict': predict_y})\n",
    "    \n",
    "    return result\n",
    "\n",
    "\n",
    "def month_stackingCVR(train_x, train_y, test_x, test_y, config, TPE_multi, meta_config) :\n",
    "    \n",
    "    sampler = 'multivariate-TPE' if TPE_multi else 'univariate-TPE'\n",
    "    reg_list = []\n",
    "    \n",
    "    for name in config[sampler].keys():\n",
    "    \n",
    "        if 'LightGBM' in name :\n",
    "            reg = LGBMRegressor(**config[sampler][name])\n",
    "        elif 'XGBoost' in name :\n",
    "            reg = XGBRegressor(**config[sampler][name])   \n",
    "        reg_list.append(reg)\n",
    "\n",
    "    second_config = meta_config.copy()\n",
    "    del second_config['meta_learner']\n",
    "        \n",
    "    if meta_config['meta_learner'] == 'Ridge Regression' :\n",
    "        meta_reg = Ridge(**second_config)\n",
    "    elif meta_config['meta_learner'] == 'Extra Trees' :\n",
    "        meta_reg = ExtraTreesRegressor(**second_config)\n",
    "\n",
    "    sreg = StackingCVRegressor(regressors = reg_list, \n",
    "                               meta_regressor = meta_reg, \n",
    "                               cv = 5,\n",
    "                               shuffle = True,\n",
    "                               n_jobs = -1)\n",
    "    sreg.fit(train_x, train_y)\n",
    "    predict_y = sreg.predict(test_x)\n",
    "    result = pd.DataFrame({'truth': test_y, 'predict': predict_y})\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-04T08:53:11.415382Z",
     "start_time": "2021-10-04T08:53:11.406371Z"
    }
   },
   "outputs": [],
   "source": [
    "def runall_stackingCVC(num_set, train_x, train_y, test_x, test_y, config, TPE_multi, meta_config) :    \n",
    "    \n",
    "    table_set = pd.DataFrame()\n",
    "    for i in tqdm(range(num_set)) :\n",
    "        \n",
    "        print(f'Dataset {i}:\\n')\n",
    "        result = month_stackingCVC(train_x[f'set{i}'], train_y[f'set{i}'], test_x, test_y, config[f'set{i}'], TPE_multi, \n",
    "                             meta_config[f'set{i}'])\n",
    "        table = cf_matrix(result, train_y[f'set{i}'])\n",
    "        table_set = pd.concat([table_set, table]).rename(index = {0: f'dataset {i}'})\n",
    "        \n",
    "    return table_set\n",
    "\n",
    "\n",
    "def runall_stackingCVR(num_set, train_x, train_y, test_x, test_y, config, TPE_multi, meta_config, thres_target, threshold):\n",
    "    \n",
    "    table_set = pd.DataFrame()\n",
    "    pr_dict = {}\n",
    "    for i in tqdm(range(num_set)) :\n",
    "        \n",
    "        print(f'Dataset {i}:\\n')\n",
    "        result = month_stackingCVR(train_x[f'set{i}'], train_y[f'set{i}'], test_x, test_y, config[f'set{i}'], TPE_multi, \n",
    "                             meta_config[f'set{i}'])\n",
    "        pr_matrix = PR_matrix(result, train_y[f'set{i}'])\n",
    "        pr_dict[f'set{i}'] = pr_matrix\n",
    "        \n",
    "        best_data, best_thres = best_threshold(pr_matrix, target = thres_target, threshold = threshold)\n",
    "        table_set = pd.concat([table_set, best_data]).rename(index = {best_data.index.values[0]: f'dataset {i}'})\n",
    "        \n",
    "    return pr_dict, table_set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Runhist data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-04T04:51:31.067123Z",
     "start_time": "2021-10-04T04:51:29.029368Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "###bad types###\n",
    "bad = pd.read_csv('event/Bad_Types.csv').iloc[:, 1:]\n",
    "Bad_Types = {bad.cb[i]:i for i in range (len(bad))}\n",
    "print('Total bad types:', len(bad))\n",
    "\n",
    "###single dataset###\n",
    "test = pd.read_csv('event/TestingSet_0.csv').iloc[:, 2:]\n",
    "train = pd.read_csv('event/TrainingSet_new.csv').iloc[:, 2:]\n",
    "print('\\ntraining data:', train.shape, '\\nBalance Ratio:', Balance_Ratio(train))\n",
    "print('\\ntesting data:', test.shape, '\\nBalance Ratio:', Balance_Ratio(test))\n",
    "\n",
    "train_x, train_y, test_x, test_y = label_divide(train, test, 'GB')\n",
    "\n",
    "###multiple dataset###\n",
    "data_dict = multiple_set(num_set = 10)\n",
    "trainset_x, trainset_y = train_set(data_dict, num_set = 10, label = 'GB')\n",
    "test_x, test_y = label_divide(test, None, 'GB', train_only = True)\n",
    "\n",
    "\n",
    "#####for runhist dataset#####\n",
    "# bad = pd.read_csv('run_bad_types.csv').iloc[:, 1:]\n",
    "# Bad_Types = {bad.cb[i]:i for i in range (len(bad))}\n",
    "# print('Total bad types:', len(bad))\n",
    "\n",
    "run_test = pd.read_csv('test_runhist.csv').iloc[:, 2:]\n",
    "run_test_x, run_test_y = label_divide(run_test, None, 'GB', train_only = True)\n",
    "print('\\n', 'Dimension of run test:', run_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-04T04:51:37.069979Z",
     "start_time": "2021-10-04T04:51:37.046855Z"
    }
   },
   "outputs": [],
   "source": [
    "hyper_info = {\n",
    "    'num_set': 10,\n",
    "    'date': '20211005',\n",
    "    'iteration': 200,\n",
    "    'filename_list': ['runhist_array_m2_m3_4selection_XGBoost',\n",
    "                      'runhist_array_m3_m4_4selection_XGBoost',\n",
    "                      'runhist_array_m4_m5_4selection_XGBoost',\n",
    "                      'runhist_array_m2_m3_4selection_LightGBM',\n",
    "                      'runhist_array_m3_m4_4selection_LightGBM',\n",
    "                      'runhist_array_m4_m5_4selection_LightGBM'],\n",
    "    'sampler_list': ['univariate-TPE', 'multivariate-TPE']\n",
    "}\n",
    "\n",
    "month_hyperC = month_hyper(**hyper_info, mode = 'C')\n",
    "month_hyperR = month_hyper(**hyper_info, mode = 'R')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-04T09:18:37.603613Z",
     "start_time": "2021-10-04T09:11:50.815466Z"
    }
   },
   "outputs": [],
   "source": [
    "table_setC = runall_stackingCVC(10, \n",
    "                                trainset_x, \n",
    "                                trainset_y, \n",
    "                                run_test_x, \n",
    "                                run_test_y, \n",
    "                                month_hyperC, \n",
    "                                TPE_multi = True,  \n",
    "                                meta_config = best_paramC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-04T09:18:39.050126Z",
     "start_time": "2021-10-04T09:18:38.869008Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "line_chart(table_setC, title = 'StackingCV Classifier (by month)')\n",
    "table_setC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-14T06:35:50.209666Z",
     "start_time": "2021-09-14T06:35:50.202651Z"
    }
   },
   "source": [
    "### Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-04T09:36:55.580902Z",
     "start_time": "2021-10-04T09:31:03.962930Z"
    }
   },
   "outputs": [],
   "source": [
    "pr_dict, table_setR = runall_stackingCVR(10, \n",
    "                                         trainset_x, \n",
    "                                         trainset_y, \n",
    "                                         run_test_x,\n",
    "                                         run_test_y, \n",
    "                                         month_hyperR, \n",
    "                                         TPE_multi = True,  \n",
    "                                         meta_config = best_paramR,\n",
    "                                         thres_target = 'Recall',\n",
    "                                         threshold = 0.8\n",
    "                                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-04T09:36:59.846217Z",
     "start_time": "2021-10-04T09:36:56.870310Z"
    }
   },
   "outputs": [],
   "source": [
    "multiple_curve(4, 3, pr_dict, table_setR, target = 'Aging Rate')\n",
    "multiple_curve(4, 3, pr_dict, table_setR, target = 'Precision')\n",
    "line_chart(table_setR, title = 'StackingCV Regressor (by month)')\n",
    "table_setR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-04T05:01:58.304928Z",
     "start_time": "2021-10-04T05:01:58.280834Z"
    }
   },
   "outputs": [],
   "source": [
    "def objective_creator(train_data, mode, TPE_multi, config, num_valid = 3) :\n",
    "    \n",
    "    def objective(trial) :\n",
    "        # hyperparameters randomize setting\n",
    "        if mode == 'C' :\n",
    "            meta_learner = trial.suggest_categorical('meta_learner', ['Logistic Regression'])\n",
    "            \n",
    "            if meta_learner == 'Logistic Regression' :\n",
    "                \n",
    "                param = {\n",
    "                    'meta_learner': 'Logistic Regression',\n",
    "                    'solver': trial.suggest_categorical('solver', ['newton-cg', 'lbfgs', 'sag', 'saga']),\n",
    "                    'C': trial.suggest_categorical('C', [100, 10 ,1 ,0.1, 0.01]),\n",
    "                    'penalty': trial.suggest_categorical('penalty', ['none', 'l2']),\n",
    "                    'n_jobs': -1\n",
    "                }\n",
    "\n",
    "            elif meta_learner == 'Extra Trees' :\n",
    "                \n",
    "                param = {\n",
    "                    'meta_learner': 'Extra Trees',\n",
    "                    'n_estimators': trial.suggest_int('n_estimators', 100, 500, step = 100),\n",
    "                    'min_samples_split': trial.suggest_int('min_samples_split', 2, 32, step = 5),\n",
    "                    'max_depth': trial.suggest_int('max_depth', 3, 21, step = 3),\n",
    "                    'n_jobs': -1\n",
    "                }     \n",
    "\n",
    "        elif mode == 'R' :\n",
    "            meta_learner = trial.suggest_categorical('meta_learner', ['Ridge Regression'])\n",
    "            \n",
    "            if meta_learner == 'Ridge Regression' :\n",
    "                param = {\n",
    "                    'meta_learner': 'Ridge Regression',\n",
    "                    'alpha': trial.suggest_float('alpha', 0, 1, step = 0.1)\n",
    "                }\n",
    "            \n",
    "            elif meta_learner == 'Extra Trees' :\n",
    "                \n",
    "                param = {\n",
    "                    'meta_learner': 'Extra Trees',\n",
    "                    'n_estimators': trial.suggest_int('n_estimators', 100, 500, step = 100),\n",
    "                    'min_samples_split': trial.suggest_int('min_samples_split', 2, 32, step = 5),\n",
    "                    'max_depth': trial.suggest_int('max_depth', 3, 21, step = 3),\n",
    "                    'n_jobs': -1\n",
    "                }\n",
    "        \n",
    "        # objective function\n",
    "        result_list = []\n",
    "        for i in range(num_valid):\n",
    "\n",
    "            train_x, train_y = label_divide(train_data, None, 'GB', train_only = True)\n",
    "            train_x, valid_x, train_y, valid_y = train_test_split(train_x, train_y, test_size = 0.25)\n",
    "\n",
    "            if mode == 'C':\n",
    "                result = month_stackingCVC(train_x, train_y, valid_x, valid_y, config, TPE_multi, param)\n",
    "                table = cf_matrix(result, valid_y)\n",
    "                recall = table['Recall']\n",
    "                aging = table['Aging Rate']\n",
    "\n",
    "                result_list.append(recall - 0.1*aging)\n",
    "\n",
    "            elif mode == 'R':\n",
    "                result = month_stackingCVR(train_x, train_y, valid_x, valid_y, config, TPE_multi, param)\n",
    "                pr_matrix = PR_matrix(result, valid_y)\n",
    "                auc = AUC(pr_matrix['Recall'], pr_matrix['Aging Rate'])\n",
    "                \n",
    "                result_list.append((-1)*auc)\n",
    "\n",
    "        return np.mean(result_list)\n",
    "    \n",
    "    return objective\n",
    "\n",
    "\n",
    "def all_optuna(num_set, all_data, mode, TPE_multi, config, n_iter, filename, creator, num_valid = 3) :\n",
    "\n",
    "    best_param = {}\n",
    "    all_score = {}\n",
    "    for i in tqdm(range(num_set)) :\n",
    "        \n",
    "        ##### define objective function and change optimized target dataset in each loop #####\n",
    "        objective = creator(all_data[f'set{i}'], mode, TPE_multi, config[f'set{i}'], num_valid = num_valid)\n",
    "        \n",
    "        ##### optimize one dataset in each loop #####\n",
    "        print(f'Dataset{i} :')\n",
    "        \n",
    "        study = optuna.create_study(sampler = optuna.samplers.TPESampler(multivariate = TPE_multi), direction = 'maximize')\n",
    "        study.optimize(objective, n_trials = n_iter, show_progress_bar = True, gc_after_trial = True)\n",
    "        best_param[f'set{i}'] = study.best_trial.params\n",
    "        \n",
    "        ##### return score and entire params for score plot or feature importance\n",
    "        collect_score = []\n",
    "        [collect_score.append(x.values) for x in study.trials]\n",
    "        all_score[f'set{i}'] = collect_score \n",
    "        \n",
    "        print(f\"Sampler is {study.sampler.__class__.__name__}\")\n",
    "    \n",
    "    ##### store the best hyperparameters #####\n",
    "    multi_mode = 'multivariate-TPE' if TPE_multi else 'univariate-TPE'\n",
    "    with open(f'{filename}{mode}_{multi_mode}_{n_iter}.data', 'wb') as f:\n",
    "        pickle.dump(best_param, f)\n",
    "    \n",
    "    return best_param, all_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-04T07:33:02.379366Z",
     "start_time": "2021-10-04T05:02:01.320509Z"
    }
   },
   "outputs": [],
   "source": [
    "best_paramC, all_scoreC = all_optuna(num_set = 10, \n",
    "                                     all_data = data_dict, \n",
    "                                     mode = 'C', \n",
    "                                     TPE_multi = True, \n",
    "                                     config = month_hyperC, \n",
    "                                     n_iter = 10, \n",
    "                                     filename = 'runhist_array_m2m5_4selection_stackingCV(LX)_bymonth', \n",
    "                                     creator = objective_creator, \n",
    "                                     num_valid = 3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-04T08:39:19.868972Z",
     "start_time": "2021-10-04T07:33:03.586860Z"
    }
   },
   "outputs": [],
   "source": [
    "best_paramR, all_scoreR = all_optuna(num_set = 10, \n",
    "                                     all_data = data_dict, \n",
    "                                     mode = 'R', \n",
    "                                     TPE_multi = True, \n",
    "                                     config = month_hyperR, \n",
    "                                     n_iter = 5, \n",
    "                                     filename = 'runhist_array_m2m5_4selection_stackingCV(LX)_bymonth', \n",
    "                                     creator = objective_creator, \n",
    "                                     num_valid = 3\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python [conda env:aging]",
   "language": "python",
   "name": "conda-env-aging-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "275.2px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
