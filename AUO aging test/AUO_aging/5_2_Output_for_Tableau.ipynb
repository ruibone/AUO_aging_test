{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-13T07:49:55.253155Z",
     "start_time": "2021-09-13T07:49:53.331298Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\user\\\\Desktop\\\\Darui_R08621110'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import itertools\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "from tqdm.auto import tqdm\n",
    "import openpyxl\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression, RidgeCV, Ridge\n",
    "from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor\n",
    "from sklearn.ensemble import ExtraTreesClassifier, ExtraTreesRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from catboost import CatBoostClassifier, CatBoostRegressor\n",
    "from lightgbm import LGBMClassifier, LGBMRegressor\n",
    "from xgboost import XGBClassifier, XGBRegressor\n",
    "\n",
    "from Dataset_Construction import Balance_Ratio \n",
    "from Sampling import label_divide\n",
    "from AdaClassifier import train_set, multiple_set, print_badC, bad_plot, line_chart, cf_matrix, runall_AdaBoostC\n",
    "from AdaRegressor import AUC, PR_curve, multiple_curve, PR_matrix, best_threshold, runall_AdaBoostR\n",
    "from Aging_Score import score1\n",
    "from XGBoost import optuna_history, runall_XGBoostC, runall_XGBoostR\n",
    "from CatBoost import runall_CatBoostC, runall_CatBoostR\n",
    "from Light_GBM import runall_LightGBMC, runall_LightGBMR\n",
    "\n",
    "os.chdir('C:/Users/user/Desktop/Darui_R08621110')  \n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load all hyperparamters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-13T07:49:57.050129Z",
     "start_time": "2021-09-13T07:49:57.036131Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def load_hyper(num_set, date, model_list, iter_list, filename, mode, sampler) :\n",
    "    \n",
    "    allset_dict = {}\n",
    "    for j in range(num_set) :\n",
    "\n",
    "        oneset_dict = {}\n",
    "        for i, model in enumerate(model_list) :\n",
    "\n",
    "            with open(f'hyperparameter/{date}/{filename}_{model}{mode}_{sampler}_{iter_list[i]}.data', 'rb') as f :\n",
    "                temp_dict = pickle.load(f)\n",
    "                oneset_dict[model] = temp_dict[f'set{j}']\n",
    "        allset_dict[f'set{j}'] = oneset_dict\n",
    "        \n",
    "    return allset_dict\n",
    "\n",
    "\n",
    "def tableau_hyper(num_set, date, model_list, iter_list, filename, mode, sampler_list) :\n",
    "    \n",
    "    model_dict = {}\n",
    "    for j, model in enumerate(model_list) :\n",
    "\n",
    "        sampler_dict = {}\n",
    "        for i, sampler in enumerate(sampler_list) :\n",
    "\n",
    "            with open(f'hyperparameter/{date}/{filename}_{model}{mode}_{sampler}_{iter_list[j]}.data', 'rb') as f :\n",
    "                temp_dict = pickle.load(f)\n",
    "                sampler_dict[sampler] = temp_dict\n",
    "                \n",
    "        model_dict[model] = sampler_dict\n",
    "\n",
    "    return model_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Runhist data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-13T07:50:01.198272Z",
     "start_time": "2021-09-13T07:49:59.931572Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total bad types: 62\n",
      "\n",
      "training data: (77138, 83) \n",
      "Balance Ratio: 18.17902\n",
      "\n",
      "testing data: (55903, 83) \n",
      "Balance Ratio: 3104.72222\n",
      "Dimension of dataset 0 : (80518, 141)  balance ratio: 1101.9863\n",
      "Dimension of dataset 1 : (1634, 141)  balance ratio: 1.0\n",
      "Dimension of dataset 2 : (1484, 141)  balance ratio: 1.0\n",
      "Dimension of dataset 3 : (1752, 141)  balance ratio: 1.0\n",
      "Dimension of dataset 4 : (1608, 141)  balance ratio: 1.0\n",
      "Dimension of dataset 5 : (1618, 141)  balance ratio: 1.00496\n",
      "Dimension of dataset 6 : (1555, 141)  balance ratio: 1.09005\n",
      "Dimension of dataset 7 : (1622, 141)  balance ratio: 1.0\n",
      "Dimension of dataset 8 : (1622, 141)  balance ratio: 1.0\n",
      "Dimension of dataset 9 : (803, 141)  balance ratio: 10.0\n",
      "\n",
      " 10 datasets are loaded.\n",
      "\n",
      "Labels of  10 datasets are divided.\n",
      "\n",
      " Dimension of run test: (47725, 141)\n"
     ]
    }
   ],
   "source": [
    "###bad types###\n",
    "bad = pd.read_csv('event/Bad_Types.csv').iloc[:, 1:]\n",
    "Bad_Types = {bad.cb[i]:i for i in range (len(bad))}\n",
    "print('Total bad types:', len(bad))\n",
    "\n",
    "###single dataset###\n",
    "test = pd.read_csv('event/TestingSet_0.csv').iloc[:, 2:]\n",
    "train = pd.read_csv('event/TrainingSet_new.csv').iloc[:, 2:]\n",
    "print('\\ntraining data:', train.shape, '\\nBalance Ratio:', Balance_Ratio(train))\n",
    "print('\\ntesting data:', test.shape, '\\nBalance Ratio:', Balance_Ratio(test))\n",
    "\n",
    "train_x, train_y, test_x, test_y = label_divide(train, test, 'GB')\n",
    "\n",
    "###multiple dataset###\n",
    "data_dict = multiple_set(num_set = 10)\n",
    "trainset_x, trainset_y = train_set(data_dict, num_set = 10, label = 'GB')\n",
    "test_x, test_y = label_divide(test, None, 'GB', train_only = True)\n",
    "\n",
    "\n",
    "#####for runhist dataset#####\n",
    "# bad = pd.read_csv('run_bad_types.csv').iloc[:, 1:]\n",
    "# Bad_Types = {bad.cb[i]:i for i in range (len(bad))}\n",
    "# print('Total bad types:', len(bad))\n",
    "\n",
    "run_test = pd.read_csv('test_runhist.csv').iloc[:, 2:]\n",
    "run_test_x, run_test_y = label_divide(run_test, None, 'GB', train_only = True)\n",
    "print('\\n', 'Dimension of run test:', run_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Output for Tableau"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-13T07:53:08.099099Z",
     "start_time": "2021-09-13T07:52:02.395018Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Dataset 0:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\envs\\aging\\lib\\site-packages\\lightgbm\\engine.py:148: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.0 \n",
      "Recall: 0.0 \n",
      "Aging Rate: 4.1906757464641176e-05\n",
      "\n",
      " Dataset 1:\n",
      "Precision: 0.0006370921771786875 \n",
      "Recall: 0.5588235294117647 \n",
      "Aging Rate: 0.6248926139339969\n",
      "\n",
      " Dataset 2:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\envs\\aging\\lib\\site-packages\\lightgbm\\engine.py:148: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "C:\\Users\\user\\anaconda3\\envs\\aging\\lib\\site-packages\\lightgbm\\engine.py:148: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.0007584695769425249 \n",
      "Recall: 0.7941176470588235 \n",
      "Aging Rate: 0.7458983761131482\n",
      "\n",
      " Dataset 3:\n",
      "Precision: 0.0008131805968038467 \n",
      "Recall: 0.6764705882352942 \n",
      "Aging Rate: 0.5926453640649555\n",
      "\n",
      " Dataset 4:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\envs\\aging\\lib\\site-packages\\lightgbm\\engine.py:148: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "C:\\Users\\user\\anaconda3\\envs\\aging\\lib\\site-packages\\lightgbm\\engine.py:148: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.0007052186177715092 \n",
      "Recall: 0.6470588235294118 \n",
      "Aging Rate: 0.653661602933473\n",
      "\n",
      " Dataset 5:\n",
      "Precision: 0.0006040759228054558 \n",
      "Recall: 0.5588235294117647 \n",
      "Aging Rate: 0.6590466212676794\n",
      "\n",
      " Dataset 6:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\envs\\aging\\lib\\site-packages\\lightgbm\\engine.py:148: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "C:\\Users\\user\\anaconda3\\envs\\aging\\lib\\site-packages\\lightgbm\\engine.py:148: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.0007614454773311336 \n",
      "Recall: 0.7058823529411765 \n",
      "Aging Rate: 0.6604295442640126\n",
      "\n",
      " Dataset 7:\n",
      "Precision: 0.000676328502415459 \n",
      "Recall: 0.6176470588235294 \n",
      "Aging Rate: 0.6506024096385542\n",
      "\n",
      " Dataset 8:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\envs\\aging\\lib\\site-packages\\lightgbm\\engine.py:148: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "C:\\Users\\user\\anaconda3\\envs\\aging\\lib\\site-packages\\lightgbm\\engine.py:148: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.0007656381594058648 \n",
      "Recall: 0.5882352941176471 \n",
      "Aging Rate: 0.5473441592456784\n",
      "\n",
      " Dataset 9:\n",
      "Precision: 0.0007172929985966006 \n",
      "Recall: 0.6764705882352942 \n",
      "Aging Rate: 0.6718700890518596\n",
      "\n",
      " Dataset 0:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\envs\\aging\\lib\\site-packages\\lightgbm\\engine.py:148: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "C:\\Users\\user\\anaconda3\\envs\\aging\\lib\\site-packages\\lightgbm\\engine.py:148: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.0 \n",
      "Recall: 0.0 \n",
      "Aging Rate: 0.0022210581456259823\n",
      "\n",
      " Dataset 1:\n",
      "Precision: 0.0006810829218457347 \n",
      "Recall: 0.5882352941176471 \n",
      "Aging Rate: 0.6152959664745941\n",
      "\n",
      " Dataset 2:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\envs\\aging\\lib\\site-packages\\lightgbm\\engine.py:148: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "C:\\Users\\user\\anaconda3\\envs\\aging\\lib\\site-packages\\lightgbm\\engine.py:148: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.0007140307033202428 \n",
      "Recall: 0.7647058823529411 \n",
      "Aging Rate: 0.7629753797799895\n",
      "\n",
      " Dataset 3:\n",
      "Precision: 0.0007634912372028457 \n",
      "Recall: 0.6470588235294118 \n",
      "Aging Rate: 0.6037716081718177\n",
      "\n",
      " Dataset 4:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\envs\\aging\\lib\\site-packages\\lightgbm\\engine.py:148: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "C:\\Users\\user\\anaconda3\\envs\\aging\\lib\\site-packages\\lightgbm\\engine.py:148: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.0008231864174241125 \n",
      "Recall: 0.7058823529411765 \n",
      "Aging Rate: 0.6108957569408067\n",
      "\n",
      " Dataset 5:\n",
      "Precision: 0.0006610009442870633 \n",
      "Recall: 0.6176470588235294 \n",
      "Aging Rate: 0.665688842325825\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\envs\\aging\\lib\\site-packages\\lightgbm\\engine.py:148: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Dataset 6:\n",
      "Precision: 0.0006529972574115189 \n",
      "Recall: 0.5882352941176471 \n",
      "Aging Rate: 0.6417600838135149\n",
      "\n",
      " Dataset 7:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\envs\\aging\\lib\\site-packages\\lightgbm\\engine.py:148: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "C:\\Users\\user\\anaconda3\\envs\\aging\\lib\\site-packages\\lightgbm\\engine.py:148: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.0007427501130271912 \n",
      "Recall: 0.6764705882352942 \n",
      "Aging Rate: 0.6488423258250393\n",
      "\n",
      " Dataset 8:\n",
      "Precision: 0.0006394270733422853 \n",
      "Recall: 0.5882352941176471 \n",
      "Aging Rate: 0.6553797799895233\n",
      "\n",
      " Dataset 9:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\envs\\aging\\lib\\site-packages\\lightgbm\\engine.py:148: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "C:\\Users\\user\\anaconda3\\envs\\aging\\lib\\site-packages\\lightgbm\\engine.py:148: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.0007075775119001673 \n",
      "Recall: 0.6470588235294118 \n",
      "Aging Rate: 0.6514824515453117\n",
      "\n",
      " Dataset 0:\n",
      "[15:52:06] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\envs\\aging\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.0 \n",
      "Recall: 0.0 \n",
      "Aging Rate: 6.286013619696175e-05\n",
      "\n",
      " Dataset 1:\n",
      "[15:52:15] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Precision: 0.0006890441972635102 \n",
      "Recall: 0.6176470588235294 \n",
      "Aging Rate: 0.6385961236249346\n",
      "\n",
      " Dataset 2:\n",
      "[15:52:15] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Precision: 0.000731858357259472 \n",
      "Recall: 0.7647058823529411 \n",
      "Aging Rate: 0.7443897328444211\n",
      "\n",
      " Dataset 3:\n",
      "[15:52:16] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Precision: 0.0007877375521055569 \n",
      "Recall: 0.7058823529411765 \n",
      "Aging Rate: 0.6383865898376113\n",
      "\n",
      " Dataset 4:\n",
      "[15:52:16] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Precision: 0.0006387939570091667 \n",
      "Recall: 0.5882352941176471 \n",
      "Aging Rate: 0.6560293347302253\n",
      "\n",
      " Dataset 5:\n",
      "[15:52:16] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Precision: 0.0006944663657312415 \n",
      "Recall: 0.6470588235294118 \n",
      "Aging Rate: 0.6637820848611838\n",
      "\n",
      " Dataset 6:\n",
      "[15:52:16] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Precision: 0.0006975269499048827 \n",
      "Recall: 0.6470588235294118 \n",
      "Aging Rate: 0.6608695652173913\n",
      "\n",
      " Dataset 7:\n",
      "[15:52:16] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Precision: 0.0008229863670519197 \n",
      "Recall: 0.6764705882352942 \n",
      "Aging Rate: 0.5855840754321634\n",
      "\n",
      " Dataset 8:\n",
      "[15:52:17] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Precision: 0.0007637643620907219 \n",
      "Recall: 0.6764705882352942 \n",
      "Aging Rate: 0.6309900471451021\n",
      "\n",
      " Dataset 9:\n",
      "[15:52:17] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Precision: 0.0007360414987206897 \n",
      "Recall: 0.6176470588235294 \n",
      "Aging Rate: 0.5978208486118387\n",
      "\n",
      " Dataset 0:\n",
      "[15:52:17] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Precision: 0.0 \n",
      "Recall: 0.0 \n",
      "Aging Rate: 4.1906757464641176e-05\n",
      "\n",
      " Dataset 1:\n",
      "[15:52:26] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Precision: 0.0006270834020924783 \n",
      "Recall: 0.5588235294117647 \n",
      "Aging Rate: 0.6348664222105814\n",
      "\n",
      " Dataset 2:\n",
      "[15:52:26] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Precision: 0.0006738355279782126 \n",
      "Recall: 0.7058823529411765 \n",
      "Aging Rate: 0.7462964903090623\n",
      "\n",
      " Dataset 3:\n",
      "[15:52:26] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Precision: 0.0008297320656871219 \n",
      "Recall: 0.7058823529411765 \n",
      "Aging Rate: 0.606076479832373\n",
      "\n",
      " Dataset 4:\n",
      "[15:52:26] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Precision: 0.0008401460561605326 \n",
      "Recall: 0.7647058823529411 \n",
      "Aging Rate: 0.6484442116291252\n",
      "\n",
      " Dataset 5:\n",
      "[15:52:27] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Precision: 0.0006503125112901478 \n",
      "Recall: 0.5294117647058824 \n",
      "Aging Rate: 0.5799685699319015\n",
      "\n",
      " Dataset 6:\n",
      "[15:52:27] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Precision: 0.000705543114819473 \n",
      "Recall: 0.6764705882352942 \n",
      "Aging Rate: 0.6830591932949188\n",
      "\n",
      " Dataset 7:\n",
      "[15:52:27] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Precision: 0.0007161528270132846 \n",
      "Recall: 0.5882352941176471 \n",
      "Aging Rate: 0.585165007857517\n",
      "\n",
      " Dataset 8:\n",
      "[15:52:27] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Precision: 0.0007756382153576367 \n",
      "Recall: 0.6764705882352942 \n",
      "Aging Rate: 0.6213305395495023\n",
      "\n",
      " Dataset 9:\n",
      "[15:52:27] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Precision: 0.0007076389626012808 \n",
      "Recall: 0.5882352941176471 \n",
      "Aging Rate: 0.5922053431115767\n",
      "\n",
      " Dataset 0:\n",
      "Precision: 0.0 \n",
      "Recall: 0.0 \n",
      "Aging Rate: 4.1906757464641176e-05\n",
      "\n",
      " Dataset 1:\n",
      "Precision: 0.0005635496111507683 \n",
      "Recall: 0.4411764705882353 \n",
      "Aging Rate: 0.5577160817181771\n",
      "\n",
      " Dataset 2:\n",
      "Precision: 0.0007561551025346319 \n",
      "Recall: 0.7352941176470589 \n",
      "Aging Rate: 0.6927606076479832\n",
      "\n",
      " Dataset 3:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.0007829738771442808 \n",
      "Recall: 0.6470588235294118 \n",
      "Aging Rate: 0.5887480356207438\n",
      "\n",
      " Dataset 4:\n",
      "Precision: 0.0008110300081103001 \n",
      "Recall: 0.5882352941176471 \n",
      "Aging Rate: 0.5167103195390257\n",
      "\n",
      " Dataset 5:\n",
      "Precision: 0.0006466678641997485 \n",
      "Recall: 0.5294117647058824 \n",
      "Aging Rate: 0.5832372970141435\n",
      "\n",
      " Dataset 6:\n",
      "Precision: 0.0006537609414157557 \n",
      "Recall: 0.5294117647058824 \n",
      "Aging Rate: 0.5769093766369827\n",
      "\n",
      " Dataset 7:\n",
      "Precision: 0.0008170490910328862 \n",
      "Recall: 0.7058823529411765 \n",
      "Aging Rate: 0.6154845468831849\n",
      "\n",
      " Dataset 8:\n",
      "Precision: 0.0007540394973070018 \n",
      "Recall: 0.6176470588235294 \n",
      "Aging Rate: 0.5835515976951283\n",
      "\n",
      " Dataset 9:\n",
      "Precision: 0.0008249852681202121 \n",
      "Recall: 0.6176470588235294 \n",
      "Aging Rate: 0.5333682556312206\n",
      "\n",
      " Dataset 0:\n",
      "Precision: 0.0 \n",
      "Recall: 0.0 \n",
      "Aging Rate: 0.00020953378732320587\n",
      "\n",
      " Dataset 1:\n",
      "Precision: 0.0006217101172959755 \n",
      "Recall: 0.4411764705882353 \n",
      "Aging Rate: 0.5055421686746988\n",
      "\n",
      " Dataset 2:\n",
      "Precision: 0.0006132147784761613 \n",
      "Recall: 0.5882352941176471 \n",
      "Aging Rate: 0.683394447354636\n",
      "\n",
      " Dataset 3:\n",
      "Precision: 0.0008159789974101536 \n",
      "Recall: 0.6764705882352942 \n",
      "Aging Rate: 0.5906128863279204\n",
      "\n",
      " Dataset 4:\n",
      "Precision: 0.0008032435740514076 \n",
      "Recall: 0.6176470588235294 \n",
      "Aging Rate: 0.5478051335777894\n",
      "\n",
      " Dataset 5:\n",
      "Precision: 0.0006607201850016518 \n",
      "Recall: 0.5882352941176471 \n",
      "Aging Rate: 0.6342587742273441\n",
      "\n",
      " Dataset 6:\n",
      "Precision: 0.000646324454876348 \n",
      "Recall: 0.5588235294117647 \n",
      "Aging Rate: 0.6159664745940283\n",
      "\n",
      " Dataset 7:\n",
      "Precision: 0.0007721439864690958 \n",
      "Recall: 0.6176470588235294 \n",
      "Aging Rate: 0.569869041382923\n",
      "\n",
      " Dataset 8:\n",
      "Precision: 0.0007164093563061933 \n",
      "Recall: 0.5882352941176471 \n",
      "Aging Rate: 0.5849554740701938\n",
      "\n",
      " Dataset 9:\n",
      "Precision: 0.00090192541468962 \n",
      "Recall: 0.6764705882352942 \n",
      "Aging Rate: 0.5343321110529072\n"
     ]
    }
   ],
   "source": [
    "def tableau_classifier(hyper, num_set, trainset_x, trainset_y, test_x, test_y) :\n",
    "    \n",
    "    temp_models = pd.DataFrame()\n",
    "    for model in hyper.keys() :\n",
    "    \n",
    "        if model == 'XGBoost' :\n",
    "\n",
    "            temp_uni = runall_XGBoostC(num_set, trainset_x, test_x, trainset_y, test_y, \n",
    "                                       hyper['XGBoost']['univariate-TPE'], record_bad = False)\n",
    "            temp_multi = runall_XGBoostC(num_set, trainset_x, test_x, trainset_y, test_y, \n",
    "                                         hyper['XGBoost']['multivariate-TPE'], record_bad = False)\n",
    "            \n",
    "        elif model == 'LightGBM' :\n",
    "            \n",
    "            temp_uni = runall_LightGBMC(num_set, trainset_x, test_x, trainset_y, test_y, \n",
    "                                        hyper['LightGBM']['univariate-TPE'], record_bad = False)\n",
    "            temp_multi = runall_LightGBMC(num_set, trainset_x, test_x, trainset_y, test_y, \n",
    "                                          hyper['LightGBM']['multivariate-TPE'], record_bad = False)\n",
    "            \n",
    "        elif model == 'CatBoost' :\n",
    "            \n",
    "            temp_uni = runall_CatBoostC(num_set, trainset_x, test_x, trainset_y, test_y, \n",
    "                                        hyper['CatBoost']['univariate-TPE'], cat_feature = [], record_bad = False)\n",
    "            temp_multi = runall_CatBoostC(num_set, trainset_x, test_x, trainset_y, test_y, \n",
    "                                          hyper['CatBoost']['multivariate-TPE'], cat_feature = [], record_bad = False)\n",
    "            \n",
    "        temp_uni['Sampler'] = 'univariate-TPE'\n",
    "        temp_uni['Model'] = model\n",
    "        temp_multi['Sampler'] = 'multivaraite-TPE'\n",
    "        temp_multi['Model'] = model\n",
    "        \n",
    "        temp_samplers = pd.concat([temp_uni, temp_multi], axis = 0)\n",
    "        temp_models = pd.concat([temp_models, temp_samplers], axis = 0)\n",
    "        final_models = temp_models.reset_index().rename(columns = {'index': 'dataset'})\n",
    "        \n",
    "    return final_models\n",
    "\n",
    "\n",
    "\n",
    "hyper_info = {\n",
    "    'num_set': 10,\n",
    "    'date': '20210914',\n",
    "    'model_list': ['LightGBM', 'XGBoost', 'CatBoost'],\n",
    "    'iter_list': [250, 250, 250],\n",
    "    'filename': 'runhist_array_m8m3_joinnewevent_eqp+rework',\n",
    "    'mode': 'C',\n",
    "    'sampler_list': ['univariate-TPE', 'multivariate-TPE']\n",
    "}\n",
    "\n",
    "output_hyper = tableau_hyper(**hyper_info)\n",
    "        \n",
    "table_C = tableau_classifier(output_hyper, 10, trainset_x, trainset_y, run_test_x, run_test_y)      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-13T08:02:20.986832Z",
     "start_time": "2021-09-13T07:53:08.630364Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Dataset 0:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\envs\\aging\\lib\\site-packages\\lightgbm\\engine.py:148: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Threshold: 8.60987633180383e-05 \n",
      "\n",
      "Recall: [0.70588235] ,   Precision: [0.00067991] ,   Aging Rate: [0.73963332]\n",
      "\n",
      " Dataset 1:\n",
      "Best Threshold: 0.2354142175051204 \n",
      "\n",
      "Recall: [0.70588235] ,   Precision: [0.00072734] ,   Aging Rate: [0.69139864]\n",
      "\n",
      " Dataset 2:\n",
      "Best Threshold: 0.6546842580783218 \n",
      "\n",
      "Recall: [0.70588235] ,   Precision: [0.00071835] ,   Aging Rate: [0.70005238]\n",
      "\n",
      " Dataset 3:\n",
      "Best Threshold: 0.2452390864930486 \n",
      "\n",
      "Recall: [0.70588235] ,   Precision: [0.00073329] ,   Aging Rate: [0.68578313]\n",
      "\n",
      " Dataset 4:\n",
      "Best Threshold: 0.37404649794061257 \n",
      "\n",
      "Recall: [0.70588235] ,   Precision: [0.00074377] ,   Aging Rate: [0.67612362]\n",
      "\n",
      " Dataset 5:\n",
      "Best Threshold: 0.1640264323601627 \n",
      "\n",
      "Recall: [0.70588235] ,   Precision: [0.00068292] ,   Aging Rate: [0.73636459]\n",
      "\n",
      " Dataset 6:\n",
      "Best Threshold: 0.5505206546869672 \n",
      "\n",
      "Recall: [0.70588235] ,   Precision: [0.00087114] ,   Aging Rate: [0.57726558]\n",
      "\n",
      " Dataset 7:\n",
      "Best Threshold: 0.22228451542768662 \n",
      "\n",
      "Recall: [0.70588235] ,   Precision: [0.00070786] ,   Aging Rate: [0.71042431]\n",
      "\n",
      " Dataset 8:\n",
      "Best Threshold: 0.06550840593694722 \n",
      "\n",
      "Recall: [0.70588235] ,   Precision: [0.0007053] ,   Aging Rate: [0.71300157]\n",
      "\n",
      " Dataset 9:\n",
      "Best Threshold: 0.2135722211156239 \n",
      "\n",
      "Recall: [0.70588235] ,   Precision: [0.00078642] ,   Aging Rate: [0.63945521]\n",
      "\n",
      " Dataset 0:\n",
      "Best Threshold: 1.1880340089441421e-07 \n",
      "\n",
      "Recall: [0.70588235] ,   Precision: [0.00062246] ,   Aging Rate: [0.80789942]\n",
      "\n",
      " Dataset 1:\n",
      "Best Threshold: 0.10804295247355201 \n",
      "\n",
      "Recall: [0.70588235] ,   Precision: [0.00066847] ,   Aging Rate: [0.75228916]\n",
      "\n",
      " Dataset 2:\n",
      "Best Threshold: 0.3583469485620142 \n",
      "\n",
      "Recall: [0.70588235] ,   Precision: [0.00066836] ,   Aging Rate: [0.75241488]\n",
      "\n",
      " Dataset 3:\n",
      "Best Threshold: 0.09881832713626662 \n",
      "\n",
      "Recall: [0.70588235] ,   Precision: [0.00075401] ,   Aging Rate: [0.66694605]\n",
      "\n",
      " Dataset 4:\n",
      "Best Threshold: 0.5063399517272242 \n",
      "\n",
      "Recall: [0.70588235] ,   Precision: [0.00080515] ,   Aging Rate: [0.62457831]\n",
      "\n",
      " Dataset 5:\n",
      "Best Threshold: 0.37793794750361254 \n",
      "\n",
      "Recall: [0.70588235] ,   Precision: [0.00078557] ,   Aging Rate: [0.64014667]\n",
      "\n",
      " Dataset 6:\n",
      "Best Threshold: 0.19439797824546523 \n",
      "\n",
      "Recall: [0.70588235] ,   Precision: [0.00076094] ,   Aging Rate: [0.66086957]\n",
      "\n",
      " Dataset 7:\n",
      "Best Threshold: 0.17357826033062895 \n",
      "\n",
      "Recall: [0.70588235] ,   Precision: [0.00072771] ,   Aging Rate: [0.69104243]\n",
      "\n",
      " Dataset 8:\n",
      "Best Threshold: 0.14900988223809553 \n",
      "\n",
      "Recall: [0.70588235] ,   Precision: [0.00069697] ,   Aging Rate: [0.7215296]\n",
      "\n",
      " Dataset 9:\n",
      "Best Threshold: 0.25124413518879707 \n",
      "\n",
      "Recall: [0.70588235] ,   Precision: [0.00075379] ,   Aging Rate: [0.66713463]\n",
      "\n",
      " Dataset 0:\n",
      "Best Threshold: 0.0027317816857248545 \n",
      "\n",
      "Recall: [0.70588235] ,   Precision: [0.0006781] ,   Aging Rate: [0.74160293]\n",
      "\n",
      " Dataset 1:\n",
      "Best Threshold: 0.19529813528060913 \n",
      "\n",
      "Recall: [0.70588235] ,   Precision: [0.00068505] ,   Aging Rate: [0.73408067]\n",
      "\n",
      " Dataset 2:\n",
      "Best Threshold: 0.18385499715805054 \n",
      "\n",
      "Recall: [0.70588235] ,   Precision: [0.0006375] ,   Aging Rate: [0.78883185]\n",
      "\n",
      " Dataset 3:\n",
      "Best Threshold: 0.36179596185684204 \n",
      "\n",
      "Recall: [0.70588235] ,   Precision: [0.00072842] ,   Aging Rate: [0.69037192]\n",
      "\n",
      " Dataset 4:\n",
      "Best Threshold: 0.3106038272380829 \n",
      "\n",
      "Recall: [0.70588235] ,   Precision: [0.0007284] ,   Aging Rate: [0.69039288]\n",
      "\n",
      " Dataset 5:\n",
      "Best Threshold: 0.3350037634372711 \n",
      "\n",
      "Recall: [0.70588235] ,   Precision: [0.00080421] ,   Aging Rate: [0.62531168]\n",
      "\n",
      " Dataset 6:\n",
      "Best Threshold: 0.3526906967163086 \n",
      "\n",
      "Recall: [0.70588235] ,   Precision: [0.00075641] ,   Aging Rate: [0.66482975]\n",
      "\n",
      " Dataset 7:\n",
      "Best Threshold: 0.325070858001709 \n",
      "\n",
      "Recall: [0.70588235] ,   Precision: [0.00070688] ,   Aging Rate: [0.71140911]\n",
      "\n",
      " Dataset 8:\n",
      "Best Threshold: 0.36835378408432007 \n",
      "\n",
      "Recall: [0.70588235] ,   Precision: [0.00078963] ,   Aging Rate: [0.63685699]\n",
      "\n",
      " Dataset 9:\n",
      "Best Threshold: 0.4988952875137329 \n",
      "\n",
      "Recall: [0.70588235] ,   Precision: [0.00088509] ,   Aging Rate: [0.56817182]\n",
      "\n",
      " Dataset 0:\n",
      "Best Threshold: -0.00113894313108176 \n",
      "\n",
      "Recall: [0.70588235] ,   Precision: [0.00075134] ,   Aging Rate: [0.66931378]\n",
      "\n",
      " Dataset 1:\n",
      "Best Threshold: 0.2101210057735443 \n",
      "\n",
      "Recall: [0.70588235] ,   Precision: [0.00066322] ,   Aging Rate: [0.75823992]\n",
      "\n",
      " Dataset 2:\n",
      "Best Threshold: 0.38852301239967346 \n",
      "\n",
      "Recall: [0.70588235] ,   Precision: [0.00074536] ,   Aging Rate: [0.67467784]\n",
      "\n",
      " Dataset 3:\n",
      "Best Threshold: 0.4736872911453247 \n",
      "\n",
      "Recall: [0.70588235] ,   Precision: [0.00082228] ,   Aging Rate: [0.61156627]\n",
      "\n",
      " Dataset 4:\n",
      "Best Threshold: 0.4145931005477905 \n",
      "\n",
      "Recall: [0.70588235] ,   Precision: [0.00101437] ,   Aging Rate: [0.49575694]\n",
      "\n",
      " Dataset 5:\n",
      "Best Threshold: 0.40148240327835083 \n",
      "\n",
      "Recall: [0.70588235] ,   Precision: [0.00079077] ,   Aging Rate: [0.63593504]\n",
      "\n",
      " Dataset 6:\n",
      "Best Threshold: 0.3888906240463257 \n",
      "\n",
      "Recall: [0.70588235] ,   Precision: [0.00076857] ,   Aging Rate: [0.65431116]\n",
      "\n",
      " Dataset 7:\n",
      "Best Threshold: 0.39102908968925476 \n",
      "\n",
      "Recall: [0.70588235] ,   Precision: [0.0007908] ,   Aging Rate: [0.63591409]\n",
      "\n",
      " Dataset 8:\n",
      "Best Threshold: 0.42225542664527893 \n",
      "\n",
      "Recall: [0.70588235] ,   Precision: [0.00084078] ,   Aging Rate: [0.5981142]\n",
      "\n",
      " Dataset 9:\n",
      "Best Threshold: 0.3571353554725647 \n",
      "\n",
      "Recall: [0.70588235] ,   Precision: [0.00075693] ,   Aging Rate: [0.66436878]\n",
      "\n",
      " Dataset 0:\n",
      "Best Threshold: 0.0003698144721331456 \n",
      "\n",
      "Recall: [0.70588235] ,   Precision: [0.00075717] ,   Aging Rate: [0.66415925]\n",
      "\n",
      " Dataset 1:\n",
      "Best Threshold: 0.3761366446002115 \n",
      "\n",
      "Recall: [0.70588235] ,   Precision: [0.00075401] ,   Aging Rate: [0.66694605]\n",
      "\n",
      " Dataset 2:\n",
      "Best Threshold: 0.22180349758737872 \n",
      "\n",
      "Recall: [0.70588235] ,   Precision: [0.00061789] ,   Aging Rate: [0.81387114]\n",
      "\n",
      " Dataset 3:\n",
      "Best Threshold: 0.3223894803842625 \n",
      "\n",
      "Recall: [0.70588235] ,   Precision: [0.00075209] ,   Aging Rate: [0.66864327]\n",
      "\n",
      " Dataset 4:\n",
      "Best Threshold: 0.4331247679993924 \n",
      "\n",
      "Recall: [0.70588235] ,   Precision: [0.0008115] ,   Aging Rate: [0.61969618]\n",
      "\n",
      " Dataset 5:\n",
      "Best Threshold: 0.3553697001764127 \n",
      "\n",
      "Recall: [0.70588235] ,   Precision: [0.00074564] ,   Aging Rate: [0.6744264]\n",
      "\n",
      " Dataset 6:\n",
      "Best Threshold: 0.39593951390589993 \n",
      "\n",
      "Recall: [0.70588235] ,   Precision: [0.00076761] ,   Aging Rate: [0.65512834]\n",
      "\n",
      " Dataset 7:\n",
      "Best Threshold: 0.3391315701942753 \n",
      "\n",
      "Recall: [0.70588235] ,   Precision: [0.00074136] ,   Aging Rate: [0.67832373]\n",
      "\n",
      " Dataset 8:\n",
      "Best Threshold: 0.407448180514626 \n",
      "\n",
      "Recall: [0.70588235] ,   Precision: [0.00076492] ,   Aging Rate: [0.65743321]\n",
      "\n",
      " Dataset 9:\n",
      "Best Threshold: 0.5087717529224755 \n",
      "\n",
      "Recall: [0.70588235] ,   Precision: [0.00085525] ,   Aging Rate: [0.58799371]\n",
      "\n",
      " Dataset 0:\n",
      "Best Threshold: -0.0007243723941524481 \n",
      "\n",
      "Recall: [0.70588235] ,   Precision: [0.00067904] ,   Aging Rate: [0.74057622]\n",
      "\n",
      " Dataset 1:\n",
      "Best Threshold: 0.43848529362982536 \n",
      "\n",
      "Recall: [0.70588235] ,   Precision: [0.00078194] ,   Aging Rate: [0.64312205]\n",
      "\n",
      " Dataset 2:\n",
      "Best Threshold: 0.39532144689509197 \n",
      "\n",
      "Recall: [0.70588235] ,   Precision: [0.00065735] ,   Aging Rate: [0.76500786]\n",
      "\n",
      " Dataset 3:\n",
      "Best Threshold: 0.31148592229473937 \n",
      "\n",
      "Recall: [0.70588235] ,   Precision: [0.00072982] ,   Aging Rate: [0.68905186]\n",
      "\n",
      " Dataset 4:\n",
      "Best Threshold: 0.4601018175005041 \n",
      "\n",
      "Recall: [0.70588235] ,   Precision: [0.00082006] ,   Aging Rate: [0.61322158]\n",
      "\n",
      " Dataset 5:\n",
      "Best Threshold: 0.40659657131760324 \n",
      "\n",
      "Recall: [0.70588235] ,   Precision: [0.00066737] ,   Aging Rate: [0.75352541]\n",
      "\n",
      " Dataset 6:\n",
      "Best Threshold: 0.3012698279726932 \n",
      "\n",
      "Recall: [0.70588235] ,   Precision: [0.00066657] ,   Aging Rate: [0.7544264]\n",
      "\n",
      " Dataset 7:\n",
      "Best Threshold: 0.46097943522828094 \n",
      "\n",
      "Recall: [0.70588235] ,   Precision: [0.00080521] ,   Aging Rate: [0.62453641]\n",
      "\n",
      " Dataset 8:\n",
      "Best Threshold: 0.45288865668708767 \n",
      "\n",
      "Recall: [0.70588235] ,   Precision: [0.00077889] ,   Aging Rate: [0.64563646]\n",
      "\n",
      " Dataset 9:\n",
      "Best Threshold: 0.14049801283966598 \n",
      "\n",
      "Recall: [0.70588235] ,   Precision: [0.00060874] ,   Aging Rate: [0.82610791]\n",
      "\n",
      " Dataset 0:\n",
      "Best Threshold: 4.761245483358789e-05 \n",
      "\n",
      "Recall: [0.82352941] ,   Precision: [0.00069551] ,   Aging Rate: [0.84354112]\n",
      "\n",
      " Dataset 1:\n",
      "Best Threshold: 0.04029081432490746 \n",
      "\n",
      "Recall: [0.82352941] ,   Precision: [0.00073842] ,   Aging Rate: [0.79453117]\n",
      "\n",
      " Dataset 2:\n",
      "Best Threshold: 0.10990798423813072 \n",
      "\n",
      "Recall: [0.82352941] ,   Precision: [0.0006882] ,   Aging Rate: [0.85250917]\n",
      "\n",
      " Dataset 3:\n",
      "Best Threshold: 0.027707191547884622 \n",
      "\n",
      "Recall: [0.82352941] ,   Precision: [0.00068879] ,   Aging Rate: [0.8517758]\n",
      "\n",
      " Dataset 4:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Threshold: 0.03683226577238504 \n",
      "\n",
      "Recall: [0.82352941] ,   Precision: [0.00074182] ,   Aging Rate: [0.79088528]\n",
      "\n",
      " Dataset 5:\n",
      "Best Threshold: 0.090878813575646 \n",
      "\n",
      "Recall: [0.82352941] ,   Precision: [0.00076411] ,   Aging Rate: [0.76781561]\n",
      "\n",
      " Dataset 6:\n",
      "Best Threshold: 0.12229180193182403 \n",
      "\n",
      "Recall: [0.82352941] ,   Precision: [0.00077095] ,   Aging Rate: [0.76100576]\n",
      "\n",
      " Dataset 7:\n",
      "Best Threshold: 0.13986249223211952 \n",
      "\n",
      "Recall: [0.82352941] ,   Precision: [0.00075417] ,   Aging Rate: [0.77793609]\n",
      "\n",
      " Dataset 8:\n",
      "Best Threshold: 0.006200695344266687 \n",
      "\n",
      "Recall: [0.82352941] ,   Precision: [0.00072376] ,   Aging Rate: [0.81062336]\n",
      "\n",
      " Dataset 9:\n",
      "Best Threshold: 0.020660312907986127 \n",
      "\n",
      "Recall: [0.82352941] ,   Precision: [0.00075372] ,   Aging Rate: [0.77839707]\n",
      "\n",
      " Dataset 0:\n",
      "Best Threshold: 6.857744625792842e-08 \n",
      "\n",
      "Recall: [0.82352941] ,   Precision: [0.00067797] ,   Aging Rate: [0.86537454]\n",
      "\n",
      " Dataset 1:\n",
      "Best Threshold: 0.015317000415591496 \n",
      "\n",
      "Recall: [0.82352941] ,   Precision: [0.00070605] ,   Aging Rate: [0.83094814]\n",
      "\n",
      " Dataset 2:\n",
      "Best Threshold: 0.15794573887766933 \n",
      "\n",
      "Recall: [0.82352941] ,   Precision: [0.00073143] ,   Aging Rate: [0.80211629]\n",
      "\n",
      " Dataset 3:\n",
      "Best Threshold: 0.009104885991922855 \n",
      "\n",
      "Recall: [0.82352941] ,   Precision: [0.00069634] ,   Aging Rate: [0.84253536]\n",
      "\n",
      " Dataset 4:\n",
      "Best Threshold: 0.2993916806573719 \n",
      "\n",
      "Recall: [0.82352941] ,   Precision: [0.00079159] ,   Aging Rate: [0.74116291]\n",
      "\n",
      " Dataset 5:\n",
      "Best Threshold: 0.07928481072513198 \n",
      "\n",
      "Recall: [0.82352941] ,   Precision: [0.00072858] ,   Aging Rate: [0.8052593]\n",
      "\n",
      " Dataset 6:\n",
      "Best Threshold: 0.0017000125840016876 \n",
      "\n",
      "Recall: [0.82352941] ,   Precision: [0.0006941] ,   Aging Rate: [0.8452593]\n",
      "\n",
      " Dataset 7:\n",
      "Best Threshold: 0.03319432596609258 \n",
      "\n",
      "Recall: [0.82352941] ,   Precision: [0.00075868] ,   Aging Rate: [0.7733054]\n",
      "\n",
      " Dataset 8:\n",
      "Best Threshold: 0.028542402851911227 \n",
      "\n",
      "Recall: [0.82352941] ,   Precision: [0.0007229] ,   Aging Rate: [0.81158722]\n",
      "\n",
      " Dataset 9:\n",
      "Best Threshold: 0.02970058325360315 \n",
      "\n",
      "Recall: [0.82352941] ,   Precision: [0.00077378] ,   Aging Rate: [0.75821896]\n",
      "\n",
      " Dataset 0:\n",
      "Best Threshold: 0.0026297506410628557 \n",
      "\n",
      "Recall: [0.82352941] ,   Precision: [0.00068938] ,   Aging Rate: [0.85104243]\n",
      "\n",
      " Dataset 1:\n",
      "Best Threshold: 0.06701523065567017 \n",
      "\n",
      "Recall: [0.82352941] ,   Precision: [0.00070679] ,   Aging Rate: [0.83008905]\n",
      "\n",
      " Dataset 2:\n",
      "Best Threshold: 0.10648676753044128 \n",
      "\n",
      "Recall: [0.82352941] ,   Precision: [0.00067141] ,   Aging Rate: [0.87381875]\n",
      "\n",
      " Dataset 3:\n",
      "Best Threshold: 0.22224067151546478 \n",
      "\n",
      "Recall: [0.82352941] ,   Precision: [0.00072786] ,   Aging Rate: [0.80605553]\n",
      "\n",
      " Dataset 4:\n",
      "Best Threshold: 0.17017386853694916 \n",
      "\n",
      "Recall: [0.82352941] ,   Precision: [0.000711] ,   Aging Rate: [0.82516501]\n",
      "\n",
      " Dataset 5:\n",
      "Best Threshold: 0.15228508412837982 \n",
      "\n",
      "Recall: [0.82352941] ,   Precision: [0.00078086] ,   Aging Rate: [0.75134625]\n",
      "\n",
      " Dataset 6:\n",
      "Best Threshold: 0.23050054907798767 \n",
      "\n",
      "Recall: [0.82352941] ,   Precision: [0.00075811] ,   Aging Rate: [0.77389209]\n",
      "\n",
      " Dataset 7:\n",
      "Best Threshold: 0.19552433490753174 \n",
      "\n",
      "Recall: [0.82352941] ,   Precision: [0.00070479] ,   Aging Rate: [0.83243583]\n",
      "\n",
      " Dataset 8:\n",
      "Best Threshold: 0.29957544803619385 \n",
      "\n",
      "Recall: [0.82352941] ,   Precision: [0.00084467] ,   Aging Rate: [0.69458355]\n",
      "\n",
      " Dataset 9:\n",
      "Best Threshold: 0.21100342273712158 \n",
      "\n",
      "Recall: [0.82352941] ,   Precision: [0.00069056] ,   Aging Rate: [0.84959665]\n",
      "\n",
      " Dataset 0:\n",
      "Best Threshold: -0.0022720657289028168 \n",
      "\n",
      "Recall: [0.82352941] ,   Precision: [0.00073136] ,   Aging Rate: [0.8022001]\n",
      "\n",
      " Dataset 1:\n",
      "Best Threshold: 0.10785581916570663 \n",
      "\n",
      "Recall: [0.82352941] ,   Precision: [0.00069782] ,   Aging Rate: [0.84075432]\n",
      "\n",
      " Dataset 2:\n",
      "Best Threshold: 0.21995726227760315 \n",
      "\n",
      "Recall: [0.82352941] ,   Precision: [0.00071066] ,   Aging Rate: [0.82556312]\n",
      "\n",
      " Dataset 3:\n",
      "Best Threshold: 0.2701001465320587 \n",
      "\n",
      "Recall: [0.82352941] ,   Precision: [0.00072464] ,   Aging Rate: [0.80963855]\n",
      "\n",
      " Dataset 4:\n",
      "Best Threshold: 0.08721035718917847 \n",
      "\n",
      "Recall: [0.82352941] ,   Precision: [0.00074156] ,   Aging Rate: [0.79115767]\n",
      "\n",
      " Dataset 5:\n",
      "Best Threshold: 0.25359076261520386 \n",
      "\n",
      "Recall: [0.82352941] ,   Precision: [0.00078822] ,   Aging Rate: [0.74432687]\n",
      "\n",
      " Dataset 6:\n",
      "Best Threshold: 0.23400789499282837 \n",
      "\n",
      "Recall: [0.82352941] ,   Precision: [0.00072659] ,   Aging Rate: [0.8074594]\n",
      "\n",
      " Dataset 7:\n",
      "Best Threshold: 0.2949516475200653 \n",
      "\n",
      "Recall: [0.82352941] ,   Precision: [0.00083042] ,   Aging Rate: [0.70650602]\n",
      "\n",
      " Dataset 8:\n",
      "Best Threshold: 0.20837661623954773 \n",
      "\n",
      "Recall: [0.82352941] ,   Precision: [0.00072133] ,   Aging Rate: [0.8133473]\n",
      "\n",
      " Dataset 9:\n",
      "Best Threshold: 0.18667861819267273 \n",
      "\n",
      "Recall: [0.82352941] ,   Precision: [0.00072884] ,   Aging Rate: [0.80496595]\n",
      "\n",
      " Dataset 0:\n",
      "Best Threshold: 0.00031472429228330016 \n",
      "\n",
      "Recall: [0.82352941] ,   Precision: [0.0007718] ,   Aging Rate: [0.76016763]\n",
      "\n",
      " Dataset 1:\n",
      "Best Threshold: 0.26109397640698534 \n",
      "\n",
      "Recall: [0.82352941] ,   Precision: [0.00074553] ,   Aging Rate: [0.78694605]\n",
      "\n",
      " Dataset 2:\n",
      "Best Threshold: 0.17808970197592916 \n",
      "\n",
      "Recall: [0.82352941] ,   Precision: [0.0006903] ,   Aging Rate: [0.84991095]\n",
      "\n",
      " Dataset 3:\n",
      "Best Threshold: 0.1301460567878272 \n",
      "\n",
      "Recall: [0.82352941] ,   Precision: [0.00065657] ,   Aging Rate: [0.89357779]\n",
      "\n",
      " Dataset 4:\n",
      "Best Threshold: 0.30448950254029306 \n",
      "\n",
      "Recall: [0.82352941] ,   Precision: [0.00076978] ,   Aging Rate: [0.7621582]\n",
      "\n",
      " Dataset 5:\n",
      "Best Threshold: 0.13849852550935254 \n",
      "\n",
      "Recall: [0.82352941] ,   Precision: [0.00066545] ,   Aging Rate: [0.88165532]\n",
      "\n",
      " Dataset 6:\n",
      "Best Threshold: 0.27702293953264634 \n",
      "\n",
      "Recall: [0.82352941] ,   Precision: [0.00074328] ,   Aging Rate: [0.78933473]\n",
      "\n",
      " Dataset 7:\n",
      "Best Threshold: 0.2748912818494415 \n",
      "\n",
      "Recall: [0.82352941] ,   Precision: [0.00077853] ,   Aging Rate: [0.75358827]\n",
      "\n",
      " Dataset 8:\n",
      "Best Threshold: 0.29542056401948646 \n",
      "\n",
      "Recall: [0.82352941] ,   Precision: [0.00076545] ,   Aging Rate: [0.76647459]\n",
      "\n",
      " Dataset 9:\n",
      "Best Threshold: 0.40716652127722835 \n",
      "\n",
      "Recall: [0.82352941] ,   Precision: [0.00085109] ,   Aging Rate: [0.68934521]\n",
      "\n",
      " Dataset 0:\n",
      "Best Threshold: -0.0008689819472005313 \n",
      "\n",
      "Recall: [0.82352941] ,   Precision: [0.00073555] ,   Aging Rate: [0.79763227]\n",
      "\n",
      " Dataset 1:\n",
      "Best Threshold: 0.25879413178967237 \n",
      "\n",
      "Recall: [0.82352941] ,   Precision: [0.00074039] ,   Aging Rate: [0.79241488]\n",
      "\n",
      " Dataset 2:\n",
      "Best Threshold: 0.35130761670905664 \n",
      "\n",
      "Recall: [0.82352941] ,   Precision: [0.00071811] ,   Aging Rate: [0.81699319]\n",
      "\n",
      " Dataset 3:\n",
      "Best Threshold: 0.17165502842037078 \n",
      "\n",
      "Recall: [0.82352941] ,   Precision: [0.00067818] ,   Aging Rate: [0.86510215]\n",
      "\n",
      " Dataset 4:\n",
      "Best Threshold: 0.37109285348482324 \n",
      "\n",
      "Recall: [0.82352941] ,   Precision: [0.00079298] ,   Aging Rate: [0.7398638]\n",
      "\n",
      " Dataset 5:\n",
      "Best Threshold: 0.30488617138079843 \n",
      "\n",
      "Recall: [0.82352941] ,   Precision: [0.00068766] ,   Aging Rate: [0.85317968]\n",
      "\n",
      " Dataset 6:\n",
      "Best Threshold: 0.1831326416741771 \n",
      "\n",
      "Recall: [0.82352941] ,   Precision: [0.00067621] ,   Aging Rate: [0.86761655]\n",
      "\n",
      " Dataset 7:\n",
      "Best Threshold: 0.26921487015951373 \n",
      "\n",
      "Recall: [0.82352941] ,   Precision: [0.00073795] ,   Aging Rate: [0.79503405]\n",
      "\n",
      " Dataset 8:\n",
      "Best Threshold: 0.41859653408197633 \n",
      "\n",
      "Recall: [0.82352941] ,   Precision: [0.00085454] ,   Aging Rate: [0.68655841]\n",
      "\n",
      " Dataset 9:\n",
      "Best Threshold: 0.10704126386584806 \n",
      "\n",
      "Recall: [0.82352941] ,   Precision: [0.00066058] ,   Aging Rate: [0.88815086]\n"
     ]
    }
   ],
   "source": [
    "def tableau_regressor(hyper, num_set, trainset_x, trainset_y, test_x, test_y, thres_target, threshold) :\n",
    "    \n",
    "    temp_models = pd.DataFrame()\n",
    "    for model in hyper.keys() :\n",
    "    \n",
    "        if model == 'XGBoost' :\n",
    "\n",
    "            _, temp_uni = runall_XGBoostR(num_set, trainset_x, test_x, trainset_y, test_y, \n",
    "                                          hyper['XGBoost']['univariate-TPE'], thres_target = thres_target, \n",
    "                                          threshold = threshold, record_bad = False)\n",
    "            _, temp_multi = runall_XGBoostR(num_set, trainset_x, test_x, trainset_y, test_y, \n",
    "                                            hyper['XGBoost']['multivariate-TPE'], thres_target = thres_target, \n",
    "                                            threshold = threshold, record_bad = False)\n",
    "            \n",
    "        elif model == 'LightGBM' :\n",
    "            \n",
    "            _, temp_uni = runall_LightGBMR(num_set, trainset_x, test_x, trainset_y, test_y, \n",
    "                                           hyper['LightGBM']['univariate-TPE'], thres_target = thres_target, \n",
    "                                           threshold = threshold, record_bad = False)\n",
    "            _, temp_multi = runall_LightGBMR(num_set, trainset_x, test_x, trainset_y, test_y, \n",
    "                                             hyper['LightGBM']['multivariate-TPE'], thres_target = thres_target, \n",
    "                                             threshold = threshold, record_bad = False)\n",
    "            \n",
    "        elif model == 'CatBoost' :\n",
    "            \n",
    "            _, temp_uni = runall_CatBoostR(num_set, trainset_x, test_x, trainset_y, test_y, \n",
    "                                           hyper['CatBoost']['univariate-TPE'], cat_feature = [], \n",
    "                                           thres_target = thres_target, threshold = threshold, record_bad = False)\n",
    "            _, temp_multi = runall_CatBoostR(num_set, trainset_x, test_x, trainset_y, test_y, \n",
    "                                             hyper['CatBoost']['multivariate-TPE'], cat_feature = [], \n",
    "                                             thres_target = thres_target, threshold = threshold, record_bad = False)\n",
    "            \n",
    "        temp_uni['Sampler'] = 'univariate-TPE'\n",
    "        temp_uni['Model'] = model\n",
    "        temp_multi['Sampler'] = 'multivaraite-TPE'\n",
    "        temp_multi['Model'] = model\n",
    "        \n",
    "        temp_samplers = pd.concat([temp_uni, temp_multi], axis = 0)\n",
    "        temp_models = pd.concat([temp_models, temp_samplers], axis = 0)\n",
    "        final_models = temp_models.reset_index().rename(columns = {'index': 'Dataset'})\n",
    "        \n",
    "    return final_models\n",
    "\n",
    "\n",
    "\n",
    "hyper_info = {\n",
    "    'num_set': 10,\n",
    "    'date': '20210914',\n",
    "    'model_list': ['LightGBM', 'XGBoost', 'CatBoost'],\n",
    "    'iter_list': [250, 250, 250],\n",
    "    'filename': 'runhist_array_m8m3_joinnewevent_eqp+rework',\n",
    "    'mode': 'R',\n",
    "    'sampler_list': ['univariate-TPE', 'multivariate-TPE']\n",
    "}\n",
    "\n",
    "output_hyper = tableau_hyper(**hyper_info)\n",
    "        \n",
    "table_7 = tableau_regressor(output_hyper, 10, trainset_x, trainset_y, run_test_x, run_test_y, 'Recall', threshold = 0.7)    \n",
    "table_8 = tableau_regressor(output_hyper, 10, trainset_x, trainset_y, run_test_x, run_test_y, 'Recall', threshold = 0.8)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combine & output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-13T08:02:21.690276Z",
     "start_time": "2021-09-13T08:02:21.596903Z"
    }
   },
   "outputs": [],
   "source": [
    "with pd.ExcelWriter(f'{hyper_info[\"filename\"]}_result_table.xlsx') as writer :  \n",
    "    table_C.to_excel(writer, sheet_name = 'classifier')\n",
    "    table_7.to_excel(writer, sheet_name = 'regressor_7')\n",
    "    table_8.to_excel(writer, sheet_name = 'regressor_8')"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python [conda env:aging]",
   "language": "python",
   "name": "conda-env-aging-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "275.2px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
