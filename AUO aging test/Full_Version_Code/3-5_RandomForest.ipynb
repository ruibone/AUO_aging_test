{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-15T16:04:05.498296Z",
     "start_time": "2021-12-15T16:04:02.583258Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from tqdm.auto import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "import optuna\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from library.Data_Preprocessing import Balance_Ratio\n",
    "from library.Imbalance_Sampling import label_divide\n",
    "from library.Aging_Score_Contour import score1\n",
    "from library.AdaBoost import train_set, multiple_set, multiple_month, line_chart, cf_matrix, AUC, PR_curve, \\\n",
    "     multiple_curve, PR_matrix, best_threshold, all_optuna, optuna_history \n",
    "\n",
    "os.chdir('C:/Users/user/Desktop/Darui_R08621110') \n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-15T16:04:05.547673Z",
     "start_time": "2021-12-15T16:04:05.532713Z"
    }
   },
   "outputs": [],
   "source": [
    "def RandomForestC(train_x, test_x, train_y, test_y, config):\n",
    "    \n",
    "    clf = RandomForestClassifier(**config, n_jobs = -1)\n",
    "    clf.fit(train_x, train_y)\n",
    "    predict_y = clf.predict(test_x)\n",
    "    result = pd.DataFrame({'truth': test_y, 'predict': predict_y})\n",
    "    \n",
    "    return result\n",
    "\n",
    "\n",
    "def RandomForestR(train_x, test_x, train_y, test_y, config):\n",
    "    \n",
    "    clf = RandomForestRegressor(**config, n_jobs = -1)\n",
    "    clf.fit(train_x, train_y)\n",
    "    predict_y = clf.predict(test_x)\n",
    "    result = pd.DataFrame({'truth': test_y, 'predict': predict_y})\n",
    "    \n",
    "    return result\n",
    "\n",
    "\n",
    "def runall_ForestC(num_set, trainset_x, test_x, trainset_y, test_y, config):\n",
    "    \n",
    "    table_set = pd.DataFrame()\n",
    "    bad_set = pd.DataFrame()\n",
    "    judge = list(config.keys())[0]\n",
    "\n",
    "    for i in range(num_set):\n",
    "        print('\\n', f'Dataset {i}:')\n",
    "        \n",
    "        if isinstance(config[judge], dict) :\n",
    "            best_config = config[f'set{i}']\n",
    "        else :\n",
    "            best_config = config\n",
    "        \n",
    "        result = RandomForestC(trainset_x[f'set{i}'], test_x, trainset_y[f'set{i}'], test_y, best_config)\n",
    "        table = cf_matrix(result, trainset_y[f'set{i}'])\n",
    "        table_set = pd.concat([table_set, table]).rename(index = {0: f'dataset {i}'})\n",
    "\n",
    "    return table_set\n",
    "    \n",
    "    \n",
    "def runall_ForestR(num_set, trainset_x, test_x, trainset_y, test_y, config, thres_target = 'Recall', threshold = 0.8):\n",
    "    \n",
    "    table_set = pd.DataFrame()\n",
    "    bad_set = pd.DataFrame()\n",
    "    pr_dict = {}\n",
    "    judge = list(config.keys())[0]\n",
    "\n",
    "    for i in range(num_set):\n",
    "        print('\\n', f'Dataset {i}:')\n",
    "        \n",
    "        if isinstance(config[judge], dict) :\n",
    "            best_config = config[f'set{i}']\n",
    "        else :\n",
    "            best_config = config\n",
    "\n",
    "        predict = RandomForestR(trainset_x[f'set{i}'], test_x, trainset_y[f'set{i}'], test_y, best_config)\n",
    "        pr_matrix = PR_matrix(predict, trainset_y[f'set{i}'])\n",
    "        pr_dict[f'set{i}'] = pr_matrix\n",
    "        \n",
    "        best_data, best_thres = best_threshold(pr_matrix, target = thres_target, threshold = threshold)\n",
    "        table_set = pd.concat([table_set, best_data]).rename(index = {best_data.index.values[0]: f'dataset {i}'})\n",
    "\n",
    "    return pr_dict, table_set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-15T16:04:05.591426Z",
     "start_time": "2021-12-15T16:04:05.579879Z"
    }
   },
   "outputs": [],
   "source": [
    "def RandomForest_creator(train_data, mode, num_valid = 3, label = 'GB') :\n",
    "    \n",
    "    def objective(trial) :\n",
    "\n",
    "        param = {\n",
    "            'n_estimators': trial.suggest_int('n_estimators', 100, 800, step = 100),\n",
    "            'min_samples_split': trial.suggest_int('min_samples_split', 2, 32, step = 5),\n",
    "            'max_depth': trial.suggest_int('max_depth', 3, 21, step = 3),\n",
    "        }\n",
    "\n",
    "        result_list = []\n",
    "        for i in range(num_valid):\n",
    "\n",
    "            train_good = train_data[train_data.GB == 0]\n",
    "            train_bad = train_data[train_data.GB == 1]\n",
    "            train_good_x, train_good_y = label_divide(train_good, None, label, train_only = True)\n",
    "            train_bad_x, train_bad_y = label_divide(train_bad, None, label, train_only = True)\n",
    "            train_g_x, valid_g_x, train_g_y, valid_g_y = train_test_split(train_good_x, train_good_y, test_size = 0.25)\n",
    "            train_b_x, valid_b_x, train_b_y, valid_b_y = train_test_split(train_bad_x, train_bad_y, test_size = 0.25)\n",
    "            train_x = pd.concat([train_g_x, train_b_x], axis = 0)\n",
    "            train_y = pd.concat([train_g_y, train_b_y], axis = 0)\n",
    "            valid_x = pd.concat([valid_g_x, valid_b_x], axis = 0)\n",
    "            valid_y = pd.concat([valid_g_y, valid_b_y], axis = 0)\n",
    "\n",
    "            if mode == 'C':\n",
    "                result = RandomForestC(train_x, valid_x, train_y, valid_y, param)\n",
    "                table = cf_matrix(result, valid_y)\n",
    "                recall = table['Recall']\n",
    "                precision = table['Precision']\n",
    "                beta = 0.3\n",
    "                fscore = ((1+beta**2)*recall*precision) / (recall+(beta**2)*precision)\n",
    "                result_list.append(fscore)\n",
    "\n",
    "            elif mode == 'R':\n",
    "                result = RandomForestR(train_x, valid_x, train_y, valid_y, param)\n",
    "                pr_matrix = PR_matrix(result, valid_y)\n",
    "                auc = AUC(pr_matrix['Recall'], pr_matrix['Aging Rate'])\n",
    "                result_list.append((-1)*auc)\n",
    "\n",
    "        return np.mean(result_list)\n",
    "    \n",
    "    return objective"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### loading training & testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-15T16:04:12.623399Z",
     "start_time": "2021-12-15T16:04:10.118916Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "### training data ### \n",
    "training_month = range(2, 5)\n",
    "\n",
    "data_dict, trainset_x, trainset_y = multiple_month(training_month, num_set = 10, filename = 'dataset')\n",
    "\n",
    "print('\\nCombined training data:\\n')\n",
    "run_train = multiple_set(num_set = 10)\n",
    "run_train_x, run_train_y = train_set(run_train, num_set = 10)\n",
    "\n",
    "### testing data ###\n",
    "run_test = pd.read_csv('test_runhist.csv').iloc[:, 2:]\n",
    "run_test_x, run_test_y = label_divide(run_test, None, 'GB', train_only = True)\n",
    "print('\\n', 'Dimension of testing data:', run_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### search for best hyperparameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-15T16:59:36.880817Z",
     "start_time": "2021-12-15T16:04:16.960409Z"
    }
   },
   "outputs": [],
   "source": [
    "best_paramC, all_scoreC = all_optuna(num_set = 10, \n",
    "                                     all_data = run_train, \n",
    "                                     mode = 'C', \n",
    "                                     TPE_multi = True, \n",
    "                                     n_iter = 50, \n",
    "                                     filename = 'runhist_array_m2m4_m5_3criteria_RandomForest', \n",
    "                                     creator = RandomForest_creator\n",
    "                                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-14T21:31:20.405872Z",
     "start_time": "2021-10-14T15:37:08.378611Z"
    }
   },
   "outputs": [],
   "source": [
    "best_paramR, all_scoreR = all_optuna(num_set = 10, \n",
    "                                     all_data = run_train, \n",
    "                                     mode = 'R', \n",
    "                                     TPE_multi = True, \n",
    "                                     n_iter = 50,\n",
    "                                     filename = 'runhist_array_m2m5_4selection_RandomForest', \n",
    "                                     creator = RandomForest_creator\n",
    "                                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-09T04:04:35.806521Z",
     "start_time": "2021-10-09T04:04:35.027647Z"
    }
   },
   "outputs": [],
   "source": [
    "##### optimization history plot #####\n",
    "optuna_history(best_paramC, all_scoreC, num_row = 4, num_col = 3, model = 'RandomForest Classifier')\n",
    "            \n",
    "##### best hyperparameter table #####\n",
    "param_table = pd.DataFrame(best_paramC).T\n",
    "param_table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-15T16:59:58.655465Z",
     "start_time": "2021-12-15T16:59:37.985260Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "table_setC = runall_ForestC(10, run_train_x, run_test_x, run_train_y, run_test_y, best_paramC)\n",
    "line_chart(table_setC, title = 'Random Forest Classifier')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-15T16:59:59.765456Z",
     "start_time": "2021-12-15T16:59:59.735718Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "table_setC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-15T00:32:50.337866Z",
     "start_time": "2021-10-15T00:28:01.253726Z"
    }
   },
   "outputs": [],
   "source": [
    "pr_dict, table_setR = runall_ForestR(10, run_train_x, run_test_x, run_train_y, run_test_y, best_paramR, \n",
    "                                     thres_target = 'Recall', threshold = 0.7)\n",
    "line_chart(table_setR, title = 'Random Forest Regressor')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-15T00:35:54.269388Z",
     "start_time": "2021-10-15T00:35:52.349547Z"
    }
   },
   "outputs": [],
   "source": [
    "multiple_curve(3, 3, pr_dict, table_setR, target = 'Aging Rate')\n",
    "multiple_curve(3, 3, pr_dict, table_setR, target = 'Precision')\n",
    "table_setR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-15T17:00:01.140134Z",
     "start_time": "2021-12-15T17:00:00.843330Z"
    }
   },
   "outputs": [],
   "source": [
    "savedate = '20211221'\n",
    "TPE_multi = True\n",
    "\n",
    "table_setC['sampler'] = 'multivariate-TPE' if TPE_multi else 'univariate-TPE'\n",
    "table_setC['model'] = 'RandomForest'\n",
    "with pd.ExcelWriter(f'{savedate}_Classifier.xlsx', mode = 'a') as writer:\n",
    "    table_setC.to_excel(writer, sheet_name = 'RandomForest')"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python [conda env:aging]",
   "language": "python",
   "name": "conda-env-aging-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
