{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-22T12:47:52.652002Z",
     "start_time": "2021-11-22T12:47:48.597838Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression, Ridge\n",
    "from sklearn.ensemble import ExtraTreesClassifier, ExtraTreesRegressor, RandomForestClassifier, RandomForestRegressor,\\\n",
    "    AdaBoostClassifier, AdaBoostRegressor\n",
    "from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from catboost import CatBoostClassifier, CatBoostRegressor\n",
    "from lightgbm import LGBMClassifier, LGBMRegressor\n",
    "from xgboost import XGBClassifier, XGBRegressor\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "import optuna\n",
    "\n",
    "from library.Data_Preprocessing import Balance_Ratio, train_col\n",
    "from library.Imbalance_Sampling import label_divide\n",
    "from library.Aging_Score_Contour import score1\n",
    "from library.AdaBoost import train_set, multiple_set, multiple_month, line_chart, cf_matrix, AUC, PR_curve, \\\n",
    "     multiple_curve, PR_matrix, best_threshold, all_optuna, optuna_history, AdaBoost_creator \n",
    "from library.XGBoost import XGBoost_creator\n",
    "from library.LightGBM import LightGBM_creator\n",
    "from library.CatBoost import CatBoost_creator\n",
    "from library.Random_Forest import RandomForest_creator\n",
    "from library.Extra_Trees import ExtraTrees_creator\n",
    "from library.Neural_Network import RunhistSet, NeuralNetworkC, trainingC\n",
    "from library.StackingCV_Scheme3 import stratified_data, runall_LR, runall_RidgeR, stackingCV_creator, vif, \\\n",
    "    correlation_plot, rank_importance\n",
    "\n",
    "os.chdir('C:/Users/user/Desktop/Darui_R08621110')  \n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load hyperparameters from all the base learners"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-22T12:47:55.179245Z",
     "start_time": "2021-11-22T12:47:55.160296Z"
    }
   },
   "outputs": [],
   "source": [
    "def load_hyper(num_set, date, model_list, iter_list, filename, mode, TPE_multi) :\n",
    "    \n",
    "    sampler = 'multivariate-TPE' if TPE_multi else 'univariate-TPE'\n",
    "    allset_dict = {}\n",
    "    for j in range(num_set) :\n",
    "        \n",
    "        model_dict = {}\n",
    "        for i, model in enumerate(model_list) :\n",
    "\n",
    "            with open(f'hyperparameter/{date}/{filename}_{model}{mode}_{sampler}_{iter_list[i]}.data', 'rb') as f:\n",
    "                temp_dict = pickle.load(f)\n",
    "                model_dict[model] = temp_dict[f'set{j}']\n",
    "                \n",
    "        allset_dict[f'set{j}'] = model_dict\n",
    "        \n",
    "    return allset_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### transform data by base learner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-22T12:48:05.774922Z",
     "start_time": "2021-11-22T12:48:05.716079Z"
    }
   },
   "outputs": [],
   "source": [
    "def transform_train(train_data, mode, base_param, cv):\n",
    "    \n",
    "    set_name = list(base_param.keys())\n",
    "    num_set = len(set_name)\n",
    "    model_list = list(base_param[set_name[0]].keys())\n",
    "    set_dict = {}\n",
    "    for i in tqdm(range(num_set)):\n",
    "        \n",
    "        print(f'Dataset {i}:\\n')\n",
    "        train_x_dict, train_y_dict, valid_x_dict, valid_y_dict = stratified_data(train_data[f'set{i}'], cv = cv)\n",
    "        all_cv = pd.DataFrame()\n",
    "        for j in tqdm(range(cv)):\n",
    "\n",
    "            model_predict = pd.DataFrame()\n",
    "            if mode == 'C':\n",
    "                \n",
    "                if 'NeuralNetwork' in model_list:\n",
    "                    temp_train = RunhistSet(train_x_dict[j], train_y_dict[j])\n",
    "                    temp_valid = RunhistSet(valid_x_dict[j], valid_y_dict[j])\n",
    "                    train_loader = DataLoader(temp_train, batch_size = 64, shuffle = True)\n",
    "                    valid_loader = DataLoader(temp_valid, batch_size = len(valid_x_dict[j]), shuffle = False)\n",
    "                    nn_model = NeuralNetworkC(dim = train_x_dict[j].shape[1])\n",
    "                    optimizer = torch.optim.Adam(nn_model.parameters(), lr = 0.001, weight_decay = 0.01)\n",
    "                    criterion = nn.CrossEntropyLoss(weight = torch.tensor([0.5, 0.5])).to('cpu')\n",
    "                    network, _, _ = trainingC(nn_model, train_loader, train_loader, optimizer, criterion, epoch = 150, \n",
    "                                              filename = 'none', early_stop = 20)\n",
    "                    \n",
    "                    for x, y in valid_loader:\n",
    "                        output = network(x)\n",
    "                        _, predict_y = torch.max(output.data, 1)\n",
    "                    predict = pd.DataFrame({'N': predict_y.numpy()})\n",
    "                    model_predict = pd.concat([model_predict, predict], axis = 1)\n",
    "                \n",
    "                if 'XGBoost' in model_list:                     \n",
    "                    clf = XGBClassifier(**base_param[f'set{i}']['XGBoost'], n_jobs = -1)\n",
    "                    clf.fit(train_x_dict[j], train_y_dict[j])\n",
    "                    predict_y = clf.predict_proba(valid_x_dict[j])\n",
    "                    predict = pd.DataFrame({'X': predict_y[:, 0]})\n",
    "                    model_predict = pd.concat([model_predict, predict], axis = 1)\n",
    "\n",
    "                if 'LightGBM' in model_list:                        \n",
    "                    clf = LGBMClassifier(**base_param[f'set{i}']['LightGBM'])\n",
    "                    clf.fit(train_x_dict[j], train_y_dict[j])\n",
    "                    predict_y = clf.predict_proba(valid_x_dict[j])\n",
    "                    predict = pd.DataFrame({'L': predict_y[:, 0]})\n",
    "                    model_predict = pd.concat([model_predict, predict], axis = 1)\n",
    "\n",
    "                if 'CatBoost' in model_list:\n",
    "                    clf = CatBoostClassifier(**base_param[f'set{i}']['CatBoost'])\n",
    "                    clf.fit(train_x_dict[j], train_y_dict[j])\n",
    "                    predict_y = clf.predict_proba(valid_x_dict[j])\n",
    "                    predict = pd.DataFrame({'C': predict_y[:, 0]})\n",
    "                    model_predict = pd.concat([model_predict, predict], axis = 1)\n",
    "\n",
    "                if 'AdaBoost' in model_list:\n",
    "                    tree_param = {\n",
    "                        'base_estimator': DecisionTreeClassifier(\n",
    "                            max_depth = base_param[f'set{i}']['AdaBoost']['max_depth']\n",
    "                        )}\n",
    "                    boost_param = dict(\n",
    "                        (key, base_param[f'set{i}']['AdaBoost'][key]) for key in ['learning_rate', 'n_estimators']\n",
    "                    )\n",
    "                    boost_param.update(tree_param)\n",
    "                    clf = AdaBoostClassifier(**boost_param)\n",
    "                    clf.fit(train_x_dict[j], train_y_dict[j])\n",
    "                    predict_y = clf.predict_proba(valid_x_dict[j])\n",
    "                    predict = pd.DataFrame({'A': predict_y[:, 0]})\n",
    "                    model_predict = pd.concat([model_predict, predict], axis = 1)\n",
    "\n",
    "                if 'RandomForest' in model_list:\n",
    "                    clf = RandomForestClassifier(**base_param[f'set{i}']['RandomForest'])\n",
    "                    clf.fit(train_x_dict[j], train_y_dict[j])\n",
    "                    predict_y = clf.predict_proba(valid_x_dict[j])\n",
    "                    predict = pd.DataFrame({'R': predict_y[:, 0]})\n",
    "                    model_predict = pd.concat([model_predict, predict], axis = 1)\n",
    "\n",
    "                if 'ExtraTrees' in model_list:\n",
    "                    clf = ExtraTreesClassifier(**base_param[f'set{i}']['ExtraTrees'])\n",
    "                    clf.fit(train_x_dict[j], train_y_dict[j])\n",
    "                    predict_y = clf.predict_proba(valid_x_dict[j])\n",
    "                    predict = pd.DataFrame({'E': predict_y[:, 0]})\n",
    "                    model_predict = pd.concat([model_predict, predict], axis = 1)\n",
    "\n",
    "            elif mode == 'R':\n",
    "\n",
    "                if 'XGBoost' in model_list:\n",
    "                    reg = XGBRegressor(**base_param[f'set{i}']['XGBoost'], n_jobs = -1)\n",
    "                    reg.fit(train_x_dict[j], train_y_dict[j])\n",
    "                    predict_y = reg.predict(valid_x_dict[j])\n",
    "                    predict = pd.DataFrame({'X': predict_y})\n",
    "                    model_predict = pd.concat([model_predict, predict], axis = 1)\n",
    "\n",
    "                if 'LightGBM' in model_list:\n",
    "                    reg = LGBMRegressor(**base_param[f'set{i}']['LightGBM'])\n",
    "                    reg.fit(train_x_dict[j], train_y_dict[j])\n",
    "                    predict_y = reg.predict(valid_x_dict[j])\n",
    "                    predict = pd.DataFrame({'L': predict_y})\n",
    "                    model_predict = pd.concat([model_predict, predict], axis = 1)\n",
    "\n",
    "                if 'CatBoost' in model_list:\n",
    "                    reg = CatBoostRegressor(**base_param[f'set{i}']['CatBoost'])\n",
    "                    reg.fit(train_x_dict[j], train_y_dict[j])\n",
    "                    predict_y = reg.predict(valid_x_dict[j])\n",
    "                    predict = pd.DataFrame({'C': predict_y})\n",
    "                    model_predict = pd.concat([model_predict, predict], axis = 1)\n",
    "\n",
    "                if 'AdaBoost' in model_list:\n",
    "                    tree_param = {\n",
    "                        'base_estimator': DecisionTreeRegressor(\n",
    "                            max_depth = base_param[f'set{i}']['AdaBoost']['max_depth']\n",
    "                        )}\n",
    "                    boost_param = dict(\n",
    "                        (key, base_param[f'set{i}']['AdaBoost'][key]) for key in ['learning_rate', 'n_estimators']\n",
    "                    )\n",
    "                    boost_param.update(tree_param)\n",
    "                    reg = AdaBoostRegressor(**boost_param)\n",
    "                    reg.fit(train_x_dict[j], train_y_dict[j])\n",
    "                    predict_y = reg.predict(valid_x_dict[j])\n",
    "                    predict = pd.DataFrame({'A': predict_y})\n",
    "                    model_predict = pd.concat([model_predict, predict], axis = 1)\n",
    "\n",
    "                if 'RandomForest' in model_list:\n",
    "                    reg = RandomForestRegressor(**base_param[f'set{i}']['RandomForest'])\n",
    "                    reg.fit(train_x_dict[j], train_y_dict[j])\n",
    "                    predict_y = reg.predict(valid_x_dict[j])\n",
    "                    predict = pd.DataFrame({'R': predict_y})\n",
    "                    model_predict = pd.concat([model_predict, predict], axis = 1)\n",
    "\n",
    "                if 'ExtraTrees' in model_list:\n",
    "                    reg = ExtraTreesRegressor(**base_param[f'set{i}']['ExtraTrees'])\n",
    "                    reg.fit(train_x_dict[j], train_y_dict[j])\n",
    "                    predict_y = reg.predict(valid_x_dict[j])\n",
    "                    predict = pd.DataFrame({'E': predict_y})\n",
    "                    model_predict = pd.concat([model_predict, predict], axis = 1)\n",
    "\n",
    "            test_label = valid_y_dict[j].reset_index(drop = True)\n",
    "            done_cv = pd.concat([model_predict, test_label], axis = 1)\n",
    "            all_cv = pd.concat([all_cv, done_cv], axis = 0)\n",
    "\n",
    "        set_dict[f'set{i}'] = all_cv\n",
    "    \n",
    "    return set_dict\n",
    "\n",
    "\n",
    "def transform_test(train_data, test_data, mode, base_param):\n",
    "    \n",
    "    set_name = list(base_param.keys())\n",
    "    num_set = len(set_name)\n",
    "    model_list = list(base_param[set_name[0]].keys())\n",
    "    test_dict = {}\n",
    "    for i in tqdm(range(num_set)):\n",
    "        \n",
    "        print(f'Dataset {i}:\\n')\n",
    "        train_x, train_y, test_x, test_y = label_divide(train_data[f'set{i}'], test_data, train_only = False)\n",
    "        model_predict = pd.DataFrame()\n",
    "        if mode == 'C':\n",
    "\n",
    "            if 'XGBoost' in model_list:\n",
    "                clf = XGBClassifier(**base_param[f'set{i}']['XGBoost'], n_jobs = -1)\n",
    "                clf.fit(train_x, train_y)\n",
    "                predict_y = clf.predict_proba(test_x)\n",
    "                predict = pd.DataFrame({'X': predict_y[:, 0]})\n",
    "                model_predict = pd.concat([model_predict, predict], axis = 1)\n",
    "\n",
    "            if 'LightGBM' in model_list:\n",
    "                clf = LGBMClassifier(**base_param[f'set{i}']['LightGBM'])\n",
    "                clf.fit(train_x, train_y)\n",
    "                predict_y = clf.predict_proba(test_x)\n",
    "                predict = pd.DataFrame({'L': predict_y[:, 0]})\n",
    "                model_predict = pd.concat([model_predict, predict], axis = 1)\n",
    "\n",
    "            if 'CatBoost' in model_list:\n",
    "                clf = CatBoostClassifier(**base_param[f'set{i}']['CatBoost'])\n",
    "                clf.fit(train_x, train_y)\n",
    "                predict_y = clf.predict_proba(test_x)\n",
    "                predict = pd.DataFrame({'C': predict_y[:, 0]})\n",
    "                model_predict = pd.concat([model_predict, predict], axis = 1)\n",
    "\n",
    "            if 'AdaBoost' in model_list:\n",
    "                tree_param = {\n",
    "                    'base_estimator': DecisionTreeClassifier(\n",
    "                        max_depth = base_param[f'set{i}']['AdaBoost']['max_depth']\n",
    "                    )}\n",
    "                boost_param = dict(\n",
    "                    (key, base_param[f'set{i}']['AdaBoost'][key]) for key in ['learning_rate', 'n_estimators']\n",
    "                )\n",
    "                boost_param.update(tree_param)\n",
    "                clf = AdaBoostClassifier(**boost_param)\n",
    "                clf.fit(train_x, train_y)\n",
    "                predict_y = clf.predict_proba(test_x)\n",
    "                predict = pd.DataFrame({'A': predict_y[:, 0]})\n",
    "                model_predict = pd.concat([model_predict, predict], axis = 1)\n",
    "\n",
    "            if 'RandomForest' in model_list:\n",
    "                clf = RandomForestClassifier(**base_param[f'set{i}']['RandomForest'])\n",
    "                clf.fit(train_x, train_y)\n",
    "                predict_y = clf.predict_proba(test_x)\n",
    "                predict = pd.DataFrame({'R': predict_y[:, 0]})\n",
    "                model_predict = pd.concat([model_predict, predict], axis = 1)\n",
    "\n",
    "            if 'ExtraTrees' in model_list:\n",
    "                clf = ExtraTreesClassifier(**base_param[f'set{i}']['ExtraTrees'])\n",
    "                clf.fit(train_x, train_y)\n",
    "                predict_y = clf.predict_proba(test_x)\n",
    "                predict = pd.DataFrame({'E': predict_y[:, 0]})\n",
    "                model_predict = pd.concat([model_predict, predict], axis = 1)\n",
    "\n",
    "        elif mode == 'R':\n",
    "\n",
    "            if 'XGBoost' in model_list:\n",
    "                reg = XGBRegressor(**base_param[f'set{i}']['XGBoost'], n_jobs = -1)\n",
    "                reg.fit(train_x, train_y)\n",
    "                predict_y = reg.predict(test_x)\n",
    "                predict = pd.DataFrame({'X': predict_y})\n",
    "                model_predict = pd.concat([model_predict, predict], axis = 1)\n",
    "\n",
    "            if 'LightGBM' in model_list:\n",
    "                reg = LGBMRegressor(**base_param[f'set{i}']['LightGBM'])\n",
    "                reg.fit(train_x, train_y)\n",
    "                predict_y = reg.predict(test_x)\n",
    "                predict = pd.DataFrame({'L': predict_y})\n",
    "                model_predict = pd.concat([model_predict, predict], axis = 1)\n",
    "\n",
    "            if 'CatBoost' in model_list:\n",
    "                reg = CatBoostRegressor(**base_param[f'set{i}']['CatBoost'])\n",
    "                reg.fit(train_x, train_y)\n",
    "                predict_y = reg.predict(test_x)\n",
    "                predict = pd.DataFrame({'C': predict_y})\n",
    "                model_predict = pd.concat([model_predict, predict], axis = 1)\n",
    "\n",
    "            if 'AdaBoost' in model_list:\n",
    "                tree_param = {\n",
    "                    'base_estimator': DecisionTreeRegressor(\n",
    "                        max_depth = base_param[f'set{i}']['AdaBoost']['max_depth']\n",
    "                    )}\n",
    "                boost_param = dict(\n",
    "                    (key, base_param[f'set{i}']['AdaBoost'][key]) for key in ['learning_rate', 'n_estimators']\n",
    "                )\n",
    "                boost_param.update(tree_param)\n",
    "                reg = AdaBoostRegressor(**boost_param)\n",
    "                reg.fit(train_x, train_y)\n",
    "                predict_y = reg.predict(test_x)\n",
    "                predict = pd.DataFrame({'A': predict_y})\n",
    "                model_predict = pd.concat([model_predict, predict], axis = 1)\n",
    "\n",
    "            if 'RandomForest' in model_list:\n",
    "                reg = RandomForestRegressor(**base_param[f'set{i}']['RandomForest'])\n",
    "                reg.fit(train_x, train_y)\n",
    "                predict_y = reg.predict(test_x)\n",
    "                predict = pd.DataFrame({'R': predict_y})\n",
    "                model_predict = pd.concat([model_predict, predict], axis = 1)\n",
    "\n",
    "            if 'ExtraTrees' in model_list:\n",
    "                reg = ExtraTreesRegressor(**base_param[f'set{i}']['ExtraTrees'])\n",
    "                reg.fit(train_x, train_y)\n",
    "                predict_y = reg.predict(test_x)\n",
    "                predict = pd.DataFrame({'E': predict_y})\n",
    "                model_predict = pd.concat([model_predict, predict], axis = 1)\n",
    "\n",
    "        model_done = pd.concat([model_predict, test_y], axis = 1)\n",
    "        test_dict[f'set{i}'] = model_done\n",
    "        \n",
    "    return test_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### loading training data & testing data & hyperparameters generating from previous files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-22T12:48:16.350747Z",
     "start_time": "2021-11-22T12:48:12.443211Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "### training data ### \n",
    "training_month = range(1, 7)\n",
    "\n",
    "data_dict, trainset_x, trainset_y = multiple_month(training_month, num_set = 10, filename = 'dataset')\n",
    "\n",
    "print('\\nCombined training data:\\n')\n",
    "run_train = multiple_set(num_set = 10)\n",
    "run_train_x, run_train_y = train_set(run_train, num_set = 10)\n",
    "\n",
    "### testing data ###\n",
    "run_test = pd.read_csv('test_runhist.csv').iloc[:, 2:]\n",
    "run_test_x, run_test_y = label_divide(run_test, None, 'GB', train_only = True)\n",
    "print('\\n', 'Dimension of testing data:', run_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## base learner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-22T12:48:23.988839Z",
     "start_time": "2021-11-22T12:48:23.978865Z"
    }
   },
   "outputs": [],
   "source": [
    "##### loading hyperparameters #####\n",
    "hyper_info = {\n",
    "    'num_set': 10,\n",
    "    'date': '20211123',\n",
    "    'model_list': ['LightGBM', 'XGBoost', 'CatBoost', 'RandomForest'],\n",
    "    'iter_list': [200, 200, 200, 50],\n",
    "    'filename': 'runhist_array_m1m6_m7_3criteria',\n",
    "    'TPE_multi': True\n",
    "}\n",
    "\n",
    "base_paramC = load_hyper(**hyper_info, mode = 'C')\n",
    "\n",
    "# for i in base_paramC.keys():\n",
    "#     base_paramC[i]['NeuralNetwork'] = dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### data transform for scheme 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-22T13:18:15.903880Z",
     "start_time": "2021-11-22T12:48:42.290868Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_firstC = transform_train(run_train, mode = 'C', base_param = base_paramC, cv = 5)\n",
    "test_firstC = transform_test(run_train, run_test, mode = 'C', base_param = base_paramC)\n",
    "train_firstC_x, train_firstC_y = train_set(train_firstC, num_set = 10)\n",
    "test_firstC_x, test_firstC_y = train_set(test_firstC, num_set = 10) \n",
    "\n",
    "# train_firstR = transform_train(run_train, mode = 'R', base_param = base_paramR, cv = 5)\n",
    "# test_firstR = transform_test(run_train, run_test, mode = 'R', base_param = base_paramR)\n",
    "# train_firstR_x, train_firstR_y = train_set(train_firstR, num_set = 10)\n",
    "# test_firstR_x, test_firstR_y = train_set(test_firstR, num_set = 10) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## meta learner"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### searching for best hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-22T13:19:12.354546Z",
     "start_time": "2021-11-22T13:18:25.608192Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "best_paramC, _ = all_optuna(num_set = 10, \n",
    "                            all_data = train_firstC, \n",
    "                            mode = 'C', \n",
    "                            TPE_multi = False, \n",
    "                            n_iter = 10,\n",
    "                            filename = f'runhist_array_4criteria_m2m5_StackingCV1',\n",
    "                            creator = stackingCV_creator\n",
    ")\n",
    "\n",
    "# best_paramR, _ = all_optuna(num_set = 10, \n",
    "#                             all_data = train_firstR, \n",
    "#                             mode = 'R', \n",
    "#                             TPE_multi = True, \n",
    "#                             n_iter = 10,\n",
    "#                             filename = f'runhist_array_4criteria_m2m5_StackingCV1',\n",
    "#                             creator = stackingCV_creator\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### feature selection by feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-22T13:19:55.766827Z",
     "start_time": "2021-11-22T13:19:41.872794Z"
    }
   },
   "outputs": [],
   "source": [
    "rank_importance(train_firstC['set7'], mode = 'C')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-22T13:19:58.480114Z",
     "start_time": "2021-11-22T13:19:57.669304Z"
    }
   },
   "outputs": [],
   "source": [
    "table_setC, coefC = runall_LR(10, train_firstC_x, test_firstC_x, train_firstC_y, test_firstC_y, best_paramC)\n",
    "line_chart(table_setC, title = 'StackingCV Classifier (scheme 1)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-22T13:20:00.426934Z",
     "start_time": "2021-11-22T13:20:00.413002Z"
    }
   },
   "outputs": [],
   "source": [
    "table_setC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-16T07:25:34.121202Z",
     "start_time": "2021-10-16T07:25:33.174919Z"
    }
   },
   "outputs": [],
   "source": [
    "pr_dict, table_setR, coefR = runall_RidgeR(10, train_firstR_x, test_firstR_x, train_firstR_y, test_firstR_y, \n",
    "                                           best_paramR, thres_target = 'Recall', threshold = 0.7)\n",
    "line_chart(table_setR, title = 'StackingCV Regressor (scheme 1)')\n",
    "multiple_curve(4, 3, pr_dict, table_setR, target = 'Aging Rate')\n",
    "multiple_curve(4, 3, pr_dict, table_setR, target = 'Precision')\n",
    "print(coefR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-20T08:59:06.227321Z",
     "start_time": "2021-11-20T08:59:06.165446Z"
    }
   },
   "outputs": [],
   "source": [
    "savedate = '20211123'\n",
    "TPE_multi = True\n",
    "\n",
    "table_setC['sampler'] = 'multivariate-TPE' if TPE_multi else 'univariate-TPE'\n",
    "table_setC['model'] = 'StackingCV 1'\n",
    "with pd.ExcelWriter(f'{savedate}_Classifier.xlsx', mode = 'a') as writer:\n",
    "    table_setC.to_excel(writer, sheet_name = 'StackingCV_1')"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python [conda env:aging]",
   "language": "python",
   "name": "conda-env-aging-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
