{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-05T08:50:32.116748Z",
     "start_time": "2021-12-05T08:50:28.139005Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\user\\\\Desktop\\\\Darui_R08621110'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression, Ridge\n",
    "from sklearn.ensemble import ExtraTreesClassifier, ExtraTreesRegressor, RandomForestClassifier, RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from catboost import CatBoostClassifier, CatBoostRegressor\n",
    "from lightgbm import LGBMClassifier, LGBMRegressor\n",
    "from xgboost import XGBClassifier, XGBRegressor\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "import optuna\n",
    "\n",
    "from library.Data_Preprocessing import Balance_Ratio, train_col\n",
    "from library.Imbalance_Sampling import label_divide\n",
    "from library.Aging_Score_Contour import score1\n",
    "from library.AdaBoost import train_set, multiple_set, multiple_month, line_chart, cf_matrix, AUC, PR_curve, \\\n",
    "     multiple_curve, PR_matrix, best_threshold, all_optuna, optuna_history\n",
    "from library.XGBoost import XGBoost_creator\n",
    "from library.LightGBM import LightGBM_creator\n",
    "from library.CatBoost import CatBoost_creator\n",
    "from library.Random_Forest import RandomForest_creator\n",
    "from library.Extra_Trees import ExtraTrees_creator\n",
    "from library.Neural_Network import RunhistSet, NeuralNetworkC, trainingC\n",
    "from library.StackingCV_Scheme3 import optimize_base, stratified_data, runall_LR, runall_RidgeR, stackingCV_creator, \\\n",
    "    correlation_plot, vif, rank_importance, month_param\n",
    "\n",
    "os.chdir('C:/Users/user/Desktop/Darui_R08621110')  \n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### transform data by base learner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-05T08:50:32.238422Z",
     "start_time": "2021-12-05T08:50:32.193542Z"
    }
   },
   "outputs": [],
   "source": [
    "def transform_train(train_data, mode, base_param, cv):\n",
    "    \n",
    "    num_set = len(train_data.keys())\n",
    "    month_list = list(base_param.keys())\n",
    "    model_list = list(base_param[month_list[0]].keys())\n",
    "    set_dict = {} \n",
    "    for i in tqdm(range(num_set)):\n",
    "        \n",
    "        train_x_dict, train_y_dict, valid_x_dict, valid_y_dict = stratified_data(train_data[f'set{i}'], cv = cv)\n",
    "        all_month = pd.DataFrame()\n",
    "        for month in tqdm(month_list):    \n",
    "            \n",
    "            all_cv = pd.DataFrame()\n",
    "            for j in range(cv):\n",
    "                \n",
    "                model_predict = pd.DataFrame()\n",
    "                if mode == 'C':\n",
    "\n",
    "                    if 'NeuralNetwork' in model_list:\n",
    "                        temp_train = RunhistSet(train_x_dict[j], train_y_dict[j])\n",
    "                        temp_valid = RunhistSet(valid_x_dict[j], valid_y_dict[j])\n",
    "                        train_loader = DataLoader(temp_train, \n",
    "                                                  batch_size = base_param[month]['NeuralNetwork'][f'set{i}']['batch_size'], \n",
    "                                                  shuffle = True)\n",
    "                        valid_loader = DataLoader(temp_valid, batch_size = len(valid_x_dict[j]), shuffle = False)\n",
    "                        nn_model = NeuralNetworkC(dim = train_x_dict[j].shape[1])\n",
    "                        optimizer = torch.optim.Adam(nn_model.parameters(), \n",
    "                                                     lr = base_param[month]['NeuralNetwork'][f'set{i}']['learning_rate'], \n",
    "                                                     weight_decay = base_param[month]['NeuralNetwork'][f'set{i}']['weight_decay'])\n",
    "                        criterion = nn.CrossEntropyLoss(\n",
    "                            weight = torch.tensor([1-base_param[month]['NeuralNetwork'][f'set{i}']['bad_weight'], \n",
    "                                                   base_param[month]['NeuralNetwork'][f'set{i}']['bad_weight']])).to('cpu')\n",
    "                        network, _, _ = trainingC(nn_model, train_loader, train_loader, optimizer, criterion, epoch = 100, \n",
    "                                                  filename = 'none', early_stop = 10)\n",
    "                        for x, y in valid_loader:\n",
    "                            output = network(x)\n",
    "                            _, predict_y = torch.max(output.data, 1)\n",
    "                        predict = pd.DataFrame({f'N_{month}': predict_y.numpy()})\n",
    "                        model_predict = pd.concat([model_predict, predict], axis = 1)\n",
    "                    \n",
    "                    if 'XGBoost' in model_list:                     \n",
    "                        clf = XGBClassifier(**base_param[month]['XGBoost'][f'set{i}'], n_jobs = -1)\n",
    "                        clf.fit(train_x_dict[j], train_y_dict[j])\n",
    "                        predict_y = clf.predict_proba(valid_x_dict[j])\n",
    "                        predict = pd.DataFrame({f'X_{month}': predict_y[:, 0]})\n",
    "                        model_predict = pd.concat([model_predict, predict], axis = 1)\n",
    "\n",
    "                    if 'LightGBM' in model_list:                        \n",
    "                        clf = LGBMClassifier(**base_param[month]['LightGBM'][f'set{i}'])\n",
    "                        clf.fit(train_x_dict[j], train_y_dict[j])\n",
    "                        predict_y = clf.predict_proba(valid_x_dict[j])\n",
    "                        predict = pd.DataFrame({f'L_{month}': predict_y[:, 0]})\n",
    "                        model_predict = pd.concat([model_predict, predict], axis = 1)\n",
    "                        \n",
    "                    if 'CatBoost' in model_list:\n",
    "                        clf = CatBoostClassifier(**base_param[month]['CatBoost'][f'set{i}'])\n",
    "                        clf.fit(train_x_dict[j], train_y_dict[j])\n",
    "                        predict_y = clf.predict_proba(valid_x_dict[j])\n",
    "                        predict = pd.DataFrame({f'C_{month}': predict_y[:, 0]})\n",
    "                        model_predict = pd.concat([model_predict, predict], axis = 1)\n",
    "                        \n",
    "                    if 'RandomForest' in model_list:\n",
    "                        clf = RandomForestClassifier(**base_param[month]['RandomForest'][f'set{i}'])\n",
    "                        clf.fit(train_x_dict[j], train_y_dict[j])\n",
    "                        predict_y = clf.predict_proba(valid_x_dict[j])\n",
    "                        predict = pd.DataFrame({f'R_{month}': predict_y[:, 0]})\n",
    "                        model_predict = pd.concat([model_predict, predict], axis = 1)\n",
    "                        \n",
    "                    if 'ExtraTrees' in model_list:\n",
    "                        clf = ExtraTreesClassifier(**base_param[month]['ExtraTrees'][f'set{i}'])\n",
    "                        clf.fit(train_x_dict[j], train_y_dict[j])\n",
    "                        predict_y = clf.predict_proba(valid_x_dict[j])\n",
    "                        predict = pd.DataFrame({f'E_{month}': predict_y[:, 0]})\n",
    "                        model_predict = pd.concat([model_predict, predict], axis = 1)\n",
    "                        \n",
    "                elif mode == 'R':\n",
    "                    \n",
    "                    if 'XGBoost' in model_list:\n",
    "                        reg = XGBRegressor(**base_param[month]['XGBoost'][f'set{i}'], n_jobs = -1)\n",
    "                        reg.fit(train_x_dict[j], train_y_dict[j])\n",
    "                        predict_y = reg.predict(valid_x_dict[j])\n",
    "                        predict = pd.DataFrame({f'X_{month}': predict_y})\n",
    "                        model_predict = pd.concat([model_predict, predict], axis = 1)\n",
    "\n",
    "                    if 'LightGBM' in model_list:\n",
    "                        reg = LGBMRegressor(**base_param[month]['LightGBM'][f'set{i}'])\n",
    "                        reg.fit(train_x_dict[j], train_y_dict[j])\n",
    "                        predict_y = reg.predict(valid_x_dict[j])\n",
    "                        predict = pd.DataFrame({f'L_{month}': predict_y})\n",
    "                        model_predict = pd.concat([model_predict, predict], axis = 1)\n",
    "                        \n",
    "                    if 'CatBoost' in model_list:\n",
    "                        reg = CatBoostRegressor(**base_param[month]['CatBoost'][f'set{i}'])\n",
    "                        reg.fit(train_x_dict[j], train_y_dict[j])\n",
    "                        predict_y = reg.predict(valid_x_dict[j])\n",
    "                        predict = pd.DataFrame({f'C_{month}': predict_y})\n",
    "                        model_predict = pd.concat([model_predict, predict], axis = 1)\n",
    "                        \n",
    "                    if 'RandomForest' in model_list:\n",
    "                        reg = RandomForestRegressor(**base_param[month]['RandomForest'][f'set{i}'])\n",
    "                        reg.fit(train_x_dict[j], train_y_dict[j])\n",
    "                        predict_y = reg.predict(valid_x_dict[j])\n",
    "                        predict = pd.DataFrame({f'R_{month}': predict_y})\n",
    "                        model_predict = pd.concat([model_predict, predict], axis = 1)\n",
    "                    \n",
    "                    if 'ExtraTrees' in model_list:\n",
    "                        reg = ExtraTreesRegressor(**base_param[month]['ExtraTrees'][f'set{i}'])\n",
    "                        reg.fit(train_x_dict[j], train_y_dict[j])\n",
    "                        predict_y = reg.predict(valid_x_dict[j])\n",
    "                        predict = pd.DataFrame({f'E_{month}': predict_y})\n",
    "                        model_predict = pd.concat([model_predict, predict], axis = 1)\n",
    "                        \n",
    "                test_label = valid_y_dict[j].reset_index(drop = True)\n",
    "                done_cv = pd.concat([model_predict, test_label], axis = 1)\n",
    "                all_cv = pd.concat([all_cv, done_cv], axis = 0)                \n",
    "        \n",
    "            all_month = pd.concat([all_month, all_cv], axis = 1)\n",
    "            if month != month_list[-1]:\n",
    "                all_month = all_month.drop(columns = 'GB')\n",
    "        \n",
    "        set_dict[f'set{i}'] = all_month\n",
    "    \n",
    "    return set_dict\n",
    "\n",
    "\n",
    "def transform_test(train_data, test_data, mode, base_param):\n",
    "    \n",
    "    month_list = list(base_param.keys())\n",
    "    model_list = list(base_param[month_list[0]].keys())\n",
    "    num_set = len(train_data[month_list[0]].keys())\n",
    "    test_dict = {}\n",
    "    for i in tqdm(range(num_set)):\n",
    "        \n",
    "        month_test = pd.DataFrame()\n",
    "        for month in tqdm(month_list):\n",
    "            \n",
    "            select_test = train_col(train_data[month][f'set{i}'], test_data)\n",
    "            train_x, train_y, test_x, test_y = label_divide(train_data[month][f'set{i}'], select_test, train_only = False)\n",
    "            model_predict = pd.DataFrame()\n",
    "            if mode == 'C':\n",
    "\n",
    "                if 'NeuralNetwork' in model_list:\n",
    "                    temp_train = RunhistSet(train_x, train_y)\n",
    "                    temp_test = RunhistSet(test_x, test_y)\n",
    "                    train_loader = DataLoader(temp_train, \n",
    "                                              batch_size = base_param[month]['NeuralNetwork'][f'set{i}']['batch_size'], \n",
    "                                              shuffle = True)\n",
    "                    test_loader = DataLoader(temp_test, batch_size = len(test_x), shuffle = False)\n",
    "                    nn_model = NeuralNetworkC(dim = train_x.shape[1])\n",
    "                    optimizer = torch.optim.Adam(nn_model.parameters(), \n",
    "                                                 lr = base_param[month]['NeuralNetwork'][f'set{i}']['learning_rate'], \n",
    "                                                 weight_decay = base_param[month]['NeuralNetwork'][f'set{i}']['weight_decay'])\n",
    "                    criterion = nn.CrossEntropyLoss(\n",
    "                        weight = torch.tensor([1-base_param[month]['NeuralNetwork'][f'set{i}']['bad_weight'], \n",
    "                                               base_param[month]['NeuralNetwork'][f'set{i}']['bad_weight']])).to('cpu')\n",
    "                    network, _, _ = trainingC(nn_model, train_loader, train_loader, optimizer, criterion, epoch = 100, \n",
    "                                              filename = 'none', early_stop = 10)\n",
    "                    for X, Y in test_loader:\n",
    "                        X, Y = X.float(), Y.long()\n",
    "                        output = network(X)\n",
    "                        _, predict_y = torch.max(output.data, 1)\n",
    "                    predict = pd.DataFrame({f'N_{month}': predict_y.numpy()})\n",
    "                    model_predict = pd.concat([model_predict, predict], axis = 1)\n",
    "                \n",
    "                if 'XGBoost' in model_list:\n",
    "                    clf = XGBClassifier(**base_param[month]['XGBoost'][f'set{i}'], n_jobs = -1)\n",
    "                    clf.fit(train_x, train_y)\n",
    "                    predict_y = clf.predict_proba(test_x)\n",
    "                    predict = pd.DataFrame({f'X_{month}': predict_y[:, 0]})\n",
    "                    model_predict = pd.concat([model_predict, predict], axis = 1)\n",
    "\n",
    "                if 'LightGBM' in model_list:\n",
    "                    clf = LGBMClassifier(**base_param[month]['LightGBM'][f'set{i}'])\n",
    "                    clf.fit(train_x, train_y)\n",
    "                    predict_y = clf.predict_proba(test_x)\n",
    "                    predict = pd.DataFrame({f'L_{month}': predict_y[:, 0]})\n",
    "                    model_predict = pd.concat([model_predict, predict], axis = 1)\n",
    "\n",
    "                if 'CatBoost' in model_list:\n",
    "                    clf = CatBoostClassifier(**base_param[month]['CatBoost'][f'set{i}'])\n",
    "                    clf.fit(train_x, train_y)\n",
    "                    predict_y = clf.predict_proba(test_x)\n",
    "                    predict = pd.DataFrame({f'C_{month}': predict_y[:, 0]})\n",
    "                    model_predict = pd.concat([model_predict, predict], axis = 1)\n",
    "\n",
    "                if 'RandomForest' in model_list:\n",
    "                    clf = RandomForestClassifier(**base_param[month]['RandomForest'][f'set{i}'])\n",
    "                    clf.fit(train_x, train_y)\n",
    "                    predict_y = clf.predict_proba(test_x)\n",
    "                    predict = pd.DataFrame({f'R_{month}': predict_y[:, 0]})\n",
    "                    model_predict = pd.concat([model_predict, predict], axis = 1)\n",
    "\n",
    "                if 'ExtraTrees' in model_list:\n",
    "                    clf = ExtraTreesClassifier(**base_param[month]['ExtraTrees'][f'set{i}'])\n",
    "                    clf.fit(train_x, train_y)\n",
    "                    predict_y = clf.predict_proba(test_x)\n",
    "                    predict = pd.DataFrame({f'E_{month}': predict_y[:, 0]})\n",
    "                    model_predict = pd.concat([model_predict, predict], axis = 1)\n",
    "\n",
    "            elif mode == 'R':\n",
    "\n",
    "                if 'XGBoost' in model_list:\n",
    "                    reg = XGBRegressor(**base_param[month]['XGBoost'][f'set{i}'], n_jobs = -1)\n",
    "                    reg.fit(train_x, train_y)\n",
    "                    predict_y = reg.predict(test_x)\n",
    "                    predict = pd.DataFrame({f'X_{month}': predict_y})\n",
    "                    model_predict = pd.concat([model_predict, predict], axis = 1)\n",
    "\n",
    "                if 'LightGBM' in model_list:\n",
    "                    reg = LGBMRegressor(**base_param[month]['LightGBM'][f'set{i}'])\n",
    "                    reg.fit(train_x, train_y)\n",
    "                    predict_y = reg.predict(test_x)\n",
    "                    predict = pd.DataFrame({f'L_{month}': predict_y})\n",
    "                    model_predict = pd.concat([model_predict, predict], axis = 1)\n",
    "\n",
    "                if 'CatBoost' in model_list:\n",
    "                    reg = CatBoostRegressor(**base_param[month]['CatBoost'][f'set{i}'])\n",
    "                    reg.fit(train_x, train_y)\n",
    "                    predict_y = reg.predict(test_x)\n",
    "                    predict = pd.DataFrame({f'C_{month}': predict_y})\n",
    "                    model_predict = pd.concat([model_predict, predict], axis = 1)\n",
    "\n",
    "                if 'RandomForest' in model_list:\n",
    "                    reg = RandomForestRegressor(**base_param[month]['RandomForest'][f'set{i}'])\n",
    "                    reg.fit(train_x, train_y)\n",
    "                    predict_y = reg.predict(test_x)\n",
    "                    predict = pd.DataFrame({f'R_{month}': predict_y})\n",
    "                    model_predict = pd.concat([model_predict, predict], axis = 1)\n",
    "\n",
    "                if 'ExtraTrees' in model_list:\n",
    "                    reg = ExtraTreesRegressor(**base_param[month]['ExtraTrees'][f'set{i}'])\n",
    "                    reg.fit(train_x, train_y)\n",
    "                    predict_y = reg.predict(test_x)\n",
    "                    predict = pd.DataFrame({f'E_{month}': predict_y})\n",
    "                    model_predict = pd.concat([model_predict, predict], axis = 1)\n",
    "\n",
    "            month_test = pd.concat([month_test, model_predict], axis = 1)\n",
    "        month_done = pd.concat([month_test, test_y], axis = 1)\n",
    "        test_dict[f'set{i}'] = month_done\n",
    "        \n",
    "    return test_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-05T08:50:34.892329Z",
     "start_time": "2021-12-05T08:50:32.317212Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Month 2:\n",
      "\n",
      "Dimension of dataset 0 : (39009, 85)  balance ratio: 590.0\n",
      "Dimension of dataset 1 : (1296, 85)  balance ratio: 1.0\n",
      "Dimension of dataset 2 : (2034, 85)  balance ratio: 1.0\n",
      "Dimension of dataset 3 : (1448, 85)  balance ratio: 1.0\n",
      "Dimension of dataset 4 : (1320, 85)  balance ratio: 1.0\n",
      "Dimension of dataset 5 : (1310, 85)  balance ratio: 1.0\n",
      "Dimension of dataset 6 : (1326, 85)  balance ratio: 1.0\n",
      "Dimension of dataset 7 : (1320, 85)  balance ratio: 1.0\n",
      "Dimension of dataset 8 : (1320, 85)  balance ratio: 1.0\n",
      "Dimension of dataset 9 : (726, 85)  balance ratio: 10.0\n",
      "\n",
      " 10 datasets are loaded.\n",
      "\n",
      "Labels of  10 datasets are divided.\n",
      "\n",
      "Month 3:\n",
      "\n",
      "Dimension of dataset 0 : (60396, 101)  balance ratio: 574.0\n",
      "Dimension of dataset 1 : (2088, 101)  balance ratio: 1.0\n",
      "Dimension of dataset 2 : (2568, 101)  balance ratio: 1.0\n",
      "Dimension of dataset 3 : (2306, 101)  balance ratio: 1.0\n",
      "Dimension of dataset 4 : (2100, 101)  balance ratio: 1.0\n",
      "Dimension of dataset 5 : (2101, 101)  balance ratio: 1.0\n",
      "Dimension of dataset 6 : (2325, 101)  balance ratio: 1.0\n",
      "Dimension of dataset 7 : (2100, 101)  balance ratio: 1.0\n",
      "Dimension of dataset 8 : (2100, 101)  balance ratio: 1.0\n",
      "Dimension of dataset 9 : (1155, 101)  balance ratio: 10.0\n",
      "\n",
      " 10 datasets are loaded.\n",
      "\n",
      "Labels of  10 datasets are divided.\n",
      "\n",
      "Month 4:\n",
      "\n",
      "Dimension of dataset 0 : (57743, 103)  balance ratio: 524.0\n",
      "Dimension of dataset 1 : (2132, 103)  balance ratio: 1.0\n",
      "Dimension of dataset 2 : (2948, 103)  balance ratio: 1.0\n",
      "Dimension of dataset 3 : (2414, 103)  balance ratio: 1.0\n",
      "Dimension of dataset 4 : (2198, 103)  balance ratio: 1.0\n",
      "Dimension of dataset 5 : (2183, 103)  balance ratio: 1.0\n",
      "Dimension of dataset 6 : (2585, 103)  balance ratio: 1.0\n",
      "Dimension of dataset 7 : (2200, 103)  balance ratio: 1.0\n",
      "Dimension of dataset 8 : (2200, 103)  balance ratio: 1.0\n",
      "Dimension of dataset 9 : (1210, 103)  balance ratio: 10.0\n",
      "\n",
      " 10 datasets are loaded.\n",
      "\n",
      "Labels of  10 datasets are divided.\n",
      "\n",
      "Combined training data:\n",
      "\n",
      "Dimension of dataset 0 : (157148, 125)  balance ratio: 558.0\n",
      "Dimension of dataset 1 : (5516, 125)  balance ratio: 1.0\n",
      "Dimension of dataset 2 : (7550, 125)  balance ratio: 1.0\n",
      "Dimension of dataset 3 : (6168, 125)  balance ratio: 1.0\n",
      "Dimension of dataset 4 : (5618, 125)  balance ratio: 1.0\n",
      "Dimension of dataset 5 : (5594, 125)  balance ratio: 1.0\n",
      "Dimension of dataset 6 : (6236, 125)  balance ratio: 1.0\n",
      "Dimension of dataset 7 : (5620, 125)  balance ratio: 1.0\n",
      "Dimension of dataset 8 : (5620, 125)  balance ratio: 1.0\n",
      "Dimension of dataset 9 : (3091, 125)  balance ratio: 10.0\n",
      "\n",
      " 10 datasets are loaded.\n",
      "\n",
      "Labels of  10 datasets are divided.\n",
      "\n",
      " Dimension of testing data: (48649, 129)\n"
     ]
    }
   ],
   "source": [
    "### training data ### \n",
    "training_month = range(2, 5)\n",
    "\n",
    "data_dict, trainset_x, trainset_y = multiple_month(training_month, num_set = 10, filename = 'dataset')\n",
    "\n",
    "print('\\nCombined training data:\\n')\n",
    "run_train = multiple_set(num_set = 10)\n",
    "run_train_x, run_train_y = train_set(run_train)\n",
    "\n",
    "### testing data ###\n",
    "run_test = pd.read_csv('test_runhist.csv').iloc[:, 2:]\n",
    "run_test_x, run_test_y = label_divide(run_test, None, 'GB', train_only = True)\n",
    "print('\\n', 'Dimension of testing data:', run_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Base Learner"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training & Testing Data Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_month = range(2, 5)\n",
    "target_model = ['NeuralNetwork', 'LightGBM']\n",
    "target_iter = {'NeuralNetwork': 10, 'LightGBM': 25}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-26T17:03:03.727638Z",
     "start_time": "2021-11-26T15:59:26.569284Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "##### datasets are optimized by by optuna ##### \n",
    "base_param_monthC = optimize_base(train_data = data_dict, \n",
    "                                  mode = 'C', \n",
    "                                  TPE_multi = False, \n",
    "                                  base_list = target_model,\n",
    "                                  iter_dict = target_iter,\n",
    "                                  filename = 'runhist_array_m2m4_m5_3criteria')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-05T08:50:43.146696Z",
     "start_time": "2021-12-05T08:50:43.141709Z"
    }
   },
   "outputs": [],
   "source": [
    "##### or load hyperparmeters of base learner from stackingCV scheme 3 #####\n",
    "base_param_monthC = month_param(date = '20220308', \n",
    "                                month_list = list(target_month), \n",
    "                                model_list = target_model, \n",
    "                                iter_dict = target_iter, \n",
    "                                filename = 'runhist_array_m2m4_m5_3criteria', \n",
    "                                mode = 'C', \n",
    "                                TPE_multi = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-05T10:23:47.046717Z",
     "start_time": "2021-12-05T08:50:57.561572Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ee4a38aa3e04a6eb0ac4ef4c1ee35a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a82574a0b73547f3961998158e263e90",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c99c014c8e6493ab27210d219809b82",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss = 0.023261250799307635, Recall = 0.0, Aging Rate = 3.181698868110628e-05, Precision = 0.0, f1 = 0\n",
      "Epoch 2: Train Loss = 0.021247629770709535, Recall = 0.0, Aging Rate = 0.0, Precision = 0, f1 = 0\n",
      "Epoch 3: Train Loss = 0.018896186811615485, Recall = 0.0, Aging Rate = 0.0, Precision = 0, f1 = 0\n",
      "Epoch 4: Train Loss = 0.019348240214265976, Recall = 0.0, Aging Rate = 0.0, Precision = 0, f1 = 0\n",
      "Epoch 5: Train Loss = 0.020277615143347836, Recall = 0.0, Aging Rate = 0.0, Precision = 0, f1 = 0\n",
      "Test Loss = 0.01835290010403942, Recall = 0.0, Aging Rate = 0.0, precision = 0\n",
      "\n",
      "Epoch 6: Train Loss = 0.019478723718295766, Recall = 0.0, Aging Rate = 0.0, Precision = 0, f1 = 0\n",
      "Epoch 7: Train Loss = 0.019830982610747463, Recall = 0.0, Aging Rate = 0.0, Precision = 0, f1 = 0\n",
      "Epoch 8: Train Loss = 0.020221016665215356, Recall = 0.0, Aging Rate = 0.0, Precision = 0, f1 = 0\n",
      "Epoch 9: Train Loss = 0.020119799169704113, Recall = 0.0, Aging Rate = 0.0, Precision = 0, f1 = 0\n",
      "Epoch 10: Train Loss = 0.01904328344804068, Recall = 0.0, Aging Rate = 0.0, Precision = 0, f1 = 0\n",
      "Test Loss = 0.01957854552457148, Recall = 0.0, Aging Rate = 0.0, precision = 0\n",
      "\n",
      "Epoch 11: Train Loss = 0.01914023181118616, Recall = 0.0, Aging Rate = 0.0, Precision = 0, f1 = 0\n",
      "Epoch 12: Train Loss = 0.01918217940059774, Recall = 0.0, Aging Rate = 0.0, Precision = 0, f1 = 0\n",
      "Epoch 13: Train Loss = 0.01905540602683466, Recall = 0.0, Aging Rate = 0.0, Precision = 0, f1 = 0\n",
      "Epoch 14: Train Loss = 0.019363319577625413, Recall = 0.0, Aging Rate = 0.0, Precision = 0, f1 = 0\n",
      "Epoch 15: Train Loss = 0.01929915706561088, Recall = 0.0, Aging Rate = 0.0, Precision = 0, f1 = 0\n",
      "Test Loss = 0.017931789822013957, Recall = 0.0, Aging Rate = 0.0, precision = 0\n",
      "\n",
      "Epoch 16: Train Loss = 0.01934776926567613, Recall = 0.0, Aging Rate = 0.0, Precision = 0, f1 = 0\n",
      "Epoch 17: Train Loss = 0.01944880682637594, Recall = 0.0, Aging Rate = 0.0, Precision = 0, f1 = 0\n",
      "Epoch 18: Train Loss = 0.019969449417707397, Recall = 0.0, Aging Rate = 0.0, Precision = 0, f1 = 0\n",
      "Epoch 19: Train Loss = 0.01918973353251663, Recall = 0.0, Aging Rate = 0.0, Precision = 0, f1 = 0\n",
      "Epoch 20: Train Loss = 0.020328630082063377, Recall = 0.0, Aging Rate = 0.0, Precision = 0, f1 = 0\n",
      "Test Loss = 0.0181552934815843, Recall = 0.0, Aging Rate = 0.0, precision = 0\n",
      "\n",
      "Epoch 21: Train Loss = 0.01950384464529868, Recall = 0.0, Aging Rate = 0.0, Precision = 0, f1 = 0\n",
      "Epoch 22: Train Loss = 0.01890717998362123, Recall = 0.0, Aging Rate = 0.0, Precision = 0, f1 = 0\n",
      "Epoch 23: Train Loss = 0.018985296446501133, Recall = 0.0, Aging Rate = 7.95424717027657e-06, Precision = 0.0, f1 = 0\n",
      "Epoch 24: Train Loss = 0.01904172702966938, Recall = 0.0, Aging Rate = 0.0, Precision = 0, f1 = 0\n",
      "Epoch 25: Train Loss = 0.01938433765964039, Recall = 0.0, Aging Rate = 0.0, Precision = 0, f1 = 0\n",
      "Test Loss = 0.01779592017946132, Recall = 0.0, Aging Rate = 0.0, precision = 0\n",
      "\n",
      "Epoch 26: Train Loss = 0.018945660601000145, Recall = 0.0, Aging Rate = 0.0, Precision = 0, f1 = 0\n",
      "Epoch 27: Train Loss = 0.01962158444787776, Recall = 0.0, Aging Rate = 0.0, Precision = 0, f1 = 0\n",
      "Epoch 28: Train Loss = 0.01904504223250418, Recall = 0.0, Aging Rate = 0.0, Precision = 0, f1 = 0\n",
      "Epoch 29: Train Loss = 0.01932386162874265, Recall = 0.0, Aging Rate = 0.0, Precision = 0, f1 = 0\n",
      "Epoch 30: Train Loss = 0.019593814950385206, Recall = 0.0, Aging Rate = 0.0, Precision = 0, f1 = 0\n",
      "Test Loss = 0.017979272453066148, Recall = 0.0, Aging Rate = 0.0, precision = 0\n",
      "\n",
      "Epoch 31: Train Loss = 0.019685126642451364, Recall = 0.0, Aging Rate = 0.0, Precision = 0, f1 = 0\n",
      "Epoch 32: Train Loss = 0.01906339548907849, Recall = 0.0, Aging Rate = 0.0, Precision = 0, f1 = 0\n",
      "Epoch 33: Train Loss = 0.0193766467091619, Recall = 0.0, Aging Rate = 0.0, Precision = 0, f1 = 0\n",
      "Epoch 34: Train Loss = 0.01914755553227703, Recall = 0.0, Aging Rate = 0.0, Precision = 0, f1 = 0\n",
      "Epoch 35: Train Loss = 0.020079282964741832, Recall = 0.0, Aging Rate = 1.590849434055314e-05, Precision = 0.0, f1 = 0\n",
      "Test Loss = 0.017805114506289643, Recall = 0.0, Aging Rate = 0.0, precision = 0\n",
      "\n",
      "Epoch 36: Train Loss = 0.01937843101294033, Recall = 0.0, Aging Rate = 0.0, Precision = 0, f1 = 0\n",
      "Epoch 37: Train Loss = 0.018765748625781595, Recall = 0.0, Aging Rate = 7.95424717027657e-06, Precision = 0.0, f1 = 0\n",
      "Epoch 38: Train Loss = 0.018844702500682847, Recall = 0.0, Aging Rate = 0.0, Precision = 0, f1 = 0\n",
      "Epoch 39: Train Loss = 0.019162032346825016, Recall = 0.0, Aging Rate = 7.95424717027657e-06, Precision = 0.0, f1 = 0\n",
      "Epoch 40: Train Loss = 0.0187413368228144, Recall = 0.0044444444444444444, Aging Rate = 2.3862741510829707e-05, Precision = 0.3333333333333333, f1 = 0.008771929824561405\n",
      "Test Loss = 0.017371545615964, Recall = 0.0, Aging Rate = 0.0, precision = 0\n",
      "\n",
      "Epoch 41: Train Loss = 0.018806886364496726, Recall = 0.0, Aging Rate = 1.590849434055314e-05, Precision = 0.0, f1 = 0\n",
      "Epoch 42: Train Loss = 0.019137523566566582, Recall = 0.008888888888888889, Aging Rate = 3.181698868110628e-05, Precision = 0.5, f1 = 0.017467248908296946\n",
      "Epoch 43: Train Loss = 0.019192385879747847, Recall = 0.0, Aging Rate = 0.0, Precision = 0, f1 = 0\n",
      "Epoch 44: Train Loss = 0.019213920009747452, Recall = 0.013333333333333334, Aging Rate = 3.181698868110628e-05, Precision = 0.75, f1 = 0.026200873362445417\n",
      "Epoch 45: Train Loss = 0.018524640998518006, Recall = 0.017777777777777778, Aging Rate = 3.9771235851382846e-05, Precision = 0.8, f1 = 0.034782608695652174\n",
      "Test Loss = 0.01738022357863437, Recall = 0.0, Aging Rate = 0.0, precision = 0\n",
      "\n",
      "Epoch 46: Train Loss = 0.019350822345687854, Recall = 0.0044444444444444444, Aging Rate = 2.3862741510829707e-05, Precision = 0.3333333333333333, f1 = 0.008771929824561405\n",
      "Epoch 47: Train Loss = 0.01873120970903414, Recall = 0.022222222222222223, Aging Rate = 4.7725483021659414e-05, Precision = 0.8333333333333334, f1 = 0.043290043290043295\n",
      "Epoch 48: Train Loss = 0.01872461664112925, Recall = 0.0044444444444444444, Aging Rate = 3.181698868110628e-05, Precision = 0.25, f1 = 0.008733624454148473\n",
      "Epoch 49: Train Loss = 0.019098715434841294, Recall = 0.013333333333333334, Aging Rate = 3.9771235851382846e-05, Precision = 0.6, f1 = 0.026086956521739132\n",
      "Epoch 50: Train Loss = 0.01895606062802798, Recall = 0.008888888888888889, Aging Rate = 3.9771235851382846e-05, Precision = 0.4, f1 = 0.017391304347826087\n",
      "Test Loss = 0.017360618900366744, Recall = 0.0, Aging Rate = 0.0, precision = 0\n",
      "\n",
      "Training Finished at epoch 50.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61b15499a65f4cb9bbdedae76ae2d19b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss = 0.02259142990098093, Recall = 0.0, Aging Rate = 0.00027839865095967994, Precision = 0.0, f1 = 0\n",
      "Epoch 2: Train Loss = 0.02048424770788522, Recall = 0.0, Aging Rate = 0.0, Precision = 0, f1 = 0\n",
      "Epoch 3: Train Loss = 0.018789965216661153, Recall = 0.0, Aging Rate = 0.0, Precision = 0, f1 = 0\n",
      "Epoch 4: Train Loss = 0.020378757769196947, Recall = 0.0, Aging Rate = 0.0, Precision = 0, f1 = 0\n",
      "Epoch 5: Train Loss = 0.018839669531421688, Recall = 0.0, Aging Rate = 0.0, Precision = 0, f1 = 0\n",
      "Test Loss = 0.018646146364128164, Recall = 0.0, Aging Rate = 0.0, precision = 0\n",
      "\n",
      "Epoch 6: Train Loss = 0.019319820364707866, Recall = 0.0, Aging Rate = 0.0, Precision = 0, f1 = 0\n",
      "Epoch 7: Train Loss = 0.019180452948917227, Recall = 0.0, Aging Rate = 0.0, Precision = 0, f1 = 0\n",
      "Epoch 8: Train Loss = 0.019433325840752982, Recall = 0.0, Aging Rate = 0.0, Precision = 0, f1 = 0\n",
      "Epoch 9: Train Loss = 0.01953143044793913, Recall = 0.0, Aging Rate = 0.0, Precision = 0, f1 = 0\n",
      "Epoch 10: Train Loss = 0.018959816891730093, Recall = 0.0, Aging Rate = 0.0, Precision = 0, f1 = 0\n",
      "Test Loss = 0.018743173950810772, Recall = 0.0, Aging Rate = 0.0, precision = 0\n",
      "\n",
      "Epoch 11: Train Loss = 0.019269466600857085, Recall = 0.0, Aging Rate = 0.0, Precision = 0, f1 = 0\n",
      "Epoch 12: Train Loss = 0.018991763858291093, Recall = 0.0, Aging Rate = 0.0, Precision = 0, f1 = 0\n",
      "Epoch 13: Train Loss = 0.019118621683358445, Recall = 0.0, Aging Rate = 0.0, Precision = 0, f1 = 0\n",
      "Epoch 14: Train Loss = 0.019121563433430938, Recall = 0.0, Aging Rate = 0.0, Precision = 0, f1 = 0\n",
      "Epoch 15: Train Loss = 0.019056040834881216, Recall = 0.0, Aging Rate = 0.0, Precision = 0, f1 = 0\n",
      "Test Loss = 0.017666778161179834, Recall = 0.0, Aging Rate = 0.0, precision = 0\n",
      "\n",
      "Epoch 16: Train Loss = 0.01985220066382479, Recall = 0.0, Aging Rate = 0.0, Precision = 0, f1 = 0\n",
      "Epoch 17: Train Loss = 0.019241497023512473, Recall = 0.0, Aging Rate = 0.0, Precision = 0, f1 = 0\n",
      "Epoch 18: Train Loss = 0.01903283160658253, Recall = 0.0, Aging Rate = 0.0, Precision = 0, f1 = 0\n",
      "Epoch 19: Train Loss = 0.019338506591388544, Recall = 0.0, Aging Rate = 0.0, Precision = 0, f1 = 0\n",
      "Epoch 20: Train Loss = 0.018793244851855326, Recall = 0.0, Aging Rate = 0.0, Precision = 0, f1 = 0\n",
      "Test Loss = 0.02230001774231375, Recall = 0.0, Aging Rate = 0.0, precision = 0\n",
      "\n",
      "Epoch 21: Train Loss = 0.01960896569764861, Recall = 0.0, Aging Rate = 0.0, Precision = 0, f1 = 0\n",
      "Epoch 22: Train Loss = 0.019347847865890277, Recall = 0.0, Aging Rate = 0.0, Precision = 0, f1 = 0\n",
      "Epoch 23: Train Loss = 0.018949603587560714, Recall = 0.0, Aging Rate = 0.0, Precision = 0, f1 = 0\n",
      "Epoch 24: Train Loss = 0.01934928725433359, Recall = 0.0, Aging Rate = 0.0, Precision = 0, f1 = 0\n",
      "Epoch 25: Train Loss = 0.01879654920304684, Recall = 0.0, Aging Rate = 0.0, Precision = 0, f1 = 0\n",
      "Test Loss = 0.017715325463914387, Recall = 0.0, Aging Rate = 0.0, precision = 0\n",
      "\n",
      "Epoch 26: Train Loss = 0.02002363960723144, Recall = 0.0, Aging Rate = 0.0, Precision = 0, f1 = 0\n",
      "Epoch 27: Train Loss = 0.019579428140379062, Recall = 0.0, Aging Rate = 0.0, Precision = 0, f1 = 0\n",
      "Epoch 28: Train Loss = 0.019071778564252795, Recall = 0.0, Aging Rate = 0.0, Precision = 0, f1 = 0\n",
      "Epoch 29: Train Loss = 0.019301971026109352, Recall = 0.0, Aging Rate = 0.0, Precision = 0, f1 = 0\n",
      "Epoch 30: Train Loss = 0.019005393708949683, Recall = 0.0, Aging Rate = 0.0, Precision = 0, f1 = 0\n",
      "Test Loss = 0.01761842527364767, Recall = 0.0, Aging Rate = 0.0, precision = 0\n",
      "\n",
      "Epoch 31: Train Loss = 0.019677867702694897, Recall = 0.0, Aging Rate = 0.0, Precision = 0, f1 = 0\n",
      "Epoch 32: Train Loss = 0.019526663001686904, Recall = 0.0, Aging Rate = 0.0, Precision = 0, f1 = 0\n",
      "Epoch 33: Train Loss = 0.01961923278391874, Recall = 0.0, Aging Rate = 0.0, Precision = 0, f1 = 0\n",
      "Epoch 34: Train Loss = 0.01897756554488122, Recall = 0.0, Aging Rate = 0.0, Precision = 0, f1 = 0\n",
      "Epoch 35: Train Loss = 0.019101326817995784, Recall = 0.0, Aging Rate = 0.0, Precision = 0, f1 = 0\n",
      "Test Loss = 0.01851358581926453, Recall = 0.0, Aging Rate = 0.0, precision = 0\n",
      "\n",
      "Epoch 36: Train Loss = 0.019054088941129376, Recall = 0.0, Aging Rate = 0.0, Precision = 0, f1 = 0\n",
      "Epoch 37: Train Loss = 0.019206801978713595, Recall = 0.0, Aging Rate = 0.0, Precision = 0, f1 = 0\n",
      "Epoch 38: Train Loss = 0.019706195723695898, Recall = 0.0, Aging Rate = 0.0, Precision = 0, f1 = 0\n",
      "Epoch 39: Train Loss = 0.01918078880141425, Recall = 0.0, Aging Rate = 0.0, Precision = 0, f1 = 0\n",
      "Epoch 40: Train Loss = 0.018616924401154387, Recall = 0.0, Aging Rate = 0.0, Precision = 0, f1 = 0\n",
      "Test Loss = 0.01764131860180061, Recall = 0.0, Aging Rate = 0.0, precision = 0\n",
      "\n",
      "Epoch 41: Train Loss = 0.01917962099514881, Recall = 0.0, Aging Rate = 0.0, Precision = 0, f1 = 0\n",
      "Epoch 42: Train Loss = 0.01930534127364216, Recall = 0.0, Aging Rate = 0.0, Precision = 0, f1 = 0\n",
      "Epoch 43: Train Loss = 0.01946382305692683, Recall = 0.0, Aging Rate = 0.0, Precision = 0, f1 = 0\n",
      "Epoch 44: Train Loss = 0.01942903528913022, Recall = 0.0, Aging Rate = 0.0, Precision = 0, f1 = 0\n",
      "Epoch 45: Train Loss = 0.019038831155893405, Recall = 0.0, Aging Rate = 0.0, Precision = 0, f1 = 0\n",
      "Test Loss = 0.017694239621453466, Recall = 0.0, Aging Rate = 0.0, precision = 0\n",
      "\n",
      "Epoch 46: Train Loss = 0.019178399970362556, Recall = 0.0, Aging Rate = 0.0, Precision = 0, f1 = 0\n",
      "Epoch 47: Train Loss = 0.01914622817592323, Recall = 0.0, Aging Rate = 0.0, Precision = 0, f1 = 0\n",
      "Epoch 48: Train Loss = 0.019735321575799394, Recall = 0.0, Aging Rate = 0.0, Precision = 0, f1 = 0\n",
      "Epoch 49: Train Loss = 0.01936323259887665, Recall = 0.0, Aging Rate = 0.0, Precision = 0, f1 = 0\n",
      "Epoch 50: Train Loss = 0.019412276055486125, Recall = 0.0, Aging Rate = 0.0, Precision = 0, f1 = 0\n",
      "Test Loss = 0.02218231524672916, Recall = 0.0, Aging Rate = 0.0, precision = 0\n",
      "\n",
      "Training Finished at epoch 50.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b5f6b244fa84aeb9ac0433a9cdb07e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss = 0.02231895555733385, Recall = 0.0, Aging Rate = 0.00016704051925738557, Precision = 0.0, f1 = 0\n",
      "Epoch 2: Train Loss = 0.02042068248751362, Recall = 0.0, Aging Rate = 0.0, Precision = 0, f1 = 0\n",
      "Epoch 3: Train Loss = 0.019165408151933884, Recall = 0.0, Aging Rate = 0.0, Precision = 0, f1 = 0\n",
      "Epoch 4: Train Loss = 0.01901693418567438, Recall = 0.0, Aging Rate = 0.0, Precision = 0, f1 = 0\n",
      "Epoch 5: Train Loss = 0.02041275180685513, Recall = 0.0, Aging Rate = 0.0, Precision = 0, f1 = 0\n",
      "Test Loss = 0.018329569815858152, Recall = 0.0, Aging Rate = 0.0, precision = 0\n",
      "\n",
      "Epoch 6: Train Loss = 0.019784486371249087, Recall = 0.0, Aging Rate = 0.0, Precision = 0, f1 = 0\n",
      "Epoch 7: Train Loss = 0.019177341832161115, Recall = 0.0, Aging Rate = 0.0, Precision = 0, f1 = 0\n",
      "Epoch 8: Train Loss = 0.019583582042471626, Recall = 0.0, Aging Rate = 0.0, Precision = 0, f1 = 0\n",
      "Epoch 9: Train Loss = 0.019064302172427623, Recall = 0.0, Aging Rate = 0.0, Precision = 0, f1 = 0\n",
      "Epoch 10: Train Loss = 0.01945312527729886, Recall = 0.0, Aging Rate = 0.0, Precision = 0, f1 = 0\n",
      "Test Loss = 0.019066902922039726, Recall = 0.0, Aging Rate = 0.0, precision = 0\n",
      "\n",
      "Epoch 11: Train Loss = 0.01884900746216464, Recall = 0.0, Aging Rate = 0.0, Precision = 0, f1 = 0\n",
      "Epoch 12: Train Loss = 0.01915583192414273, Recall = 0.0, Aging Rate = 0.0, Precision = 0, f1 = 0\n",
      "Epoch 13: Train Loss = 0.019494365878872957, Recall = 0.0, Aging Rate = 0.0, Precision = 0, f1 = 0\n",
      "Epoch 14: Train Loss = 0.019108928956275226, Recall = 0.0, Aging Rate = 0.0, Precision = 0, f1 = 0\n",
      "Epoch 15: Train Loss = 0.019716671621405495, Recall = 0.0, Aging Rate = 0.0, Precision = 0, f1 = 0\n",
      "Test Loss = 0.01768705680581145, Recall = 0.0, Aging Rate = 0.0, precision = 0\n",
      "\n",
      "Epoch 16: Train Loss = 0.01867495597108827, Recall = 0.0, Aging Rate = 0.0, Precision = 0, f1 = 0\n",
      "Epoch 17: Train Loss = 0.01939690952549257, Recall = 0.0, Aging Rate = 0.0, Precision = 0, f1 = 0\n",
      "Epoch 18: Train Loss = 0.019058233761559025, Recall = 0.0, Aging Rate = 0.0, Precision = 0, f1 = 0\n",
      "Epoch 19: Train Loss = 0.019818192580638428, Recall = 0.0, Aging Rate = 0.0, Precision = 0, f1 = 0\n",
      "Epoch 20: Train Loss = 0.019060481945020046, Recall = 0.0, Aging Rate = 0.0, Precision = 0, f1 = 0\n",
      "Test Loss = 0.01754188905871144, Recall = 0.0, Aging Rate = 0.0, precision = 0\n",
      "\n",
      "Epoch 21: Train Loss = 0.018923991662377022, Recall = 0.0, Aging Rate = 0.0, Precision = 0, f1 = 0\n",
      "Epoch 22: Train Loss = 0.019503697696799226, Recall = 0.0, Aging Rate = 0.0, Precision = 0, f1 = 0\n",
      "Epoch 23: Train Loss = 0.01961447189801727, Recall = 0.0, Aging Rate = 0.0, Precision = 0, f1 = 0\n",
      "Epoch 24: Train Loss = 0.019526217289876375, Recall = 0.0, Aging Rate = 0.0, Precision = 0, f1 = 0\n",
      "Epoch 25: Train Loss = 0.01937140036641517, Recall = 0.0, Aging Rate = 0.0, Precision = 0, f1 = 0\n",
      "Test Loss = 0.0186049437289882, Recall = 0.0, Aging Rate = 0.0, precision = 0\n",
      "\n",
      "Epoch 26: Train Loss = 0.01874839980941771, Recall = 0.0, Aging Rate = 0.0, Precision = 0, f1 = 0\n",
      "Epoch 27: Train Loss = 0.018895929885756862, Recall = 0.0, Aging Rate = 0.0, Precision = 0, f1 = 0\n",
      "Epoch 28: Train Loss = 0.019236307928433706, Recall = 0.0, Aging Rate = 0.0, Precision = 0, f1 = 0\n",
      "Epoch 29: Train Loss = 0.01908274334203789, Recall = 0.0, Aging Rate = 0.0, Precision = 0, f1 = 0\n",
      "Epoch 30: Train Loss = 0.01903077869181376, Recall = 0.0, Aging Rate = 0.0, Precision = 0, f1 = 0\n",
      "Test Loss = 0.01746886952643183, Recall = 0.0, Aging Rate = 0.0, precision = 0\n",
      "\n",
      "Epoch 31: Train Loss = 0.019191805382237383, Recall = 0.0, Aging Rate = 0.0, Precision = 0, f1 = 0\n",
      "Epoch 32: Train Loss = 0.01915600693776917, Recall = 0.0, Aging Rate = 0.0, Precision = 0, f1 = 0\n",
      "Epoch 33: Train Loss = 0.018688019661732624, Recall = 0.0044444444444444444, Aging Rate = 2.3862931322483654e-05, Precision = 0.3333333333333333, f1 = 0.008771929824561405\n",
      "Epoch 34: Train Loss = 0.018302069109668626, Recall = 0.0, Aging Rate = 0.0, Precision = 0, f1 = 0\n",
      "Epoch 35: Train Loss = 0.019639054852445142, Recall = 0.0044444444444444444, Aging Rate = 1.5908620881655768e-05, Precision = 0.5, f1 = 0.008810572687224669\n",
      "Test Loss = 0.019059236522061436, Recall = 0.0, Aging Rate = 0.0, precision = 0\n",
      "\n",
      "Epoch 36: Train Loss = 0.01861743247782258, Recall = 0.0, Aging Rate = 2.3862931322483654e-05, Precision = 0.0, f1 = 0\n",
      "Epoch 37: Train Loss = 0.01866489896469965, Recall = 0.0, Aging Rate = 7.954310440827884e-06, Precision = 0.0, f1 = 0\n",
      "Epoch 38: Train Loss = 0.018140242724647572, Recall = 0.017777777777777778, Aging Rate = 3.9771552204139425e-05, Precision = 0.8, f1 = 0.034782608695652174\n",
      "Epoch 39: Train Loss = 0.017866345889510714, Recall = 0.008888888888888889, Aging Rate = 2.3862931322483654e-05, Precision = 0.6666666666666666, f1 = 0.01754385964912281\n",
      "Epoch 40: Train Loss = 0.018932091108242975, Recall = 0.008888888888888889, Aging Rate = 1.5908620881655768e-05, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.022502380656600724, Recall = 0.03111111111111111, Aging Rate = 0.00018294914013904133, precision = 0.30434782608695654\n",
      "Model in epoch 40 is saved.\n",
      "\n",
      "Epoch 41: Train Loss = 0.0193794356844801, Recall = 0.008888888888888889, Aging Rate = 2.3862931322483654e-05, Precision = 0.6666666666666666, f1 = 0.01754385964912281\n",
      "Epoch 42: Train Loss = 0.018393797558183784, Recall = 0.0, Aging Rate = 1.5908620881655768e-05, Precision = 0.0, f1 = 0\n",
      "Epoch 43: Train Loss = 0.017957828885311243, Recall = 0.013333333333333334, Aging Rate = 3.9771552204139425e-05, Precision = 0.6, f1 = 0.026086956521739132\n",
      "Epoch 44: Train Loss = 0.018398434543852475, Recall = 0.008888888888888889, Aging Rate = 3.1817241763311536e-05, Precision = 0.5, f1 = 0.017467248908296946\n",
      "Epoch 45: Train Loss = 0.01880569969919212, Recall = 0.017777777777777778, Aging Rate = 3.9771552204139425e-05, Precision = 0.8, f1 = 0.034782608695652174\n",
      "Test Loss = 0.019919212552190035, Recall = 0.0, Aging Rate = 0.0, precision = 0\n",
      "\n",
      "Epoch 46: Train Loss = 0.018469914967064318, Recall = 0.008888888888888889, Aging Rate = 1.5908620881655768e-05, Precision = 0, f1 = 0.0\n",
      "Epoch 47: Train Loss = 0.01817631962156942, Recall = 0.013333333333333334, Aging Rate = 5.568017308579519e-05, Precision = 0.42857142857142855, f1 = 0.025862068965517244\n",
      "Epoch 48: Train Loss = 0.018642332100750194, Recall = 0.0044444444444444444, Aging Rate = 2.3862931322483654e-05, Precision = 0.3333333333333333, f1 = 0.008771929824561405\n",
      "Epoch 49: Train Loss = 0.018684359038883824, Recall = 0.008888888888888889, Aging Rate = 1.5908620881655768e-05, Precision = 0, f1 = 0.0\n",
      "Epoch 50: Train Loss = 0.019078632448317704, Recall = 0.008888888888888889, Aging Rate = 1.5908620881655768e-05, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.019721110563163488, Recall = 0.0, Aging Rate = 0.0, precision = 0\n",
      "\n",
      "Epoch 51: Train Loss = 0.01888200633301149, Recall = 0.0044444444444444444, Aging Rate = 4.772586264496731e-05, Precision = 0.16666666666666666, f1 = 0.008658008658008658\n",
      "Epoch 52: Train Loss = 0.019283947760230243, Recall = 0.0, Aging Rate = 2.3862931322483654e-05, Precision = 0.0, f1 = 0\n",
      "Epoch 53: Train Loss = 0.018773215315202298, Recall = 0.0044444444444444444, Aging Rate = 1.5908620881655768e-05, Precision = 0.5, f1 = 0.008810572687224669\n",
      "Epoch 54: Train Loss = 0.019039413279312703, Recall = 0.0, Aging Rate = 7.954310440827884e-06, Precision = 0.0, f1 = 0\n",
      "Epoch 55: Train Loss = 0.01879591764346093, Recall = 0.0, Aging Rate = 2.3862931322483654e-05, Precision = 0.0, f1 = 0\n",
      "Test Loss = 0.017424598007973732, Recall = 0.0, Aging Rate = 0.0, precision = 0\n",
      "\n",
      "Epoch 56: Train Loss = 0.019524234647218863, Recall = 0.0, Aging Rate = 0.0, Precision = 0, f1 = 0\n",
      "Epoch 57: Train Loss = 0.018591442267628638, Recall = 0.0044444444444444444, Aging Rate = 7.954310440827884e-06, Precision = 0, f1 = 0.0\n",
      "Epoch 58: Train Loss = 0.0185705094044455, Recall = 0.0, Aging Rate = 7.954310440827884e-06, Precision = 0.0, f1 = 0\n",
      "Epoch 59: Train Loss = 0.019335770446895346, Recall = 0.0, Aging Rate = 0.0, Precision = 0, f1 = 0\n",
      "Epoch 60: Train Loss = 0.018551412059443696, Recall = 0.017777777777777778, Aging Rate = 4.772586264496731e-05, Precision = 0.6666666666666666, f1 = 0.03463203463203463\n",
      "Test Loss = 0.01739080073648027, Recall = 0.0, Aging Rate = 0.0, precision = 0\n",
      "\n",
      "Epoch 61: Train Loss = 0.019279729604025693, Recall = 0.0, Aging Rate = 0.0, Precision = 0, f1 = 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 62: Train Loss = 0.018412641911868574, Recall = 0.017777777777777778, Aging Rate = 3.9771552204139425e-05, Precision = 0.8, f1 = 0.034782608695652174\n",
      "Epoch 63: Train Loss = 0.018731427840720627, Recall = 0.0044444444444444444, Aging Rate = 2.3862931322483654e-05, Precision = 0.3333333333333333, f1 = 0.008771929824561405\n",
      "Epoch 64: Train Loss = 0.018978925636603052, Recall = 0.0, Aging Rate = 0.0, Precision = 0, f1 = 0\n",
      "Epoch 65: Train Loss = 0.01831835227686346, Recall = 0.008888888888888889, Aging Rate = 3.1817241763311536e-05, Precision = 0.5, f1 = 0.017467248908296946\n",
      "Test Loss = 0.017409289391803376, Recall = 0.0, Aging Rate = 0.0, precision = 0\n",
      "\n",
      "Epoch 66: Train Loss = 0.019382730858876072, Recall = 0.0044444444444444444, Aging Rate = 1.5908620881655768e-05, Precision = 0.5, f1 = 0.008810572687224669\n",
      "Epoch 67: Train Loss = 0.01813140203540369, Recall = 0.013333333333333334, Aging Rate = 3.9771552204139425e-05, Precision = 0.6, f1 = 0.026086956521739132\n",
      "Epoch 68: Train Loss = 0.018521171817748577, Recall = 0.008888888888888889, Aging Rate = 2.3862931322483654e-05, Precision = 0.6666666666666666, f1 = 0.01754385964912281\n",
      "Epoch 69: Train Loss = 0.019603212171472085, Recall = 0.0, Aging Rate = 1.5908620881655768e-05, Precision = 0.0, f1 = 0\n",
      "Epoch 70: Train Loss = 0.018734315184901262, Recall = 0.0, Aging Rate = 1.5908620881655768e-05, Precision = 0.0, f1 = 0\n",
      "Test Loss = 0.01922481604888619, Recall = 0.0, Aging Rate = 0.0, precision = 0\n",
      "\n",
      "Epoch 71: Train Loss = 0.018272895911076562, Recall = 0.008888888888888889, Aging Rate = 1.5908620881655768e-05, Precision = 0, f1 = 0.0\n",
      "Epoch 72: Train Loss = 0.018559578562201792, Recall = 0.008888888888888889, Aging Rate = 3.1817241763311536e-05, Precision = 0.5, f1 = 0.017467248908296946\n",
      "Epoch 73: Train Loss = 0.01903152365836213, Recall = 0.008888888888888889, Aging Rate = 3.1817241763311536e-05, Precision = 0.5, f1 = 0.017467248908296946\n",
      "Epoch 74: Train Loss = 0.01876629169694242, Recall = 0.0044444444444444444, Aging Rate = 7.954310440827884e-06, Precision = 0, f1 = 0.0\n",
      "Epoch 75: Train Loss = 0.018552194454899227, Recall = 0.0044444444444444444, Aging Rate = 1.5908620881655768e-05, Precision = 0.5, f1 = 0.008810572687224669\n",
      "Test Loss = 0.01725992784130243, Recall = 0.0, Aging Rate = 0.0, precision = 0\n",
      "\n",
      "Epoch 76: Train Loss = 0.018954714367385998, Recall = 0.0, Aging Rate = 0.0, Precision = 0, f1 = 0\n",
      "Epoch 77: Train Loss = 0.01924194633588466, Recall = 0.0, Aging Rate = 7.954310440827884e-06, Precision = 0.0, f1 = 0\n",
      "Epoch 78: Train Loss = 0.01863658569894964, Recall = 0.0044444444444444444, Aging Rate = 1.5908620881655768e-05, Precision = 0.5, f1 = 0.008810572687224669\n",
      "Epoch 79: Train Loss = 0.01882711240455047, Recall = 0.008888888888888889, Aging Rate = 3.1817241763311536e-05, Precision = 0.5, f1 = 0.017467248908296946\n",
      "Epoch 80: Train Loss = 0.018815027611886945, Recall = 0.0044444444444444444, Aging Rate = 7.954310440827884e-06, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.018350699979874326, Recall = 0.0, Aging Rate = 0.0, precision = 0\n",
      "\n",
      "Epoch 81: Train Loss = 0.01944517776019486, Recall = 0.0, Aging Rate = 7.954310440827884e-06, Precision = 0.0, f1 = 0\n",
      "Epoch 82: Train Loss = 0.01893056031749077, Recall = 0.0, Aging Rate = 7.954310440827884e-06, Precision = 0.0, f1 = 0\n",
      "Epoch 83: Train Loss = 0.0186092258986514, Recall = 0.0, Aging Rate = 7.954310440827884e-06, Precision = 0.0, f1 = 0\n",
      "Epoch 84: Train Loss = 0.01902111155430859, Recall = 0.0044444444444444444, Aging Rate = 1.5908620881655768e-05, Precision = 0.5, f1 = 0.008810572687224669\n",
      "Epoch 85: Train Loss = 0.019372225562797364, Recall = 0.0044444444444444444, Aging Rate = 1.5908620881655768e-05, Precision = 0.5, f1 = 0.008810572687224669\n",
      "Test Loss = 0.017624675660722025, Recall = 0.0, Aging Rate = 0.0, precision = 0\n",
      "\n",
      "Epoch 86: Train Loss = 0.01875243047705503, Recall = 0.0044444444444444444, Aging Rate = 7.954310440827884e-06, Precision = 0, f1 = 0.0\n",
      "Epoch 87: Train Loss = 0.01885096793185642, Recall = 0.0, Aging Rate = 7.954310440827884e-06, Precision = 0.0, f1 = 0\n",
      "Epoch 88: Train Loss = 0.01901550850061231, Recall = 0.0, Aging Rate = 0.0, Precision = 0, f1 = 0\n",
      "Epoch 89: Train Loss = 0.018779893808003118, Recall = 0.0, Aging Rate = 0.0, Precision = 0, f1 = 0\n",
      "Epoch 90: Train Loss = 0.01883786260017834, Recall = 0.013333333333333334, Aging Rate = 2.3862931322483654e-05, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.01820069902322144, Recall = 0.0, Aging Rate = 0.0, precision = 0\n",
      "\n",
      "Training Finished at epoch 90.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "40a53b41ea18448dbaf019457ff965dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss = 0.02285114912233937, Recall = 0.0, Aging Rate = 3.9771235851382846e-05, Precision = 0.0, f1 = 0\n",
      "Epoch 2: Train Loss = 0.020526551782554917, Recall = 0.0, Aging Rate = 0.0, Precision = 0, f1 = 0\n",
      "Epoch 3: Train Loss = 0.019126406709866452, Recall = 0.0, Aging Rate = 0.0, Precision = 0, f1 = 0\n",
      "Epoch 4: Train Loss = 0.01951648049861154, Recall = 0.0, Aging Rate = 0.0, Precision = 0, f1 = 0\n",
      "Epoch 5: Train Loss = 0.02000174812806696, Recall = 0.0, Aging Rate = 0.0, Precision = 0, f1 = 0\n",
      "Test Loss = 0.02573087485073996, Recall = 0.0, Aging Rate = 0.0, precision = 0\n",
      "\n",
      "Epoch 6: Train Loss = 0.019080018391155286, Recall = 0.0, Aging Rate = 0.0, Precision = 0, f1 = 0\n",
      "Epoch 7: Train Loss = 0.0194689235612576, Recall = 0.0, Aging Rate = 0.0, Precision = 0, f1 = 0\n",
      "Epoch 8: Train Loss = 0.019828729589458867, Recall = 0.0, Aging Rate = 0.0, Precision = 0, f1 = 0\n",
      "Epoch 9: Train Loss = 0.01966785846950365, Recall = 0.0, Aging Rate = 0.0, Precision = 0, f1 = 0\n",
      "Epoch 10: Train Loss = 0.020848123205825294, Recall = 0.0, Aging Rate = 0.0, Precision = 0, f1 = 0\n",
      "Test Loss = 0.01858992868528086, Recall = 0.0, Aging Rate = 0.0, precision = 0\n",
      "\n",
      "Epoch 11: Train Loss = 0.018997666841604085, Recall = 0.0, Aging Rate = 0.0, Precision = 0, f1 = 0\n",
      "Epoch 12: Train Loss = 0.019535751871563443, Recall = 0.0, Aging Rate = 0.0, Precision = 0, f1 = 0\n",
      "Epoch 13: Train Loss = 0.01987332887848701, Recall = 0.0, Aging Rate = 0.0, Precision = 0, f1 = 0\n",
      "Epoch 14: Train Loss = 0.01887521802142345, Recall = 0.0, Aging Rate = 0.0, Precision = 0, f1 = 0\n",
      "Epoch 15: Train Loss = 0.018838976707479013, Recall = 0.0, Aging Rate = 0.0, Precision = 0, f1 = 0\n",
      "Test Loss = 0.017632302219088708, Recall = 0.0, Aging Rate = 0.0, precision = 0\n",
      "\n",
      "Epoch 16: Train Loss = 0.019024978420169918, Recall = 0.0, Aging Rate = 1.590849434055314e-05, Precision = 0.0, f1 = 0\n",
      "Epoch 17: Train Loss = 0.020335894797305364, Recall = 0.0, Aging Rate = 7.95424717027657e-06, Precision = 0.0, f1 = 0\n",
      "Epoch 18: Train Loss = 0.018966516682819224, Recall = 0.0044444444444444444, Aging Rate = 7.95424717027657e-06, Precision = 0, f1 = 0.0\n",
      "Epoch 19: Train Loss = 0.019161794764259728, Recall = 0.0, Aging Rate = 2.3862741510829707e-05, Precision = 0.0, f1 = 0\n",
      "Epoch 20: Train Loss = 0.019194536731055964, Recall = 0.0, Aging Rate = 7.95424717027657e-06, Precision = 0.0, f1 = 0\n",
      "Test Loss = 0.017613428733590838, Recall = 0.0, Aging Rate = 0.0, precision = 0\n",
      "\n",
      "Epoch 21: Train Loss = 0.019893796478784403, Recall = 0.0, Aging Rate = 0.0, Precision = 0, f1 = 0\n",
      "Epoch 22: Train Loss = 0.01891087049996456, Recall = 0.0, Aging Rate = 0.0, Precision = 0, f1 = 0\n",
      "Epoch 23: Train Loss = 0.019473631938061033, Recall = 0.0, Aging Rate = 0.0, Precision = 0, f1 = 0\n",
      "Epoch 24: Train Loss = 0.01929988970686905, Recall = 0.0, Aging Rate = 0.0, Precision = 0, f1 = 0\n",
      "Epoch 25: Train Loss = 0.0189760882833228, Recall = 0.0, Aging Rate = 0.0, Precision = 0, f1 = 0\n",
      "Test Loss = 0.017633750868216582, Recall = 0.0, Aging Rate = 0.0, precision = 0\n",
      "\n",
      "Epoch 26: Train Loss = 0.019272590339149295, Recall = 0.0, Aging Rate = 0.0, Precision = 0, f1 = 0\n",
      "Epoch 27: Train Loss = 0.019289972427798674, Recall = 0.0, Aging Rate = 0.0, Precision = 0, f1 = 0\n",
      "Epoch 28: Train Loss = 0.01896023912569234, Recall = 0.0, Aging Rate = 0.0, Precision = 0, f1 = 0\n",
      "Epoch 29: Train Loss = 0.01882861664905919, Recall = 0.0, Aging Rate = 0.0, Precision = 0, f1 = 0\n",
      "Epoch 30: Train Loss = 0.019595501472998815, Recall = 0.0, Aging Rate = 7.95424717027657e-06, Precision = 0.0, f1 = 0\n",
      "Test Loss = 0.017821164666453754, Recall = 0.022222222222222223, Aging Rate = 5.567973019193598e-05, precision = 0.7142857142857143\n",
      "Model in epoch 30 is saved.\n",
      "\n",
      "Epoch 31: Train Loss = 0.019280237325001275, Recall = 0.0, Aging Rate = 0.0, Precision = 0, f1 = 0\n",
      "Epoch 32: Train Loss = 0.01898715574711557, Recall = 0.0, Aging Rate = 7.95424717027657e-06, Precision = 0.0, f1 = 0\n",
      "Epoch 33: Train Loss = 0.019069476224288503, Recall = 0.0044444444444444444, Aging Rate = 7.95424717027657e-06, Precision = 0, f1 = 0.0\n",
      "Epoch 34: Train Loss = 0.019589890953919675, Recall = 0.0, Aging Rate = 7.95424717027657e-06, Precision = 0.0, f1 = 0\n",
      "Epoch 35: Train Loss = 0.0187873384138978, Recall = 0.0, Aging Rate = 3.181698868110628e-05, Precision = 0.0, f1 = 0\n",
      "Test Loss = 0.017556293657227284, Recall = 0.0, Aging Rate = 0.0, precision = 0\n",
      "\n",
      "Epoch 36: Train Loss = 0.01907741769777931, Recall = 0.0, Aging Rate = 0.0, Precision = 0, f1 = 0\n",
      "Epoch 37: Train Loss = 0.020133028433292722, Recall = 0.0, Aging Rate = 0.0, Precision = 0, f1 = 0\n",
      "Epoch 38: Train Loss = 0.018797401003701354, Recall = 0.0, Aging Rate = 0.0, Precision = 0, f1 = 0\n",
      "Epoch 39: Train Loss = 0.019777968289934552, Recall = 0.0, Aging Rate = 0.0, Precision = 0, f1 = 0\n",
      "Epoch 40: Train Loss = 0.01911876290373128, Recall = 0.0, Aging Rate = 0.0, Precision = 0, f1 = 0\n",
      "Test Loss = 0.01747952362515986, Recall = 0.0, Aging Rate = 0.0, precision = 0\n",
      "\n",
      "Epoch 41: Train Loss = 0.01909661958009382, Recall = 0.0, Aging Rate = 0.0, Precision = 0, f1 = 0\n",
      "Epoch 42: Train Loss = 0.019460339818916136, Recall = 0.0044444444444444444, Aging Rate = 7.95424717027657e-06, Precision = 0, f1 = 0.0\n",
      "Epoch 43: Train Loss = 0.019315189803664763, Recall = 0.0, Aging Rate = 0.0, Precision = 0, f1 = 0\n",
      "Epoch 44: Train Loss = 0.019508371451410527, Recall = 0.0, Aging Rate = 0.0, Precision = 0, f1 = 0\n",
      "Epoch 45: Train Loss = 0.019166793633915696, Recall = 0.0, Aging Rate = 0.0, Precision = 0, f1 = 0\n",
      "Test Loss = 0.017996352252512518, Recall = 0.0, Aging Rate = 0.0, precision = 0\n",
      "\n",
      "Epoch 46: Train Loss = 0.019012701360144425, Recall = 0.0, Aging Rate = 0.0, Precision = 0, f1 = 0\n",
      "Epoch 47: Train Loss = 0.019340495987425373, Recall = 0.0, Aging Rate = 0.0, Precision = 0, f1 = 0\n",
      "Epoch 48: Train Loss = 0.019254525763141732, Recall = 0.0, Aging Rate = 0.0, Precision = 0, f1 = 0\n",
      "Epoch 49: Train Loss = 0.018909678942997075, Recall = 0.0, Aging Rate = 0.0, Precision = 0, f1 = 0\n",
      "Epoch 50: Train Loss = 0.018980893365978607, Recall = 0.0, Aging Rate = 0.0, Precision = 0, f1 = 0\n",
      "Test Loss = 0.017950614757760244, Recall = 0.0, Aging Rate = 0.0, precision = 0\n",
      "\n",
      "Epoch 51: Train Loss = 0.01944133419394958, Recall = 0.0, Aging Rate = 0.0, Precision = 0, f1 = 0\n",
      "Epoch 52: Train Loss = 0.01980298156565035, Recall = 0.0, Aging Rate = 0.0, Precision = 0, f1 = 0\n",
      "Epoch 53: Train Loss = 0.01966845087955842, Recall = 0.0, Aging Rate = 0.0, Precision = 0, f1 = 0\n",
      "Epoch 54: Train Loss = 0.019972933672359368, Recall = 0.0, Aging Rate = 0.0, Precision = 0, f1 = 0\n",
      "Epoch 55: Train Loss = 0.01880089875234473, Recall = 0.0, Aging Rate = 0.0, Precision = 0, f1 = 0\n",
      "Test Loss = 0.020019857228029115, Recall = 0.0, Aging Rate = 0.0, precision = 0\n",
      "\n",
      "Epoch 56: Train Loss = 0.019367836244810022, Recall = 0.0, Aging Rate = 0.0, Precision = 0, f1 = 0\n",
      "Epoch 57: Train Loss = 0.019209006333038924, Recall = 0.0, Aging Rate = 0.0, Precision = 0, f1 = 0\n",
      "Epoch 58: Train Loss = 0.01939436924880168, Recall = 0.0, Aging Rate = 0.0, Precision = 0, f1 = 0\n",
      "Epoch 59: Train Loss = 0.018709830561536623, Recall = 0.0, Aging Rate = 0.0, Precision = 0, f1 = 0\n",
      "Epoch 60: Train Loss = 0.018989408355401045, Recall = 0.0, Aging Rate = 0.0, Precision = 0, f1 = 0\n",
      "Test Loss = 0.018463520552572738, Recall = 0.0, Aging Rate = 0.0, precision = 0\n",
      "\n",
      "Epoch 61: Train Loss = 0.019184640008389757, Recall = 0.0, Aging Rate = 0.0, Precision = 0, f1 = 0\n",
      "Epoch 62: Train Loss = 0.018799623737094626, Recall = 0.0, Aging Rate = 0.0, Precision = 0, f1 = 0\n",
      "Epoch 63: Train Loss = 0.019364957606343724, Recall = 0.0, Aging Rate = 0.0, Precision = 0, f1 = 0\n",
      "Epoch 64: Train Loss = 0.019515129286988744, Recall = 0.0, Aging Rate = 0.0, Precision = 0, f1 = 0\n",
      "Epoch 65: Train Loss = 0.0187237772606653, Recall = 0.0, Aging Rate = 0.0, Precision = 0, f1 = 0\n",
      "Test Loss = 0.018503686130225197, Recall = 0.0, Aging Rate = 0.0, precision = 0\n",
      "\n",
      "Epoch 66: Train Loss = 0.01940337521651022, Recall = 0.0, Aging Rate = 0.0, Precision = 0, f1 = 0\n",
      "Epoch 67: Train Loss = 0.019860219986198743, Recall = 0.0, Aging Rate = 0.0, Precision = 0, f1 = 0\n",
      "Epoch 68: Train Loss = 0.01901500037985791, Recall = 0.0, Aging Rate = 0.0, Precision = 0, f1 = 0\n",
      "Epoch 69: Train Loss = 0.019677413738359815, Recall = 0.0, Aging Rate = 0.0, Precision = 0, f1 = 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 70: Train Loss = 0.01970777211267816, Recall = 0.0, Aging Rate = 0.0, Precision = 0, f1 = 0\n",
      "Test Loss = 0.01993739989773711, Recall = 0.0, Aging Rate = 0.0, precision = 0\n",
      "\n",
      "Epoch 71: Train Loss = 0.01912542376307669, Recall = 0.0, Aging Rate = 0.0, Precision = 0, f1 = 0\n",
      "Epoch 72: Train Loss = 0.018749571639755998, Recall = 0.0, Aging Rate = 0.0, Precision = 0, f1 = 0\n",
      "Epoch 73: Train Loss = 0.01995999348589296, Recall = 0.0, Aging Rate = 0.0, Precision = 0, f1 = 0\n",
      "Epoch 74: Train Loss = 0.01979867522535278, Recall = 0.0, Aging Rate = 0.0, Precision = 0, f1 = 0\n",
      "Epoch 75: Train Loss = 0.019253439775787414, Recall = 0.0, Aging Rate = 0.0, Precision = 0, f1 = 0\n",
      "Test Loss = 0.01774873629864377, Recall = 0.0, Aging Rate = 0.0, precision = 0\n",
      "\n",
      "Epoch 76: Train Loss = 0.019196196932382812, Recall = 0.0, Aging Rate = 0.0, Precision = 0, f1 = 0\n",
      "Epoch 77: Train Loss = 0.019232514793758326, Recall = 0.008888888888888889, Aging Rate = 1.590849434055314e-05, Precision = 0, f1 = 0.0\n",
      "Epoch 78: Train Loss = 0.01871108596264677, Recall = 0.0, Aging Rate = 7.95424717027657e-06, Precision = 0.0, f1 = 0\n",
      "Epoch 79: Train Loss = 0.01987900570879312, Recall = 0.0, Aging Rate = 0.0, Precision = 0, f1 = 0\n",
      "Epoch 80: Train Loss = 0.018948386693807995, Recall = 0.017777777777777778, Aging Rate = 4.7725483021659414e-05, Precision = 0.6666666666666666, f1 = 0.03463203463203463\n",
      "Test Loss = 0.017314661671146796, Recall = 0.0, Aging Rate = 0.0, precision = 0\n",
      "\n",
      "Training Finished at epoch 80.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba38767637d4403e9cff78785df123eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss = 0.023242654183484066, Recall = 0.0, Aging Rate = 0.0005011255438803026, Precision = 0.0, f1 = 0\n",
      "Epoch 2: Train Loss = 0.021064061005521308, Recall = 0.0, Aging Rate = 0.0, Precision = 0, f1 = 0\n",
      "Epoch 3: Train Loss = 0.01936823187175325, Recall = 0.0, Aging Rate = 0.0, Precision = 0, f1 = 0\n",
      "Epoch 4: Train Loss = 0.01893772192704692, Recall = 0.0, Aging Rate = 0.0, Precision = 0, f1 = 0\n",
      "Epoch 5: Train Loss = 0.01932573838061018, Recall = 0.0, Aging Rate = 0.0, Precision = 0, f1 = 0\n",
      "Test Loss = 0.018561635569541806, Recall = 0.0, Aging Rate = 0.0, precision = 0\n",
      "\n",
      "Epoch 6: Train Loss = 0.019047530781514974, Recall = 0.0, Aging Rate = 0.0, Precision = 0, f1 = 0\n",
      "Epoch 7: Train Loss = 0.01989939869868566, Recall = 0.0, Aging Rate = 0.0, Precision = 0, f1 = 0\n",
      "Epoch 8: Train Loss = 0.01893818992494996, Recall = 0.0, Aging Rate = 0.0, Precision = 0, f1 = 0\n",
      "Epoch 9: Train Loss = 0.020275153168800422, Recall = 0.0, Aging Rate = 0.0, Precision = 0, f1 = 0\n",
      "Epoch 10: Train Loss = 0.01886126897838216, Recall = 0.0, Aging Rate = 0.0, Precision = 0, f1 = 0\n",
      "Test Loss = 0.017615685017054558, Recall = 0.0, Aging Rate = 0.0, precision = 0\n",
      "\n",
      "Epoch 11: Train Loss = 0.018925319735733533, Recall = 0.0, Aging Rate = 0.0, Precision = 0, f1 = 0\n",
      "Epoch 12: Train Loss = 0.019601955388507963, Recall = 0.0, Aging Rate = 0.0, Precision = 0, f1 = 0\n",
      "Epoch 13: Train Loss = 0.018529001701120134, Recall = 0.0, Aging Rate = 0.0, Precision = 0, f1 = 0\n",
      "Epoch 14: Train Loss = 0.0191006106162793, Recall = 0.0, Aging Rate = 0.0, Precision = 0, f1 = 0\n",
      "Epoch 15: Train Loss = 0.01934773783221464, Recall = 0.0, Aging Rate = 0.0, Precision = 0, f1 = 0\n",
      "Test Loss = 0.01775078145017553, Recall = 0.0, Aging Rate = 0.0, precision = 0\n",
      "\n",
      "Epoch 16: Train Loss = 0.019088904776932796, Recall = 0.0, Aging Rate = 0.0, Precision = 0, f1 = 0\n",
      "Epoch 17: Train Loss = 0.018951575772113823, Recall = 0.0, Aging Rate = 0.0, Precision = 0, f1 = 0\n",
      "Epoch 18: Train Loss = 0.019681878139880368, Recall = 0.0, Aging Rate = 0.0, Precision = 0, f1 = 0\n",
      "Epoch 19: Train Loss = 0.018912213837139046, Recall = 0.0, Aging Rate = 0.0, Precision = 0, f1 = 0\n",
      "Epoch 20: Train Loss = 0.01920567708720853, Recall = 0.0, Aging Rate = 0.0, Precision = 0, f1 = 0\n",
      "Test Loss = 0.018101022764122534, Recall = 0.0, Aging Rate = 0.0, precision = 0\n",
      "\n",
      "Epoch 21: Train Loss = 0.019046218466943383, Recall = 0.0, Aging Rate = 0.0, Precision = 0, f1 = 0\n",
      "Epoch 22: Train Loss = 0.01940397059649745, Recall = 0.0, Aging Rate = 0.0, Precision = 0, f1 = 0\n",
      "Epoch 23: Train Loss = 0.018817989125060677, Recall = 0.0, Aging Rate = 0.0, Precision = 0, f1 = 0\n",
      "Epoch 24: Train Loss = 0.019120762174093305, Recall = 0.0, Aging Rate = 0.0, Precision = 0, f1 = 0\n",
      "Epoch 25: Train Loss = 0.019783044683545723, Recall = 0.0, Aging Rate = 0.0, Precision = 0, f1 = 0\n",
      "Test Loss = 0.017478714400557958, Recall = 0.0, Aging Rate = 0.0, precision = 0\n",
      "\n",
      "Epoch 26: Train Loss = 0.018831233149291266, Recall = 0.0, Aging Rate = 0.0, Precision = 0, f1 = 0\n",
      "Epoch 27: Train Loss = 0.018993167898180677, Recall = 0.0, Aging Rate = 0.0, Precision = 0, f1 = 0\n",
      "Epoch 28: Train Loss = 0.01936732751048613, Recall = 0.0, Aging Rate = 0.0, Precision = 0, f1 = 0\n",
      "Epoch 29: Train Loss = 0.018965342155206788, Recall = 0.0, Aging Rate = 0.0, Precision = 0, f1 = 0\n",
      "Epoch 30: Train Loss = 0.01902592836248342, Recall = 0.0, Aging Rate = 0.0, Precision = 0, f1 = 0\n",
      "Test Loss = 0.018082797559139302, Recall = 0.0, Aging Rate = 0.0, precision = 0\n",
      "\n",
      "Epoch 31: Train Loss = 0.019595505429816074, Recall = 0.0, Aging Rate = 0.0, Precision = 0, f1 = 0\n",
      "Epoch 32: Train Loss = 0.019433981996539437, Recall = 0.0, Aging Rate = 0.0, Precision = 0, f1 = 0\n",
      "Epoch 33: Train Loss = 0.019240328586356454, Recall = 0.0, Aging Rate = 0.0, Precision = 0, f1 = 0\n",
      "Epoch 34: Train Loss = 0.018651227417770297, Recall = 0.0, Aging Rate = 0.0, Precision = 0, f1 = 0\n",
      "Epoch 35: Train Loss = 0.019342452261745382, Recall = 0.0, Aging Rate = 0.0, Precision = 0, f1 = 0\n",
      "Test Loss = 0.018029541177326504, Recall = 0.0, Aging Rate = 0.0, precision = 0\n",
      "\n",
      "Epoch 36: Train Loss = 0.019623205384405776, Recall = 0.0, Aging Rate = 0.0, Precision = 0, f1 = 0\n",
      "Epoch 37: Train Loss = 0.018959104872640225, Recall = 0.0, Aging Rate = 0.0, Precision = 0, f1 = 0\n",
      "Epoch 38: Train Loss = 0.019734488185031325, Recall = 0.0, Aging Rate = 7.954373712385755e-06, Precision = 0.0, f1 = 0\n",
      "Epoch 39: Train Loss = 0.019949133767057693, Recall = 0.0, Aging Rate = 0.0, Precision = 0, f1 = 0\n",
      "Epoch 40: Train Loss = 0.01883483007069314, Recall = 0.0, Aging Rate = 0.0, Precision = 0, f1 = 0\n",
      "Test Loss = 0.01746886586559618, Recall = 0.0, Aging Rate = 0.0, precision = 0\n",
      "\n",
      "Epoch 41: Train Loss = 0.019303731291972843, Recall = 0.0, Aging Rate = 0.0, Precision = 0, f1 = 0\n",
      "Epoch 42: Train Loss = 0.018569497604415914, Recall = 0.0, Aging Rate = 0.0, Precision = 0, f1 = 0\n",
      "Epoch 43: Train Loss = 0.018981974259506082, Recall = 0.0, Aging Rate = 0.0, Precision = 0, f1 = 0\n",
      "Epoch 44: Train Loss = 0.019534109875887197, Recall = 0.0, Aging Rate = 0.0, Precision = 0, f1 = 0\n",
      "Epoch 45: Train Loss = 0.019802607610401705, Recall = 0.0, Aging Rate = 0.0, Precision = 0, f1 = 0\n",
      "Test Loss = 0.01821687548162507, Recall = 0.0, Aging Rate = 0.0, precision = 0\n",
      "\n",
      "Epoch 46: Train Loss = 0.018359976874327964, Recall = 0.0, Aging Rate = 0.0, Precision = 0, f1 = 0\n",
      "Epoch 47: Train Loss = 0.019449011700976154, Recall = 0.0, Aging Rate = 0.0, Precision = 0, f1 = 0\n",
      "Epoch 48: Train Loss = 0.019059805100849054, Recall = 0.0, Aging Rate = 0.0, Precision = 0, f1 = 0\n",
      "Epoch 49: Train Loss = 0.01916347338140355, Recall = 0.0, Aging Rate = 0.0, Precision = 0, f1 = 0\n",
      "Epoch 50: Train Loss = 0.019235417993782748, Recall = 0.0, Aging Rate = 0.0, Precision = 0, f1 = 0\n",
      "Test Loss = 0.01791169674582871, Recall = 0.0, Aging Rate = 0.0, precision = 0\n",
      "\n",
      "Training Finished at epoch 50.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d85f56d113b43a797b4e94f25189e2c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss = 0.02763369523941772, Recall = 0.0044444444444444444, Aging Rate = 0.0012329083113928683, Precision = 0.0064516129032258064, f1 = 0.005263157894736842\n",
      "Epoch 2: Train Loss = 0.018757274821207145, Recall = 0.0, Aging Rate = 0.0, Precision = 0, f1 = 0\n",
      "Epoch 3: Train Loss = 0.018561293726511705, Recall = 0.0, Aging Rate = 0.0, Precision = 0, f1 = 0\n",
      "Epoch 4: Train Loss = 0.01850403256761629, Recall = 0.0, Aging Rate = 0.0, Precision = 0, f1 = 0\n",
      "Epoch 5: Train Loss = 0.01832627690418827, Recall = 0.0, Aging Rate = 0.0, Precision = 0, f1 = 0\n",
      "Test Loss = 0.017266994019309315, Recall = 0.0, Aging Rate = 0.0, precision = 0\n",
      "\n",
      "Epoch 6: Train Loss = 0.017739761201955938, Recall = 0.0, Aging Rate = 0.0, Precision = 0, f1 = 0\n",
      "Epoch 7: Train Loss = 0.01746946020044325, Recall = 0.0, Aging Rate = 0.0, Precision = 0, f1 = 0\n",
      "Epoch 8: Train Loss = 0.017015046709239052, Recall = 0.0, Aging Rate = 0.0, Precision = 0, f1 = 0\n",
      "Epoch 9: Train Loss = 0.016449243401405043, Recall = 0.0, Aging Rate = 0.0, Precision = 0, f1 = 0\n",
      "Epoch 10: Train Loss = 0.015970235169288634, Recall = 0.0, Aging Rate = 0.0, Precision = 0, f1 = 0\n",
      "Test Loss = 0.01502900131810667, Recall = 0.022222222222222223, Aging Rate = 4.7725483021659414e-05, precision = 0.8333333333333334\n",
      "Model in epoch 10 is saved.\n",
      "\n",
      "Epoch 11: Train Loss = 0.015414581600692456, Recall = 0.017777777777777778, Aging Rate = 3.9771235851382846e-05, Precision = 0.8, f1 = 0.034782608695652174\n",
      "Epoch 12: Train Loss = 0.015104020445726894, Recall = 0.0, Aging Rate = 2.3862741510829707e-05, Precision = 0.0, f1 = 0\n",
      "Epoch 13: Train Loss = 0.014942167293766578, Recall = 0.013333333333333334, Aging Rate = 3.181698868110628e-05, Precision = 0.75, f1 = 0.026200873362445417\n",
      "Epoch 14: Train Loss = 0.014466737435881009, Recall = 0.02666666666666667, Aging Rate = 6.363397736221256e-05, Precision = 0.75, f1 = 0.05150214592274679\n",
      "Epoch 15: Train Loss = 0.014264830904195724, Recall = 0.017777777777777778, Aging Rate = 3.9771235851382846e-05, Precision = 0.8, f1 = 0.034782608695652174\n",
      "Test Loss = 0.013562318873087275, Recall = 0.06666666666666667, Aging Rate = 0.0001511306962352548, precision = 0.7894736842105263\n",
      "\n",
      "Epoch 16: Train Loss = 0.013943206175219783, Recall = 0.035555555555555556, Aging Rate = 7.954247170276569e-05, Precision = 0.8, f1 = 0.06808510638297872\n",
      "Epoch 17: Train Loss = 0.013679479906532791, Recall = 0.04, Aging Rate = 8.749671887304226e-05, Precision = 0.8181818181818182, f1 = 0.07627118644067797\n",
      "Epoch 18: Train Loss = 0.013525645410901448, Recall = 0.044444444444444446, Aging Rate = 0.0001034052132135954, Precision = 0.7692307692307693, f1 = 0.08403361344537816\n",
      "Epoch 19: Train Loss = 0.01333792259304424, Recall = 0.03111111111111111, Aging Rate = 7.954247170276569e-05, Precision = 0.7, f1 = 0.05957446808510638\n",
      "Epoch 20: Train Loss = 0.013289799924316652, Recall = 0.04, Aging Rate = 7.954247170276569e-05, Precision = 0.9, f1 = 0.07659574468085106\n",
      "Test Loss = 0.012440521254887399, Recall = 0.13777777777777778, Aging Rate = 0.00029430714530023305, precision = 0.8378378378378378\n",
      "Model in epoch 20 is saved.\n",
      "\n",
      "Epoch 21: Train Loss = 0.01295981772234287, Recall = 0.044444444444444446, Aging Rate = 9.545096604331883e-05, Precision = 0.8333333333333334, f1 = 0.08438818565400845\n",
      "Epoch 22: Train Loss = 0.012839682804799909, Recall = 0.06222222222222222, Aging Rate = 0.00016703919057580794, Precision = 0.6666666666666666, f1 = 0.11382113821138212\n",
      "Epoch 23: Train Loss = 0.012740118430481525, Recall = 0.04, Aging Rate = 9.545096604331883e-05, Precision = 0.75, f1 = 0.07594936708860758\n",
      "Epoch 24: Train Loss = 0.012589432343244169, Recall = 0.05333333333333334, Aging Rate = 0.00012726795472442511, Precision = 0.75, f1 = 0.09958506224066391\n",
      "Epoch 25: Train Loss = 0.01241728882076677, Recall = 0.07555555555555556, Aging Rate = 0.00016703919057580794, Precision = 0.8095238095238095, f1 = 0.13821138211382114\n",
      "Test Loss = 0.011897449427926619, Recall = 0.04888888888888889, Aging Rate = 8.749671887304226e-05, precision = 1.0\n",
      "Model in epoch 25 is saved.\n",
      "\n",
      "Epoch 26: Train Loss = 0.012334893168736266, Recall = 0.07111111111111111, Aging Rate = 0.00015908494340553139, Precision = 0.8, f1 = 0.13061224489795917\n",
      "Epoch 27: Train Loss = 0.01229882365590573, Recall = 0.06222222222222222, Aging Rate = 0.00013522220189470167, Precision = 0.8235294117647058, f1 = 0.11570247933884296\n",
      "Epoch 28: Train Loss = 0.012148269481398523, Recall = 0.07555555555555556, Aging Rate = 0.00015908494340553139, Precision = 0.85, f1 = 0.13877551020408163\n",
      "Epoch 29: Train Loss = 0.0120923954212153, Recall = 0.07111111111111111, Aging Rate = 0.0001511306962352548, Precision = 0.8421052631578947, f1 = 0.13114754098360656\n",
      "Epoch 30: Train Loss = 0.012005061756431665, Recall = 0.06222222222222222, Aging Rate = 0.00014317644906497825, Precision = 0.7777777777777778, f1 = 0.11522633744855967\n",
      "Test Loss = 0.011513824042375581, Recall = 0.0, Aging Rate = 0.0, precision = 0\n",
      "\n",
      "Epoch 31: Train Loss = 0.01205025182293741, Recall = 0.06666666666666667, Aging Rate = 0.00014317644906497825, Precision = 0.8333333333333334, f1 = 0.1234567901234568\n",
      "Epoch 32: Train Loss = 0.011722053782635388, Recall = 0.10666666666666667, Aging Rate = 0.00021476467359746737, Precision = 0.8888888888888888, f1 = 0.19047619047619047\n",
      "Epoch 33: Train Loss = 0.01184385972274837, Recall = 0.05333333333333334, Aging Rate = 0.00011135946038387196, Precision = 0.8571428571428571, f1 = 0.100418410041841\n",
      "Epoch 34: Train Loss = 0.011653735811531035, Recall = 0.06666666666666667, Aging Rate = 0.00013522220189470167, Precision = 0.8823529411764706, f1 = 0.12396694214876033\n",
      "Epoch 35: Train Loss = 0.011655225001869007, Recall = 0.1111111111111111, Aging Rate = 0.00022271892076774393, Precision = 0.8928571428571429, f1 = 0.1976284584980237\n",
      "Test Loss = 0.0109495868701578, Recall = 0.13777777777777778, Aging Rate = 0.0002863528981299565, precision = 0.8611111111111112\n",
      "\n",
      "Epoch 36: Train Loss = 0.011550967788749771, Recall = 0.07555555555555556, Aging Rate = 0.0001511306962352548, Precision = 0.8947368421052632, f1 = 0.13934426229508196\n",
      "Epoch 37: Train Loss = 0.011560215248134166, Recall = 0.08444444444444445, Aging Rate = 0.00019090193208663766, Precision = 0.7916666666666666, f1 = 0.15261044176706828\n",
      "Epoch 38: Train Loss = 0.011511320867107077, Recall = 0.08, Aging Rate = 0.00019885617925691424, Precision = 0.72, f1 = 0.14400000000000002\n",
      "Epoch 39: Train Loss = 0.011335682601269043, Recall = 0.09333333333333334, Aging Rate = 0.00019885617925691424, Precision = 0.84, f1 = 0.16799999999999998\n",
      "Epoch 40: Train Loss = 0.011300231048955929, Recall = 0.08888888888888889, Aging Rate = 0.00019090193208663766, Precision = 0.8333333333333334, f1 = 0.1606425702811245\n",
      "Test Loss = 0.01041995807887162, Recall = 0.10222222222222223, Aging Rate = 0.0001829476849163611, precision = 1.0\n",
      "Model in epoch 40 is saved.\n",
      "\n",
      "Epoch 41: Train Loss = 0.011329921365816852, Recall = 0.10222222222222223, Aging Rate = 0.00022271892076774393, Precision = 0.8214285714285714, f1 = 0.18181818181818182\n",
      "Epoch 42: Train Loss = 0.011313515677081469, Recall = 0.09777777777777778, Aging Rate = 0.00019090193208663766, Precision = 0.9166666666666666, f1 = 0.17670682730923695\n",
      "Epoch 43: Train Loss = 0.011141019024011191, Recall = 0.12, Aging Rate = 0.0002306731679380205, Precision = 0.9310344827586207, f1 = 0.21259842519685038\n",
      "Epoch 44: Train Loss = 0.011250680991017682, Recall = 0.07555555555555556, Aging Rate = 0.00017499343774608452, Precision = 0.7727272727272727, f1 = 0.13765182186234817\n",
      "Epoch 45: Train Loss = 0.01116102792812584, Recall = 0.07111111111111111, Aging Rate = 0.0001511306962352548, Precision = 0.8421052631578947, f1 = 0.13114754098360656\n",
      "Test Loss = 0.010810035802841468, Recall = 0.19555555555555557, Aging Rate = 0.00042952934719493475, precision = 0.8148148148148148\n",
      "\n",
      "Epoch 46: Train Loss = 0.01112588060769789, Recall = 0.09333333333333334, Aging Rate = 0.0002068104264271908, Precision = 0.8076923076923077, f1 = 0.16733067729083664\n",
      "Epoch 47: Train Loss = 0.011143972340310648, Recall = 0.08, Aging Rate = 0.00019090193208663766, Precision = 0.75, f1 = 0.14457831325301204\n",
      "Epoch 48: Train Loss = 0.011088803483665274, Recall = 0.08444444444444445, Aging Rate = 0.00019090193208663766, Precision = 0.7916666666666666, f1 = 0.15261044176706828\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49: Train Loss = 0.011149011709412427, Recall = 0.10222222222222223, Aging Rate = 0.00019885617925691424, Precision = 0.92, f1 = 0.184\n",
      "Epoch 50: Train Loss = 0.011074689705700762, Recall = 0.09777777777777778, Aging Rate = 0.00019885617925691424, Precision = 0.88, f1 = 0.17600000000000002\n",
      "Test Loss = 0.010435103389796448, Recall = 0.12, Aging Rate = 0.00023862741510829706, precision = 0.9\n",
      "\n",
      "Epoch 51: Train Loss = 0.011147823415428549, Recall = 0.08888888888888889, Aging Rate = 0.0001829476849163611, Precision = 0.8695652173913043, f1 = 0.16129032258064516\n",
      "Epoch 52: Train Loss = 0.01106458327376642, Recall = 0.08, Aging Rate = 0.00015908494340553139, Precision = 0.9, f1 = 0.1469387755102041\n",
      "Epoch 53: Train Loss = 0.011065964532510136, Recall = 0.10222222222222223, Aging Rate = 0.00021476467359746737, Precision = 0.8518518518518519, f1 = 0.18253968253968256\n",
      "Epoch 54: Train Loss = 0.011055683975096575, Recall = 0.10666666666666667, Aging Rate = 0.00022271892076774393, Precision = 0.8571428571428571, f1 = 0.18972332015810278\n",
      "Epoch 55: Train Loss = 0.01116899009412153, Recall = 0.08444444444444445, Aging Rate = 0.00015908494340553139, Precision = 0.95, f1 = 0.15510204081632653\n",
      "Test Loss = 0.010245323471644774, Recall = 0.13333333333333333, Aging Rate = 0.00027044440378940334, precision = 0.8823529411764706\n",
      "\n",
      "Epoch 56: Train Loss = 0.011041583686537904, Recall = 0.08444444444444445, Aging Rate = 0.00016703919057580794, Precision = 0.9047619047619048, f1 = 0.15447154471544716\n",
      "Epoch 57: Train Loss = 0.010958597143296491, Recall = 0.10222222222222223, Aging Rate = 0.0002068104264271908, Precision = 0.8846153846153846, f1 = 0.18326693227091634\n",
      "Epoch 58: Train Loss = 0.010985838409968507, Recall = 0.08888888888888889, Aging Rate = 0.00019090193208663766, Precision = 0.8333333333333334, f1 = 0.1606425702811245\n",
      "Epoch 59: Train Loss = 0.011053822078447701, Recall = 0.09777777777777778, Aging Rate = 0.0002068104264271908, Precision = 0.8461538461538461, f1 = 0.17529880478087653\n",
      "Epoch 60: Train Loss = 0.010974677598286131, Recall = 0.08888888888888889, Aging Rate = 0.0002068104264271908, Precision = 0.7692307692307693, f1 = 0.1593625498007968\n",
      "Test Loss = 0.010294656698142276, Recall = 0.08, Aging Rate = 0.00014317644906497825, precision = 1.0\n",
      "\n",
      "Epoch 61: Train Loss = 0.010872254305511675, Recall = 0.10222222222222223, Aging Rate = 0.00022271892076774393, Precision = 0.8214285714285714, f1 = 0.18181818181818182\n",
      "Epoch 62: Train Loss = 0.010962600645034733, Recall = 0.09777777777777778, Aging Rate = 0.00019885617925691424, Precision = 0.88, f1 = 0.17600000000000002\n",
      "Epoch 63: Train Loss = 0.01080938910053775, Recall = 0.08888888888888889, Aging Rate = 0.00019090193208663766, Precision = 0.8333333333333334, f1 = 0.1606425702811245\n",
      "Epoch 64: Train Loss = 0.01096496409797171, Recall = 0.09777777777777778, Aging Rate = 0.00022271892076774393, Precision = 0.7857142857142857, f1 = 0.17391304347826086\n",
      "Epoch 65: Train Loss = 0.010915963994693136, Recall = 0.09333333333333334, Aging Rate = 0.00019885617925691424, Precision = 0.84, f1 = 0.16799999999999998\n",
      "Test Loss = 0.010463788913948953, Recall = 0.20444444444444446, Aging Rate = 0.0003977123585138285, precision = 0.92\n",
      "\n",
      "Epoch 66: Train Loss = 0.010890293475495895, Recall = 0.08888888888888889, Aging Rate = 0.00017499343774608452, Precision = 0.9090909090909091, f1 = 0.1619433198380567\n",
      "Epoch 67: Train Loss = 0.0108761007057505, Recall = 0.10222222222222223, Aging Rate = 0.00021476467359746737, Precision = 0.8518518518518519, f1 = 0.18253968253968256\n",
      "Epoch 68: Train Loss = 0.010949460309285912, Recall = 0.08444444444444445, Aging Rate = 0.00019885617925691424, Precision = 0.76, f1 = 0.152\n",
      "Epoch 69: Train Loss = 0.01095329369675787, Recall = 0.09777777777777778, Aging Rate = 0.00022271892076774393, Precision = 0.7857142857142857, f1 = 0.17391304347826086\n",
      "Epoch 70: Train Loss = 0.011015315906116402, Recall = 0.06666666666666667, Aging Rate = 0.00013522220189470167, Precision = 0.8823529411764706, f1 = 0.12396694214876033\n",
      "Test Loss = 0.010091269604189034, Recall = 0.13333333333333333, Aging Rate = 0.00027839865095967994, precision = 0.8571428571428571\n",
      "\n",
      "Epoch 71: Train Loss = 0.010865688181325814, Recall = 0.09333333333333334, Aging Rate = 0.0002306731679380205, Precision = 0.7241379310344828, f1 = 0.16535433070866143\n",
      "Epoch 72: Train Loss = 0.010890004086160992, Recall = 0.08, Aging Rate = 0.00015908494340553139, Precision = 0.9, f1 = 0.1469387755102041\n",
      "Epoch 73: Train Loss = 0.010841525955013451, Recall = 0.09333333333333334, Aging Rate = 0.0001829476849163611, Precision = 0.9130434782608695, f1 = 0.16935483870967744\n",
      "Epoch 74: Train Loss = 0.010806867950507056, Recall = 0.08888888888888889, Aging Rate = 0.00017499343774608452, Precision = 0.9090909090909091, f1 = 0.1619433198380567\n",
      "Epoch 75: Train Loss = 0.010871517455591959, Recall = 0.10222222222222223, Aging Rate = 0.00021476467359746737, Precision = 0.8518518518518519, f1 = 0.18253968253968256\n",
      "Test Loss = 0.010058359220599012, Recall = 0.08, Aging Rate = 0.00014317644906497825, precision = 1.0\n",
      "\n",
      "Epoch 76: Train Loss = 0.010864884947586341, Recall = 0.1111111111111111, Aging Rate = 0.0002306731679380205, Precision = 0.8620689655172413, f1 = 0.19685039370078738\n",
      "Epoch 77: Train Loss = 0.010879860411290163, Recall = 0.09333333333333334, Aging Rate = 0.00023862741510829706, Precision = 0.7, f1 = 0.16470588235294115\n",
      "Epoch 78: Train Loss = 0.01087386425968132, Recall = 0.07555555555555556, Aging Rate = 0.00019090193208663766, Precision = 0.7083333333333334, f1 = 0.13654618473895583\n",
      "Epoch 79: Train Loss = 0.01086889115713206, Recall = 0.08888888888888889, Aging Rate = 0.00016703919057580794, Precision = 0.9523809523809523, f1 = 0.1626016260162602\n",
      "Epoch 80: Train Loss = 0.010717779051575211, Recall = 0.1111111111111111, Aging Rate = 0.0002306731679380205, Precision = 0.8620689655172413, f1 = 0.19685039370078738\n",
      "Test Loss = 0.01054231823902466, Recall = 0.2222222222222222, Aging Rate = 0.0005090718188977005, precision = 0.78125\n",
      "\n",
      "Epoch 81: Train Loss = 0.010828394813047046, Recall = 0.08, Aging Rate = 0.00016703919057580794, Precision = 0.8571428571428571, f1 = 0.14634146341463417\n",
      "Epoch 82: Train Loss = 0.010858804806487467, Recall = 0.09777777777777778, Aging Rate = 0.00019885617925691424, Precision = 0.88, f1 = 0.17600000000000002\n",
      "Epoch 83: Train Loss = 0.01078561420706459, Recall = 0.09777777777777778, Aging Rate = 0.0002068104264271908, Precision = 0.8461538461538461, f1 = 0.17529880478087653\n",
      "Epoch 84: Train Loss = 0.010813347097551936, Recall = 0.07111111111111111, Aging Rate = 0.00016703919057580794, Precision = 0.7619047619047619, f1 = 0.13008130081300812\n",
      "Epoch 85: Train Loss = 0.010679527792720047, Recall = 0.09333333333333334, Aging Rate = 0.00019885617925691424, Precision = 0.84, f1 = 0.16799999999999998\n",
      "Test Loss = 0.0098922543293785, Recall = 0.10666666666666667, Aging Rate = 0.00019885617925691424, precision = 0.96\n",
      "\n",
      "Epoch 86: Train Loss = 0.010664579044947754, Recall = 0.08888888888888889, Aging Rate = 0.00019090193208663766, Precision = 0.8333333333333334, f1 = 0.1606425702811245\n",
      "Epoch 87: Train Loss = 0.01070887774579091, Recall = 0.10222222222222223, Aging Rate = 0.00019885617925691424, Precision = 0.92, f1 = 0.184\n",
      "Epoch 88: Train Loss = 0.010725812177081646, Recall = 0.08888888888888889, Aging Rate = 0.00019090193208663766, Precision = 0.8333333333333334, f1 = 0.1606425702811245\n",
      "Epoch 89: Train Loss = 0.010678760440809997, Recall = 0.09333333333333334, Aging Rate = 0.0002068104264271908, Precision = 0.8076923076923077, f1 = 0.16733067729083664\n",
      "Epoch 90: Train Loss = 0.010668944557909735, Recall = 0.09777777777777778, Aging Rate = 0.0002068104264271908, Precision = 0.8461538461538461, f1 = 0.17529880478087653\n",
      "Test Loss = 0.009951939594602898, Recall = 0.07111111111111111, Aging Rate = 0.00012726795472442511, precision = 1.0\n",
      "\n",
      "Training Finished at epoch 90.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ddc00ece358a4c32b2402d865d1b516d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss = 0.026043540579661063, Recall = 0.0, Aging Rate = 0.0010101893906251244, Precision = 0.0, f1 = 0\n",
      "Epoch 2: Train Loss = 0.018687527132074548, Recall = 0.0, Aging Rate = 0.0, Precision = 0, f1 = 0\n",
      "Epoch 3: Train Loss = 0.018568971496566496, Recall = 0.0, Aging Rate = 0.0, Precision = 0, f1 = 0\n",
      "Epoch 4: Train Loss = 0.018310445876006266, Recall = 0.0, Aging Rate = 0.0, Precision = 0, f1 = 0\n",
      "Epoch 5: Train Loss = 0.018037590474121255, Recall = 0.0, Aging Rate = 0.0, Precision = 0, f1 = 0\n",
      "Test Loss = 0.016955757722448908, Recall = 0.0, Aging Rate = 0.0, precision = 0\n",
      "\n",
      "Epoch 6: Train Loss = 0.01744078325995924, Recall = 0.0, Aging Rate = 0.0, Precision = 0, f1 = 0\n",
      "Epoch 7: Train Loss = 0.01719370542118906, Recall = 0.0, Aging Rate = 0.0, Precision = 0, f1 = 0\n",
      "Epoch 8: Train Loss = 0.01662064911084144, Recall = 0.0, Aging Rate = 7.95424717027657e-06, Precision = 0.0, f1 = 0\n",
      "Epoch 9: Train Loss = 0.015959462705988324, Recall = 0.008888888888888889, Aging Rate = 1.590849434055314e-05, Precision = 0, f1 = 0.0\n",
      "Epoch 10: Train Loss = 0.015492759623039087, Recall = 0.013333333333333334, Aging Rate = 3.9771235851382846e-05, Precision = 0.6, f1 = 0.026086956521739132\n",
      "Test Loss = 0.015599128402436978, Recall = 0.044444444444444446, Aging Rate = 8.749671887304226e-05, precision = 0.9090909090909091\n",
      "Model in epoch 10 is saved.\n",
      "\n",
      "Epoch 11: Train Loss = 0.014824624951117985, Recall = 0.022222222222222223, Aging Rate = 5.567973019193598e-05, Precision = 0.7142857142857143, f1 = 0.04310344827586207\n",
      "Epoch 12: Train Loss = 0.014627552601472431, Recall = 0.02666666666666667, Aging Rate = 5.567973019193598e-05, Precision = 0.8571428571428571, f1 = 0.05172413793103449\n",
      "Epoch 13: Train Loss = 0.014104276088646985, Recall = 0.044444444444444446, Aging Rate = 8.749671887304226e-05, Precision = 0.9090909090909091, f1 = 0.08474576271186442\n",
      "Epoch 14: Train Loss = 0.013796730333855589, Recall = 0.03111111111111111, Aging Rate = 7.954247170276569e-05, Precision = 0.7, f1 = 0.05957446808510638\n",
      "Epoch 15: Train Loss = 0.013295173974789944, Recall = 0.02666666666666667, Aging Rate = 7.158822453248912e-05, Precision = 0.6666666666666666, f1 = 0.05128205128205129\n",
      "Test Loss = 0.012751052019159968, Recall = 0.022222222222222223, Aging Rate = 3.9771235851382846e-05, precision = 1.0\n",
      "Model in epoch 15 is saved.\n",
      "\n",
      "Epoch 16: Train Loss = 0.013107775169820958, Recall = 0.044444444444444446, Aging Rate = 0.0001034052132135954, Precision = 0.7692307692307693, f1 = 0.08403361344537816\n",
      "Epoch 17: Train Loss = 0.012925069753311232, Recall = 0.04, Aging Rate = 9.545096604331883e-05, Precision = 0.75, f1 = 0.07594936708860758\n",
      "Epoch 18: Train Loss = 0.012532855149664556, Recall = 0.044444444444444446, Aging Rate = 0.00011931370755414853, Precision = 0.6666666666666666, f1 = 0.08333333333333334\n",
      "Epoch 19: Train Loss = 0.012299878421857164, Recall = 0.057777777777777775, Aging Rate = 0.00011135946038387196, Precision = 0.9285714285714286, f1 = 0.10878661087866108\n",
      "Epoch 20: Train Loss = 0.012229387811441025, Recall = 0.06222222222222222, Aging Rate = 0.00014317644906497825, Precision = 0.7777777777777778, f1 = 0.11522633744855967\n",
      "Test Loss = 0.011283440592888197, Recall = 0.044444444444444446, Aging Rate = 7.954247170276569e-05, precision = 1.0\n",
      "Model in epoch 20 is saved.\n",
      "\n",
      "Epoch 21: Train Loss = 0.01189364691839808, Recall = 0.057777777777777775, Aging Rate = 0.0001511306962352548, Precision = 0.6842105263157895, f1 = 0.10655737704918032\n",
      "Epoch 22: Train Loss = 0.011679394172867993, Recall = 0.04888888888888889, Aging Rate = 0.00013522220189470167, Precision = 0.6470588235294118, f1 = 0.09090909090909091\n",
      "Epoch 23: Train Loss = 0.011403742095301648, Recall = 0.07555555555555556, Aging Rate = 0.00015908494340553139, Precision = 0.85, f1 = 0.13877551020408163\n",
      "Epoch 24: Train Loss = 0.01113774737703649, Recall = 0.07555555555555556, Aging Rate = 0.0001511306962352548, Precision = 0.8947368421052632, f1 = 0.13934426229508196\n",
      "Epoch 25: Train Loss = 0.010990536141777963, Recall = 0.09333333333333334, Aging Rate = 0.00021476467359746737, Precision = 0.7777777777777778, f1 = 0.16666666666666666\n",
      "Test Loss = 0.010413887196592508, Recall = 0.0, Aging Rate = 0.0, precision = 0\n",
      "\n",
      "Epoch 26: Train Loss = 0.010821224035180186, Recall = 0.08444444444444445, Aging Rate = 0.00019885617925691424, Precision = 0.76, f1 = 0.152\n",
      "Epoch 27: Train Loss = 0.010768421991172285, Recall = 0.08888888888888889, Aging Rate = 0.0001829476849163611, Precision = 0.8695652173913043, f1 = 0.16129032258064516\n",
      "Epoch 28: Train Loss = 0.010585775153714639, Recall = 0.10222222222222223, Aging Rate = 0.00021476467359746737, Precision = 0.8518518518518519, f1 = 0.18253968253968256\n",
      "Epoch 29: Train Loss = 0.0104037722709891, Recall = 0.08, Aging Rate = 0.00021476467359746737, Precision = 0.6666666666666666, f1 = 0.14285714285714285\n",
      "Epoch 30: Train Loss = 0.010314299364255732, Recall = 0.10222222222222223, Aging Rate = 0.00019885617925691424, Precision = 0.92, f1 = 0.184\n",
      "Test Loss = 0.010101532394922874, Recall = 0.1511111111111111, Aging Rate = 0.0003420326283218925, precision = 0.7906976744186046\n",
      "\n",
      "Epoch 31: Train Loss = 0.010216572463839942, Recall = 0.08888888888888889, Aging Rate = 0.00019885617925691424, Precision = 0.8, f1 = 0.15999999999999998\n",
      "Epoch 32: Train Loss = 0.010088071613008532, Recall = 0.10222222222222223, Aging Rate = 0.0002624901566191268, Precision = 0.696969696969697, f1 = 0.17829457364341086\n",
      "Epoch 33: Train Loss = 0.009973263547442665, Recall = 0.08444444444444445, Aging Rate = 0.00021476467359746737, Precision = 0.7037037037037037, f1 = 0.1507936507936508\n",
      "Epoch 34: Train Loss = 0.009756806963079711, Recall = 0.10666666666666667, Aging Rate = 0.00022271892076774393, Precision = 0.8571428571428571, f1 = 0.18972332015810278\n",
      "Epoch 35: Train Loss = 0.009848866744479212, Recall = 0.13777777777777778, Aging Rate = 0.00029430714530023305, Precision = 0.8378378378378378, f1 = 0.23664122137404578\n",
      "Test Loss = 0.009342309842027729, Recall = 0.022222222222222223, Aging Rate = 3.9771235851382846e-05, precision = 1.0\n",
      "\n",
      "Epoch 36: Train Loss = 0.009721665736216346, Recall = 0.08444444444444445, Aging Rate = 0.0002068104264271908, Precision = 0.7307692307692307, f1 = 0.15139442231075698\n",
      "Epoch 37: Train Loss = 0.009670358630310669, Recall = 0.13333333333333333, Aging Rate = 0.00029430714530023305, Precision = 0.8108108108108109, f1 = 0.22900763358778628\n",
      "Epoch 38: Train Loss = 0.009679755730675166, Recall = 0.16, Aging Rate = 0.0003420326283218925, Precision = 0.8372093023255814, f1 = 0.26865671641791045\n",
      "Epoch 39: Train Loss = 0.009663585950402344, Recall = 0.09777777777777778, Aging Rate = 0.00022271892076774393, Precision = 0.7857142857142857, f1 = 0.17391304347826086\n",
      "Epoch 40: Train Loss = 0.00950200431173335, Recall = 0.10222222222222223, Aging Rate = 0.0002306731679380205, Precision = 0.7931034482758621, f1 = 0.18110236220472442\n",
      "Test Loss = 0.008541812295359219, Recall = 0.16444444444444445, Aging Rate = 0.00031816988681106277, precision = 0.925\n",
      "\n",
      "Epoch 41: Train Loss = 0.009476615120417177, Recall = 0.13777777777777778, Aging Rate = 0.0003102156396407862, Precision = 0.7948717948717948, f1 = 0.23484848484848483\n",
      "Epoch 42: Train Loss = 0.009566070218388924, Recall = 0.10666666666666667, Aging Rate = 0.00023862741510829706, Precision = 0.8, f1 = 0.18823529411764706\n",
      "Epoch 43: Train Loss = 0.009455790042735987, Recall = 0.11555555555555555, Aging Rate = 0.0002624901566191268, Precision = 0.7878787878787878, f1 = 0.20155038759689922\n",
      "Epoch 44: Train Loss = 0.009331499013352916, Recall = 0.1111111111111111, Aging Rate = 0.00025453590944885023, Precision = 0.78125, f1 = 0.19455252918287935\n",
      "Epoch 45: Train Loss = 0.009382804796446103, Recall = 0.13333333333333333, Aging Rate = 0.00027839865095967994, Precision = 0.8571428571428571, f1 = 0.23076923076923078\n",
      "Test Loss = 0.008766184956243848, Recall = 0.21777777777777776, Aging Rate = 0.00045339208870576447, precision = 0.8596491228070176\n",
      "\n",
      "Epoch 46: Train Loss = 0.009360213741510151, Recall = 0.1288888888888889, Aging Rate = 0.0002863528981299565, Precision = 0.8055555555555556, f1 = 0.22222222222222224\n",
      "Epoch 47: Train Loss = 0.009384909797164144, Recall = 0.09777777777777778, Aging Rate = 0.00019885617925691424, Precision = 0.88, f1 = 0.17600000000000002\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 48: Train Loss = 0.009175541793226142, Recall = 0.14222222222222222, Aging Rate = 0.0003022613924705096, Precision = 0.8421052631578947, f1 = 0.24334600760456274\n",
      "Epoch 49: Train Loss = 0.009270586533205729, Recall = 0.13333333333333333, Aging Rate = 0.00029430714530023305, Precision = 0.8108108108108109, f1 = 0.22900763358778628\n",
      "Epoch 50: Train Loss = 0.009170370718166395, Recall = 0.11555555555555555, Aging Rate = 0.00027044440378940334, Precision = 0.7647058823529411, f1 = 0.20077220077220076\n",
      "Test Loss = 0.009230528171489474, Recall = 0.30666666666666664, Aging Rate = 0.0006442940207924021, precision = 0.8518518518518519\n",
      "\n",
      "Epoch 51: Train Loss = 0.009110361862997933, Recall = 0.13333333333333333, Aging Rate = 0.00027044440378940334, Precision = 0.8823529411764706, f1 = 0.23166023166023167\n",
      "Epoch 52: Train Loss = 0.009222232410289013, Recall = 0.13777777777777778, Aging Rate = 0.0003022613924705096, Precision = 0.8157894736842105, f1 = 0.23574144486692014\n",
      "Epoch 53: Train Loss = 0.009221111927646259, Recall = 0.10666666666666667, Aging Rate = 0.0002306731679380205, Precision = 0.8275862068965517, f1 = 0.18897637795275593\n",
      "Epoch 54: Train Loss = 0.009152199324539525, Recall = 0.13777777777777778, Aging Rate = 0.0003022613924705096, Precision = 0.8157894736842105, f1 = 0.23574144486692014\n",
      "Epoch 55: Train Loss = 0.00920967735241094, Recall = 0.11555555555555555, Aging Rate = 0.0002306731679380205, Precision = 0.896551724137931, f1 = 0.20472440944881887\n",
      "Test Loss = 0.008529477051336332, Recall = 0.08444444444444445, Aging Rate = 0.00019885617925691424, precision = 0.76\n",
      "\n",
      "Epoch 56: Train Loss = 0.00916732444960185, Recall = 0.1288888888888889, Aging Rate = 0.0003022613924705096, Precision = 0.7631578947368421, f1 = 0.22053231939163495\n",
      "Epoch 57: Train Loss = 0.009069080258950373, Recall = 0.12, Aging Rate = 0.00025453590944885023, Precision = 0.84375, f1 = 0.2101167315175097\n",
      "Epoch 58: Train Loss = 0.008973192698053845, Recall = 0.12, Aging Rate = 0.0002465816622785736, Precision = 0.8709677419354839, f1 = 0.21093749999999997\n",
      "Epoch 59: Train Loss = 0.009046681660492143, Recall = 0.1511111111111111, Aging Rate = 0.0003102156396407862, Precision = 0.8717948717948718, f1 = 0.25757575757575757\n",
      "Epoch 60: Train Loss = 0.009116574477256553, Recall = 0.08888888888888889, Aging Rate = 0.00019090193208663766, Precision = 0.8333333333333334, f1 = 0.1606425702811245\n",
      "Test Loss = 0.008234733943941589, Recall = 0.08444444444444445, Aging Rate = 0.00017499343774608452, precision = 0.8636363636363636\n",
      "\n",
      "Epoch 61: Train Loss = 0.009056156664365532, Recall = 0.13333333333333333, Aging Rate = 0.0003261241339813393, Precision = 0.7317073170731707, f1 = 0.2255639097744361\n",
      "Epoch 62: Train Loss = 0.008938532956186816, Recall = 0.1288888888888889, Aging Rate = 0.00025453590944885023, Precision = 0.90625, f1 = 0.22568093385214008\n",
      "Epoch 63: Train Loss = 0.009073339531887293, Recall = 0.14222222222222222, Aging Rate = 0.0003022613924705096, Precision = 0.8421052631578947, f1 = 0.24334600760456274\n",
      "Epoch 64: Train Loss = 0.00924567102183671, Recall = 0.1111111111111111, Aging Rate = 0.0002624901566191268, Precision = 0.7575757575757576, f1 = 0.19379844961240308\n",
      "Epoch 65: Train Loss = 0.008958151116464348, Recall = 0.1288888888888889, Aging Rate = 0.0002624901566191268, Precision = 0.8787878787878788, f1 = 0.22480620155038758\n",
      "Test Loss = 0.008243047985868678, Recall = 0.21777777777777776, Aging Rate = 0.00044543784153548786, precision = 0.875\n",
      "\n",
      "Epoch 66: Train Loss = 0.008958194742709645, Recall = 0.13777777777777778, Aging Rate = 0.00025453590944885023, Precision = 0.96875, f1 = 0.2412451361867704\n",
      "Epoch 67: Train Loss = 0.00898988512180405, Recall = 0.09333333333333334, Aging Rate = 0.00022271892076774393, Precision = 0.75, f1 = 0.16600790513833993\n",
      "Epoch 68: Train Loss = 0.00884882059161302, Recall = 0.13333333333333333, Aging Rate = 0.0002863528981299565, Precision = 0.8333333333333334, f1 = 0.2298850574712644\n",
      "Epoch 69: Train Loss = 0.009020841651439925, Recall = 0.12, Aging Rate = 0.00027044440378940334, Precision = 0.7941176470588235, f1 = 0.2084942084942085\n",
      "Epoch 70: Train Loss = 0.008946396988685075, Recall = 0.11555555555555555, Aging Rate = 0.00027044440378940334, Precision = 0.7647058823529411, f1 = 0.20077220077220076\n",
      "Test Loss = 0.008067342255037118, Recall = 0.2222222222222222, Aging Rate = 0.00042157510002465814, precision = 0.9433962264150944\n",
      "Model in epoch 70 is saved.\n",
      "\n",
      "Epoch 71: Train Loss = 0.00887083694651111, Recall = 0.1511111111111111, Aging Rate = 0.0002863528981299565, Precision = 0.9444444444444444, f1 = 0.26053639846743293\n",
      "Epoch 72: Train Loss = 0.008940461744731992, Recall = 0.12444444444444444, Aging Rate = 0.00029430714530023305, Precision = 0.7567567567567568, f1 = 0.21374045801526717\n",
      "Epoch 73: Train Loss = 0.008844147523842242, Recall = 0.13333333333333333, Aging Rate = 0.0002863528981299565, Precision = 0.8333333333333334, f1 = 0.2298850574712644\n",
      "Epoch 74: Train Loss = 0.008745756387322735, Recall = 0.14666666666666667, Aging Rate = 0.0003340783811516159, Precision = 0.7857142857142857, f1 = 0.24719101123595508\n",
      "Epoch 75: Train Loss = 0.008937700925821695, Recall = 0.13333333333333333, Aging Rate = 0.00029430714530023305, Precision = 0.8108108108108109, f1 = 0.22900763358778628\n",
      "Test Loss = 0.008263429521325572, Recall = 0.20444444444444446, Aging Rate = 0.00040566660568410503, precision = 0.9019607843137255\n",
      "\n",
      "Epoch 76: Train Loss = 0.008868567447518995, Recall = 0.1511111111111111, Aging Rate = 0.0003340783811516159, Precision = 0.8095238095238095, f1 = 0.2546816479400749\n",
      "Epoch 77: Train Loss = 0.008748200457024177, Recall = 0.13777777777777778, Aging Rate = 0.00027839865095967994, Precision = 0.8857142857142857, f1 = 0.23846153846153845\n",
      "Epoch 78: Train Loss = 0.00875771825552462, Recall = 0.14666666666666667, Aging Rate = 0.0003022613924705096, Precision = 0.868421052631579, f1 = 0.2509505703422053\n",
      "Epoch 79: Train Loss = 0.008793059812794192, Recall = 0.1511111111111111, Aging Rate = 0.00031816988681106277, Precision = 0.85, f1 = 0.25660377358490566\n",
      "Epoch 80: Train Loss = 0.008760563096107945, Recall = 0.1111111111111111, Aging Rate = 0.00027044440378940334, Precision = 0.7352941176470589, f1 = 0.19305019305019303\n",
      "Test Loss = 0.008236958600845615, Recall = 0.07555555555555556, Aging Rate = 0.0001511306962352548, precision = 0.8947368421052632\n",
      "\n",
      "Epoch 81: Train Loss = 0.008734863133994315, Recall = 0.14222222222222222, Aging Rate = 0.0003022613924705096, Precision = 0.8421052631578947, f1 = 0.24334600760456274\n",
      "Epoch 82: Train Loss = 0.008795423049792547, Recall = 0.13777777777777778, Aging Rate = 0.0003022613924705096, Precision = 0.8157894736842105, f1 = 0.23574144486692014\n",
      "Epoch 83: Train Loss = 0.00871663952408928, Recall = 0.1511111111111111, Aging Rate = 0.0003420326283218925, Precision = 0.7906976744186046, f1 = 0.2537313432835821\n",
      "Epoch 84: Train Loss = 0.008681364735715003, Recall = 0.1288888888888889, Aging Rate = 0.00027839865095967994, Precision = 0.8285714285714286, f1 = 0.22307692307692306\n",
      "Epoch 85: Train Loss = 0.008666147918569397, Recall = 0.1511111111111111, Aging Rate = 0.00031816988681106277, Precision = 0.85, f1 = 0.25660377358490566\n",
      "Test Loss = 0.007680302579228872, Recall = 0.16444444444444445, Aging Rate = 0.0003022613924705096, precision = 0.9736842105263158\n",
      "Model in epoch 85 is saved.\n",
      "\n",
      "Epoch 86: Train Loss = 0.008715815927465528, Recall = 0.12444444444444444, Aging Rate = 0.0002863528981299565, Precision = 0.7777777777777778, f1 = 0.21455938697318008\n",
      "Epoch 87: Train Loss = 0.008771853594375496, Recall = 0.12444444444444444, Aging Rate = 0.00029430714530023305, Precision = 0.7567567567567568, f1 = 0.21374045801526717\n",
      "Epoch 88: Train Loss = 0.008645074612406753, Recall = 0.13777777777777778, Aging Rate = 0.0003022613924705096, Precision = 0.8157894736842105, f1 = 0.23574144486692014\n",
      "Epoch 89: Train Loss = 0.008633779612472353, Recall = 0.13333333333333333, Aging Rate = 0.00027044440378940334, Precision = 0.8823529411764706, f1 = 0.23166023166023167\n",
      "Epoch 90: Train Loss = 0.008633891800807451, Recall = 0.13777777777777778, Aging Rate = 0.0002863528981299565, Precision = 0.8611111111111112, f1 = 0.23754789272030652\n",
      "Test Loss = 0.007951432745269608, Recall = 0.28, Aging Rate = 0.000572705796259913, precision = 0.875\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 91: Train Loss = 0.008592294703731617, Recall = 0.13777777777777778, Aging Rate = 0.00029430714530023305, Precision = 0.8378378378378378, f1 = 0.23664122137404578\n",
      "Epoch 92: Train Loss = 0.00863931171061969, Recall = 0.1511111111111111, Aging Rate = 0.0003340783811516159, Precision = 0.8095238095238095, f1 = 0.2546816479400749\n",
      "Epoch 93: Train Loss = 0.008627669968965534, Recall = 0.15555555555555556, Aging Rate = 0.0003261241339813393, Precision = 0.8536585365853658, f1 = 0.2631578947368421\n",
      "Epoch 94: Train Loss = 0.008606184806592173, Recall = 0.14666666666666667, Aging Rate = 0.00027839865095967994, Precision = 0.9428571428571428, f1 = 0.25384615384615383\n",
      "Epoch 95: Train Loss = 0.008553568132842398, Recall = 0.1288888888888889, Aging Rate = 0.00027839865095967994, Precision = 0.8285714285714286, f1 = 0.22307692307692306\n",
      "Test Loss = 0.00790936066658018, Recall = 0.1111111111111111, Aging Rate = 0.0002068104264271908, precision = 0.9615384615384616\n",
      "\n",
      "Epoch 96: Train Loss = 0.008628726081977595, Recall = 0.13333333333333333, Aging Rate = 0.00027839865095967994, Precision = 0.8571428571428571, f1 = 0.23076923076923078\n",
      "Epoch 97: Train Loss = 0.008563258521833275, Recall = 0.14666666666666667, Aging Rate = 0.00029430714530023305, Precision = 0.8918918918918919, f1 = 0.25190839694656486\n",
      "Epoch 98: Train Loss = 0.008629226939370032, Recall = 0.10666666666666667, Aging Rate = 0.0002068104264271908, Precision = 0.9230769230769231, f1 = 0.1912350597609562\n",
      "Epoch 99: Train Loss = 0.008501782319157762, Recall = 0.14666666666666667, Aging Rate = 0.00029430714530023305, Precision = 0.8918918918918919, f1 = 0.25190839694656486\n",
      "Epoch 100: Train Loss = 0.008563139184528447, Recall = 0.14666666666666667, Aging Rate = 0.00031816988681106277, Precision = 0.825, f1 = 0.2490566037735849\n",
      "Test Loss = 0.008422809299942519, Recall = 0.35555555555555557, Aging Rate = 0.0007317907396654444, precision = 0.8695652173913043\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b703a9a8900d48a38350eea17c883742",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss = 0.027422678690523353, Recall = 0.0, Aging Rate = 0.001734039676100479, Precision = 0.0, f1 = 0\n",
      "Epoch 2: Train Loss = 0.018469193991843377, Recall = 0.0, Aging Rate = 0.0, Precision = 0, f1 = 0\n",
      "Epoch 3: Train Loss = 0.01828676110521739, Recall = 0.0, Aging Rate = 0.0, Precision = 0, f1 = 0\n",
      "Epoch 4: Train Loss = 0.018424034429300625, Recall = 0.0, Aging Rate = 0.0, Precision = 0, f1 = 0\n",
      "Epoch 5: Train Loss = 0.01797275356462335, Recall = 0.0, Aging Rate = 0.0, Precision = 0, f1 = 0\n",
      "Test Loss = 0.01707962975029756, Recall = 0.0, Aging Rate = 0.0, precision = 0\n",
      "\n",
      "Epoch 6: Train Loss = 0.017392627076687525, Recall = 0.0, Aging Rate = 0.0, Precision = 0, f1 = 0\n",
      "Epoch 7: Train Loss = 0.017149629989965262, Recall = 0.0, Aging Rate = 0.0, Precision = 0, f1 = 0\n",
      "Epoch 8: Train Loss = 0.016685152838196587, Recall = 0.0044444444444444444, Aging Rate = 1.5908620881655768e-05, Precision = 0.5, f1 = 0.008810572687224669\n",
      "Epoch 9: Train Loss = 0.016153450756285454, Recall = 0.0, Aging Rate = 7.954310440827884e-06, Precision = 0.0, f1 = 0\n",
      "Epoch 10: Train Loss = 0.015605857179033056, Recall = 0.0044444444444444444, Aging Rate = 1.5908620881655768e-05, Precision = 0.5, f1 = 0.008810572687224669\n",
      "Test Loss = 0.01466334240678585, Recall = 0.022222222222222223, Aging Rate = 6.363448352662307e-05, precision = 0.625\n",
      "Model in epoch 10 is saved.\n",
      "\n",
      "Epoch 11: Train Loss = 0.015283275017027807, Recall = 0.008888888888888889, Aging Rate = 2.3862931322483654e-05, Precision = 0.6666666666666666, f1 = 0.01754385964912281\n",
      "Epoch 12: Train Loss = 0.014802471168046961, Recall = 0.017777777777777778, Aging Rate = 4.772586264496731e-05, Precision = 0.6666666666666666, f1 = 0.03463203463203463\n",
      "Epoch 13: Train Loss = 0.014549283858794742, Recall = 0.008888888888888889, Aging Rate = 4.772586264496731e-05, Precision = 0.3333333333333333, f1 = 0.017316017316017316\n",
      "Epoch 14: Train Loss = 0.014128552496376186, Recall = 0.008888888888888889, Aging Rate = 3.1817241763311536e-05, Precision = 0.5, f1 = 0.017467248908296946\n",
      "Epoch 15: Train Loss = 0.013768743434139953, Recall = 0.02666666666666667, Aging Rate = 7.158879396745097e-05, Precision = 0.6666666666666666, f1 = 0.05128205128205129\n",
      "Test Loss = 0.012947682560914145, Recall = 0.044444444444444446, Aging Rate = 0.00011136034617159038, precision = 0.7142857142857143\n",
      "Model in epoch 15 is saved.\n",
      "\n",
      "Epoch 16: Train Loss = 0.01380771393119412, Recall = 0.035555555555555556, Aging Rate = 0.0001034060357307625, Precision = 0.6153846153846154, f1 = 0.06722689075630252\n",
      "Epoch 17: Train Loss = 0.013413711447404825, Recall = 0.044444444444444446, Aging Rate = 9.545172528993462e-05, Precision = 0.8333333333333334, f1 = 0.08438818565400845\n",
      "Epoch 18: Train Loss = 0.013215070009794815, Recall = 0.03111111111111111, Aging Rate = 7.158879396745097e-05, Precision = 0.7777777777777778, f1 = 0.05982905982905983\n",
      "Epoch 19: Train Loss = 0.013054105927321853, Recall = 0.022222222222222223, Aging Rate = 5.568017308579519e-05, Precision = 0.7142857142857143, f1 = 0.04310344827586207\n",
      "Epoch 20: Train Loss = 0.012967503034197114, Recall = 0.04888888888888889, Aging Rate = 0.00011931465661241828, Precision = 0.7333333333333333, f1 = 0.09166666666666667\n",
      "Test Loss = 0.01211810790240855, Recall = 0.035555555555555556, Aging Rate = 8.749741484910673e-05, precision = 0.7272727272727273\n",
      "Model in epoch 20 is saved.\n",
      "\n",
      "Epoch 21: Train Loss = 0.012792774286789496, Recall = 0.04888888888888889, Aging Rate = 0.00014317758793490194, Precision = 0.6111111111111112, f1 = 0.09053497942386833\n",
      "Epoch 22: Train Loss = 0.012749531815858023, Recall = 0.035555555555555556, Aging Rate = 9.545172528993462e-05, Precision = 0.6666666666666666, f1 = 0.06751054852320675\n",
      "Epoch 23: Train Loss = 0.012482572457323886, Recall = 0.05333333333333334, Aging Rate = 0.00013522327749407404, Precision = 0.7058823529411765, f1 = 0.09917355371900827\n",
      "Epoch 24: Train Loss = 0.012591404319784257, Recall = 0.04, Aging Rate = 0.00011136034617159038, Precision = 0.6428571428571429, f1 = 0.07531380753138076\n",
      "Epoch 25: Train Loss = 0.012512608215239314, Recall = 0.02666666666666667, Aging Rate = 9.545172528993462e-05, Precision = 0.5, f1 = 0.05063291139240507\n",
      "Test Loss = 0.011567810049667846, Recall = 0.09333333333333334, Aging Rate = 0.000206812071461525, precision = 0.8076923076923077\n",
      "Model in epoch 25 is saved.\n",
      "\n",
      "Epoch 26: Train Loss = 0.012440454976997488, Recall = 0.03111111111111111, Aging Rate = 9.545172528993462e-05, Precision = 0.5833333333333334, f1 = 0.05907172995780591\n",
      "Epoch 27: Train Loss = 0.012275479735155153, Recall = 0.03111111111111111, Aging Rate = 0.0001034060357307625, Precision = 0.5384615384615384, f1 = 0.0588235294117647\n",
      "Epoch 28: Train Loss = 0.012360684735408375, Recall = 0.04, Aging Rate = 0.00013522327749407404, Precision = 0.5294117647058824, f1 = 0.07438016528925619\n",
      "Epoch 29: Train Loss = 0.012255262941802023, Recall = 0.05333333333333334, Aging Rate = 0.0001034060357307625, Precision = 0.9230769230769231, f1 = 0.10084033613445378\n",
      "Epoch 30: Train Loss = 0.012205331711245142, Recall = 0.02666666666666667, Aging Rate = 0.00011136034617159038, Precision = 0.42857142857142855, f1 = 0.0502092050209205\n",
      "Test Loss = 0.011249349142995876, Recall = 0.057777777777777775, Aging Rate = 0.0001511318983757298, precision = 0.6842105263157895\n",
      "\n",
      "Epoch 31: Train Loss = 0.012069584676815947, Recall = 0.035555555555555556, Aging Rate = 0.00011931465661241828, Precision = 0.5333333333333333, f1 = 0.06666666666666667\n",
      "Epoch 32: Train Loss = 0.012098455227157986, Recall = 0.044444444444444446, Aging Rate = 0.00011931465661241828, Precision = 0.6666666666666666, f1 = 0.08333333333333334\n",
      "Epoch 33: Train Loss = 0.012087495679782557, Recall = 0.04, Aging Rate = 0.0001034060357307625, Precision = 0.6923076923076923, f1 = 0.07563025210084033\n",
      "Epoch 34: Train Loss = 0.011938821424073223, Recall = 0.06222222222222222, Aging Rate = 0.0001590862088165577, Precision = 0.7, f1 = 0.11428571428571428\n",
      "Epoch 35: Train Loss = 0.012114183956055617, Recall = 0.044444444444444446, Aging Rate = 0.00011931465661241828, Precision = 0.6666666666666666, f1 = 0.08333333333333334\n",
      "Test Loss = 0.011158478632531532, Recall = 0.1288888888888889, Aging Rate = 0.000278400865428976, precision = 0.8285714285714286\n",
      "Model in epoch 35 is saved.\n",
      "\n",
      "Epoch 36: Train Loss = 0.01188161848436968, Recall = 0.07555555555555556, Aging Rate = 0.00016704051925738557, Precision = 0.8095238095238095, f1 = 0.13821138211382114\n",
      "Epoch 37: Train Loss = 0.01193267142362298, Recall = 0.06666666666666667, Aging Rate = 0.0001590862088165577, Precision = 0.75, f1 = 0.12244897959183675\n",
      "Epoch 38: Train Loss = 0.01190782970201596, Recall = 0.04888888888888889, Aging Rate = 0.00014317758793490194, Precision = 0.6111111111111112, f1 = 0.09053497942386833\n",
      "Epoch 39: Train Loss = 0.011860211285662614, Recall = 0.057777777777777775, Aging Rate = 0.00014317758793490194, Precision = 0.7222222222222222, f1 = 0.10699588477366255\n",
      "Epoch 40: Train Loss = 0.011809700768141737, Recall = 0.057777777777777775, Aging Rate = 0.00016704051925738557, Precision = 0.6190476190476191, f1 = 0.1056910569105691\n",
      "Test Loss = 0.0111019115629055, Recall = 0.057777777777777775, Aging Rate = 0.00014317758793490194, precision = 0.7222222222222222\n",
      "\n",
      "Epoch 41: Train Loss = 0.011835955176711373, Recall = 0.044444444444444446, Aging Rate = 0.00014317758793490194, Precision = 0.5555555555555556, f1 = 0.08230452674897121\n",
      "Epoch 42: Train Loss = 0.011792639865919245, Recall = 0.06666666666666667, Aging Rate = 0.00016704051925738557, Precision = 0.7142857142857143, f1 = 0.12195121951219512\n",
      "Epoch 43: Train Loss = 0.011845674189155192, Recall = 0.035555555555555556, Aging Rate = 0.00011136034617159038, Precision = 0.5714285714285714, f1 = 0.06694560669456068\n",
      "Epoch 44: Train Loss = 0.011855626098348209, Recall = 0.04, Aging Rate = 0.00012726896705324614, Precision = 0.5625, f1 = 0.07468879668049792\n",
      "Epoch 45: Train Loss = 0.011675315270256288, Recall = 0.05333333333333334, Aging Rate = 0.00012726896705324614, Precision = 0.75, f1 = 0.09958506224066391\n",
      "Test Loss = 0.011238468927759083, Recall = 0.06666666666666667, Aging Rate = 0.0001590862088165577, precision = 0.75\n",
      "\n",
      "Epoch 46: Train Loss = 0.011749620262156684, Recall = 0.057777777777777775, Aging Rate = 0.0001590862088165577, Precision = 0.65, f1 = 0.10612244897959183\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 47: Train Loss = 0.011852153284152603, Recall = 0.044444444444444446, Aging Rate = 0.00011931465661241828, Precision = 0.6666666666666666, f1 = 0.08333333333333334\n",
      "Epoch 48: Train Loss = 0.01168978923414519, Recall = 0.057777777777777775, Aging Rate = 0.00013522327749407404, Precision = 0.7647058823529411, f1 = 0.10743801652892561\n",
      "Epoch 49: Train Loss = 0.01177274796717761, Recall = 0.05333333333333334, Aging Rate = 0.00018294914013904133, Precision = 0.5217391304347826, f1 = 0.09677419354838711\n",
      "Epoch 50: Train Loss = 0.011774359986845905, Recall = 0.044444444444444446, Aging Rate = 0.00013522327749407404, Precision = 0.5882352941176471, f1 = 0.08264462809917356\n",
      "Test Loss = 0.01097980360928106, Recall = 0.07111111111111111, Aging Rate = 0.00017499482969821347, precision = 0.7272727272727273\n",
      "\n",
      "Epoch 51: Train Loss = 0.01173423172207027, Recall = 0.06222222222222222, Aging Rate = 0.00014317758793490194, Precision = 0.7777777777777778, f1 = 0.11522633744855967\n",
      "Epoch 52: Train Loss = 0.011830328695438342, Recall = 0.04, Aging Rate = 0.00011136034617159038, Precision = 0.6428571428571429, f1 = 0.07531380753138076\n",
      "Epoch 53: Train Loss = 0.01157875576282159, Recall = 0.04888888888888889, Aging Rate = 0.00014317758793490194, Precision = 0.6111111111111112, f1 = 0.09053497942386833\n",
      "Epoch 54: Train Loss = 0.011790073337453426, Recall = 0.05333333333333334, Aging Rate = 0.0001590862088165577, Precision = 0.6, f1 = 0.0979591836734694\n",
      "Epoch 55: Train Loss = 0.01181348074947832, Recall = 0.057777777777777775, Aging Rate = 0.0001511318983757298, Precision = 0.6842105263157895, f1 = 0.10655737704918032\n",
      "Test Loss = 0.011122689207487133, Recall = 0.10666666666666667, Aging Rate = 0.000278400865428976, precision = 0.6857142857142857\n",
      "\n",
      "Epoch 56: Train Loss = 0.011652133981706819, Recall = 0.04888888888888889, Aging Rate = 0.00014317758793490194, Precision = 0.6111111111111112, f1 = 0.09053497942386833\n",
      "Epoch 57: Train Loss = 0.011824570975516596, Recall = 0.06666666666666667, Aging Rate = 0.00019885776102069713, Precision = 0.6, f1 = 0.12000000000000001\n",
      "Epoch 58: Train Loss = 0.011715628433037762, Recall = 0.057777777777777775, Aging Rate = 0.00013522327749407404, Precision = 0.7647058823529411, f1 = 0.10743801652892561\n",
      "Epoch 59: Train Loss = 0.011746491350272713, Recall = 0.04888888888888889, Aging Rate = 0.0001590862088165577, Precision = 0.55, f1 = 0.08979591836734695\n",
      "Epoch 60: Train Loss = 0.011725586504625532, Recall = 0.044444444444444446, Aging Rate = 0.00012726896705324614, Precision = 0.625, f1 = 0.08298755186721993\n",
      "Test Loss = 0.01097085589196467, Recall = 0.017777777777777778, Aging Rate = 3.9771552204139425e-05, precision = 0.8\n",
      "\n",
      "Epoch 61: Train Loss = 0.01167316732257256, Recall = 0.04, Aging Rate = 0.00012726896705324614, Precision = 0.5625, f1 = 0.07468879668049792\n",
      "Epoch 62: Train Loss = 0.011731763749400236, Recall = 0.044444444444444446, Aging Rate = 0.00014317758793490194, Precision = 0.5555555555555556, f1 = 0.08230452674897121\n",
      "Epoch 63: Train Loss = 0.011667514865450928, Recall = 0.09333333333333334, Aging Rate = 0.00022272069234318076, Precision = 0.75, f1 = 0.16600790513833993\n",
      "Epoch 64: Train Loss = 0.011587378675178448, Recall = 0.057777777777777775, Aging Rate = 0.00016704051925738557, Precision = 0.6190476190476191, f1 = 0.1056910569105691\n",
      "Epoch 65: Train Loss = 0.011639504119144809, Recall = 0.035555555555555556, Aging Rate = 0.00011136034617159038, Precision = 0.5714285714285714, f1 = 0.06694560669456068\n",
      "Test Loss = 0.01088585569373429, Recall = 0.04, Aging Rate = 7.954310440827885e-05, precision = 0.9\n",
      "Model in epoch 65 is saved.\n",
      "\n",
      "Epoch 66: Train Loss = 0.01163980448877664, Recall = 0.04888888888888889, Aging Rate = 0.00011931465661241828, Precision = 0.7333333333333333, f1 = 0.09166666666666667\n",
      "Epoch 67: Train Loss = 0.011635745741192792, Recall = 0.07111111111111111, Aging Rate = 0.00017499482969821347, Precision = 0.7272727272727273, f1 = 0.12955465587044535\n",
      "Epoch 68: Train Loss = 0.011676073032048383, Recall = 0.044444444444444446, Aging Rate = 0.00013522327749407404, Precision = 0.5882352941176471, f1 = 0.08264462809917356\n",
      "Epoch 69: Train Loss = 0.011547279488381102, Recall = 0.06666666666666667, Aging Rate = 0.00018294914013904133, Precision = 0.6521739130434783, f1 = 0.12096774193548387\n",
      "Epoch 70: Train Loss = 0.011689186328488671, Recall = 0.07111111111111111, Aging Rate = 0.00018294914013904133, Precision = 0.6956521739130435, f1 = 0.12903225806451613\n",
      "Test Loss = 0.010798739865770278, Recall = 0.09333333333333334, Aging Rate = 0.00022272069234318076, precision = 0.75\n",
      "\n",
      "Epoch 71: Train Loss = 0.011638030764959388, Recall = 0.07111111111111111, Aging Rate = 0.00017499482969821347, Precision = 0.7272727272727273, f1 = 0.12955465587044535\n",
      "Epoch 72: Train Loss = 0.011691593407233547, Recall = 0.06222222222222222, Aging Rate = 0.00014317758793490194, Precision = 0.7777777777777778, f1 = 0.11522633744855967\n",
      "Epoch 73: Train Loss = 0.011782587838077108, Recall = 0.04888888888888889, Aging Rate = 0.0001511318983757298, Precision = 0.5789473684210527, f1 = 0.09016393442622951\n",
      "Epoch 74: Train Loss = 0.01168518879457347, Recall = 0.04888888888888889, Aging Rate = 0.00013522327749407404, Precision = 0.6470588235294118, f1 = 0.09090909090909091\n",
      "Epoch 75: Train Loss = 0.011716227172611449, Recall = 0.06222222222222222, Aging Rate = 0.00016704051925738557, Precision = 0.6666666666666666, f1 = 0.11382113821138212\n",
      "Test Loss = 0.01115049885750629, Recall = 0.057777777777777775, Aging Rate = 0.0001590862088165577, precision = 0.65\n",
      "\n",
      "Epoch 76: Train Loss = 0.011649444888414393, Recall = 0.04, Aging Rate = 0.00011931465661241828, Precision = 0.6, f1 = 0.075\n",
      "Epoch 77: Train Loss = 0.011612258089219772, Recall = 0.044444444444444446, Aging Rate = 0.00013522327749407404, Precision = 0.5882352941176471, f1 = 0.08264462809917356\n",
      "Epoch 78: Train Loss = 0.01169360309571293, Recall = 0.02666666666666667, Aging Rate = 0.00013522327749407404, Precision = 0.35294117647058826, f1 = 0.049586776859504134\n",
      "Epoch 79: Train Loss = 0.011671419759377744, Recall = 0.06666666666666667, Aging Rate = 0.00019885776102069713, Precision = 0.6, f1 = 0.12000000000000001\n",
      "Epoch 80: Train Loss = 0.01152251772688762, Recall = 0.05333333333333334, Aging Rate = 0.00013522327749407404, Precision = 0.7058823529411765, f1 = 0.09917355371900827\n",
      "Test Loss = 0.011038731492148455, Recall = 0.10222222222222223, Aging Rate = 0.0003181724176331154, precision = 0.575\n",
      "\n",
      "Epoch 81: Train Loss = 0.01171781932366571, Recall = 0.04888888888888889, Aging Rate = 0.00019885776102069713, Precision = 0.44, f1 = 0.08800000000000001\n",
      "Epoch 82: Train Loss = 0.011604282047341043, Recall = 0.06666666666666667, Aging Rate = 0.00016704051925738557, Precision = 0.7142857142857143, f1 = 0.12195121951219512\n",
      "Epoch 83: Train Loss = 0.011665260187080058, Recall = 0.06666666666666667, Aging Rate = 0.00017499482969821347, Precision = 0.6818181818181818, f1 = 0.1214574898785425\n",
      "Epoch 84: Train Loss = 0.011497908307457698, Recall = 0.04, Aging Rate = 0.00012726896705324614, Precision = 0.5625, f1 = 0.07468879668049792\n",
      "Epoch 85: Train Loss = 0.011528079203076715, Recall = 0.07111111111111111, Aging Rate = 0.00018294914013904133, Precision = 0.6956521739130435, f1 = 0.12903225806451613\n",
      "Test Loss = 0.010991217352004123, Recall = 0.022222222222222223, Aging Rate = 4.772586264496731e-05, precision = 0.8333333333333334\n",
      "\n",
      "Epoch 86: Train Loss = 0.011659128587129017, Recall = 0.05333333333333334, Aging Rate = 0.0001511318983757298, Precision = 0.631578947368421, f1 = 0.09836065573770492\n",
      "Epoch 87: Train Loss = 0.011627108680048967, Recall = 0.04888888888888889, Aging Rate = 0.00014317758793490194, Precision = 0.6111111111111112, f1 = 0.09053497942386833\n",
      "Epoch 88: Train Loss = 0.011725467241198106, Recall = 0.05333333333333334, Aging Rate = 0.0001511318983757298, Precision = 0.631578947368421, f1 = 0.09836065573770492\n",
      "Epoch 89: Train Loss = 0.01159585940614637, Recall = 0.06222222222222222, Aging Rate = 0.0001511318983757298, Precision = 0.7368421052631579, f1 = 0.11475409836065574\n",
      "Epoch 90: Train Loss = 0.011711783857432262, Recall = 0.05333333333333334, Aging Rate = 0.00012726896705324614, Precision = 0.75, f1 = 0.09958506224066391\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss = 0.01074336099550201, Recall = 0.07111111111111111, Aging Rate = 0.0001590862088165577, precision = 0.8\n",
      "\n",
      "Epoch 91: Train Loss = 0.011593940579617323, Recall = 0.06666666666666667, Aging Rate = 0.0001590862088165577, Precision = 0.75, f1 = 0.12244897959183675\n",
      "Epoch 92: Train Loss = 0.01160039860537498, Recall = 0.05333333333333334, Aging Rate = 0.0001511318983757298, Precision = 0.631578947368421, f1 = 0.09836065573770492\n",
      "Epoch 93: Train Loss = 0.011587004456151271, Recall = 0.08, Aging Rate = 0.00019090345057986923, Precision = 0.75, f1 = 0.14457831325301204\n",
      "Epoch 94: Train Loss = 0.011615419339666677, Recall = 0.05333333333333334, Aging Rate = 0.00014317758793490194, Precision = 0.6666666666666666, f1 = 0.09876543209876544\n",
      "Epoch 95: Train Loss = 0.011565868095931955, Recall = 0.057777777777777775, Aging Rate = 0.0001590862088165577, Precision = 0.65, f1 = 0.10612244897959183\n",
      "Test Loss = 0.010729812297279599, Recall = 0.07111111111111111, Aging Rate = 0.0001590862088165577, precision = 0.8\n",
      "\n",
      "Epoch 96: Train Loss = 0.011520092238631674, Recall = 0.06222222222222222, Aging Rate = 0.0001511318983757298, Precision = 0.7368421052631579, f1 = 0.11475409836065574\n",
      "Epoch 97: Train Loss = 0.01154731601252295, Recall = 0.05333333333333334, Aging Rate = 0.0001511318983757298, Precision = 0.631578947368421, f1 = 0.09836065573770492\n",
      "Epoch 98: Train Loss = 0.011497251684289176, Recall = 0.044444444444444446, Aging Rate = 0.00011931465661241828, Precision = 0.6666666666666666, f1 = 0.08333333333333334\n",
      "Epoch 99: Train Loss = 0.011472723924382025, Recall = 0.044444444444444446, Aging Rate = 0.00012726896705324614, Precision = 0.625, f1 = 0.08298755186721993\n",
      "Epoch 100: Train Loss = 0.011491537488615974, Recall = 0.06666666666666667, Aging Rate = 0.00018294914013904133, Precision = 0.6521739130434783, f1 = 0.12096774193548387\n",
      "Test Loss = 0.011203064902935427, Recall = 0.16444444444444445, Aging Rate = 0.00037385259071891057, precision = 0.7872340425531915\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f2230add66641f8ab093e996c5f8eb9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss = 0.027971775007050656, Recall = 0.0, Aging Rate = 0.0026885355435534806, Precision = 0.0, f1 = 0\n",
      "Epoch 2: Train Loss = 0.018671651295454696, Recall = 0.0, Aging Rate = 0.0, Precision = 0, f1 = 0\n",
      "Epoch 3: Train Loss = 0.018325288499988247, Recall = 0.0, Aging Rate = 0.0, Precision = 0, f1 = 0\n",
      "Epoch 4: Train Loss = 0.018342689597700027, Recall = 0.0, Aging Rate = 0.0, Precision = 0, f1 = 0\n",
      "Epoch 5: Train Loss = 0.018339894016811086, Recall = 0.0, Aging Rate = 0.0, Precision = 0, f1 = 0\n",
      "Test Loss = 0.017246754483874506, Recall = 0.0, Aging Rate = 0.0, precision = 0\n",
      "\n",
      "Epoch 6: Train Loss = 0.017595100130449865, Recall = 0.0, Aging Rate = 0.0, Precision = 0, f1 = 0\n",
      "Epoch 7: Train Loss = 0.01708072482181767, Recall = 0.0, Aging Rate = 0.0, Precision = 0, f1 = 0\n",
      "Epoch 8: Train Loss = 0.016405131051244467, Recall = 0.0, Aging Rate = 0.0, Precision = 0, f1 = 0\n",
      "Epoch 9: Train Loss = 0.016033380494084298, Recall = 0.0, Aging Rate = 0.0, Precision = 0, f1 = 0\n",
      "Epoch 10: Train Loss = 0.015247410524016297, Recall = 0.008888888888888889, Aging Rate = 1.590849434055314e-05, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.014271519094018597, Recall = 0.0, Aging Rate = 0.0, precision = 0\n",
      "\n",
      "Epoch 11: Train Loss = 0.014624403750880975, Recall = 0.0044444444444444444, Aging Rate = 7.95424717027657e-06, Precision = 0, f1 = 0.0\n",
      "Epoch 12: Train Loss = 0.01430704659439813, Recall = 0.013333333333333334, Aging Rate = 2.3862741510829707e-05, Precision = 0, f1 = 0.0\n",
      "Epoch 13: Train Loss = 0.013797430034481114, Recall = 0.017777777777777778, Aging Rate = 3.181698868110628e-05, Precision = 0, f1 = 0.0\n",
      "Epoch 14: Train Loss = 0.013479626920105346, Recall = 0.03111111111111111, Aging Rate = 5.567973019193598e-05, Precision = 0, f1 = 0.0\n",
      "Epoch 15: Train Loss = 0.013129403807297864, Recall = 0.03111111111111111, Aging Rate = 7.158822453248912e-05, Precision = 0.7777777777777778, f1 = 0.05982905982905983\n",
      "Test Loss = 0.012158819643007508, Recall = 0.04888888888888889, Aging Rate = 8.749671887304226e-05, precision = 1.0\n",
      "Model in epoch 15 is saved.\n",
      "\n",
      "Epoch 16: Train Loss = 0.012941095862166527, Recall = 0.04, Aging Rate = 0.0001034052132135954, Precision = 0.6923076923076923, f1 = 0.07563025210084033\n",
      "Epoch 17: Train Loss = 0.012668388546823207, Recall = 0.035555555555555556, Aging Rate = 7.954247170276569e-05, Precision = 0.8, f1 = 0.06808510638297872\n",
      "Epoch 18: Train Loss = 0.01247950325567808, Recall = 0.057777777777777775, Aging Rate = 0.00011931370755414853, Precision = 0.8666666666666667, f1 = 0.10833333333333334\n",
      "Epoch 19: Train Loss = 0.012246139706476806, Recall = 0.04888888888888889, Aging Rate = 0.00011931370755414853, Precision = 0.7333333333333333, f1 = 0.09166666666666667\n",
      "Epoch 20: Train Loss = 0.012244599070485859, Recall = 0.04888888888888889, Aging Rate = 0.00011135946038387196, Precision = 0.7857142857142857, f1 = 0.09205020920502092\n",
      "Test Loss = 0.011213556141360877, Recall = 0.07111111111111111, Aging Rate = 0.00012726795472442511, precision = 1.0\n",
      "Model in epoch 20 is saved.\n",
      "\n",
      "Epoch 21: Train Loss = 0.012060091004142084, Recall = 0.05333333333333334, Aging Rate = 9.545096604331883e-05, Precision = 0, f1 = 0.0\n",
      "Epoch 22: Train Loss = 0.011957563103152592, Recall = 0.05333333333333334, Aging Rate = 0.00013522220189470167, Precision = 0.7058823529411765, f1 = 0.09917355371900827\n",
      "Epoch 23: Train Loss = 0.011802098454669608, Recall = 0.06222222222222222, Aging Rate = 0.00012726795472442511, Precision = 0.875, f1 = 0.11618257261410789\n",
      "Epoch 24: Train Loss = 0.011737258546311049, Recall = 0.05333333333333334, Aging Rate = 0.00011931370755414853, Precision = 0.8, f1 = 0.1\n",
      "Epoch 25: Train Loss = 0.011698395498646022, Recall = 0.08444444444444445, Aging Rate = 0.0001829476849163611, Precision = 0.8260869565217391, f1 = 0.1532258064516129\n",
      "Test Loss = 0.010866908361864425, Recall = 0.08444444444444445, Aging Rate = 0.0001511306962352548, precision = 1.0\n",
      "Model in epoch 25 is saved.\n",
      "\n",
      "Epoch 26: Train Loss = 0.011704035431764535, Recall = 0.06666666666666667, Aging Rate = 0.00013522220189470167, Precision = 0.8823529411764706, f1 = 0.12396694214876033\n",
      "Epoch 27: Train Loss = 0.011538533659111228, Recall = 0.07111111111111111, Aging Rate = 0.0001511306962352548, Precision = 0.8421052631578947, f1 = 0.13114754098360656\n",
      "Epoch 28: Train Loss = 0.01140985249187399, Recall = 0.06222222222222222, Aging Rate = 0.00017499343774608452, Precision = 0.6363636363636364, f1 = 0.11336032388663968\n",
      "Epoch 29: Train Loss = 0.011449362216050498, Recall = 0.08, Aging Rate = 0.0001829476849163611, Precision = 0.782608695652174, f1 = 0.14516129032258066\n",
      "Epoch 30: Train Loss = 0.011376979682554876, Recall = 0.08, Aging Rate = 0.0001829476849163611, Precision = 0.782608695652174, f1 = 0.14516129032258066\n",
      "Test Loss = 0.010870822480902162, Recall = 0.013333333333333334, Aging Rate = 2.3862741510829707e-05, precision = 1.0\n",
      "\n",
      "Epoch 31: Train Loss = 0.011280787798494028, Recall = 0.08444444444444445, Aging Rate = 0.00019090193208663766, Precision = 0.7916666666666666, f1 = 0.15261044176706828\n",
      "Epoch 32: Train Loss = 0.011231901044422966, Recall = 0.10666666666666667, Aging Rate = 0.00019885617925691424, Precision = 0.96, f1 = 0.192\n",
      "Epoch 33: Train Loss = 0.011212426195425427, Recall = 0.09333333333333334, Aging Rate = 0.0001829476849163611, Precision = 0.9130434782608695, f1 = 0.16935483870967744\n",
      "Epoch 34: Train Loss = 0.011136461892486972, Recall = 0.1111111111111111, Aging Rate = 0.00022271892076774393, Precision = 0.8928571428571429, f1 = 0.1976284584980237\n",
      "Epoch 35: Train Loss = 0.011172401454210393, Recall = 0.06222222222222222, Aging Rate = 0.00015908494340553139, Precision = 0.7, f1 = 0.11428571428571428\n",
      "Test Loss = 0.010225130791145813, Recall = 0.13777777777777778, Aging Rate = 0.00025453590944885023, precision = 0.96875\n",
      "\n",
      "Epoch 36: Train Loss = 0.01099995658681984, Recall = 0.06222222222222222, Aging Rate = 0.00013522220189470167, Precision = 0.8235294117647058, f1 = 0.11570247933884296\n",
      "Epoch 37: Train Loss = 0.011002403802312018, Recall = 0.10222222222222223, Aging Rate = 0.00021476467359746737, Precision = 0.8518518518518519, f1 = 0.18253968253968256\n",
      "Epoch 38: Train Loss = 0.01106201920415613, Recall = 0.07555555555555556, Aging Rate = 0.0001511306962352548, Precision = 0.8947368421052632, f1 = 0.13934426229508196\n",
      "Epoch 39: Train Loss = 0.01094640208784239, Recall = 0.10666666666666667, Aging Rate = 0.00019885617925691424, Precision = 0.96, f1 = 0.192\n",
      "Epoch 40: Train Loss = 0.010953238981834411, Recall = 0.08444444444444445, Aging Rate = 0.00017499343774608452, Precision = 0.8636363636363636, f1 = 0.15384615384615385\n",
      "Test Loss = 0.010002733485513837, Recall = 0.13777777777777778, Aging Rate = 0.00025453590944885023, precision = 0.96875\n",
      "\n",
      "Epoch 41: Train Loss = 0.010874975646685221, Recall = 0.09777777777777778, Aging Rate = 0.0002068104264271908, Precision = 0.8461538461538461, f1 = 0.17529880478087653\n",
      "Epoch 42: Train Loss = 0.010855075213036306, Recall = 0.07555555555555556, Aging Rate = 0.00014317644906497825, Precision = 0.9444444444444444, f1 = 0.139917695473251\n",
      "Epoch 43: Train Loss = 0.010962420479753345, Recall = 0.09333333333333334, Aging Rate = 0.00019885617925691424, Precision = 0.84, f1 = 0.16799999999999998\n",
      "Epoch 44: Train Loss = 0.010813564494477288, Recall = 0.10666666666666667, Aging Rate = 0.00021476467359746737, Precision = 0.8888888888888888, f1 = 0.19047619047619047\n",
      "Epoch 45: Train Loss = 0.0107325358589386, Recall = 0.10222222222222223, Aging Rate = 0.0002068104264271908, Precision = 0.8846153846153846, f1 = 0.18326693227091634\n",
      "Test Loss = 0.010092736216710639, Recall = 0.06666666666666667, Aging Rate = 0.00011931370755414853, precision = 1.0\n",
      "\n",
      "Epoch 46: Train Loss = 0.010767618597916069, Recall = 0.10666666666666667, Aging Rate = 0.00021476467359746737, Precision = 0.8888888888888888, f1 = 0.19047619047619047\n",
      "Epoch 47: Train Loss = 0.010838660233254636, Recall = 0.09777777777777778, Aging Rate = 0.0002068104264271908, Precision = 0.8461538461538461, f1 = 0.17529880478087653\n",
      "Epoch 48: Train Loss = 0.010773313191032575, Recall = 0.09333333333333334, Aging Rate = 0.00022271892076774393, Precision = 0.75, f1 = 0.16600790513833993\n",
      "Epoch 49: Train Loss = 0.01068901001481426, Recall = 0.07555555555555556, Aging Rate = 0.00017499343774608452, Precision = 0.7727272727272727, f1 = 0.13765182186234817\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50: Train Loss = 0.010675944507995017, Recall = 0.10666666666666667, Aging Rate = 0.00021476467359746737, Precision = 0.8888888888888888, f1 = 0.19047619047619047\n",
      "Test Loss = 0.01000555896618627, Recall = 0.19111111111111112, Aging Rate = 0.0003658953698327222, precision = 0.9347826086956522\n",
      "\n",
      "Epoch 51: Train Loss = 0.010609652897203578, Recall = 0.1111111111111111, Aging Rate = 0.00023862741510829706, Precision = 0.8333333333333334, f1 = 0.19607843137254902\n",
      "Epoch 52: Train Loss = 0.010653240360441409, Recall = 0.10666666666666667, Aging Rate = 0.00021476467359746737, Precision = 0.8888888888888888, f1 = 0.19047619047619047\n",
      "Epoch 53: Train Loss = 0.010611526555331704, Recall = 0.09333333333333334, Aging Rate = 0.0001829476849163611, Precision = 0.9130434782608695, f1 = 0.16935483870967744\n",
      "Epoch 54: Train Loss = 0.01050891580116625, Recall = 0.12, Aging Rate = 0.00027839865095967994, Precision = 0.7714285714285715, f1 = 0.20769230769230768\n",
      "Epoch 55: Train Loss = 0.0105424426028686, Recall = 0.09777777777777778, Aging Rate = 0.0002068104264271908, Precision = 0.8461538461538461, f1 = 0.17529880478087653\n",
      "Test Loss = 0.009863716845740117, Recall = 0.13777777777777778, Aging Rate = 0.00027044440378940334, precision = 0.9117647058823529\n",
      "\n",
      "Epoch 56: Train Loss = 0.010538553809891112, Recall = 0.10666666666666667, Aging Rate = 0.0002306731679380205, Precision = 0.8275862068965517, f1 = 0.18897637795275593\n",
      "Epoch 57: Train Loss = 0.01050598548963595, Recall = 0.09333333333333334, Aging Rate = 0.00019885617925691424, Precision = 0.84, f1 = 0.16799999999999998\n",
      "Epoch 58: Train Loss = 0.010513013147382705, Recall = 0.12, Aging Rate = 0.0002306731679380205, Precision = 0.9310344827586207, f1 = 0.21259842519685038\n",
      "Epoch 59: Train Loss = 0.010470605410121632, Recall = 0.11555555555555555, Aging Rate = 0.00023862741510829706, Precision = 0.8666666666666667, f1 = 0.20392156862745098\n",
      "Epoch 60: Train Loss = 0.010479379737736614, Recall = 0.10222222222222223, Aging Rate = 0.0002465816622785736, Precision = 0.7419354838709677, f1 = 0.1796875\n",
      "Test Loss = 0.010097630509890088, Recall = 0.057777777777777775, Aging Rate = 0.0001034052132135954, precision = 1.0\n",
      "\n",
      "Epoch 61: Train Loss = 0.01053036267052431, Recall = 0.12, Aging Rate = 0.00022271892076774393, Precision = 0.9642857142857143, f1 = 0.2134387351778656\n",
      "Epoch 62: Train Loss = 0.010504957424439895, Recall = 0.11555555555555555, Aging Rate = 0.0002465816622785736, Precision = 0.8387096774193549, f1 = 0.203125\n",
      "Epoch 63: Train Loss = 0.010376621975741013, Recall = 0.12444444444444444, Aging Rate = 0.00027044440378940334, Precision = 0.8235294117647058, f1 = 0.2162162162162162\n",
      "Epoch 64: Train Loss = 0.01054757613641363, Recall = 0.09777777777777778, Aging Rate = 0.0002068104264271908, Precision = 0.8461538461538461, f1 = 0.17529880478087653\n",
      "Epoch 65: Train Loss = 0.010381247836077879, Recall = 0.13333333333333333, Aging Rate = 0.0002624901566191268, Precision = 0.9090909090909091, f1 = 0.2325581395348837\n",
      "Test Loss = 0.00969385346779379, Recall = 0.09777777777777778, Aging Rate = 0.0002068104264271908, precision = 0.8461538461538461\n",
      "\n",
      "Epoch 66: Train Loss = 0.010491536294121803, Recall = 0.12444444444444444, Aging Rate = 0.0002465816622785736, Precision = 0.9032258064516129, f1 = 0.21875\n",
      "Epoch 67: Train Loss = 0.010374315635552177, Recall = 0.09333333333333334, Aging Rate = 0.00019090193208663766, Precision = 0.875, f1 = 0.1686746987951807\n",
      "Epoch 68: Train Loss = 0.010437165458695073, Recall = 0.12, Aging Rate = 0.00023862741510829706, Precision = 0.9, f1 = 0.21176470588235294\n",
      "Epoch 69: Train Loss = 0.010422198092132982, Recall = 0.09777777777777778, Aging Rate = 0.0001829476849163611, Precision = 0.9565217391304348, f1 = 0.17741935483870971\n",
      "Epoch 70: Train Loss = 0.010358095714568066, Recall = 0.12444444444444444, Aging Rate = 0.0002306731679380205, Precision = 0.9655172413793104, f1 = 0.2204724409448819\n",
      "Test Loss = 0.009741248765004767, Recall = 0.13777777777777778, Aging Rate = 0.0002624901566191268, precision = 0.9393939393939394\n",
      "\n",
      "Epoch 71: Train Loss = 0.010327284789982667, Recall = 0.1111111111111111, Aging Rate = 0.0002306731679380205, Precision = 0.8620689655172413, f1 = 0.19685039370078738\n",
      "Epoch 72: Train Loss = 0.010448883812668865, Recall = 0.12444444444444444, Aging Rate = 0.00025453590944885023, Precision = 0.875, f1 = 0.21789883268482488\n",
      "Epoch 73: Train Loss = 0.010513321296562564, Recall = 0.09777777777777778, Aging Rate = 0.00019885617925691424, Precision = 0.88, f1 = 0.17600000000000002\n",
      "Epoch 74: Train Loss = 0.010368425537260697, Recall = 0.1111111111111111, Aging Rate = 0.0002068104264271908, Precision = 0.9615384615384616, f1 = 0.199203187250996\n",
      "Epoch 75: Train Loss = 0.010313304114864606, Recall = 0.11555555555555555, Aging Rate = 0.0002624901566191268, Precision = 0.7878787878787878, f1 = 0.20155038759689922\n",
      "Test Loss = 0.009530524582628522, Recall = 0.13777777777777778, Aging Rate = 0.0002624901566191268, precision = 0.9393939393939394\n",
      "\n",
      "Training Finished at epoch 75.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "77db93e3ed0f4a58b9906a47c8fc0248",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss = 0.028369524009733558, Recall = 0.013392857142857142, Aging Rate = 0.0032374301009410024, Precision = 0.007371007371007371, f1 = 0.009508716323296355\n",
      "Epoch 2: Train Loss = 0.018636956198817233, Recall = 0.0, Aging Rate = 0.0, Precision = 0, f1 = 0\n",
      "Epoch 3: Train Loss = 0.018571004048979416, Recall = 0.0, Aging Rate = 0.0, Precision = 0, f1 = 0\n",
      "Epoch 4: Train Loss = 0.018302950342792553, Recall = 0.0, Aging Rate = 0.0, Precision = 0, f1 = 0\n",
      "Epoch 5: Train Loss = 0.018320054712572184, Recall = 0.0, Aging Rate = 0.0, Precision = 0, f1 = 0\n",
      "Test Loss = 0.017346506620164612, Recall = 0.0, Aging Rate = 0.0, precision = 0\n",
      "\n",
      "Epoch 6: Train Loss = 0.01767455448894668, Recall = 0.0, Aging Rate = 0.0, Precision = 0, f1 = 0\n",
      "Epoch 7: Train Loss = 0.017439071628267726, Recall = 0.0, Aging Rate = 0.0, Precision = 0, f1 = 0\n",
      "Epoch 8: Train Loss = 0.016963956426242217, Recall = 0.0, Aging Rate = 0.0, Precision = 0, f1 = 0\n",
      "Epoch 9: Train Loss = 0.016483812523113525, Recall = 0.0, Aging Rate = 0.0, Precision = 0, f1 = 0\n",
      "Epoch 10: Train Loss = 0.016043870326125316, Recall = 0.0, Aging Rate = 0.0, Precision = 0, f1 = 0\n",
      "Test Loss = 0.01532420119636953, Recall = 0.0, Aging Rate = 0.0, precision = 0\n",
      "\n",
      "Epoch 11: Train Loss = 0.01563471026765332, Recall = 0.0, Aging Rate = 0.0, Precision = 0, f1 = 0\n",
      "Epoch 12: Train Loss = 0.015295186369800345, Recall = 0.0, Aging Rate = 0.0, Precision = 0, f1 = 0\n",
      "Epoch 13: Train Loss = 0.01478930986859854, Recall = 0.013392857142857142, Aging Rate = 2.3863121137157266e-05, Precision = 0, f1 = 0.0\n",
      "Epoch 14: Train Loss = 0.01462288388598517, Recall = 0.004464285714285714, Aging Rate = 1.590874742477151e-05, Precision = 0.5, f1 = 0.008849557522123894\n",
      "Epoch 15: Train Loss = 0.01443539325739655, Recall = 0.008928571428571428, Aging Rate = 2.3863121137157266e-05, Precision = 0.6666666666666666, f1 = 0.01762114537444934\n",
      "Test Loss = 0.013506181826101832, Recall = 0.0, Aging Rate = 0.0, precision = 0\n",
      "\n",
      "Epoch 16: Train Loss = 0.014067867421033005, Recall = 0.004464285714285714, Aging Rate = 1.590874742477151e-05, Precision = 0.5, f1 = 0.008849557522123894\n",
      "Epoch 17: Train Loss = 0.013847270167445252, Recall = 0.017857142857142856, Aging Rate = 4.772624227431453e-05, Precision = 0.6666666666666666, f1 = 0.034782608695652174\n",
      "Epoch 18: Train Loss = 0.01376362862312198, Recall = 0.013392857142857142, Aging Rate = 3.9771868561928776e-05, Precision = 0.6, f1 = 0.026200873362445417\n",
      "Epoch 19: Train Loss = 0.013580716197277057, Recall = 0.026785714285714284, Aging Rate = 5.568061598670029e-05, Precision = 0.8571428571428571, f1 = 0.051948051948051945\n",
      "Epoch 20: Train Loss = 0.013452788248866985, Recall = 0.022321428571428572, Aging Rate = 7.15893634114718e-05, Precision = 0.5555555555555556, f1 = 0.04291845493562232\n",
      "Test Loss = 0.012788429879495076, Recall = 0.03571428571428571, Aging Rate = 7.15893634114718e-05, precision = 0.8888888888888888\n",
      "Model in epoch 20 is saved.\n",
      "\n",
      "Epoch 21: Train Loss = 0.013311255010037302, Recall = 0.013392857142857142, Aging Rate = 6.363498969908604e-05, Precision = 0.375, f1 = 0.025862068965517238\n",
      "Epoch 22: Train Loss = 0.013226241734669604, Recall = 0.026785714285714284, Aging Rate = 6.363498969908604e-05, Precision = 0.75, f1 = 0.051724137931034475\n",
      "Epoch 23: Train Loss = 0.012955870097275045, Recall = 0.04017857142857143, Aging Rate = 0.00010340685826101482, Precision = 0.6923076923076923, f1 = 0.07594936708860761\n",
      "Epoch 24: Train Loss = 0.013085854499308816, Recall = 0.026785714285714284, Aging Rate = 7.15893634114718e-05, Precision = 0.6666666666666666, f1 = 0.05150214592274678\n",
      "Epoch 25: Train Loss = 0.013006788150390068, Recall = 0.022321428571428572, Aging Rate = 7.15893634114718e-05, Precision = 0.5555555555555556, f1 = 0.04291845493562232\n",
      "Test Loss = 0.012191380164432846, Recall = 0.05803571428571429, Aging Rate = 0.0001431787268229436, precision = 0.7222222222222222\n",
      "\n",
      "Epoch 26: Train Loss = 0.012898616395954186, Recall = 0.04017857142857143, Aging Rate = 0.00011136123197340058, Precision = 0.6428571428571429, f1 = 0.07563025210084034\n",
      "Epoch 27: Train Loss = 0.012850160061909576, Recall = 0.03571428571428571, Aging Rate = 9.545248454862907e-05, Precision = 0.6666666666666666, f1 = 0.06779661016949153\n",
      "Epoch 28: Train Loss = 0.012720662995039867, Recall = 0.04017857142857143, Aging Rate = 0.00010340685826101482, Precision = 0.6923076923076923, f1 = 0.07594936708860761\n",
      "Epoch 29: Train Loss = 0.012736395532568556, Recall = 0.017857142857142856, Aging Rate = 6.363498969908604e-05, Precision = 0.5, f1 = 0.03448275862068965\n",
      "Epoch 30: Train Loss = 0.012744018926895011, Recall = 0.017857142857142856, Aging Rate = 7.15893634114718e-05, Precision = 0.4444444444444444, f1 = 0.034334763948497854\n",
      "Test Loss = 0.011841267843625842, Recall = 0.03571428571428571, Aging Rate = 7.15893634114718e-05, precision = 0.8888888888888888\n",
      "\n",
      "Epoch 31: Train Loss = 0.012639101554881, Recall = 0.03571428571428571, Aging Rate = 9.545248454862907e-05, Precision = 0.6666666666666666, f1 = 0.06779661016949153\n",
      "Epoch 32: Train Loss = 0.012532349572165738, Recall = 0.03571428571428571, Aging Rate = 7.15893634114718e-05, Precision = 0.8888888888888888, f1 = 0.06866952789699571\n",
      "Epoch 33: Train Loss = 0.012539199049287481, Recall = 0.017857142857142856, Aging Rate = 5.568061598670029e-05, Precision = 0.5714285714285714, f1 = 0.034632034632034625\n",
      "Epoch 34: Train Loss = 0.012567004983697854, Recall = 0.044642857142857144, Aging Rate = 0.00011931560568578633, Precision = 0.6666666666666666, f1 = 0.08368200836820085\n",
      "Epoch 35: Train Loss = 0.012423463288816713, Recall = 0.03571428571428571, Aging Rate = 9.545248454862907e-05, Precision = 0.6666666666666666, f1 = 0.06779661016949153\n",
      "Test Loss = 0.011687529964915054, Recall = 0.017857142857142856, Aging Rate = 3.181749484954302e-05, precision = 1.0\n",
      "Model in epoch 35 is saved.\n",
      "\n",
      "Epoch 36: Train Loss = 0.012541148965589192, Recall = 0.03125, Aging Rate = 7.954373712385755e-05, Precision = 0.7, f1 = 0.05982905982905983\n",
      "Epoch 37: Train Loss = 0.012468831794604255, Recall = 0.03125, Aging Rate = 8.749811083624331e-05, Precision = 0.6363636363636364, f1 = 0.059574468085106386\n",
      "Epoch 38: Train Loss = 0.012426153006681442, Recall = 0.049107142857142856, Aging Rate = 0.00012726997939817208, Precision = 0.6875, f1 = 0.09166666666666666\n",
      "Epoch 39: Train Loss = 0.012378018946993618, Recall = 0.03571428571428571, Aging Rate = 7.15893634114718e-05, Precision = 0.8888888888888888, f1 = 0.06866952789699571\n",
      "Epoch 40: Train Loss = 0.012392511894267167, Recall = 0.03571428571428571, Aging Rate = 0.00010340685826101482, Precision = 0.6153846153846154, f1 = 0.06751054852320676\n",
      "Test Loss = 0.011672516470085374, Recall = 0.017857142857142856, Aging Rate = 3.9771868561928776e-05, precision = 0.8\n",
      "\n",
      "Epoch 41: Train Loss = 0.012391400600718624, Recall = 0.04017857142857143, Aging Rate = 0.00011136123197340058, Precision = 0.6428571428571429, f1 = 0.07563025210084034\n",
      "Epoch 42: Train Loss = 0.012344147007855851, Recall = 0.05357142857142857, Aging Rate = 0.00010340685826101482, Precision = 0.9230769230769231, f1 = 0.10126582278481011\n",
      "Epoch 43: Train Loss = 0.012360641615462261, Recall = 0.044642857142857144, Aging Rate = 0.00011931560568578633, Precision = 0.6666666666666666, f1 = 0.08368200836820085\n",
      "Epoch 44: Train Loss = 0.012220846251731528, Recall = 0.0625, Aging Rate = 0.00016704184796010086, Precision = 0.6666666666666666, f1 = 0.11428571428571428\n",
      "Epoch 45: Train Loss = 0.012352022336375902, Recall = 0.03571428571428571, Aging Rate = 8.749811083624331e-05, Precision = 0.7272727272727273, f1 = 0.06808510638297872\n",
      "Test Loss = 0.011783819050562652, Recall = 0.10714285714285714, Aging Rate = 0.0002465855850839584, precision = 0.7741935483870968\n",
      "\n",
      "Epoch 46: Train Loss = 0.012200864404827554, Recall = 0.044642857142857144, Aging Rate = 0.00012726997939817208, Precision = 0.625, f1 = 0.08333333333333334\n",
      "Epoch 47: Train Loss = 0.012133969263201694, Recall = 0.049107142857142856, Aging Rate = 0.00012726997939817208, Precision = 0.6875, f1 = 0.09166666666666666\n",
      "Epoch 48: Train Loss = 0.01218789731621358, Recall = 0.05357142857142857, Aging Rate = 0.0001431787268229436, Precision = 0.6666666666666666, f1 = 0.09917355371900825\n",
      "Epoch 49: Train Loss = 0.012213367595050394, Recall = 0.04017857142857143, Aging Rate = 9.545248454862907e-05, Precision = 0.75, f1 = 0.07627118644067798\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50: Train Loss = 0.012151569961744553, Recall = 0.044642857142857144, Aging Rate = 0.00010340685826101482, Precision = 0.7692307692307693, f1 = 0.08438818565400845\n",
      "Test Loss = 0.011510143739237547, Recall = 0.03571428571428571, Aging Rate = 7.15893634114718e-05, precision = 0.8888888888888888\n",
      "\n",
      "Epoch 51: Train Loss = 0.012157885181225033, Recall = 0.05803571428571429, Aging Rate = 0.00015113310053532935, Precision = 0.6842105263157895, f1 = 0.10699588477366255\n",
      "Epoch 52: Train Loss = 0.012145446388195475, Recall = 0.03125, Aging Rate = 8.749811083624331e-05, Precision = 0.6363636363636364, f1 = 0.059574468085106386\n",
      "Epoch 53: Train Loss = 0.012080730776755647, Recall = 0.05803571428571429, Aging Rate = 0.00011931560568578633, Precision = 0.8666666666666667, f1 = 0.10878661087866108\n",
      "Epoch 54: Train Loss = 0.012102343268866495, Recall = 0.05357142857142857, Aging Rate = 0.00011136123197340058, Precision = 0.8571428571428571, f1 = 0.10084033613445377\n",
      "Epoch 55: Train Loss = 0.012072123211569228, Recall = 0.044642857142857144, Aging Rate = 0.00010340685826101482, Precision = 0.7692307692307693, f1 = 0.08438818565400845\n",
      "Test Loss = 0.011556486887010796, Recall = 0.11160714285714286, Aging Rate = 0.0002863574536458872, precision = 0.6944444444444444\n",
      "\n",
      "Epoch 56: Train Loss = 0.012143888196186605, Recall = 0.05803571428571429, Aging Rate = 0.0001431787268229436, Precision = 0.7222222222222222, f1 = 0.10743801652892562\n",
      "Epoch 57: Train Loss = 0.012036232286987929, Recall = 0.03125, Aging Rate = 0.00011136123197340058, Precision = 0.5, f1 = 0.058823529411764705\n",
      "Epoch 58: Train Loss = 0.012059305089411193, Recall = 0.05803571428571429, Aging Rate = 0.00012726997939817208, Precision = 0.8125, f1 = 0.10833333333333332\n",
      "Epoch 59: Train Loss = 0.012052869404786929, Recall = 0.03125, Aging Rate = 8.749811083624331e-05, Precision = 0.6363636363636364, f1 = 0.059574468085106386\n",
      "Epoch 60: Train Loss = 0.011996877833833077, Recall = 0.05803571428571429, Aging Rate = 0.00015113310053532935, Precision = 0.6842105263157895, f1 = 0.10699588477366255\n",
      "Test Loss = 0.011216840193199965, Recall = 0.07142857142857142, Aging Rate = 0.00015113310053532935, precision = 0.8421052631578947\n",
      "\n",
      "Epoch 61: Train Loss = 0.012004624510749124, Recall = 0.05357142857142857, Aging Rate = 0.00011931560568578633, Precision = 0.8, f1 = 0.100418410041841\n",
      "Epoch 62: Train Loss = 0.012004781601488277, Recall = 0.026785714285714284, Aging Rate = 8.749811083624331e-05, Precision = 0.5454545454545454, f1 = 0.05106382978723404\n",
      "Epoch 63: Train Loss = 0.011903608279567948, Recall = 0.05803571428571429, Aging Rate = 0.0001431787268229436, Precision = 0.7222222222222222, f1 = 0.10743801652892562\n",
      "Epoch 64: Train Loss = 0.01197368765902786, Recall = 0.049107142857142856, Aging Rate = 0.00011931560568578633, Precision = 0.7333333333333333, f1 = 0.09205020920502091\n",
      "Epoch 65: Train Loss = 0.011957630628855315, Recall = 0.044642857142857144, Aging Rate = 9.545248454862907e-05, Precision = 0.8333333333333334, f1 = 0.0847457627118644\n",
      "Test Loss = 0.011259539044563657, Recall = 0.09821428571428571, Aging Rate = 0.0001988593428096439, precision = 0.88\n",
      "\n",
      "Epoch 66: Train Loss = 0.011892017896336747, Recall = 0.03571428571428571, Aging Rate = 8.749811083624331e-05, Precision = 0.7272727272727273, f1 = 0.06808510638297872\n",
      "Epoch 67: Train Loss = 0.011832469576721594, Recall = 0.06696428571428571, Aging Rate = 0.00015113310053532935, Precision = 0.7894736842105263, f1 = 0.12345679012345678\n",
      "Epoch 68: Train Loss = 0.011905461622472998, Recall = 0.049107142857142856, Aging Rate = 0.00011931560568578633, Precision = 0.7333333333333333, f1 = 0.09205020920502091\n",
      "Epoch 69: Train Loss = 0.011867342827978852, Recall = 0.05357142857142857, Aging Rate = 0.00015113310053532935, Precision = 0.631578947368421, f1 = 0.09876543209876543\n",
      "Epoch 70: Train Loss = 0.011888539541283862, Recall = 0.044642857142857144, Aging Rate = 0.00010340685826101482, Precision = 0.7692307692307693, f1 = 0.08438818565400845\n",
      "Test Loss = 0.011161864100362979, Recall = 0.09375, Aging Rate = 0.0002147680902344154, precision = 0.7777777777777778\n",
      "\n",
      "Epoch 71: Train Loss = 0.011875853894194889, Recall = 0.03571428571428571, Aging Rate = 9.545248454862907e-05, Precision = 0.6666666666666666, f1 = 0.06779661016949153\n",
      "Epoch 72: Train Loss = 0.011940767007887328, Recall = 0.044642857142857144, Aging Rate = 0.00010340685826101482, Precision = 0.7692307692307693, f1 = 0.08438818565400845\n",
      "Epoch 73: Train Loss = 0.011865859877147195, Recall = 0.05357142857142857, Aging Rate = 0.00012726997939817208, Precision = 0.75, f1 = 0.09999999999999999\n",
      "Epoch 74: Train Loss = 0.011887384903411754, Recall = 0.05357142857142857, Aging Rate = 0.00015113310053532935, Precision = 0.631578947368421, f1 = 0.09876543209876543\n",
      "Epoch 75: Train Loss = 0.01196546617494376, Recall = 0.0625, Aging Rate = 0.0001431787268229436, Precision = 0.7777777777777778, f1 = 0.11570247933884298\n",
      "Test Loss = 0.011180009095498761, Recall = 0.03571428571428571, Aging Rate = 6.363498969908604e-05, precision = 1.0\n",
      "Model in epoch 75 is saved.\n",
      "\n",
      "Epoch 76: Train Loss = 0.011992914103233148, Recall = 0.05357142857142857, Aging Rate = 0.00011136123197340058, Precision = 0.8571428571428571, f1 = 0.10084033613445377\n",
      "Epoch 77: Train Loss = 0.011896821459263901, Recall = 0.049107142857142856, Aging Rate = 0.00012726997939817208, Precision = 0.6875, f1 = 0.09166666666666666\n",
      "Epoch 78: Train Loss = 0.01198534386804559, Recall = 0.049107142857142856, Aging Rate = 0.00012726997939817208, Precision = 0.6875, f1 = 0.09166666666666666\n",
      "Epoch 79: Train Loss = 0.01191443166799041, Recall = 0.05803571428571429, Aging Rate = 0.00011931560568578633, Precision = 0.8666666666666667, f1 = 0.10878661087866108\n",
      "Epoch 80: Train Loss = 0.011846253177375563, Recall = 0.05357142857142857, Aging Rate = 0.0001431787268229436, Precision = 0.6666666666666666, f1 = 0.09917355371900825\n",
      "Test Loss = 0.01150353245179703, Recall = 0.0, Aging Rate = 7.954373712385755e-06, precision = 0.0\n",
      "\n",
      "Epoch 81: Train Loss = 0.011950260757347066, Recall = 0.07142857142857142, Aging Rate = 0.0001431787268229436, Precision = 0.8888888888888888, f1 = 0.1322314049586777\n",
      "Epoch 82: Train Loss = 0.011875198298960266, Recall = 0.044642857142857144, Aging Rate = 0.00010340685826101482, Precision = 0.7692307692307693, f1 = 0.08438818565400845\n",
      "Epoch 83: Train Loss = 0.011915530543941049, Recall = 0.06696428571428571, Aging Rate = 0.00015113310053532935, Precision = 0.7894736842105263, f1 = 0.12345679012345678\n",
      "Epoch 84: Train Loss = 0.011866541893625612, Recall = 0.05357142857142857, Aging Rate = 0.0001590874742477151, Precision = 0.6, f1 = 0.0983606557377049\n",
      "Epoch 85: Train Loss = 0.011853446894062232, Recall = 0.05357142857142857, Aging Rate = 0.00011136123197340058, Precision = 0.8571428571428571, f1 = 0.10084033613445377\n",
      "Test Loss = 0.011504042418311435, Recall = 0.017857142857142856, Aging Rate = 3.181749484954302e-05, precision = 1.0\n",
      "\n",
      "Epoch 86: Train Loss = 0.01186196115166768, Recall = 0.05803571428571429, Aging Rate = 0.00011136123197340058, Precision = 0.9285714285714286, f1 = 0.1092436974789916\n",
      "Epoch 87: Train Loss = 0.011973871592213848, Recall = 0.026785714285714284, Aging Rate = 7.954373712385755e-05, Precision = 0.6, f1 = 0.05128205128205128\n",
      "Epoch 88: Train Loss = 0.011879905974359308, Recall = 0.049107142857142856, Aging Rate = 0.00012726997939817208, Precision = 0.6875, f1 = 0.09166666666666666\n",
      "Epoch 89: Train Loss = 0.011869915765194684, Recall = 0.044642857142857144, Aging Rate = 0.00010340685826101482, Precision = 0.7692307692307693, f1 = 0.08438818565400845\n",
      "Epoch 90: Train Loss = 0.011885525506842371, Recall = 0.05357142857142857, Aging Rate = 0.00016704184796010086, Precision = 0.5714285714285714, f1 = 0.09795918367346937\n",
      "Test Loss = 0.012028520130221099, Recall = 0.1875, Aging Rate = 0.0004693080490307596, precision = 0.711864406779661\n",
      "\n",
      "Epoch 91: Train Loss = 0.011998729499163679, Recall = 0.0625, Aging Rate = 0.00013522435311055783, Precision = 0.8235294117647058, f1 = 0.11618257261410789\n",
      "Epoch 92: Train Loss = 0.012093538971668578, Recall = 0.05357142857142857, Aging Rate = 0.00013522435311055783, Precision = 0.7058823529411765, f1 = 0.09958506224066388\n",
      "Epoch 93: Train Loss = 0.011973664841614598, Recall = 0.05357142857142857, Aging Rate = 0.00015113310053532935, Precision = 0.631578947368421, f1 = 0.09876543209876543\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 94: Train Loss = 0.011877109181197254, Recall = 0.05803571428571429, Aging Rate = 0.00015113310053532935, Precision = 0.6842105263157895, f1 = 0.10699588477366255\n",
      "Epoch 95: Train Loss = 0.011823891023665543, Recall = 0.0625, Aging Rate = 0.0001431787268229436, Precision = 0.7777777777777778, f1 = 0.11570247933884298\n",
      "Test Loss = 0.01133569746913755, Recall = 0.049107142857142856, Aging Rate = 0.00012726997939817208, precision = 0.6875\n",
      "\n",
      "Epoch 96: Train Loss = 0.01184017858256662, Recall = 0.044642857142857144, Aging Rate = 0.0001431787268229436, Precision = 0.5555555555555556, f1 = 0.08264462809917357\n",
      "Epoch 97: Train Loss = 0.011909806268174845, Recall = 0.049107142857142856, Aging Rate = 0.0001431787268229436, Precision = 0.6111111111111112, f1 = 0.0909090909090909\n",
      "Epoch 98: Train Loss = 0.011847788519611716, Recall = 0.0625, Aging Rate = 0.00016704184796010086, Precision = 0.6666666666666666, f1 = 0.11428571428571428\n",
      "Epoch 99: Train Loss = 0.011842044495157616, Recall = 0.05357142857142857, Aging Rate = 0.0001431787268229436, Precision = 0.6666666666666666, f1 = 0.09917355371900825\n",
      "Epoch 100: Train Loss = 0.011820317150336978, Recall = 0.044642857142857144, Aging Rate = 0.00010340685826101482, Precision = 0.7692307692307693, f1 = 0.08438818565400845\n",
      "Test Loss = 0.01129599267048475, Recall = 0.03125, Aging Rate = 5.568061598670029e-05, precision = 1.0\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "667fbb1340d342478bef27b305fcae95",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss = 0.03692748001398274, Recall = 0.0, Aging Rate = 0.0019090193208663765, Precision = 0.0, f1 = 0\n",
      "Epoch 2: Train Loss = 0.026892107853290572, Recall = 0.0, Aging Rate = 0.0, Precision = 0, f1 = 0\n",
      "Epoch 3: Train Loss = 0.026432310167610357, Recall = 0.0, Aging Rate = 0.0, Precision = 0, f1 = 0\n",
      "Epoch 4: Train Loss = 0.025805409216894205, Recall = 0.0, Aging Rate = 0.0, Precision = 0, f1 = 0\n",
      "Epoch 5: Train Loss = 0.02613410369353627, Recall = 0.0, Aging Rate = 0.0, Precision = 0, f1 = 0\n",
      "Test Loss = 0.02413358068409341, Recall = 0.0, Aging Rate = 0.0, precision = 0\n",
      "\n",
      "Epoch 6: Train Loss = 0.024455705475506045, Recall = 0.0, Aging Rate = 0.0, Precision = 0, f1 = 0\n",
      "Epoch 7: Train Loss = 0.023654606444545364, Recall = 0.0, Aging Rate = 0.0, Precision = 0, f1 = 0\n",
      "Epoch 8: Train Loss = 0.022657382605979673, Recall = 0.008888888888888889, Aging Rate = 2.3862741510829707e-05, Precision = 0.6666666666666666, f1 = 0.01754385964912281\n",
      "Epoch 9: Train Loss = 0.02138442299163806, Recall = 0.008888888888888889, Aging Rate = 1.590849434055314e-05, Precision = 0, f1 = 0.0\n",
      "Epoch 10: Train Loss = 0.02066651801448876, Recall = 0.03111111111111111, Aging Rate = 7.158822453248912e-05, Precision = 0.7777777777777778, f1 = 0.05982905982905983\n",
      "Test Loss = 0.019453940425444138, Recall = 0.057777777777777775, Aging Rate = 0.00013522220189470167, precision = 0.7647058823529411\n",
      "Model in epoch 10 is saved.\n",
      "\n",
      "Epoch 11: Train Loss = 0.01966819157210605, Recall = 0.04888888888888889, Aging Rate = 9.545096604331883e-05, Precision = 0.9166666666666666, f1 = 0.09282700421940929\n",
      "Epoch 12: Train Loss = 0.018901982855185937, Recall = 0.06222222222222222, Aging Rate = 0.00014317644906497825, Precision = 0.7777777777777778, f1 = 0.11522633744855967\n",
      "Epoch 13: Train Loss = 0.01837559035001885, Recall = 0.08, Aging Rate = 0.00016703919057580794, Precision = 0.8571428571428571, f1 = 0.14634146341463417\n",
      "Epoch 14: Train Loss = 0.01756630088258363, Recall = 0.08888888888888889, Aging Rate = 0.00019090193208663766, Precision = 0.8333333333333334, f1 = 0.1606425702811245\n",
      "Epoch 15: Train Loss = 0.017230878599873278, Recall = 0.10666666666666667, Aging Rate = 0.00022271892076774393, Precision = 0.8571428571428571, f1 = 0.18972332015810278\n",
      "Test Loss = 0.01563920073620128, Recall = 0.17333333333333334, Aging Rate = 0.00037384961700299876, precision = 0.8297872340425532\n",
      "Model in epoch 15 is saved.\n",
      "\n",
      "Epoch 16: Train Loss = 0.01677854831719893, Recall = 0.1111111111111111, Aging Rate = 0.0002465816622785736, Precision = 0.8064516129032258, f1 = 0.19531249999999997\n",
      "Epoch 17: Train Loss = 0.01615130409241153, Recall = 0.12, Aging Rate = 0.00023862741510829706, Precision = 0.9, f1 = 0.21176470588235294\n",
      "Epoch 18: Train Loss = 0.015882543868667224, Recall = 0.11555555555555555, Aging Rate = 0.00029430714530023305, Precision = 0.7027027027027027, f1 = 0.1984732824427481\n",
      "Epoch 19: Train Loss = 0.015603391478914581, Recall = 0.1511111111111111, Aging Rate = 0.0003340783811516159, Precision = 0.8095238095238095, f1 = 0.2546816479400749\n",
      "Epoch 20: Train Loss = 0.015469706487482181, Recall = 0.16, Aging Rate = 0.0003340783811516159, Precision = 0.8571428571428571, f1 = 0.2696629213483146\n",
      "Test Loss = 0.013894175188840454, Recall = 0.2222222222222222, Aging Rate = 0.00042952934719493475, precision = 0.9259259259259259\n",
      "Model in epoch 20 is saved.\n",
      "\n",
      "Epoch 21: Train Loss = 0.015061473078409817, Recall = 0.1511111111111111, Aging Rate = 0.0003261241339813393, Precision = 0.8292682926829268, f1 = 0.25563909774436094\n",
      "Epoch 22: Train Loss = 0.014752148199778298, Recall = 0.18222222222222223, Aging Rate = 0.00042952934719493475, Precision = 0.7592592592592593, f1 = 0.2939068100358423\n",
      "Epoch 23: Train Loss = 0.014719191012662815, Recall = 0.14666666666666667, Aging Rate = 0.00034998687549216904, Precision = 0.75, f1 = 0.2453531598513011\n",
      "Epoch 24: Train Loss = 0.014618274227046889, Recall = 0.18222222222222223, Aging Rate = 0.0003818038641732753, Precision = 0.8541666666666666, f1 = 0.3003663003663004\n",
      "Epoch 25: Train Loss = 0.014355654518663935, Recall = 0.17333333333333334, Aging Rate = 0.00038975811134355187, Precision = 0.7959183673469388, f1 = 0.28467153284671537\n",
      "Test Loss = 0.01307453996486373, Recall = 0.2222222222222222, Aging Rate = 0.000517026066067977, precision = 0.7692307692307693\n",
      "\n",
      "Epoch 26: Train Loss = 0.014368471340858753, Recall = 0.17777777777777778, Aging Rate = 0.00040566660568410503, Precision = 0.7843137254901961, f1 = 0.2898550724637681\n",
      "Epoch 27: Train Loss = 0.01396863166840098, Recall = 0.19111111111111112, Aging Rate = 0.0004136208528543816, Precision = 0.8269230769230769, f1 = 0.3104693140794224\n",
      "Epoch 28: Train Loss = 0.013982346248414166, Recall = 0.17777777777777778, Aging Rate = 0.00042157510002465814, Precision = 0.7547169811320755, f1 = 0.28776978417266186\n",
      "Epoch 29: Train Loss = 0.014097264602564386, Recall = 0.17777777777777778, Aging Rate = 0.0004136208528543816, Precision = 0.7692307692307693, f1 = 0.2888086642599278\n",
      "Epoch 30: Train Loss = 0.01364291447418294, Recall = 0.20444444444444446, Aging Rate = 0.00042952934719493475, Precision = 0.8518518518518519, f1 = 0.32974910394265233\n",
      "Test Loss = 0.012821259161780688, Recall = 0.27555555555555555, Aging Rate = 0.0005886142906004661, precision = 0.8378378378378378\n",
      "\n",
      "Epoch 31: Train Loss = 0.013795106075225617, Recall = 0.17777777777777778, Aging Rate = 0.0003579411226624456, Precision = 0.8888888888888888, f1 = 0.2962962962962963\n",
      "Epoch 32: Train Loss = 0.013423294887266821, Recall = 0.2222222222222222, Aging Rate = 0.00048520907738687074, Precision = 0.819672131147541, f1 = 0.3496503496503496\n",
      "Epoch 33: Train Loss = 0.013560179950143249, Recall = 0.17777777777777778, Aging Rate = 0.00042157510002465814, Precision = 0.7547169811320755, f1 = 0.28776978417266186\n",
      "Epoch 34: Train Loss = 0.013550740866328575, Recall = 0.19555555555555557, Aging Rate = 0.00047725483021659413, Precision = 0.7333333333333333, f1 = 0.3087719298245614\n",
      "Epoch 35: Train Loss = 0.013430435788828823, Recall = 0.19555555555555557, Aging Rate = 0.00042952934719493475, Precision = 0.8148148148148148, f1 = 0.3154121863799283\n",
      "Test Loss = 0.012221683503877511, Recall = 0.3022222222222222, Aging Rate = 0.000628385526451849, precision = 0.8607594936708861\n",
      "\n",
      "Epoch 36: Train Loss = 0.013369288663434445, Recall = 0.21333333333333335, Aging Rate = 0.00047725483021659413, Precision = 0.8, f1 = 0.3368421052631579\n",
      "Epoch 37: Train Loss = 0.013387030059220182, Recall = 0.19111111111111112, Aging Rate = 0.00044543784153548786, Precision = 0.7678571428571429, f1 = 0.30604982206405695\n",
      "Epoch 38: Train Loss = 0.013002966297944124, Recall = 0.24, Aging Rate = 0.0005488430547490832, Precision = 0.782608695652174, f1 = 0.36734693877551017\n",
      "Epoch 39: Train Loss = 0.013189624636488208, Recall = 0.2222222222222222, Aging Rate = 0.0005011175717274239, Precision = 0.7936507936507936, f1 = 0.3472222222222222\n",
      "Epoch 40: Train Loss = 0.013155804668575256, Recall = 0.2222222222222222, Aging Rate = 0.00048520907738687074, Precision = 0.819672131147541, f1 = 0.3496503496503496\n",
      "Test Loss = 0.01206837257733921, Recall = 0.16444444444444445, Aging Rate = 0.0003658953698327222, precision = 0.8043478260869565\n",
      "\n",
      "Epoch 41: Train Loss = 0.013052650501683947, Recall = 0.20444444444444446, Aging Rate = 0.0005011175717274239, Precision = 0.7301587301587301, f1 = 0.3194444444444445\n",
      "Epoch 42: Train Loss = 0.013009991798631704, Recall = 0.2088888888888889, Aging Rate = 0.000461346335876041, Precision = 0.8103448275862069, f1 = 0.33215547703180215\n",
      "Epoch 43: Train Loss = 0.013122249012239151, Recall = 0.2311111111111111, Aging Rate = 0.0005090718188977005, Precision = 0.8125, f1 = 0.35986159169550175\n",
      "Epoch 44: Train Loss = 0.012897527883051799, Recall = 0.2222222222222222, Aging Rate = 0.00048520907738687074, Precision = 0.819672131147541, f1 = 0.3496503496503496\n",
      "Epoch 45: Train Loss = 0.01282283951131518, Recall = 0.21777777777777776, Aging Rate = 0.0004931633245571472, Precision = 0.7903225806451613, f1 = 0.3414634146341463\n",
      "Test Loss = 0.011532498477261652, Recall = 0.24, Aging Rate = 0.00047725483021659413, precision = 0.9\n",
      "\n",
      "Epoch 46: Train Loss = 0.012758322108822995, Recall = 0.22666666666666666, Aging Rate = 0.0004931633245571472, Precision = 0.8225806451612904, f1 = 0.3554006968641115\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 47: Train Loss = 0.012912071491779017, Recall = 0.21777777777777776, Aging Rate = 0.00047725483021659413, Precision = 0.8166666666666667, f1 = 0.343859649122807\n",
      "Epoch 48: Train Loss = 0.012509713514804783, Recall = 0.2311111111111111, Aging Rate = 0.000517026066067977, Precision = 0.8, f1 = 0.3586206896551724\n",
      "Epoch 49: Train Loss = 0.012728050211471166, Recall = 0.21333333333333335, Aging Rate = 0.00047725483021659413, Precision = 0.8, f1 = 0.3368421052631579\n",
      "Epoch 50: Train Loss = 0.012588102156553762, Recall = 0.22666666666666666, Aging Rate = 0.0005408888075788067, Precision = 0.75, f1 = 0.3481228668941979\n",
      "Test Loss = 0.011205434031839769, Recall = 0.2577777777777778, Aging Rate = 0.000517026066067977, precision = 0.8923076923076924\n",
      "\n",
      "Epoch 51: Train Loss = 0.012362182790577497, Recall = 0.22666666666666666, Aging Rate = 0.0005090718188977005, Precision = 0.796875, f1 = 0.3529411764705882\n",
      "Epoch 52: Train Loss = 0.012589675267722847, Recall = 0.2088888888888889, Aging Rate = 0.000461346335876041, Precision = 0.8103448275862069, f1 = 0.33215547703180215\n",
      "Epoch 53: Train Loss = 0.012512495778643563, Recall = 0.21777777777777776, Aging Rate = 0.00048520907738687074, Precision = 0.8032786885245902, f1 = 0.3426573426573426\n",
      "Epoch 54: Train Loss = 0.012466044263075541, Recall = 0.24444444444444444, Aging Rate = 0.0005567973019193599, Precision = 0.7857142857142857, f1 = 0.3728813559322034\n",
      "Epoch 55: Train Loss = 0.01257127357936156, Recall = 0.22666666666666666, Aging Rate = 0.0005408888075788067, Precision = 0.75, f1 = 0.3481228668941979\n",
      "Test Loss = 0.011211594009412375, Recall = 0.28888888888888886, Aging Rate = 0.0006124770321112959, precision = 0.8441558441558441\n",
      "\n",
      "Epoch 56: Train Loss = 0.012390136192732278, Recall = 0.23555555555555555, Aging Rate = 0.0005488430547490832, Precision = 0.7681159420289855, f1 = 0.3605442176870748\n",
      "Epoch 57: Train Loss = 0.012403404517657748, Recall = 0.2, Aging Rate = 0.0004693005830463176, Precision = 0.7627118644067796, f1 = 0.31690140845070425\n",
      "Epoch 58: Train Loss = 0.012502298859732267, Recall = 0.2088888888888889, Aging Rate = 0.0004693005830463176, Precision = 0.7966101694915254, f1 = 0.3309859154929578\n",
      "Epoch 59: Train Loss = 0.012127137116379772, Recall = 0.24, Aging Rate = 0.0005806600434301896, Precision = 0.7397260273972602, f1 = 0.3624161073825503\n",
      "Epoch 60: Train Loss = 0.012178718966009121, Recall = 0.21333333333333335, Aging Rate = 0.00048520907738687074, Precision = 0.7868852459016393, f1 = 0.3356643356643357\n",
      "Test Loss = 0.011453458137862027, Recall = 0.19555555555555557, Aging Rate = 0.0003579411226624456, precision = 0.9777777777777777\n",
      "Model in epoch 60 is saved.\n",
      "\n",
      "Epoch 61: Train Loss = 0.012410450925688547, Recall = 0.2222222222222222, Aging Rate = 0.0005329345604085301, Precision = 0.746268656716418, f1 = 0.3424657534246575\n",
      "Epoch 62: Train Loss = 0.012133677955553873, Recall = 0.24444444444444444, Aging Rate = 0.0005329345604085301, Precision = 0.8208955223880597, f1 = 0.3767123287671233\n",
      "Epoch 63: Train Loss = 0.012135325305397529, Recall = 0.2311111111111111, Aging Rate = 0.0005647515490896364, Precision = 0.7323943661971831, f1 = 0.35135135135135137\n",
      "Epoch 64: Train Loss = 0.01238267901704935, Recall = 0.22666666666666666, Aging Rate = 0.0005011175717274239, Precision = 0.8095238095238095, f1 = 0.3541666666666667\n",
      "Epoch 65: Train Loss = 0.012080169112936533, Recall = 0.2311111111111111, Aging Rate = 0.0004931633245571472, Precision = 0.8387096774193549, f1 = 0.36236933797909404\n",
      "Test Loss = 0.010938774527425421, Recall = 0.19555555555555557, Aging Rate = 0.00037384961700299876, precision = 0.9361702127659575\n",
      "\n",
      "Epoch 66: Train Loss = 0.01197798982601037, Recall = 0.24444444444444444, Aging Rate = 0.0005408888075788067, Precision = 0.8088235294117647, f1 = 0.37542662116040953\n",
      "Epoch 67: Train Loss = 0.012049426802711108, Recall = 0.2311111111111111, Aging Rate = 0.0005090718188977005, Precision = 0.8125, f1 = 0.35986159169550175\n",
      "Epoch 68: Train Loss = 0.012121655688558943, Recall = 0.2222222222222222, Aging Rate = 0.00047725483021659413, Precision = 0.8333333333333334, f1 = 0.3508771929824561\n",
      "Epoch 69: Train Loss = 0.0118914247681895, Recall = 0.2311111111111111, Aging Rate = 0.0005090718188977005, Precision = 0.8125, f1 = 0.35986159169550175\n",
      "Epoch 70: Train Loss = 0.012019739695655967, Recall = 0.2311111111111111, Aging Rate = 0.0005488430547490832, Precision = 0.7536231884057971, f1 = 0.35374149659863946\n",
      "Test Loss = 0.011495304946672691, Recall = 0.4622222222222222, Aging Rate = 0.0010658691208170602, precision = 0.7761194029850746\n",
      "\n",
      "Epoch 71: Train Loss = 0.011891340669719898, Recall = 0.24444444444444444, Aging Rate = 0.0005249803132382536, Precision = 0.8333333333333334, f1 = 0.37800687285223367\n",
      "Epoch 72: Train Loss = 0.011861214097364866, Recall = 0.22666666666666666, Aging Rate = 0.00045339208870576447, Precision = 0.8947368421052632, f1 = 0.36170212765957444\n",
      "Epoch 73: Train Loss = 0.011980632306225005, Recall = 0.2311111111111111, Aging Rate = 0.000517026066067977, Precision = 0.8, f1 = 0.3586206896551724\n",
      "Epoch 74: Train Loss = 0.012034455908549657, Recall = 0.2311111111111111, Aging Rate = 0.0005329345604085301, Precision = 0.7761194029850746, f1 = 0.3561643835616438\n",
      "Epoch 75: Train Loss = 0.011943836427099562, Recall = 0.20444444444444446, Aging Rate = 0.0004693005830463176, Precision = 0.7796610169491526, f1 = 0.323943661971831\n",
      "Test Loss = 0.010646418200062674, Recall = 0.2088888888888889, Aging Rate = 0.0004931633245571472, precision = 0.7580645161290323\n",
      "\n",
      "Epoch 76: Train Loss = 0.011727301344416345, Recall = 0.24444444444444444, Aging Rate = 0.0005647515490896364, Precision = 0.7746478873239436, f1 = 0.37162162162162166\n",
      "Epoch 77: Train Loss = 0.011901685069869512, Recall = 0.23555555555555555, Aging Rate = 0.000517026066067977, Precision = 0.8153846153846154, f1 = 0.36551724137931035\n",
      "Epoch 78: Train Loss = 0.01187157099590062, Recall = 0.25333333333333335, Aging Rate = 0.000572705796259913, Precision = 0.7916666666666666, f1 = 0.38383838383838387\n",
      "Epoch 79: Train Loss = 0.011853073283545613, Recall = 0.23555555555555555, Aging Rate = 0.0005011175717274239, Precision = 0.8412698412698413, f1 = 0.36805555555555547\n",
      "Epoch 80: Train Loss = 0.011633600655955957, Recall = 0.24888888888888888, Aging Rate = 0.000572705796259913, Precision = 0.7777777777777778, f1 = 0.3771043771043771\n",
      "Test Loss = 0.010572702425236813, Recall = 0.3333333333333333, Aging Rate = 0.0006681567623032318, precision = 0.8928571428571429\n",
      "\n",
      "Epoch 81: Train Loss = 0.011595039023089022, Recall = 0.25333333333333335, Aging Rate = 0.0005329345604085301, Precision = 0.8507462686567164, f1 = 0.3904109589041096\n",
      "Epoch 82: Train Loss = 0.011519746530269255, Recall = 0.2577777777777778, Aging Rate = 0.0006124770321112959, Precision = 0.7532467532467533, f1 = 0.38410596026490074\n",
      "Epoch 83: Train Loss = 0.011512624297784204, Recall = 0.24888888888888888, Aging Rate = 0.0005806600434301896, Precision = 0.7671232876712328, f1 = 0.37583892617449666\n",
      "Epoch 84: Train Loss = 0.011513238192035433, Recall = 0.24, Aging Rate = 0.0005249803132382536, Precision = 0.8181818181818182, f1 = 0.37113402061855677\n",
      "Epoch 85: Train Loss = 0.011549849722339574, Recall = 0.24, Aging Rate = 0.00048520907738687074, Precision = 0.8852459016393442, f1 = 0.37762237762237766\n",
      "Test Loss = 0.01021483171831419, Recall = 0.3288888888888889, Aging Rate = 0.0006999737509843381, precision = 0.8409090909090909\n",
      "\n",
      "Epoch 86: Train Loss = 0.011502826197065767, Recall = 0.2577777777777778, Aging Rate = 0.0005567973019193599, Precision = 0.8285714285714286, f1 = 0.39322033898305087\n",
      "Epoch 87: Train Loss = 0.011385325065588333, Recall = 0.23555555555555555, Aging Rate = 0.0005488430547490832, Precision = 0.7681159420289855, f1 = 0.3605442176870748\n",
      "Epoch 88: Train Loss = 0.01151003894962473, Recall = 0.2577777777777778, Aging Rate = 0.0005806600434301896, Precision = 0.7945205479452054, f1 = 0.38926174496644295\n",
      "Epoch 89: Train Loss = 0.01132177205600243, Recall = 0.26666666666666666, Aging Rate = 0.0006124770321112959, Precision = 0.7792207792207793, f1 = 0.3973509933774835\n",
      "Epoch 90: Train Loss = 0.011432279506372486, Recall = 0.22666666666666666, Aging Rate = 0.0004931633245571472, Precision = 0.8225806451612904, f1 = 0.3554006968641115\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss = 0.010579405187186633, Recall = 0.25333333333333335, Aging Rate = 0.0005408888075788067, precision = 0.8382352941176471\n",
      "\n",
      "Epoch 91: Train Loss = 0.01150120068139219, Recall = 0.24888888888888888, Aging Rate = 0.0005886142906004661, Precision = 0.7567567567567568, f1 = 0.3745819397993311\n",
      "Epoch 92: Train Loss = 0.011439445219941809, Recall = 0.2311111111111111, Aging Rate = 0.0005090718188977005, Precision = 0.8125, f1 = 0.35986159169550175\n",
      "Epoch 93: Train Loss = 0.011363530625497562, Recall = 0.23555555555555555, Aging Rate = 0.0005329345604085301, Precision = 0.7910447761194029, f1 = 0.36301369863013694\n",
      "Epoch 94: Train Loss = 0.011336843878517992, Recall = 0.24444444444444444, Aging Rate = 0.0005249803132382536, Precision = 0.8333333333333334, f1 = 0.37800687285223367\n",
      "Epoch 95: Train Loss = 0.011319125946212172, Recall = 0.24444444444444444, Aging Rate = 0.0005567973019193599, Precision = 0.7857142857142857, f1 = 0.3728813559322034\n",
      "Test Loss = 0.010821617808685331, Recall = 0.44, Aging Rate = 0.0009704181547737415, precision = 0.8114754098360656\n",
      "\n",
      "Epoch 96: Train Loss = 0.01132594084546266, Recall = 0.2577777777777778, Aging Rate = 0.0005806600434301896, Precision = 0.7945205479452054, f1 = 0.38926174496644295\n",
      "Epoch 97: Train Loss = 0.011403769361998153, Recall = 0.22666666666666666, Aging Rate = 0.0005329345604085301, Precision = 0.7611940298507462, f1 = 0.3493150684931507\n",
      "Epoch 98: Train Loss = 0.011157071295213388, Recall = 0.25333333333333335, Aging Rate = 0.0005567973019193599, Precision = 0.8142857142857143, f1 = 0.3864406779661017\n",
      "Epoch 99: Train Loss = 0.011428659484176205, Recall = 0.24444444444444444, Aging Rate = 0.0005488430547490832, Precision = 0.7971014492753623, f1 = 0.37414965986394555\n",
      "Epoch 100: Train Loss = 0.011217006423404006, Recall = 0.26222222222222225, Aging Rate = 0.000572705796259913, Precision = 0.8194444444444444, f1 = 0.3973063973063974\n",
      "Test Loss = 0.010778868923249172, Recall = 0.13333333333333333, Aging Rate = 0.0002465816622785736, precision = 0.967741935483871\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4531b70b7caf4455958692e395faa4d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss = 0.03914886463499376, Recall = 0.0, Aging Rate = 0.00486799926820926, Precision = 0.0, f1 = 0\n",
      "Epoch 2: Train Loss = 0.026973209666038042, Recall = 0.0, Aging Rate = 0.0, Precision = 0, f1 = 0\n",
      "Epoch 3: Train Loss = 0.026659527718446874, Recall = 0.0, Aging Rate = 0.0, Precision = 0, f1 = 0\n",
      "Epoch 4: Train Loss = 0.026365512907849654, Recall = 0.0, Aging Rate = 0.0, Precision = 0, f1 = 0\n",
      "Epoch 5: Train Loss = 0.02580906984725289, Recall = 0.0044444444444444444, Aging Rate = 7.95424717027657e-06, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.02519395156310356, Recall = 0.0, Aging Rate = 0.0, precision = 0\n",
      "\n",
      "Epoch 6: Train Loss = 0.024651997396886522, Recall = 0.0, Aging Rate = 7.95424717027657e-06, Precision = 0.0, f1 = 0\n",
      "Epoch 7: Train Loss = 0.02364108921412962, Recall = 0.008888888888888889, Aging Rate = 4.7725483021659414e-05, Precision = 0.3333333333333333, f1 = 0.017316017316017316\n",
      "Epoch 8: Train Loss = 0.022769052513904972, Recall = 0.0044444444444444444, Aging Rate = 3.181698868110628e-05, Precision = 0.25, f1 = 0.008733624454148473\n",
      "Epoch 9: Train Loss = 0.021783941773331737, Recall = 0.017777777777777778, Aging Rate = 7.954247170276569e-05, Precision = 0.4, f1 = 0.03404255319148936\n",
      "Epoch 10: Train Loss = 0.02059351592840343, Recall = 0.044444444444444446, Aging Rate = 0.0001034052132135954, Precision = 0.7692307692307693, f1 = 0.08403361344537816\n",
      "Test Loss = 0.019076473258066825, Recall = 0.022222222222222223, Aging Rate = 4.7725483021659414e-05, precision = 0.8333333333333334\n",
      "Model in epoch 10 is saved.\n",
      "\n",
      "Epoch 11: Train Loss = 0.020081552016847137, Recall = 0.02666666666666667, Aging Rate = 9.545096604331883e-05, Precision = 0.5, f1 = 0.05063291139240507\n",
      "Epoch 12: Train Loss = 0.01931835093378782, Recall = 0.04888888888888889, Aging Rate = 0.00012726795472442511, Precision = 0.6875, f1 = 0.09128630705394192\n",
      "Epoch 13: Train Loss = 0.01873900332606951, Recall = 0.05333333333333334, Aging Rate = 0.00015908494340553139, Precision = 0.6, f1 = 0.0979591836734694\n",
      "Epoch 14: Train Loss = 0.01803516705455461, Recall = 0.06666666666666667, Aging Rate = 0.00019090193208663766, Precision = 0.625, f1 = 0.12048192771084337\n",
      "Epoch 15: Train Loss = 0.017336625639994576, Recall = 0.08, Aging Rate = 0.0002624901566191268, Precision = 0.5454545454545454, f1 = 0.13953488372093023\n",
      "Test Loss = 0.015729862233382703, Recall = 0.04888888888888889, Aging Rate = 9.545096604331883e-05, precision = 0.9166666666666666\n",
      "Model in epoch 15 is saved.\n",
      "\n",
      "Epoch 16: Train Loss = 0.016755162372146915, Recall = 0.07555555555555556, Aging Rate = 0.00022271892076774393, Precision = 0.6071428571428571, f1 = 0.13438735177865613\n",
      "Epoch 17: Train Loss = 0.016312524404693978, Recall = 0.09333333333333334, Aging Rate = 0.00025453590944885023, Precision = 0.65625, f1 = 0.16342412451361868\n",
      "Epoch 18: Train Loss = 0.015735625834592322, Recall = 0.10222222222222223, Aging Rate = 0.0003022613924705096, Precision = 0.6052631578947368, f1 = 0.1749049429657795\n",
      "Epoch 19: Train Loss = 0.015386116845893619, Recall = 0.10666666666666667, Aging Rate = 0.00027044440378940334, Precision = 0.7058823529411765, f1 = 0.18532818532818532\n",
      "Epoch 20: Train Loss = 0.014908825350170499, Recall = 0.13777777777777778, Aging Rate = 0.0003818038641732753, Precision = 0.6458333333333334, f1 = 0.2271062271062271\n",
      "Test Loss = 0.014101757064225853, Recall = 0.09777777777777778, Aging Rate = 0.00019090193208663766, precision = 0.9166666666666666\n",
      "Model in epoch 20 is saved.\n",
      "\n",
      "Epoch 21: Train Loss = 0.014533193107639243, Recall = 0.16, Aging Rate = 0.00042952934719493475, Precision = 0.6666666666666666, f1 = 0.25806451612903225\n",
      "Epoch 22: Train Loss = 0.014243699203737624, Recall = 0.13777777777777778, Aging Rate = 0.00040566660568410503, Precision = 0.6078431372549019, f1 = 0.2246376811594203\n",
      "Epoch 23: Train Loss = 0.014049970953670526, Recall = 0.13777777777777778, Aging Rate = 0.0003579411226624456, Precision = 0.6888888888888889, f1 = 0.22962962962962963\n",
      "Epoch 24: Train Loss = 0.013649854960222087, Recall = 0.15555555555555556, Aging Rate = 0.0003818038641732753, Precision = 0.7291666666666666, f1 = 0.2564102564102564\n",
      "Epoch 25: Train Loss = 0.013317477139576135, Recall = 0.19111111111111112, Aging Rate = 0.00045339208870576447, Precision = 0.7543859649122807, f1 = 0.3049645390070922\n",
      "Test Loss = 0.012611334184465766, Recall = 0.08444444444444445, Aging Rate = 0.0001511306962352548, precision = 1.0\n",
      "Model in epoch 25 is saved.\n",
      "\n",
      "Epoch 26: Train Loss = 0.013168778895180455, Recall = 0.20444444444444446, Aging Rate = 0.00048520907738687074, Precision = 0.7540983606557377, f1 = 0.32167832167832167\n",
      "Epoch 27: Train Loss = 0.012819899659816917, Recall = 0.20444444444444446, Aging Rate = 0.00045339208870576447, Precision = 0.8070175438596491, f1 = 0.326241134751773\n",
      "Epoch 28: Train Loss = 0.012763601281935008, Recall = 0.18222222222222223, Aging Rate = 0.000461346335876041, Precision = 0.7068965517241379, f1 = 0.28975265017667845\n",
      "Epoch 29: Train Loss = 0.012638790343064575, Recall = 0.18222222222222223, Aging Rate = 0.00047725483021659413, Precision = 0.6833333333333333, f1 = 0.28771929824561404\n",
      "Epoch 30: Train Loss = 0.012341815048147646, Recall = 0.20444444444444446, Aging Rate = 0.00044543784153548786, Precision = 0.8214285714285714, f1 = 0.3274021352313167\n",
      "Test Loss = 0.010862201334292587, Recall = 0.24444444444444444, Aging Rate = 0.0005090718188977005, precision = 0.859375\n",
      "\n",
      "Epoch 31: Train Loss = 0.012240761524475886, Recall = 0.2088888888888889, Aging Rate = 0.0005090718188977005, Precision = 0.734375, f1 = 0.32525951557093424\n",
      "Epoch 32: Train Loss = 0.012078344173784417, Recall = 0.2311111111111111, Aging Rate = 0.0005647515490896364, Precision = 0.7323943661971831, f1 = 0.35135135135135137\n",
      "Epoch 33: Train Loss = 0.012005821885867329, Recall = 0.2, Aging Rate = 0.0004931633245571472, Precision = 0.7258064516129032, f1 = 0.31358885017421606\n",
      "Epoch 34: Train Loss = 0.011897064027979104, Recall = 0.24, Aging Rate = 0.0005567973019193599, Precision = 0.7714285714285715, f1 = 0.3661016949152542\n",
      "Epoch 35: Train Loss = 0.011905341152421735, Recall = 0.19555555555555557, Aging Rate = 0.00048520907738687074, Precision = 0.7213114754098361, f1 = 0.3076923076923077\n",
      "Test Loss = 0.010597561605504088, Recall = 0.3022222222222222, Aging Rate = 0.0006442940207924021, precision = 0.8395061728395061\n",
      "\n",
      "Epoch 36: Train Loss = 0.011710860265736112, Recall = 0.21333333333333335, Aging Rate = 0.000461346335876041, Precision = 0.8275862068965517, f1 = 0.3392226148409895\n",
      "Epoch 37: Train Loss = 0.011665401076073324, Recall = 0.24, Aging Rate = 0.0005408888075788067, Precision = 0.7941176470588235, f1 = 0.36860068259385664\n",
      "Epoch 38: Train Loss = 0.011475156410045371, Recall = 0.24, Aging Rate = 0.000572705796259913, Precision = 0.75, f1 = 0.36363636363636365\n",
      "Epoch 39: Train Loss = 0.01136830105185137, Recall = 0.23555555555555555, Aging Rate = 0.0005647515490896364, Precision = 0.7464788732394366, f1 = 0.35810810810810806\n",
      "Epoch 40: Train Loss = 0.011364311900629729, Recall = 0.24444444444444444, Aging Rate = 0.0005408888075788067, Precision = 0.8088235294117647, f1 = 0.37542662116040953\n",
      "Test Loss = 0.010167742589221524, Recall = 0.1511111111111111, Aging Rate = 0.00029430714530023305, precision = 0.918918918918919\n",
      "\n",
      "Epoch 41: Train Loss = 0.011384716113334614, Recall = 0.21777777777777776, Aging Rate = 0.000517026066067977, Precision = 0.7538461538461538, f1 = 0.33793103448275863\n",
      "Epoch 42: Train Loss = 0.011333185953693462, Recall = 0.2577777777777778, Aging Rate = 0.0006442940207924021, Precision = 0.7160493827160493, f1 = 0.3790849673202614\n",
      "Epoch 43: Train Loss = 0.011149441630178263, Recall = 0.24, Aging Rate = 0.0005806600434301896, Precision = 0.7397260273972602, f1 = 0.3624161073825503\n",
      "Epoch 44: Train Loss = 0.011031690959221675, Recall = 0.25333333333333335, Aging Rate = 0.0005567973019193599, Precision = 0.8142857142857143, f1 = 0.3864406779661017\n",
      "Epoch 45: Train Loss = 0.01098882020301006, Recall = 0.24888888888888888, Aging Rate = 0.0005886142906004661, Precision = 0.7567567567567568, f1 = 0.3745819397993311\n",
      "Test Loss = 0.009521131206970944, Recall = 0.35555555555555557, Aging Rate = 0.0007715619755168272, precision = 0.8247422680412371\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 46: Train Loss = 0.010936344332272028, Recall = 0.24444444444444444, Aging Rate = 0.0005886142906004661, Precision = 0.7432432432432432, f1 = 0.36789297658862874\n",
      "Epoch 47: Train Loss = 0.010876158450101231, Recall = 0.28888888888888886, Aging Rate = 0.0006442940207924021, Precision = 0.8024691358024691, f1 = 0.4248366013071896\n",
      "Epoch 48: Train Loss = 0.010981209656990683, Recall = 0.25333333333333335, Aging Rate = 0.0005806600434301896, Precision = 0.7808219178082192, f1 = 0.3825503355704698\n",
      "Epoch 49: Train Loss = 0.010969193957024996, Recall = 0.28, Aging Rate = 0.000628385526451849, Precision = 0.7974683544303798, f1 = 0.4144736842105264\n",
      "Epoch 50: Train Loss = 0.010859178218141745, Recall = 0.2222222222222222, Aging Rate = 0.0005806600434301896, Precision = 0.684931506849315, f1 = 0.33557046979865773\n",
      "Test Loss = 0.009365596513640191, Recall = 0.28, Aging Rate = 0.0005329345604085301, precision = 0.9402985074626866\n",
      "Model in epoch 50 is saved.\n",
      "\n",
      "Epoch 51: Train Loss = 0.010790057803600525, Recall = 0.28444444444444444, Aging Rate = 0.000572705796259913, Precision = 0.8888888888888888, f1 = 0.43097643097643096\n",
      "Epoch 52: Train Loss = 0.0106011853794436, Recall = 0.24444444444444444, Aging Rate = 0.000572705796259913, Precision = 0.7638888888888888, f1 = 0.3703703703703703\n",
      "Epoch 53: Train Loss = 0.010747733058479671, Recall = 0.28888888888888886, Aging Rate = 0.0006681567623032318, Precision = 0.7738095238095238, f1 = 0.4207119741100323\n",
      "Epoch 54: Train Loss = 0.010705311454603095, Recall = 0.2577777777777778, Aging Rate = 0.0005806600434301896, Precision = 0.7945205479452054, f1 = 0.38926174496644295\n",
      "Epoch 55: Train Loss = 0.010609783518821794, Recall = 0.2311111111111111, Aging Rate = 0.0005408888075788067, Precision = 0.7647058823529411, f1 = 0.35494880546075086\n",
      "Test Loss = 0.009251074511429808, Recall = 0.32, Aging Rate = 0.0006681567623032318, precision = 0.8571428571428571\n",
      "\n",
      "Epoch 56: Train Loss = 0.010489881659579588, Recall = 0.3111111111111111, Aging Rate = 0.0006681567623032318, Precision = 0.8333333333333334, f1 = 0.45307443365695804\n",
      "Epoch 57: Train Loss = 0.01054668477583476, Recall = 0.24, Aging Rate = 0.0005647515490896364, Precision = 0.7605633802816901, f1 = 0.36486486486486486\n",
      "Epoch 58: Train Loss = 0.010442899385640178, Recall = 0.26666666666666666, Aging Rate = 0.0006045227849410192, Precision = 0.7894736842105263, f1 = 0.39867109634551495\n",
      "Epoch 59: Train Loss = 0.010477095739115648, Recall = 0.25333333333333335, Aging Rate = 0.0005329345604085301, Precision = 0.8507462686567164, f1 = 0.3904109589041096\n",
      "Epoch 60: Train Loss = 0.010450138620784248, Recall = 0.26222222222222225, Aging Rate = 0.0006124770321112959, Precision = 0.7662337662337663, f1 = 0.3907284768211921\n",
      "Test Loss = 0.009307149175806696, Recall = 0.3688888888888889, Aging Rate = 0.0007158822453248912, precision = 0.9222222222222223\n",
      "Model in epoch 60 is saved.\n",
      "\n",
      "Epoch 61: Train Loss = 0.010432897567322207, Recall = 0.28888888888888886, Aging Rate = 0.0006442940207924021, Precision = 0.8024691358024691, f1 = 0.4248366013071896\n",
      "Epoch 62: Train Loss = 0.010282891194143561, Recall = 0.26222222222222225, Aging Rate = 0.0006442940207924021, Precision = 0.7283950617283951, f1 = 0.3856209150326798\n",
      "Epoch 63: Train Loss = 0.010376651186262905, Recall = 0.27111111111111114, Aging Rate = 0.0006363397736221255, Precision = 0.7625, f1 = 0.4\n",
      "Epoch 64: Train Loss = 0.010248949417195492, Recall = 0.21777777777777776, Aging Rate = 0.000572705796259913, Precision = 0.6805555555555556, f1 = 0.32996632996632996\n",
      "Epoch 65: Train Loss = 0.010133593128038906, Recall = 0.27555555555555555, Aging Rate = 0.000628385526451849, Precision = 0.7848101265822784, f1 = 0.40789473684210525\n",
      "Test Loss = 0.008949761385346519, Recall = 0.29777777777777775, Aging Rate = 0.0005567973019193599, precision = 0.9571428571428572\n",
      "\n",
      "Epoch 66: Train Loss = 0.010245665854707618, Recall = 0.28888888888888886, Aging Rate = 0.000628385526451849, Precision = 0.8227848101265823, f1 = 0.4276315789473684\n",
      "Epoch 67: Train Loss = 0.010171829601997723, Recall = 0.28444444444444444, Aging Rate = 0.000628385526451849, Precision = 0.810126582278481, f1 = 0.4210526315789474\n",
      "Epoch 68: Train Loss = 0.010241614720191127, Recall = 0.2577777777777778, Aging Rate = 0.0006045227849410192, Precision = 0.7631578947368421, f1 = 0.3853820598006644\n",
      "Epoch 69: Train Loss = 0.010247976812921212, Recall = 0.28, Aging Rate = 0.000628385526451849, Precision = 0.7974683544303798, f1 = 0.4144736842105264\n",
      "Epoch 70: Train Loss = 0.010117016439107462, Recall = 0.27555555555555555, Aging Rate = 0.0006204312792815724, Precision = 0.7948717948717948, f1 = 0.40924092409240925\n",
      "Test Loss = 0.010938444086526847, Recall = 0.6222222222222222, Aging Rate = 0.0016465291642472498, precision = 0.6763285024154589\n",
      "\n",
      "Epoch 71: Train Loss = 0.010117519780753361, Recall = 0.28, Aging Rate = 0.0006045227849410192, Precision = 0.8289473684210527, f1 = 0.4186046511627907\n",
      "Epoch 72: Train Loss = 0.009996707884069558, Recall = 0.28, Aging Rate = 0.000628385526451849, Precision = 0.7974683544303798, f1 = 0.4144736842105264\n",
      "Epoch 73: Train Loss = 0.01021649969813278, Recall = 0.24, Aging Rate = 0.0005488430547490832, Precision = 0.782608695652174, f1 = 0.36734693877551017\n",
      "Epoch 74: Train Loss = 0.010007076160841575, Recall = 0.28, Aging Rate = 0.0006602025151329552, Precision = 0.7590361445783133, f1 = 0.40909090909090917\n",
      "Epoch 75: Train Loss = 0.01019057888292486, Recall = 0.26222222222222225, Aging Rate = 0.0005886142906004661, Precision = 0.7972972972972973, f1 = 0.39464882943143814\n",
      "Test Loss = 0.008653628827224402, Recall = 0.39555555555555555, Aging Rate = 0.0008272417057087632, precision = 0.8557692307692307\n",
      "\n",
      "Epoch 76: Train Loss = 0.010041854338020862, Recall = 0.28, Aging Rate = 0.0006045227849410192, Precision = 0.8289473684210527, f1 = 0.4186046511627907\n",
      "Epoch 77: Train Loss = 0.01000837388074337, Recall = 0.29333333333333333, Aging Rate = 0.0006602025151329552, Precision = 0.7951807228915663, f1 = 0.42857142857142855\n",
      "Epoch 78: Train Loss = 0.009935414416003879, Recall = 0.28, Aging Rate = 0.000628385526451849, Precision = 0.7974683544303798, f1 = 0.4144736842105264\n",
      "Epoch 79: Train Loss = 0.009949250651088638, Recall = 0.27111111111111114, Aging Rate = 0.0005806600434301896, Precision = 0.8356164383561644, f1 = 0.40939597315436244\n",
      "Epoch 80: Train Loss = 0.010053799422705649, Recall = 0.28888888888888886, Aging Rate = 0.000628385526451849, Precision = 0.8227848101265823, f1 = 0.4276315789473684\n",
      "Test Loss = 0.009031584500184887, Recall = 0.3288888888888889, Aging Rate = 0.0006522482679626787, precision = 0.9024390243902439\n",
      "\n",
      "Epoch 81: Train Loss = 0.009964213219145599, Recall = 0.28444444444444444, Aging Rate = 0.0006522482679626787, Precision = 0.7804878048780488, f1 = 0.41693811074918563\n",
      "Epoch 82: Train Loss = 0.009964058788172126, Recall = 0.28444444444444444, Aging Rate = 0.0006204312792815724, Precision = 0.8205128205128205, f1 = 0.4224422442244224\n",
      "Epoch 83: Train Loss = 0.010017018631975062, Recall = 0.27555555555555555, Aging Rate = 0.0006124770321112959, Precision = 0.8051948051948052, f1 = 0.4105960264900662\n",
      "Epoch 84: Train Loss = 0.009938047888799323, Recall = 0.27111111111111114, Aging Rate = 0.0006681567623032318, Precision = 0.7261904761904762, f1 = 0.39482200647249194\n",
      "Epoch 85: Train Loss = 0.010000019009257895, Recall = 0.27555555555555555, Aging Rate = 0.0006363397736221255, Precision = 0.775, f1 = 0.4065573770491804\n",
      "Test Loss = 0.009305141480557466, Recall = 0.4533333333333333, Aging Rate = 0.0010260978849656775, precision = 0.7906976744186046\n",
      "\n",
      "Epoch 86: Train Loss = 0.009986909987296701, Recall = 0.3111111111111111, Aging Rate = 0.0006522482679626787, Precision = 0.8536585365853658, f1 = 0.4560260586319218\n",
      "Epoch 87: Train Loss = 0.00994517669452242, Recall = 0.28, Aging Rate = 0.0006442940207924021, Precision = 0.7777777777777778, f1 = 0.4117647058823529\n",
      "Epoch 88: Train Loss = 0.00991272260862995, Recall = 0.26222222222222225, Aging Rate = 0.0005886142906004661, Precision = 0.7972972972972973, f1 = 0.39464882943143814\n",
      "Epoch 89: Train Loss = 0.010019764882920763, Recall = 0.24, Aging Rate = 0.000572705796259913, Precision = 0.75, f1 = 0.36363636363636365\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 90: Train Loss = 0.010001543041936168, Recall = 0.27111111111111114, Aging Rate = 0.0006602025151329552, Precision = 0.7349397590361446, f1 = 0.3961038961038961\n",
      "Test Loss = 0.008702340824942412, Recall = 0.36444444444444446, Aging Rate = 0.0007158822453248912, precision = 0.9111111111111111\n",
      "\n",
      "Epoch 91: Train Loss = 0.009883663296557557, Recall = 0.3244444444444444, Aging Rate = 0.000684065256643785, Precision = 0.8488372093023255, f1 = 0.46945337620578775\n",
      "Epoch 92: Train Loss = 0.009895690499391194, Recall = 0.27111111111111114, Aging Rate = 0.000628385526451849, Precision = 0.7721518987341772, f1 = 0.40131578947368424\n",
      "Epoch 93: Train Loss = 0.009823317296751823, Recall = 0.3244444444444444, Aging Rate = 0.000684065256643785, Precision = 0.8488372093023255, f1 = 0.46945337620578775\n",
      "Epoch 94: Train Loss = 0.00987380282473797, Recall = 0.3022222222222222, Aging Rate = 0.0006761110094735084, Precision = 0.8, f1 = 0.43870967741935485\n",
      "Epoch 95: Train Loss = 0.009894161382149958, Recall = 0.30666666666666664, Aging Rate = 0.0006522482679626787, Precision = 0.8414634146341463, f1 = 0.4495114006514658\n",
      "Test Loss = 0.009109139301351652, Recall = 0.36, Aging Rate = 0.0008192874585384866, precision = 0.7864077669902912\n",
      "\n",
      "Epoch 96: Train Loss = 0.009949790918682139, Recall = 0.28888888888888886, Aging Rate = 0.0006761110094735084, Precision = 0.7647058823529411, f1 = 0.41935483870967744\n",
      "Epoch 97: Train Loss = 0.009898360282536102, Recall = 0.29777777777777775, Aging Rate = 0.0006761110094735084, Precision = 0.788235294117647, f1 = 0.43225806451612897\n",
      "Epoch 98: Train Loss = 0.009938167450740653, Recall = 0.3111111111111111, Aging Rate = 0.0006999737509843381, Precision = 0.7954545454545454, f1 = 0.4472843450479233\n",
      "Epoch 99: Train Loss = 0.009919993788209078, Recall = 0.28, Aging Rate = 0.0006124770321112959, Precision = 0.8181818181818182, f1 = 0.4172185430463577\n",
      "Epoch 100: Train Loss = 0.009865983438174478, Recall = 0.28888888888888886, Aging Rate = 0.0006442940207924021, Precision = 0.8024691358024691, f1 = 0.4248366013071896\n",
      "Test Loss = 0.008640603006545698, Recall = 0.41333333333333333, Aging Rate = 0.0008272417057087632, precision = 0.8942307692307693\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "99b997af633249ff9fd80988d703aa30",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss = 0.031598688686107504, Recall = 0.0, Aging Rate = 0.0, Precision = 0, f1 = 0\n",
      "Epoch 2: Train Loss = 0.02646629861814904, Recall = 0.0, Aging Rate = 0.0, Precision = 0, f1 = 0\n",
      "Epoch 3: Train Loss = 0.02621132599856867, Recall = 0.0, Aging Rate = 0.0, Precision = 0, f1 = 0\n",
      "Epoch 4: Train Loss = 0.02580767300045975, Recall = 0.0, Aging Rate = 0.0, Precision = 0, f1 = 0\n",
      "Epoch 5: Train Loss = 0.02494062939226725, Recall = 0.0, Aging Rate = 0.0, Precision = 0, f1 = 0\n",
      "Test Loss = 0.023009817210626, Recall = 0.0, Aging Rate = 0.0, precision = 0\n",
      "\n",
      "Epoch 6: Train Loss = 0.02359791505596979, Recall = 0.0044444444444444444, Aging Rate = 7.954310440827884e-06, Precision = 0, f1 = 0.0\n",
      "Epoch 7: Train Loss = 0.022607883183646604, Recall = 0.0044444444444444444, Aging Rate = 2.3862931322483654e-05, Precision = 0.3333333333333333, f1 = 0.008771929824561405\n",
      "Epoch 8: Train Loss = 0.02153146646411313, Recall = 0.008888888888888889, Aging Rate = 2.3862931322483654e-05, Precision = 0.6666666666666666, f1 = 0.01754385964912281\n",
      "Epoch 9: Train Loss = 0.02044699708143971, Recall = 0.035555555555555556, Aging Rate = 8.749741484910673e-05, Precision = 0.7272727272727273, f1 = 0.06779661016949153\n",
      "Epoch 10: Train Loss = 0.01940872375817357, Recall = 0.02666666666666667, Aging Rate = 7.954310440827885e-05, Precision = 0.6, f1 = 0.05106382978723405\n",
      "Test Loss = 0.018237949692670535, Recall = 0.02666666666666667, Aging Rate = 4.772586264496731e-05, precision = 1.0\n",
      "Model in epoch 10 is saved.\n",
      "\n",
      "Epoch 11: Train Loss = 0.018585806024200457, Recall = 0.044444444444444446, Aging Rate = 8.749741484910673e-05, Precision = 0.9090909090909091, f1 = 0.08474576271186442\n",
      "Epoch 12: Train Loss = 0.017990689164370088, Recall = 0.06666666666666667, Aging Rate = 0.00019090345057986923, Precision = 0.625, f1 = 0.12048192771084337\n",
      "Epoch 13: Train Loss = 0.017170224555343637, Recall = 0.07111111111111111, Aging Rate = 0.00022272069234318076, Precision = 0.5714285714285714, f1 = 0.12648221343873517\n",
      "Epoch 14: Train Loss = 0.016870591229025896, Recall = 0.06666666666666667, Aging Rate = 0.00019885776102069713, Precision = 0.6, f1 = 0.12000000000000001\n",
      "Epoch 15: Train Loss = 0.016097243225643956, Recall = 0.09333333333333334, Aging Rate = 0.0002863551758698039, Precision = 0.5833333333333334, f1 = 0.16091954022988506\n",
      "Test Loss = 0.014610863772900922, Recall = 0.13777777777777778, Aging Rate = 0.0003102181071922875, precision = 0.7948717948717948\n",
      "\n",
      "Epoch 16: Train Loss = 0.015718275678826735, Recall = 0.13777777777777778, Aging Rate = 0.00034998965939642693, Precision = 0.7045454545454546, f1 = 0.23048327137546468\n",
      "Epoch 17: Train Loss = 0.015324290820082699, Recall = 0.12, Aging Rate = 0.0003022637967514596, Precision = 0.7105263157894737, f1 = 0.2053231939163498\n",
      "Epoch 18: Train Loss = 0.014838288933313312, Recall = 0.13333333333333333, Aging Rate = 0.00034203534895559904, Precision = 0.6976744186046512, f1 = 0.22388059701492538\n",
      "Epoch 19: Train Loss = 0.014498611603394298, Recall = 0.1511111111111111, Aging Rate = 0.00038180690115973846, Precision = 0.7083333333333334, f1 = 0.2490842490842491\n",
      "Epoch 20: Train Loss = 0.014076626733139147, Recall = 0.13333333333333333, Aging Rate = 0.00039771552204139425, Precision = 0.6, f1 = 0.2181818181818182\n",
      "Test Loss = 0.012967877980585312, Recall = 0.24, Aging Rate = 0.0005965732830620913, precision = 0.72\n",
      "\n",
      "Epoch 21: Train Loss = 0.013689359350724056, Recall = 0.16, Aging Rate = 0.0004295327638047058, Precision = 0.6666666666666666, f1 = 0.25806451612903225\n",
      "Epoch 22: Train Loss = 0.013546429645551111, Recall = 0.2, Aging Rate = 0.0004931672473313289, Precision = 0.7258064516129032, f1 = 0.31358885017421606\n",
      "Epoch 23: Train Loss = 0.013270902840202096, Recall = 0.17777777777777778, Aging Rate = 0.0004295327638047058, Precision = 0.7407407407407407, f1 = 0.28673835125448033\n",
      "Epoch 24: Train Loss = 0.012719778588441763, Recall = 0.18222222222222223, Aging Rate = 0.0004454413846863615, Precision = 0.7321428571428571, f1 = 0.2918149466192171\n",
      "Epoch 25: Train Loss = 0.012815249032060343, Recall = 0.17777777777777778, Aging Rate = 0.0004772586264496731, Precision = 0.6666666666666666, f1 = 0.2807017543859649\n",
      "Test Loss = 0.01115806560587094, Recall = 0.30666666666666664, Aging Rate = 0.0007079336292336818, precision = 0.7752808988764045\n",
      "\n",
      "Epoch 26: Train Loss = 0.012331567431543558, Recall = 0.2, Aging Rate = 0.0004693043160088452, Precision = 0.7627118644067796, f1 = 0.31690140845070425\n",
      "Epoch 27: Train Loss = 0.012167010511206005, Recall = 0.17333333333333334, Aging Rate = 0.0004295327638047058, Precision = 0.7222222222222222, f1 = 0.27956989247311825\n",
      "Epoch 28: Train Loss = 0.012134642602559313, Recall = 0.2088888888888889, Aging Rate = 0.0005329387995354683, Precision = 0.7014925373134329, f1 = 0.3219178082191781\n",
      "Epoch 29: Train Loss = 0.011931373513244714, Recall = 0.23555555555555555, Aging Rate = 0.0005647560412987799, Precision = 0.7464788732394366, f1 = 0.35810810810810806\n",
      "Epoch 30: Train Loss = 0.011777335797024812, Recall = 0.25333333333333335, Aging Rate = 0.0006363448352662308, Precision = 0.7125, f1 = 0.37377049180327876\n",
      "Test Loss = 0.011549112297399553, Recall = 0.08888888888888889, Aging Rate = 0.00019090345057986923, precision = 0.8333333333333334\n",
      "\n",
      "Epoch 31: Train Loss = 0.011623373329812116, Recall = 0.2311111111111111, Aging Rate = 0.000556801730857952, Precision = 0.7428571428571429, f1 = 0.352542372881356\n",
      "Epoch 32: Train Loss = 0.011476914392327222, Recall = 0.24, Aging Rate = 0.0005886189726212634, Precision = 0.7297297297297297, f1 = 0.3612040133779264\n",
      "Epoch 33: Train Loss = 0.011419428990394128, Recall = 0.2311111111111111, Aging Rate = 0.000556801730857952, Precision = 0.7428571428571429, f1 = 0.352542372881356\n",
      "Epoch 34: Train Loss = 0.011335707868637006, Recall = 0.2, Aging Rate = 0.0004931672473313289, Precision = 0.7258064516129032, f1 = 0.31358885017421606\n",
      "Epoch 35: Train Loss = 0.011245695153501179, Recall = 0.23555555555555555, Aging Rate = 0.0005408931099762962, Precision = 0.7794117647058824, f1 = 0.3617747440273037\n",
      "Test Loss = 0.009728700933490899, Recall = 0.28, Aging Rate = 0.0005170301786538125, precision = 0.9692307692307692\n",
      "Model in epoch 35 is saved.\n",
      "\n",
      "Epoch 36: Train Loss = 0.010991173488596573, Recall = 0.24888888888888888, Aging Rate = 0.0006045275935029192, Precision = 0.7368421052631579, f1 = 0.37209302325581395\n",
      "Epoch 37: Train Loss = 0.011134403976302656, Recall = 0.2311111111111111, Aging Rate = 0.0005965732830620913, Precision = 0.6933333333333334, f1 = 0.3466666666666667\n",
      "Epoch 38: Train Loss = 0.010755692990230955, Recall = 0.26222222222222225, Aging Rate = 0.0005806646621804355, Precision = 0.8082191780821918, f1 = 0.3959731543624161\n",
      "Epoch 39: Train Loss = 0.010831161522798232, Recall = 0.23555555555555555, Aging Rate = 0.0005408931099762962, Precision = 0.7794117647058824, f1 = 0.3617747440273037\n",
      "Epoch 40: Train Loss = 0.010716485735603697, Recall = 0.28444444444444444, Aging Rate = 0.0006442991457070587, Precision = 0.7901234567901234, f1 = 0.41830065359477125\n",
      "Test Loss = 0.009386104414843043, Recall = 0.3511111111111111, Aging Rate = 0.0007079336292336818, precision = 0.8876404494382022\n",
      "\n",
      "Epoch 41: Train Loss = 0.010792665398378849, Recall = 0.21333333333333335, Aging Rate = 0.0005011215577721567, Precision = 0.7619047619047619, f1 = 0.3333333333333333\n",
      "Epoch 42: Train Loss = 0.01072667452709138, Recall = 0.28888888888888886, Aging Rate = 0.0006442991457070587, Precision = 0.8024691358024691, f1 = 0.4248366013071896\n",
      "Epoch 43: Train Loss = 0.010524485731821078, Recall = 0.25333333333333335, Aging Rate = 0.0005647560412987799, Precision = 0.8028169014084507, f1 = 0.38513513513513514\n",
      "Epoch 44: Train Loss = 0.010378069858393343, Recall = 0.27555555555555555, Aging Rate = 0.0006283905248254029, Precision = 0.7848101265822784, f1 = 0.40789473684210525\n",
      "Epoch 45: Train Loss = 0.010414795776607238, Recall = 0.26222222222222225, Aging Rate = 0.0006363448352662308, Precision = 0.7375, f1 = 0.38688524590163936\n",
      "Test Loss = 0.009370314640413092, Recall = 0.36, Aging Rate = 0.0007477051814378211, precision = 0.8617021276595744\n",
      "\n",
      "Epoch 46: Train Loss = 0.01046581901101855, Recall = 0.27111111111111114, Aging Rate = 0.0006124819039437471, Precision = 0.7922077922077922, f1 = 0.40397350993377484\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 47: Train Loss = 0.010443228549478966, Recall = 0.2577777777777778, Aging Rate = 0.0005806646621804355, Precision = 0.7945205479452054, f1 = 0.38926174496644295\n",
      "Epoch 48: Train Loss = 0.010301879872941094, Recall = 0.28888888888888886, Aging Rate = 0.0006363448352662308, Precision = 0.8125, f1 = 0.4262295081967213\n",
      "Epoch 49: Train Loss = 0.010376245125919113, Recall = 0.27111111111111114, Aging Rate = 0.0006283905248254029, Precision = 0.7721518987341772, f1 = 0.40131578947368424\n",
      "Epoch 50: Train Loss = 0.010157513744847618, Recall = 0.28888888888888886, Aging Rate = 0.0006522534561478865, Precision = 0.7926829268292683, f1 = 0.42345276872964166\n",
      "Test Loss = 0.008934357310663284, Recall = 0.29777777777777775, Aging Rate = 0.0005965732830620913, precision = 0.8933333333333333\n",
      "\n",
      "Epoch 51: Train Loss = 0.01016779021367403, Recall = 0.27111111111111114, Aging Rate = 0.0005965732830620913, Precision = 0.8133333333333334, f1 = 0.4066666666666667\n",
      "Epoch 52: Train Loss = 0.010175285998852129, Recall = 0.28888888888888886, Aging Rate = 0.0006363448352662308, Precision = 0.8125, f1 = 0.4262295081967213\n",
      "Epoch 53: Train Loss = 0.010034620416836837, Recall = 0.26666666666666666, Aging Rate = 0.0006045275935029192, Precision = 0.7894736842105263, f1 = 0.39867109634551495\n",
      "Epoch 54: Train Loss = 0.010138434941256753, Recall = 0.29777777777777775, Aging Rate = 0.0006602077665887144, Precision = 0.8072289156626506, f1 = 0.4350649350649351\n",
      "Epoch 55: Train Loss = 0.009952533652116373, Recall = 0.30666666666666664, Aging Rate = 0.0006363448352662308, Precision = 0.8625, f1 = 0.45245901639344266\n",
      "Test Loss = 0.009474809819473125, Recall = 0.5377777777777778, Aging Rate = 0.0011454207034792155, precision = 0.8402777777777778\n",
      "\n",
      "Epoch 56: Train Loss = 0.010000043820510842, Recall = 0.32, Aging Rate = 0.0007079336292336818, Precision = 0.8089887640449438, f1 = 0.4585987261146497\n",
      "Epoch 57: Train Loss = 0.009895036184182153, Recall = 0.28444444444444444, Aging Rate = 0.0006602077665887144, Precision = 0.7710843373493976, f1 = 0.4155844155844156\n",
      "Epoch 58: Train Loss = 0.00992424276107512, Recall = 0.30666666666666664, Aging Rate = 0.0006840706979111981, Precision = 0.8023255813953488, f1 = 0.4437299035369774\n",
      "Epoch 59: Train Loss = 0.009926086431138055, Recall = 0.29333333333333333, Aging Rate = 0.0006602077665887144, Precision = 0.7951807228915663, f1 = 0.42857142857142855\n",
      "Epoch 60: Train Loss = 0.009979760617492053, Recall = 0.31555555555555553, Aging Rate = 0.0006761163874703702, Precision = 0.8352941176470589, f1 = 0.4580645161290323\n",
      "Test Loss = 0.00863448833749341, Recall = 0.4088888888888889, Aging Rate = 0.0008352025962869279, precision = 0.8761904761904762\n",
      "\n",
      "Epoch 61: Train Loss = 0.009798027444149487, Recall = 0.3244444444444444, Aging Rate = 0.0007238422501153376, Precision = 0.8021978021978022, f1 = 0.4620253164556962\n",
      "Epoch 62: Train Loss = 0.00981875175071206, Recall = 0.27111111111111114, Aging Rate = 0.0005886189726212634, Precision = 0.8243243243243243, f1 = 0.40802675585284287\n",
      "Epoch 63: Train Loss = 0.009792938203471446, Recall = 0.28888888888888886, Aging Rate = 0.0006442991457070587, Precision = 0.8024691358024691, f1 = 0.4248366013071896\n",
      "Epoch 64: Train Loss = 0.009792864975737975, Recall = 0.3244444444444444, Aging Rate = 0.000692025008352026, Precision = 0.8390804597701149, f1 = 0.46794871794871784\n",
      "Epoch 65: Train Loss = 0.009853276902805649, Recall = 0.28888888888888886, Aging Rate = 0.0006363448352662308, Precision = 0.8125, f1 = 0.4262295081967213\n",
      "Test Loss = 0.008528118517772267, Recall = 0.3466666666666667, Aging Rate = 0.0006840706979111981, precision = 0.9069767441860465\n",
      "\n",
      "Epoch 66: Train Loss = 0.009819338099768508, Recall = 0.32, Aging Rate = 0.0006761163874703702, Precision = 0.8470588235294118, f1 = 0.46451612903225803\n",
      "Epoch 67: Train Loss = 0.0097546906601226, Recall = 0.3244444444444444, Aging Rate = 0.000692025008352026, Precision = 0.8390804597701149, f1 = 0.46794871794871784\n",
      "Epoch 68: Train Loss = 0.009761602685239226, Recall = 0.3111111111111111, Aging Rate = 0.0006522534561478865, Precision = 0.8536585365853658, f1 = 0.4560260586319218\n",
      "Epoch 69: Train Loss = 0.009724070160063313, Recall = 0.29333333333333333, Aging Rate = 0.0006442991457070587, Precision = 0.8148148148148148, f1 = 0.43137254901960786\n",
      "Epoch 70: Train Loss = 0.009881621932372004, Recall = 0.31555555555555553, Aging Rate = 0.000692025008352026, Precision = 0.8160919540229885, f1 = 0.4551282051282051\n",
      "Test Loss = 0.009030634827074628, Recall = 0.52, Aging Rate = 0.0011533750139200432, precision = 0.8068965517241379\n",
      "\n",
      "Epoch 71: Train Loss = 0.00976654671461859, Recall = 0.30666666666666664, Aging Rate = 0.0007317965605561653, Precision = 0.75, f1 = 0.43533123028391163\n",
      "Epoch 72: Train Loss = 0.0095668446188449, Recall = 0.32, Aging Rate = 0.000692025008352026, Precision = 0.8275862068965517, f1 = 0.46153846153846156\n",
      "Epoch 73: Train Loss = 0.009737604805484587, Recall = 0.32, Aging Rate = 0.0007158879396745097, Precision = 0.8, f1 = 0.45714285714285713\n",
      "Epoch 74: Train Loss = 0.00971335855069336, Recall = 0.3022222222222222, Aging Rate = 0.0006840706979111981, Precision = 0.7906976744186046, f1 = 0.4372990353697749\n",
      "Epoch 75: Train Loss = 0.0096352133323301, Recall = 0.32, Aging Rate = 0.0006840706979111981, Precision = 0.8372093023255814, f1 = 0.46302250803858525\n",
      "Test Loss = 0.008594144293699053, Recall = 0.4488888888888889, Aging Rate = 0.0009306543215768625, precision = 0.8632478632478633\n",
      "\n",
      "Epoch 76: Train Loss = 0.009674583858343348, Recall = 0.3022222222222222, Aging Rate = 0.0006124819039437471, Precision = 0.8831168831168831, f1 = 0.4503311258278146\n",
      "Epoch 77: Train Loss = 0.009588350191326925, Recall = 0.30666666666666664, Aging Rate = 0.0006681620770295423, Precision = 0.8214285714285714, f1 = 0.44660194174757273\n",
      "Epoch 78: Train Loss = 0.009620270108340868, Recall = 0.3333333333333333, Aging Rate = 0.0007238422501153376, Precision = 0.8241758241758241, f1 = 0.47468354430379744\n",
      "Epoch 79: Train Loss = 0.009647608856110823, Recall = 0.3111111111111111, Aging Rate = 0.0006522534561478865, Precision = 0.8536585365853658, f1 = 0.4560260586319218\n",
      "Epoch 80: Train Loss = 0.009452342035625174, Recall = 0.3333333333333333, Aging Rate = 0.0007238422501153376, Precision = 0.8241758241758241, f1 = 0.47468354430379744\n",
      "Test Loss = 0.0095620431191837, Recall = 0.5822222222222222, Aging Rate = 0.0013522327749407404, precision = 0.7705882352941177\n",
      "\n",
      "Epoch 81: Train Loss = 0.009609291794435527, Recall = 0.35555555555555557, Aging Rate = 0.0007158879396745097, Precision = 0.8888888888888888, f1 = 0.5079365079365079\n",
      "Epoch 82: Train Loss = 0.009425725599317774, Recall = 0.29333333333333333, Aging Rate = 0.0006442991457070587, Precision = 0.8148148148148148, f1 = 0.43137254901960786\n",
      "Epoch 83: Train Loss = 0.009504436008962521, Recall = 0.3288888888888889, Aging Rate = 0.0007158879396745097, Precision = 0.8222222222222222, f1 = 0.4698412698412698\n",
      "Epoch 84: Train Loss = 0.009490835050600367, Recall = 0.31555555555555553, Aging Rate = 0.0006602077665887144, Precision = 0.8554216867469879, f1 = 0.46103896103896097\n",
      "Epoch 85: Train Loss = 0.009389827178329526, Recall = 0.3511111111111111, Aging Rate = 0.0007158879396745097, Precision = 0.8777777777777778, f1 = 0.5015873015873015\n",
      "Test Loss = 0.00930850172269319, Recall = 0.5066666666666667, Aging Rate = 0.0011931465661241827, precision = 0.76\n",
      "\n",
      "Training Finished at epoch 85.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b76b4838b8946c4b4b156a6c05e3c06",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss = 0.03707905344328084, Recall = 0.0, Aging Rate = 0.0015113069623525481, Precision = 0.0, f1 = 0\n",
      "Epoch 2: Train Loss = 0.026982080283929, Recall = 0.0, Aging Rate = 0.0, Precision = 0, f1 = 0\n",
      "Epoch 3: Train Loss = 0.026428536157514063, Recall = 0.0, Aging Rate = 0.0, Precision = 0, f1 = 0\n",
      "Epoch 4: Train Loss = 0.026394561767587577, Recall = 0.0, Aging Rate = 0.0, Precision = 0, f1 = 0\n",
      "Epoch 5: Train Loss = 0.025253763140967108, Recall = 0.0, Aging Rate = 0.0, Precision = 0, f1 = 0\n",
      "Test Loss = 0.023389086795931966, Recall = 0.0, Aging Rate = 0.0, precision = 0\n",
      "\n",
      "Epoch 6: Train Loss = 0.023739031127198967, Recall = 0.0, Aging Rate = 0.0, Precision = 0, f1 = 0\n",
      "Epoch 7: Train Loss = 0.02258209447180941, Recall = 0.008888888888888889, Aging Rate = 1.590849434055314e-05, Precision = 0, f1 = 0.0\n",
      "Epoch 8: Train Loss = 0.02156140916179157, Recall = 0.02666666666666667, Aging Rate = 5.567973019193598e-05, Precision = 0.8571428571428571, f1 = 0.05172413793103449\n",
      "Epoch 9: Train Loss = 0.02057529156029082, Recall = 0.03111111111111111, Aging Rate = 7.158822453248912e-05, Precision = 0.7777777777777778, f1 = 0.05982905982905983\n",
      "Epoch 10: Train Loss = 0.019602364444171228, Recall = 0.05333333333333334, Aging Rate = 0.00013522220189470167, Precision = 0.7058823529411765, f1 = 0.09917355371900827\n",
      "Test Loss = 0.018347421142285488, Recall = 0.0, Aging Rate = 0.0, precision = 0\n",
      "\n",
      "Epoch 11: Train Loss = 0.019088506332191685, Recall = 0.04, Aging Rate = 0.00013522220189470167, Precision = 0.5294117647058824, f1 = 0.07438016528925619\n",
      "Epoch 12: Train Loss = 0.018333015411887733, Recall = 0.06666666666666667, Aging Rate = 0.00017499343774608452, Precision = 0.6818181818181818, f1 = 0.1214574898785425\n",
      "Epoch 13: Train Loss = 0.017605907730270227, Recall = 0.08444444444444445, Aging Rate = 0.00022271892076774393, Precision = 0.6785714285714286, f1 = 0.15019762845849802\n",
      "Epoch 14: Train Loss = 0.017410953350158093, Recall = 0.09777777777777778, Aging Rate = 0.00023862741510829706, Precision = 0.7333333333333333, f1 = 0.17254901960784313\n",
      "Epoch 15: Train Loss = 0.01697368804815475, Recall = 0.10666666666666667, Aging Rate = 0.00027044440378940334, Precision = 0.7058823529411765, f1 = 0.18532818532818532\n",
      "Test Loss = 0.015501825482308136, Recall = 0.05333333333333334, Aging Rate = 0.0001034052132135954, precision = 0.9230769230769231\n",
      "Model in epoch 15 is saved.\n",
      "\n",
      "Epoch 16: Train Loss = 0.016594618032102923, Recall = 0.10666666666666667, Aging Rate = 0.00027839865095967994, Precision = 0.6857142857142857, f1 = 0.18461538461538463\n",
      "Epoch 17: Train Loss = 0.01633097310147036, Recall = 0.10666666666666667, Aging Rate = 0.00027044440378940334, Precision = 0.7058823529411765, f1 = 0.18532818532818532\n",
      "Epoch 18: Train Loss = 0.015837329246837537, Recall = 0.15555555555555556, Aging Rate = 0.00042952934719493475, Precision = 0.6481481481481481, f1 = 0.25089605734767023\n",
      "Epoch 19: Train Loss = 0.015544997455567644, Recall = 0.14666666666666667, Aging Rate = 0.0003977123585138285, Precision = 0.66, f1 = 0.24000000000000005\n",
      "Epoch 20: Train Loss = 0.015359527544699996, Recall = 0.16444444444444445, Aging Rate = 0.0004136208528543816, Precision = 0.7115384615384616, f1 = 0.2671480144404332\n",
      "Test Loss = 0.014014514418339195, Recall = 0.08444444444444445, Aging Rate = 0.00015908494340553139, precision = 0.95\n",
      "Model in epoch 20 is saved.\n",
      "\n",
      "Epoch 21: Train Loss = 0.014880736005807355, Recall = 0.16, Aging Rate = 0.0003818038641732753, Precision = 0.75, f1 = 0.26373626373626374\n",
      "Epoch 22: Train Loss = 0.014717690928401285, Recall = 0.14222222222222222, Aging Rate = 0.0003261241339813393, Precision = 0.7804878048780488, f1 = 0.24060150375939848\n",
      "Epoch 23: Train Loss = 0.014414853977659223, Recall = 0.1511111111111111, Aging Rate = 0.00040566660568410503, Precision = 0.6666666666666666, f1 = 0.2463768115942029\n",
      "Epoch 24: Train Loss = 0.014001940108012093, Recall = 0.2, Aging Rate = 0.00047725483021659413, Precision = 0.75, f1 = 0.31578947368421056\n",
      "Epoch 25: Train Loss = 0.013757479189721146, Recall = 0.2, Aging Rate = 0.0004931633245571472, Precision = 0.7258064516129032, f1 = 0.31358885017421606\n",
      "Test Loss = 0.012467180859280816, Recall = 0.14666666666666667, Aging Rate = 0.0002863528981299565, precision = 0.9166666666666666\n",
      "\n",
      "Epoch 26: Train Loss = 0.013693929785114552, Recall = 0.17777777777777778, Aging Rate = 0.00047725483021659413, Precision = 0.6666666666666666, f1 = 0.2807017543859649\n",
      "Epoch 27: Train Loss = 0.013448330749339845, Recall = 0.19555555555555557, Aging Rate = 0.00047725483021659413, Precision = 0.7333333333333333, f1 = 0.3087719298245614\n",
      "Epoch 28: Train Loss = 0.013467491094341621, Recall = 0.1688888888888889, Aging Rate = 0.0004931633245571472, Precision = 0.6129032258064516, f1 = 0.26480836236933797\n",
      "Epoch 29: Train Loss = 0.012984012801099055, Recall = 0.21333333333333335, Aging Rate = 0.0005329345604085301, Precision = 0.7164179104477612, f1 = 0.3287671232876712\n",
      "Epoch 30: Train Loss = 0.013066311002984022, Recall = 0.2088888888888889, Aging Rate = 0.00048520907738687074, Precision = 0.7704918032786885, f1 = 0.32867132867132864\n",
      "Test Loss = 0.012484489565345076, Recall = 0.36, Aging Rate = 0.0010658691208170602, precision = 0.6044776119402985\n",
      "\n",
      "Epoch 31: Train Loss = 0.012900472217136758, Recall = 0.2222222222222222, Aging Rate = 0.0005329345604085301, Precision = 0.746268656716418, f1 = 0.3424657534246575\n",
      "Epoch 32: Train Loss = 0.012813559730710635, Recall = 0.2222222222222222, Aging Rate = 0.0005567973019193599, Precision = 0.7142857142857143, f1 = 0.3389830508474576\n",
      "Epoch 33: Train Loss = 0.012541497818923334, Recall = 0.21333333333333335, Aging Rate = 0.0005329345604085301, Precision = 0.7164179104477612, f1 = 0.3287671232876712\n",
      "Epoch 34: Train Loss = 0.012485335141302711, Recall = 0.21333333333333335, Aging Rate = 0.0005249803132382536, Precision = 0.7272727272727273, f1 = 0.3298969072164949\n",
      "Epoch 35: Train Loss = 0.012377665508827136, Recall = 0.20444444444444446, Aging Rate = 0.0005408888075788067, Precision = 0.6764705882352942, f1 = 0.31399317406143346\n",
      "Test Loss = 0.0111564569227314, Recall = 0.25333333333333335, Aging Rate = 0.000517026066067977, precision = 0.8769230769230769\n",
      "Model in epoch 35 is saved.\n",
      "\n",
      "Epoch 36: Train Loss = 0.012280888500856305, Recall = 0.21333333333333335, Aging Rate = 0.0005249803132382536, Precision = 0.7272727272727273, f1 = 0.3298969072164949\n",
      "Epoch 37: Train Loss = 0.012187711874545846, Recall = 0.21333333333333335, Aging Rate = 0.000517026066067977, Precision = 0.7384615384615385, f1 = 0.3310344827586207\n",
      "Epoch 38: Train Loss = 0.012078463836255604, Recall = 0.2577777777777778, Aging Rate = 0.000572705796259913, Precision = 0.8055555555555556, f1 = 0.3905723905723905\n",
      "Epoch 39: Train Loss = 0.012121180296903102, Recall = 0.2311111111111111, Aging Rate = 0.0005329345604085301, Precision = 0.7761194029850746, f1 = 0.3561643835616438\n",
      "Epoch 40: Train Loss = 0.011898095116868661, Recall = 0.25333333333333335, Aging Rate = 0.0005806600434301896, Precision = 0.7808219178082192, f1 = 0.3825503355704698\n",
      "Test Loss = 0.010566270385784005, Recall = 0.21777777777777776, Aging Rate = 0.00042157510002465814, precision = 0.9245283018867925\n",
      "Model in epoch 40 is saved.\n",
      "\n",
      "Epoch 41: Train Loss = 0.011884715036192796, Recall = 0.26666666666666666, Aging Rate = 0.0006124770321112959, Precision = 0.7792207792207793, f1 = 0.3973509933774835\n",
      "Epoch 42: Train Loss = 0.011783223215983046, Recall = 0.26222222222222225, Aging Rate = 0.0005886142906004661, Precision = 0.7972972972972973, f1 = 0.39464882943143814\n",
      "Epoch 43: Train Loss = 0.011737735974808603, Recall = 0.24444444444444444, Aging Rate = 0.0005488430547490832, Precision = 0.7971014492753623, f1 = 0.37414965986394555\n",
      "Epoch 44: Train Loss = 0.011673079365286056, Recall = 0.27111111111111114, Aging Rate = 0.0005886142906004661, Precision = 0.8243243243243243, f1 = 0.40802675585284287\n",
      "Epoch 45: Train Loss = 0.012018139652900085, Recall = 0.21333333333333335, Aging Rate = 0.0005329345604085301, Precision = 0.7164179104477612, f1 = 0.3287671232876712\n",
      "Test Loss = 0.010282546659230273, Recall = 0.29777777777777775, Aging Rate = 0.0005965685377707427, precision = 0.8933333333333333\n",
      "Model in epoch 45 is saved.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 46: Train Loss = 0.011758711385063153, Recall = 0.25333333333333335, Aging Rate = 0.0006204312792815724, Precision = 0.7307692307692307, f1 = 0.3762376237623763\n",
      "Epoch 47: Train Loss = 0.011530926614662382, Recall = 0.24, Aging Rate = 0.0006045227849410192, Precision = 0.7105263157894737, f1 = 0.3588039867109634\n",
      "Epoch 48: Train Loss = 0.011605180742528951, Recall = 0.2222222222222222, Aging Rate = 0.0005249803132382536, Precision = 0.7575757575757576, f1 = 0.34364261168384874\n",
      "Epoch 49: Train Loss = 0.011515431712040263, Recall = 0.26222222222222225, Aging Rate = 0.0006602025151329552, Precision = 0.7108433734939759, f1 = 0.38311688311688313\n",
      "Epoch 50: Train Loss = 0.011529529788121665, Recall = 0.2577777777777778, Aging Rate = 0.0005806600434301896, Precision = 0.7945205479452054, f1 = 0.38926174496644295\n",
      "Test Loss = 0.010304231750270074, Recall = 0.26222222222222225, Aging Rate = 0.000517026066067977, precision = 0.9076923076923077\n",
      "\n",
      "Epoch 51: Train Loss = 0.011502955714651998, Recall = 0.2577777777777778, Aging Rate = 0.0005647515490896364, Precision = 0.8169014084507042, f1 = 0.39189189189189183\n",
      "Epoch 52: Train Loss = 0.01135754602370375, Recall = 0.26222222222222225, Aging Rate = 0.0006522482679626787, Precision = 0.7195121951219512, f1 = 0.38436482084690554\n",
      "Epoch 53: Train Loss = 0.011505923619070359, Recall = 0.25333333333333335, Aging Rate = 0.0006204312792815724, Precision = 0.7307692307692307, f1 = 0.3762376237623763\n",
      "Epoch 54: Train Loss = 0.011352976465058064, Recall = 0.24888888888888888, Aging Rate = 0.0005647515490896364, Precision = 0.7887323943661971, f1 = 0.3783783783783784\n",
      "Epoch 55: Train Loss = 0.011258565400030885, Recall = 0.28444444444444444, Aging Rate = 0.0006602025151329552, Precision = 0.7710843373493976, f1 = 0.4155844155844156\n",
      "Test Loss = 0.010824205227042753, Recall = 0.4577777777777778, Aging Rate = 0.0010976861094981665, precision = 0.7463768115942029\n",
      "\n",
      "Epoch 56: Train Loss = 0.011266279697766921, Recall = 0.24888888888888888, Aging Rate = 0.0006045227849410192, Precision = 0.7368421052631579, f1 = 0.37209302325581395\n",
      "Epoch 57: Train Loss = 0.011181510390699714, Recall = 0.27111111111111114, Aging Rate = 0.0006761110094735084, Precision = 0.7176470588235294, f1 = 0.3935483870967742\n",
      "Epoch 58: Train Loss = 0.011341362992854336, Recall = 0.24888888888888888, Aging Rate = 0.0006045227849410192, Precision = 0.7368421052631579, f1 = 0.37209302325581395\n",
      "Epoch 59: Train Loss = 0.011271468379804446, Recall = 0.27111111111111114, Aging Rate = 0.0006761110094735084, Precision = 0.7176470588235294, f1 = 0.3935483870967742\n",
      "Epoch 60: Train Loss = 0.011134392151884477, Recall = 0.25333333333333335, Aging Rate = 0.0005647515490896364, Precision = 0.8028169014084507, f1 = 0.38513513513513514\n",
      "Test Loss = 0.009946151005122571, Recall = 0.25333333333333335, Aging Rate = 0.0004931633245571472, precision = 0.9193548387096774\n",
      "Model in epoch 60 is saved.\n",
      "\n",
      "Epoch 61: Train Loss = 0.011143070420490578, Recall = 0.27555555555555555, Aging Rate = 0.0006204312792815724, Precision = 0.7948717948717948, f1 = 0.40924092409240925\n",
      "Epoch 62: Train Loss = 0.01112180342497372, Recall = 0.26666666666666666, Aging Rate = 0.0006124770321112959, Precision = 0.7792207792207793, f1 = 0.3973509933774835\n",
      "Epoch 63: Train Loss = 0.011094749475721585, Recall = 0.2577777777777778, Aging Rate = 0.0005886142906004661, Precision = 0.7837837837837838, f1 = 0.38795986622073586\n",
      "Epoch 64: Train Loss = 0.01108964529460274, Recall = 0.24888888888888888, Aging Rate = 0.0006124770321112959, Precision = 0.7272727272727273, f1 = 0.37086092715231783\n",
      "Epoch 65: Train Loss = 0.011176278430366463, Recall = 0.23555555555555555, Aging Rate = 0.0005965685377707427, Precision = 0.7066666666666667, f1 = 0.35333333333333333\n",
      "Test Loss = 0.009861586910173019, Recall = 0.3377777777777778, Aging Rate = 0.0007874704698573804, precision = 0.7676767676767676\n",
      "\n",
      "Epoch 66: Train Loss = 0.010977971733426871, Recall = 0.29333333333333333, Aging Rate = 0.0006681567623032318, Precision = 0.7857142857142857, f1 = 0.42718446601941745\n",
      "Epoch 67: Train Loss = 0.010931703494489471, Recall = 0.26222222222222225, Aging Rate = 0.0005965685377707427, Precision = 0.7866666666666666, f1 = 0.3933333333333333\n",
      "Epoch 68: Train Loss = 0.01112238714998581, Recall = 0.2577777777777778, Aging Rate = 0.0005647515490896364, Precision = 0.8169014084507042, f1 = 0.39189189189189183\n",
      "Epoch 69: Train Loss = 0.011162022782198983, Recall = 0.25333333333333335, Aging Rate = 0.0006124770321112959, Precision = 0.7402597402597403, f1 = 0.3774834437086093\n",
      "Epoch 70: Train Loss = 0.010917548295484159, Recall = 0.28444444444444444, Aging Rate = 0.0006920195038140615, Precision = 0.735632183908046, f1 = 0.41025641025641024\n",
      "Test Loss = 0.010358187267131495, Recall = 0.27111111111111114, Aging Rate = 0.0006204312792815724, precision = 0.782051282051282\n",
      "\n",
      "Epoch 71: Train Loss = 0.011140702707721323, Recall = 0.27555555555555555, Aging Rate = 0.0006204312792815724, Precision = 0.7948717948717948, f1 = 0.40924092409240925\n",
      "Epoch 72: Train Loss = 0.01111691448607216, Recall = 0.26666666666666666, Aging Rate = 0.0006045227849410192, Precision = 0.7894736842105263, f1 = 0.39867109634551495\n",
      "Epoch 73: Train Loss = 0.011181466102668977, Recall = 0.24, Aging Rate = 0.0005965685377707427, Precision = 0.72, f1 = 0.36\n",
      "Epoch 74: Train Loss = 0.01083226401399231, Recall = 0.28444444444444444, Aging Rate = 0.0006602025151329552, Precision = 0.7710843373493976, f1 = 0.4155844155844156\n",
      "Epoch 75: Train Loss = 0.010970276424201304, Recall = 0.28, Aging Rate = 0.0006602025151329552, Precision = 0.7590361445783133, f1 = 0.40909090909090917\n",
      "Test Loss = 0.009865244271613099, Recall = 0.18666666666666668, Aging Rate = 0.00037384961700299876, precision = 0.8936170212765957\n",
      "\n",
      "Epoch 76: Train Loss = 0.010942224431150468, Recall = 0.26222222222222225, Aging Rate = 0.0006363397736221255, Precision = 0.7375, f1 = 0.38688524590163936\n",
      "Epoch 77: Train Loss = 0.010858304139890074, Recall = 0.28, Aging Rate = 0.0006522482679626787, Precision = 0.7682926829268293, f1 = 0.41042345276872966\n",
      "Epoch 78: Train Loss = 0.011118100723783221, Recall = 0.22666666666666666, Aging Rate = 0.000572705796259913, Precision = 0.7083333333333334, f1 = 0.3434343434343434\n",
      "Epoch 79: Train Loss = 0.011064085199367727, Recall = 0.26222222222222225, Aging Rate = 0.0006045227849410192, Precision = 0.7763157894736842, f1 = 0.3920265780730897\n",
      "Epoch 80: Train Loss = 0.010802494586250717, Recall = 0.26666666666666666, Aging Rate = 0.0005965685377707427, Precision = 0.8, f1 = 0.4\n",
      "Test Loss = 0.00990563172555329, Recall = 0.29777777777777775, Aging Rate = 0.0006442940207924021, precision = 0.8271604938271605\n",
      "\n",
      "Epoch 81: Train Loss = 0.010815262997299844, Recall = 0.25333333333333335, Aging Rate = 0.0006045227849410192, Precision = 0.75, f1 = 0.3787375415282392\n",
      "Epoch 82: Train Loss = 0.010985277712800477, Recall = 0.25333333333333335, Aging Rate = 0.0006045227849410192, Precision = 0.75, f1 = 0.3787375415282392\n",
      "Epoch 83: Train Loss = 0.010828025697863477, Recall = 0.26222222222222225, Aging Rate = 0.0006045227849410192, Precision = 0.7763157894736842, f1 = 0.3920265780730897\n",
      "Epoch 84: Train Loss = 0.01076197510938312, Recall = 0.27111111111111114, Aging Rate = 0.0006442940207924021, Precision = 0.7530864197530864, f1 = 0.39869281045751637\n",
      "Epoch 85: Train Loss = 0.010696706069094553, Recall = 0.28444444444444444, Aging Rate = 0.0006522482679626787, Precision = 0.7804878048780488, f1 = 0.41693811074918563\n",
      "Test Loss = 0.010566790597762856, Recall = 0.21333333333333335, Aging Rate = 0.0003977123585138285, precision = 0.96\n",
      "Model in epoch 85 is saved.\n",
      "\n",
      "Epoch 86: Train Loss = 0.010848462879516402, Recall = 0.27555555555555555, Aging Rate = 0.0006681567623032318, Precision = 0.7380952380952381, f1 = 0.40129449838187703\n",
      "Epoch 87: Train Loss = 0.010801262994739097, Recall = 0.25333333333333335, Aging Rate = 0.0005886142906004661, Precision = 0.7702702702702703, f1 = 0.3812709030100335\n",
      "Epoch 88: Train Loss = 0.010640761246434066, Recall = 0.2577777777777778, Aging Rate = 0.0005886142906004661, Precision = 0.7837837837837838, f1 = 0.38795986622073586\n",
      "Epoch 89: Train Loss = 0.010821781946331096, Recall = 0.25333333333333335, Aging Rate = 0.000572705796259913, Precision = 0.7916666666666666, f1 = 0.38383838383838387\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 90: Train Loss = 0.01067984727669398, Recall = 0.30666666666666664, Aging Rate = 0.0006522482679626787, Precision = 0.8414634146341463, f1 = 0.4495114006514658\n",
      "Test Loss = 0.00938478343992809, Recall = 0.37333333333333335, Aging Rate = 0.000739744986835721, precision = 0.9032258064516129\n",
      "Model in epoch 90 is saved.\n",
      "\n",
      "Epoch 91: Train Loss = 0.010698531281590113, Recall = 0.27111111111111114, Aging Rate = 0.0006602025151329552, Precision = 0.7349397590361446, f1 = 0.3961038961038961\n",
      "Epoch 92: Train Loss = 0.010615568251019392, Recall = 0.26222222222222225, Aging Rate = 0.0005886142906004661, Precision = 0.7972972972972973, f1 = 0.39464882943143814\n",
      "Epoch 93: Train Loss = 0.01083493093592226, Recall = 0.26666666666666666, Aging Rate = 0.0006124770321112959, Precision = 0.7792207792207793, f1 = 0.3973509933774835\n",
      "Epoch 94: Train Loss = 0.01064168320300578, Recall = 0.29777777777777775, Aging Rate = 0.0006442940207924021, Precision = 0.8271604938271605, f1 = 0.4379084967320261\n",
      "Epoch 95: Train Loss = 0.010610900976690872, Recall = 0.26222222222222225, Aging Rate = 0.0005806600434301896, Precision = 0.8082191780821918, f1 = 0.3959731543624161\n",
      "Test Loss = 0.009616759233100592, Recall = 0.26666666666666666, Aging Rate = 0.0004931633245571472, precision = 0.967741935483871\n",
      "Model in epoch 95 is saved.\n",
      "\n",
      "Epoch 96: Train Loss = 0.010750559976603853, Recall = 0.27555555555555555, Aging Rate = 0.0006602025151329552, Precision = 0.7469879518072289, f1 = 0.4025974025974026\n",
      "Epoch 97: Train Loss = 0.01068622483496145, Recall = 0.27555555555555555, Aging Rate = 0.0006681567623032318, Precision = 0.7380952380952381, f1 = 0.40129449838187703\n",
      "Epoch 98: Train Loss = 0.010651324901969603, Recall = 0.25333333333333335, Aging Rate = 0.0005965685377707427, Precision = 0.76, f1 = 0.38\n",
      "Epoch 99: Train Loss = 0.010782516567418472, Recall = 0.2577777777777778, Aging Rate = 0.0005886142906004661, Precision = 0.7837837837837838, f1 = 0.38795986622073586\n",
      "Epoch 100: Train Loss = 0.010825871324433209, Recall = 0.2577777777777778, Aging Rate = 0.0005806600434301896, Precision = 0.7945205479452054, f1 = 0.38926174496644295\n",
      "Test Loss = 0.009439390432217726, Recall = 0.31555555555555553, Aging Rate = 0.0006124770321112959, precision = 0.922077922077922\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "65eb3536761e47f4bffbfabf795d4370",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss = 0.03490002695769076, Recall = 0.0, Aging Rate = 0.0005488517861546171, Precision = 0.0, f1 = 0\n",
      "Epoch 2: Train Loss = 0.026627826282381514, Recall = 0.0, Aging Rate = 0.0, Precision = 0, f1 = 0\n",
      "Epoch 3: Train Loss = 0.026302856279462807, Recall = 0.0, Aging Rate = 0.0, Precision = 0, f1 = 0\n",
      "Epoch 4: Train Loss = 0.025829409489750862, Recall = 0.0, Aging Rate = 0.0, Precision = 0, f1 = 0\n",
      "Epoch 5: Train Loss = 0.025281454469398838, Recall = 0.0, Aging Rate = 0.0, Precision = 0, f1 = 0\n",
      "Test Loss = 0.02341007912525554, Recall = 0.0, Aging Rate = 0.0, precision = 0\n",
      "\n",
      "Epoch 6: Train Loss = 0.023992743047997006, Recall = 0.0, Aging Rate = 0.0, Precision = 0, f1 = 0\n",
      "Epoch 7: Train Loss = 0.022839518931504762, Recall = 0.0, Aging Rate = 0.0, Precision = 0, f1 = 0\n",
      "Epoch 8: Train Loss = 0.021681971931793713, Recall = 0.008928571428571428, Aging Rate = 2.3863121137157266e-05, Precision = 0.6666666666666666, f1 = 0.01762114537444934\n",
      "Epoch 9: Train Loss = 0.02070714772609135, Recall = 0.022321428571428572, Aging Rate = 7.954373712385755e-05, Precision = 0.5, f1 = 0.042735042735042736\n",
      "Epoch 10: Train Loss = 0.01970540638222609, Recall = 0.049107142857142856, Aging Rate = 0.00012726997939817208, Precision = 0.6875, f1 = 0.09166666666666666\n",
      "Test Loss = 0.017927403998829576, Recall = 0.08928571428571429, Aging Rate = 0.00019090496909725813, precision = 0.8333333333333334\n",
      "Model in epoch 10 is saved.\n",
      "\n",
      "Epoch 11: Train Loss = 0.01887150475782018, Recall = 0.049107142857142856, Aging Rate = 0.00012726997939817208, Precision = 0.6875, f1 = 0.09166666666666666\n",
      "Epoch 12: Train Loss = 0.018326530667574722, Recall = 0.07142857142857142, Aging Rate = 0.00017499622167248662, Precision = 0.7272727272727273, f1 = 0.13008130081300812\n",
      "Epoch 13: Train Loss = 0.017610241921035608, Recall = 0.07589285714285714, Aging Rate = 0.00018295059538487237, Precision = 0.7391304347826086, f1 = 0.13765182186234817\n",
      "Epoch 14: Train Loss = 0.016814204505219105, Recall = 0.12946428571428573, Aging Rate = 0.0003022662010706587, Precision = 0.7631578947368421, f1 = 0.22137404580152675\n",
      "Epoch 15: Train Loss = 0.01651068451023414, Recall = 0.12946428571428573, Aging Rate = 0.00032612932220781596, Precision = 0.7073170731707317, f1 = 0.21886792452830192\n",
      "Test Loss = 0.015518746469178153, Recall = 0.29017857142857145, Aging Rate = 0.0007715742501014182, precision = 0.6701030927835051\n",
      "\n",
      "Epoch 16: Train Loss = 0.016080115926627295, Recall = 0.12946428571428573, Aging Rate = 0.0003181749484954302, Precision = 0.725, f1 = 0.2196969696969697\n",
      "Epoch 17: Train Loss = 0.015650306700167517, Recall = 0.15178571428571427, Aging Rate = 0.00038180993819451626, Precision = 0.7083333333333334, f1 = 0.24999999999999997\n",
      "Epoch 18: Train Loss = 0.015132098868759809, Recall = 0.16071428571428573, Aging Rate = 0.00040567305933167353, Precision = 0.7058823529411765, f1 = 0.26181818181818184\n",
      "Epoch 19: Train Loss = 0.014779032790382646, Recall = 0.16517857142857142, Aging Rate = 0.00042158180675644504, Precision = 0.6981132075471698, f1 = 0.26714801444043323\n",
      "Epoch 20: Train Loss = 0.014493905157460352, Recall = 0.16517857142857142, Aging Rate = 0.00040567305933167353, Precision = 0.7254901960784313, f1 = 0.2690909090909091\n",
      "Test Loss = 0.012836379225101118, Recall = 0.3169642857142857, Aging Rate = 0.000715893634114718, precision = 0.7888888888888889\n",
      "Model in epoch 20 is saved.\n",
      "\n",
      "Epoch 21: Train Loss = 0.013895408644735109, Recall = 0.19642857142857142, Aging Rate = 0.0004613536753183738, Precision = 0.7586206896551724, f1 = 0.3120567375886525\n",
      "Epoch 22: Train Loss = 0.013720955556213504, Recall = 0.21428571428571427, Aging Rate = 0.0004693080490307596, Precision = 0.8135593220338984, f1 = 0.3392226148409894\n",
      "Epoch 23: Train Loss = 0.0133287168796516, Recall = 0.21875, Aging Rate = 0.0005170342913050741, Precision = 0.7538461538461538, f1 = 0.3391003460207612\n",
      "Epoch 24: Train Loss = 0.013211409824006462, Recall = 0.23660714285714285, Aging Rate = 0.0005568061598670028, Precision = 0.7571428571428571, f1 = 0.36054421768707484\n",
      "Epoch 25: Train Loss = 0.012860371646730583, Recall = 0.24553571428571427, Aging Rate = 0.0006045324021413174, Precision = 0.7236842105263158, f1 = 0.36666666666666664\n",
      "Test Loss = 0.011850208990639063, Recall = 0.19642857142857142, Aging Rate = 0.00040567305933167353, precision = 0.8627450980392157\n",
      "Model in epoch 25 is saved.\n",
      "\n",
      "Epoch 26: Train Loss = 0.012762860035946122, Recall = 0.21428571428571427, Aging Rate = 0.0005090799175926883, Precision = 0.75, f1 = 0.3333333333333333\n",
      "Epoch 27: Train Loss = 0.01232646432899923, Recall = 0.22321428571428573, Aging Rate = 0.0005727149072917744, Precision = 0.6944444444444444, f1 = 0.3378378378378379\n",
      "Epoch 28: Train Loss = 0.012295532541306964, Recall = 0.22767857142857142, Aging Rate = 0.0005090799175926883, Precision = 0.796875, f1 = 0.3541666666666667\n",
      "Epoch 29: Train Loss = 0.01201693435417601, Recall = 0.25892857142857145, Aging Rate = 0.0005727149072917744, Precision = 0.8055555555555556, f1 = 0.39189189189189194\n",
      "Epoch 30: Train Loss = 0.011954659175865471, Recall = 0.22767857142857142, Aging Rate = 0.0005488517861546171, Precision = 0.7391304347826086, f1 = 0.3481228668941979\n",
      "Test Loss = 0.01076114411010193, Recall = 0.33035714285714285, Aging Rate = 0.0007397567552518752, precision = 0.7956989247311828\n",
      "\n",
      "Epoch 31: Train Loss = 0.011894949289407463, Recall = 0.2857142857142857, Aging Rate = 0.0006363498969908604, Precision = 0.8, f1 = 0.4210526315789473\n",
      "Epoch 32: Train Loss = 0.01177417014573411, Recall = 0.29464285714285715, Aging Rate = 0.0006363498969908604, Precision = 0.825, f1 = 0.43421052631578944\n",
      "Epoch 33: Train Loss = 0.011495142419036234, Recall = 0.27232142857142855, Aging Rate = 0.0006283955232784747, Precision = 0.7721518987341772, f1 = 0.40264026402640263\n",
      "Epoch 34: Train Loss = 0.01164567245102979, Recall = 0.27232142857142855, Aging Rate = 0.0006443042707032462, Precision = 0.7530864197530864, f1 = 0.39999999999999997\n",
      "Epoch 35: Train Loss = 0.01124113778733771, Recall = 0.2857142857142857, Aging Rate = 0.0006204411495660889, Precision = 0.8205128205128205, f1 = 0.42384105960264895\n",
      "Test Loss = 0.01015807939235123, Recall = 0.32142857142857145, Aging Rate = 0.0006522586444156319, precision = 0.8780487804878049\n",
      "Model in epoch 35 is saved.\n",
      "\n",
      "Epoch 36: Train Loss = 0.011261759000882082, Recall = 0.25892857142857145, Aging Rate = 0.0006045324021413174, Precision = 0.7631578947368421, f1 = 0.38666666666666666\n",
      "Epoch 37: Train Loss = 0.011279198594591186, Recall = 0.29910714285714285, Aging Rate = 0.0006920305129775608, Precision = 0.7701149425287356, f1 = 0.4308681672025723\n",
      "Epoch 38: Train Loss = 0.011082814823519629, Recall = 0.27232142857142855, Aging Rate = 0.0006283955232784747, Precision = 0.7721518987341772, f1 = 0.40264026402640263\n",
      "Epoch 39: Train Loss = 0.011213451561847037, Recall = 0.25, Aging Rate = 0.0006204411495660889, Precision = 0.717948717948718, f1 = 0.3708609271523179\n",
      "Epoch 40: Train Loss = 0.011105860358289416, Recall = 0.29017857142857145, Aging Rate = 0.0006681673918404034, Precision = 0.7738095238095238, f1 = 0.42207792207792205\n",
      "Test Loss = 0.009836623025481358, Recall = 0.39732142857142855, Aging Rate = 0.0008511179872252758, precision = 0.8317757009345794\n",
      "\n",
      "Epoch 41: Train Loss = 0.010866793416277672, Recall = 0.29017857142857145, Aging Rate = 0.0006602130181280177, Precision = 0.7831325301204819, f1 = 0.4234527687296417\n",
      "Epoch 42: Train Loss = 0.010764717591815824, Recall = 0.29017857142857145, Aging Rate = 0.0006681673918404034, Precision = 0.7738095238095238, f1 = 0.42207792207792205\n",
      "Epoch 43: Train Loss = 0.010829373057803798, Recall = 0.25892857142857145, Aging Rate = 0.0005886236547165459, Precision = 0.7837837837837838, f1 = 0.389261744966443\n",
      "Epoch 44: Train Loss = 0.010944416450274577, Recall = 0.3080357142857143, Aging Rate = 0.0007397567552518752, Precision = 0.7419354838709677, f1 = 0.43533123028391174\n",
      "Epoch 45: Train Loss = 0.01078765006458288, Recall = 0.3080357142857143, Aging Rate = 0.000715893634114718, Precision = 0.7666666666666667, f1 = 0.4394904458598726\n",
      "Test Loss = 0.009326019918826136, Recall = 0.26785714285714285, Aging Rate = 0.0005011255438803026, precision = 0.9523809523809523\n",
      "Model in epoch 45 is saved.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 46: Train Loss = 0.010715364131726277, Recall = 0.26339285714285715, Aging Rate = 0.0006045324021413174, Precision = 0.7763157894736842, f1 = 0.39333333333333337\n",
      "Epoch 47: Train Loss = 0.010577600920172455, Recall = 0.3080357142857143, Aging Rate = 0.0006920305129775608, Precision = 0.7931034482758621, f1 = 0.44372990353697744\n",
      "Epoch 48: Train Loss = 0.01064458404053708, Recall = 0.29017857142857145, Aging Rate = 0.0006681673918404034, Precision = 0.7738095238095238, f1 = 0.42207792207792205\n",
      "Epoch 49: Train Loss = 0.010524984482686444, Recall = 0.2857142857142857, Aging Rate = 0.0006124867758537032, Precision = 0.8311688311688312, f1 = 0.4252491694352159\n",
      "Epoch 50: Train Loss = 0.010450895542535843, Recall = 0.30357142857142855, Aging Rate = 0.0006761217655527893, Precision = 0.8, f1 = 0.4401294498381877\n",
      "Test Loss = 0.009994404409007849, Recall = 0.44642857142857145, Aging Rate = 0.001169292935720706, precision = 0.6802721088435374\n",
      "\n",
      "Epoch 51: Train Loss = 0.01054436833252925, Recall = 0.28125, Aging Rate = 0.0006681673918404034, Precision = 0.75, f1 = 0.4090909090909091\n",
      "Epoch 52: Train Loss = 0.010246462532467675, Recall = 0.3125, Aging Rate = 0.000684076139265175, Precision = 0.813953488372093, f1 = 0.45161290322580644\n",
      "Epoch 53: Train Loss = 0.010513238889503645, Recall = 0.3080357142857143, Aging Rate = 0.0007318023815394895, Precision = 0.75, f1 = 0.43670886075949367\n",
      "Epoch 54: Train Loss = 0.010406982815246345, Recall = 0.29017857142857145, Aging Rate = 0.0006443042707032462, Precision = 0.8024691358024691, f1 = 0.4262295081967214\n",
      "Epoch 55: Train Loss = 0.010316839698910323, Recall = 0.3080357142857143, Aging Rate = 0.0007238480078271037, Precision = 0.7582417582417582, f1 = 0.4380952380952381\n",
      "Test Loss = 0.008914089573643246, Recall = 0.42410714285714285, Aging Rate = 0.0008431636135128901, precision = 0.8962264150943396\n",
      "Model in epoch 55 is saved.\n",
      "\n",
      "Epoch 56: Train Loss = 0.0103907288885796, Recall = 0.29910714285714285, Aging Rate = 0.0006761217655527893, Precision = 0.788235294117647, f1 = 0.43365695792880254\n",
      "Epoch 57: Train Loss = 0.010332277690950289, Recall = 0.28125, Aging Rate = 0.0006522586444156319, Precision = 0.7682926829268293, f1 = 0.411764705882353\n",
      "Epoch 58: Train Loss = 0.01027165477929634, Recall = 0.3392857142857143, Aging Rate = 0.0007079392604023322, Precision = 0.8539325842696629, f1 = 0.4856230031948882\n",
      "Epoch 59: Train Loss = 0.01043193844523824, Recall = 0.2857142857142857, Aging Rate = 0.000684076139265175, Precision = 0.7441860465116279, f1 = 0.4129032258064516\n",
      "Epoch 60: Train Loss = 0.010359031006690018, Recall = 0.3080357142857143, Aging Rate = 0.0007318023815394895, Precision = 0.75, f1 = 0.43670886075949367\n",
      "Test Loss = 0.009882720993978642, Recall = 0.48660714285714285, Aging Rate = 0.001201110430570249, precision = 0.7218543046357616\n",
      "\n",
      "Epoch 61: Train Loss = 0.010095435182116298, Recall = 0.30357142857142855, Aging Rate = 0.0006761217655527893, Precision = 0.8, f1 = 0.4401294498381877\n",
      "Epoch 62: Train Loss = 0.010132054226959966, Recall = 0.32142857142857145, Aging Rate = 0.000779528623813804, Precision = 0.7346938775510204, f1 = 0.4472049689440994\n",
      "Epoch 63: Train Loss = 0.010065751378345459, Recall = 0.28125, Aging Rate = 0.0006522586444156319, Precision = 0.7682926829268293, f1 = 0.411764705882353\n",
      "Epoch 64: Train Loss = 0.01012934812979921, Recall = 0.3169642857142857, Aging Rate = 0.000684076139265175, Precision = 0.8255813953488372, f1 = 0.45806451612903226\n",
      "Epoch 65: Train Loss = 0.010063811617287569, Recall = 0.2767857142857143, Aging Rate = 0.0006363498969908604, Precision = 0.775, f1 = 0.40789473684210525\n",
      "Test Loss = 0.008641115865275575, Recall = 0.32142857142857145, Aging Rate = 0.0006522586444156319, precision = 0.8780487804878049\n",
      "\n",
      "Epoch 66: Train Loss = 0.009970204282244242, Recall = 0.32142857142857145, Aging Rate = 0.0006920305129775608, Precision = 0.8275862068965517, f1 = 0.4630225080385852\n",
      "Epoch 67: Train Loss = 0.009959124976190102, Recall = 0.32589285714285715, Aging Rate = 0.000715893634114718, Precision = 0.8111111111111111, f1 = 0.46496815286624205\n",
      "Epoch 68: Train Loss = 0.009921740781571042, Recall = 0.3125, Aging Rate = 0.0006920305129775608, Precision = 0.8045977011494253, f1 = 0.45016077170418\n",
      "Epoch 69: Train Loss = 0.00988825624337811, Recall = 0.33482142857142855, Aging Rate = 0.0007079392604023322, Precision = 0.8426966292134831, f1 = 0.4792332268370607\n",
      "Epoch 70: Train Loss = 0.009888741022338879, Recall = 0.33035714285714285, Aging Rate = 0.000779528623813804, Precision = 0.7551020408163265, f1 = 0.4596273291925466\n",
      "Test Loss = 0.008627513843871023, Recall = 0.36160714285714285, Aging Rate = 0.0006761217655527893, precision = 0.9529411764705882\n",
      "Model in epoch 70 is saved.\n",
      "\n",
      "Epoch 71: Train Loss = 0.009880187702085527, Recall = 0.30357142857142855, Aging Rate = 0.000684076139265175, Precision = 0.7906976744186046, f1 = 0.4387096774193548\n",
      "Epoch 72: Train Loss = 0.009959751052866362, Recall = 0.3169642857142857, Aging Rate = 0.0007079392604023322, Precision = 0.797752808988764, f1 = 0.45367412140575086\n",
      "Epoch 73: Train Loss = 0.009853926679062411, Recall = 0.3080357142857143, Aging Rate = 0.0007079392604023322, Precision = 0.7752808988764045, f1 = 0.44089456869009586\n",
      "Epoch 74: Train Loss = 0.009938073584335886, Recall = 0.33035714285714285, Aging Rate = 0.000715893634114718, Precision = 0.8222222222222222, f1 = 0.4713375796178344\n",
      "Epoch 75: Train Loss = 0.009946728321422875, Recall = 0.30357142857142855, Aging Rate = 0.000715893634114718, Precision = 0.7555555555555555, f1 = 0.43312101910828016\n",
      "Test Loss = 0.009010793173178653, Recall = 0.29910714285714285, Aging Rate = 0.0005886236547165459, precision = 0.9054054054054054\n",
      "\n",
      "Epoch 76: Train Loss = 0.009787450317766212, Recall = 0.3125, Aging Rate = 0.0006761217655527893, Precision = 0.8235294117647058, f1 = 0.4530744336569579\n",
      "Epoch 77: Train Loss = 0.009819304251902345, Recall = 0.30357142857142855, Aging Rate = 0.0006443042707032462, Precision = 0.8395061728395061, f1 = 0.44590163934426225\n",
      "Epoch 78: Train Loss = 0.009725469454050967, Recall = 0.3169642857142857, Aging Rate = 0.0006920305129775608, Precision = 0.8160919540229885, f1 = 0.45659163987138257\n",
      "Epoch 79: Train Loss = 0.009847217430131075, Recall = 0.29910714285714285, Aging Rate = 0.0006761217655527893, Precision = 0.788235294117647, f1 = 0.43365695792880254\n",
      "Epoch 80: Train Loss = 0.009808106400551122, Recall = 0.3125, Aging Rate = 0.0006681673918404034, Precision = 0.8333333333333334, f1 = 0.45454545454545453\n",
      "Test Loss = 0.008521708493827277, Recall = 0.36607142857142855, Aging Rate = 0.0007397567552518752, precision = 0.8817204301075269\n",
      "\n",
      "Epoch 81: Train Loss = 0.009699809546929174, Recall = 0.3080357142857143, Aging Rate = 0.0006522586444156319, Precision = 0.8414634146341463, f1 = 0.45098039215686275\n",
      "Epoch 82: Train Loss = 0.00957788273942054, Recall = 0.33035714285714285, Aging Rate = 0.0007318023815394895, Precision = 0.8043478260869565, f1 = 0.4683544303797469\n",
      "Epoch 83: Train Loss = 0.00993828153501758, Recall = 0.30357142857142855, Aging Rate = 0.0006443042707032462, Precision = 0.8395061728395061, f1 = 0.44590163934426225\n",
      "Epoch 84: Train Loss = 0.00980120221655481, Recall = 0.32589285714285715, Aging Rate = 0.0007318023815394895, Precision = 0.7934782608695652, f1 = 0.46202531645569617\n",
      "Epoch 85: Train Loss = 0.009672137901382228, Recall = 0.33482142857142855, Aging Rate = 0.0007079392604023322, Precision = 0.8426966292134831, f1 = 0.4792332268370607\n",
      "Test Loss = 0.008482166547028873, Recall = 0.35267857142857145, Aging Rate = 0.0007318023815394895, precision = 0.8586956521739131\n",
      "\n",
      "Epoch 86: Train Loss = 0.00954796389903492, Recall = 0.32142857142857145, Aging Rate = 0.0007079392604023322, Precision = 0.8089887640449438, f1 = 0.4600638977635783\n",
      "Epoch 87: Train Loss = 0.009720463362458624, Recall = 0.34375, Aging Rate = 0.0007238480078271037, Precision = 0.8461538461538461, f1 = 0.4888888888888889\n",
      "Epoch 88: Train Loss = 0.009688805497187897, Recall = 0.32142857142857145, Aging Rate = 0.0006761217655527893, Precision = 0.8470588235294118, f1 = 0.46601941747572817\n",
      "Epoch 89: Train Loss = 0.009792154968356882, Recall = 0.2857142857142857, Aging Rate = 0.0006363498969908604, Precision = 0.8, f1 = 0.4210526315789473\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 90: Train Loss = 0.00949649958999702, Recall = 0.3125, Aging Rate = 0.0006999848866899465, Precision = 0.7954545454545454, f1 = 0.44871794871794873\n",
      "Test Loss = 0.008490553425128632, Recall = 0.3125, Aging Rate = 0.0006204411495660889, precision = 0.8974358974358975\n",
      "\n",
      "Epoch 91: Train Loss = 0.009588484989200981, Recall = 0.32142857142857145, Aging Rate = 0.0007636198763890325, Precision = 0.75, f1 = 0.45000000000000007\n",
      "Epoch 92: Train Loss = 0.009667784810746418, Recall = 0.33035714285714285, Aging Rate = 0.0007636198763890325, Precision = 0.7708333333333334, f1 = 0.46249999999999997\n",
      "Epoch 93: Train Loss = 0.00954486901034235, Recall = 0.33035714285714285, Aging Rate = 0.000747711128964261, Precision = 0.7872340425531915, f1 = 0.4654088050314465\n",
      "Epoch 94: Train Loss = 0.009598868962288369, Recall = 0.33035714285714285, Aging Rate = 0.0007397567552518752, Precision = 0.7956989247311828, f1 = 0.46687697160883285\n",
      "Epoch 95: Train Loss = 0.009514112571630986, Recall = 0.33482142857142855, Aging Rate = 0.0007318023815394895, Precision = 0.8152173913043478, f1 = 0.4746835443037975\n",
      "Test Loss = 0.00898125256911929, Recall = 0.3080357142857143, Aging Rate = 0.0007318023815394895, precision = 0.75\n",
      "\n",
      "Epoch 96: Train Loss = 0.009582681619535191, Recall = 0.3392857142857143, Aging Rate = 0.0007556655026766467, Precision = 0.8, f1 = 0.47648902821316624\n",
      "Epoch 97: Train Loss = 0.009576197252993426, Recall = 0.30357142857142855, Aging Rate = 0.0006920305129775608, Precision = 0.7816091954022989, f1 = 0.43729903536977494\n",
      "Epoch 98: Train Loss = 0.009562072877006594, Recall = 0.29910714285714285, Aging Rate = 0.0007079392604023322, Precision = 0.7528089887640449, f1 = 0.42811501597444085\n",
      "Epoch 99: Train Loss = 0.009480476910900756, Recall = 0.35714285714285715, Aging Rate = 0.0007874829975261897, Precision = 0.8080808080808081, f1 = 0.4953560371517028\n",
      "Epoch 100: Train Loss = 0.009590987100897008, Recall = 0.30357142857142855, Aging Rate = 0.0006999848866899465, Precision = 0.7727272727272727, f1 = 0.43589743589743585\n",
      "Test Loss = 0.01009545505990309, Recall = 0.5178571428571429, Aging Rate = 0.0013442891573931927, precision = 0.6863905325443787\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a713f78734d4a35873805c2bff2439d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e391ad3d4ef543708bb62b7ce8378f81",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss = 0.3911936673161451, Recall = 0.7680108744902583, Aging Rate = 0.44879927503398276, Precision = 0.8556284704694599, f1 = 0.8094555873925502\n",
      "Epoch 2: Train Loss = 0.18113818646530572, Recall = 0.9265971907566832, Aging Rate = 0.4913910285455369, Precision = 0.9428307976025818, f1 = 0.9346435100548446\n",
      "Epoch 3: Train Loss = 0.11273041917125078, Recall = 0.9565020389669234, Aging Rate = 0.4934299954689624, Precision = 0.9692378328741965, f1 = 0.9628278221208667\n",
      "Epoch 4: Train Loss = 0.096944369574883, Recall = 0.9642048028998641, Aging Rate = 0.4966017217942909, Precision = 0.9708029197080292, f1 = 0.9674926119572631\n",
      "Epoch 5: Train Loss = 0.0824139909595116, Recall = 0.9687358405074762, Aging Rate = 0.4979610330765745, Precision = 0.9727024567788899, f1 = 0.9707150964812713\n",
      "Test Loss = 0.034635077815082585, Recall = 0.9859537834164024, Aging Rate = 0.4938830992297236, precision = 0.998165137614679\n",
      "Model in epoch 5 is saved.\n",
      "\n",
      "Epoch 6: Train Loss = 0.030522159960308277, Recall = 0.9922972360670593, Aging Rate = 0.49818758495695514, Precision = 0.9959072305593452, f1 = 0.994098955969133\n",
      "Epoch 7: Train Loss = 0.019556493442260847, Recall = 0.9981875849569551, Aging Rate = 0.4997734481196194, Precision = 0.9986400725294651, f1 = 0.9984137774756402\n",
      "Epoch 8: Train Loss = 0.01978539011268579, Recall = 0.9990937924784775, Aging Rate = 0.5006796556411418, Precision = 0.997737556561086, f1 = 0.9984152139461173\n",
      "Epoch 9: Train Loss = 0.021054722559454758, Recall = 0.9977344811961939, Aging Rate = 0.49886724059809695, Precision = 0, f1 = 0.0\n",
      "Epoch 10: Train Loss = 0.019978066361127367, Recall = 0.9972813774354327, Aging Rate = 0.49909379247847757, Precision = 0.9990921470721743, f1 = 0.998185941043084\n",
      "Test Loss = 0.021224939521768404, Recall = 1.0, Aging Rate = 0.5020389669234254, precision = 0.9959386281588448\n",
      "Model in epoch 10 is saved.\n",
      "\n",
      "Epoch 11: Train Loss = 0.03387317579791564, Recall = 0.9922972360670593, Aging Rate = 0.5, Precision = 0.9922972360670593, f1 = 0.9922972360670593\n",
      "Epoch 12: Train Loss = 0.023670595840605397, Recall = 0.9954689623923878, Aging Rate = 0.5, Precision = 0.9954689623923878, f1 = 0.9954689623923878\n",
      "Epoch 13: Train Loss = 0.015481058692987493, Recall = 0.9981875849569551, Aging Rate = 0.4993203443588582, Precision = 0.9995462794918331, f1 = 0.9988664701881659\n",
      "Epoch 14: Train Loss = 0.01683776397772866, Recall = 0.9990937924784775, Aging Rate = 0.4997734481196194, Precision = 0.9995466908431551, f1 = 0.9993201903467029\n",
      "Epoch 15: Train Loss = 0.021652514850075126, Recall = 0.9981875849569551, Aging Rate = 0.4997734481196194, Precision = 0.9986400725294651, f1 = 0.9984137774756402\n",
      "Test Loss = 0.018628630273155512, Recall = 1.0, Aging Rate = 0.501132759401903, precision = 0.9977396021699819\n",
      "Model in epoch 15 is saved.\n",
      "\n",
      "Epoch 16: Train Loss = 0.025250156481354064, Recall = 0.9941096511101042, Aging Rate = 0.49954689623923876, Precision = 0.9950113378684807, f1 = 0.9945602901178603\n",
      "Epoch 17: Train Loss = 0.042202122582905045, Recall = 0.9877661984594472, Aging Rate = 0.5004531037607612, Precision = 0.9868718877320054, f1 = 0.9873188405797101\n",
      "Epoch 18: Train Loss = 0.021650002663765197, Recall = 0.9968282736746715, Aging Rate = 0.5004531037607612, Precision = 0.9959257582616569, f1 = 0.9963768115942029\n",
      "Epoch 19: Train Loss = 0.014428993205969886, Recall = 0.9990937924784775, Aging Rate = 0.5, Precision = 0.9990937924784775, f1 = 0.9990937924784775\n",
      "Epoch 20: Train Loss = 0.014855730989175682, Recall = 1.0, Aging Rate = 0.5004531037607612, Precision = 0.9990946129470348, f1 = 0.9995471014492754\n",
      "Test Loss = 0.013220749523678028, Recall = 0.9986406887177164, Aging Rate = 0.49954689623923876, precision = 0.999546485260771\n",
      "Model in epoch 20 is saved.\n",
      "\n",
      "Epoch 21: Train Loss = 0.015192527307503813, Recall = 0.9995468962392388, Aging Rate = 0.4997734481196194, Precision = 0, f1 = 0.0\n",
      "Epoch 22: Train Loss = 0.01819139386653414, Recall = 0.9990937924784775, Aging Rate = 0.5, Precision = 0.9990937924784775, f1 = 0.9990937924784775\n",
      "Epoch 23: Train Loss = 0.020069485245838823, Recall = 0.9972813774354327, Aging Rate = 0.49954689623923876, Precision = 0.9981859410430839, f1 = 0.9977334542157752\n",
      "Epoch 24: Train Loss = 0.021555700014025906, Recall = 0.9977344811961939, Aging Rate = 0.4997734481196194, Precision = 0.9981867633726201, f1 = 0.9979605710401087\n",
      "Epoch 25: Train Loss = 0.0328435084449594, Recall = 0.9904848210240145, Aging Rate = 0.49954689623923876, Precision = 0.9913832199546485, f1 = 0.9909338168631006\n",
      "Test Loss = 0.03326913096959309, Recall = 0.9891255097417309, Aging Rate = 0.49456275487086543, precision = 1.0\n",
      "\n",
      "Epoch 26: Train Loss = 0.02469109000969808, Recall = 0.993656547349343, Aging Rate = 0.49841413683733576, Precision = 0.9968181818181818, f1 = 0.9952348536419332\n",
      "Epoch 27: Train Loss = 0.015493349254462154, Recall = 0.9981875849569551, Aging Rate = 0.49954689623923876, Precision = 0.999092970521542, f1 = 0.9986400725294652\n",
      "Epoch 28: Train Loss = 0.01728109160702343, Recall = 0.9986406887177164, Aging Rate = 0.49954689623923876, Precision = 0.999546485260771, f1 = 0.99909338168631\n",
      "Epoch 29: Train Loss = 0.016320967242479542, Recall = 0.9981875849569551, Aging Rate = 0.49954689623923876, Precision = 0.999092970521542, f1 = 0.9986400725294652\n",
      "Epoch 30: Train Loss = 0.019533523354606765, Recall = 0.9968282736746715, Aging Rate = 0.49909379247847757, Precision = 0.9986382206082615, f1 = 0.997732426303855\n",
      "Test Loss = 0.019295793994299065, Recall = 1.0, Aging Rate = 0.5006796556411418, precision = 0.9986425339366516\n",
      "\n",
      "Epoch 31: Train Loss = 0.01678306845746391, Recall = 0.9981875849569551, Aging Rate = 0.49909379247847757, Precision = 0, f1 = 0.0\n",
      "Epoch 32: Train Loss = 0.020946532573954357, Recall = 0.9981875849569551, Aging Rate = 0.5002265518803806, Precision = 0.9977355072463768, f1 = 0.9979614949037372\n",
      "Epoch 33: Train Loss = 0.027092643409602827, Recall = 0.9922972360670593, Aging Rate = 0.49864068871771633, Precision = 0.9950022716946842, f1 = 0.9936479128856625\n",
      "Epoch 34: Train Loss = 0.02293090373665891, Recall = 0.9972813774354327, Aging Rate = 0.4997734481196194, Precision = 0.9977334542157752, f1 = 0.9975073646045773\n",
      "Epoch 35: Train Loss = 0.01514380329381801, Recall = 0.9986406887177164, Aging Rate = 0.4997734481196194, Precision = 0.99909338168631, f1 = 0.9988669839111715\n",
      "Test Loss = 0.013384847419009822, Recall = 0.9990937924784775, Aging Rate = 0.49954689623923876, precision = 1.0\n",
      "Model in epoch 35 is saved.\n",
      "\n",
      "Epoch 36: Train Loss = 0.01955163882269706, Recall = 0.9977344811961939, Aging Rate = 0.49954689623923876, Precision = 0.998639455782313, f1 = 0.99818676337262\n",
      "Epoch 37: Train Loss = 0.02715190373678444, Recall = 0.9941096511101042, Aging Rate = 0.49886724059809695, Precision = 0.9963669391462306, f1 = 0.9952370151961896\n",
      "Epoch 38: Train Loss = 0.01678635769594996, Recall = 0.9986406887177164, Aging Rate = 0.5002265518803806, Precision = 0.9981884057971014, f1 = 0.9984144960362401\n",
      "Epoch 39: Train Loss = 0.01898403338139339, Recall = 0.9968282736746715, Aging Rate = 0.49841413683733576, Precision = 0, f1 = 0.0\n",
      "Epoch 40: Train Loss = 0.017245292527694803, Recall = 0.9977344811961939, Aging Rate = 0.49886724059809695, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.018619726626789023, Recall = 0.9977344811961939, Aging Rate = 0.49886724059809695, precision = 1.0\n",
      "\n",
      "Epoch 41: Train Loss = 0.017127437910337658, Recall = 0.9990937924784775, Aging Rate = 0.5002265518803806, Precision = 0.998641304347826, f1 = 0.9988674971687429\n",
      "Epoch 42: Train Loss = 0.024959829182283448, Recall = 0.995922066153149, Aging Rate = 0.4993203443588582, Precision = 0.9972776769509982, f1 = 0.9965994105644979\n",
      "Epoch 43: Train Loss = 0.01878300746611653, Recall = 0.9968282736746715, Aging Rate = 0.49909379247847757, Precision = 0.9986382206082615, f1 = 0.997732426303855\n",
      "Epoch 44: Train Loss = 0.016516933467460262, Recall = 0.9981875849569551, Aging Rate = 0.49909379247847757, Precision = 0, f1 = 0.0\n",
      "Epoch 45: Train Loss = 0.0142115774831562, Recall = 0.9995468962392388, Aging Rate = 0.4997734481196194, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.011845290479404276, Recall = 1.0, Aging Rate = 0.5002265518803806, precision = 0.9995471014492754\n",
      "Model in epoch 45 is saved.\n",
      "\n",
      "Epoch 46: Train Loss = 0.015010020608275684, Recall = 1.0, Aging Rate = 0.5002265518803806, Precision = 0.9995471014492754, f1 = 0.9997734994337486\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 47: Train Loss = 0.021432306161753775, Recall = 0.9968282736746715, Aging Rate = 0.4993203443588582, Precision = 0.9981851179673321, f1 = 0.9975062344139651\n",
      "Epoch 48: Train Loss = 0.024849407585007765, Recall = 0.9968282736746715, Aging Rate = 0.5004531037607612, Precision = 0.9959257582616569, f1 = 0.9963768115942029\n",
      "Epoch 49: Train Loss = 0.018867946388119748, Recall = 0.9977344811961939, Aging Rate = 0.4997734481196194, Precision = 0.9981867633726201, f1 = 0.9979605710401087\n",
      "Epoch 50: Train Loss = 0.03131524014139424, Recall = 0.991391028545537, Aging Rate = 0.49818758495695514, Precision = 0.9949977262391997, f1 = 0.9931911030413073\n",
      "Test Loss = 0.0497262679246361, Recall = 0.9990937924784775, Aging Rate = 0.5106479383778886, precision = 0.9782608695652174\n",
      "\n",
      "Epoch 51: Train Loss = 0.03391796358243664, Recall = 0.9900317172632532, Aging Rate = 0.4993203443588582, Precision = 0.9913793103448276, f1 = 0.9907050555429608\n",
      "Epoch 52: Train Loss = 0.01419028904884851, Recall = 0.9990937924784775, Aging Rate = 0.5, Precision = 0.9990937924784775, f1 = 0.9990937924784775\n",
      "Epoch 53: Train Loss = 0.013484097099818685, Recall = 1.0, Aging Rate = 0.5002265518803806, Precision = 0.9995471014492754, f1 = 0.9997734994337486\n",
      "Epoch 54: Train Loss = 0.015004356046121586, Recall = 1.0, Aging Rate = 0.5002265518803806, Precision = 0.9995471014492754, f1 = 0.9997734994337486\n",
      "Epoch 55: Train Loss = 0.01799209938752986, Recall = 0.9986406887177164, Aging Rate = 0.5, Precision = 0.9986406887177164, f1 = 0.9986406887177164\n",
      "Test Loss = 0.021835124770818278, Recall = 1.0, Aging Rate = 0.5006796556411418, precision = 0.9986425339366516\n",
      "\n",
      "Epoch 56: Train Loss = 0.021859328618241913, Recall = 0.9981875849569551, Aging Rate = 0.4997734481196194, Precision = 0.9986400725294651, f1 = 0.9984137774756402\n",
      "Epoch 57: Train Loss = 0.022163340756876412, Recall = 0.9968282736746715, Aging Rate = 0.5004531037607612, Precision = 0.9959257582616569, f1 = 0.9963768115942029\n",
      "Epoch 58: Train Loss = 0.0219437736067558, Recall = 0.995922066153149, Aging Rate = 0.4993203443588582, Precision = 0.9972776769509982, f1 = 0.9965994105644979\n",
      "Epoch 59: Train Loss = 0.015166174303900617, Recall = 0.9986406887177164, Aging Rate = 0.4993203443588582, Precision = 0, f1 = 0.0\n",
      "Epoch 60: Train Loss = 0.01876296557226114, Recall = 0.9972813774354327, Aging Rate = 0.49954689623923876, Precision = 0.9981859410430839, f1 = 0.9977334542157752\n",
      "Test Loss = 0.018146211560773375, Recall = 1.0, Aging Rate = 0.5015858631626643, precision = 0.9968383017163505\n",
      "\n",
      "Epoch 61: Train Loss = 0.01919989011621362, Recall = 0.9981875849569551, Aging Rate = 0.5002265518803806, Precision = 0.9977355072463768, f1 = 0.9979614949037372\n",
      "Epoch 62: Train Loss = 0.016532313003950413, Recall = 0.9995468962392388, Aging Rate = 0.5, Precision = 0.9995468962392388, f1 = 0.9995468962392388\n",
      "Epoch 63: Train Loss = 0.015208494314425095, Recall = 0.9995468962392388, Aging Rate = 0.5, Precision = 0.9995468962392388, f1 = 0.9995468962392388\n",
      "Epoch 64: Train Loss = 0.021315614703838432, Recall = 0.9968282736746715, Aging Rate = 0.4993203443588582, Precision = 0.9981851179673321, f1 = 0.9975062344139651\n",
      "Epoch 65: Train Loss = 0.016899649547535367, Recall = 0.9995468962392388, Aging Rate = 0.5006796556411418, Precision = 0.9981900452488688, f1 = 0.9988680099615123\n",
      "Test Loss = 0.012845495044779982, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "Model in epoch 65 is saved.\n",
      "\n",
      "Epoch 66: Train Loss = 0.015265851850420115, Recall = 0.9995468962392388, Aging Rate = 0.5002265518803806, Precision = 0.9990942028985508, f1 = 0.9993204983012457\n",
      "Epoch 67: Train Loss = 0.028888825725512532, Recall = 0.9954689623923878, Aging Rate = 0.5, Precision = 0.9954689623923878, f1 = 0.9954689623923878\n",
      "Epoch 68: Train Loss = 0.024265848060518732, Recall = 0.9941096511101042, Aging Rate = 0.49864068871771633, Precision = 0.9968196274420718, f1 = 0.9954627949183303\n",
      "Epoch 69: Train Loss = 0.02118124260208863, Recall = 0.9972813774354327, Aging Rate = 0.49954689623923876, Precision = 0.9981859410430839, f1 = 0.9977334542157752\n",
      "Epoch 70: Train Loss = 0.013254449410785173, Recall = 1.0, Aging Rate = 0.5002265518803806, Precision = 0.9995471014492754, f1 = 0.9997734994337486\n",
      "Test Loss = 0.010415791095444181, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 71: Train Loss = 0.014593424104191245, Recall = 0.9977344811961939, Aging Rate = 0.49886724059809695, Precision = 0, f1 = 0.0\n",
      "Epoch 72: Train Loss = 0.016351549768433022, Recall = 0.9986406887177164, Aging Rate = 0.4997734481196194, Precision = 0.99909338168631, f1 = 0.9988669839111715\n",
      "Epoch 73: Train Loss = 0.016088021948670282, Recall = 0.9995468962392388, Aging Rate = 0.4997734481196194, Precision = 0, f1 = 0.0\n",
      "Epoch 74: Train Loss = 0.017351474006135754, Recall = 0.9986406887177164, Aging Rate = 0.5, Precision = 0.9986406887177164, f1 = 0.9986406887177164\n",
      "Epoch 75: Train Loss = 0.02195968219650024, Recall = 0.9981875849569551, Aging Rate = 0.5009062075215225, Precision = 0.9963817277250113, f1 = 0.9972838388411046\n",
      "Test Loss = 0.015055752651344801, Recall = 0.9981875849569551, Aging Rate = 0.49909379247847757, precision = 1.0\n",
      "\n",
      "Epoch 76: Train Loss = 0.01583627478810771, Recall = 0.9986406887177164, Aging Rate = 0.4997734481196194, Precision = 0.99909338168631, f1 = 0.9988669839111715\n",
      "Epoch 77: Train Loss = 0.015737065686715585, Recall = 0.9990937924784775, Aging Rate = 0.49954689623923876, Precision = 0, f1 = 0.0\n",
      "Epoch 78: Train Loss = 0.017864828001780374, Recall = 0.9990937924784775, Aging Rate = 0.49954689623923876, Precision = 0, f1 = 0.0\n",
      "Epoch 79: Train Loss = 0.017866672488882306, Recall = 0.9990937924784775, Aging Rate = 0.5004531037607612, Precision = 0.9981892258940697, f1 = 0.9986413043478259\n",
      "Epoch 80: Train Loss = 0.02471516419777678, Recall = 0.995922066153149, Aging Rate = 0.5, Precision = 0.995922066153149, f1 = 0.995922066153149\n",
      "Test Loss = 0.024039324611850762, Recall = 0.9981875849569551, Aging Rate = 0.5006796556411418, precision = 0.9968325791855204\n",
      "\n",
      "Epoch 81: Train Loss = 0.035133362051030334, Recall = 0.9891255097417309, Aging Rate = 0.49864068871771633, Precision = 0.991821899136756, f1 = 0.9904718693284936\n",
      "Epoch 82: Train Loss = 0.014772510632035362, Recall = 0.9990937924784775, Aging Rate = 0.5004531037607612, Precision = 0.9981892258940697, f1 = 0.9986413043478259\n",
      "Epoch 83: Train Loss = 0.012455757870665897, Recall = 0.9995468962392388, Aging Rate = 0.4997734481196194, Precision = 0, f1 = 0.0\n",
      "Epoch 84: Train Loss = 0.01335568893759916, Recall = 0.9995468962392388, Aging Rate = 0.4997734481196194, Precision = 0, f1 = 0.0\n",
      "Epoch 85: Train Loss = 0.014674351222333754, Recall = 0.9990937924784775, Aging Rate = 0.4997734481196194, Precision = 0.9995466908431551, f1 = 0.9993201903467029\n",
      "Test Loss = 0.013022909906414715, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 86: Train Loss = 0.016437307443245265, Recall = 0.9981875849569551, Aging Rate = 0.4993203443588582, Precision = 0.9995462794918331, f1 = 0.9988664701881659\n",
      "Epoch 87: Train Loss = 0.017253983287308677, Recall = 0.9990937924784775, Aging Rate = 0.5, Precision = 0.9990937924784775, f1 = 0.9990937924784775\n",
      "Epoch 88: Train Loss = 0.01893418934069638, Recall = 0.9986406887177164, Aging Rate = 0.49954689623923876, Precision = 0.999546485260771, f1 = 0.99909338168631\n",
      "Epoch 89: Train Loss = 0.02095704816288547, Recall = 0.9977344811961939, Aging Rate = 0.5002265518803806, Precision = 0.9972826086956522, f1 = 0.9975084937712344\n",
      "Epoch 90: Train Loss = 0.015078910764460387, Recall = 0.9986406887177164, Aging Rate = 0.4997734481196194, Precision = 0.99909338168631, f1 = 0.9988669839111715\n",
      "Test Loss = 0.011319637158484712, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 91: Train Loss = 0.01802051786500429, Recall = 0.9986406887177164, Aging Rate = 0.4997734481196194, Precision = 0.99909338168631, f1 = 0.9988669839111715\n",
      "Epoch 92: Train Loss = 0.017391161161412007, Recall = 0.9986406887177164, Aging Rate = 0.49954689623923876, Precision = 0.999546485260771, f1 = 0.99909338168631\n",
      "Epoch 93: Train Loss = 0.01787923936916521, Recall = 0.9977344811961939, Aging Rate = 0.49909379247847757, Precision = 0.9995460735360872, f1 = 0.998639455782313\n",
      "Epoch 94: Train Loss = 0.023306086145030814, Recall = 0.995922066153149, Aging Rate = 0.5, Precision = 0.995922066153149, f1 = 0.995922066153149\n",
      "Epoch 95: Train Loss = 0.014641125902523403, Recall = 0.9990937924784775, Aging Rate = 0.4997734481196194, Precision = 0.9995466908431551, f1 = 0.9993201903467029\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss = 0.013513712439893678, Recall = 0.9968282736746715, Aging Rate = 0.49864068871771633, precision = 0.9995456610631531\n",
      "\n",
      "Epoch 96: Train Loss = 0.013873525996032915, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 97: Train Loss = 0.02203788670344514, Recall = 0.9972813774354327, Aging Rate = 0.49954689623923876, Precision = 0.9981859410430839, f1 = 0.9977334542157752\n",
      "Epoch 98: Train Loss = 0.018030049107583955, Recall = 0.9995468962392388, Aging Rate = 0.5006796556411418, Precision = 0.9981900452488688, f1 = 0.9988680099615123\n",
      "Epoch 99: Train Loss = 0.015524320771953991, Recall = 0.9986406887177164, Aging Rate = 0.49954689623923876, Precision = 0.999546485260771, f1 = 0.99909338168631\n",
      "Epoch 100: Train Loss = 0.014594101885905026, Recall = 0.9986406887177164, Aging Rate = 0.4993203443588582, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.012882067880153954, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "13fc144857a54b41abd5efd17ffabfa6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss = 0.38486409733107385, Recall = 0.7923844061650045, Aging Rate = 0.46214868540344517, Precision = 0.8572829818538499, f1 = 0.8235571260306243\n",
      "Epoch 2: Train Loss = 0.1613905405995528, Recall = 0.943336355394379, Aging Rate = 0.4968268359020852, Precision = 0.9493613138686131, f1 = 0.9463392451114142\n",
      "Epoch 3: Train Loss = 0.1122204761475946, Recall = 0.9632819582955575, Aging Rate = 0.49977334542157753, Precision = 0.963718820861678, f1 = 0.9635003400589435\n",
      "Epoch 4: Train Loss = 0.07848846232847852, Recall = 0.970988213961922, Aging Rate = 0.4941069809610154, Precision = 0.9825688073394495, f1 = 0.9767441860465116\n",
      "Epoch 5: Train Loss = 0.06893038329544222, Recall = 0.9759746146872167, Aging Rate = 0.49705349048050773, Precision = 0.9817601459188326, f1 = 0.9788588315526257\n",
      "Test Loss = 0.047633496299723764, Recall = 0.9959202175883953, Aging Rate = 0.5090661831368993, precision = 0.9781834372217275\n",
      "Model in epoch 5 is saved.\n",
      "\n",
      "Epoch 6: Train Loss = 0.02954756432564985, Recall = 0.9945602901178604, Aging Rate = 0.49932003626473254, Precision = 0.9959146618247844, f1 = 0.9952370151961896\n",
      "Epoch 7: Train Loss = 0.022660636100732295, Recall = 0.9959202175883953, Aging Rate = 0.4986400725294651, Precision = 0.9986363636363637, f1 = 0.9972764412165229\n",
      "Epoch 8: Train Loss = 0.02200093072208349, Recall = 0.9968268359020852, Aging Rate = 0.49932003626473254, Precision = 0.9981842941443486, f1 = 0.997505103198004\n",
      "Epoch 9: Train Loss = 0.023571565264290502, Recall = 0.9959202175883953, Aging Rate = 0.4984134179510426, Precision = 0.9990904956798545, f1 = 0.9975028376844495\n",
      "Epoch 10: Train Loss = 0.018384270413912975, Recall = 0.9995466908431551, Aging Rate = 0.5002266545784225, Precision = 0.9990937924784775, f1 = 0.9993201903467029\n",
      "Test Loss = 0.01687678458474759, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "Model in epoch 10 is saved.\n",
      "\n",
      "Epoch 11: Train Loss = 0.02092145428953123, Recall = 0.9977334542157752, Aging Rate = 0.49977334542157753, Precision = 0.9981859410430839, f1 = 0.9979596463386986\n",
      "Epoch 12: Train Loss = 0.02622162184913593, Recall = 0.9959202175883953, Aging Rate = 0.499546690843155, Precision = 0.9968239564428312, f1 = 0.9963718820861678\n",
      "Epoch 13: Train Loss = 0.023596058379274438, Recall = 0.9950135992747053, Aging Rate = 0.49909338168631007, Precision = 0.9968210717529519, f1 = 0.9959165154264972\n",
      "Epoch 14: Train Loss = 0.025361057990657018, Recall = 0.9963735267452403, Aging Rate = 0.49977334542157753, Precision = 0.9968253968253968, f1 = 0.9965994105644979\n",
      "Epoch 15: Train Loss = 0.04766529354208562, Recall = 0.985947416137806, Aging Rate = 0.5002266545784225, Precision = 0.9855006796556411, f1 = 0.9857239972807614\n",
      "Test Loss = 0.023307849365140455, Recall = 0.9968268359020852, Aging Rate = 0.5015865820489573, precision = 0.9936737460460913\n",
      "\n",
      "Epoch 16: Train Loss = 0.01893896178924162, Recall = 0.9968268359020852, Aging Rate = 0.5002266545784225, Precision = 0.9963751699139103, f1 = 0.9966009517335147\n",
      "Epoch 17: Train Loss = 0.019292659355042097, Recall = 0.9972801450589301, Aging Rate = 0.49977334542157753, Precision = 0.9977324263038548, f1 = 0.997506234413965\n",
      "Epoch 18: Train Loss = 0.020705176149228975, Recall = 0.9968268359020852, Aging Rate = 0.5, Precision = 0.9968268359020852, f1 = 0.9968268359020852\n",
      "Epoch 19: Train Loss = 0.024196068388988294, Recall = 0.9950135992747053, Aging Rate = 0.499546690843155, Precision = 0.9959165154264973, f1 = 0.9954648526077098\n",
      "Epoch 20: Train Loss = 0.02563936304696181, Recall = 0.9954669084315503, Aging Rate = 0.5002266545784225, Precision = 0.9950158586316267, f1 = 0.9952413324269205\n",
      "Test Loss = 0.01835175410608811, Recall = 0.9995466908431551, Aging Rate = 0.50090661831369, precision = 0.997737556561086\n",
      "\n",
      "Epoch 21: Train Loss = 0.017832055529165787, Recall = 0.9968268359020852, Aging Rate = 0.499546690843155, Precision = 0.9977313974591652, f1 = 0.9972789115646259\n",
      "Epoch 22: Train Loss = 0.02402521460633708, Recall = 0.9959202175883953, Aging Rate = 0.5004533091568449, Precision = 0.9950181159420289, f1 = 0.9954689623923878\n",
      "Epoch 23: Train Loss = 0.01808097721976739, Recall = 0.9986400725294651, Aging Rate = 0.49977334542157753, Precision = 0.999092970521542, f1 = 0.998866470188166\n",
      "Epoch 24: Train Loss = 0.02799284835755555, Recall = 0.9936536718041704, Aging Rate = 0.49909338168631007, Precision = 0.9954586739327884, f1 = 0.9945553539019963\n",
      "Epoch 25: Train Loss = 0.041609247121368875, Recall = 0.9900271985494107, Aging Rate = 0.5004533091568449, Precision = 0.9891304347826086, f1 = 0.9895786135024921\n",
      "Test Loss = 0.023290672127566116, Recall = 0.9981867633726201, Aging Rate = 0.5024932003626473, precision = 0.993234100135318\n",
      "\n",
      "Epoch 26: Train Loss = 0.01958841336375999, Recall = 0.9954669084315503, Aging Rate = 0.49909338168631007, Precision = 0.997275204359673, f1 = 0.9963702359346642\n",
      "Epoch 27: Train Loss = 0.01875501850169027, Recall = 0.9977334542157752, Aging Rate = 0.499546690843155, Precision = 0.9986388384754991, f1 = 0.9981859410430838\n",
      "Epoch 28: Train Loss = 0.018273960650372484, Recall = 0.9968268359020852, Aging Rate = 0.4988667271078876, Precision = 0.9990913221263062, f1 = 0.9979577944179714\n",
      "Epoch 29: Train Loss = 0.020482567510485702, Recall = 0.9972801450589301, Aging Rate = 0.5004533091568449, Precision = 0.9963768115942029, f1 = 0.9968282736746715\n",
      "Epoch 30: Train Loss = 0.019407425602646383, Recall = 0.9972801450589301, Aging Rate = 0.49977334542157753, Precision = 0.9977324263038548, f1 = 0.997506234413965\n",
      "Test Loss = 0.020010766330076313, Recall = 0.99909338168631, Aging Rate = 0.49977334542157753, precision = 0.999546485260771\n",
      "\n",
      "Epoch 31: Train Loss = 0.021209299611645402, Recall = 0.9981867633726201, Aging Rate = 0.5004533091568449, Precision = 0.9972826086956522, f1 = 0.9977344811961939\n",
      "Epoch 32: Train Loss = 0.038576952677392355, Recall = 0.9904805077062556, Aging Rate = 0.50090661831369, Precision = 0.9886877828054299, f1 = 0.9895833333333334\n",
      "Epoch 33: Train Loss = 0.022723984383620787, Recall = 0.9959202175883953, Aging Rate = 0.499546690843155, Precision = 0.9968239564428312, f1 = 0.9963718820861678\n",
      "Epoch 34: Train Loss = 0.01427197117098385, Recall = 0.99909338168631, Aging Rate = 0.5, Precision = 0.99909338168631, f1 = 0.99909338168631\n",
      "Epoch 35: Train Loss = 0.018655021751767274, Recall = 0.9972801450589301, Aging Rate = 0.499546690843155, Precision = 0.9981851179673321, f1 = 0.9977324263038548\n",
      "Test Loss = 0.014801717051731276, Recall = 0.9995466908431551, Aging Rate = 0.5006799637352675, precision = 0.9981892258940697\n",
      "\n",
      "Epoch 36: Train Loss = 0.017905366504843517, Recall = 0.9977334542157752, Aging Rate = 0.49977334542157753, Precision = 0.9981859410430839, f1 = 0.9979596463386986\n",
      "Epoch 37: Train Loss = 0.020710631497440724, Recall = 0.9959202175883953, Aging Rate = 0.49932003626473254, Precision = 0.9972764412165229, f1 = 0.9965978679972782\n",
      "Epoch 38: Train Loss = 0.019927029844951004, Recall = 0.9981867633726201, Aging Rate = 0.5, Precision = 0.9981867633726201, f1 = 0.9981867633726201\n",
      "Epoch 39: Train Loss = 0.01760002212718818, Recall = 0.9972801450589301, Aging Rate = 0.49932003626473254, Precision = 0.9986382206082615, f1 = 0.9979587207983669\n",
      "Epoch 40: Train Loss = 0.02659685723990175, Recall = 0.9945602901178604, Aging Rate = 0.4984134179510426, Precision = 0.9977262391996362, f1 = 0.9961407491486948\n",
      "Test Loss = 0.017562323843457434, Recall = 1.0, Aging Rate = 0.5006799637352675, precision = 0.9986419194205522\n",
      "\n",
      "Epoch 41: Train Loss = 0.016784553886378558, Recall = 0.9986400725294651, Aging Rate = 0.5, Precision = 0.9986400725294651, f1 = 0.9986400725294651\n",
      "Epoch 42: Train Loss = 0.01531655049071405, Recall = 0.99909338168631, Aging Rate = 0.5, Precision = 0.99909338168631, f1 = 0.99909338168631\n",
      "Epoch 43: Train Loss = 0.021524768170722484, Recall = 0.9963735267452403, Aging Rate = 0.49932003626473254, Precision = 0.9977303676804358, f1 = 0.9970514855976411\n",
      "Epoch 44: Train Loss = 0.021836282788410256, Recall = 0.9968268359020852, Aging Rate = 0.49977334542157753, Precision = 0.9972789115646259, f1 = 0.9970528224892314\n",
      "Epoch 45: Train Loss = 0.026745288344885366, Recall = 0.9932003626473255, Aging Rate = 0.5, Precision = 0.9932003626473255, f1 = 0.9932003626473255\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss = 0.020555364977862225, Recall = 1.0, Aging Rate = 0.5018132366273799, precision = 0.996386630532972\n",
      "\n",
      "Epoch 46: Train Loss = 0.018636381880110863, Recall = 0.9981867633726201, Aging Rate = 0.49977334542157753, Precision = 0.998639455782313, f1 = 0.9984130582634324\n",
      "Epoch 47: Train Loss = 0.01986484558525025, Recall = 0.9977334542157752, Aging Rate = 0.499546690843155, Precision = 0.9986388384754991, f1 = 0.9981859410430838\n",
      "Epoch 48: Train Loss = 0.022769734263420105, Recall = 0.9959202175883953, Aging Rate = 0.4988667271078876, Precision = 0.9981826442526125, f1 = 0.9970501474926254\n",
      "Epoch 49: Train Loss = 0.023010817338676205, Recall = 0.9959202175883953, Aging Rate = 0.5, Precision = 0.9959202175883953, f1 = 0.9959202175883953\n",
      "Epoch 50: Train Loss = 0.01522307910180481, Recall = 0.99909338168631, Aging Rate = 0.5, Precision = 0.99909338168631, f1 = 0.99909338168631\n",
      "Test Loss = 0.012032653730284974, Recall = 0.9995466908431551, Aging Rate = 0.49977334542157753, precision = 1.0\n",
      "\n",
      "Epoch 51: Train Loss = 0.018188677447850556, Recall = 0.9981867633726201, Aging Rate = 0.49932003626473254, Precision = 0.9995460735360872, f1 = 0.9988659559990928\n",
      "Epoch 52: Train Loss = 0.023942867369945765, Recall = 0.9968268359020852, Aging Rate = 0.5, Precision = 0.9968268359020852, f1 = 0.9968268359020852\n",
      "Epoch 53: Train Loss = 0.02897997588216448, Recall = 0.9932003626473255, Aging Rate = 0.5, Precision = 0.9932003626473255, f1 = 0.9932003626473255\n",
      "Epoch 54: Train Loss = 0.03013180652911946, Recall = 0.9927470534904805, Aging Rate = 0.4988667271078876, Precision = 0.9950022716946842, f1 = 0.9938733832539142\n",
      "Epoch 55: Train Loss = 0.015075769239963992, Recall = 0.9981867633726201, Aging Rate = 0.5, Precision = 0.9981867633726201, f1 = 0.9981867633726201\n",
      "Test Loss = 0.012520595540225858, Recall = 0.9995466908431551, Aging Rate = 0.49977334542157753, precision = 1.0\n",
      "\n",
      "Epoch 56: Train Loss = 0.02038061223647212, Recall = 0.9986400725294651, Aging Rate = 0.5002266545784225, Precision = 0.9981875849569551, f1 = 0.9984137774756402\n",
      "Epoch 57: Train Loss = 0.020057748207790358, Recall = 0.9981867633726201, Aging Rate = 0.5006799637352675, Precision = 0.996831145314622, f1 = 0.9975084937712345\n",
      "Epoch 58: Train Loss = 0.016355391726883994, Recall = 0.99909338168631, Aging Rate = 0.5, Precision = 0.99909338168631, f1 = 0.99909338168631\n",
      "Epoch 59: Train Loss = 0.015789944166866413, Recall = 0.9986400725294651, Aging Rate = 0.49977334542157753, Precision = 0.999092970521542, f1 = 0.998866470188166\n",
      "Epoch 60: Train Loss = 0.021030146594844076, Recall = 0.9959202175883953, Aging Rate = 0.49818676337262013, Precision = 0.9995450409463148, f1 = 0.9977293369663942\n",
      "Test Loss = 0.01616829625015921, Recall = 0.99909338168631, Aging Rate = 0.5011332728921124, precision = 0.9968340117593849\n",
      "\n",
      "Training Finished at epoch 60.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3633a88cfc904a91a9e46931a29eacfb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss = 0.40497879540833837, Recall = 0.7711826008155868, Aging Rate = 0.4589941096511101, Precision = 0.8400789733464955, f1 = 0.8041578077013939\n",
      "Epoch 2: Train Loss = 0.18266118626060884, Recall = 0.9256909832351609, Aging Rate = 0.4913910285455369, Precision = 0.941908713692946, f1 = 0.9337294332723948\n",
      "Epoch 3: Train Loss = 0.1038970563984398, Recall = 0.9710013593112823, Aging Rate = 0.501132759401903, Precision = 0.9688065099457505, f1 = 0.9699026929169496\n",
      "Epoch 4: Train Loss = 0.08509347635930245, Recall = 0.9714544630720435, Aging Rate = 0.4968282736746715, Precision = 0.97765617875057, f1 = 0.9745454545454546\n",
      "Epoch 5: Train Loss = 0.07051927687817156, Recall = 0.9723606705935659, Aging Rate = 0.4941096511101042, Precision = 0.9839523154516276, f1 = 0.9781221513217866\n",
      "Test Loss = 0.040807571385341045, Recall = 0.993656547349343, Aging Rate = 0.5024920706841867, precision = 0.9887285843101894\n",
      "Model in epoch 5 is saved.\n",
      "\n",
      "Epoch 6: Train Loss = 0.033201302055271165, Recall = 0.991391028545537, Aging Rate = 0.49841413683733576, Precision = 0.9945454545454545, f1 = 0.9929657363285682\n",
      "Epoch 7: Train Loss = 0.025043810923268583, Recall = 0.9968282736746715, Aging Rate = 0.5, Precision = 0.9968282736746715, f1 = 0.9968282736746715\n",
      "Epoch 8: Train Loss = 0.030302124547780127, Recall = 0.9941096511101042, Aging Rate = 0.49954689623923876, Precision = 0.9950113378684807, f1 = 0.9945602901178603\n",
      "Epoch 9: Train Loss = 0.024648631969741097, Recall = 0.995922066153149, Aging Rate = 0.5, Precision = 0.995922066153149, f1 = 0.995922066153149\n",
      "Epoch 10: Train Loss = 0.018958222332415155, Recall = 0.9977344811961939, Aging Rate = 0.4997734481196194, Precision = 0.9981867633726201, f1 = 0.9979605710401087\n",
      "Test Loss = 0.014541752767248233, Recall = 0.9990937924784775, Aging Rate = 0.5, precision = 0.9990937924784775\n",
      "Model in epoch 10 is saved.\n",
      "\n",
      "Epoch 11: Train Loss = 0.018826533741084332, Recall = 0.9981875849569551, Aging Rate = 0.5, Precision = 0.9981875849569551, f1 = 0.9981875849569551\n",
      "Epoch 12: Train Loss = 0.027049810629410607, Recall = 0.993656547349343, Aging Rate = 0.49886724059809695, Precision = 0.9959128065395095, f1 = 0.9947833975958268\n",
      "Epoch 13: Train Loss = 0.026651579587908963, Recall = 0.995922066153149, Aging Rate = 0.5, Precision = 0.995922066153149, f1 = 0.995922066153149\n",
      "Epoch 14: Train Loss = 0.032673705929631175, Recall = 0.9909379247847757, Aging Rate = 0.49818758495695514, Precision = 0.9945429740791268, f1 = 0.9927371765773945\n",
      "Epoch 15: Train Loss = 0.019777636164415326, Recall = 0.9972813774354327, Aging Rate = 0.5, Precision = 0.9972813774354327, f1 = 0.9972813774354327\n",
      "Test Loss = 0.01431400690642981, Recall = 0.9981875849569551, Aging Rate = 0.49909379247847757, precision = 1.0\n",
      "Model in epoch 15 is saved.\n",
      "\n",
      "Epoch 16: Train Loss = 0.01868220007255518, Recall = 0.995922066153149, Aging Rate = 0.49954689623923876, Precision = 0.9968253968253968, f1 = 0.9963735267452403\n",
      "Epoch 17: Train Loss = 0.017759148975877295, Recall = 0.9977344811961939, Aging Rate = 0.5002265518803806, Precision = 0.9972826086956522, f1 = 0.9975084937712344\n",
      "Epoch 18: Train Loss = 0.02645860233955595, Recall = 0.9950158586316267, Aging Rate = 0.4993203443588582, Precision = 0.9963702359346642, f1 = 0.9956925867150307\n",
      "Epoch 19: Train Loss = 0.035423387556856284, Recall = 0.9941096511101042, Aging Rate = 0.5018124150430449, Precision = 0.9905191873589165, f1 = 0.9923111714156491\n",
      "Epoch 20: Train Loss = 0.021885100771526594, Recall = 0.9950158586316267, Aging Rate = 0.4993203443588582, Precision = 0.9963702359346642, f1 = 0.9956925867150307\n",
      "Test Loss = 0.01990866890463237, Recall = 0.9963751699139103, Aging Rate = 0.49954689623923876, precision = 0.9972789115646259\n",
      "\n",
      "Epoch 21: Train Loss = 0.023326134970002334, Recall = 0.995922066153149, Aging Rate = 0.4997734481196194, Precision = 0.9963735267452403, f1 = 0.9961477452979831\n",
      "Epoch 22: Train Loss = 0.021704230240643645, Recall = 0.9981875849569551, Aging Rate = 0.5013593112822836, Precision = 0.9954812471757795, f1 = 0.9968325791855203\n",
      "Epoch 23: Train Loss = 0.015156151835292267, Recall = 0.9981875849569551, Aging Rate = 0.49954689623923876, Precision = 0.999092970521542, f1 = 0.9986400725294652\n",
      "Epoch 24: Train Loss = 0.01878166894163003, Recall = 0.9977344811961939, Aging Rate = 0.4993203443588582, Precision = 0.9990925589836661, f1 = 0.9984130582634323\n",
      "Epoch 25: Train Loss = 0.01723204356819513, Recall = 0.9981875849569551, Aging Rate = 0.4997734481196194, Precision = 0.9986400725294651, f1 = 0.9984137774756402\n",
      "Test Loss = 0.015760650322361125, Recall = 0.9968282736746715, Aging Rate = 0.49909379247847757, precision = 0.9986382206082615\n",
      "\n",
      "Epoch 26: Train Loss = 0.019796624327332497, Recall = 0.9977344811961939, Aging Rate = 0.4997734481196194, Precision = 0.9981867633726201, f1 = 0.9979605710401087\n",
      "Epoch 27: Train Loss = 0.030012607544923887, Recall = 0.9932034435885818, Aging Rate = 0.49886724059809695, Precision = 0.9954586739327884, f1 = 0.9943297799954639\n",
      "Epoch 28: Train Loss = 0.02448564118823424, Recall = 0.9941096511101042, Aging Rate = 0.4993203443588582, Precision = 0.9954627949183303, f1 = 0.9947857628655633\n",
      "Epoch 29: Train Loss = 0.026274837123075653, Recall = 0.9941096511101042, Aging Rate = 0.5, Precision = 0.9941096511101042, f1 = 0.9941096511101042\n",
      "Epoch 30: Train Loss = 0.026677526714213574, Recall = 0.9945627548708654, Aging Rate = 0.49954689623923876, Precision = 0.9954648526077098, f1 = 0.9950135992747055\n",
      "Test Loss = 0.020200459841481826, Recall = 0.9990937924784775, Aging Rate = 0.5029451744449479, precision = 0.9932432432432432\n",
      "\n",
      "Epoch 31: Train Loss = 0.03435411472354585, Recall = 0.991391028545537, Aging Rate = 0.49954689623923876, Precision = 0.9922902494331066, f1 = 0.9918404351767907\n",
      "Epoch 32: Train Loss = 0.0256270370283681, Recall = 0.993656547349343, Aging Rate = 0.5, Precision = 0.993656547349343, f1 = 0.993656547349343\n",
      "Epoch 33: Train Loss = 0.015094866822539113, Recall = 0.9990937924784775, Aging Rate = 0.5, Precision = 0.9990937924784775, f1 = 0.9990937924784775\n",
      "Epoch 34: Train Loss = 0.018325553339364628, Recall = 0.9981875849569551, Aging Rate = 0.5002265518803806, Precision = 0.9977355072463768, f1 = 0.9979614949037372\n",
      "Epoch 35: Train Loss = 0.0170460107069974, Recall = 0.9995468962392388, Aging Rate = 0.5004531037607612, Precision = 0.9986419194205522, f1 = 0.9990942028985506\n",
      "Test Loss = 0.015833403056847817, Recall = 1.0, Aging Rate = 0.5004531037607612, precision = 0.9990946129470348\n",
      "Model in epoch 35 is saved.\n",
      "\n",
      "Epoch 36: Train Loss = 0.02322676596723372, Recall = 0.9963751699139103, Aging Rate = 0.5, Precision = 0.9963751699139103, f1 = 0.9963751699139103\n",
      "Epoch 37: Train Loss = 0.020839358479507002, Recall = 0.9981875849569551, Aging Rate = 0.5002265518803806, Precision = 0.9977355072463768, f1 = 0.9979614949037372\n",
      "Epoch 38: Train Loss = 0.017970770815624523, Recall = 0.9990937924784775, Aging Rate = 0.5002265518803806, Precision = 0.998641304347826, f1 = 0.9988674971687429\n",
      "Epoch 39: Train Loss = 0.01704034998364777, Recall = 0.9972813774354327, Aging Rate = 0.49909379247847757, Precision = 0.9990921470721743, f1 = 0.998185941043084\n",
      "Epoch 40: Train Loss = 0.022664158070805147, Recall = 0.9968282736746715, Aging Rate = 0.5004531037607612, Precision = 0.9959257582616569, f1 = 0.9963768115942029\n",
      "Test Loss = 0.017793633787304933, Recall = 0.9968282736746715, Aging Rate = 0.49841413683733576, precision = 1.0\n",
      "\n",
      "Epoch 41: Train Loss = 0.020168641139046338, Recall = 0.995922066153149, Aging Rate = 0.49864068871771633, Precision = 0.9986369831894594, f1 = 0.9972776769509982\n",
      "Epoch 42: Train Loss = 0.015378869345009084, Recall = 0.9990937924784775, Aging Rate = 0.5002265518803806, Precision = 0.998641304347826, f1 = 0.9988674971687429\n",
      "Epoch 43: Train Loss = 0.017057725496330195, Recall = 0.9986406887177164, Aging Rate = 0.5002265518803806, Precision = 0.9981884057971014, f1 = 0.9984144960362401\n",
      "Epoch 44: Train Loss = 0.021752746756335, Recall = 0.995922066153149, Aging Rate = 0.4993203443588582, Precision = 0.9972776769509982, f1 = 0.9965994105644979\n",
      "Epoch 45: Train Loss = 0.024150502343046405, Recall = 0.9950158586316267, Aging Rate = 0.5, Precision = 0.9950158586316267, f1 = 0.9950158586316267\n",
      "Test Loss = 0.014684380823345437, Recall = 0.9977344811961939, Aging Rate = 0.49909379247847757, precision = 0.9995460735360872\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 46: Train Loss = 0.01670178455542427, Recall = 0.9986406887177164, Aging Rate = 0.5, Precision = 0.9986406887177164, f1 = 0.9986406887177164\n",
      "Epoch 47: Train Loss = 0.01995838831141287, Recall = 0.9977344811961939, Aging Rate = 0.5002265518803806, Precision = 0.9972826086956522, f1 = 0.9975084937712344\n",
      "Epoch 48: Train Loss = 0.026584500196256085, Recall = 0.9941096511101042, Aging Rate = 0.4997734481196194, Precision = 0.9945602901178604, f1 = 0.9943349195558576\n",
      "Epoch 49: Train Loss = 0.028193866968235927, Recall = 0.9941096511101042, Aging Rate = 0.5002265518803806, Precision = 0.9936594202898551, f1 = 0.9938844847112117\n",
      "Epoch 50: Train Loss = 0.02103085325896659, Recall = 0.9986406887177164, Aging Rate = 0.5006796556411418, Precision = 0.9972850678733032, f1 = 0.9979624179307222\n",
      "Test Loss = 0.013360939660427335, Recall = 0.9972813774354327, Aging Rate = 0.49864068871771633, precision = 1.0\n",
      "\n",
      "Epoch 51: Train Loss = 0.017841201411466497, Recall = 0.9981875849569551, Aging Rate = 0.5004531037607612, Precision = 0.9972838388411046, f1 = 0.9977355072463768\n",
      "Epoch 52: Train Loss = 0.018398852512918965, Recall = 0.9968282736746715, Aging Rate = 0.4993203443588582, Precision = 0.9981851179673321, f1 = 0.9975062344139651\n",
      "Epoch 53: Train Loss = 0.027934150966529965, Recall = 0.9941096511101042, Aging Rate = 0.5002265518803806, Precision = 0.9936594202898551, f1 = 0.9938844847112117\n",
      "Epoch 54: Train Loss = 0.019567806057642096, Recall = 0.9972813774354327, Aging Rate = 0.4997734481196194, Precision = 0.9977334542157752, f1 = 0.9975073646045773\n",
      "Epoch 55: Train Loss = 0.01567128395951194, Recall = 0.9977344811961939, Aging Rate = 0.49954689623923876, Precision = 0.998639455782313, f1 = 0.99818676337262\n",
      "Test Loss = 0.015969679513663446, Recall = 1.0, Aging Rate = 0.5002265518803806, precision = 0.9995471014492754\n",
      "Model in epoch 55 is saved.\n",
      "\n",
      "Epoch 56: Train Loss = 0.018883502418888497, Recall = 0.9986406887177164, Aging Rate = 0.5002265518803806, Precision = 0.9981884057971014, f1 = 0.9984144960362401\n",
      "Epoch 57: Train Loss = 0.030084330689855762, Recall = 0.9927503398278206, Aging Rate = 0.49886724059809695, Precision = 0.9950045413260672, f1 = 0.9938761623951009\n",
      "Epoch 58: Train Loss = 0.014758040492161669, Recall = 0.9986406887177164, Aging Rate = 0.4997734481196194, Precision = 0.99909338168631, f1 = 0.9988669839111715\n",
      "Epoch 59: Train Loss = 0.015396694475502168, Recall = 0.9990937924784775, Aging Rate = 0.5004531037607612, Precision = 0.9981892258940697, f1 = 0.9986413043478259\n",
      "Epoch 60: Train Loss = 0.01716104678060196, Recall = 0.9986406887177164, Aging Rate = 0.49954689623923876, Precision = 0.999546485260771, f1 = 0.99909338168631\n",
      "Test Loss = 0.014118333268230405, Recall = 0.9990937924784775, Aging Rate = 0.5, precision = 0.9990937924784775\n",
      "\n",
      "Epoch 61: Train Loss = 0.017692816729425683, Recall = 0.9977344811961939, Aging Rate = 0.4997734481196194, Precision = 0.9981867633726201, f1 = 0.9979605710401087\n",
      "Epoch 62: Train Loss = 0.021875340045916316, Recall = 0.9963751699139103, Aging Rate = 0.49909379247847757, Precision = 0.9981842941443486, f1 = 0.9972789115646259\n",
      "Epoch 63: Train Loss = 0.03394036976207853, Recall = 0.9922972360670593, Aging Rate = 0.4997734481196194, Precision = 0.9927470534904805, f1 = 0.9925220938137321\n",
      "Epoch 64: Train Loss = 0.020921983583532797, Recall = 0.9968282736746715, Aging Rate = 0.5, Precision = 0.9968282736746715, f1 = 0.9968282736746715\n",
      "Epoch 65: Train Loss = 0.016856917847280432, Recall = 0.9977344811961939, Aging Rate = 0.4993203443588582, Precision = 0.9990925589836661, f1 = 0.9984130582634323\n",
      "Test Loss = 0.013639877634279103, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "Model in epoch 65 is saved.\n",
      "\n",
      "Epoch 66: Train Loss = 0.01659511465378406, Recall = 0.9968282736746715, Aging Rate = 0.49886724059809695, Precision = 0.9990917347865577, f1 = 0.9979587207983669\n",
      "Epoch 67: Train Loss = 0.015473992142220347, Recall = 0.9977344811961939, Aging Rate = 0.4993203443588582, Precision = 0.9990925589836661, f1 = 0.9984130582634323\n",
      "Epoch 68: Train Loss = 0.02119086553500041, Recall = 0.9963751699139103, Aging Rate = 0.5002265518803806, Precision = 0.9959239130434783, f1 = 0.9961494903737259\n",
      "Epoch 69: Train Loss = 0.02814634801338013, Recall = 0.991391028545537, Aging Rate = 0.4977344811961939, Precision = 0.9959035047792444, f1 = 0.9936421435059037\n",
      "Epoch 70: Train Loss = 0.016334213323192355, Recall = 0.9981875849569551, Aging Rate = 0.5004531037607612, Precision = 0.9972838388411046, f1 = 0.9977355072463768\n",
      "Test Loss = 0.01538236779179787, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 71: Train Loss = 0.014303963083232021, Recall = 0.9995468962392388, Aging Rate = 0.5004531037607612, Precision = 0.9986419194205522, f1 = 0.9990942028985506\n",
      "Epoch 72: Train Loss = 0.019099476461530433, Recall = 0.9977344811961939, Aging Rate = 0.49954689623923876, Precision = 0.998639455782313, f1 = 0.99818676337262\n",
      "Epoch 73: Train Loss = 0.01628595173838293, Recall = 0.9995468962392388, Aging Rate = 0.5, Precision = 0.9995468962392388, f1 = 0.9995468962392388\n",
      "Epoch 74: Train Loss = 0.029576730449807607, Recall = 0.993656547349343, Aging Rate = 0.5004531037607612, Precision = 0.9927569035762789, f1 = 0.9932065217391304\n",
      "Epoch 75: Train Loss = 0.034878791207350594, Recall = 0.9909379247847757, Aging Rate = 0.5002265518803806, Precision = 0.9904891304347826, f1 = 0.9907134767836919\n",
      "Test Loss = 0.015646511892225604, Recall = 0.9995468962392388, Aging Rate = 0.5015858631626643, precision = 0.996386630532972\n",
      "\n",
      "Epoch 76: Train Loss = 0.01720946212267519, Recall = 0.9990937924784775, Aging Rate = 0.5013593112822836, Precision = 0.9963849977406236, f1 = 0.997737556561086\n",
      "Epoch 77: Train Loss = 0.016119642542716493, Recall = 0.9977344811961939, Aging Rate = 0.5, Precision = 0.9977344811961939, f1 = 0.9977344811961939\n",
      "Epoch 78: Train Loss = 0.013845349035357047, Recall = 0.9995468962392388, Aging Rate = 0.5, Precision = 0.9995468962392388, f1 = 0.9995468962392388\n",
      "Epoch 79: Train Loss = 0.013580743733187526, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 80: Train Loss = 0.01795860146871575, Recall = 0.9986406887177164, Aging Rate = 0.5, Precision = 0.9986406887177164, f1 = 0.9986406887177164\n",
      "Test Loss = 0.01689851527766075, Recall = 0.9995468962392388, Aging Rate = 0.5009062075215225, precision = 0.9977385798281321\n",
      "\n",
      "Epoch 81: Train Loss = 0.02014795478684874, Recall = 0.9981875849569551, Aging Rate = 0.5002265518803806, Precision = 0.9977355072463768, f1 = 0.9979614949037372\n",
      "Epoch 82: Train Loss = 0.019243748678805118, Recall = 0.9963751699139103, Aging Rate = 0.49886724059809695, Precision = 0.9986376021798365, f1 = 0.9975051031980042\n",
      "Epoch 83: Train Loss = 0.01652482969540382, Recall = 0.9977344811961939, Aging Rate = 0.49909379247847757, Precision = 0.9995460735360872, f1 = 0.998639455782313\n",
      "Epoch 84: Train Loss = 0.01551714724695245, Recall = 1.0, Aging Rate = 0.5004531037607612, Precision = 0.9990946129470348, f1 = 0.9995471014492754\n",
      "Epoch 85: Train Loss = 0.015998734470995292, Recall = 0.9986406887177164, Aging Rate = 0.4993203443588582, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.020003701520954584, Recall = 0.9990937924784775, Aging Rate = 0.4997734481196194, precision = 0.9995466908431551\n",
      "\n",
      "Epoch 86: Train Loss = 0.017027758060197892, Recall = 0.9990937924784775, Aging Rate = 0.5004531037607612, Precision = 0.9981892258940697, f1 = 0.9986413043478259\n",
      "Epoch 87: Train Loss = 0.018057390051591325, Recall = 0.9977344811961939, Aging Rate = 0.49954689623923876, Precision = 0.998639455782313, f1 = 0.99818676337262\n",
      "Epoch 88: Train Loss = 0.023875980629105887, Recall = 0.9954689623923878, Aging Rate = 0.49954689623923876, Precision = 0.9963718820861678, f1 = 0.9959202175883952\n",
      "Epoch 89: Train Loss = 0.06590827638186315, Recall = 0.9773448119619392, Aging Rate = 0.5006796556411418, Precision = 0.9760180995475113, f1 = 0.9766810052071542\n",
      "Epoch 90: Train Loss = 0.030426858137325836, Recall = 0.9927503398278206, Aging Rate = 0.4993203443588582, Precision = 0.9941016333938294, f1 = 0.9934255270913624\n",
      "Test Loss = 0.009568153837283015, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 91: Train Loss = 0.011476053027533194, Recall = 0.9986406887177164, Aging Rate = 0.4993203443588582, Precision = 0, f1 = 0.0\n",
      "Epoch 92: Train Loss = 0.013201084826015, Recall = 0.9990937924784775, Aging Rate = 0.5, Precision = 0.9990937924784775, f1 = 0.9990937924784775\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 93: Train Loss = 0.014905296270720793, Recall = 0.9990937924784775, Aging Rate = 0.4997734481196194, Precision = 0.9995466908431551, f1 = 0.9993201903467029\n",
      "Epoch 94: Train Loss = 0.015020972249863183, Recall = 0.9990937924784775, Aging Rate = 0.5, Precision = 0.9990937924784775, f1 = 0.9990937924784775\n",
      "Epoch 95: Train Loss = 0.015030378973728454, Recall = 0.9995468962392388, Aging Rate = 0.5, Precision = 0.9995468962392388, f1 = 0.9995468962392388\n",
      "Test Loss = 0.013265818548205216, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 96: Train Loss = 0.015864589420794144, Recall = 0.9986406887177164, Aging Rate = 0.4993203443588582, Precision = 0, f1 = 0.0\n",
      "Epoch 97: Train Loss = 0.015568639109131433, Recall = 0.9990937924784775, Aging Rate = 0.5002265518803806, Precision = 0.998641304347826, f1 = 0.9988674971687429\n",
      "Epoch 98: Train Loss = 0.019234126313464182, Recall = 0.9981875849569551, Aging Rate = 0.5002265518803806, Precision = 0.9977355072463768, f1 = 0.9979614949037372\n",
      "Epoch 99: Train Loss = 0.01688729683304392, Recall = 0.9977344811961939, Aging Rate = 0.49886724059809695, Precision = 0, f1 = 0.0\n",
      "Epoch 100: Train Loss = 0.018403744922995593, Recall = 0.9990937924784775, Aging Rate = 0.5004531037607612, Precision = 0.9981892258940697, f1 = 0.9986413043478259\n",
      "Test Loss = 0.03527756723924276, Recall = 0.9886724059809696, Aging Rate = 0.4943362029904848, precision = 1.0\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f39d7732ad747fb92de929c8568d722",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss = 0.38003415496156956, Recall = 0.7932910244786945, Aging Rate = 0.46441523118767, Precision = 0.854075158613958, f1 = 0.8225616921269094\n",
      "Epoch 2: Train Loss = 0.16761144148633356, Recall = 0.9329102447869447, Aging Rate = 0.49206708975521307, Precision = 0.9479502533394749, f1 = 0.940370116518163\n",
      "Epoch 3: Train Loss = 0.10736036830238073, Recall = 0.9619220308250227, Aging Rate = 0.49614687216681774, Precision = 0.9693924166285975, f1 = 0.9656427758816837\n",
      "Epoch 4: Train Loss = 0.0858865644063392, Recall = 0.9691749773345422, Aging Rate = 0.4956935630099728, Precision = 0.9775948788294467, f1 = 0.9733667197814706\n",
      "Epoch 5: Train Loss = 0.07740444587315631, Recall = 0.9732547597461468, Aging Rate = 0.49705349048050773, Precision = 0.9790241678066576, f1 = 0.9761309388497386\n",
      "Test Loss = 0.0348958325904143, Recall = 0.9941069809610155, Aging Rate = 0.5002266545784225, precision = 0.993656547349343\n",
      "Model in epoch 5 is saved.\n",
      "\n",
      "Epoch 6: Train Loss = 0.031209047098499695, Recall = 0.9936536718041704, Aging Rate = 0.4986400725294651, Precision = 0.9963636363636363, f1 = 0.9950068088969587\n",
      "Epoch 7: Train Loss = 0.022055042129945506, Recall = 0.9972801450589301, Aging Rate = 0.49909338168631007, Precision = 0.9990917347865577, f1 = 0.9981851179673321\n",
      "Epoch 8: Train Loss = 0.022149424663899384, Recall = 0.9954669084315503, Aging Rate = 0.4988667271078876, Precision = 0.9977283053157655, f1 = 0.9965963240299522\n",
      "Epoch 9: Train Loss = 0.022525098591921335, Recall = 0.9977334542157752, Aging Rate = 0.5, Precision = 0.9977334542157752, f1 = 0.9977334542157752\n",
      "Epoch 10: Train Loss = 0.019699822263564183, Recall = 0.9972801450589301, Aging Rate = 0.499546690843155, Precision = 0.9981851179673321, f1 = 0.9977324263038548\n",
      "Test Loss = 0.016978471116893202, Recall = 0.9981867633726201, Aging Rate = 0.49932003626473254, precision = 0.9995460735360872\n",
      "Model in epoch 10 is saved.\n",
      "\n",
      "Epoch 11: Train Loss = 0.021352388142039855, Recall = 0.9972801450589301, Aging Rate = 0.4988667271078876, Precision = 0.9995456610631531, f1 = 0.9984116178806445\n",
      "Epoch 12: Train Loss = 0.02299755442201929, Recall = 0.9954669084315503, Aging Rate = 0.49909338168631007, Precision = 0.997275204359673, f1 = 0.9963702359346642\n",
      "Epoch 13: Train Loss = 0.02441573465717509, Recall = 0.9968268359020852, Aging Rate = 0.50090661831369, Precision = 0.9950226244343892, f1 = 0.9959239130434782\n",
      "Epoch 14: Train Loss = 0.025288360350421635, Recall = 0.9959202175883953, Aging Rate = 0.5, Precision = 0.9959202175883953, f1 = 0.9959202175883953\n",
      "Epoch 15: Train Loss = 0.023506072997888136, Recall = 0.9968268359020852, Aging Rate = 0.5004533091568449, Precision = 0.9959239130434783, f1 = 0.9963751699139104\n",
      "Test Loss = 0.024933821517477656, Recall = 0.9927470534904805, Aging Rate = 0.49637352674524027, precision = 1.0\n",
      "\n",
      "Epoch 16: Train Loss = 0.020112641665709634, Recall = 0.9977334542157752, Aging Rate = 0.49977334542157753, Precision = 0.9981859410430839, f1 = 0.9979596463386986\n",
      "Epoch 17: Train Loss = 0.022303548866523224, Recall = 0.9959202175883953, Aging Rate = 0.4986400725294651, Precision = 0.9986363636363637, f1 = 0.9972764412165229\n",
      "Epoch 18: Train Loss = 0.02156764818465207, Recall = 0.9968268359020852, Aging Rate = 0.49977334542157753, Precision = 0.9972789115646259, f1 = 0.9970528224892314\n",
      "Epoch 19: Train Loss = 0.023972372128438214, Recall = 0.9954669084315503, Aging Rate = 0.49977334542157753, Precision = 0.9959183673469387, f1 = 0.9956925867150306\n",
      "Epoch 20: Train Loss = 0.033090389008589044, Recall = 0.9891205802357208, Aging Rate = 0.49773345421577514, Precision = 0.9936247723132969, f1 = 0.9913675601999092\n",
      "Test Loss = 0.02061448596816439, Recall = 0.9922937443336355, Aging Rate = 0.49796010879419766, precision = 0.996358670914884\n",
      "\n",
      "Epoch 21: Train Loss = 0.022492830704894266, Recall = 0.9963735267452403, Aging Rate = 0.5, Precision = 0.9963735267452403, f1 = 0.9963735267452403\n",
      "Epoch 22: Train Loss = 0.017279709247721937, Recall = 0.9968268359020852, Aging Rate = 0.4988667271078876, Precision = 0.9990913221263062, f1 = 0.9979577944179714\n",
      "Epoch 23: Train Loss = 0.015834841381586202, Recall = 0.9995466908431551, Aging Rate = 0.49977334542157753, Precision = 0, f1 = 0.0\n",
      "Epoch 24: Train Loss = 0.021392268452502902, Recall = 0.9954669084315503, Aging Rate = 0.49909338168631007, Precision = 0.997275204359673, f1 = 0.9963702359346642\n",
      "Epoch 25: Train Loss = 0.025325467039983812, Recall = 0.9945602901178604, Aging Rate = 0.4988667271078876, Precision = 0.9968196274420718, f1 = 0.9956886771046063\n",
      "Test Loss = 0.010924239745084956, Recall = 1.0, Aging Rate = 0.5002266545784225, precision = 0.9995468962392388\n",
      "Model in epoch 25 is saved.\n",
      "\n",
      "Epoch 26: Train Loss = 0.015429937369371692, Recall = 0.9981867633726201, Aging Rate = 0.49977334542157753, Precision = 0.998639455782313, f1 = 0.9984130582634324\n",
      "Epoch 27: Train Loss = 0.019522511269407496, Recall = 0.9977334542157752, Aging Rate = 0.49977334542157753, Precision = 0.9981859410430839, f1 = 0.9979596463386986\n",
      "Epoch 28: Train Loss = 0.021890484218773577, Recall = 0.9972801450589301, Aging Rate = 0.5006799637352675, Precision = 0.9959257582616569, f1 = 0.9966024915062288\n",
      "Epoch 29: Train Loss = 0.01995045020129339, Recall = 0.9981867633726201, Aging Rate = 0.5004533091568449, Precision = 0.9972826086956522, f1 = 0.9977344811961939\n",
      "Epoch 30: Train Loss = 0.017070548852073097, Recall = 0.9981867633726201, Aging Rate = 0.499546690843155, Precision = 0.9990925589836661, f1 = 0.998639455782313\n",
      "Test Loss = 0.01594793832846533, Recall = 0.9995466908431551, Aging Rate = 0.5002266545784225, precision = 0.9990937924784775\n",
      "\n",
      "Epoch 31: Train Loss = 0.021587252557777537, Recall = 0.9968268359020852, Aging Rate = 0.4988667271078876, Precision = 0.9990913221263062, f1 = 0.9979577944179714\n",
      "Epoch 32: Train Loss = 0.03739687946311798, Recall = 0.9900271985494107, Aging Rate = 0.5006799637352675, Precision = 0.9886826618379357, f1 = 0.9893544733861834\n",
      "Epoch 33: Train Loss = 0.033310107234949864, Recall = 0.9941069809610155, Aging Rate = 0.5018132366273799, Precision = 0.9905149051490515, f1 = 0.9923076923076924\n",
      "Epoch 34: Train Loss = 0.01780478762511708, Recall = 0.9972801450589301, Aging Rate = 0.5004533091568449, Precision = 0.9963768115942029, f1 = 0.9968282736746715\n",
      "Epoch 35: Train Loss = 0.02224603470107532, Recall = 0.9963735267452403, Aging Rate = 0.5, Precision = 0.9963735267452403, f1 = 0.9963735267452403\n",
      "Test Loss = 0.013016340848825136, Recall = 1.0, Aging Rate = 0.5006799637352675, precision = 0.9986419194205522\n",
      "\n",
      "Epoch 36: Train Loss = 0.01732040527643989, Recall = 0.9977334542157752, Aging Rate = 0.499546690843155, Precision = 0.9986388384754991, f1 = 0.9981859410430838\n",
      "Epoch 37: Train Loss = 0.018224424104175022, Recall = 0.9972801450589301, Aging Rate = 0.4988667271078876, Precision = 0.9995456610631531, f1 = 0.9984116178806445\n",
      "Epoch 38: Train Loss = 0.018425278615540844, Recall = 0.9981867633726201, Aging Rate = 0.5, Precision = 0.9981867633726201, f1 = 0.9981867633726201\n",
      "Epoch 39: Train Loss = 0.015230306336387708, Recall = 1.0, Aging Rate = 0.5002266545784225, Precision = 0.9995468962392388, f1 = 0.9997733967822342\n",
      "Epoch 40: Train Loss = 0.021428296820396524, Recall = 0.9972801450589301, Aging Rate = 0.5, Precision = 0.9972801450589301, f1 = 0.9972801450589301\n",
      "Test Loss = 0.022618714807823584, Recall = 0.9959202175883953, Aging Rate = 0.49818676337262013, precision = 0.9995450409463148\n",
      "\n",
      "Epoch 41: Train Loss = 0.023724910142009947, Recall = 0.9954669084315503, Aging Rate = 0.499546690843155, Precision = 0.9963702359346642, f1 = 0.9959183673469388\n",
      "Epoch 42: Train Loss = 0.025715870792865213, Recall = 0.9963735267452403, Aging Rate = 0.50090661831369, Precision = 0.9945701357466064, f1 = 0.9954710144927537\n",
      "Epoch 43: Train Loss = 0.014193300384072315, Recall = 0.9995466908431551, Aging Rate = 0.5, Precision = 0.9995466908431551, f1 = 0.9995466908431551\n",
      "Epoch 44: Train Loss = 0.019037999057380697, Recall = 0.9977334542157752, Aging Rate = 0.49977334542157753, Precision = 0.9981859410430839, f1 = 0.9979596463386986\n",
      "Epoch 45: Train Loss = 0.024340620223881976, Recall = 0.9968268359020852, Aging Rate = 0.5006799637352675, Precision = 0.9954730647351743, f1 = 0.9961494903737259\n",
      "Test Loss = 0.0227797468001207, Recall = 0.99909338168631, Aging Rate = 0.5011332728921124, precision = 0.9968340117593849\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 46: Train Loss = 0.0257082906832829, Recall = 0.9950135992747053, Aging Rate = 0.49909338168631007, Precision = 0.9968210717529519, f1 = 0.9959165154264972\n",
      "Epoch 47: Train Loss = 0.01570626409894914, Recall = 0.9981867633726201, Aging Rate = 0.49932003626473254, Precision = 0.9995460735360872, f1 = 0.9988659559990928\n",
      "Epoch 48: Train Loss = 0.023364994045032877, Recall = 0.9972801450589301, Aging Rate = 0.50090661831369, Precision = 0.995475113122172, f1 = 0.9963768115942029\n",
      "Epoch 49: Train Loss = 0.020649703297213544, Recall = 0.9945602901178604, Aging Rate = 0.49909338168631007, Precision = 0.9963669391462306, f1 = 0.9954627949183303\n",
      "Epoch 50: Train Loss = 0.020378705732193407, Recall = 0.9977334542157752, Aging Rate = 0.499546690843155, Precision = 0.9986388384754991, f1 = 0.9981859410430838\n",
      "Test Loss = 0.024420970557755703, Recall = 0.9968268359020852, Aging Rate = 0.499546690843155, precision = 0.9977313974591652\n",
      "\n",
      "Epoch 51: Train Loss = 0.0209997643785026, Recall = 0.9968268359020852, Aging Rate = 0.5006799637352675, Precision = 0.9954730647351743, f1 = 0.9961494903737259\n",
      "Epoch 52: Train Loss = 0.016970226637417905, Recall = 0.9986400725294651, Aging Rate = 0.5002266545784225, Precision = 0.9981875849569551, f1 = 0.9984137774756402\n",
      "Epoch 53: Train Loss = 0.016632221314924367, Recall = 0.9986400725294651, Aging Rate = 0.5, Precision = 0.9986400725294651, f1 = 0.9986400725294651\n",
      "Epoch 54: Train Loss = 0.018328954613449244, Recall = 0.9977334542157752, Aging Rate = 0.49977334542157753, Precision = 0.9981859410430839, f1 = 0.9979596463386986\n",
      "Epoch 55: Train Loss = 0.02011643456681847, Recall = 0.9977334542157752, Aging Rate = 0.49977334542157753, Precision = 0.9981859410430839, f1 = 0.9979596463386986\n",
      "Test Loss = 0.014117529863999955, Recall = 0.9972801450589301, Aging Rate = 0.4986400725294651, precision = 1.0\n",
      "\n",
      "Epoch 56: Train Loss = 0.022269439962055073, Recall = 0.9977334542157752, Aging Rate = 0.5004533091568449, Precision = 0.9968297101449275, f1 = 0.9972813774354327\n",
      "Epoch 57: Train Loss = 0.020042196633876828, Recall = 0.9959202175883953, Aging Rate = 0.4984134179510426, Precision = 0.9990904956798545, f1 = 0.9975028376844495\n",
      "Epoch 58: Train Loss = 0.015434725714994364, Recall = 0.9977334542157752, Aging Rate = 0.49909338168631007, Precision = 0.9995458673932789, f1 = 0.9986388384754992\n",
      "Epoch 59: Train Loss = 0.021711198225489066, Recall = 0.9963735267452403, Aging Rate = 0.49909338168631007, Precision = 0.9981834695731153, f1 = 0.9972776769509981\n",
      "Epoch 60: Train Loss = 0.015514851886363647, Recall = 0.9995466908431551, Aging Rate = 0.50090661831369, Precision = 0.997737556561086, f1 = 0.998641304347826\n",
      "Test Loss = 0.014872515905928795, Recall = 0.99909338168631, Aging Rate = 0.499546690843155, precision = 1.0\n",
      "\n",
      "Epoch 61: Train Loss = 0.0191484396316361, Recall = 0.9972801450589301, Aging Rate = 0.499546690843155, Precision = 0.9981851179673321, f1 = 0.9977324263038548\n",
      "Epoch 62: Train Loss = 0.016089051098968913, Recall = 0.9986400725294651, Aging Rate = 0.49932003626473254, Precision = 0, f1 = 0.0\n",
      "Epoch 63: Train Loss = 0.01755711789380553, Recall = 0.9972801450589301, Aging Rate = 0.4988667271078876, Precision = 0.9995456610631531, f1 = 0.9984116178806445\n",
      "Epoch 64: Train Loss = 0.02056772364024833, Recall = 0.9977334542157752, Aging Rate = 0.5, Precision = 0.9977334542157752, f1 = 0.9977334542157752\n",
      "Epoch 65: Train Loss = 0.025575617556261778, Recall = 0.9954669084315503, Aging Rate = 0.5004533091568449, Precision = 0.9945652173913043, f1 = 0.9950158586316266\n",
      "Test Loss = 0.024564225277301947, Recall = 0.9995466908431551, Aging Rate = 0.5040797824116047, precision = 0.9914568345323741\n",
      "\n",
      "Epoch 66: Train Loss = 0.024994917848871062, Recall = 0.9941069809610155, Aging Rate = 0.49909338168631007, Precision = 0.9959128065395095, f1 = 0.9950090744101634\n",
      "Epoch 67: Train Loss = 0.017760733032729122, Recall = 0.9977334542157752, Aging Rate = 0.499546690843155, Precision = 0.9986388384754991, f1 = 0.9981859410430838\n",
      "Epoch 68: Train Loss = 0.015890541438313904, Recall = 0.9981867633726201, Aging Rate = 0.499546690843155, Precision = 0.9990925589836661, f1 = 0.998639455782313\n",
      "Epoch 69: Train Loss = 0.014950686007744868, Recall = 0.9995466908431551, Aging Rate = 0.5004533091568449, Precision = 0.998641304347826, f1 = 0.9990937924784776\n",
      "Epoch 70: Train Loss = 0.018223348579429435, Recall = 0.9977334542157752, Aging Rate = 0.49932003626473254, Precision = 0.9990921470721743, f1 = 0.9984123383987299\n",
      "Test Loss = 0.01846521250998174, Recall = 0.9995466908431551, Aging Rate = 0.5, precision = 0.9995466908431551\n",
      "\n",
      "Epoch 71: Train Loss = 0.018817520620181466, Recall = 0.9972801450589301, Aging Rate = 0.49932003626473254, Precision = 0.9986382206082615, f1 = 0.9979587207983669\n",
      "Epoch 72: Train Loss = 0.021045856494439644, Recall = 0.9972801450589301, Aging Rate = 0.49932003626473254, Precision = 0.9986382206082615, f1 = 0.9979587207983669\n",
      "Epoch 73: Train Loss = 0.0182731870447006, Recall = 0.9981867633726201, Aging Rate = 0.5, Precision = 0.9981867633726201, f1 = 0.9981867633726201\n",
      "Epoch 74: Train Loss = 0.01670809500831317, Recall = 0.99909338168631, Aging Rate = 0.5004533091568449, Precision = 0.9981884057971014, f1 = 0.9986406887177163\n",
      "Epoch 75: Train Loss = 0.026061386771750038, Recall = 0.9950135992747053, Aging Rate = 0.4988667271078876, Precision = 0.9972739663789186, f1 = 0.9961425005672793\n",
      "Test Loss = 0.014823321411799865, Recall = 1.0, Aging Rate = 0.50090661831369, precision = 0.9981900452488688\n",
      "\n",
      "Training Finished at epoch 75.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c163af37652d4f498fa7ef8de59fbd85",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss = 0.4030725410172643, Recall = 0.7805983680870353, Aging Rate = 0.4657751586582049, Precision = 0.8379562043795621, f1 = 0.8082609716029102\n",
      "Epoch 2: Train Loss = 0.16558772306602215, Recall = 0.9347234814143246, Aging Rate = 0.49070716228467814, Precision = 0.9524249422632795, f1 = 0.9434911919469229\n",
      "Epoch 3: Train Loss = 0.10443369475474491, Recall = 0.9632819582955575, Aging Rate = 0.49478694469628287, Precision = 0.9734310581768209, f1 = 0.9683299156983367\n",
      "Epoch 4: Train Loss = 0.0868315750721197, Recall = 0.9687216681776972, Aging Rate = 0.49637352674524027, Precision = 0.9757990867579909, f1 = 0.9722474977252048\n",
      "Epoch 5: Train Loss = 0.0654179603199146, Recall = 0.9796010879419764, Aging Rate = 0.49796010879419766, Precision = 0.9836140191169777, f1 = 0.9816034521916874\n",
      "Test Loss = 0.028805710415837987, Recall = 0.9954669084315503, Aging Rate = 0.499546690843155, precision = 0.9963702359346642\n",
      "Model in epoch 5 is saved.\n",
      "\n",
      "Epoch 6: Train Loss = 0.03235375327298778, Recall = 0.9950135992747053, Aging Rate = 0.5002266545784225, Precision = 0.9945627548708654, f1 = 0.9947881259913891\n",
      "Epoch 7: Train Loss = 0.024882997699412886, Recall = 0.9950135992747053, Aging Rate = 0.499546690843155, Precision = 0.9959165154264973, f1 = 0.9954648526077098\n",
      "Epoch 8: Train Loss = 0.018749166568800307, Recall = 0.9995466908431551, Aging Rate = 0.5004533091568449, Precision = 0.998641304347826, f1 = 0.9990937924784776\n",
      "Epoch 9: Train Loss = 0.022840087410950814, Recall = 0.9972801450589301, Aging Rate = 0.49977334542157753, Precision = 0.9977324263038548, f1 = 0.997506234413965\n",
      "Epoch 10: Train Loss = 0.028607767389399942, Recall = 0.9936536718041704, Aging Rate = 0.49977334542157753, Precision = 0.9941043083900227, f1 = 0.9938789390160961\n",
      "Test Loss = 0.035085659896311495, Recall = 0.9891205802357208, Aging Rate = 0.4945602901178604, precision = 1.0\n",
      "Model in epoch 10 is saved.\n",
      "\n",
      "Epoch 11: Train Loss = 0.023828537074185346, Recall = 0.9936536718041704, Aging Rate = 0.4986400725294651, Precision = 0.9963636363636363, f1 = 0.9950068088969587\n",
      "Epoch 12: Train Loss = 0.027970689467930406, Recall = 0.9932003626473255, Aging Rate = 0.49932003626473254, Precision = 0.9945528824330458, f1 = 0.993876162395101\n",
      "Epoch 13: Train Loss = 0.020672851312206426, Recall = 0.9963735267452403, Aging Rate = 0.49932003626473254, Precision = 0.9977303676804358, f1 = 0.9970514855976411\n",
      "Epoch 14: Train Loss = 0.017630772231145005, Recall = 0.9986400725294651, Aging Rate = 0.5004533091568449, Precision = 0.9977355072463768, f1 = 0.9981875849569551\n",
      "Epoch 15: Train Loss = 0.022917730654382965, Recall = 0.9972801450589301, Aging Rate = 0.5002266545784225, Precision = 0.9968282736746715, f1 = 0.997054158169046\n",
      "Test Loss = 0.01953855513722542, Recall = 0.9968268359020852, Aging Rate = 0.4988667271078876, precision = 0.9990913221263062\n",
      "Model in epoch 15 is saved.\n",
      "\n",
      "Epoch 16: Train Loss = 0.021698963099707286, Recall = 0.9977334542157752, Aging Rate = 0.5004533091568449, Precision = 0.9968297101449275, f1 = 0.9972813774354327\n",
      "Epoch 17: Train Loss = 0.02364091604529244, Recall = 0.9977334542157752, Aging Rate = 0.5004533091568449, Precision = 0.9968297101449275, f1 = 0.9972813774354327\n",
      "Epoch 18: Train Loss = 0.032332363509736, Recall = 0.9927470534904805, Aging Rate = 0.5006799637352675, Precision = 0.9913988229968311, f1 = 0.9920724801812004\n",
      "Epoch 19: Train Loss = 0.02762740839640876, Recall = 0.9954669084315503, Aging Rate = 0.5, Precision = 0.9954669084315503, f1 = 0.9954669084315503\n",
      "Epoch 20: Train Loss = 0.022009741386579365, Recall = 0.9977334542157752, Aging Rate = 0.5004533091568449, Precision = 0.9968297101449275, f1 = 0.9972813774354327\n",
      "Test Loss = 0.013401773450043347, Recall = 1.0, Aging Rate = 0.5002266545784225, precision = 0.9995468962392388\n",
      "Model in epoch 20 is saved.\n",
      "\n",
      "Epoch 21: Train Loss = 0.015487541941924195, Recall = 0.9981867633726201, Aging Rate = 0.49977334542157753, Precision = 0.998639455782313, f1 = 0.9984130582634324\n",
      "Epoch 22: Train Loss = 0.03133411800399328, Recall = 0.9945602901178604, Aging Rate = 0.50090661831369, Precision = 0.9927601809954751, f1 = 0.9936594202898551\n",
      "Epoch 23: Train Loss = 0.030552177135228894, Recall = 0.9927470534904805, Aging Rate = 0.4988667271078876, Precision = 0.9950022716946842, f1 = 0.9938733832539142\n",
      "Epoch 24: Train Loss = 0.019159799414675882, Recall = 0.9972801450589301, Aging Rate = 0.5, Precision = 0.9972801450589301, f1 = 0.9972801450589301\n",
      "Epoch 25: Train Loss = 0.01594815278765243, Recall = 0.9977334542157752, Aging Rate = 0.499546690843155, Precision = 0.9986388384754991, f1 = 0.9981859410430838\n",
      "Test Loss = 0.01751831640993479, Recall = 0.9995466908431551, Aging Rate = 0.49977334542157753, precision = 1.0\n",
      "Model in epoch 25 is saved.\n",
      "\n",
      "Epoch 26: Train Loss = 0.016881227678199683, Recall = 0.99909338168631, Aging Rate = 0.5, Precision = 0.99909338168631, f1 = 0.99909338168631\n",
      "Epoch 27: Train Loss = 0.02603232664506163, Recall = 0.9950135992747053, Aging Rate = 0.5006799637352675, Precision = 0.993662290629244, f1 = 0.9943374858437146\n",
      "Epoch 28: Train Loss = 0.020993857169126988, Recall = 0.9954669084315503, Aging Rate = 0.4988667271078876, Precision = 0.9977283053157655, f1 = 0.9965963240299522\n",
      "Epoch 29: Train Loss = 0.024723724143770425, Recall = 0.9954669084315503, Aging Rate = 0.5, Precision = 0.9954669084315503, f1 = 0.9954669084315503\n",
      "Epoch 30: Train Loss = 0.015774755074168915, Recall = 0.99909338168631, Aging Rate = 0.5002266545784225, Precision = 0.9986406887177164, f1 = 0.9988669839111715\n",
      "Test Loss = 0.017713410513017898, Recall = 1.0, Aging Rate = 0.5011332728921124, precision = 0.9977385798281321\n",
      "\n",
      "Epoch 31: Train Loss = 0.017620502649413814, Recall = 0.9981867633726201, Aging Rate = 0.499546690843155, Precision = 0.9990925589836661, f1 = 0.998639455782313\n",
      "Epoch 32: Train Loss = 0.021543482730565347, Recall = 0.9963735267452403, Aging Rate = 0.4986400725294651, Precision = 0.9990909090909091, f1 = 0.9977303676804358\n",
      "Epoch 33: Train Loss = 0.02664415365725026, Recall = 0.9963735267452403, Aging Rate = 0.5011332728921124, Precision = 0.9941203075531434, f1 = 0.9952456418383518\n",
      "Epoch 34: Train Loss = 0.023448030885683875, Recall = 0.9954669084315503, Aging Rate = 0.49977334542157753, Precision = 0.9959183673469387, f1 = 0.9956925867150306\n",
      "Epoch 35: Train Loss = 0.021157090122374964, Recall = 0.9972801450589301, Aging Rate = 0.5, Precision = 0.9972801450589301, f1 = 0.9972801450589301\n",
      "Test Loss = 0.018766254539570263, Recall = 0.9981867633726201, Aging Rate = 0.49909338168631007, precision = 1.0\n",
      "\n",
      "Epoch 36: Train Loss = 0.019110636822777992, Recall = 0.9977334542157752, Aging Rate = 0.5002266545784225, Precision = 0.9972813774354327, f1 = 0.9975073646045773\n",
      "Epoch 37: Train Loss = 0.02354632617258961, Recall = 0.9950135992747053, Aging Rate = 0.499546690843155, Precision = 0.9959165154264973, f1 = 0.9954648526077098\n",
      "Epoch 38: Train Loss = 0.021702304256173123, Recall = 0.9963735267452403, Aging Rate = 0.5, Precision = 0.9963735267452403, f1 = 0.9963735267452403\n",
      "Epoch 39: Train Loss = 0.03955939710680615, Recall = 0.9909338168631007, Aging Rate = 0.5006799637352675, Precision = 0.9895880488909009, f1 = 0.9902604756511891\n",
      "Epoch 40: Train Loss = 0.015915541756806973, Recall = 0.9972801450589301, Aging Rate = 0.4986400725294651, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.009826958052820762, Recall = 1.0, Aging Rate = 0.5004533091568449, precision = 0.9990942028985508\n",
      "\n",
      "Epoch 41: Train Loss = 0.015599226577381383, Recall = 0.9986400725294651, Aging Rate = 0.5002266545784225, Precision = 0.9981875849569551, f1 = 0.9984137774756402\n",
      "Epoch 42: Train Loss = 0.020033926156738727, Recall = 0.9972801450589301, Aging Rate = 0.4988667271078876, Precision = 0.9995456610631531, f1 = 0.9984116178806445\n",
      "Epoch 43: Train Loss = 0.02951737006928633, Recall = 0.9927470534904805, Aging Rate = 0.499546690843155, Precision = 0.9936479128856625, f1 = 0.9931972789115647\n",
      "Epoch 44: Train Loss = 0.027824006647087722, Recall = 0.9932003626473255, Aging Rate = 0.4984134179510426, Precision = 0.9963619827194179, f1 = 0.9947786606129397\n",
      "Epoch 45: Train Loss = 0.0199755947354671, Recall = 0.9968268359020852, Aging Rate = 0.5, Precision = 0.9968268359020852, f1 = 0.9968268359020852\n",
      "Test Loss = 0.017536076068614737, Recall = 0.9922937443336355, Aging Rate = 0.49614687216681774, precision = 1.0\n",
      "\n",
      "Epoch 46: Train Loss = 0.023179568056479867, Recall = 0.9968268359020852, Aging Rate = 0.5002266545784225, Precision = 0.9963751699139103, f1 = 0.9966009517335147\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 47: Train Loss = 0.02302003687489119, Recall = 0.9963735267452403, Aging Rate = 0.5006799637352675, Precision = 0.9950203712086917, f1 = 0.995696489241223\n",
      "Epoch 48: Train Loss = 0.019295760867771027, Recall = 0.9963735267452403, Aging Rate = 0.4988667271078876, Precision = 0.9986369831894594, f1 = 0.9975039709552984\n",
      "Epoch 49: Train Loss = 0.014956903492766732, Recall = 0.99909338168631, Aging Rate = 0.49977334542157753, Precision = 0.999546485260771, f1 = 0.9993198821128995\n",
      "Epoch 50: Train Loss = 0.01611993260046675, Recall = 0.9995466908431551, Aging Rate = 0.50090661831369, Precision = 0.997737556561086, f1 = 0.998641304347826\n",
      "Test Loss = 0.016494626680883837, Recall = 0.9995466908431551, Aging Rate = 0.5, precision = 0.9995466908431551\n",
      "\n",
      "Epoch 51: Train Loss = 0.02186343862471641, Recall = 0.9968268359020852, Aging Rate = 0.499546690843155, Precision = 0.9977313974591652, f1 = 0.9972789115646259\n",
      "Epoch 52: Train Loss = 0.01804789654988245, Recall = 0.9977334542157752, Aging Rate = 0.499546690843155, Precision = 0.9986388384754991, f1 = 0.9981859410430838\n",
      "Epoch 53: Train Loss = 0.018607230542070575, Recall = 0.9981867633726201, Aging Rate = 0.5, Precision = 0.9981867633726201, f1 = 0.9981867633726201\n",
      "Epoch 54: Train Loss = 0.018621076319741588, Recall = 0.9981867633726201, Aging Rate = 0.49977334542157753, Precision = 0.998639455782313, f1 = 0.9984130582634324\n",
      "Epoch 55: Train Loss = 0.018648090744467074, Recall = 0.9981867633726201, Aging Rate = 0.5, Precision = 0.9981867633726201, f1 = 0.9981867633726201\n",
      "Test Loss = 0.014449846070405038, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "Model in epoch 55 is saved.\n",
      "\n",
      "Epoch 56: Train Loss = 0.026061669878614347, Recall = 0.9959202175883953, Aging Rate = 0.5006799637352675, Precision = 0.9945676776822091, f1 = 0.9952434881087203\n",
      "Epoch 57: Train Loss = 0.02036738841341013, Recall = 0.9954669084315503, Aging Rate = 0.49932003626473254, Precision = 0.9968225147526101, f1 = 0.9961442503969153\n",
      "Epoch 58: Train Loss = 0.020405034669729816, Recall = 0.9972801450589301, Aging Rate = 0.499546690843155, Precision = 0.9981851179673321, f1 = 0.9977324263038548\n",
      "Epoch 59: Train Loss = 0.027309373904320183, Recall = 0.9945602901178604, Aging Rate = 0.5, Precision = 0.9945602901178604, f1 = 0.9945602901178604\n",
      "Epoch 60: Train Loss = 0.02479595258994094, Recall = 0.9954669084315503, Aging Rate = 0.499546690843155, Precision = 0.9963702359346642, f1 = 0.9959183673469388\n",
      "Test Loss = 0.015531651896921916, Recall = 0.9995466908431551, Aging Rate = 0.5, precision = 0.9995466908431551\n",
      "\n",
      "Epoch 61: Train Loss = 0.01447740509930461, Recall = 0.9981867633726201, Aging Rate = 0.499546690843155, Precision = 0.9990925589836661, f1 = 0.998639455782313\n",
      "Epoch 62: Train Loss = 0.01601228136687471, Recall = 0.9995466908431551, Aging Rate = 0.5, Precision = 0.9995466908431551, f1 = 0.9995466908431551\n",
      "Epoch 63: Train Loss = 0.01624399723091643, Recall = 0.99909338168631, Aging Rate = 0.49977334542157753, Precision = 0.999546485260771, f1 = 0.9993198821128995\n",
      "Epoch 64: Train Loss = 0.02554925569144845, Recall = 0.9959202175883953, Aging Rate = 0.49977334542157753, Precision = 0.9963718820861678, f1 = 0.9961459986397642\n",
      "Epoch 65: Train Loss = 0.034720991174956396, Recall = 0.9900271985494107, Aging Rate = 0.4984134179510426, Precision = 0.9931787175989086, f1 = 0.991600454029512\n",
      "Test Loss = 0.037435552346792855, Recall = 0.985494106980961, Aging Rate = 0.4956935630099728, precision = 0.994055784179241\n",
      "\n",
      "Epoch 66: Train Loss = 0.03465257783978502, Recall = 0.9918404351767905, Aging Rate = 0.5, Precision = 0.9918404351767905, f1 = 0.9918404351767905\n",
      "Epoch 67: Train Loss = 0.016048986492602533, Recall = 0.9986400725294651, Aging Rate = 0.499546690843155, Precision = 0.9995462794918331, f1 = 0.9990929705215419\n",
      "Epoch 68: Train Loss = 0.013766913310855168, Recall = 0.9995466908431551, Aging Rate = 0.5002266545784225, Precision = 0.9990937924784775, f1 = 0.9993201903467029\n",
      "Epoch 69: Train Loss = 0.017873277845484283, Recall = 0.9986400725294651, Aging Rate = 0.5002266545784225, Precision = 0.9981875849569551, f1 = 0.9984137774756402\n",
      "Epoch 70: Train Loss = 0.025150959363928298, Recall = 0.9977334542157752, Aging Rate = 0.5013599274705349, Precision = 0.9950271247739603, f1 = 0.9963784517881396\n",
      "Test Loss = 0.017477210676964585, Recall = 0.9968268359020852, Aging Rate = 0.4986400725294651, precision = 0.9995454545454545\n",
      "\n",
      "Epoch 71: Train Loss = 0.018377770795567083, Recall = 0.9963735267452403, Aging Rate = 0.4988667271078876, Precision = 0.9986369831894594, f1 = 0.9975039709552984\n",
      "Epoch 72: Train Loss = 0.02074546325725528, Recall = 0.9972801450589301, Aging Rate = 0.49977334542157753, Precision = 0.9977324263038548, f1 = 0.997506234413965\n",
      "Epoch 73: Train Loss = 0.01764137187258341, Recall = 0.9981867633726201, Aging Rate = 0.49977334542157753, Precision = 0.998639455782313, f1 = 0.9984130582634324\n",
      "Epoch 74: Train Loss = 0.01879780642613971, Recall = 0.9986400725294651, Aging Rate = 0.5004533091568449, Precision = 0.9977355072463768, f1 = 0.9981875849569551\n",
      "Epoch 75: Train Loss = 0.01800110037940962, Recall = 0.9981867633726201, Aging Rate = 0.499546690843155, Precision = 0.9990925589836661, f1 = 0.998639455782313\n",
      "Test Loss = 0.012254792219998884, Recall = 0.9995466908431551, Aging Rate = 0.49977334542157753, precision = 1.0\n",
      "\n",
      "Epoch 76: Train Loss = 0.020561715869987864, Recall = 0.9981867633726201, Aging Rate = 0.50090661831369, Precision = 0.9963800904977376, f1 = 0.9972826086956521\n",
      "Epoch 77: Train Loss = 0.021496294209850126, Recall = 0.9968268359020852, Aging Rate = 0.49932003626473254, Precision = 0.9981842941443486, f1 = 0.997505103198004\n",
      "Epoch 78: Train Loss = 0.019245441574924173, Recall = 0.9968268359020852, Aging Rate = 0.49932003626473254, Precision = 0.9981842941443486, f1 = 0.997505103198004\n",
      "Epoch 79: Train Loss = 0.018853499663019333, Recall = 0.9977334542157752, Aging Rate = 0.49932003626473254, Precision = 0.9990921470721743, f1 = 0.9984123383987299\n",
      "Epoch 80: Train Loss = 0.019479226270320733, Recall = 0.9977334542157752, Aging Rate = 0.5, Precision = 0.9977334542157752, f1 = 0.9977334542157752\n",
      "Test Loss = 0.015763998392999766, Recall = 0.9995466908431551, Aging Rate = 0.5002266545784225, precision = 0.9990937924784775\n",
      "\n",
      "Epoch 81: Train Loss = 0.018079747742249658, Recall = 0.9972801450589301, Aging Rate = 0.49932003626473254, Precision = 0.9986382206082615, f1 = 0.9979587207983669\n",
      "Epoch 82: Train Loss = 0.020803202882557704, Recall = 0.9977334542157752, Aging Rate = 0.5, Precision = 0.9977334542157752, f1 = 0.9977334542157752\n",
      "Epoch 83: Train Loss = 0.017703108591680245, Recall = 0.9972801450589301, Aging Rate = 0.49932003626473254, Precision = 0.9986382206082615, f1 = 0.9979587207983669\n",
      "Epoch 84: Train Loss = 0.015733653804454496, Recall = 0.9995466908431551, Aging Rate = 0.49977334542157753, Precision = 0, f1 = 0.0\n",
      "Epoch 85: Train Loss = 0.023397598060984452, Recall = 0.9968268359020852, Aging Rate = 0.50090661831369, Precision = 0.9950226244343892, f1 = 0.9959239130434782\n",
      "Test Loss = 0.023626168288040574, Recall = 0.9968268359020852, Aging Rate = 0.5004533091568449, precision = 0.9959239130434783\n",
      "\n",
      "Epoch 86: Train Loss = 0.024635972037188647, Recall = 0.9954669084315503, Aging Rate = 0.5004533091568449, Precision = 0.9945652173913043, f1 = 0.9950158586316266\n",
      "Epoch 87: Train Loss = 0.024232038776352258, Recall = 0.9950135992747053, Aging Rate = 0.49977334542157753, Precision = 0.9954648526077098, f1 = 0.9952391747902971\n",
      "Epoch 88: Train Loss = 0.025558966016928822, Recall = 0.9954669084315503, Aging Rate = 0.5004533091568449, Precision = 0.9945652173913043, f1 = 0.9950158586316266\n",
      "Epoch 89: Train Loss = 0.01951663756906878, Recall = 0.9972801450589301, Aging Rate = 0.5002266545784225, Precision = 0.9968282736746715, f1 = 0.997054158169046\n",
      "Epoch 90: Train Loss = 0.015881516328140593, Recall = 0.9986400725294651, Aging Rate = 0.49932003626473254, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.011812941284794513, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 91: Train Loss = 0.015978126848287078, Recall = 0.9995466908431551, Aging Rate = 0.5006799637352675, Precision = 0.9981892258940697, f1 = 0.9988674971687429\n",
      "Epoch 92: Train Loss = 0.019688010854090977, Recall = 0.9986400725294651, Aging Rate = 0.5006799637352675, Precision = 0.9972838388411046, f1 = 0.9979614949037373\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 93: Train Loss = 0.019294304823028373, Recall = 0.9968268359020852, Aging Rate = 0.49977334542157753, Precision = 0.9972789115646259, f1 = 0.9970528224892314\n",
      "Epoch 94: Train Loss = 0.015753116465409236, Recall = 0.9981867633726201, Aging Rate = 0.49909338168631007, Precision = 0, f1 = 0.0\n",
      "Epoch 95: Train Loss = 0.018781556479349152, Recall = 0.9981867633726201, Aging Rate = 0.5, Precision = 0.9981867633726201, f1 = 0.9981867633726201\n",
      "Test Loss = 0.02000362602681435, Recall = 1.0, Aging Rate = 0.5004533091568449, precision = 0.9990942028985508\n",
      "\n",
      "Epoch 96: Train Loss = 0.020932111684790224, Recall = 0.9977334542157752, Aging Rate = 0.5, Precision = 0.9977334542157752, f1 = 0.9977334542157752\n",
      "Epoch 97: Train Loss = 0.0169487547497531, Recall = 0.9981867633726201, Aging Rate = 0.5, Precision = 0.9981867633726201, f1 = 0.9981867633726201\n",
      "Epoch 98: Train Loss = 0.016912144436547406, Recall = 0.9995466908431551, Aging Rate = 0.5004533091568449, Precision = 0.998641304347826, f1 = 0.9990937924784776\n",
      "Epoch 99: Train Loss = 0.016786018648232964, Recall = 0.9977334542157752, Aging Rate = 0.49909338168631007, Precision = 0.9995458673932789, f1 = 0.9986388384754992\n",
      "Epoch 100: Train Loss = 0.025603591081967487, Recall = 0.9954669084315503, Aging Rate = 0.499546690843155, Precision = 0.9963702359346642, f1 = 0.9959183673469388\n",
      "Test Loss = 0.019697281526079094, Recall = 0.9968268359020852, Aging Rate = 0.4986400725294651, precision = 0.9995454545454545\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f77422d08e0245749b26535966b6849a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss = 0.3431051069787038, Recall = 0.9342999546896239, Aging Rate = 0.625736293611237, Precision = 0.7465604634322954, f1 = 0.8299456631112899\n",
      "Epoch 2: Train Loss = 0.13426438726123555, Recall = 0.9719075668328047, Aging Rate = 0.531717263253285, Precision = 0.9139326800170431, f1 = 0.9420289855072465\n",
      "Epoch 3: Train Loss = 0.08836183930174576, Recall = 0.980969642048029, Aging Rate = 0.5172179429089262, Precision = 0.9483136224266316, f1 = 0.9643652561247215\n",
      "Epoch 4: Train Loss = 0.057429720057274994, Recall = 0.987313094698686, Aging Rate = 0.5104213864975079, Precision = 0.9671549045716822, f1 = 0.9771300448430493\n",
      "Epoch 5: Train Loss = 0.046619633416926695, Recall = 0.991391028545537, Aging Rate = 0.5077027639329407, Precision = 0.9763498438197233, f1 = 0.9838129496402878\n",
      "Test Loss = 0.015224335989043434, Recall = 1.0, Aging Rate = 0.5018124150430449, precision = 0.9963882618510158\n",
      "Model in epoch 5 is saved.\n",
      "\n",
      "Epoch 6: Train Loss = 0.008568538208316975, Recall = 0.9995468962392388, Aging Rate = 0.5009062075215225, Precision = 0.9977385798281321, f1 = 0.9986419194205524\n",
      "Epoch 7: Train Loss = 0.0032964820630078705, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 8: Train Loss = 0.002269309930635028, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 9: Train Loss = 0.002056181660034041, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 10: Train Loss = 0.001878984416271659, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0018054551943049162, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "Model in epoch 10 is saved.\n",
      "\n",
      "Epoch 11: Train Loss = 0.0019002958554496013, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 12: Train Loss = 0.0020256782835497136, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 13: Train Loss = 0.0018818346451415996, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 14: Train Loss = 0.0019929804421427917, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 15: Train Loss = 0.002213327040896664, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0017037661056725057, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 16: Train Loss = 0.002521447602992411, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 17: Train Loss = 0.0023192055112486905, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 18: Train Loss = 0.10134769479883814, Recall = 0.9764386044404169, Aging Rate = 0.5158586316266425, Precision = 0.9464207290294246, f1 = 0.9611953612845674\n",
      "Epoch 19: Train Loss = 0.03299717061849514, Recall = 0.9927503398278206, Aging Rate = 0.5079293158133212, Precision = 0.9772524531668153, f1 = 0.9849404360530457\n",
      "Epoch 20: Train Loss = 0.006119811874179243, Recall = 0.9990937924784775, Aging Rate = 0.5009062075215225, Precision = 0.9972862957937585, f1 = 0.9981892258940697\n",
      "Test Loss = 0.0017461733337965218, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 21: Train Loss = 0.0016400991585806153, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 22: Train Loss = 0.0013181670181922477, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 23: Train Loss = 0.0012514527967705223, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 24: Train Loss = 0.0012825737639218923, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 25: Train Loss = 0.0013496709359975597, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0012083145041093838, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 26: Train Loss = 0.001439732350670662, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 27: Train Loss = 0.0015608712793026148, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 28: Train Loss = 0.0015342156458152336, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 29: Train Loss = 0.0015431866371530684, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 30: Train Loss = 0.025472135960973048, Recall = 0.9954689623923878, Aging Rate = 0.506343452650657, Precision = 0.9829977628635347, f1 = 0.9891940567312021\n",
      "Test Loss = 0.028899125801251657, Recall = 0.9950158586316267, Aging Rate = 0.5092886270956049, precision = 0.9768683274021353\n",
      "\n",
      "Epoch 31: Train Loss = 0.028947184892184778, Recall = 0.9950158586316267, Aging Rate = 0.5065700045310376, Precision = 0.9821109123434705, f1 = 0.988521269412559\n",
      "Epoch 32: Train Loss = 0.01683642922888063, Recall = 0.9972813774354327, Aging Rate = 0.5029451744449479, Precision = 0.9914414414414414, f1 = 0.9943528348768919\n",
      "Epoch 33: Train Loss = 0.002545391051099759, Recall = 0.9995468962392388, Aging Rate = 0.5, Precision = 0.9995468962392388, f1 = 0.9995468962392388\n",
      "Epoch 34: Train Loss = 0.0007166420993102714, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 35: Train Loss = 0.000703996549553829, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0006866566335462121, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 36: Train Loss = 0.0008365154175313993, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 37: Train Loss = 0.0009405060786683, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 38: Train Loss = 0.0010688205337538847, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 39: Train Loss = 0.001241276806023556, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 40: Train Loss = 0.0012842974515600567, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0013049392676969217, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 41: Train Loss = 0.0013875641613628159, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 42: Train Loss = 0.0020443501358043265, Recall = 1.0, Aging Rate = 0.5002265518803806, Precision = 0.9995471014492754, f1 = 0.9997734994337486\n",
      "Epoch 43: Train Loss = 0.022775599183569573, Recall = 0.995922066153149, Aging Rate = 0.5054372451291346, Precision = 0.9852084267144778, f1 = 0.9905362776025235\n",
      "Epoch 44: Train Loss = 0.06692612936760763, Recall = 0.983235160851835, Aging Rate = 0.5111010421386497, Precision = 0.9618794326241135, f1 = 0.9724400627380685\n",
      "Epoch 45: Train Loss = 0.00879969438456723, Recall = 0.9977344811961939, Aging Rate = 0.501132759401903, Precision = 0.9954792043399638, f1 = 0.9966055668703326\n",
      "Test Loss = 0.0016837513453433037, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 46: Train Loss = 0.001108202214961923, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 47: Train Loss = 0.0008234096304684419, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 48: Train Loss = 0.000839711191657193, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 49: Train Loss = 0.0009444228537620383, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 50: Train Loss = 0.0010250649624314256, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0010712465735432562, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 51: Train Loss = 0.0011011364784426767, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 52: Train Loss = 0.0012763791440027767, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 53: Train Loss = 0.0013483543768985089, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 54: Train Loss = 0.0014315420756640617, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 55: Train Loss = 0.001502760620308786, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0012334832633566154, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 56: Train Loss = 0.015310227374474914, Recall = 0.995922066153149, Aging Rate = 0.5020389669234254, Precision = 0.9918772563176895, f1 = 0.9938955460094958\n",
      "Epoch 57: Train Loss = 0.04688979711237574, Recall = 0.987313094698686, Aging Rate = 0.5072496601721794, Precision = 0.9732023224653863, f1 = 0.9802069275753487\n",
      "Epoch 58: Train Loss = 0.012072897993720643, Recall = 0.9977344811961939, Aging Rate = 0.5022655188038061, Precision = 0.993234100135318, f1 = 0.9954792043399638\n",
      "Epoch 59: Train Loss = 0.0014457295045946983, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 60: Train Loss = 0.0009077771481461604, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.00083080284779796, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Training Finished at epoch 60.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d4e6aa931bf43dcac6b40532b5aeaa1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss = 0.3432502800080307, Recall = 0.9247506799637353, Aging Rate = 0.6262466001813236, Precision = 0.738327904451683, f1 = 0.8210907627289192\n",
      "Epoch 2: Train Loss = 0.13778714107472792, Recall = 0.9678150498640072, Aging Rate = 0.5303717135086129, Precision = 0.9123931623931624, f1 = 0.9392872855257368\n",
      "Epoch 3: Train Loss = 0.09292668602002932, Recall = 0.9786944696282865, Aging Rate = 0.5185856754306437, Precision = 0.9436188811188811, f1 = 0.9608366711170451\n",
      "Epoch 4: Train Loss = 0.06519204393664167, Recall = 0.9832275611967362, Aging Rate = 0.5086128739800544, Precision = 0.9665775401069518, f1 = 0.9748314606741573\n",
      "Epoch 5: Train Loss = 0.048815300161270586, Recall = 0.9909338168631007, Aging Rate = 0.5095194922937444, Precision = 0.9724199288256228, f1 = 0.9815895823978447\n",
      "Test Loss = 0.020249247501147462, Recall = 0.9963735267452403, Aging Rate = 0.5022665457842248, precision = 0.9918772563176895\n",
      "Model in epoch 5 is saved.\n",
      "\n",
      "Epoch 6: Train Loss = 0.01608942432501307, Recall = 0.9972801450589301, Aging Rate = 0.5020398912058024, Precision = 0.9932279909706546, f1 = 0.9952499434517078\n",
      "Epoch 7: Train Loss = 0.008346922135829979, Recall = 0.9986400725294651, Aging Rate = 0.5004533091568449, Precision = 0.9977355072463768, f1 = 0.9981875849569551\n",
      "Epoch 8: Train Loss = 0.004276949728240453, Recall = 0.9995466908431551, Aging Rate = 0.5, Precision = 0.9995466908431551, f1 = 0.9995466908431551\n",
      "Epoch 9: Train Loss = 0.0022644095531481564, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 10: Train Loss = 0.0018907650070964061, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0016732248644397703, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "Model in epoch 10 is saved.\n",
      "\n",
      "Epoch 11: Train Loss = 0.001950403425719248, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 12: Train Loss = 0.0019869028183429798, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 13: Train Loss = 0.001916590165085111, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 14: Train Loss = 0.002009106435621341, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 15: Train Loss = 0.0025697716415529616, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.00281736250343654, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 16: Train Loss = 0.0057070840927768, Recall = 0.9995466908431551, Aging Rate = 0.5006799637352675, Precision = 0.9981892258940697, f1 = 0.9988674971687429\n",
      "Epoch 17: Train Loss = 0.06902471674202602, Recall = 0.9832275611967362, Aging Rate = 0.5129193109700816, Precision = 0.9584622182942996, f1 = 0.9706869545759677\n",
      "Epoch 18: Train Loss = 0.018479952850954898, Recall = 0.9968268359020852, Aging Rate = 0.5038531278331823, Precision = 0.9892037786774629, f1 = 0.9930006773538045\n",
      "Epoch 19: Train Loss = 0.0031344268688634847, Recall = 1.0, Aging Rate = 0.5006799637352675, Precision = 0.9986419194205522, f1 = 0.9993204983012457\n",
      "Epoch 20: Train Loss = 0.0011394130745108965, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0008017859068730422, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 21: Train Loss = 0.000913238901117646, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 22: Train Loss = 0.0010448445901418222, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 23: Train Loss = 0.0011241204003572924, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 24: Train Loss = 0.0011393070350872252, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 25: Train Loss = 0.0014654686814321819, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0011614730657844156, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 26: Train Loss = 0.01086329638933491, Recall = 0.9977334542157752, Aging Rate = 0.5015865820489573, Precision = 0.9945774966109354, f1 = 0.9961529757863771\n",
      "Epoch 27: Train Loss = 0.020843142604308435, Recall = 0.9972801450589301, Aging Rate = 0.5047597461468721, Precision = 0.9878760664571172, f1 = 0.9925558312655087\n",
      "Epoch 28: Train Loss = 0.028030195530353692, Recall = 0.9945602901178604, Aging Rate = 0.5047597461468721, Precision = 0.9851818590031433, f1 = 0.9898488608166027\n",
      "Epoch 29: Train Loss = 0.011006382490522612, Recall = 0.9977334542157752, Aging Rate = 0.5029465095194923, Precision = 0.9918882379450202, f1 = 0.9948022598870057\n",
      "Epoch 30: Train Loss = 0.005720425654237107, Recall = 0.99909338168631, Aging Rate = 0.50090661831369, Precision = 0.9972850678733032, f1 = 0.9981884057971016\n",
      "Test Loss = 0.0015581762082784007, Recall = 1.0, Aging Rate = 0.5004533091568449, precision = 0.9990942028985508\n",
      "\n",
      "Epoch 31: Train Loss = 0.0035340788606165866, Recall = 0.99909338168631, Aging Rate = 0.5004533091568449, Precision = 0.9981884057971014, f1 = 0.9986406887177163\n",
      "Epoch 32: Train Loss = 0.0014936070404153112, Recall = 1.0, Aging Rate = 0.5002266545784225, Precision = 0.9995468962392388, f1 = 0.9997733967822342\n",
      "Epoch 33: Train Loss = 0.0006300664964334233, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 34: Train Loss = 0.0006723801110611919, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 35: Train Loss = 0.0008040445249131691, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0007498134510188025, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 36: Train Loss = 0.0009607565552308642, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 37: Train Loss = 0.004538523345777861, Recall = 0.9995466908431551, Aging Rate = 0.5004533091568449, Precision = 0.998641304347826, f1 = 0.9990937924784776\n",
      "Epoch 38: Train Loss = 0.00397196581200059, Recall = 1.0, Aging Rate = 0.5002266545784225, Precision = 0.9995468962392388, f1 = 0.9997733967822342\n",
      "Epoch 39: Train Loss = 0.011505566070663489, Recall = 0.9986400725294651, Aging Rate = 0.5027198549410699, Precision = 0.9932371505861136, f1 = 0.9959312839059675\n",
      "Epoch 40: Train Loss = 0.05792294247375661, Recall = 0.985040797824116, Aging Rate = 0.5088395285584769, Precision = 0.9679287305122495, f1 = 0.9764097955515615\n",
      "Test Loss = 0.022222816830767777, Recall = 0.9904805077062556, Aging Rate = 0.4959202175883953, precision = 0.9986288848263254\n",
      "\n",
      "Epoch 41: Train Loss = 0.0123769238757743, Recall = 0.9972801450589301, Aging Rate = 0.5029465095194923, Precision = 0.9914375844975214, f1 = 0.9943502824858758\n",
      "Epoch 42: Train Loss = 0.006916312107418225, Recall = 0.9981867633726201, Aging Rate = 0.5002266545784225, Precision = 0.9977344811961939, f1 = 0.9979605710401087\n",
      "Epoch 43: Train Loss = 0.003260671115889453, Recall = 0.9995466908431551, Aging Rate = 0.5002266545784225, Precision = 0.9990937924784775, f1 = 0.9993201903467029\n",
      "Epoch 44: Train Loss = 0.0006899400752465007, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 45: Train Loss = 0.0006416972719142611, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0006168933752784885, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 46: Train Loss = 0.0007188389941556877, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 47: Train Loss = 0.0008549009607990838, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 48: Train Loss = 0.0009725191327511034, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 49: Train Loss = 0.0010885954885709785, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 50: Train Loss = 0.0011415352602848143, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0010569382208574256, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 51: Train Loss = 0.00133209928920018, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 52: Train Loss = 0.001768342419088407, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 53: Train Loss = 0.014416304487035908, Recall = 0.9986400725294651, Aging Rate = 0.5029465095194923, Precision = 0.992789544840018, f1 = 0.9957062146892655\n",
      "Epoch 54: Train Loss = 0.04923114377024971, Recall = 0.9900271985494107, Aging Rate = 0.507479601087942, Precision = 0.9754354622599375, f1 = 0.9826771653543308\n",
      "Epoch 55: Train Loss = 0.0054194131523711865, Recall = 0.99909338168631, Aging Rate = 0.5006799637352675, Precision = 0.9977365323675872, f1 = 0.9984144960362401\n",
      "Test Loss = 0.01643549640595842, Recall = 1.0, Aging Rate = 0.5077062556663645, precision = 0.9848214285714286\n",
      "\n",
      "Epoch 56: Train Loss = 0.0039017894134307086, Recall = 0.9995466908431551, Aging Rate = 0.5004533091568449, Precision = 0.998641304347826, f1 = 0.9990937924784776\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57: Train Loss = 0.0026615293048903115, Recall = 0.9995466908431551, Aging Rate = 0.5002266545784225, Precision = 0.9990937924784775, f1 = 0.9993201903467029\n",
      "Epoch 58: Train Loss = 0.0018383034487324155, Recall = 1.0, Aging Rate = 0.5002266545784225, Precision = 0.9995468962392388, f1 = 0.9997733967822342\n",
      "Epoch 59: Train Loss = 0.0007400747491784014, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 60: Train Loss = 0.0008451902529318477, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0007912025142905192, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Training Finished at epoch 60.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f732e3f0f5a4330a045936b40f25a5d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss = 0.33677996663983506, Recall = 0.9361123697326688, Aging Rate = 0.6291345718169461, Precision = 0.7439683111271156, f1 = 0.8290529695024077\n",
      "Epoch 2: Train Loss = 0.14080588098262628, Recall = 0.9669234254644313, Aging Rate = 0.5244676030811056, Precision = 0.9218142548596112, f1 = 0.9438301636444051\n",
      "Epoch 3: Train Loss = 0.08517776102192218, Recall = 0.9805165382872678, Aging Rate = 0.5165382872677843, Precision = 0.9491228070175438, f1 = 0.9645642968575885\n",
      "Epoch 4: Train Loss = 0.06237291360352447, Recall = 0.9845944721341187, Aging Rate = 0.5090620752152243, Precision = 0.9670672007120605, f1 = 0.9757521329142343\n",
      "Epoch 5: Train Loss = 0.05877482194890655, Recall = 0.9845944721341187, Aging Rate = 0.5070231082917989, Precision = 0.9709562109025917, f1 = 0.9777277840269967\n",
      "Test Loss = 0.02013492049910145, Recall = 1.0, Aging Rate = 0.5070231082917989, precision = 0.9861483467381591\n",
      "Model in epoch 5 is saved.\n",
      "\n",
      "Epoch 6: Train Loss = 0.012790069996375518, Recall = 0.9972813774354327, Aging Rate = 0.5006796556411418, Precision = 0.9959276018099548, f1 = 0.9966040298845369\n",
      "Epoch 7: Train Loss = 0.004537945688905985, Recall = 1.0, Aging Rate = 0.5006796556411418, Precision = 0.9986425339366516, f1 = 0.9993208059769074\n",
      "Epoch 8: Train Loss = 0.002817825473582108, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 9: Train Loss = 0.002344778546648658, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 10: Train Loss = 0.0021918358521364665, Recall = 1.0, Aging Rate = 0.5002265518803806, Precision = 0.9995471014492754, f1 = 0.9997734994337486\n",
      "Test Loss = 0.0028100732919022838, Recall = 0.9995468962392388, Aging Rate = 0.4997734481196194, precision = 1.0\n",
      "Model in epoch 10 is saved.\n",
      "\n",
      "Epoch 11: Train Loss = 0.005007211547674072, Recall = 0.9990937924784775, Aging Rate = 0.5002265518803806, Precision = 0.998641304347826, f1 = 0.9988674971687429\n",
      "Epoch 12: Train Loss = 0.01576386298931541, Recall = 0.9963751699139103, Aging Rate = 0.5027186225645673, Precision = 0.9909869310500226, f1 = 0.9936737460460913\n",
      "Epoch 13: Train Loss = 0.00829782001516458, Recall = 0.9986406887177164, Aging Rate = 0.501132759401903, Precision = 0.9963833634719711, f1 = 0.9975107490382439\n",
      "Epoch 14: Train Loss = 0.0032004415693532087, Recall = 1.0, Aging Rate = 0.5004531037607612, Precision = 0.9990946129470348, f1 = 0.9995471014492754\n",
      "Epoch 15: Train Loss = 0.002191678041066446, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0010361413809622324, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "Model in epoch 15 is saved.\n",
      "\n",
      "Epoch 16: Train Loss = 0.0010541552956010636, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 17: Train Loss = 0.001041743554525992, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 18: Train Loss = 0.001257392983091552, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 19: Train Loss = 0.0014573882943070752, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 20: Train Loss = 0.0016630282563313092, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.002022703914170115, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 21: Train Loss = 0.014786140681390019, Recall = 0.9977344811961939, Aging Rate = 0.5015858631626643, Precision = 0.994579945799458, f1 = 0.9961547161275729\n",
      "Epoch 22: Train Loss = 0.08854886841309127, Recall = 0.978704123244223, Aging Rate = 0.5183507023108291, Precision = 0.9440559440559441, f1 = 0.9610678531701892\n",
      "Epoch 23: Train Loss = 0.010051894446963205, Recall = 0.9986406887177164, Aging Rate = 0.5020389669234254, Precision = 0.9945848375451264, f1 = 0.9966086366719421\n",
      "Epoch 24: Train Loss = 0.0018571147921051633, Recall = 1.0, Aging Rate = 0.5002265518803806, Precision = 0.9995471014492754, f1 = 0.9997734994337486\n",
      "Epoch 25: Train Loss = 0.001818101030985302, Recall = 1.0, Aging Rate = 0.5002265518803806, Precision = 0.9995471014492754, f1 = 0.9997734994337486\n",
      "Test Loss = 0.0016303311834659547, Recall = 0.9995468962392388, Aging Rate = 0.4997734481196194, precision = 1.0\n",
      "\n",
      "Epoch 26: Train Loss = 0.002591281248260573, Recall = 0.9995468962392388, Aging Rate = 0.5002265518803806, Precision = 0.9990942028985508, f1 = 0.9993204983012457\n",
      "Epoch 27: Train Loss = 0.0010873516392514303, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 28: Train Loss = 0.0010956543256338993, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 29: Train Loss = 0.001223918713177088, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 30: Train Loss = 0.0013486758606845119, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0012796951584348318, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 31: Train Loss = 0.01242794370992716, Recall = 0.9977344811961939, Aging Rate = 0.5018124150430449, Precision = 0.9941309255079007, f1 = 0.9959294436906377\n",
      "Epoch 32: Train Loss = 0.028268439016369475, Recall = 0.9932034435885818, Aging Rate = 0.5056637970095151, Precision = 0.982078853046595, f1 = 0.9876098220319892\n",
      "Epoch 33: Train Loss = 0.00932426028183396, Recall = 0.9986406887177164, Aging Rate = 0.5022655188038061, Precision = 0.9941362201172756, f1 = 0.9963833634719711\n",
      "Epoch 34: Train Loss = 0.00404082374458632, Recall = 0.9995468962392388, Aging Rate = 0.501132759401903, Precision = 0.9972875226039783, f1 = 0.9984159312061552\n",
      "Epoch 35: Train Loss = 0.0008894046559663152, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0007070035863149529, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 36: Train Loss = 0.0007890344897642104, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 37: Train Loss = 0.0008943962028412984, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 38: Train Loss = 0.0011028716999670937, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 39: Train Loss = 0.0012243793726935443, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 40: Train Loss = 0.001282306455485489, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0012168298220617665, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 41: Train Loss = 0.0017188445270491075, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 42: Train Loss = 0.040695311799544144, Recall = 0.991391028545537, Aging Rate = 0.5072496601721794, Precision = 0.9772219740955784, f1 = 0.9842555105713001\n",
      "Epoch 43: Train Loss = 0.05243478727889449, Recall = 0.9877661984594472, Aging Rate = 0.508608971454463, Precision = 0.9710467706013363, f1 = 0.9793351302785265\n",
      "Epoch 44: Train Loss = 0.006624720290003198, Recall = 0.9981875849569551, Aging Rate = 0.501132759401903, Precision = 0.9959312839059674, f1 = 0.9970581579542883\n",
      "Epoch 45: Train Loss = 0.0011819871614075687, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0007705053758548381, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 46: Train Loss = 0.0008261506190140764, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 47: Train Loss = 0.0008327619429622022, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 48: Train Loss = 0.0008923665117010336, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 49: Train Loss = 0.001004772465448197, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 50: Train Loss = 0.001083172660298421, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0010300002636419172, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 51: Train Loss = 0.0012151744789209709, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 52: Train Loss = 0.001392996890605843, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 53: Train Loss = 0.0017789312075307878, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 54: Train Loss = 0.006647051044068404, Recall = 0.9995468962392388, Aging Rate = 0.5009062075215225, Precision = 0.9977385798281321, f1 = 0.9986419194205524\n",
      "Epoch 55: Train Loss = 0.0305622785900119, Recall = 0.9941096511101042, Aging Rate = 0.5081558676937019, Precision = 0.9781542576905929, f1 = 0.9860674157303371\n",
      "Test Loss = 0.03786693771944078, Recall = 1.0, Aging Rate = 0.521295876755777, precision = 0.959148196436332\n",
      "\n",
      "Epoch 56: Train Loss = 0.023851474958898583, Recall = 0.9954689623923878, Aging Rate = 0.5045310376076122, Precision = 0.9865289627301302, f1 = 0.9909788001804241\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57: Train Loss = 0.0035286662208361998, Recall = 0.9990937924784775, Aging Rate = 0.5, Precision = 0.9990937924784775, f1 = 0.9990937924784775\n",
      "Epoch 58: Train Loss = 0.001449151408335757, Recall = 1.0, Aging Rate = 0.5002265518803806, Precision = 0.9995471014492754, f1 = 0.9997734994337486\n",
      "Epoch 59: Train Loss = 0.0007704091387975786, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 60: Train Loss = 0.0007941904694702153, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0007508802856962181, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 61: Train Loss = 0.0008949766373719664, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 62: Train Loss = 0.0010390730800120204, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 63: Train Loss = 0.0011826329142965906, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 64: Train Loss = 0.0013356004741087583, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 65: Train Loss = 0.00172628809313497, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.004868190946043936, Recall = 1.0, Aging Rate = 0.5013593112822836, precision = 0.9972887483054677\n",
      "\n",
      "Training Finished at epoch 65.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e08c04bc8e34301b692a712986708f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss = 0.3309131166606412, Recall = 0.9310970081595649, Aging Rate = 0.6199002719854941, Precision = 0.7510054844606947, f1 = 0.8314106456182958\n",
      "Epoch 2: Train Loss = 0.12782228459770423, Recall = 0.9750679963735267, Aging Rate = 0.5262919310970081, Precision = 0.9263565891472868, f1 = 0.9500883392226147\n",
      "Epoch 3: Train Loss = 0.07829894581919405, Recall = 0.9832275611967362, Aging Rate = 0.514505893019039, Precision = 0.9555066079295155, f1 = 0.9691689008042895\n",
      "Epoch 4: Train Loss = 0.05768066922292208, Recall = 0.9891205802357208, Aging Rate = 0.5113327289211242, Precision = 0.9671985815602837, f1 = 0.9780367548184671\n",
      "Epoch 5: Train Loss = 0.05329601199502093, Recall = 0.985947416137806, Aging Rate = 0.5067996373526745, Precision = 0.9727191413237924, f1 = 0.9792886087348042\n",
      "Test Loss = 0.02256450920044052, Recall = 0.9995466908431551, Aging Rate = 0.5045330915684497, precision = 0.9905660377358491\n",
      "Model in epoch 5 is saved.\n",
      "\n",
      "Epoch 6: Train Loss = 0.01163925089538165, Recall = 0.9986400725294651, Aging Rate = 0.5006799637352675, Precision = 0.9972838388411046, f1 = 0.9979614949037373\n",
      "Epoch 7: Train Loss = 0.0037433150429565694, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 8: Train Loss = 0.002687496860559729, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 9: Train Loss = 0.0018734821488452587, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 10: Train Loss = 0.00436924842328968, Recall = 0.9995466908431551, Aging Rate = 0.5006799637352675, Precision = 0.9981892258940697, f1 = 0.9988674971687429\n",
      "Test Loss = 0.007325193034155684, Recall = 1.0, Aging Rate = 0.5018132366273799, precision = 0.996386630532972\n",
      "Model in epoch 10 is saved.\n",
      "\n",
      "Epoch 11: Train Loss = 0.002842107287131871, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 12: Train Loss = 0.0017825956968252875, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 13: Train Loss = 0.0016596756243515939, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 14: Train Loss = 0.0019323727202957203, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 15: Train Loss = 0.0022455562190646654, Recall = 1.0, Aging Rate = 0.5002266545784225, Precision = 0.9995468962392388, f1 = 0.9997733967822342\n",
      "Test Loss = 0.006576989782557857, Recall = 0.9995466908431551, Aging Rate = 0.5002266545784225, precision = 0.9990937924784775\n",
      "Model in epoch 15 is saved.\n",
      "\n",
      "Epoch 16: Train Loss = 0.057580200682545345, Recall = 0.9877606527651859, Aging Rate = 0.5090661831368993, Precision = 0.9701691896705253, f1 = 0.9788858939802335\n",
      "Epoch 17: Train Loss = 0.041039937604320044, Recall = 0.9922937443336355, Aging Rate = 0.5067996373526745, Precision = 0.9789803220035778, f1 = 0.9855920756416029\n",
      "Epoch 18: Train Loss = 0.008115058339366408, Recall = 0.9981867633726201, Aging Rate = 0.5024932003626473, Precision = 0.993234100135318, f1 = 0.9957042731177933\n",
      "Epoch 19: Train Loss = 0.0013373312441140738, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 20: Train Loss = 0.000845582652727272, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0007215597147416706, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "Model in epoch 20 is saved.\n",
      "\n",
      "Epoch 21: Train Loss = 0.0008498691775190542, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 22: Train Loss = 0.0009888222890484704, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 23: Train Loss = 0.0010773481906485402, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 24: Train Loss = 0.0017044121964816898, Recall = 0.9995466908431551, Aging Rate = 0.49977334542157753, Precision = 0, f1 = 0.0\n",
      "Epoch 25: Train Loss = 0.0029088774514878517, Recall = 1.0, Aging Rate = 0.5002266545784225, Precision = 0.9995468962392388, f1 = 0.9997733967822342\n",
      "Test Loss = 0.001307090912508193, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 26: Train Loss = 0.0015434510569980644, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 27: Train Loss = 0.0016170406941213018, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 28: Train Loss = 0.03726459296626239, Recall = 0.9913871260199456, Aging Rate = 0.507479601087942, Precision = 0.9767753461366682, f1 = 0.9840269966254219\n",
      "Epoch 29: Train Loss = 0.04665347294846477, Recall = 0.9891205802357208, Aging Rate = 0.5058930190389845, Precision = 0.9775985663082437, f1 = 0.9833258224425417\n",
      "Epoch 30: Train Loss = 0.0075981884310106435, Recall = 0.9981867633726201, Aging Rate = 0.5011332728921124, Precision = 0.9959294436906377, f1 = 0.9970568258999322\n",
      "Test Loss = 0.0021629685567479146, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 31: Train Loss = 0.0011793221629892601, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 32: Train Loss = 0.0008443150524635135, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 33: Train Loss = 0.0008544895067812701, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 34: Train Loss = 0.0009739844867088245, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 35: Train Loss = 0.0010966849981968443, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0010439987686578377, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 36: Train Loss = 0.0014491423220202287, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 37: Train Loss = 0.001370251281541567, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 38: Train Loss = 0.0014931464542238782, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 39: Train Loss = 0.027583730897628927, Recall = 0.9945602901178604, Aging Rate = 0.5056663644605621, Precision = 0.9834155087404751, f1 = 0.9889565021410863\n",
      "Epoch 40: Train Loss = 0.04046445288022023, Recall = 0.9877606527651859, Aging Rate = 0.5063463281958296, Precision = 0.9753804834377797, f1 = 0.9815315315315315\n",
      "Test Loss = 0.02895658968712253, Recall = 0.9927470534904805, Aging Rate = 0.49750679963735267, precision = 0.9977220956719818\n",
      "\n",
      "Epoch 41: Train Loss = 0.011181934069734866, Recall = 0.9972801450589301, Aging Rate = 0.5022665457842248, Precision = 0.9927797833935018, f1 = 0.9950248756218906\n",
      "Epoch 42: Train Loss = 0.001678643599584241, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 43: Train Loss = 0.000891491261546028, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 44: Train Loss = 0.0008673243481251694, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 45: Train Loss = 0.0009422536477837492, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0009677128797500029, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 46: Train Loss = 0.0011385927260291855, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 47: Train Loss = 0.0011851047496573117, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 48: Train Loss = 0.0012946633890343802, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 49: Train Loss = 0.0013685922539672212, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 50: Train Loss = 0.001462125319671747, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0012830872269045876, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 51: Train Loss = 0.0016193025826087267, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 52: Train Loss = 0.019630866071609535, Recall = 0.9954669084315503, Aging Rate = 0.5045330915684497, Precision = 0.9865229110512129, f1 = 0.9909747292418772\n",
      "Epoch 53: Train Loss = 0.07597679203025345, Recall = 0.9818676337262012, Aging Rate = 0.5129193109700816, Precision = 0.9571365444100751, f1 = 0.969344372342806\n",
      "Epoch 54: Train Loss = 0.008192608761843901, Recall = 0.9986400725294651, Aging Rate = 0.5015865820489573, Precision = 0.9954812471757795, f1 = 0.9970581579542883\n",
      "Epoch 55: Train Loss = 0.0017437940809186734, Recall = 1.0, Aging Rate = 0.5002266545784225, Precision = 0.9995468962392388, f1 = 0.9997733967822342\n",
      "Test Loss = 0.0014074357820282996, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 56: Train Loss = 0.0010741290508440998, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57: Train Loss = 0.000959925455482827, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 58: Train Loss = 0.0010360913556831165, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 59: Train Loss = 0.001137450423692408, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 60: Train Loss = 0.001208394296393001, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0010935502189717316, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 61: Train Loss = 0.0014256656221396957, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 62: Train Loss = 0.0017343009484328958, Recall = 1.0, Aging Rate = 0.5002266545784225, Precision = 0.9995468962392388, f1 = 0.9997733967822342\n",
      "Epoch 63: Train Loss = 0.0019421136588895066, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 64: Train Loss = 0.0013632396485040966, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 65: Train Loss = 0.003940725380534531, Recall = 0.9995466908431551, Aging Rate = 0.5004533091568449, Precision = 0.998641304347826, f1 = 0.9990937924784776\n",
      "Test Loss = 0.008884406223655057, Recall = 1.0, Aging Rate = 0.5006799637352675, precision = 0.9986419194205522\n",
      "\n",
      "Epoch 66: Train Loss = 0.006320786865150298, Recall = 1.0, Aging Rate = 0.5015865820489573, Precision = 0.9968368730230457, f1 = 0.9984159312061552\n",
      "Epoch 67: Train Loss = 0.0038480630943658048, Recall = 1.0, Aging Rate = 0.5006799637352675, Precision = 0.9986419194205522, f1 = 0.9993204983012457\n",
      "Epoch 68: Train Loss = 0.00594947870642602, Recall = 1.0, Aging Rate = 0.5015865820489573, Precision = 0.9968368730230457, f1 = 0.9984159312061552\n",
      "Epoch 69: Train Loss = 0.0019694540348006977, Recall = 1.0, Aging Rate = 0.5002266545784225, Precision = 0.9995468962392388, f1 = 0.9997733967822342\n",
      "Epoch 70: Train Loss = 0.005211858291086907, Recall = 0.9995466908431551, Aging Rate = 0.5006799637352675, Precision = 0.9981892258940697, f1 = 0.9988674971687429\n",
      "Test Loss = 0.039397997051268036, Recall = 0.9832275611967362, Aging Rate = 0.49229374433363554, precision = 0.9986187845303868\n",
      "\n",
      "Training Finished at epoch 70.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "36c3e59cfefc4a1db9a8d6bea3a092c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss = 0.3252042783111847, Recall = 0.9351767905711695, Aging Rate = 0.6176337262012692, Precision = 0.7570642201834863, f1 = 0.8367471101196512\n",
      "Epoch 2: Train Loss = 0.1473139028384917, Recall = 0.9650951949229375, Aging Rate = 0.5353581142339076, Precision = 0.901354784081287, f1 = 0.9321366024518388\n",
      "Epoch 3: Train Loss = 0.09820148164401353, Recall = 0.9773345421577516, Aging Rate = 0.5197189483227561, Precision = 0.9402529437418229, f1 = 0.958435207823961\n",
      "Epoch 4: Train Loss = 0.0627420440532355, Recall = 0.9836808703535811, Aging Rate = 0.5077062556663645, Precision = 0.96875, f1 = 0.9761583445793972\n",
      "Epoch 5: Train Loss = 0.050816615641535896, Recall = 0.9877606527651859, Aging Rate = 0.5088395285584769, Precision = 0.9706013363028954, f1 = 0.9791058189170972\n",
      "Test Loss = 0.0157981432369781, Recall = 0.9995466908431551, Aging Rate = 0.5031731640979148, precision = 0.9932432432432432\n",
      "Model in epoch 5 is saved.\n",
      "\n",
      "Epoch 6: Train Loss = 0.011293179834732686, Recall = 0.9981867633726201, Aging Rate = 0.5002266545784225, Precision = 0.9977344811961939, f1 = 0.9979605710401087\n",
      "Epoch 7: Train Loss = 0.004484611670617504, Recall = 1.0, Aging Rate = 0.5006799637352675, Precision = 0.9986419194205522, f1 = 0.9993204983012457\n",
      "Epoch 8: Train Loss = 0.0031608080418386976, Recall = 0.9995466908431551, Aging Rate = 0.5, Precision = 0.9995466908431551, f1 = 0.9995466908431551\n",
      "Epoch 9: Train Loss = 0.00290121708267072, Recall = 1.0, Aging Rate = 0.5002266545784225, Precision = 0.9995468962392388, f1 = 0.9997733967822342\n",
      "Epoch 10: Train Loss = 0.0022156990911298222, Recall = 1.0, Aging Rate = 0.5002266545784225, Precision = 0.9995468962392388, f1 = 0.9997733967822342\n",
      "Test Loss = 0.0016763267596611113, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "Model in epoch 10 is saved.\n",
      "\n",
      "Epoch 11: Train Loss = 0.0019290493843453858, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 12: Train Loss = 0.0017708267810554366, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 13: Train Loss = 0.0027347256903176077, Recall = 1.0, Aging Rate = 0.5002266545784225, Precision = 0.9995468962392388, f1 = 0.9997733967822342\n",
      "Epoch 14: Train Loss = 0.0019262547517982281, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 15: Train Loss = 0.0021041759339618014, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0019924830160241366, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 16: Train Loss = 0.0018684334696438551, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 17: Train Loss = 0.0019455169870476775, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 18: Train Loss = 0.08995080741792782, Recall = 0.9768812330009066, Aging Rate = 0.5165457842248413, Precision = 0.9455901711276876, f1 = 0.9609810479375697\n",
      "Epoch 19: Train Loss = 0.026582013130870226, Recall = 0.9945602901178604, Aging Rate = 0.5052130553037172, Precision = 0.984297891431135, f1 = 0.989402480270575\n",
      "Epoch 20: Train Loss = 0.006451443974110226, Recall = 0.9995466908431551, Aging Rate = 0.5015865820489573, Precision = 0.9963849977406236, f1 = 0.9979633401221997\n",
      "Test Loss = 0.0028477431009401137, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 21: Train Loss = 0.0020792797464938163, Recall = 1.0, Aging Rate = 0.5002266545784225, Precision = 0.9995468962392388, f1 = 0.9997733967822342\n",
      "Epoch 22: Train Loss = 0.004475278425235588, Recall = 0.9995466908431551, Aging Rate = 0.50090661831369, Precision = 0.997737556561086, f1 = 0.998641304347826\n",
      "Epoch 23: Train Loss = 0.0012668948989962704, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 24: Train Loss = 0.0011144138717262288, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 25: Train Loss = 0.0013167411465736499, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.00118788557627609, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 26: Train Loss = 0.0014463200474306537, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 27: Train Loss = 0.001475176855551074, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 28: Train Loss = 0.0015772783228281484, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 29: Train Loss = 0.001771438056273776, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 30: Train Loss = 0.0028907917389276346, Recall = 0.9995466908431551, Aging Rate = 0.5, Precision = 0.9995466908431551, f1 = 0.9995466908431551\n",
      "Test Loss = 0.016316350636850108, Recall = 1.0, Aging Rate = 0.5090661831368993, precision = 0.9821905609973286\n",
      "\n",
      "Epoch 31: Train Loss = 0.05124709966988493, Recall = 0.9895738893925657, Aging Rate = 0.5122393472348141, Precision = 0.965929203539823, f1 = 0.9776085982982535\n",
      "Epoch 32: Train Loss = 0.03275614831274069, Recall = 0.9950135992747053, Aging Rate = 0.5056663644605621, Precision = 0.9838637382339758, f1 = 0.9894072571557357\n",
      "Epoch 33: Train Loss = 0.0065485205606228974, Recall = 0.99909338168631, Aging Rate = 0.5013599274705349, Precision = 0.9963833634719711, f1 = 0.9977365323675871\n",
      "Epoch 34: Train Loss = 0.0011943413005573531, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 35: Train Loss = 0.0007130420268443603, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0006864235278050958, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 36: Train Loss = 0.0007924705648588748, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 37: Train Loss = 0.0009471204451429687, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 38: Train Loss = 0.001068023227799873, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 39: Train Loss = 0.0012601117336664919, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 40: Train Loss = 0.0013075654153439367, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0012205165104475293, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 41: Train Loss = 0.0013557357667351745, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 42: Train Loss = 0.0016169545007658512, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 43: Train Loss = 0.049509943524546116, Recall = 0.9877606527651859, Aging Rate = 0.5097461468721668, Precision = 0.9688750555802579, f1 = 0.9782267115600448\n",
      "Epoch 44: Train Loss = 0.04649919110281918, Recall = 0.9913871260199456, Aging Rate = 0.5088395285584769, Precision = 0.9741648106904232, f1 = 0.9827005167378117\n",
      "Epoch 45: Train Loss = 0.0034669735228283127, Recall = 1.0, Aging Rate = 0.5004533091568449, Precision = 0.9990942028985508, f1 = 0.9995468962392388\n",
      "Test Loss = 0.0013463084067953438, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 46: Train Loss = 0.0012183226102231456, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 47: Train Loss = 0.0009259318197564014, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 48: Train Loss = 0.0009842476781043085, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 49: Train Loss = 0.0010735554479616453, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 50: Train Loss = 0.00118530563632717, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0011056795929907293, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 51: Train Loss = 0.0013480197161951982, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 52: Train Loss = 0.0014740293677718947, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 53: Train Loss = 0.0103244516377507, Recall = 0.99909338168631, Aging Rate = 0.5027198549410699, Precision = 0.9936880072137061, f1 = 0.9963833634719711\n",
      "Epoch 54: Train Loss = 0.032650748548095375, Recall = 0.9909338168631007, Aging Rate = 0.5058930190389845, Precision = 0.9793906810035843, f1 = 0.9851284362325372\n",
      "Epoch 55: Train Loss = 0.019347379681530153, Recall = 0.9954669084315503, Aging Rate = 0.5029465095194923, Precision = 0.9896349707075259, f1 = 0.9925423728813559\n",
      "Test Loss = 0.004478698869876256, Recall = 1.0, Aging Rate = 0.5018132366273799, precision = 0.996386630532972\n",
      "\n",
      "Epoch 56: Train Loss = 0.004044454601354363, Recall = 0.99909338168631, Aging Rate = 0.5002266545784225, Precision = 0.9986406887177164, f1 = 0.9988669839111715\n",
      "Epoch 57: Train Loss = 0.002001874470597358, Recall = 1.0, Aging Rate = 0.5002266545784225, Precision = 0.9995468962392388, f1 = 0.9997733967822342\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58: Train Loss = 0.0008903534105121465, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 59: Train Loss = 0.000805558713726321, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 60: Train Loss = 0.0008951831206464878, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0008777852618415837, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Training Finished at epoch 60.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7724add769c94a05bf8d2d8a323df110",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss = 0.44298907142178096, Recall = 0.8500226551880381, Aging Rate = 0.5722700498414137, Precision = 0.7426761678543151, f1 = 0.7927318825269385\n",
      "Epoch 2: Train Loss = 0.1953322492644535, Recall = 0.9460806524694155, Aging Rate = 0.5240144993203444, Precision = 0.9027237354085603, f1 = 0.9238938053097345\n",
      "Epoch 3: Train Loss = 0.11017010301878186, Recall = 0.9732668781150884, Aging Rate = 0.5099682827367468, Precision = 0.9542425588627277, f1 = 0.9636608344549126\n",
      "Epoch 4: Train Loss = 0.07149194610040545, Recall = 0.9836882646125963, Aging Rate = 0.5065700045310376, Precision = 0.9709302325581395, f1 = 0.9772676119738916\n",
      "Epoch 5: Train Loss = 0.05531120005915702, Recall = 0.9864068871771635, Aging Rate = 0.5049841413683733, Precision = 0.9766711529834007, f1 = 0.9815148782687105\n",
      "Test Loss = 0.026469632102101435, Recall = 0.9945627548708654, Aging Rate = 0.49818758495695514, precision = 0.998180991359709\n",
      "Model in epoch 5 is saved.\n",
      "\n",
      "Epoch 6: Train Loss = 0.01681321097337854, Recall = 0.9977344811961939, Aging Rate = 0.5, Precision = 0.9977344811961939, f1 = 0.9977344811961939\n",
      "Epoch 7: Train Loss = 0.0074077203838592695, Recall = 0.9995468962392388, Aging Rate = 0.5, Precision = 0.9995468962392388, f1 = 0.9995468962392388\n",
      "Epoch 8: Train Loss = 0.004915253329924196, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 9: Train Loss = 0.0038548793817149143, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 10: Train Loss = 0.0033968451756124832, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.002876123542254719, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "Model in epoch 10 is saved.\n",
      "\n",
      "Epoch 11: Train Loss = 0.003087245411689823, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 12: Train Loss = 0.0027719283358104896, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 13: Train Loss = 0.002584730038979763, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 14: Train Loss = 0.002441657291544668, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 15: Train Loss = 0.0022295884582107296, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0020365074954633265, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 16: Train Loss = 0.0022529387356241635, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 17: Train Loss = 0.002233046680631046, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 18: Train Loss = 0.002073997100388971, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 19: Train Loss = 0.0020406660017243906, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 20: Train Loss = 0.00195373736236896, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0017430404620287297, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 21: Train Loss = 0.0018777078865572817, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 22: Train Loss = 0.0020028947220417266, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 23: Train Loss = 0.0019549589085518827, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 24: Train Loss = 0.0019597396790250413, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 25: Train Loss = 0.001876999926848289, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0016153923703815854, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 26: Train Loss = 0.0017593671058928726, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 27: Train Loss = 0.0017847956973075273, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 28: Train Loss = 0.0032131832559716663, Recall = 1.0, Aging Rate = 0.5002265518803806, Precision = 0.9995471014492754, f1 = 0.9997734994337486\n",
      "Epoch 29: Train Loss = 0.007175838345839837, Recall = 0.9990937924784775, Aging Rate = 0.5002265518803806, Precision = 0.998641304347826, f1 = 0.9988674971687429\n",
      "Epoch 30: Train Loss = 0.020249300481482334, Recall = 0.9950158586316267, Aging Rate = 0.5015858631626643, Precision = 0.991869918699187, f1 = 0.9934403980999774\n",
      "Test Loss = 0.0214446091713864, Recall = 0.991391028545537, Aging Rate = 0.5006796556411418, precision = 0.9900452488687783\n",
      "\n",
      "Epoch 31: Train Loss = 0.04046989200483986, Recall = 0.9891255097417309, Aging Rate = 0.5056637970095151, Precision = 0.9780465949820788, f1 = 0.9835548546970038\n",
      "Epoch 32: Train Loss = 0.025709071518801824, Recall = 0.9932034435885818, Aging Rate = 0.501132759401903, Precision = 0.9909584086799277, f1 = 0.9920796560307763\n",
      "Epoch 33: Train Loss = 0.006093232100122656, Recall = 1.0, Aging Rate = 0.5015858631626643, Precision = 0.9968383017163505, f1 = 0.9984166478172359\n",
      "Epoch 34: Train Loss = 0.0010500250618519134, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 35: Train Loss = 0.00046430137579164316, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.00045108755956944896, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 36: Train Loss = 0.0004735304506670297, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 37: Train Loss = 0.000504817726784928, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 38: Train Loss = 0.0005513437830621067, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 39: Train Loss = 0.000607873840505653, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 40: Train Loss = 0.0007008921703305577, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0006854520702593646, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 41: Train Loss = 0.000754327415587827, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 42: Train Loss = 0.0008190903173021949, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 43: Train Loss = 0.0008954573325086157, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 44: Train Loss = 0.0009776883794789806, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 45: Train Loss = 0.0010173680018874137, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0009887052601178848, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 46: Train Loss = 0.0011213132250745155, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 47: Train Loss = 0.0011673961228243314, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 48: Train Loss = 0.0012102821967587731, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 49: Train Loss = 0.0012612717080457067, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 50: Train Loss = 0.001332084561751309, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0012396934837728274, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 51: Train Loss = 0.0014573857706739796, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 52: Train Loss = 0.00138574946355446, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 53: Train Loss = 0.001416415398053008, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 54: Train Loss = 0.0015065640266596475, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 55: Train Loss = 0.0014201251860715594, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0014118514129534147, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 56: Train Loss = 0.007049621915420257, Recall = 0.9990937924784775, Aging Rate = 0.5006796556411418, Precision = 0.997737556561086, f1 = 0.9984152139461173\n",
      "Epoch 57: Train Loss = 0.03056634678393535, Recall = 0.9918441323062981, Aging Rate = 0.5020389669234254, Precision = 0.9878158844765343, f1 = 0.9898259100158264\n",
      "Epoch 58: Train Loss = 0.017219681818250062, Recall = 0.9950158586316267, Aging Rate = 0.5006796556411418, Precision = 0.9936651583710407, f1 = 0.9943400498075617\n",
      "Epoch 59: Train Loss = 0.013126800147863802, Recall = 0.9968282736746715, Aging Rate = 0.501132759401903, Precision = 0.9945750452079566, f1 = 0.9957003847024213\n",
      "Epoch 60: Train Loss = 0.0025103287059770694, Recall = 0.9995468962392388, Aging Rate = 0.5, Precision = 0.9995468962392388, f1 = 0.9995468962392388\n",
      "Test Loss = 0.0009489323649307317, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Training Finished at epoch 60.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1aa7cf3dbce84249ae31ab65afa9c439",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss = 0.44871106479023115, Recall = 0.8631006346328196, Aging Rate = 0.5961015412511332, Precision = 0.7239543726235741, f1 = 0.7874276261373035\n",
      "Epoch 2: Train Loss = 0.20992083196356853, Recall = 0.9383499546690843, Aging Rate = 0.5217588395285585, Precision = 0.8992180712423979, f1 = 0.9183673469387755\n",
      "Epoch 3: Train Loss = 0.13163988912310906, Recall = 0.9628286491387126, Aging Rate = 0.5097461468721668, Precision = 0.9444197421076034, f1 = 0.9535353535353536\n",
      "Epoch 4: Train Loss = 0.0870934948899318, Recall = 0.9805077062556664, Aging Rate = 0.5072529465095195, Precision = 0.9664879356568364, f1 = 0.9734473447344735\n",
      "Epoch 5: Train Loss = 0.07380992786811896, Recall = 0.9777878513145966, Aging Rate = 0.5011332728921124, Precision = 0.9755766621438263, f1 = 0.9766810052071542\n",
      "Test Loss = 0.0370128921141083, Recall = 0.9968268359020852, Aging Rate = 0.5029465095194923, precision = 0.9909869310500226\n",
      "Model in epoch 5 is saved.\n",
      "\n",
      "Epoch 6: Train Loss = 0.024228193945777438, Recall = 0.9950135992747053, Aging Rate = 0.50090661831369, Precision = 0.9932126696832579, f1 = 0.9941123188405797\n",
      "Epoch 7: Train Loss = 0.012344355683973024, Recall = 0.99909338168631, Aging Rate = 0.5002266545784225, Precision = 0.9986406887177164, f1 = 0.9988669839111715\n",
      "Epoch 8: Train Loss = 0.00792124313416326, Recall = 0.9995466908431551, Aging Rate = 0.5, Precision = 0.9995466908431551, f1 = 0.9995466908431551\n",
      "Epoch 9: Train Loss = 0.005928202565583795, Recall = 0.9995466908431551, Aging Rate = 0.5, Precision = 0.9995466908431551, f1 = 0.9995466908431551\n",
      "Epoch 10: Train Loss = 0.0048893171772934965, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.003856266162283077, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "Model in epoch 10 is saved.\n",
      "\n",
      "Epoch 11: Train Loss = 0.0038336657510322273, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 12: Train Loss = 0.0034662598852956447, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 13: Train Loss = 0.0030103123086949613, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 14: Train Loss = 0.0027706789653680727, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 15: Train Loss = 0.0025999189516173124, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0023459399575815076, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 16: Train Loss = 0.0025655501334255026, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 17: Train Loss = 0.0024394643994754116, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 18: Train Loss = 0.0025144550959467346, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 19: Train Loss = 0.002333830288676368, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 20: Train Loss = 0.0023383856024880197, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.001992367787019823, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 21: Train Loss = 0.0022555264156288108, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 22: Train Loss = 0.0022861979515920792, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 23: Train Loss = 0.0028306515452537285, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 24: Train Loss = 0.0023065419261388527, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 25: Train Loss = 0.0018773619667099195, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0017248825102551407, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 26: Train Loss = 0.0019310543595214568, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 27: Train Loss = 0.0019035815687281023, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 28: Train Loss = 0.002041725556012361, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 29: Train Loss = 0.003507818531494922, Recall = 0.9995466908431551, Aging Rate = 0.49977334542157753, Precision = 0, f1 = 0.0\n",
      "Epoch 30: Train Loss = 0.004598304264564894, Recall = 1.0, Aging Rate = 0.5002266545784225, Precision = 0.9995468962392388, f1 = 0.9997733967822342\n",
      "Test Loss = 0.004914885761084563, Recall = 0.9995466908431551, Aging Rate = 0.5002266545784225, precision = 0.9990937924784775\n",
      "\n",
      "Epoch 31: Train Loss = 0.0038996755309294866, Recall = 0.99909338168631, Aging Rate = 0.499546690843155, Precision = 0, f1 = 0.0\n",
      "Epoch 32: Train Loss = 0.0336581060244066, Recall = 0.9936536718041704, Aging Rate = 0.5038531278331823, Precision = 0.9860548807917229, f1 = 0.9898396929329419\n",
      "Epoch 33: Train Loss = 0.021620717385137017, Recall = 0.9954669084315503, Aging Rate = 0.5031731640979148, Precision = 0.9891891891891892, f1 = 0.992318120198825\n",
      "Epoch 34: Train Loss = 0.007858128160033933, Recall = 0.9981867633726201, Aging Rate = 0.49977334542157753, Precision = 0.998639455782313, f1 = 0.9984130582634324\n",
      "Epoch 35: Train Loss = 0.0025868209840726455, Recall = 0.9995466908431551, Aging Rate = 0.49977334542157753, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0007872777023261492, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 36: Train Loss = 0.0007358501910790126, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 37: Train Loss = 0.0006552389460883474, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 38: Train Loss = 0.0007516095275017124, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 39: Train Loss = 0.0007946405354811255, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 40: Train Loss = 0.0008655849327894767, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0008509591501923861, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 41: Train Loss = 0.0009513141555502227, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 42: Train Loss = 0.0010266778705656826, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 43: Train Loss = 0.0010872677483419438, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 44: Train Loss = 0.0011788915025014582, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 45: Train Loss = 0.0012895693533470413, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.001272263923927581, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 46: Train Loss = 0.0013369806531980525, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 47: Train Loss = 0.001352977267477462, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 48: Train Loss = 0.0014168261206292583, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 49: Train Loss = 0.0014267108496658484, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 50: Train Loss = 0.0014904094240940594, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0013932926263254904, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 51: Train Loss = 0.0015143964561323043, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 52: Train Loss = 0.001588276562307128, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 53: Train Loss = 0.0015723864494713998, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 54: Train Loss = 0.0016734293309071608, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 55: Train Loss = 0.0015939235862881512, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0013551816761372096, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 56: Train Loss = 0.0015538738812940535, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 57: Train Loss = 0.0017306372966171526, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 58: Train Loss = 0.0024423288715055935, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 59: Train Loss = 0.01347649769168533, Recall = 0.9963735267452403, Aging Rate = 0.5015865820489573, Precision = 0.9932218707636692, f1 = 0.99479520253451\n",
      "Epoch 60: Train Loss = 0.0970639607557522, Recall = 0.972348141432457, Aging Rate = 0.5081595648232095, Precision = 0.9567350579839429, f1 = 0.9644784172661871\n",
      "Test Loss = 0.026477103510825935, Recall = 0.9945602901178604, Aging Rate = 0.5024932003626473, precision = 0.9896256202074876\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Finished at epoch 60.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce3032e91929444ca3eeb4d6f210487b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss = 0.40571228748649074, Recall = 0.889895786135025, Aging Rate = 0.5781603987313094, Precision = 0.7695924764890282, f1 = 0.8253834839251943\n",
      "Epoch 2: Train Loss = 0.16504260520887526, Recall = 0.9565020389669234, Aging Rate = 0.5144993203443589, Precision = 0.9295464553060326, f1 = 0.9428316212594908\n",
      "Epoch 3: Train Loss = 0.1007835905531385, Recall = 0.9755323969188944, Aging Rate = 0.5083824195740825, Precision = 0.9594474153297683, f1 = 0.9674230509997753\n",
      "Epoch 4: Train Loss = 0.07246102609742967, Recall = 0.9800634345265066, Aging Rate = 0.504077933846851, Precision = 0.9721348314606741, f1 = 0.9760830324909746\n",
      "Epoch 5: Train Loss = 0.051856894658791515, Recall = 0.9882193022202084, Aging Rate = 0.504077933846851, Precision = 0.9802247191011236, f1 = 0.9842057761732852\n",
      "Test Loss = 0.021425291857887677, Recall = 1.0, Aging Rate = 0.5027186225645673, precision = 0.9945921586300135\n",
      "Model in epoch 5 is saved.\n",
      "\n",
      "Epoch 6: Train Loss = 0.016202314480409992, Recall = 0.9990937924784775, Aging Rate = 0.5013593112822836, Precision = 0.9963849977406236, f1 = 0.997737556561086\n",
      "Epoch 7: Train Loss = 0.009310771231372863, Recall = 0.9995468962392388, Aging Rate = 0.5006796556411418, Precision = 0.9981900452488688, f1 = 0.9988680099615123\n",
      "Epoch 8: Train Loss = 0.006439107714122137, Recall = 1.0, Aging Rate = 0.5002265518803806, Precision = 0.9995471014492754, f1 = 0.9997734994337486\n",
      "Epoch 9: Train Loss = 0.004459026843515332, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 10: Train Loss = 0.0035788435860286756, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0030541259985953895, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "Model in epoch 10 is saved.\n",
      "\n",
      "Epoch 11: Train Loss = 0.0030075106470190296, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 12: Train Loss = 0.0027915781351607284, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 13: Train Loss = 0.0027035649738847995, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 14: Train Loss = 0.0026304430607242122, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 15: Train Loss = 0.0023704141338947043, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.002144590537428795, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 16: Train Loss = 0.0023055455090809744, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 17: Train Loss = 0.0023257195988904615, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 18: Train Loss = 0.00215583621890558, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 19: Train Loss = 0.00219723914908587, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 20: Train Loss = 0.00226147513073672, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0019006625630803775, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 21: Train Loss = 0.0058876801538312795, Recall = 0.9995468962392388, Aging Rate = 0.5, Precision = 0.9995468962392388, f1 = 0.9995468962392388\n",
      "Epoch 22: Train Loss = 0.0040916756350812085, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 23: Train Loss = 0.002545098870717104, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 24: Train Loss = 0.0015511067782912284, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 25: Train Loss = 0.0014993012208119373, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0013245494489667335, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 26: Train Loss = 0.0015543328433989209, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 27: Train Loss = 0.001718856216740415, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 28: Train Loss = 0.0017239455269555943, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 29: Train Loss = 0.0020670650942431696, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 30: Train Loss = 0.0016656058768610548, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0014652653263293553, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 31: Train Loss = 0.0016977411362932894, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 32: Train Loss = 0.0020219896212988206, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 33: Train Loss = 0.002012867567366378, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 34: Train Loss = 0.002064126275212255, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 35: Train Loss = 0.0016931909037623968, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.001476231506434035, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 36: Train Loss = 0.001979116414448708, Recall = 1.0, Aging Rate = 0.5002265518803806, Precision = 0.9995471014492754, f1 = 0.9997734994337486\n",
      "Epoch 37: Train Loss = 0.009635070035015505, Recall = 0.9981875849569551, Aging Rate = 0.5009062075215225, Precision = 0.9963817277250113, f1 = 0.9972838388411046\n",
      "Epoch 38: Train Loss = 0.08601140639207511, Recall = 0.9737199818758495, Aging Rate = 0.5070231082917989, Precision = 0.9602323503127793, f1 = 0.9669291338582678\n",
      "Epoch 39: Train Loss = 0.02447692737195136, Recall = 0.9941096511101042, Aging Rate = 0.5027186225645673, Precision = 0.9887336638125281, f1 = 0.991414369633981\n",
      "Epoch 40: Train Loss = 0.0076838797127121595, Recall = 0.9990937924784775, Aging Rate = 0.5009062075215225, Precision = 0.9972862957937585, f1 = 0.9981892258940697\n",
      "Test Loss = 0.010379381975433128, Recall = 1.0, Aging Rate = 0.5036248300860897, precision = 0.9928025191183086\n",
      "\n",
      "Epoch 41: Train Loss = 0.005235212594095582, Recall = 0.9990937924784775, Aging Rate = 0.5004531037607612, Precision = 0.9981892258940697, f1 = 0.9986413043478259\n",
      "Epoch 42: Train Loss = 0.004226306989163626, Recall = 0.9990937924784775, Aging Rate = 0.4997734481196194, Precision = 0.9995466908431551, f1 = 0.9993201903467029\n",
      "Epoch 43: Train Loss = 0.0012782140791932678, Recall = 1.0, Aging Rate = 0.5002265518803806, Precision = 0.9995471014492754, f1 = 0.9997734994337486\n",
      "Epoch 44: Train Loss = 0.0008837444855499039, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 45: Train Loss = 0.0007804874295417741, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0006619510118476963, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 46: Train Loss = 0.0007043453285788782, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 47: Train Loss = 0.0007806807748458969, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 48: Train Loss = 0.0008355181621080395, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 49: Train Loss = 0.0009471001422647125, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 50: Train Loss = 0.0009935756488675762, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0009736810331593644, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 51: Train Loss = 0.001112657006208392, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 52: Train Loss = 0.0011993342603645006, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 53: Train Loss = 0.001218130870019206, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 54: Train Loss = 0.0012753156317511045, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 55: Train Loss = 0.0013660298734034044, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0012449774540678903, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 56: Train Loss = 0.0013999714634048287, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 57: Train Loss = 0.0014393418453111366, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 58: Train Loss = 0.001511341919981139, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 59: Train Loss = 0.0015301375438243584, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 60: Train Loss = 0.0016615423531067697, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0013940346585611986, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Training Finished at epoch 60.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f29f3bfeb23e46dbb000b5d105d031b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss = 0.4185786326690252, Recall = 0.8844061650045331, Aging Rate = 0.5847688123300091, Precision = 0.756201550387597, f1 = 0.815294609277058\n",
      "Epoch 2: Train Loss = 0.18288943220135956, Recall = 0.9519492293744334, Aging Rate = 0.5172257479601088, Precision = 0.9202453987730062, f1 = 0.9358288770053477\n",
      "Epoch 3: Train Loss = 0.10384767436348949, Recall = 0.972348141432457, Aging Rate = 0.5072529465095195, Precision = 0.9584450402144772, f1 = 0.9653465346534653\n",
      "Epoch 4: Train Loss = 0.06915318643030857, Recall = 0.985040797824116, Aging Rate = 0.5077062556663645, Precision = 0.9700892857142858, f1 = 0.9775078722447144\n",
      "Epoch 5: Train Loss = 0.04331979030913801, Recall = 0.9918404351767905, Aging Rate = 0.5020398912058024, Precision = 0.9878103837471783, f1 = 0.9898213073965165\n",
      "Test Loss = 0.01825776760038309, Recall = 0.99909338168631, Aging Rate = 0.5013599274705349, precision = 0.9963833634719711\n",
      "Model in epoch 5 is saved.\n",
      "\n",
      "Epoch 6: Train Loss = 0.016829778587214263, Recall = 0.9986400725294651, Aging Rate = 0.50090661831369, Precision = 0.9968325791855204, f1 = 0.9977355072463768\n",
      "Epoch 7: Train Loss = 0.008290236176211972, Recall = 0.99909338168631, Aging Rate = 0.5, Precision = 0.99909338168631, f1 = 0.99909338168631\n",
      "Epoch 8: Train Loss = 0.005895909948269427, Recall = 0.9995466908431551, Aging Rate = 0.5, Precision = 0.9995466908431551, f1 = 0.9995466908431551\n",
      "Epoch 9: Train Loss = 0.0042624358235117885, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 10: Train Loss = 0.003601669416199704, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0031035959149406022, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "Model in epoch 10 is saved.\n",
      "\n",
      "Epoch 11: Train Loss = 0.0032077833439340835, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 12: Train Loss = 0.002797228771689114, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 13: Train Loss = 0.002565906699307783, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 14: Train Loss = 0.0023992573189087285, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 15: Train Loss = 0.0023443055831416024, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.002138582677584638, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 16: Train Loss = 0.002257796914522736, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 17: Train Loss = 0.0022445697403248614, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 18: Train Loss = 0.0021397135253608942, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 19: Train Loss = 0.002577589240080507, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 20: Train Loss = 0.0022945349897973153, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0017736647369893958, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 21: Train Loss = 0.001952198846350109, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 22: Train Loss = 0.0018844191220961342, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 23: Train Loss = 0.001955352815633077, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 24: Train Loss = 0.0018889451385091514, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 25: Train Loss = 0.0018940325007383, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0015944229746668018, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 26: Train Loss = 0.0018492507280111448, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 27: Train Loss = 0.0019681450555393185, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 28: Train Loss = 0.0019010896104238487, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 29: Train Loss = 0.0020432618019404947, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 30: Train Loss = 0.06771107789986883, Recall = 0.9800543970988214, Aging Rate = 0.507026291931097, Precision = 0.9664729548502459, f1 = 0.9732162952959711\n",
      "Test Loss = 0.038422884453334596, Recall = 0.9918404351767905, Aging Rate = 0.5052130553037172, precision = 0.9816061013907582\n",
      "\n",
      "Epoch 31: Train Loss = 0.030886794301129856, Recall = 0.9922937443336355, Aging Rate = 0.5015865820489573, Precision = 0.9891549932218707, f1 = 0.9907218827789092\n",
      "Epoch 32: Train Loss = 0.006847306742444331, Recall = 0.9981867633726201, Aging Rate = 0.5006799637352675, Precision = 0.996831145314622, f1 = 0.9975084937712345\n",
      "Epoch 33: Train Loss = 0.0015057243491419113, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 34: Train Loss = 0.0009493651317098159, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 35: Train Loss = 0.0008952649820432175, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0008451501280111569, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 36: Train Loss = 0.0009295412499486306, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 37: Train Loss = 0.000986926885070963, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 38: Train Loss = 0.001024828856669076, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 39: Train Loss = 0.0010843579439954632, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 40: Train Loss = 0.0011538990979282995, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.001064900805960905, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 41: Train Loss = 0.0011631643954970125, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 42: Train Loss = 0.0012170868475709518, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 43: Train Loss = 0.0012512396300610085, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 44: Train Loss = 0.0013112069217569228, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 45: Train Loss = 0.0013881277137605687, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0013084463744127916, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 46: Train Loss = 0.0014596318873363197, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 47: Train Loss = 0.0015741728166209455, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 48: Train Loss = 0.0013780204957293673, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 49: Train Loss = 0.0013855312121753408, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 50: Train Loss = 0.0014381687529849486, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0014029882620498267, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 51: Train Loss = 0.0015147197420615113, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 52: Train Loss = 0.0015109179924383206, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 53: Train Loss = 0.001471510131025209, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 54: Train Loss = 0.0014930294682242225, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 55: Train Loss = 0.0015784222593595184, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.001360517406392022, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 56: Train Loss = 0.0015362688562522895, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 57: Train Loss = 0.005003768143498238, Recall = 0.99909338168631, Aging Rate = 0.49977334542157753, Precision = 0.999546485260771, f1 = 0.9993198821128995\n",
      "Epoch 58: Train Loss = 0.013184815304098839, Recall = 0.9981867633726201, Aging Rate = 0.5022665457842248, Precision = 0.9936823104693141, f1 = 0.9959294436906377\n",
      "Epoch 59: Train Loss = 0.04191340116660701, Recall = 0.9913871260199456, Aging Rate = 0.5045330915684497, Precision = 0.9824797843665768, f1 = 0.9869133574007221\n",
      "Epoch 60: Train Loss = 0.01870379264357543, Recall = 0.9968268359020852, Aging Rate = 0.5022665457842248, Precision = 0.9923285198555957, f1 = 0.994572591587517\n",
      "Test Loss = 0.005645467942379624, Recall = 0.9977334542157752, Aging Rate = 0.49909338168631007, precision = 0.9995458673932789\n",
      "\n",
      "Training Finished at epoch 60.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f2588e52e5124db4b525327d51556b19",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss = 0.4510826134508778, Recall = 0.8309156844968268, Aging Rate = 0.5475974614687217, Precision = 0.7586920529801324, f1 = 0.7931631328429252\n",
      "Epoch 2: Train Loss = 0.2159573878495129, Recall = 0.9333635539437897, Aging Rate = 0.5217588395285585, Precision = 0.8944396177237185, f1 = 0.9134871339840285\n",
      "Epoch 3: Train Loss = 0.1264998414642359, Recall = 0.9664551223934723, Aging Rate = 0.5138259292837716, Precision = 0.9404499338332598, f1 = 0.9532752067963335\n",
      "Epoch 4: Train Loss = 0.07366742733410026, Recall = 0.985040797824116, Aging Rate = 0.507479601087942, Precision = 0.970522554711925, f1 = 0.9777277840269967\n",
      "Epoch 5: Train Loss = 0.061991329432371414, Recall = 0.9827742520398912, Aging Rate = 0.5011332728921124, Precision = 0.9805517865219358, f1 = 0.9816617613765\n",
      "Test Loss = 0.028263383660657993, Recall = 0.9995466908431551, Aging Rate = 0.5045330915684497, precision = 0.9905660377358491\n",
      "Model in epoch 5 is saved.\n",
      "\n",
      "Epoch 6: Train Loss = 0.02050472825515681, Recall = 0.9986400725294651, Aging Rate = 0.5011332728921124, Precision = 0.9963817277250113, f1 = 0.9975096219153271\n",
      "Epoch 7: Train Loss = 0.00981519386216201, Recall = 1.0, Aging Rate = 0.5006799637352675, Precision = 0.9986419194205522, f1 = 0.9993204983012457\n",
      "Epoch 8: Train Loss = 0.006425619316612415, Recall = 0.9995466908431551, Aging Rate = 0.5002266545784225, Precision = 0.9990937924784775, f1 = 0.9993201903467029\n",
      "Epoch 9: Train Loss = 0.005064433586639322, Recall = 1.0, Aging Rate = 0.5002266545784225, Precision = 0.9995468962392388, f1 = 0.9997733967822342\n",
      "Epoch 10: Train Loss = 0.004383159548479891, Recall = 0.9995466908431551, Aging Rate = 0.49977334542157753, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.003628234879062228, Recall = 1.0, Aging Rate = 0.5002266545784225, precision = 0.9995468962392388\n",
      "Model in epoch 10 is saved.\n",
      "\n",
      "Epoch 11: Train Loss = 0.004532916413946035, Recall = 0.9995466908431551, Aging Rate = 0.5, Precision = 0.9995466908431551, f1 = 0.9995466908431551\n",
      "Epoch 12: Train Loss = 0.0037974866737416546, Recall = 1.0, Aging Rate = 0.5002266545784225, Precision = 0.9995468962392388, f1 = 0.9997733967822342\n",
      "Epoch 13: Train Loss = 0.0030660027896027915, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 14: Train Loss = 0.0028313788754657817, Recall = 1.0, Aging Rate = 0.5002266545784225, Precision = 0.9995468962392388, f1 = 0.9997733967822342\n",
      "Epoch 15: Train Loss = 0.002332200350261826, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0020466671695304546, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "Model in epoch 15 is saved.\n",
      "\n",
      "Epoch 16: Train Loss = 0.002185767101071579, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 17: Train Loss = 0.002247254497178257, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 18: Train Loss = 0.0021375246953509635, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 19: Train Loss = 0.0020270425993493225, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 20: Train Loss = 0.0020677149855191476, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.001844239955664978, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 21: Train Loss = 0.0020965393628428605, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 22: Train Loss = 0.001984357705520481, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 23: Train Loss = 0.002005771587113913, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 24: Train Loss = 0.001902242703975456, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 25: Train Loss = 0.001964457941022875, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0017280109602019042, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 26: Train Loss = 0.001894825607823615, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 27: Train Loss = 0.0050769724880183895, Recall = 0.9995466908431551, Aging Rate = 0.5002266545784225, Precision = 0.9990937924784775, f1 = 0.9993201903467029\n",
      "Epoch 28: Train Loss = 0.03766904885653518, Recall = 0.9900271985494107, Aging Rate = 0.5031731640979148, Precision = 0.9837837837837838, f1 = 0.9868956168097605\n",
      "Epoch 29: Train Loss = 0.04551026993283389, Recall = 0.986400725294651, Aging Rate = 0.5027198549410699, Precision = 0.9810640216411182, f1 = 0.9837251356238699\n",
      "Epoch 30: Train Loss = 0.023127659871593348, Recall = 0.9954669084315503, Aging Rate = 0.5031731640979148, Precision = 0.9891891891891892, f1 = 0.992318120198825\n",
      "Test Loss = 0.007944708169925136, Recall = 0.9995466908431551, Aging Rate = 0.5004533091568449, precision = 0.998641304347826\n",
      "\n",
      "Epoch 31: Train Loss = 0.0044022183552897744, Recall = 0.99909338168631, Aging Rate = 0.5004533091568449, Precision = 0.9981884057971014, f1 = 0.9986406887177163\n",
      "Epoch 32: Train Loss = 0.0017850747243214166, Recall = 1.0, Aging Rate = 0.5002266545784225, Precision = 0.9995468962392388, f1 = 0.9997733967822342\n",
      "Epoch 33: Train Loss = 0.0006552342079161452, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 34: Train Loss = 0.0006116509189215385, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 35: Train Loss = 0.0006390458603194515, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0006272184864321516, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 36: Train Loss = 0.0006831520499728269, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 37: Train Loss = 0.00074169810484345, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 38: Train Loss = 0.0008306116996508628, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 39: Train Loss = 0.0008666778102783943, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 40: Train Loss = 0.0009513545962065756, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0008906477611386981, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 41: Train Loss = 0.0009978820788500964, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 42: Train Loss = 0.0010960024263513893, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 43: Train Loss = 0.001160025972883949, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 44: Train Loss = 0.0011960286696687179, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 45: Train Loss = 0.001273331350472976, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0011614049623989698, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 46: Train Loss = 0.0012910437576197499, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 47: Train Loss = 0.0013220465171268228, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 48: Train Loss = 0.0013763568074259221, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 49: Train Loss = 0.0014837839281193217, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 50: Train Loss = 0.0020896553423708254, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0018133137901571131, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 51: Train Loss = 0.001741085469689818, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 52: Train Loss = 0.0015382641542859962, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 53: Train Loss = 0.003662768505675784, Recall = 0.9995466908431551, Aging Rate = 0.5, Precision = 0.9995466908431551, f1 = 0.9995466908431551\n",
      "Epoch 54: Train Loss = 0.004574871185494896, Recall = 0.9995466908431551, Aging Rate = 0.5, Precision = 0.9995466908431551, f1 = 0.9995466908431551\n",
      "Epoch 55: Train Loss = 0.02148241618714031, Recall = 0.9941069809610155, Aging Rate = 0.50090661831369, Precision = 0.9923076923076923, f1 = 0.9932065217391305\n",
      "Test Loss = 0.10603890033710683, Recall = 1.0, Aging Rate = 0.5466908431550317, precision = 0.9145936981757877\n",
      "\n",
      "Epoch 56: Train Loss = 0.02379012282968162, Recall = 0.9945602901178604, Aging Rate = 0.5029465095194923, Precision = 0.9887336638125281, f1 = 0.991638418079096\n",
      "Epoch 57: Train Loss = 0.02379557460226483, Recall = 0.9936536718041704, Aging Rate = 0.5029465095194923, Precision = 0.9878323569175305, f1 = 0.9907344632768362\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58: Train Loss = 0.006153700514827413, Recall = 1.0, Aging Rate = 0.5015865820489573, Precision = 0.9968368730230457, f1 = 0.9984159312061552\n",
      "Epoch 59: Train Loss = 0.002680517494461498, Recall = 0.99909338168631, Aging Rate = 0.49977334542157753, Precision = 0.999546485260771, f1 = 0.9993198821128995\n",
      "Epoch 60: Train Loss = 0.0008968897456225559, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.00047468488513731, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 61: Train Loss = 0.000472016079346662, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 62: Train Loss = 0.000491746582747551, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 63: Train Loss = 0.0005535012771141592, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 64: Train Loss = 0.000605444946826173, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 65: Train Loss = 0.000682217661284606, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0006754696328536601, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Training Finished at epoch 65.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "89d1ffa2d5e74d248649fadd93353ff0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a008855e32d40149ce30507fecbdfe0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss = 0.3835696037834054, Recall = 0.8880794701986755, Aging Rate = 0.5783112582781457, Precision = 0.7678213569997138, f1 = 0.8235836020267159\n",
      "Epoch 2: Train Loss = 0.21797060552022315, Recall = 0.9334437086092715, Aging Rate = 0.5245033112582781, Precision = 0.8898358585858586, f1 = 0.9111182934712346\n",
      "Epoch 3: Train Loss = 0.1608995968142882, Recall = 0.9543046357615894, Aging Rate = 0.5190397350993378, Precision = 0.9192982456140351, f1 = 0.9364744110479285\n",
      "Epoch 4: Train Loss = 0.15201272972372193, Recall = 0.9556291390728476, Aging Rate = 0.5167218543046358, Precision = 0.924703620634412, f1 = 0.9399120664386907\n",
      "Epoch 5: Train Loss = 0.13675177377580808, Recall = 0.9543046357615894, Aging Rate = 0.506953642384106, Precision = 0.9412148922273024, f1 = 0.947714567576455\n",
      "Test Loss = 0.094330433011055, Recall = 0.9953642384105961, Aging Rate = 0.5327814569536424, precision = 0.9341205717837165\n",
      "Model in epoch 5 is saved.\n",
      "\n",
      "Epoch 6: Train Loss = 0.07860249173858308, Recall = 0.9821192052980132, Aging Rate = 0.5105960264900662, Precision = 0.9617380025940337, f1 = 0.9718217562254259\n",
      "Epoch 7: Train Loss = 0.062453527578356254, Recall = 0.9857615894039735, Aging Rate = 0.5064569536423841, Precision = 0.9731938542007192, f1 = 0.9794374074683336\n",
      "Epoch 8: Train Loss = 0.06955032462365185, Recall = 0.9817880794701986, Aging Rate = 0.5072847682119205, Precision = 0.9676892950391645, f1 = 0.9746877054569362\n",
      "Epoch 9: Train Loss = 0.054284760471902144, Recall = 0.9874172185430463, Aging Rate = 0.5051324503311259, Precision = 0.9773844641101278, f1 = 0.9823752264865755\n",
      "Epoch 10: Train Loss = 0.06426640636972245, Recall = 0.9844370860927152, Aging Rate = 0.5054635761589404, Precision = 0.9737962659679005, f1 = 0.9790877655195126\n",
      "Test Loss = 0.05332872218742276, Recall = 0.997682119205298, Aging Rate = 0.5142384105960265, precision = 0.9700579523502898\n",
      "Model in epoch 10 is saved.\n",
      "\n",
      "Epoch 11: Train Loss = 0.057774724584344204, Recall = 0.9874172185430463, Aging Rate = 0.5062913907284768, Precision = 0.9751471550032701, f1 = 0.9812438302073049\n",
      "Epoch 12: Train Loss = 0.0544561267491208, Recall = 0.9877483443708609, Aging Rate = 0.5046357615894039, Precision = 0.9786745406824147, f1 = 0.9831905075807514\n",
      "Epoch 13: Train Loss = 0.053893254618376296, Recall = 0.9894039735099338, Aging Rate = 0.5046357615894039, Precision = 0.9803149606299213, f1 = 0.984838497033619\n",
      "Epoch 14: Train Loss = 0.05576487069098365, Recall = 0.9864238410596027, Aging Rate = 0.5051324503311259, Precision = 0.976401179941003, f1 = 0.9813869214297479\n",
      "Epoch 15: Train Loss = 0.05451455626957464, Recall = 0.9877483443708609, Aging Rate = 0.5051324503311259, Precision = 0.9777122254998362, f1 = 0.982704661505518\n",
      "Test Loss = 0.0416951854941466, Recall = 0.990728476821192, Aging Rate = 0.49933774834437084, precision = 0.9920424403183024\n",
      "Model in epoch 15 is saved.\n",
      "\n",
      "Epoch 16: Train Loss = 0.0512459052714291, Recall = 0.990728476821192, Aging Rate = 0.5059602649006623, Precision = 0.9790575916230366, f1 = 0.9848584595128375\n",
      "Epoch 17: Train Loss = 0.0516225744556907, Recall = 0.9897350993377484, Aging Rate = 0.5051324503311259, Precision = 0.9796787938380859, f1 = 0.9846812716191732\n",
      "Epoch 18: Train Loss = 0.052644004041193335, Recall = 0.9900662251655629, Aging Rate = 0.5062913907284768, Precision = 0.9777632439502943, f1 = 0.9838762750904902\n",
      "Epoch 19: Train Loss = 0.052871758529040594, Recall = 0.9903973509933774, Aging Rate = 0.5059602649006623, Precision = 0.9787303664921466, f1 = 0.9845292955892033\n",
      "Epoch 20: Train Loss = 0.04919020136115172, Recall = 0.9917218543046358, Aging Rate = 0.5067880794701987, Precision = 0.9784384188173799, f1 = 0.9850353560269692\n",
      "Test Loss = 0.06329887779244524, Recall = 0.9708609271523179, Aging Rate = 0.48923841059602646, precision = 0.9922165820642977\n",
      "\n",
      "Epoch 21: Train Loss = 0.053023505933730807, Recall = 0.9880794701986755, Aging Rate = 0.5049668874172185, Precision = 0.9783606557377049, f1 = 0.9831960461285009\n",
      "Epoch 22: Train Loss = 0.04275783652945465, Recall = 0.993046357615894, Aging Rate = 0.5046357615894039, Precision = 0.9839238845144357, f1 = 0.9884640738299275\n",
      "Epoch 23: Train Loss = 0.05009901484856937, Recall = 0.9897350993377484, Aging Rate = 0.5051324503311259, Precision = 0.9796787938380859, f1 = 0.9846812716191732\n",
      "Epoch 24: Train Loss = 0.0516454678990983, Recall = 0.9894039735099338, Aging Rate = 0.5052980132450331, Precision = 0.9790301441677588, f1 = 0.9841897233201581\n",
      "Epoch 25: Train Loss = 0.05547313085010904, Recall = 0.9890728476821192, Aging Rate = 0.5056291390728477, Precision = 0.9780615586116569, f1 = 0.983536384590056\n",
      "Test Loss = 0.06102991714974902, Recall = 0.9711920529801324, Aging Rate = 0.4872516556291391, precision = 0.9966021066938499\n",
      "\n",
      "Epoch 26: Train Loss = 0.052601482383660136, Recall = 0.9910596026490066, Aging Rate = 0.5054635761589404, Precision = 0.9803471994759253, f1 = 0.985674296064548\n",
      "Epoch 27: Train Loss = 0.052074758883639674, Recall = 0.9894039735099338, Aging Rate = 0.5059602649006623, Precision = 0.9777486910994765, f1 = 0.9835418038183016\n",
      "Epoch 28: Train Loss = 0.05214687433118457, Recall = 0.9877483443708609, Aging Rate = 0.5057947019867549, Precision = 0.9764320785597381, f1 = 0.9820576131687243\n",
      "Epoch 29: Train Loss = 0.05379313165877039, Recall = 0.9874172185430463, Aging Rate = 0.5049668874172185, Precision = 0.9777049180327869, f1 = 0.9825370675453048\n",
      "Epoch 30: Train Loss = 0.04580487884482406, Recall = 0.9900662251655629, Aging Rate = 0.5048013245033113, Precision = 0.9806493932436865, f1 = 0.9853353105948262\n",
      "Test Loss = 0.03366693355241753, Recall = 0.9947019867549669, Aging Rate = 0.503476821192053, precision = 0.9878329496876027\n",
      "\n",
      "Epoch 31: Train Loss = 0.046650312448672904, Recall = 0.9927152317880795, Aging Rate = 0.5056291390728477, Precision = 0.9816633922724296, f1 = 0.9871583799802436\n",
      "Epoch 32: Train Loss = 0.04914222601431095, Recall = 0.9897350993377484, Aging Rate = 0.5056291390728477, Precision = 0.9787164374590701, f1 = 0.9841949292064538\n",
      "Epoch 33: Train Loss = 0.05743889307590905, Recall = 0.9887417218543046, Aging Rate = 0.5061258278145695, Precision = 0.9767746156362447, f1 = 0.9827217376995229\n",
      "Epoch 34: Train Loss = 0.05158856360624168, Recall = 0.9897350993377484, Aging Rate = 0.5064569536423841, Precision = 0.977116704805492, f1 = 0.9833854252344135\n",
      "Epoch 35: Train Loss = 0.043952527829748116, Recall = 0.9900662251655629, Aging Rate = 0.503476821192053, Precision = 0.9832292009207497, f1 = 0.9866358686685365\n",
      "Test Loss = 0.03972803014299727, Recall = 0.9953642384105961, Aging Rate = 0.5061258278145695, precision = 0.9833169774288518\n",
      "\n",
      "Epoch 36: Train Loss = 0.04720469716664971, Recall = 0.9913907284768212, Aging Rate = 0.5048013245033113, Precision = 0.9819612987864874, f1 = 0.9866534849233811\n",
      "Epoch 37: Train Loss = 0.050182487068093376, Recall = 0.9903973509933774, Aging Rate = 0.5052980132450331, Precision = 0.9800131061598951, f1 = 0.9851778656126482\n",
      "Epoch 38: Train Loss = 0.05324529190331895, Recall = 0.990728476821192, Aging Rate = 0.5051324503311259, Precision = 0.9806620780072107, f1 = 0.9856695766760006\n",
      "Epoch 39: Train Loss = 0.044912762481053144, Recall = 0.9923841059602649, Aging Rate = 0.5049668874172185, Precision = 0.9826229508196721, f1 = 0.9874794069192752\n",
      "Epoch 40: Train Loss = 0.05040869250992276, Recall = 0.9887417218543046, Aging Rate = 0.5051324503311259, Precision = 0.978695509668961, f1 = 0.9836929665623455\n",
      "Test Loss = 0.041629014201215564, Recall = 0.9956953642384105, Aging Rate = 0.5096026490066226, precision = 0.9769330734243015\n",
      "\n",
      "Epoch 41: Train Loss = 0.052519760002067546, Recall = 0.9887417218543046, Aging Rate = 0.5057947019867549, Precision = 0.9774140752864157, f1 = 0.983045267489712\n",
      "Epoch 42: Train Loss = 0.0423959426162456, Recall = 0.9933774834437086, Aging Rate = 0.5043046357615895, Precision = 0.9848982271831911, f1 = 0.9891196834817013\n",
      "Epoch 43: Train Loss = 0.04623785450166425, Recall = 0.9917218543046358, Aging Rate = 0.5054635761589404, Precision = 0.9810022928267278, f1 = 0.9863329491190517\n",
      "Epoch 44: Train Loss = 0.04728622843344875, Recall = 0.990728476821192, Aging Rate = 0.5041390728476821, Precision = 0.9825944170771757, f1 = 0.9866446826051112\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45: Train Loss = 0.05307139770084659, Recall = 0.9847682119205298, Aging Rate = 0.5031456953642384, Precision = 0.9786113853241197, f1 = 0.9816801452384881\n",
      "Test Loss = 0.03702048072653101, Recall = 0.9933774834437086, Aging Rate = 0.5006622516556292, precision = 0.9920634920634921\n",
      "Model in epoch 45 is saved.\n",
      "\n",
      "Epoch 46: Train Loss = 0.0508394138653152, Recall = 0.9900662251655629, Aging Rate = 0.5039735099337749, Precision = 0.9822601839684626, f1 = 0.9861477572559366\n",
      "Epoch 47: Train Loss = 0.04635249337810554, Recall = 0.9920529801324504, Aging Rate = 0.5057947019867549, Precision = 0.9806873977086743, f1 = 0.9863374485596709\n",
      "Epoch 48: Train Loss = 0.046049839519704414, Recall = 0.9894039735099338, Aging Rate = 0.5024834437086093, Precision = 0.9845140032948929, f1 = 0.9869529314616019\n",
      "Epoch 49: Train Loss = 0.04875647713559748, Recall = 0.9910596026490066, Aging Rate = 0.5064569536423841, Precision = 0.9784243216737496, f1 = 0.9847014311564402\n",
      "Epoch 50: Train Loss = 0.04797492350470151, Recall = 0.9913907284768212, Aging Rate = 0.5041390728476821, Precision = 0.9832512315270936, f1 = 0.9873042044517726\n",
      "Test Loss = 0.04149767438578882, Recall = 0.9966887417218543, Aging Rate = 0.5096026490066226, precision = 0.9779077322936972\n",
      "\n",
      "Epoch 51: Train Loss = 0.04722218773025551, Recall = 0.9917218543046358, Aging Rate = 0.5054635761589404, Precision = 0.9810022928267278, f1 = 0.9863329491190517\n",
      "Epoch 52: Train Loss = 0.054445482060214545, Recall = 0.9844370860927152, Aging Rate = 0.5036423841059603, Precision = 0.9773175542406312, f1 = 0.9808644011877268\n",
      "Epoch 53: Train Loss = 0.044561120660494495, Recall = 0.990728476821192, Aging Rate = 0.5033112582781457, Precision = 0.9842105263157894, f1 = 0.9874587458745875\n",
      "Epoch 54: Train Loss = 0.04638333798984423, Recall = 0.9937086092715232, Aging Rate = 0.5066225165562914, Precision = 0.980718954248366, f1 = 0.9871710526315789\n",
      "Epoch 55: Train Loss = 0.04792496764304622, Recall = 0.9900662251655629, Aging Rate = 0.5043046357615895, Precision = 0.9816152330925805, f1 = 0.9858226178700956\n",
      "Test Loss = 0.047388049311294464, Recall = 0.9986754966887417, Aging Rate = 0.5145695364238411, precision = 0.9703989703989704\n",
      "\n",
      "Epoch 56: Train Loss = 0.04817891723124791, Recall = 0.9923841059602649, Aging Rate = 0.5067880794701987, Precision = 0.9790918000653381, f1 = 0.9856931425752344\n",
      "Epoch 57: Train Loss = 0.045433089420791495, Recall = 0.9927152317880795, Aging Rate = 0.5056291390728477, Precision = 0.9816633922724296, f1 = 0.9871583799802436\n",
      "Epoch 58: Train Loss = 0.04399732886659388, Recall = 0.9910596026490066, Aging Rate = 0.5038079470198675, Precision = 0.9835688465330266, f1 = 0.987300016493485\n",
      "Epoch 59: Train Loss = 0.051192063524924364, Recall = 0.9910596026490066, Aging Rate = 0.506953642384106, Precision = 0.9774657086871326, f1 = 0.9842157185136469\n",
      "Epoch 60: Train Loss = 0.04935493577913141, Recall = 0.9903973509933774, Aging Rate = 0.5046357615894039, Precision = 0.9812992125984252, f1 = 0.9858272907053395\n",
      "Test Loss = 0.030820426177110102, Recall = 0.9950331125827815, Aging Rate = 0.5021523178807947, precision = 0.9907682162875041\n",
      "\n",
      "Epoch 61: Train Loss = 0.04338161834571141, Recall = 0.9947019867549669, Aging Rate = 0.5062913907284768, Precision = 0.9823413996075867, f1 = 0.9884830536360646\n",
      "Epoch 62: Train Loss = 0.04282604728806887, Recall = 0.9937086092715232, Aging Rate = 0.5039735099337749, Precision = 0.985873850197109, f1 = 0.9897757255936676\n",
      "Epoch 63: Train Loss = 0.05344118524145409, Recall = 0.9857615894039735, Aging Rate = 0.5039735099337749, Precision = 0.9779894875164258, f1 = 0.9818601583113458\n",
      "Epoch 64: Train Loss = 0.04901266675812519, Recall = 0.9867549668874173, Aging Rate = 0.5013245033112583, Precision = 0.9841479524438573, f1 = 0.9854497354497355\n",
      "Epoch 65: Train Loss = 0.04821674695472843, Recall = 0.990728476821192, Aging Rate = 0.5041390728476821, Precision = 0.9825944170771757, f1 = 0.9866446826051112\n",
      "Test Loss = 0.03594501619011361, Recall = 0.9953642384105961, Aging Rate = 0.5036423841059603, precision = 0.9881656804733728\n",
      "\n",
      "Epoch 66: Train Loss = 0.04395662070998293, Recall = 0.990728476821192, Aging Rate = 0.5033112582781457, Precision = 0.9842105263157894, f1 = 0.9874587458745875\n",
      "Epoch 67: Train Loss = 0.05135829054954036, Recall = 0.9903973509933774, Aging Rate = 0.5064569536423841, Precision = 0.9777705132396208, f1 = 0.9840434281954269\n",
      "Epoch 68: Train Loss = 0.04373944648942411, Recall = 0.9917218543046358, Aging Rate = 0.5028145695364239, Precision = 0.986170563055647, f1 = 0.9889384183589235\n",
      "Epoch 69: Train Loss = 0.04890956465241234, Recall = 0.9910596026490066, Aging Rate = 0.5067880794701987, Precision = 0.9777850375694218, f1 = 0.9843775694787043\n",
      "Epoch 70: Train Loss = 0.04613490176714019, Recall = 0.9910596026490066, Aging Rate = 0.5031456953642384, Precision = 0.9848634419216847, f1 = 0.9879518072289155\n",
      "Test Loss = 0.0529940700688899, Recall = 0.9837748344370861, Aging Rate = 0.4991721854304636, precision = 0.9854063018242123\n",
      "\n",
      "Epoch 71: Train Loss = 0.055384545161431986, Recall = 0.9864238410596027, Aging Rate = 0.5036423841059603, Precision = 0.9792899408284024, f1 = 0.9828439458924447\n",
      "Epoch 72: Train Loss = 0.05219840602270815, Recall = 0.9874172185430463, Aging Rate = 0.5052980132450331, Precision = 0.9770642201834863, f1 = 0.9822134387351779\n",
      "Epoch 73: Train Loss = 0.04568473516858571, Recall = 0.993046357615894, Aging Rate = 0.5062913907284768, Precision = 0.9807063440156966, f1 = 0.9868377755840737\n",
      "Epoch 74: Train Loss = 0.04011833284864363, Recall = 0.9913907284768212, Aging Rate = 0.502317880794702, Precision = 0.98681608437706, f1 = 0.9890981169474728\n",
      "Epoch 75: Train Loss = 0.046997715256466774, Recall = 0.9910596026490066, Aging Rate = 0.503476821192053, Precision = 0.9842157185136469, f1 = 0.987625804322719\n",
      "Test Loss = 0.029737444256512535, Recall = 0.9980132450331126, Aging Rate = 0.503476821192053, precision = 0.9911213416639263\n",
      "Model in epoch 75 is saved.\n",
      "\n",
      "Epoch 76: Train Loss = 0.04687687445259252, Recall = 0.990728476821192, Aging Rate = 0.5044701986754967, Precision = 0.9819494584837545, f1 = 0.9863194329981869\n",
      "Epoch 77: Train Loss = 0.042558721023679566, Recall = 0.9937086092715232, Aging Rate = 0.5056291390728477, Precision = 0.9826457105435494, f1 = 0.9881461969048403\n",
      "Epoch 78: Train Loss = 0.061204380798616155, Recall = 0.9854304635761589, Aging Rate = 0.5067880794701987, Precision = 0.9722312969617772, f1 = 0.9787863838184511\n",
      "Epoch 79: Train Loss = 0.04772554708533729, Recall = 0.9897350993377484, Aging Rate = 0.5043046357615895, Precision = 0.9812869336835194, f1 = 0.985492911308935\n",
      "Epoch 80: Train Loss = 0.04312298996559042, Recall = 0.993046357615894, Aging Rate = 0.5052980132450331, Precision = 0.9826343381389253, f1 = 0.9878129117259552\n",
      "Test Loss = 0.04668540428855167, Recall = 0.9910596026490066, Aging Rate = 0.502317880794702, precision = 0.9864864864864865\n",
      "\n",
      "Epoch 81: Train Loss = 0.04250536422609099, Recall = 0.993046357615894, Aging Rate = 0.5046357615894039, Precision = 0.9839238845144357, f1 = 0.9884640738299275\n",
      "Epoch 82: Train Loss = 0.04205153733738606, Recall = 0.993046357615894, Aging Rate = 0.5039735099337749, Precision = 0.9852168199737188, f1 = 0.9891160949868073\n",
      "Epoch 83: Train Loss = 0.04968051146592525, Recall = 0.9884105960264901, Aging Rate = 0.5036423841059603, Precision = 0.9812623274161736, f1 = 0.9848234905971627\n",
      "Epoch 84: Train Loss = 0.04253586174932537, Recall = 0.9943708609271523, Aging Rate = 0.5061258278145695, Precision = 0.9823356231599607, f1 = 0.9883166035872963\n",
      "Epoch 85: Train Loss = 0.04481265474086171, Recall = 0.9927152317880795, Aging Rate = 0.5052980132450331, Precision = 0.9823066841415465, f1 = 0.9874835309617919\n",
      "Test Loss = 0.07289473313764232, Recall = 0.9956953642384105, Aging Rate = 0.5256622516556292, precision = 0.9470866141732284\n",
      "\n",
      "Epoch 86: Train Loss = 0.04614305859369947, Recall = 0.9913907284768212, Aging Rate = 0.5046357615894039, Precision = 0.9822834645669292, f1 = 0.98681608437706\n",
      "Epoch 87: Train Loss = 0.04342797383764722, Recall = 0.9920529801324504, Aging Rate = 0.5036423841059603, Precision = 0.9848783694937541, f1 = 0.9884526558891455\n",
      "Epoch 88: Train Loss = 0.045242368947985945, Recall = 0.9920529801324504, Aging Rate = 0.5033112582781457, Precision = 0.9855263157894737, f1 = 0.9887788778877888\n",
      "Epoch 89: Train Loss = 0.04815827084840923, Recall = 0.9943708609271523, Aging Rate = 0.5077814569536424, Precision = 0.9791327029670688, f1 = 0.9866929521931986\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 90: Train Loss = 0.04551449072430071, Recall = 0.9920529801324504, Aging Rate = 0.5043046357615895, Precision = 0.9835850295469468, f1 = 0.9878008572370589\n",
      "Test Loss = 0.03546614358016592, Recall = 0.9950331125827815, Aging Rate = 0.5016556291390728, precision = 0.9917491749174917\n",
      "\n",
      "Epoch 91: Train Loss = 0.05633967999886993, Recall = 0.9870860927152317, Aging Rate = 0.5064569536423841, Precision = 0.9745014710689768, f1 = 0.9807534133903603\n",
      "Epoch 92: Train Loss = 0.04457591539433855, Recall = 0.9923841059602649, Aging Rate = 0.5051324503311259, Precision = 0.9823008849557522, f1 = 0.9873167517707132\n",
      "Epoch 93: Train Loss = 0.047458082526330124, Recall = 0.9910596026490066, Aging Rate = 0.5052980132450331, Precision = 0.9806684141546527, f1 = 0.985836627140975\n",
      "Epoch 94: Train Loss = 0.052034058939936935, Recall = 0.9900662251655629, Aging Rate = 0.5054635761589404, Precision = 0.9793645594497216, f1 = 0.9846863164827927\n",
      "Epoch 95: Train Loss = 0.04376033844475616, Recall = 0.9943708609271523, Aging Rate = 0.5066225165562914, Precision = 0.9813725490196078, f1 = 0.9878289473684211\n",
      "Test Loss = 0.037908032906568606, Recall = 0.9966887417218543, Aging Rate = 0.5061258278145695, precision = 0.9846254497873732\n",
      "\n",
      "Epoch 96: Train Loss = 0.04292060726427085, Recall = 0.993046357615894, Aging Rate = 0.5041390728476821, Precision = 0.9848932676518883, f1 = 0.9889530090684254\n",
      "Epoch 97: Train Loss = 0.05240111266392351, Recall = 0.9890728476821192, Aging Rate = 0.5054635761589404, Precision = 0.9783819194235178, f1 = 0.9836983369010374\n",
      "Epoch 98: Train Loss = 0.046836360090023635, Recall = 0.9923841059602649, Aging Rate = 0.5064569536423841, Precision = 0.9797319385420072, f1 = 0.9860174370784668\n",
      "Epoch 99: Train Loss = 0.0449295605082583, Recall = 0.9900662251655629, Aging Rate = 0.503476821192053, Precision = 0.9832292009207497, f1 = 0.9866358686685365\n",
      "Epoch 100: Train Loss = 0.046069503481814406, Recall = 0.9913907284768212, Aging Rate = 0.5054635761589404, Precision = 0.9806747461513265, f1 = 0.9860036225917999\n",
      "Test Loss = 0.0316738869600146, Recall = 0.9950331125827815, Aging Rate = 0.5038079470198675, precision = 0.9875123233651002\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ae9cc3b689941488ce77552cbb48154",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss = 0.37600175477811043, Recall = 0.8847682119205298, Aging Rate = 0.575, Precision = 0.7693636625395911, f1 = 0.8230401971353767\n",
      "Epoch 2: Train Loss = 0.19350770674399193, Recall = 0.952317880794702, Aging Rate = 0.5306291390728477, Precision = 0.8973478939157566, f1 = 0.9240160642570281\n",
      "Epoch 3: Train Loss = 0.15004702756144353, Recall = 0.9579470198675497, Aging Rate = 0.516887417218543, Precision = 0.9266495836002563, f1 = 0.9420384239661348\n",
      "Epoch 4: Train Loss = 0.13432239193395273, Recall = 0.9559602649006622, Aging Rate = 0.5122516556291391, Precision = 0.9330963154492566, f1 = 0.9443899247628394\n",
      "Epoch 5: Train Loss = 0.12513473640806627, Recall = 0.9622516556291391, Aging Rate = 0.510430463576159, Precision = 0.9425883879338307, f1 = 0.9523185318695724\n",
      "Test Loss = 0.06731559553288466, Recall = 0.9943708609271523, Aging Rate = 0.5142384105960265, precision = 0.9668383773341919\n",
      "Model in epoch 5 is saved.\n",
      "\n",
      "Epoch 6: Train Loss = 0.07006235885501698, Recall = 0.9850993377483444, Aging Rate = 0.5071192052980132, Precision = 0.9712699967352268, f1 = 0.9781357882623706\n",
      "Epoch 7: Train Loss = 0.06274202054995574, Recall = 0.9850993377483444, Aging Rate = 0.5051324503311259, Precision = 0.9750901343821697, f1 = 0.9800691813539779\n",
      "Epoch 8: Train Loss = 0.05836175886901799, Recall = 0.9870860927152317, Aging Rate = 0.5049668874172185, Precision = 0.9773770491803279, f1 = 0.9822075782537067\n",
      "Epoch 9: Train Loss = 0.05789271886182937, Recall = 0.9864238410596027, Aging Rate = 0.5054635761589404, Precision = 0.9757615460203078, f1 = 0.9810637246830232\n",
      "Epoch 10: Train Loss = 0.05757924049155207, Recall = 0.9880794701986755, Aging Rate = 0.5057947019867549, Precision = 0.976759410801964, f1 = 0.9823868312757202\n",
      "Test Loss = 0.03438516783941266, Recall = 0.9950331125827815, Aging Rate = 0.503476821192053, precision = 0.9881617888852351\n",
      "Model in epoch 10 is saved.\n",
      "\n",
      "Epoch 11: Train Loss = 0.060017218736820664, Recall = 0.9854304635761589, Aging Rate = 0.5046357615894039, Precision = 0.9763779527559056, f1 = 0.980883322346737\n",
      "Epoch 12: Train Loss = 0.05211009397017245, Recall = 0.9890728476821192, Aging Rate = 0.5049668874172185, Precision = 0.979344262295082, f1 = 0.984184514003295\n",
      "Epoch 13: Train Loss = 0.05456330104922222, Recall = 0.9880794701986755, Aging Rate = 0.5056291390728477, Precision = 0.977079240340537, f1 = 0.9825485676654593\n",
      "Epoch 14: Train Loss = 0.05083543835639559, Recall = 0.9910596026490066, Aging Rate = 0.5054635761589404, Precision = 0.9803471994759253, f1 = 0.985674296064548\n",
      "Epoch 15: Train Loss = 0.06446913574507694, Recall = 0.9844370860927152, Aging Rate = 0.5046357615894039, Precision = 0.9753937007874016, f1 = 0.9798945286750165\n",
      "Test Loss = 0.08279105834416206, Recall = 0.9602649006622517, Aging Rate = 0.4872516556291391, precision = 0.9853890587835542\n",
      "\n",
      "Epoch 16: Train Loss = 0.05419097209707001, Recall = 0.9890728476821192, Aging Rate = 0.5051324503311259, Precision = 0.9790232710586693, f1 = 0.9840224015812882\n",
      "Epoch 17: Train Loss = 0.05373106158727052, Recall = 0.9894039735099338, Aging Rate = 0.5066225165562914, Precision = 0.9764705882352941, f1 = 0.9828947368421052\n",
      "Epoch 18: Train Loss = 0.054222671571650255, Recall = 0.9880794701986755, Aging Rate = 0.5054635761589404, Precision = 0.9773992793973141, f1 = 0.982710357319282\n",
      "Epoch 19: Train Loss = 0.04721471631517079, Recall = 0.9913907284768212, Aging Rate = 0.5044701986754967, Precision = 0.982605841811618, f1 = 0.9869787374320093\n",
      "Epoch 20: Train Loss = 0.051298625757362666, Recall = 0.9897350993377484, Aging Rate = 0.5057947019867549, Precision = 0.9783960720130933, f1 = 0.9840329218106997\n",
      "Test Loss = 0.04442863329652919, Recall = 0.9947019867549669, Aging Rate = 0.5077814569536424, precision = 0.9794587544832083\n",
      "\n",
      "Epoch 21: Train Loss = 0.051255791086629525, Recall = 0.9897350993377484, Aging Rate = 0.5048013245033113, Precision = 0.9803214168579862, f1 = 0.9850057670126874\n",
      "Epoch 22: Train Loss = 0.0578273125658959, Recall = 0.9874172185430463, Aging Rate = 0.5052980132450331, Precision = 0.9770642201834863, f1 = 0.9822134387351779\n",
      "Epoch 23: Train Loss = 0.05425690506023682, Recall = 0.9890728476821192, Aging Rate = 0.5048013245033113, Precision = 0.9796654640865857, f1 = 0.98434667984841\n",
      "Epoch 24: Train Loss = 0.04686793482412171, Recall = 0.9903973509933774, Aging Rate = 0.5038079470198675, Precision = 0.9829116003943477, f1 = 0.9866402770905492\n",
      "Epoch 25: Train Loss = 0.049183428655100975, Recall = 0.990728476821192, Aging Rate = 0.5046357615894039, Precision = 0.9816272965879265, f1 = 0.986156888595913\n",
      "Test Loss = 0.04361941965901299, Recall = 0.9940397350993377, Aging Rate = 0.5062913907284768, precision = 0.9816873773708306\n",
      "\n",
      "Epoch 26: Train Loss = 0.046751554334992604, Recall = 0.9910596026490066, Aging Rate = 0.5049668874172185, Precision = 0.9813114754098361, f1 = 0.986161449752883\n",
      "Epoch 27: Train Loss = 0.05664009233159537, Recall = 0.9864238410596027, Aging Rate = 0.503476821192053, Precision = 0.9796119697467938, f1 = 0.9830061046032008\n",
      "Epoch 28: Train Loss = 0.045168729698815885, Recall = 0.9923841059602649, Aging Rate = 0.5048013245033113, Precision = 0.9829452279435881, f1 = 0.9876421156697974\n",
      "Epoch 29: Train Loss = 0.0527488403972115, Recall = 0.9870860927152317, Aging Rate = 0.5044701986754967, Precision = 0.9783393501805054, f1 = 0.9826932586121642\n",
      "Epoch 30: Train Loss = 0.05265888477496754, Recall = 0.9874172185430463, Aging Rate = 0.5051324503311259, Precision = 0.9773844641101278, f1 = 0.9823752264865755\n",
      "Test Loss = 0.03923222204756658, Recall = 0.9960264900662251, Aging Rate = 0.5059602649006623, precision = 0.9842931937172775\n",
      "\n",
      "Epoch 31: Train Loss = 0.047852671509053535, Recall = 0.9894039735099338, Aging Rate = 0.5041390728476821, Precision = 0.9812807881773399, f1 = 0.9853256389117889\n",
      "Epoch 32: Train Loss = 0.04931367266158394, Recall = 0.9900662251655629, Aging Rate = 0.503476821192053, Precision = 0.9832292009207497, f1 = 0.9866358686685365\n",
      "Epoch 33: Train Loss = 0.049495371894923264, Recall = 0.9910596026490066, Aging Rate = 0.5031456953642384, Precision = 0.9848634419216847, f1 = 0.9879518072289155\n",
      "Epoch 34: Train Loss = 0.04868685232093003, Recall = 0.9900662251655629, Aging Rate = 0.5046357615894039, Precision = 0.9809711286089239, f1 = 0.985497692814766\n",
      "Epoch 35: Train Loss = 0.05062638811816443, Recall = 0.9900662251655629, Aging Rate = 0.5049668874172185, Precision = 0.980327868852459, f1 = 0.9851729818780889\n",
      "Test Loss = 0.053973470988455195, Recall = 0.9993377483443708, Aging Rate = 0.5185430463576159, precision = 0.9636015325670498\n",
      "\n",
      "Epoch 36: Train Loss = 0.04399018709529315, Recall = 0.9923841059602649, Aging Rate = 0.5033112582781457, Precision = 0.9858552631578947, f1 = 0.9891089108910891\n",
      "Epoch 37: Train Loss = 0.049667188495594934, Recall = 0.9894039735099338, Aging Rate = 0.5044701986754967, Precision = 0.9806366918280276, f1 = 0.9850008241305422\n",
      "Epoch 38: Train Loss = 0.048851615817760985, Recall = 0.9913907284768212, Aging Rate = 0.5054635761589404, Precision = 0.9806747461513265, f1 = 0.9860036225917999\n",
      "Epoch 39: Train Loss = 0.0449632577104679, Recall = 0.9920529801324504, Aging Rate = 0.5041390728476821, Precision = 0.9839080459770115, f1 = 0.9879637262984335\n",
      "Epoch 40: Train Loss = 0.04893971900671523, Recall = 0.990728476821192, Aging Rate = 0.5048013245033113, Precision = 0.9813053460150869, f1 = 0.9859943977591037\n",
      "Test Loss = 0.09885826420951759, Recall = 0.9417218543046357, Aging Rate = 0.47135761589403974, precision = 0.9989462592202318\n",
      "\n",
      "Epoch 41: Train Loss = 0.05227973726115479, Recall = 0.9887417218543046, Aging Rate = 0.5036423841059603, Precision = 0.9815910585141354, f1 = 0.9851534147146156\n",
      "Epoch 42: Train Loss = 0.05319146207527609, Recall = 0.9884105960264901, Aging Rate = 0.5046357615894039, Precision = 0.9793307086614174, f1 = 0.9838497033618985\n",
      "Epoch 43: Train Loss = 0.046438949875878974, Recall = 0.9917218543046358, Aging Rate = 0.5051324503311259, Precision = 0.9816453621763356, f1 = 0.9866578817328281\n",
      "Epoch 44: Train Loss = 0.047249503285679596, Recall = 0.9910596026490066, Aging Rate = 0.5036423841059603, Precision = 0.9838921761998685, f1 = 0.9874628835367865\n",
      "Epoch 45: Train Loss = 0.05211850674391188, Recall = 0.9897350993377484, Aging Rate = 0.5067880794701987, Precision = 0.9764782750735054, f1 = 0.983061996382174\n",
      "Test Loss = 0.03343743370068784, Recall = 0.9970198675496689, Aging Rate = 0.5048013245033113, precision = 0.9875368973433912\n",
      "Model in epoch 45 is saved.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 46: Train Loss = 0.05110758609132261, Recall = 0.9890728476821192, Aging Rate = 0.5052980132450331, Precision = 0.97870249017038, f1 = 0.9838603425559946\n",
      "Epoch 47: Train Loss = 0.04656490403048645, Recall = 0.9903973509933774, Aging Rate = 0.5033112582781457, Precision = 0.9838815789473684, f1 = 0.9871287128712871\n",
      "Epoch 48: Train Loss = 0.048649551166801266, Recall = 0.9900662251655629, Aging Rate = 0.5033112582781457, Precision = 0.9835526315789473, f1 = 0.9867986798679869\n",
      "Epoch 49: Train Loss = 0.04563238374543506, Recall = 0.9917218543046358, Aging Rate = 0.5046357615894039, Precision = 0.9826115485564304, f1 = 0.9871456822676334\n",
      "Epoch 50: Train Loss = 0.046679174374566965, Recall = 0.9917218543046358, Aging Rate = 0.5036423841059603, Precision = 0.9845496383957922, f1 = 0.9881227317716924\n",
      "Test Loss = 0.048938044394977044, Recall = 0.9821192052980132, Aging Rate = 0.4925496688741722, precision = 0.9969747899159664\n",
      "Model in epoch 50 is saved.\n",
      "\n",
      "Epoch 51: Train Loss = 0.04537013832060312, Recall = 0.9933774834437086, Aging Rate = 0.5046357615894039, Precision = 0.984251968503937, f1 = 0.988793671720501\n",
      "Epoch 52: Train Loss = 0.04672212170696022, Recall = 0.9920529801324504, Aging Rate = 0.5038079470198675, Precision = 0.984554715741045, f1 = 0.9882896255978889\n",
      "Epoch 53: Train Loss = 0.04393044456543512, Recall = 0.9937086092715232, Aging Rate = 0.5051324503311259, Precision = 0.9836119305145854, f1 = 0.9886344918464833\n",
      "Epoch 54: Train Loss = 0.050387756306900094, Recall = 0.9897350993377484, Aging Rate = 0.5041390728476821, Precision = 0.9816091954022989, f1 = 0.9856553998351195\n",
      "Epoch 55: Train Loss = 0.049683081894027474, Recall = 0.9910596026490066, Aging Rate = 0.5064569536423841, Precision = 0.9784243216737496, f1 = 0.9847014311564402\n",
      "Test Loss = 0.0548178858117552, Recall = 0.9811258278145696, Aging Rate = 0.4943708609271523, precision = 0.9922973878097789\n",
      "\n",
      "Epoch 56: Train Loss = 0.044071743220386914, Recall = 0.9910596026490066, Aging Rate = 0.5031456953642384, Precision = 0.9848634419216847, f1 = 0.9879518072289155\n",
      "Epoch 57: Train Loss = 0.046069024745004857, Recall = 0.9923841059602649, Aging Rate = 0.5046357615894039, Precision = 0.9832677165354331, f1 = 0.9878048780487805\n",
      "Epoch 58: Train Loss = 0.04492481090621838, Recall = 0.9920529801324504, Aging Rate = 0.5048013245033113, Precision = 0.9826172515578878, f1 = 0.9873125720876587\n",
      "Epoch 59: Train Loss = 0.04490678789501159, Recall = 0.9923841059602649, Aging Rate = 0.5043046357615895, Precision = 0.9839133289560079, f1 = 0.9881305637982195\n",
      "Epoch 60: Train Loss = 0.048541485528085404, Recall = 0.9894039735099338, Aging Rate = 0.5031456953642384, Precision = 0.983218163869694, f1 = 0.9863013698630138\n",
      "Test Loss = 0.09479519947869888, Recall = 0.9433774834437086, Aging Rate = 0.4725165562913907, precision = 0.9982480728801681\n",
      "\n",
      "Epoch 61: Train Loss = 0.05090985368468509, Recall = 0.9894039735099338, Aging Rate = 0.5038079470198675, Precision = 0.9819257311863293, f1 = 0.9856506679861456\n",
      "Epoch 62: Train Loss = 0.04568637340570128, Recall = 0.9913907284768212, Aging Rate = 0.5043046357615895, Precision = 0.9829284307288247, f1 = 0.9871414441147379\n",
      "Epoch 63: Train Loss = 0.05292433135655542, Recall = 0.9903973509933774, Aging Rate = 0.5064569536423841, Precision = 0.9777705132396208, f1 = 0.9840434281954269\n",
      "Epoch 64: Train Loss = 0.045210923792313264, Recall = 0.9913907284768212, Aging Rate = 0.5048013245033113, Precision = 0.9819612987864874, f1 = 0.9866534849233811\n",
      "Epoch 65: Train Loss = 0.052667867177665625, Recall = 0.9867549668874173, Aging Rate = 0.5044701986754967, Precision = 0.9780111585165737, f1 = 0.982363606395253\n",
      "Test Loss = 0.04204734587511479, Recall = 0.9854304635761589, Aging Rate = 0.4958609271523179, precision = 0.9936560934891486\n",
      "\n",
      "Epoch 66: Train Loss = 0.045841521809235314, Recall = 0.9917218543046358, Aging Rate = 0.5044701986754967, Precision = 0.9829340334755498, f1 = 0.9873083896489203\n",
      "Epoch 67: Train Loss = 0.047597935568812665, Recall = 0.9917218543046358, Aging Rate = 0.5043046357615895, Precision = 0.9832567301378857, f1 = 0.9874711506758984\n",
      "Epoch 68: Train Loss = 0.04467055271595519, Recall = 0.9913907284768212, Aging Rate = 0.503476821192053, Precision = 0.9845445577112791, f1 = 0.9879557828741132\n",
      "Epoch 69: Train Loss = 0.04430170733456975, Recall = 0.9920529801324504, Aging Rate = 0.5044701986754967, Precision = 0.9832622251394815, f1 = 0.9876380418658315\n",
      "Epoch 70: Train Loss = 0.043092330784493725, Recall = 0.9927152317880795, Aging Rate = 0.5043046357615895, Precision = 0.9842416283650689, f1 = 0.9884602703593801\n",
      "Test Loss = 0.0502879166531543, Recall = 0.9768211920529801, Aging Rate = 0.4913907284768212, precision = 0.9939353099730458\n",
      "\n",
      "Epoch 71: Train Loss = 0.048979447113461055, Recall = 0.9897350993377484, Aging Rate = 0.5043046357615895, Precision = 0.9812869336835194, f1 = 0.985492911308935\n",
      "Epoch 72: Train Loss = 0.04595139363521574, Recall = 0.9923841059602649, Aging Rate = 0.5048013245033113, Precision = 0.9829452279435881, f1 = 0.9876421156697974\n",
      "Epoch 73: Train Loss = 0.04272794270308207, Recall = 0.9910596026490066, Aging Rate = 0.5031456953642384, Precision = 0.9848634419216847, f1 = 0.9879518072289155\n",
      "Epoch 74: Train Loss = 0.044897345707609955, Recall = 0.9917218543046358, Aging Rate = 0.5036423841059603, Precision = 0.9845496383957922, f1 = 0.9881227317716924\n",
      "Epoch 75: Train Loss = 0.04764443403541647, Recall = 0.9897350993377484, Aging Rate = 0.5036423841059603, Precision = 0.982577251808021, f1 = 0.9861431870669747\n",
      "Test Loss = 0.03725649034049337, Recall = 0.997682119205298, Aging Rate = 0.5062913907284768, precision = 0.9852844996729889\n",
      "\n",
      "Epoch 76: Train Loss = 0.04271970959688654, Recall = 0.9927152317880795, Aging Rate = 0.5036423841059603, Precision = 0.9855358316896778, f1 = 0.9891125041240515\n",
      "Epoch 77: Train Loss = 0.05051476823178348, Recall = 0.9894039735099338, Aging Rate = 0.5044701986754967, Precision = 0.9806366918280276, f1 = 0.9850008241305422\n",
      "Epoch 78: Train Loss = 0.04468153335696814, Recall = 0.990728476821192, Aging Rate = 0.5036423841059603, Precision = 0.9835634451019066, f1 = 0.9871329594193334\n",
      "Epoch 79: Train Loss = 0.049884602272056586, Recall = 0.9874172185430463, Aging Rate = 0.5038079470198675, Precision = 0.9799539927702925, f1 = 0.9836714497773379\n",
      "Epoch 80: Train Loss = 0.04458933156353748, Recall = 0.9903973509933774, Aging Rate = 0.5039735099337749, Precision = 0.9825886990801577, f1 = 0.9864775725593667\n",
      "Test Loss = 0.04320332514035781, Recall = 0.9894039735099338, Aging Rate = 0.4996688741721854, precision = 0.9900596421471173\n",
      "\n",
      "Epoch 81: Train Loss = 0.04272297749801582, Recall = 0.9937086092715232, Aging Rate = 0.5041390728476821, Precision = 0.9855500821018063, f1 = 0.9896125309150865\n",
      "Epoch 82: Train Loss = 0.04579441557508825, Recall = 0.9913907284768212, Aging Rate = 0.5056291390728477, Precision = 0.9803536345776032, f1 = 0.9858412907474481\n",
      "Epoch 83: Train Loss = 0.04397137316301564, Recall = 0.9917218543046358, Aging Rate = 0.5052980132450331, Precision = 0.9813237221494102, f1 = 0.9864953886693016\n",
      "Epoch 84: Train Loss = 0.044473434274165044, Recall = 0.9900662251655629, Aging Rate = 0.5036423841059603, Precision = 0.9829059829059829, f1 = 0.9864731111844275\n",
      "Epoch 85: Train Loss = 0.049570033936113714, Recall = 0.9913907284768212, Aging Rate = 0.5036423841059603, Precision = 0.9842209072978304, f1 = 0.9877928076542396\n",
      "Test Loss = 0.03652404170508022, Recall = 0.997682119205298, Aging Rate = 0.508112582781457, precision = 0.9817530140110785\n",
      "\n",
      "Epoch 86: Train Loss = 0.05176594093047231, Recall = 0.9880794701986755, Aging Rate = 0.5041390728476821, Precision = 0.9799671592775041, f1 = 0.9840065952184667\n",
      "Epoch 87: Train Loss = 0.03905845729769855, Recall = 0.9943708609271523, Aging Rate = 0.5046357615894039, Precision = 0.985236220472441, f1 = 0.9897824653922215\n",
      "Epoch 88: Train Loss = 0.0428000234560856, Recall = 0.9923841059602649, Aging Rate = 0.5041390728476821, Precision = 0.9842364532019704, f1 = 0.9882934872217642\n",
      "Epoch 89: Train Loss = 0.04176935875011201, Recall = 0.9940397350993377, Aging Rate = 0.5044701986754967, Precision = 0.9852313751230719, f1 = 0.9896159551672985\n",
      "Epoch 90: Train Loss = 0.046530162197667244, Recall = 0.9920529801324504, Aging Rate = 0.5054635761589404, Precision = 0.981329839502129, f1 = 0.9866622756463034\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss = 0.05499746691410905, Recall = 0.9874172185430463, Aging Rate = 0.503476821192053, precision = 0.9805984873396909\n",
      "\n",
      "Epoch 91: Train Loss = 0.05815988820021516, Recall = 0.9884105960264901, Aging Rate = 0.506953642384106, Precision = 0.9748530372305683, f1 = 0.981585004932588\n",
      "Epoch 92: Train Loss = 0.04323580525322071, Recall = 0.9923841059602649, Aging Rate = 0.5051324503311259, Precision = 0.9823008849557522, f1 = 0.9873167517707132\n",
      "Epoch 93: Train Loss = 0.04368025112329729, Recall = 0.9913907284768212, Aging Rate = 0.5029801324503311, Precision = 0.9855167873601053, f1 = 0.9884450313634863\n",
      "Epoch 94: Train Loss = 0.04918838254860695, Recall = 0.9900662251655629, Aging Rate = 0.5049668874172185, Precision = 0.980327868852459, f1 = 0.9851729818780889\n",
      "Epoch 95: Train Loss = 0.04514197189336186, Recall = 0.9913907284768212, Aging Rate = 0.5044701986754967, Precision = 0.982605841811618, f1 = 0.9869787374320093\n",
      "Test Loss = 0.03318593485268536, Recall = 0.9956953642384105, Aging Rate = 0.5033112582781457, precision = 0.9891447368421052\n",
      "\n",
      "Epoch 96: Train Loss = 0.04701886274512635, Recall = 0.9913907284768212, Aging Rate = 0.5044701986754967, Precision = 0.982605841811618, f1 = 0.9869787374320093\n",
      "Epoch 97: Train Loss = 0.044544582828780675, Recall = 0.9910596026490066, Aging Rate = 0.5041390728476821, Precision = 0.9829228243021346, f1 = 0.9869744435284419\n",
      "Epoch 98: Train Loss = 0.04106782040749954, Recall = 0.9920529801324504, Aging Rate = 0.5031456953642384, Precision = 0.9858506087528792, f1 = 0.9889420696484569\n",
      "Epoch 99: Train Loss = 0.04858144319166016, Recall = 0.9917218543046358, Aging Rate = 0.5051324503311259, Precision = 0.9816453621763356, f1 = 0.9866578817328281\n",
      "Epoch 100: Train Loss = 0.04102736560023384, Recall = 0.9937086092715232, Aging Rate = 0.5036423841059603, Precision = 0.9865220249835635, f1 = 0.9901022764764105\n",
      "Test Loss = 0.035148239811722014, Recall = 0.9966887417218543, Aging Rate = 0.5021523178807947, precision = 0.9924167490933069\n",
      "Model in epoch 100 is saved.\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "79ad71032bb04db9a5d35d52276dd76f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss = 0.37638473848238685, Recall = 0.8980132450331125, Aging Rate = 0.5824503311258278, Precision = 0.770892552586697, f1 = 0.8296115019883756\n",
      "Epoch 2: Train Loss = 0.2012529752507115, Recall = 0.9456953642384106, Aging Rate = 0.5269867549668874, Precision = 0.8972667295004713, f1 = 0.9208447525390939\n",
      "Epoch 3: Train Loss = 0.158561916382897, Recall = 0.9549668874172186, Aging Rate = 0.5178807947019868, Precision = 0.921994884910486, f1 = 0.9381912817176319\n",
      "Epoch 4: Train Loss = 0.13203405643141033, Recall = 0.9615894039735099, Aging Rate = 0.5129139072847683, Precision = 0.9373789541639768, f1 = 0.9493298463550178\n",
      "Epoch 5: Train Loss = 0.13103973369132604, Recall = 0.964569536423841, Aging Rate = 0.5139072847682119, Precision = 0.9384664948453608, f1 = 0.9513389941214891\n",
      "Test Loss = 0.08592773844666829, Recall = 0.9599337748344371, Aging Rate = 0.4862582781456954, precision = 0.9870616275110657\n",
      "Model in epoch 5 is saved.\n",
      "\n",
      "Epoch 6: Train Loss = 0.07162021440978082, Recall = 0.9834437086092715, Aging Rate = 0.5071192052980132, Precision = 0.9696376101860921, f1 = 0.976491862567812\n",
      "Epoch 7: Train Loss = 0.06101252736881474, Recall = 0.9887417218543046, Aging Rate = 0.506953642384106, Precision = 0.9751796211626388, f1 = 0.9819138441302204\n",
      "Epoch 8: Train Loss = 0.061512772119696565, Recall = 0.9847682119205298, Aging Rate = 0.5059602649006623, Precision = 0.9731675392670157, f1 = 0.9789335088874259\n",
      "Epoch 9: Train Loss = 0.05997022538637089, Recall = 0.9880794701986755, Aging Rate = 0.5074503311258278, Precision = 0.9735725938009788, f1 = 0.9807723911257189\n",
      "Epoch 10: Train Loss = 0.06408213222559714, Recall = 0.9844370860927152, Aging Rate = 0.5064569536423841, Precision = 0.9718862373324616, f1 = 0.978121401546307\n",
      "Test Loss = 0.04285422239872004, Recall = 0.9894039735099338, Aging Rate = 0.4998344370860927, precision = 0.9897316992381583\n",
      "Model in epoch 10 is saved.\n",
      "\n",
      "Epoch 11: Train Loss = 0.061942874919006366, Recall = 0.9834437086092715, Aging Rate = 0.5048013245033113, Precision = 0.9740898655296819, f1 = 0.9787444389520514\n",
      "Epoch 12: Train Loss = 0.0544569181340025, Recall = 0.9897350993377484, Aging Rate = 0.5077814569536424, Precision = 0.9745679817411151, f1 = 0.9820929850501069\n",
      "Epoch 13: Train Loss = 0.054214092235494137, Recall = 0.9894039735099338, Aging Rate = 0.5051324503311259, Precision = 0.9793510324483776, f1 = 0.9843518366002306\n",
      "Epoch 14: Train Loss = 0.057755001071865195, Recall = 0.9884105960264901, Aging Rate = 0.5061258278145695, Precision = 0.9764474975466143, f1 = 0.9823926279414185\n",
      "Epoch 15: Train Loss = 0.06368635934561688, Recall = 0.9854304635761589, Aging Rate = 0.5077814569536424, Precision = 0.9703293120313009, f1 = 0.9778215869886643\n",
      "Test Loss = 0.054122797515712036, Recall = 0.9973509933774835, Aging Rate = 0.518046357615894, precision = 0.962607861936721\n",
      "\n",
      "Epoch 16: Train Loss = 0.05115097098989992, Recall = 0.9897350993377484, Aging Rate = 0.5059602649006623, Precision = 0.9780759162303665, f1 = 0.9838709677419355\n",
      "Epoch 17: Train Loss = 0.0487002112859527, Recall = 0.9900662251655629, Aging Rate = 0.5044701986754967, Precision = 0.981293075155891, f1 = 0.9856601285643646\n",
      "Epoch 18: Train Loss = 0.0593065855346176, Recall = 0.9887417218543046, Aging Rate = 0.5067880794701987, Precision = 0.9754982032015681, f1 = 0.9820753165597763\n",
      "Epoch 19: Train Loss = 0.055834942996896654, Recall = 0.9857615894039735, Aging Rate = 0.5038079470198675, Precision = 0.9783108774235951, f1 = 0.9820221012699983\n",
      "Epoch 20: Train Loss = 0.05129190172185961, Recall = 0.9890728476821192, Aging Rate = 0.5043046357615895, Precision = 0.9806303348653972, f1 = 0.9848334981866138\n",
      "Test Loss = 0.04008808750289165, Recall = 0.993046357615894, Aging Rate = 0.5009933774834437, precision = 0.9910773298083279\n",
      "Model in epoch 20 is saved.\n",
      "\n",
      "Epoch 21: Train Loss = 0.05406178291516983, Recall = 0.9854304635761589, Aging Rate = 0.5031456953642384, Precision = 0.9792694965449161, f1 = 0.982340320184849\n",
      "Epoch 22: Train Loss = 0.051912307134823296, Recall = 0.9897350993377484, Aging Rate = 0.5044701986754967, Precision = 0.9809648834919593, f1 = 0.9853304763474535\n",
      "Epoch 23: Train Loss = 0.05066052480841315, Recall = 0.9913907284768212, Aging Rate = 0.5062913907284768, Precision = 0.9790712884238064, f1 = 0.9851924975320829\n",
      "Epoch 24: Train Loss = 0.04664687510357787, Recall = 0.993046357615894, Aging Rate = 0.5072847682119205, Precision = 0.9787859007832899, f1 = 0.9858645627876398\n",
      "Epoch 25: Train Loss = 0.04852555964808196, Recall = 0.9913907284768212, Aging Rate = 0.5051324503311259, Precision = 0.9813176007866273, f1 = 0.9863284467138858\n",
      "Test Loss = 0.06632271772188857, Recall = 0.976158940397351, Aging Rate = 0.49271523178807947, precision = 0.9905913978494624\n",
      "\n",
      "Epoch 26: Train Loss = 0.05702413764615722, Recall = 0.9877483443708609, Aging Rate = 0.5059602649006623, Precision = 0.9761125654450262, f1 = 0.9818959842001317\n",
      "Epoch 27: Train Loss = 0.05472891291492427, Recall = 0.9877483443708609, Aging Rate = 0.5041390728476821, Precision = 0.9796387520525451, f1 = 0.983676834295136\n",
      "Epoch 28: Train Loss = 0.05170711609010665, Recall = 0.9894039735099338, Aging Rate = 0.5048013245033113, Precision = 0.979993440472286, f1 = 0.9846762234305486\n",
      "Epoch 29: Train Loss = 0.05375367281896784, Recall = 0.9870860927152317, Aging Rate = 0.5046357615894039, Precision = 0.9780183727034121, f1 = 0.9825313117996044\n",
      "Epoch 30: Train Loss = 0.05311540997284927, Recall = 0.9894039735099338, Aging Rate = 0.5046357615894039, Precision = 0.9803149606299213, f1 = 0.984838497033619\n",
      "Test Loss = 0.03802250805033359, Recall = 0.9956953642384105, Aging Rate = 0.5036423841059603, precision = 0.9884944115713347\n",
      "\n",
      "Epoch 31: Train Loss = 0.05254997419600455, Recall = 0.9884105960264901, Aging Rate = 0.5054635761589404, Precision = 0.9777268260727153, f1 = 0.9830396838465338\n",
      "Epoch 32: Train Loss = 0.04389393907780482, Recall = 0.9953642384105961, Aging Rate = 0.5054635761589404, Precision = 0.9846053062561415, f1 = 0.989955540918821\n",
      "Epoch 33: Train Loss = 0.04769551373574118, Recall = 0.9913907284768212, Aging Rate = 0.5052980132450331, Precision = 0.9809960681520314, f1 = 0.9861660079051383\n",
      "Epoch 34: Train Loss = 0.04682666621362137, Recall = 0.9920529801324504, Aging Rate = 0.5049668874172185, Precision = 0.9822950819672132, f1 = 0.9871499176276771\n",
      "Epoch 35: Train Loss = 0.04790681362990907, Recall = 0.9910596026490066, Aging Rate = 0.5054635761589404, Precision = 0.9803471994759253, f1 = 0.985674296064548\n",
      "Test Loss = 0.03399862908196962, Recall = 0.9943708609271523, Aging Rate = 0.5008278145695364, precision = 0.9927272727272727\n",
      "Model in epoch 35 is saved.\n",
      "\n",
      "Epoch 36: Train Loss = 0.04569161964568081, Recall = 0.9927152317880795, Aging Rate = 0.5046357615894039, Precision = 0.9835958005249343, f1 = 0.988134475939354\n",
      "Epoch 37: Train Loss = 0.05250574511704066, Recall = 0.9880794701986755, Aging Rate = 0.5033112582781457, Precision = 0.9815789473684211, f1 = 0.9848184818481849\n",
      "Epoch 38: Train Loss = 0.046476239054803026, Recall = 0.9933774834437086, Aging Rate = 0.5054635761589404, Precision = 0.982640026203734, f1 = 0.9879795817553104\n",
      "Epoch 39: Train Loss = 0.05267824540963236, Recall = 0.9897350993377484, Aging Rate = 0.5061258278145695, Precision = 0.9777559699051358, f1 = 0.9837090669738359\n",
      "Epoch 40: Train Loss = 0.05492677398716772, Recall = 0.9867549668874173, Aging Rate = 0.5051324503311259, Precision = 0.9767289413307112, f1 = 0.9817163564486905\n",
      "Test Loss = 0.04396143166336003, Recall = 0.9841059602649007, Aging Rate = 0.4951986754966887, precision = 0.9936476094951521\n",
      "\n",
      "Epoch 41: Train Loss = 0.045315180612814344, Recall = 0.9927152317880795, Aging Rate = 0.5054635761589404, Precision = 0.9819849328529315, f1 = 0.9873209287008069\n",
      "Epoch 42: Train Loss = 0.04834437657961782, Recall = 0.9903973509933774, Aging Rate = 0.5041390728476821, Precision = 0.9822660098522168, f1 = 0.9863149216817808\n",
      "Epoch 43: Train Loss = 0.05264532562616645, Recall = 0.9887417218543046, Aging Rate = 0.5036423841059603, Precision = 0.9815910585141354, f1 = 0.9851534147146156\n",
      "Epoch 44: Train Loss = 0.04812137716949381, Recall = 0.9897350993377484, Aging Rate = 0.5052980132450331, Precision = 0.9793577981651376, f1 = 0.9845191040843214\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45: Train Loss = 0.04924368021750687, Recall = 0.9903973509933774, Aging Rate = 0.5052980132450331, Precision = 0.9800131061598951, f1 = 0.9851778656126482\n",
      "Test Loss = 0.0514366420035232, Recall = 0.9996688741721854, Aging Rate = 0.5178807947019868, precision = 0.965153452685422\n",
      "\n",
      "Epoch 46: Train Loss = 0.04033347810341033, Recall = 0.9937086092715232, Aging Rate = 0.5028145695364239, Precision = 0.9881461969048403, f1 = 0.9909195971603103\n",
      "Epoch 47: Train Loss = 0.046356234270215825, Recall = 0.9933774834437086, Aging Rate = 0.5061258278145695, Precision = 0.9813542688910697, f1 = 0.9873292743129833\n",
      "Epoch 48: Train Loss = 0.05356429294738548, Recall = 0.9903973509933774, Aging Rate = 0.5067880794701987, Precision = 0.9771316563214636, f1 = 0.983719782930439\n",
      "Epoch 49: Train Loss = 0.05469633563366157, Recall = 0.9884105960264901, Aging Rate = 0.5061258278145695, Precision = 0.9764474975466143, f1 = 0.9823926279414185\n",
      "Epoch 50: Train Loss = 0.04520228398556741, Recall = 0.9927152317880795, Aging Rate = 0.5044701986754967, Precision = 0.9839186084673449, f1 = 0.9882973462996538\n",
      "Test Loss = 0.03969309914684453, Recall = 0.9943708609271523, Aging Rate = 0.5048013245033113, precision = 0.9849130862577894\n",
      "\n",
      "Epoch 51: Train Loss = 0.04496564015696775, Recall = 0.9933774834437086, Aging Rate = 0.5046357615894039, Precision = 0.984251968503937, f1 = 0.988793671720501\n",
      "Epoch 52: Train Loss = 0.04708922863845399, Recall = 0.9910596026490066, Aging Rate = 0.5044701986754967, Precision = 0.9822776501476862, f1 = 0.986649085215098\n",
      "Epoch 53: Train Loss = 0.0498506328917497, Recall = 0.9900662251655629, Aging Rate = 0.5046357615894039, Precision = 0.9809711286089239, f1 = 0.985497692814766\n",
      "Epoch 54: Train Loss = 0.04647225652457468, Recall = 0.9927152317880795, Aging Rate = 0.5043046357615895, Precision = 0.9842416283650689, f1 = 0.9884602703593801\n",
      "Epoch 55: Train Loss = 0.04406517670051941, Recall = 0.9943708609271523, Aging Rate = 0.5048013245033113, Precision = 0.9849130862577894, f1 = 0.9896193771626297\n",
      "Test Loss = 0.053071015609415954, Recall = 0.9943708609271523, Aging Rate = 0.5145695364238411, precision = 0.9662162162162162\n",
      "\n",
      "Epoch 56: Train Loss = 0.048464600176902004, Recall = 0.9903973509933774, Aging Rate = 0.5046357615894039, Precision = 0.9812992125984252, f1 = 0.9858272907053395\n",
      "Epoch 57: Train Loss = 0.059101272164073015, Recall = 0.9857615894039735, Aging Rate = 0.5048013245033113, Precision = 0.9763857002295835, f1 = 0.9810512440270226\n",
      "Epoch 58: Train Loss = 0.04372528613551168, Recall = 0.9937086092715232, Aging Rate = 0.5052980132450331, Precision = 0.9832896461336829, f1 = 0.9884716732542821\n",
      "Epoch 59: Train Loss = 0.04642546712266688, Recall = 0.9903973509933774, Aging Rate = 0.5033112582781457, Precision = 0.9838815789473684, f1 = 0.9871287128712871\n",
      "Epoch 60: Train Loss = 0.05354290959357426, Recall = 0.9884105960264901, Aging Rate = 0.5031456953642384, Precision = 0.9822309970384995, f1 = 0.9853111074434725\n",
      "Test Loss = 0.03904956690720375, Recall = 0.9970198675496689, Aging Rate = 0.5066225165562914, precision = 0.9839869281045751\n",
      "\n",
      "Epoch 61: Train Loss = 0.04561061828539072, Recall = 0.9923841059602649, Aging Rate = 0.5044701986754967, Precision = 0.9835904168034132, f1 = 0.9879676940827428\n",
      "Epoch 62: Train Loss = 0.050094178047598595, Recall = 0.9897350993377484, Aging Rate = 0.5048013245033113, Precision = 0.9803214168579862, f1 = 0.9850057670126874\n",
      "Epoch 63: Train Loss = 0.061912162424318046, Recall = 0.9860927152317881, Aging Rate = 0.506953642384106, Precision = 0.9725669497060745, f1 = 0.9792831305491615\n",
      "Epoch 64: Train Loss = 0.04470590116419145, Recall = 0.9923841059602649, Aging Rate = 0.5054635761589404, Precision = 0.9816573861775303, f1 = 0.9869916021735552\n",
      "Epoch 65: Train Loss = 0.041595222161996445, Recall = 0.993046357615894, Aging Rate = 0.503476821192053, Precision = 0.9861887536994409, f1 = 0.989605675631084\n",
      "Test Loss = 0.034474516127085846, Recall = 0.9966887417218543, Aging Rate = 0.5039735099337749, precision = 0.9888304862023654\n",
      "\n",
      "Epoch 66: Train Loss = 0.05805277156810097, Recall = 0.9900662251655629, Aging Rate = 0.5079470198675496, Precision = 0.9745762711864406, f1 = 0.9822601839684625\n",
      "Epoch 67: Train Loss = 0.046055024524299513, Recall = 0.9917218543046358, Aging Rate = 0.5059602649006623, Precision = 0.9800392670157068, f1 = 0.9858459512837393\n",
      "Epoch 68: Train Loss = 0.048585244001734335, Recall = 0.990728476821192, Aging Rate = 0.5049668874172185, Precision = 0.980983606557377, f1 = 0.9858319604612851\n",
      "Epoch 69: Train Loss = 0.0581666472682495, Recall = 0.9874172185430463, Aging Rate = 0.506953642384106, Precision = 0.9738732854343566, f1 = 0.9805984873396909\n",
      "Epoch 70: Train Loss = 0.046039688032095794, Recall = 0.9923841059602649, Aging Rate = 0.5049668874172185, Precision = 0.9826229508196721, f1 = 0.9874794069192752\n",
      "Test Loss = 0.03684357155780524, Recall = 0.9933774834437086, Aging Rate = 0.5014900662251656, precision = 0.9904258831297458\n",
      "\n",
      "Epoch 71: Train Loss = 0.050400236078741535, Recall = 0.9890728476821192, Aging Rate = 0.5052980132450331, Precision = 0.97870249017038, f1 = 0.9838603425559946\n",
      "Epoch 72: Train Loss = 0.05041825244610278, Recall = 0.9910596026490066, Aging Rate = 0.5056291390728477, Precision = 0.9800261951538966, f1 = 0.9855120184392492\n",
      "Epoch 73: Train Loss = 0.0490544659757851, Recall = 0.9910596026490066, Aging Rate = 0.5046357615894039, Precision = 0.9819553805774278, f1 = 0.9864864864864864\n",
      "Epoch 74: Train Loss = 0.042783283202952105, Recall = 0.9933774834437086, Aging Rate = 0.5048013245033113, Precision = 0.9839291571006887, f1 = 0.9886307464162135\n",
      "Epoch 75: Train Loss = 0.04727585079111406, Recall = 0.9920529801324504, Aging Rate = 0.5041390728476821, Precision = 0.9839080459770115, f1 = 0.9879637262984335\n",
      "Test Loss = 0.03682432769742233, Recall = 0.9917218543046358, Aging Rate = 0.4996688741721854, precision = 0.9923790589794566\n",
      "\n",
      "Epoch 76: Train Loss = 0.05216179913933704, Recall = 0.9890728476821192, Aging Rate = 0.5044701986754967, Precision = 0.9803085001640959, f1 = 0.9846711719136311\n",
      "Epoch 77: Train Loss = 0.046587301768510544, Recall = 0.9910596026490066, Aging Rate = 0.5039735099337749, Precision = 0.9832457293035479, f1 = 0.9871372031662269\n",
      "Epoch 78: Train Loss = 0.052030371391023233, Recall = 0.9887417218543046, Aging Rate = 0.5043046357615895, Precision = 0.9803020354563362, f1 = 0.9845037916254533\n",
      "Epoch 79: Train Loss = 0.049861854556577885, Recall = 0.9913907284768212, Aging Rate = 0.5049668874172185, Precision = 0.981639344262295, f1 = 0.986490939044481\n",
      "Epoch 80: Train Loss = 0.041091492249081464, Recall = 0.993046357615894, Aging Rate = 0.5033112582781457, Precision = 0.9865131578947368, f1 = 0.9897689768976897\n",
      "Test Loss = 0.032601375962971454, Recall = 0.9970198675496689, Aging Rate = 0.5041390728476821, precision = 0.9888341543513958\n",
      "\n",
      "Epoch 81: Train Loss = 0.046495639197281655, Recall = 0.9910596026490066, Aging Rate = 0.5048013245033113, Precision = 0.9816333224007872, f1 = 0.9863239413412423\n",
      "Epoch 82: Train Loss = 0.044644616887170745, Recall = 0.9920529801324504, Aging Rate = 0.5044701986754967, Precision = 0.9832622251394815, f1 = 0.9876380418658315\n",
      "Epoch 83: Train Loss = 0.0501620934696387, Recall = 0.9913907284768212, Aging Rate = 0.5052980132450331, Precision = 0.9809960681520314, f1 = 0.9861660079051383\n",
      "Epoch 84: Train Loss = 0.0537869639503492, Recall = 0.9877483443708609, Aging Rate = 0.5038079470198675, Precision = 0.9802826158396319, f1 = 0.9840013194788059\n",
      "Epoch 85: Train Loss = 0.046208710608300785, Recall = 0.990728476821192, Aging Rate = 0.5041390728476821, Precision = 0.9825944170771757, f1 = 0.9866446826051112\n",
      "Test Loss = 0.056012366630679725, Recall = 0.9751655629139073, Aging Rate = 0.48923841059602646, precision = 0.9966159052453468\n",
      "\n",
      "Training Finished at epoch 85.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "125668eef32248c1b40077e74f095840",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss = 0.37055716936951444, Recall = 0.8986754966887417, Aging Rate = 0.5779801324503311, Precision = 0.777427671154397, f1 = 0.8336661035171248\n",
      "Epoch 2: Train Loss = 0.19211543133321976, Recall = 0.9456953642384106, Aging Rate = 0.5233443708609271, Precision = 0.9035115469788042, f1 = 0.9241223103057759\n",
      "Epoch 3: Train Loss = 0.14554224653749276, Recall = 0.9582781456953643, Aging Rate = 0.5147350993377483, Precision = 0.930845931167578, f1 = 0.9443628650677108\n",
      "Epoch 4: Train Loss = 0.1193887625407699, Recall = 0.9701986754966887, Aging Rate = 0.518046357615894, Precision = 0.936401406200064, f1 = 0.9530004878842088\n",
      "Epoch 5: Train Loss = 0.11601979555870523, Recall = 0.9678807947019867, Aging Rate = 0.5125827814569537, Precision = 0.9441214470284238, f1 = 0.9558534990189667\n",
      "Test Loss = 0.06305696589514515, Recall = 0.9804635761589404, Aging Rate = 0.4948675496688742, precision = 0.990632318501171\n",
      "Model in epoch 5 is saved.\n",
      "\n",
      "Epoch 6: Train Loss = 0.06400789477868585, Recall = 0.9834437086092715, Aging Rate = 0.5046357615894039, Precision = 0.9744094488188977, f1 = 0.978905735003296\n",
      "Epoch 7: Train Loss = 0.05905481981520621, Recall = 0.9867549668874173, Aging Rate = 0.5052980132450331, Precision = 0.9764089121887287, f1 = 0.9815546772068512\n",
      "Epoch 8: Train Loss = 0.05662295393004323, Recall = 0.9884105960264901, Aging Rate = 0.5052980132450331, Precision = 0.9780471821756226, f1 = 0.983201581027668\n",
      "Epoch 9: Train Loss = 0.06081048289178223, Recall = 0.9860927152317881, Aging Rate = 0.5056291390728477, Precision = 0.9751146037982973, f1 = 0.980572933816266\n",
      "Epoch 10: Train Loss = 0.06050854182203874, Recall = 0.9844370860927152, Aging Rate = 0.5049668874172185, Precision = 0.9747540983606557, f1 = 0.9795716639209225\n",
      "Test Loss = 0.049283328272451625, Recall = 0.9966887417218543, Aging Rate = 0.5144039735099337, precision = 0.9687801738010943\n",
      "\n",
      "Epoch 11: Train Loss = 0.057051019888642605, Recall = 0.9864238410596027, Aging Rate = 0.5039735099337749, Precision = 0.978646517739816, f1 = 0.9825197889182058\n",
      "Epoch 12: Train Loss = 0.05310429748123055, Recall = 0.9887417218543046, Aging Rate = 0.5066225165562914, Precision = 0.9758169934640523, f1 = 0.9822368421052632\n",
      "Epoch 13: Train Loss = 0.04817842392880001, Recall = 0.9923841059602649, Aging Rate = 0.5054635761589404, Precision = 0.9816573861775303, f1 = 0.9869916021735552\n",
      "Epoch 14: Train Loss = 0.06064851891422114, Recall = 0.9844370860927152, Aging Rate = 0.5051324503311259, Precision = 0.9744346116027532, f1 = 0.9794103113160929\n",
      "Epoch 15: Train Loss = 0.05933653573869475, Recall = 0.9870860927152317, Aging Rate = 0.5067880794701987, Precision = 0.9738647500816726, f1 = 0.9804308501891137\n",
      "Test Loss = 0.05852568544546105, Recall = 0.9867549668874173, Aging Rate = 0.5048013245033113, precision = 0.9773696293866841\n",
      "\n",
      "Epoch 16: Train Loss = 0.053452994087279236, Recall = 0.9903973509933774, Aging Rate = 0.5056291390728477, Precision = 0.9793713163064833, f1 = 0.9848534738228515\n",
      "Epoch 17: Train Loss = 0.05447675894131724, Recall = 0.9900662251655629, Aging Rate = 0.5057947019867549, Precision = 0.9787234042553191, f1 = 0.9843621399176954\n",
      "Epoch 18: Train Loss = 0.05016632308036286, Recall = 0.9897350993377484, Aging Rate = 0.5041390728476821, Precision = 0.9816091954022989, f1 = 0.9856553998351195\n",
      "Epoch 19: Train Loss = 0.04827487183525073, Recall = 0.9913907284768212, Aging Rate = 0.5041390728476821, Precision = 0.9832512315270936, f1 = 0.9873042044517726\n",
      "Epoch 20: Train Loss = 0.052461409438031396, Recall = 0.9884105960264901, Aging Rate = 0.5052980132450331, Precision = 0.9780471821756226, f1 = 0.983201581027668\n",
      "Test Loss = 0.03821743127229987, Recall = 0.993046357615894, Aging Rate = 0.49933774834437084, precision = 0.9943633952254642\n",
      "Model in epoch 20 is saved.\n",
      "\n",
      "Epoch 21: Train Loss = 0.04818059271879938, Recall = 0.9900662251655629, Aging Rate = 0.5039735099337749, Precision = 0.9822601839684626, f1 = 0.9861477572559366\n",
      "Epoch 22: Train Loss = 0.05032096652203048, Recall = 0.9887417218543046, Aging Rate = 0.5043046357615895, Precision = 0.9803020354563362, f1 = 0.9845037916254533\n",
      "Epoch 23: Train Loss = 0.05060757437585205, Recall = 0.9900662251655629, Aging Rate = 0.5049668874172185, Precision = 0.980327868852459, f1 = 0.9851729818780889\n",
      "Epoch 24: Train Loss = 0.0489934117934167, Recall = 0.990728476821192, Aging Rate = 0.5046357615894039, Precision = 0.9816272965879265, f1 = 0.986156888595913\n",
      "Epoch 25: Train Loss = 0.04734023626375672, Recall = 0.9910596026490066, Aging Rate = 0.5051324503311259, Precision = 0.9809898393969191, f1 = 0.9859990116949431\n",
      "Test Loss = 0.04498429558184368, Recall = 0.9884105960264901, Aging Rate = 0.49850993377483444, precision = 0.9913649950182664\n",
      "\n",
      "Epoch 26: Train Loss = 0.047682083879184246, Recall = 0.9913907284768212, Aging Rate = 0.5052980132450331, Precision = 0.9809960681520314, f1 = 0.9861660079051383\n",
      "Epoch 27: Train Loss = 0.04883159078065528, Recall = 0.990728476821192, Aging Rate = 0.5054635761589404, Precision = 0.980019652800524, f1 = 0.9853449695372962\n",
      "Epoch 28: Train Loss = 0.05215715332980582, Recall = 0.9900662251655629, Aging Rate = 0.5031456953642384, Precision = 0.9838762750904902, f1 = 0.9869615448093744\n",
      "Epoch 29: Train Loss = 0.04620676358655983, Recall = 0.9927152317880795, Aging Rate = 0.5061258278145695, Precision = 0.9807000327118089, f1 = 0.9866710547967749\n",
      "Epoch 30: Train Loss = 0.05820287814400844, Recall = 0.9877483443708609, Aging Rate = 0.506953642384106, Precision = 0.9741998693664272, f1 = 0.9809273265373233\n",
      "Test Loss = 0.050036571557257346, Recall = 0.9966887417218543, Aging Rate = 0.5099337748344371, precision = 0.9772727272727273\n",
      "\n",
      "Epoch 31: Train Loss = 0.052326552915257334, Recall = 0.990728476821192, Aging Rate = 0.5071192052980132, Precision = 0.9768201110022854, f1 = 0.9837251356238699\n",
      "Epoch 32: Train Loss = 0.045427253588244614, Recall = 0.9894039735099338, Aging Rate = 0.5028145695364239, Precision = 0.9838656568982549, f1 = 0.9866270430906389\n",
      "Epoch 33: Train Loss = 0.05031082123172599, Recall = 0.9920529801324504, Aging Rate = 0.506953642384106, Precision = 0.9784454604833442, f1 = 0.9852022361065439\n",
      "Epoch 34: Train Loss = 0.04313905116491365, Recall = 0.9927152317880795, Aging Rate = 0.5051324503311259, Precision = 0.9826286463454605, f1 = 0.9876461867896558\n",
      "Epoch 35: Train Loss = 0.04794667614315519, Recall = 0.9927152317880795, Aging Rate = 0.5059602649006623, Precision = 0.981020942408377, f1 = 0.9868334430546413\n",
      "Test Loss = 0.04959392428694182, Recall = 0.9913907284768212, Aging Rate = 0.5074503311258278, precision = 0.9768352365415987\n",
      "\n",
      "Epoch 36: Train Loss = 0.04996509242630163, Recall = 0.9903973509933774, Aging Rate = 0.5057947019867549, Precision = 0.979050736497545, f1 = 0.9846913580246914\n",
      "Epoch 37: Train Loss = 0.05423936315423605, Recall = 0.9880794701986755, Aging Rate = 0.5038079470198675, Precision = 0.9806112389089714, f1 = 0.9843311891802737\n",
      "Epoch 38: Train Loss = 0.04672326462355671, Recall = 0.993046357615894, Aging Rate = 0.5061258278145695, Precision = 0.9810271508014393, f1 = 0.987000164554879\n",
      "Epoch 39: Train Loss = 0.04730041365305714, Recall = 0.9903973509933774, Aging Rate = 0.5046357615894039, Precision = 0.9812992125984252, f1 = 0.9858272907053395\n",
      "Epoch 40: Train Loss = 0.047603454189190014, Recall = 0.9913907284768212, Aging Rate = 0.5056291390728477, Precision = 0.9803536345776032, f1 = 0.9858412907474481\n",
      "Test Loss = 0.03559828789670341, Recall = 0.9950331125827815, Aging Rate = 0.5001655629139072, precision = 0.9947037404832837\n",
      "Model in epoch 40 is saved.\n",
      "\n",
      "Epoch 41: Train Loss = 0.04495958570909026, Recall = 0.9903973509933774, Aging Rate = 0.502317880794702, Precision = 0.9858272907053395, f1 = 0.9881070366699702\n",
      "Epoch 42: Train Loss = 0.055635213956779596, Recall = 0.9887417218543046, Aging Rate = 0.508112582781457, Precision = 0.9729553600521342, f1 = 0.9807850221711283\n",
      "Epoch 43: Train Loss = 0.042575116533267975, Recall = 0.9923841059602649, Aging Rate = 0.5041390728476821, Precision = 0.9842364532019704, f1 = 0.9882934872217642\n",
      "Epoch 44: Train Loss = 0.052063311352733746, Recall = 0.9877483443708609, Aging Rate = 0.503476821192053, Precision = 0.9809273265373233, f1 = 0.9843260188087773\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45: Train Loss = 0.04469711313283207, Recall = 0.9923841059602649, Aging Rate = 0.5028145695364239, Precision = 0.9868291076720448, f1 = 0.9895988112927191\n",
      "Test Loss = 0.030853905398028576, Recall = 0.9973509933774835, Aging Rate = 0.5044701986754967, precision = 0.9885132917623892\n",
      "\n",
      "Epoch 46: Train Loss = 0.04435110753340437, Recall = 0.9927152317880795, Aging Rate = 0.5043046357615895, Precision = 0.9842416283650689, f1 = 0.9884602703593801\n",
      "Epoch 47: Train Loss = 0.04295564653314897, Recall = 0.9943708609271523, Aging Rate = 0.5059602649006623, Precision = 0.9826570680628273, f1 = 0.988479262672811\n",
      "Epoch 48: Train Loss = 0.04576695200228533, Recall = 0.9900662251655629, Aging Rate = 0.503476821192053, Precision = 0.9832292009207497, f1 = 0.9866358686685365\n",
      "Epoch 49: Train Loss = 0.0502572539601697, Recall = 0.9894039735099338, Aging Rate = 0.503476821192053, Precision = 0.9825715225254851, f1 = 0.9859759115657482\n",
      "Epoch 50: Train Loss = 0.051371641849346505, Recall = 0.9887417218543046, Aging Rate = 0.5049668874172185, Precision = 0.9790163934426229, f1 = 0.9838550247116968\n",
      "Test Loss = 0.04278865923229235, Recall = 0.9890728476821192, Aging Rate = 0.49801324503311256, precision = 0.9930186170212766\n",
      "\n",
      "Epoch 51: Train Loss = 0.044056407877842325, Recall = 0.993046357615894, Aging Rate = 0.5036423841059603, Precision = 0.9858645627876397, f1 = 0.9894424282415043\n",
      "Epoch 52: Train Loss = 0.047333609448462134, Recall = 0.9897350993377484, Aging Rate = 0.5029801324503311, Precision = 0.9838709677419355, f1 = 0.9867943215582701\n",
      "Epoch 53: Train Loss = 0.048714725056428786, Recall = 0.9900662251655629, Aging Rate = 0.5046357615894039, Precision = 0.9809711286089239, f1 = 0.985497692814766\n",
      "Epoch 54: Train Loss = 0.04374415766916528, Recall = 0.9933774834437086, Aging Rate = 0.5051324503311259, Precision = 0.983284169124877, f1 = 0.9883050568275408\n",
      "Epoch 55: Train Loss = 0.045236496648300956, Recall = 0.9933774834437086, Aging Rate = 0.5061258278145695, Precision = 0.9813542688910697, f1 = 0.9873292743129833\n",
      "Test Loss = 0.033966452448277284, Recall = 0.9986754966887417, Aging Rate = 0.5071192052980132, precision = 0.9846555664381326\n",
      "\n",
      "Epoch 56: Train Loss = 0.04768524971969475, Recall = 0.9903973509933774, Aging Rate = 0.5051324503311259, Precision = 0.9803343166175025, f1 = 0.9853401416570582\n",
      "Epoch 57: Train Loss = 0.05002077162660511, Recall = 0.9920529801324504, Aging Rate = 0.5064569536423841, Precision = 0.9794050343249427, f1 = 0.9856884355979602\n",
      "Epoch 58: Train Loss = 0.045106377081316436, Recall = 0.9920529801324504, Aging Rate = 0.5051324503311259, Precision = 0.9819731235660439, f1 = 0.9869873167517708\n",
      "Epoch 59: Train Loss = 0.04515744113912251, Recall = 0.9894039735099338, Aging Rate = 0.5038079470198675, Precision = 0.9819257311863293, f1 = 0.9856506679861456\n",
      "Epoch 60: Train Loss = 0.04693036592065893, Recall = 0.9903973509933774, Aging Rate = 0.5051324503311259, Precision = 0.9803343166175025, f1 = 0.9853401416570582\n",
      "Test Loss = 0.03806102332837929, Recall = 0.9913907284768212, Aging Rate = 0.5003311258278146, precision = 0.9907346128391793\n",
      "\n",
      "Epoch 61: Train Loss = 0.048859645959162555, Recall = 0.9903973509933774, Aging Rate = 0.503476821192053, Precision = 0.9835580401183821, f1 = 0.9869658472199306\n",
      "Epoch 62: Train Loss = 0.043892776260510184, Recall = 0.9920529801324504, Aging Rate = 0.5036423841059603, Precision = 0.9848783694937541, f1 = 0.9884526558891455\n",
      "Epoch 63: Train Loss = 0.042211907954010745, Recall = 0.9940397350993377, Aging Rate = 0.5039735099337749, Precision = 0.9862023653088042, f1 = 0.9901055408970977\n",
      "Epoch 64: Train Loss = 0.0454281864798819, Recall = 0.993046357615894, Aging Rate = 0.5044701986754967, Precision = 0.9842468001312766, f1 = 0.9886269985165649\n",
      "Epoch 65: Train Loss = 0.04280361406233729, Recall = 0.9943708609271523, Aging Rate = 0.5043046357615895, Precision = 0.9858831254103743, f1 = 0.9901088031651829\n",
      "Test Loss = 0.03397578045306419, Recall = 0.9956953642384105, Aging Rate = 0.5049668874172185, precision = 0.9859016393442623\n",
      "\n",
      "Epoch 66: Train Loss = 0.048421656809105776, Recall = 0.9897350993377484, Aging Rate = 0.5041390728476821, Precision = 0.9816091954022989, f1 = 0.9856553998351195\n",
      "Epoch 67: Train Loss = 0.049553759280123455, Recall = 0.9890728476821192, Aging Rate = 0.5048013245033113, Precision = 0.9796654640865857, f1 = 0.98434667984841\n",
      "Epoch 68: Train Loss = 0.050619664331836414, Recall = 0.9903973509933774, Aging Rate = 0.5061258278145695, Precision = 0.9784102060843964, f1 = 0.9843672864900443\n",
      "Epoch 69: Train Loss = 0.04632654885286527, Recall = 0.9917218543046358, Aging Rate = 0.5048013245033113, Precision = 0.9822892751721876, f1 = 0.9869830285055198\n",
      "Epoch 70: Train Loss = 0.04383563564855926, Recall = 0.9940397350993377, Aging Rate = 0.5051324503311259, Precision = 0.9839396919042936, f1 = 0.9889639268654258\n",
      "Test Loss = 0.03690102971991561, Recall = 0.9943708609271523, Aging Rate = 0.4998344370860927, precision = 0.9947002318648559\n",
      "\n",
      "Epoch 71: Train Loss = 0.04587403080543343, Recall = 0.9920529801324504, Aging Rate = 0.5041390728476821, Precision = 0.9839080459770115, f1 = 0.9879637262984335\n",
      "Epoch 72: Train Loss = 0.04715508372825108, Recall = 0.9910596026490066, Aging Rate = 0.5054635761589404, Precision = 0.9803471994759253, f1 = 0.985674296064548\n",
      "Epoch 73: Train Loss = 0.04472346530844834, Recall = 0.9920529801324504, Aging Rate = 0.5039735099337749, Precision = 0.9842312746386334, f1 = 0.9881266490765171\n",
      "Epoch 74: Train Loss = 0.04442280650706283, Recall = 0.9920529801324504, Aging Rate = 0.5041390728476821, Precision = 0.9839080459770115, f1 = 0.9879637262984335\n",
      "Epoch 75: Train Loss = 0.047200562775332404, Recall = 0.9917218543046358, Aging Rate = 0.5048013245033113, Precision = 0.9822892751721876, f1 = 0.9869830285055198\n",
      "Test Loss = 0.03469180650762375, Recall = 0.9953642384105961, Aging Rate = 0.5014900662251656, precision = 0.9924067348960053\n",
      "\n",
      "Epoch 76: Train Loss = 0.042975459733842224, Recall = 0.9937086092715232, Aging Rate = 0.5039735099337749, Precision = 0.985873850197109, f1 = 0.9897757255936676\n",
      "Epoch 77: Train Loss = 0.047098532175978286, Recall = 0.9900662251655629, Aging Rate = 0.5041390728476821, Precision = 0.9819376026272578, f1 = 0.9859851607584501\n",
      "Epoch 78: Train Loss = 0.04724289208946639, Recall = 0.9923841059602649, Aging Rate = 0.5054635761589404, Precision = 0.9816573861775303, f1 = 0.9869916021735552\n",
      "Epoch 79: Train Loss = 0.047966567831521, Recall = 0.9933774834437086, Aging Rate = 0.5066225165562914, Precision = 0.9803921568627451, f1 = 0.9868421052631579\n",
      "Epoch 80: Train Loss = 0.04603813717894207, Recall = 0.9910596026490066, Aging Rate = 0.5049668874172185, Precision = 0.9813114754098361, f1 = 0.986161449752883\n",
      "Test Loss = 0.04040555414182461, Recall = 0.9864238410596027, Aging Rate = 0.49619205298013247, precision = 0.993993993993994\n",
      "\n",
      "Epoch 81: Train Loss = 0.045384333763789655, Recall = 0.9920529801324504, Aging Rate = 0.5046357615894039, Precision = 0.9829396325459318, f1 = 0.9874752801582071\n",
      "Epoch 82: Train Loss = 0.048014394684836564, Recall = 0.9910596026490066, Aging Rate = 0.5043046357615895, Precision = 0.9826001313197636, f1 = 0.9868117375535773\n",
      "Epoch 83: Train Loss = 0.039122947833395955, Recall = 0.9950331125827815, Aging Rate = 0.5039735099337749, Precision = 0.9871879106438897, f1 = 0.9910949868073878\n",
      "Epoch 84: Train Loss = 0.04591067429409911, Recall = 0.993046357615894, Aging Rate = 0.5052980132450331, Precision = 0.9826343381389253, f1 = 0.9878129117259552\n",
      "Epoch 85: Train Loss = 0.04675579955246275, Recall = 0.9890728476821192, Aging Rate = 0.5036423841059603, Precision = 0.9819197896120972, f1 = 0.9854833388320687\n",
      "Test Loss = 0.042685215379919435, Recall = 0.9953642384105961, Aging Rate = 0.5100993377483444, precision = 0.9756572541382668\n",
      "\n",
      "Epoch 86: Train Loss = 0.0465756578284581, Recall = 0.9910596026490066, Aging Rate = 0.5041390728476821, Precision = 0.9829228243021346, f1 = 0.9869744435284419\n",
      "Epoch 87: Train Loss = 0.05176922829439309, Recall = 0.9884105960264901, Aging Rate = 0.5056291390728477, Precision = 0.9774066797642437, f1 = 0.9828778399736583\n",
      "Epoch 88: Train Loss = 0.044440706281472515, Recall = 0.9890728476821192, Aging Rate = 0.5029801324503311, Precision = 0.9832126398946676, f1 = 0.9861340376361836\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 89: Train Loss = 0.04977559979437598, Recall = 0.9903973509933774, Aging Rate = 0.5052980132450331, Precision = 0.9800131061598951, f1 = 0.9851778656126482\n",
      "Epoch 90: Train Loss = 0.04430460427203123, Recall = 0.993046357615894, Aging Rate = 0.5057947019867549, Precision = 0.9816693944353518, f1 = 0.9873251028806583\n",
      "Test Loss = 0.03196923114013988, Recall = 0.9956953642384105, Aging Rate = 0.5026490066225165, precision = 0.9904479578392622\n",
      "\n",
      "Training Finished at epoch 90.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b044874083ba4bb5ae564fa6196b5588",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss = 0.37319632981786666, Recall = 0.8960264900662251, Aging Rate = 0.5779801324503311, Precision = 0.7751360641649957, f1 = 0.8312087236983566\n",
      "Epoch 2: Train Loss = 0.2050700150134153, Recall = 0.9413907284768211, Aging Rate = 0.5291390728476821, Precision = 0.889549436795995, f1 = 0.9147361647361647\n",
      "Epoch 3: Train Loss = 0.15809162546763356, Recall = 0.9579470198675497, Aging Rate = 0.5195364238410596, Precision = 0.9219247928616954, f1 = 0.9395907762260475\n",
      "Epoch 4: Train Loss = 0.12979058582853797, Recall = 0.9652317880794702, Aging Rate = 0.5149006622516556, Precision = 0.9372990353697749, f1 = 0.9510603588907014\n",
      "Epoch 5: Train Loss = 0.1287877593904931, Recall = 0.9655629139072848, Aging Rate = 0.5153973509933775, Precision = 0.9367169932540957, f1 = 0.950921245719876\n",
      "Test Loss = 0.07973663632739458, Recall = 0.9791390728476821, Aging Rate = 0.4996688741721854, precision = 0.9797879390324719\n",
      "Model in epoch 5 is saved.\n",
      "\n",
      "Epoch 6: Train Loss = 0.0734063737735843, Recall = 0.9850993377483444, Aging Rate = 0.5082781456953642, Precision = 0.9690553745928339, f1 = 0.9770114942528735\n",
      "Epoch 7: Train Loss = 0.06648624176221178, Recall = 0.9854304635761589, Aging Rate = 0.5074503311258278, Precision = 0.9709624796084829, f1 = 0.9781429745275267\n",
      "Epoch 8: Train Loss = 0.06019777302068985, Recall = 0.9854304635761589, Aging Rate = 0.5061258278145695, Precision = 0.9735034347399412, f1 = 0.9794306401184795\n",
      "Epoch 9: Train Loss = 0.0593179541017046, Recall = 0.9877483443708609, Aging Rate = 0.5074503311258278, Precision = 0.9732463295269168, f1 = 0.9804437140509449\n",
      "Epoch 10: Train Loss = 0.06486727511448576, Recall = 0.9844370860927152, Aging Rate = 0.5061258278145695, Precision = 0.97252208047105, f1 = 0.9784433108441665\n",
      "Test Loss = 0.05436820183566075, Recall = 0.9821192052980132, Aging Rate = 0.49619205298013247, precision = 0.9896563229896563\n",
      "Model in epoch 10 is saved.\n",
      "\n",
      "Epoch 11: Train Loss = 0.06074063875619939, Recall = 0.9854304635761589, Aging Rate = 0.5046357615894039, Precision = 0.9763779527559056, f1 = 0.980883322346737\n",
      "Epoch 12: Train Loss = 0.058068910310205245, Recall = 0.9877483443708609, Aging Rate = 0.5062913907284768, Precision = 0.9754741661216482, f1 = 0.9815728858177031\n",
      "Epoch 13: Train Loss = 0.055237593007156784, Recall = 0.9900662251655629, Aging Rate = 0.5074503311258278, Precision = 0.9755301794453507, f1 = 0.9827444535743631\n",
      "Epoch 14: Train Loss = 0.049114184893223625, Recall = 0.9913907284768212, Aging Rate = 0.5054635761589404, Precision = 0.9806747461513265, f1 = 0.9860036225917999\n",
      "Epoch 15: Train Loss = 0.06172706481093997, Recall = 0.9860927152317881, Aging Rate = 0.5052980132450331, Precision = 0.9757536041939712, f1 = 0.9808959156785244\n",
      "Test Loss = 0.039888847434264144, Recall = 0.9880794701986755, Aging Rate = 0.49817880794701985, precision = 0.9916915918909937\n",
      "Model in epoch 15 is saved.\n",
      "\n",
      "Epoch 16: Train Loss = 0.04662547932061928, Recall = 0.990728476821192, Aging Rate = 0.5036423841059603, Precision = 0.9835634451019066, f1 = 0.9871329594193334\n",
      "Epoch 17: Train Loss = 0.05407226836641893, Recall = 0.9887417218543046, Aging Rate = 0.5054635761589404, Precision = 0.9780543727481166, f1 = 0.9833690103737857\n",
      "Epoch 18: Train Loss = 0.057846231886882656, Recall = 0.9887417218543046, Aging Rate = 0.5049668874172185, Precision = 0.9790163934426229, f1 = 0.9838550247116968\n",
      "Epoch 19: Train Loss = 0.05759144479174488, Recall = 0.9867549668874173, Aging Rate = 0.5066225165562914, Precision = 0.9738562091503268, f1 = 0.9802631578947368\n",
      "Epoch 20: Train Loss = 0.0514957099955603, Recall = 0.9870860927152317, Aging Rate = 0.5043046357615895, Precision = 0.9786605384110308, f1 = 0.9828552588196505\n",
      "Test Loss = 0.04700977480076007, Recall = 0.9850993377483444, Aging Rate = 0.4990066225165563, precision = 0.9870603848706039\n",
      "\n",
      "Epoch 21: Train Loss = 0.050771192068986545, Recall = 0.993046357615894, Aging Rate = 0.5076158940397351, Precision = 0.9781474233529028, f1 = 0.9855405849490635\n",
      "Epoch 22: Train Loss = 0.05524658589124285, Recall = 0.9864238410596027, Aging Rate = 0.5048013245033113, Precision = 0.9770416530009839, f1 = 0.9817103311913001\n",
      "Epoch 23: Train Loss = 0.05444250045874656, Recall = 0.9877483443708609, Aging Rate = 0.5049668874172185, Precision = 0.9780327868852459, f1 = 0.9828665568369028\n",
      "Epoch 24: Train Loss = 0.04802596307057418, Recall = 0.9894039735099338, Aging Rate = 0.5031456953642384, Precision = 0.983218163869694, f1 = 0.9863013698630138\n",
      "Epoch 25: Train Loss = 0.054923825252135065, Recall = 0.9890728476821192, Aging Rate = 0.5048013245033113, Precision = 0.9796654640865857, f1 = 0.98434667984841\n",
      "Test Loss = 0.04270036329102043, Recall = 0.997682119205298, Aging Rate = 0.5077814569536424, precision = 0.9823932181284643\n",
      "\n",
      "Epoch 26: Train Loss = 0.053505592331882346, Recall = 0.9897350993377484, Aging Rate = 0.5048013245033113, Precision = 0.9803214168579862, f1 = 0.9850057670126874\n",
      "Epoch 27: Train Loss = 0.0551887338351927, Recall = 0.9880794701986755, Aging Rate = 0.5066225165562914, Precision = 0.9751633986928104, f1 = 0.981578947368421\n",
      "Epoch 28: Train Loss = 0.05127676616342652, Recall = 0.9887417218543046, Aging Rate = 0.5052980132450331, Precision = 0.9783748361730014, f1 = 0.9835309617918314\n",
      "Epoch 29: Train Loss = 0.06020858764451071, Recall = 0.9877483443708609, Aging Rate = 0.5067880794701987, Precision = 0.9745181313296308, f1 = 0.9810886367373788\n",
      "Epoch 30: Train Loss = 0.053072874894402676, Recall = 0.9884105960264901, Aging Rate = 0.5048013245033113, Precision = 0.9790095113151853, f1 = 0.9836875926841325\n",
      "Test Loss = 0.08659007224124789, Recall = 0.95, Aging Rate = 0.4768211920529801, precision = 0.9961805555555555\n",
      "\n",
      "Epoch 31: Train Loss = 0.04964948353536476, Recall = 0.9890728476821192, Aging Rate = 0.5049668874172185, Precision = 0.979344262295082, f1 = 0.984184514003295\n",
      "Epoch 32: Train Loss = 0.04576854166013516, Recall = 0.9927152317880795, Aging Rate = 0.5052980132450331, Precision = 0.9823066841415465, f1 = 0.9874835309617919\n",
      "Epoch 33: Train Loss = 0.047082871815424095, Recall = 0.9917218543046358, Aging Rate = 0.5033112582781457, Precision = 0.9851973684210527, f1 = 0.9884488448844885\n",
      "Epoch 34: Train Loss = 0.05704295440324095, Recall = 0.9874172185430463, Aging Rate = 0.5057947019867549, Precision = 0.9761047463175123, f1 = 0.9817283950617284\n",
      "Epoch 35: Train Loss = 0.04659355040516285, Recall = 0.9903973509933774, Aging Rate = 0.5043046357615895, Precision = 0.9819435325016415, f1 = 0.9861523244312561\n",
      "Test Loss = 0.036410655957085404, Recall = 0.9910596026490066, Aging Rate = 0.4996688741721854, precision = 0.991716368455931\n",
      "Model in epoch 35 is saved.\n",
      "\n",
      "Epoch 36: Train Loss = 0.04938307917917406, Recall = 0.9903973509933774, Aging Rate = 0.5038079470198675, Precision = 0.9829116003943477, f1 = 0.9866402770905492\n",
      "Epoch 37: Train Loss = 0.04853144724242735, Recall = 0.9917218543046358, Aging Rate = 0.5057947019867549, Precision = 0.9803600654664485, f1 = 0.9860082304526748\n",
      "Epoch 38: Train Loss = 0.046389174308405806, Recall = 0.9927152317880795, Aging Rate = 0.5044701986754967, Precision = 0.9839186084673449, f1 = 0.9882973462996538\n",
      "Epoch 39: Train Loss = 0.044481012654422926, Recall = 0.9927152317880795, Aging Rate = 0.502317880794702, Precision = 0.988134475939354, f1 = 0.9904195573174761\n",
      "Epoch 40: Train Loss = 0.0536226401907324, Recall = 0.9880794701986755, Aging Rate = 0.5039735099337749, Precision = 0.9802890932982917, f1 = 0.9841688654353562\n",
      "Test Loss = 0.04646667440896792, Recall = 0.9943708609271523, Aging Rate = 0.5089403973509934, precision = 0.9769030579050098\n",
      "\n",
      "Epoch 41: Train Loss = 0.04614714792380664, Recall = 0.9923841059602649, Aging Rate = 0.5041390728476821, Precision = 0.9842364532019704, f1 = 0.9882934872217642\n",
      "Epoch 42: Train Loss = 0.04898859570357973, Recall = 0.9923841059602649, Aging Rate = 0.5052980132450331, Precision = 0.9819790301441678, f1 = 0.9871541501976285\n",
      "Epoch 43: Train Loss = 0.0460316029062729, Recall = 0.993046357615894, Aging Rate = 0.5046357615894039, Precision = 0.9839238845144357, f1 = 0.9884640738299275\n",
      "Epoch 44: Train Loss = 0.04963861277808022, Recall = 0.993046357615894, Aging Rate = 0.5071192052980132, Precision = 0.9791054521710741, f1 = 0.9860266315962518\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45: Train Loss = 0.04718735943862934, Recall = 0.9887417218543046, Aging Rate = 0.5018211920529801, Precision = 0.9851534147146156, f1 = 0.9869443067261608\n",
      "Test Loss = 0.04969847755420287, Recall = 0.9933774834437086, Aging Rate = 0.5061258278145695, precision = 0.9813542688910697\n",
      "\n",
      "Epoch 46: Train Loss = 0.04935462065041065, Recall = 0.9890728476821192, Aging Rate = 0.5028145695364239, Precision = 0.983536384590056, f1 = 0.9862968466237412\n",
      "Epoch 47: Train Loss = 0.0457091528971661, Recall = 0.9923841059602649, Aging Rate = 0.5051324503311259, Precision = 0.9823008849557522, f1 = 0.9873167517707132\n",
      "Epoch 48: Train Loss = 0.05347071366742352, Recall = 0.9887417218543046, Aging Rate = 0.5059602649006623, Precision = 0.9770942408376964, f1 = 0.9828834759710336\n",
      "Epoch 49: Train Loss = 0.04717024092297285, Recall = 0.9933774834437086, Aging Rate = 0.5071192052980132, Precision = 0.9794319294809011, f1 = 0.9863554167351636\n",
      "Epoch 50: Train Loss = 0.043201716204747456, Recall = 0.993046357615894, Aging Rate = 0.5044701986754967, Precision = 0.9842468001312766, f1 = 0.9886269985165649\n",
      "Test Loss = 0.041933233093544346, Recall = 0.9844370860927152, Aging Rate = 0.49370860927152316, precision = 0.9969818913480886\n",
      "Model in epoch 50 is saved.\n",
      "\n",
      "Epoch 51: Train Loss = 0.048412402398538903, Recall = 0.9900662251655629, Aging Rate = 0.5039735099337749, Precision = 0.9822601839684626, f1 = 0.9861477572559366\n",
      "Epoch 52: Train Loss = 0.048491894172516876, Recall = 0.9910596026490066, Aging Rate = 0.5044701986754967, Precision = 0.9822776501476862, f1 = 0.986649085215098\n",
      "Epoch 53: Train Loss = 0.051419371494789, Recall = 0.9887417218543046, Aging Rate = 0.5043046357615895, Precision = 0.9803020354563362, f1 = 0.9845037916254533\n",
      "Epoch 54: Train Loss = 0.047521865003378384, Recall = 0.9910596026490066, Aging Rate = 0.5051324503311259, Precision = 0.9809898393969191, f1 = 0.9859990116949431\n",
      "Epoch 55: Train Loss = 0.046350442270273406, Recall = 0.9923841059602649, Aging Rate = 0.5046357615894039, Precision = 0.9832677165354331, f1 = 0.9878048780487805\n",
      "Test Loss = 0.040144242051470755, Recall = 0.9943708609271523, Aging Rate = 0.5036423841059603, precision = 0.9871794871794872\n",
      "\n",
      "Epoch 56: Train Loss = 0.050387082149009436, Recall = 0.9903973509933774, Aging Rate = 0.5038079470198675, Precision = 0.9829116003943477, f1 = 0.9866402770905492\n",
      "Epoch 57: Train Loss = 0.053450974555599766, Recall = 0.9897350993377484, Aging Rate = 0.5059602649006623, Precision = 0.9780759162303665, f1 = 0.9838709677419355\n",
      "Epoch 58: Train Loss = 0.04187952100687864, Recall = 0.9940397350993377, Aging Rate = 0.5039735099337749, Precision = 0.9862023653088042, f1 = 0.9901055408970977\n",
      "Epoch 59: Train Loss = 0.04824309240755261, Recall = 0.9910596026490066, Aging Rate = 0.5038079470198675, Precision = 0.9835688465330266, f1 = 0.987300016493485\n",
      "Epoch 60: Train Loss = 0.04697458811400347, Recall = 0.9933774834437086, Aging Rate = 0.5061258278145695, Precision = 0.9813542688910697, f1 = 0.9873292743129833\n",
      "Test Loss = 0.033690807161643015, Recall = 0.9923841059602649, Aging Rate = 0.49933774834437084, precision = 0.9937002652519894\n",
      "Model in epoch 60 is saved.\n",
      "\n",
      "Epoch 61: Train Loss = 0.04673609357105186, Recall = 0.9903973509933774, Aging Rate = 0.5049668874172185, Precision = 0.980655737704918, f1 = 0.985502471169687\n",
      "Epoch 62: Train Loss = 0.047571985014029684, Recall = 0.9917218543046358, Aging Rate = 0.5048013245033113, Precision = 0.9822892751721876, f1 = 0.9869830285055198\n",
      "Epoch 63: Train Loss = 0.045579103893594236, Recall = 0.9927152317880795, Aging Rate = 0.5043046357615895, Precision = 0.9842416283650689, f1 = 0.9884602703593801\n",
      "Epoch 64: Train Loss = 0.054726476760100055, Recall = 0.9903973509933774, Aging Rate = 0.5064569536423841, Precision = 0.9777705132396208, f1 = 0.9840434281954269\n",
      "Epoch 65: Train Loss = 0.05529362445216108, Recall = 0.9884105960264901, Aging Rate = 0.5048013245033113, Precision = 0.9790095113151853, f1 = 0.9836875926841325\n",
      "Test Loss = 0.03941706638561179, Recall = 0.9894039735099338, Aging Rate = 0.4986754966887417, precision = 0.9920318725099602\n",
      "\n",
      "Epoch 66: Train Loss = 0.0419909579000923, Recall = 0.9947019867549669, Aging Rate = 0.5049668874172185, Precision = 0.9849180327868853, f1 = 0.9897858319604612\n",
      "Epoch 67: Train Loss = 0.053267169191150474, Recall = 0.9894039735099338, Aging Rate = 0.5056291390728477, Precision = 0.9783889980353635, f1 = 0.9838656568982549\n",
      "Epoch 68: Train Loss = 0.052453166786704634, Recall = 0.9897350993377484, Aging Rate = 0.5057947019867549, Precision = 0.9783960720130933, f1 = 0.9840329218106997\n",
      "Epoch 69: Train Loss = 0.04832110514013183, Recall = 0.9903973509933774, Aging Rate = 0.5031456953642384, Precision = 0.9842053307008884, f1 = 0.9872916322825549\n",
      "Epoch 70: Train Loss = 0.04730464131478837, Recall = 0.9920529801324504, Aging Rate = 0.5043046357615895, Precision = 0.9835850295469468, f1 = 0.9878008572370589\n",
      "Test Loss = 0.05303986177144461, Recall = 0.9817880794701986, Aging Rate = 0.4960264900662252, precision = 0.989652870493992\n",
      "\n",
      "Epoch 71: Train Loss = 0.04883349894342438, Recall = 0.990728476821192, Aging Rate = 0.5038079470198675, Precision = 0.9832402234636871, f1 = 0.9869701467920172\n",
      "Epoch 72: Train Loss = 0.05588696605914476, Recall = 0.9864238410596027, Aging Rate = 0.5052980132450331, Precision = 0.9760812581913499, f1 = 0.9812252964426877\n",
      "Epoch 73: Train Loss = 0.048883656851503234, Recall = 0.9894039735099338, Aging Rate = 0.5046357615894039, Precision = 0.9803149606299213, f1 = 0.984838497033619\n",
      "Epoch 74: Train Loss = 0.0424665059820311, Recall = 0.9923841059602649, Aging Rate = 0.5044701986754967, Precision = 0.9835904168034132, f1 = 0.9879676940827428\n",
      "Epoch 75: Train Loss = 0.0543117791883006, Recall = 0.9860927152317881, Aging Rate = 0.5036423841059603, Precision = 0.9789612097304405, f1 = 0.9825140217749918\n",
      "Test Loss = 0.045268135769477746, Recall = 0.9943708609271523, Aging Rate = 0.5084437086092716, precision = 0.9778573754477369\n",
      "\n",
      "Epoch 76: Train Loss = 0.04505112995177705, Recall = 0.9917218543046358, Aging Rate = 0.5044701986754967, Precision = 0.9829340334755498, f1 = 0.9873083896489203\n",
      "Epoch 77: Train Loss = 0.052688688478919846, Recall = 0.9900662251655629, Aging Rate = 0.5059602649006623, Precision = 0.9784031413612565, f1 = 0.9842001316655694\n",
      "Epoch 78: Train Loss = 0.04957582720413508, Recall = 0.9887417218543046, Aging Rate = 0.5036423841059603, Precision = 0.9815910585141354, f1 = 0.9851534147146156\n",
      "Epoch 79: Train Loss = 0.045749555552834706, Recall = 0.9917218543046358, Aging Rate = 0.5046357615894039, Precision = 0.9826115485564304, f1 = 0.9871456822676334\n",
      "Epoch 80: Train Loss = 0.045227758443316085, Recall = 0.993046357615894, Aging Rate = 0.5052980132450331, Precision = 0.9826343381389253, f1 = 0.9878129117259552\n",
      "Test Loss = 0.03478524954064398, Recall = 0.9943708609271523, Aging Rate = 0.5019867549668874, precision = 0.9904353562005277\n",
      "\n",
      "Epoch 81: Train Loss = 0.04797806931745927, Recall = 0.9890728476821192, Aging Rate = 0.5036423841059603, Precision = 0.9819197896120972, f1 = 0.9854833388320687\n",
      "Epoch 82: Train Loss = 0.05040208094858176, Recall = 0.9903973509933774, Aging Rate = 0.5051324503311259, Precision = 0.9803343166175025, f1 = 0.9853401416570582\n",
      "Epoch 83: Train Loss = 0.04330282967463629, Recall = 0.9923841059602649, Aging Rate = 0.5038079470198675, Precision = 0.9848833388103845, f1 = 0.9886194952993568\n",
      "Epoch 84: Train Loss = 0.047412044925010756, Recall = 0.9923841059602649, Aging Rate = 0.5064569536423841, Precision = 0.9797319385420072, f1 = 0.9860174370784668\n",
      "Epoch 85: Train Loss = 0.046466807692946976, Recall = 0.9917218543046358, Aging Rate = 0.5044701986754967, Precision = 0.9829340334755498, f1 = 0.9873083896489203\n",
      "Test Loss = 0.038030110958297524, Recall = 0.9990066225165563, Aging Rate = 0.5094370860927152, precision = 0.9805004874878128\n",
      "\n",
      "Epoch 86: Train Loss = 0.04972530838274798, Recall = 0.9884105960264901, Aging Rate = 0.5036423841059603, Precision = 0.9812623274161736, f1 = 0.9848234905971627\n",
      "Epoch 87: Train Loss = 0.051743362853858645, Recall = 0.9900662251655629, Aging Rate = 0.5061258278145695, Precision = 0.9780830879947661, f1 = 0.98403817673194\n",
      "Epoch 88: Train Loss = 0.049176835512976774, Recall = 0.9903973509933774, Aging Rate = 0.5049668874172185, Precision = 0.980655737704918, f1 = 0.985502471169687\n",
      "Epoch 89: Train Loss = 0.04502070712801439, Recall = 0.993046357615894, Aging Rate = 0.5052980132450331, Precision = 0.9826343381389253, f1 = 0.9878129117259552\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 90: Train Loss = 0.04863918231343789, Recall = 0.990728476821192, Aging Rate = 0.5039735099337749, Precision = 0.9829172141918529, f1 = 0.9868073878627969\n",
      "Test Loss = 0.032652737333482465, Recall = 0.9980132450331126, Aging Rate = 0.5052980132450331, precision = 0.9875491480996068\n",
      "\n",
      "Epoch 91: Train Loss = 0.04329771948546566, Recall = 0.9923841059602649, Aging Rate = 0.5044701986754967, Precision = 0.9835904168034132, f1 = 0.9879676940827428\n",
      "Epoch 92: Train Loss = 0.048717483624026475, Recall = 0.9917218543046358, Aging Rate = 0.5066225165562914, Precision = 0.9787581699346405, f1 = 0.9851973684210527\n",
      "Epoch 93: Train Loss = 0.054817432076331, Recall = 0.9884105960264901, Aging Rate = 0.5049668874172185, Precision = 0.978688524590164, f1 = 0.9835255354200989\n",
      "Epoch 94: Train Loss = 0.050097904670120076, Recall = 0.9910596026490066, Aging Rate = 0.5062913907284768, Precision = 0.9787442773054283, f1 = 0.9848634419216847\n",
      "Epoch 95: Train Loss = 0.04958379441711879, Recall = 0.9894039735099338, Aging Rate = 0.5048013245033113, Precision = 0.979993440472286, f1 = 0.9846762234305486\n",
      "Test Loss = 0.04673275755138587, Recall = 0.9910596026490066, Aging Rate = 0.5029801324503311, precision = 0.9851876234364714\n",
      "\n",
      "Epoch 96: Train Loss = 0.0475694836777271, Recall = 0.990728476821192, Aging Rate = 0.5039735099337749, Precision = 0.9829172141918529, f1 = 0.9868073878627969\n",
      "Epoch 97: Train Loss = 0.04513349018448236, Recall = 0.993046357615894, Aging Rate = 0.5048013245033113, Precision = 0.9836011807149885, f1 = 0.9883012028340749\n",
      "Epoch 98: Train Loss = 0.047900140075790174, Recall = 0.9903973509933774, Aging Rate = 0.5046357615894039, Precision = 0.9812992125984252, f1 = 0.9858272907053395\n",
      "Epoch 99: Train Loss = 0.04543739502990483, Recall = 0.9917218543046358, Aging Rate = 0.5049668874172185, Precision = 0.9819672131147541, f1 = 0.9868204283360791\n",
      "Epoch 100: Train Loss = 0.05317828868892019, Recall = 0.9867549668874173, Aging Rate = 0.5064569536423841, Precision = 0.9741745668519124, f1 = 0.9804244119098535\n",
      "Test Loss = 0.035336215436359904, Recall = 0.9960264900662251, Aging Rate = 0.5041390728476821, precision = 0.9878489326765189\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "889577f3c23541a6981361902afb60d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss = 0.6121329509659319, Recall = 0.9417218543046357, Aging Rate = 0.8612582781456953, Precision = 0.5467128027681661, f1 = 0.6918024811481392\n",
      "Epoch 2: Train Loss = 0.4587496017383424, Recall = 0.9086092715231788, Aging Rate = 0.6293046357615895, Precision = 0.7219152854511971, f1 = 0.8045741093681279\n",
      "Epoch 3: Train Loss = 0.37454485384044267, Recall = 0.9, Aging Rate = 0.5701986754966888, Precision = 0.789198606271777, f1 = 0.8409653465346534\n",
      "Epoch 4: Train Loss = 0.32287100300883614, Recall = 0.9205298013245033, Aging Rate = 0.5582781456953643, Precision = 0.8244365361803084, f1 = 0.8698372966207759\n",
      "Epoch 5: Train Loss = 0.2840092438735709, Recall = 0.9311258278145695, Aging Rate = 0.5486754966887417, Precision = 0.8485214242607121, f1 = 0.8879065361540889\n",
      "Test Loss = 0.2531470496922929, Recall = 0.9321192052980133, Aging Rate = 0.5210264900662251, precision = 0.8945027009850651\n",
      "Model in epoch 5 is saved.\n",
      "\n",
      "Epoch 6: Train Loss = 0.23906565987511186, Recall = 0.9473509933774834, Aging Rate = 0.5369205298013245, Precision = 0.8822078322540857, f1 = 0.913619671084145\n",
      "Epoch 7: Train Loss = 0.20913358395857526, Recall = 0.9536423841059603, Aging Rate = 0.5283112582781457, Precision = 0.9025383892196803, f1 = 0.9273868942199324\n",
      "Epoch 8: Train Loss = 0.1839343316310289, Recall = 0.9605960264900663, Aging Rate = 0.5213576158940397, Precision = 0.9212448396316291, f1 = 0.9405089965958827\n",
      "Epoch 9: Train Loss = 0.1640718378768062, Recall = 0.963907284768212, Aging Rate = 0.5177152317880794, Precision = 0.9309242085065558, f1 = 0.9471286806572312\n",
      "Epoch 10: Train Loss = 0.14676909545399494, Recall = 0.9685430463576159, Aging Rate = 0.5142384105960265, Precision = 0.9417256922086285, f1 = 0.9549461312438784\n",
      "Test Loss = 0.14109038235928048, Recall = 0.9543046357615894, Aging Rate = 0.49370860927152316, precision = 0.9664654594232059\n",
      "Model in epoch 10 is saved.\n",
      "\n",
      "Epoch 11: Train Loss = 0.13556675755030273, Recall = 0.9731788079470198, Aging Rate = 0.5149006622516556, Precision = 0.945016077170418, f1 = 0.9588907014681892\n",
      "Epoch 12: Train Loss = 0.12091594641374437, Recall = 0.9768211920529801, Aging Rate = 0.5119205298013245, Precision = 0.9540750323415266, f1 = 0.9653141361256544\n",
      "Epoch 13: Train Loss = 0.11177908044974535, Recall = 0.9794701986754967, Aging Rate = 0.5112582781456954, Precision = 0.957901554404145, f1 = 0.9685658153241651\n",
      "Epoch 14: Train Loss = 0.10143595338854569, Recall = 0.9814569536423841, Aging Rate = 0.508112582781457, Precision = 0.9657869012707723, f1 = 0.9735588766628346\n",
      "Epoch 15: Train Loss = 0.0954530719198928, Recall = 0.9824503311258278, Aging Rate = 0.508774834437086, Precision = 0.9655060201757241, f1 = 0.9739044805514525\n",
      "Test Loss = 0.08862984382750973, Recall = 0.9903973509933774, Aging Rate = 0.5140728476821192, precision = 0.9632850241545894\n",
      "Model in epoch 15 is saved.\n",
      "\n",
      "Epoch 16: Train Loss = 0.08811567992169336, Recall = 0.9864238410596027, Aging Rate = 0.508112582781457, Precision = 0.9706744868035191, f1 = 0.978485794054853\n",
      "Epoch 17: Train Loss = 0.0824072809408832, Recall = 0.9870860927152317, Aging Rate = 0.5064569536423841, Precision = 0.9745014710689768, f1 = 0.9807534133903603\n",
      "Epoch 18: Train Loss = 0.07787561088010965, Recall = 0.9884105960264901, Aging Rate = 0.506953642384106, Precision = 0.9748530372305683, f1 = 0.981585004932588\n",
      "Epoch 19: Train Loss = 0.07266884450091432, Recall = 0.9877483443708609, Aging Rate = 0.5056291390728477, Precision = 0.9767518009168303, f1 = 0.9822192953572604\n",
      "Epoch 20: Train Loss = 0.06940807023190505, Recall = 0.9897350993377484, Aging Rate = 0.5054635761589404, Precision = 0.9790370127743203, f1 = 0.9843569899555409\n",
      "Test Loss = 0.06394483120433542, Recall = 0.9933774834437086, Aging Rate = 0.5071192052980132, precision = 0.9794319294809011\n",
      "Model in epoch 20 is saved.\n",
      "\n",
      "Epoch 21: Train Loss = 0.06550702442297872, Recall = 0.990728476821192, Aging Rate = 0.5054635761589404, Precision = 0.980019652800524, f1 = 0.9853449695372962\n",
      "Epoch 22: Train Loss = 0.06237229976235636, Recall = 0.9933774834437086, Aging Rate = 0.5067880794701987, Precision = 0.9800718719372754, f1 = 0.986679822397632\n",
      "Epoch 23: Train Loss = 0.060044390871035344, Recall = 0.9917218543046358, Aging Rate = 0.5049668874172185, Precision = 0.9819672131147541, f1 = 0.9868204283360791\n",
      "Epoch 24: Train Loss = 0.056956591560745874, Recall = 0.9943708609271523, Aging Rate = 0.5061258278145695, Precision = 0.9823356231599607, f1 = 0.9883166035872963\n",
      "Epoch 25: Train Loss = 0.05460601655754033, Recall = 0.9940397350993377, Aging Rate = 0.5051324503311259, Precision = 0.9839396919042936, f1 = 0.9889639268654258\n",
      "Test Loss = 0.05150566060120696, Recall = 0.9963576158940397, Aging Rate = 0.5072847682119205, precision = 0.9820496083550914\n",
      "Model in epoch 25 is saved.\n",
      "\n",
      "Epoch 26: Train Loss = 0.05262566247819275, Recall = 0.9943708609271523, Aging Rate = 0.5049668874172185, Precision = 0.9845901639344262, f1 = 0.9894563426688632\n",
      "Epoch 27: Train Loss = 0.051371130095609764, Recall = 0.9947019867549669, Aging Rate = 0.5051324503311259, Precision = 0.9845952146837103, f1 = 0.9896227969033108\n",
      "Epoch 28: Train Loss = 0.04866998213904583, Recall = 0.9947019867549669, Aging Rate = 0.5048013245033113, Precision = 0.9852410626434897, f1 = 0.9899489207447686\n",
      "Epoch 29: Train Loss = 0.04736836002954584, Recall = 0.9956953642384105, Aging Rate = 0.5048013245033113, Precision = 0.9862249918005903, f1 = 0.9909375514911847\n",
      "Epoch 30: Train Loss = 0.04625829101496974, Recall = 0.9950331125827815, Aging Rate = 0.5043046357615895, Precision = 0.9865397242284963, f1 = 0.9907682162875041\n",
      "Test Loss = 0.0426027864119075, Recall = 0.9970198675496689, Aging Rate = 0.5051324503311259, precision = 0.9868895444116683\n",
      "Model in epoch 30 is saved.\n",
      "\n",
      "Epoch 31: Train Loss = 0.044975800456984946, Recall = 0.9960264900662251, Aging Rate = 0.5051324503311259, Precision = 0.9859062602425435, f1 = 0.9909405369790809\n",
      "Epoch 32: Train Loss = 0.04342511544460492, Recall = 0.9956953642384105, Aging Rate = 0.5044701986754967, Precision = 0.9868723334427305, f1 = 0.9912642162518542\n",
      "Epoch 33: Train Loss = 0.041829495314533345, Recall = 0.9947019867549669, Aging Rate = 0.503476821192053, Precision = 0.9878329496876027, f1 = 0.9912555683880548\n",
      "Epoch 34: Train Loss = 0.04076351070936942, Recall = 0.9960264900662251, Aging Rate = 0.503476821192053, Precision = 0.9891483064781322, f1 = 0.9925754825936314\n",
      "Epoch 35: Train Loss = 0.04011534568144391, Recall = 0.9960264900662251, Aging Rate = 0.5038079470198675, Precision = 0.9884981925731187, f1 = 0.9922480620155039\n",
      "Test Loss = 0.03776503862776109, Recall = 0.997682119205298, Aging Rate = 0.5031456953642384, precision = 0.9914445541296479\n",
      "Model in epoch 35 is saved.\n",
      "\n",
      "Epoch 36: Train Loss = 0.04016233046125892, Recall = 0.9966887417218543, Aging Rate = 0.5044701986754967, Precision = 0.9878569084345258, f1 = 0.9922531729025877\n",
      "Epoch 37: Train Loss = 0.03812026550240864, Recall = 0.9973509933774835, Aging Rate = 0.5039735099337749, Precision = 0.9894875164257556, f1 = 0.9934036939313985\n",
      "Epoch 38: Train Loss = 0.037389784982267596, Recall = 0.9963576158940397, Aging Rate = 0.5031456953642384, Precision = 0.9901283316880553, f1 = 0.9932332067998019\n",
      "Epoch 39: Train Loss = 0.03710978273919087, Recall = 0.9963576158940397, Aging Rate = 0.5033112582781457, Precision = 0.9898026315789473, f1 = 0.9930693069306931\n",
      "Epoch 40: Train Loss = 0.03601714415808782, Recall = 0.9970198675496689, Aging Rate = 0.5028145695364239, Precision = 0.9914389199868291, f1 = 0.9942215618292884\n",
      "Test Loss = 0.03319184832422938, Recall = 0.9983443708609272, Aging Rate = 0.502317880794702, precision = 0.9937376400791035\n",
      "Model in epoch 40 is saved.\n",
      "\n",
      "Epoch 41: Train Loss = 0.035350062207176985, Recall = 0.9973509933774835, Aging Rate = 0.5029801324503311, Precision = 0.9914417379855168, f1 = 0.9943875866622649\n",
      "Epoch 42: Train Loss = 0.03481204743860968, Recall = 0.997682119205298, Aging Rate = 0.5029801324503311, Precision = 0.9917709019091507, f1 = 0.994717728623308\n",
      "Epoch 43: Train Loss = 0.033807015863080686, Recall = 0.9973509933774835, Aging Rate = 0.502317880794702, Precision = 0.992748846407383, f1 = 0.9950445986124876\n",
      "Epoch 44: Train Loss = 0.03368653237622305, Recall = 0.997682119205298, Aging Rate = 0.5033112582781457, Precision = 0.9911184210526316, f1 = 0.9943894389438944\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45: Train Loss = 0.0329720185489844, Recall = 0.9973509933774835, Aging Rate = 0.503476821192053, Precision = 0.9904636632686616, f1 = 0.993895396799208\n",
      "Test Loss = 0.031004477992949895, Recall = 0.9990066225165563, Aging Rate = 0.5038079470198675, precision = 0.9914558001971738\n",
      "\n",
      "Epoch 46: Train Loss = 0.03358178595882773, Recall = 0.9973509933774835, Aging Rate = 0.502317880794702, Precision = 0.992748846407383, f1 = 0.9950445986124876\n",
      "Epoch 47: Train Loss = 0.03260154396492914, Recall = 0.997682119205298, Aging Rate = 0.5029801324503311, Precision = 0.9917709019091507, f1 = 0.994717728623308\n",
      "Epoch 48: Train Loss = 0.03326451625946342, Recall = 0.9973509933774835, Aging Rate = 0.5028145695364239, Precision = 0.991768192295028, f1 = 0.9945517582961863\n",
      "Epoch 49: Train Loss = 0.03129696961714337, Recall = 0.9986754966887417, Aging Rate = 0.5029801324503311, Precision = 0.9927583936800527, f1 = 0.9957081545064377\n",
      "Epoch 50: Train Loss = 0.03088948495488688, Recall = 0.9983443708609272, Aging Rate = 0.5028145695364239, Precision = 0.9927560092196246, f1 = 0.9955423476968797\n",
      "Test Loss = 0.028759420273319774, Recall = 0.9996688741721854, Aging Rate = 0.5036423841059603, precision = 0.9924391847468771\n",
      "\n",
      "Epoch 51: Train Loss = 0.03072796253277766, Recall = 0.9986754966887417, Aging Rate = 0.5036423841059603, Precision = 0.9914529914529915, f1 = 0.9950511382382052\n",
      "Epoch 52: Train Loss = 0.030063173821232966, Recall = 0.9986754966887417, Aging Rate = 0.502317880794702, Precision = 0.994067237969677, f1 = 0.9963660389824909\n",
      "Epoch 53: Train Loss = 0.02988894744621997, Recall = 0.9990066225165563, Aging Rate = 0.5033112582781457, Precision = 0.9924342105263158, f1 = 0.9957095709570958\n",
      "Epoch 54: Train Loss = 0.02929094166846465, Recall = 0.9983443708609272, Aging Rate = 0.5021523178807947, Precision = 0.9940652818991098, f1 = 0.9962002312902692\n",
      "Epoch 55: Train Loss = 0.029018226808664813, Recall = 0.9986754966887417, Aging Rate = 0.5029801324503311, Precision = 0.9927583936800527, f1 = 0.9957081545064377\n",
      "Test Loss = 0.026954340675710054, Recall = 0.9990066225165563, Aging Rate = 0.5014900662251656, precision = 0.996038296467481\n",
      "Model in epoch 55 is saved.\n",
      "\n",
      "Epoch 56: Train Loss = 0.028480270006601385, Recall = 0.9986754966887417, Aging Rate = 0.5016556291390728, Precision = 0.9953795379537954, f1 = 0.9970247933884296\n",
      "Epoch 57: Train Loss = 0.02977534859681761, Recall = 0.9993377483443708, Aging Rate = 0.503476821192053, Precision = 0.9924366984544558, f1 = 0.995875268107573\n",
      "Epoch 58: Train Loss = 0.0286398505335612, Recall = 0.9983443708609272, Aging Rate = 0.5019867549668874, Precision = 0.9943931398416886, f1 = 0.9963648380700596\n",
      "Epoch 59: Train Loss = 0.028515006466121075, Recall = 0.9983443708609272, Aging Rate = 0.5024834437086093, Precision = 0.9934102141680395, f1 = 0.9958711808422791\n",
      "Epoch 60: Train Loss = 0.02819057461244381, Recall = 0.9993377483443708, Aging Rate = 0.5024834437086093, Precision = 0.9943986820428337, f1 = 0.9968620974401321\n",
      "Test Loss = 0.02631909478431111, Recall = 0.9996688741721854, Aging Rate = 0.5018211920529801, precision = 0.9960409105905642\n",
      "Model in epoch 60 is saved.\n",
      "\n",
      "Epoch 61: Train Loss = 0.027803124593484482, Recall = 0.9983443708609272, Aging Rate = 0.502317880794702, Precision = 0.9937376400791035, f1 = 0.9960356788899902\n",
      "Epoch 62: Train Loss = 0.028128331396358692, Recall = 0.9993377483443708, Aging Rate = 0.5026490066225165, Precision = 0.9940711462450593, f1 = 0.9966974900924703\n",
      "Epoch 63: Train Loss = 0.028029733780302747, Recall = 0.9990066225165563, Aging Rate = 0.5024834437086093, Precision = 0.9940691927512356, f1 = 0.9965317919075144\n",
      "Epoch 64: Train Loss = 0.028337728987071688, Recall = 0.9986754966887417, Aging Rate = 0.5018211920529801, Precision = 0.9950511382382052, f1 = 0.9968600231366715\n",
      "Epoch 65: Train Loss = 0.028172437923140083, Recall = 0.9986754966887417, Aging Rate = 0.5026490066225165, Precision = 0.9934123847167325, f1 = 0.9960369881109644\n",
      "Test Loss = 0.025391826766314886, Recall = 0.9996688741721854, Aging Rate = 0.502317880794702, precision = 0.9950560316413974\n",
      "\n",
      "Epoch 66: Train Loss = 0.027097944120894994, Recall = 0.9993377483443708, Aging Rate = 0.502317880794702, Precision = 0.994726433750824, f1 = 0.9970267591674926\n",
      "Epoch 67: Train Loss = 0.027406982161005997, Recall = 0.9993377483443708, Aging Rate = 0.5029801324503311, Precision = 0.9934167215273206, f1 = 0.9963684384285243\n",
      "Epoch 68: Train Loss = 0.026783908306565504, Recall = 0.9990066225165563, Aging Rate = 0.5021523178807947, Precision = 0.9947246950214309, f1 = 0.996861060631092\n",
      "Epoch 69: Train Loss = 0.027323974789866548, Recall = 0.9986754966887417, Aging Rate = 0.5016556291390728, Precision = 0.9953795379537954, f1 = 0.9970247933884296\n",
      "Epoch 70: Train Loss = 0.02728717297266256, Recall = 0.9993377483443708, Aging Rate = 0.5024834437086093, Precision = 0.9943986820428337, f1 = 0.9968620974401321\n",
      "Test Loss = 0.02844929943070901, Recall = 0.9983443708609272, Aging Rate = 0.5003311258278146, precision = 0.9976836532097948\n",
      "Model in epoch 70 is saved.\n",
      "\n",
      "Epoch 71: Train Loss = 0.027103338052598847, Recall = 0.9986754966887417, Aging Rate = 0.5016556291390728, Precision = 0.9953795379537954, f1 = 0.9970247933884296\n",
      "Epoch 72: Train Loss = 0.026649195039706513, Recall = 0.9986754966887417, Aging Rate = 0.5018211920529801, Precision = 0.9950511382382052, f1 = 0.9968600231366715\n",
      "Epoch 73: Train Loss = 0.02680418115380584, Recall = 0.9983443708609272, Aging Rate = 0.502317880794702, Precision = 0.9937376400791035, f1 = 0.9960356788899902\n",
      "Epoch 74: Train Loss = 0.026525087057557326, Recall = 0.9993377483443708, Aging Rate = 0.502317880794702, Precision = 0.994726433750824, f1 = 0.9970267591674926\n",
      "Epoch 75: Train Loss = 0.026504067489445605, Recall = 0.9993377483443708, Aging Rate = 0.5019867549668874, Precision = 0.9953825857519789, f1 = 0.9973562458691342\n",
      "Test Loss = 0.02575035946604037, Recall = 1.0, Aging Rate = 0.5026490066225165, precision = 0.994729907773386\n",
      "\n",
      "Epoch 76: Train Loss = 0.025998089144265414, Recall = 0.9996688741721854, Aging Rate = 0.502317880794702, Precision = 0.9950560316413974, f1 = 0.9973571192599933\n",
      "Epoch 77: Train Loss = 0.026647756125358555, Recall = 0.9990066225165563, Aging Rate = 0.5019867549668874, Precision = 0.9950527704485488, f1 = 0.9970257766027759\n",
      "Epoch 78: Train Loss = 0.025821333842364368, Recall = 0.9996688741721854, Aging Rate = 0.5016556291390728, Precision = 0.9963696369636964, f1 = 0.9980165289256199\n",
      "Epoch 79: Train Loss = 0.025802511684843245, Recall = 0.9990066225165563, Aging Rate = 0.5016556291390728, Precision = 0.9957095709570957, f1 = 0.9973553719008265\n",
      "Epoch 80: Train Loss = 0.026029321173859747, Recall = 1.0, Aging Rate = 0.5021523178807947, Precision = 0.9957138147049126, f1 = 0.9978523046423261\n",
      "Test Loss = 0.026408541197611008, Recall = 0.9986754966887417, Aging Rate = 0.4996688741721854, precision = 0.9993373094764745\n",
      "Model in epoch 80 is saved.\n",
      "\n",
      "Epoch 81: Train Loss = 0.025979208368931386, Recall = 0.9986754966887417, Aging Rate = 0.5004966887417218, Precision = 0.9976844194508766, f1 = 0.9981797120635445\n",
      "Epoch 82: Train Loss = 0.026362821074905774, Recall = 0.9986754966887417, Aging Rate = 0.5021523178807947, Precision = 0.9943949884602704, f1 = 0.9965306459606807\n",
      "Epoch 83: Train Loss = 0.02611085492007385, Recall = 0.9993377483443708, Aging Rate = 0.502317880794702, Precision = 0.994726433750824, f1 = 0.9970267591674926\n",
      "Epoch 84: Train Loss = 0.02546920557290513, Recall = 0.9993377483443708, Aging Rate = 0.5019867549668874, Precision = 0.9953825857519789, f1 = 0.9973562458691342\n",
      "Epoch 85: Train Loss = 0.026728202348315952, Recall = 0.9990066225165563, Aging Rate = 0.5021523178807947, Precision = 0.9947246950214309, f1 = 0.996861060631092\n",
      "Test Loss = 0.023894134760889786, Recall = 0.9993377483443708, Aging Rate = 0.5009933774834437, precision = 0.9973562458691342\n",
      "\n",
      "Epoch 86: Train Loss = 0.025797810543649245, Recall = 0.9990066225165563, Aging Rate = 0.5016556291390728, Precision = 0.9957095709570957, f1 = 0.9973553719008265\n",
      "Epoch 87: Train Loss = 0.025370995843449966, Recall = 0.9990066225165563, Aging Rate = 0.5016556291390728, Precision = 0.9957095709570957, f1 = 0.9973553719008265\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 88: Train Loss = 0.025562431505381667, Recall = 0.9993377483443708, Aging Rate = 0.5016556291390728, Precision = 0.996039603960396, f1 = 0.9976859504132232\n",
      "Epoch 89: Train Loss = 0.025225405528253277, Recall = 0.9993377483443708, Aging Rate = 0.5021523178807947, Precision = 0.9950544015825915, f1 = 0.9971914753015033\n",
      "Epoch 90: Train Loss = 0.02543939472922426, Recall = 0.9990066225165563, Aging Rate = 0.5013245033112583, Precision = 0.9963672391017173, f1 = 0.9976851851851852\n",
      "Test Loss = 0.02366052305461555, Recall = 0.9996688741721854, Aging Rate = 0.5018211920529801, precision = 0.9960409105905642\n",
      "\n",
      "Epoch 91: Train Loss = 0.025275748945920672, Recall = 0.9990066225165563, Aging Rate = 0.5019867549668874, Precision = 0.9950527704485488, f1 = 0.9970257766027759\n",
      "Epoch 92: Train Loss = 0.02499827869137786, Recall = 0.9993377483443708, Aging Rate = 0.5018211920529801, Precision = 0.9957109864731112, f1 = 0.9975210708973722\n",
      "Epoch 93: Train Loss = 0.025609581493186633, Recall = 0.9990066225165563, Aging Rate = 0.5018211920529801, Precision = 0.9953810623556582, f1 = 0.9971905470170219\n",
      "Epoch 94: Train Loss = 0.025414675582718375, Recall = 0.9993377483443708, Aging Rate = 0.5013245033112583, Precision = 0.9966974900924703, f1 = 0.998015873015873\n",
      "Epoch 95: Train Loss = 0.025064552148545024, Recall = 0.9993377483443708, Aging Rate = 0.5016556291390728, Precision = 0.996039603960396, f1 = 0.9976859504132232\n",
      "Test Loss = 0.02342134239460459, Recall = 1.0, Aging Rate = 0.5014900662251656, precision = 0.9970287223506108\n",
      "\n",
      "Epoch 96: Train Loss = 0.02515708732338536, Recall = 0.9993377483443708, Aging Rate = 0.5009933774834437, Precision = 0.9973562458691342, f1 = 0.9983460138934833\n",
      "Epoch 97: Train Loss = 0.024743438272780142, Recall = 0.9996688741721854, Aging Rate = 0.5018211920529801, Precision = 0.9960409105905642, f1 = 0.9978515947777227\n",
      "Epoch 98: Train Loss = 0.025450590090049022, Recall = 1.0, Aging Rate = 0.5019867549668874, Precision = 0.996042216358839, f1 = 0.9980171844018507\n",
      "Epoch 99: Train Loss = 0.025204100812606465, Recall = 0.9990066225165563, Aging Rate = 0.5018211920529801, Precision = 0.9953810623556582, f1 = 0.9971905470170219\n",
      "Epoch 100: Train Loss = 0.02504122174585497, Recall = 0.9993377483443708, Aging Rate = 0.5014900662251656, Precision = 0.9963684384285243, f1 = 0.9978508844437097\n",
      "Test Loss = 0.02328131130298242, Recall = 0.9996688741721854, Aging Rate = 0.5016556291390728, precision = 0.9963696369636964\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55bdaaaeb27449bcb57f5e067e74d2d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss = 0.620566329261325, Recall = 0.963907284768212, Aging Rate = 0.8973509933774835, Precision = 0.5370848708487085, f1 = 0.6898104265402845\n",
      "Epoch 2: Train Loss = 0.46697697011840267, Recall = 0.9079470198675497, Aging Rate = 0.6283112582781457, Precision = 0.7225296442687748, f1 = 0.8046955245781365\n",
      "Epoch 3: Train Loss = 0.37888681474110936, Recall = 0.9036423841059603, Aging Rate = 0.5745033112582781, Precision = 0.7864553314121038, f1 = 0.8409861325115562\n",
      "Epoch 4: Train Loss = 0.3315671386702961, Recall = 0.9175496688741722, Aging Rate = 0.5576158940397351, Precision = 0.8227434679334917, f1 = 0.8675641828428303\n",
      "Epoch 5: Train Loss = 0.29182639931211407, Recall = 0.9344370860927153, Aging Rate = 0.5514900662251656, Precision = 0.8471930351245872, f1 = 0.8886789481971343\n",
      "Test Loss = 0.26159621536336986, Recall = 0.9430463576158941, Aging Rate = 0.5425496688741722, precision = 0.8690875801037534\n",
      "Model in epoch 5 is saved.\n",
      "\n",
      "Epoch 6: Train Loss = 0.2502973581584084, Recall = 0.9433774834437086, Aging Rate = 0.5394039735099337, Precision = 0.874462860650706, f1 = 0.9076138897738133\n",
      "Epoch 7: Train Loss = 0.2198440083210042, Recall = 0.952317880794702, Aging Rate = 0.5359271523178808, Precision = 0.888476984862527, f1 = 0.9192903947578712\n",
      "Epoch 8: Train Loss = 0.19310878894186967, Recall = 0.9592715231788079, Aging Rate = 0.5304635761589404, Precision = 0.9041822721598003, f1 = 0.9309125964010283\n",
      "Epoch 9: Train Loss = 0.172142942654376, Recall = 0.9622516556291391, Aging Rate = 0.5220198675496689, Precision = 0.9216619092927371, f1 = 0.9415195204924671\n",
      "Epoch 10: Train Loss = 0.1538071597451406, Recall = 0.9688741721854305, Aging Rate = 0.5205298013245033, Precision = 0.9306615776081425, f1 = 0.9493835171966255\n",
      "Test Loss = 0.14161635667875114, Recall = 0.9745033112582782, Aging Rate = 0.5206953642384106, precision = 0.9357710651828299\n",
      "Model in epoch 10 is saved.\n",
      "\n",
      "Epoch 11: Train Loss = 0.13791023066501742, Recall = 0.9725165562913908, Aging Rate = 0.5155629139072848, Precision = 0.9431599229287091, f1 = 0.9576133029018585\n",
      "Epoch 12: Train Loss = 0.1258458900135874, Recall = 0.9768211920529801, Aging Rate = 0.5147350993377483, Precision = 0.9488581537471856, f1 = 0.9626366454560288\n",
      "Epoch 13: Train Loss = 0.11502706082846155, Recall = 0.980794701986755, Aging Rate = 0.5139072847682119, Precision = 0.9542525773195877, f1 = 0.9673416067929458\n",
      "Epoch 14: Train Loss = 0.10602619695347666, Recall = 0.9817880794701986, Aging Rate = 0.5099337748344371, Precision = 0.9626623376623377, f1 = 0.9721311475409836\n",
      "Epoch 15: Train Loss = 0.09810167008283123, Recall = 0.9837748344370861, Aging Rate = 0.5086092715231788, Precision = 0.9671223958333334, f1 = 0.9753775443204202\n",
      "Test Loss = 0.09098198995092846, Recall = 0.9880794701986755, Aging Rate = 0.510430463576159, precision = 0.9678884203697697\n",
      "Model in epoch 15 is saved.\n",
      "\n",
      "Epoch 16: Train Loss = 0.09138715086591165, Recall = 0.9847682119205298, Aging Rate = 0.508774834437086, Precision = 0.9677839245037423, f1 = 0.9762021992450353\n",
      "Epoch 17: Train Loss = 0.08552159658133589, Recall = 0.9870860927152317, Aging Rate = 0.5077814569536424, Precision = 0.9719595696119987, f1 = 0.9794644323969113\n",
      "Epoch 18: Train Loss = 0.08004464581115356, Recall = 0.9877483443708609, Aging Rate = 0.5066225165562914, Precision = 0.9748366013071895, f1 = 0.98125\n",
      "Epoch 19: Train Loss = 0.07609123148961572, Recall = 0.9890728476821192, Aging Rate = 0.5066225165562914, Precision = 0.9761437908496732, f1 = 0.9825657894736842\n",
      "Epoch 20: Train Loss = 0.07157697818729261, Recall = 0.9917218543046358, Aging Rate = 0.5067880794701987, Precision = 0.9784384188173799, f1 = 0.9850353560269692\n",
      "Test Loss = 0.06914169819939216, Recall = 0.9860927152317881, Aging Rate = 0.4991721854304636, precision = 0.9877280265339967\n",
      "Model in epoch 20 is saved.\n",
      "\n",
      "Epoch 21: Train Loss = 0.06783720907193935, Recall = 0.9910596026490066, Aging Rate = 0.5051324503311259, Precision = 0.9809898393969191, f1 = 0.9859990116949431\n",
      "Epoch 22: Train Loss = 0.06549352469625852, Recall = 0.9910596026490066, Aging Rate = 0.5056291390728477, Precision = 0.9800261951538966, f1 = 0.9855120184392492\n",
      "Epoch 23: Train Loss = 0.06235455246950617, Recall = 0.9923841059602649, Aging Rate = 0.5046357615894039, Precision = 0.9832677165354331, f1 = 0.9878048780487805\n",
      "Epoch 24: Train Loss = 0.060399601110164694, Recall = 0.9923841059602649, Aging Rate = 0.5049668874172185, Precision = 0.9826229508196721, f1 = 0.9874794069192752\n",
      "Epoch 25: Train Loss = 0.05721707217247281, Recall = 0.9933774834437086, Aging Rate = 0.5039735099337749, Precision = 0.985545335085414, f1 = 0.9894459102902374\n",
      "Test Loss = 0.054585600930531296, Recall = 0.9966887417218543, Aging Rate = 0.5079470198675496, precision = 0.9810951760104303\n",
      "\n",
      "Epoch 26: Train Loss = 0.05483080155604723, Recall = 0.9933774834437086, Aging Rate = 0.5041390728476821, Precision = 0.9852216748768473, f1 = 0.989282769991756\n",
      "Epoch 27: Train Loss = 0.05317755558632857, Recall = 0.9933774834437086, Aging Rate = 0.5048013245033113, Precision = 0.9839291571006887, f1 = 0.9886307464162135\n",
      "Epoch 28: Train Loss = 0.05146240563384744, Recall = 0.9933774834437086, Aging Rate = 0.5038079470198675, Precision = 0.9858692080184029, f1 = 0.9896091044037606\n",
      "Epoch 29: Train Loss = 0.049357634363387595, Recall = 0.9940397350993377, Aging Rate = 0.5036423841059603, Precision = 0.9868507560815253, f1 = 0.9904322005938634\n",
      "Epoch 30: Train Loss = 0.04780073942036818, Recall = 0.9953642384105961, Aging Rate = 0.5044701986754967, Precision = 0.9865441417787988, f1 = 0.9909345640349432\n",
      "Test Loss = 0.0454701464598542, Recall = 0.997682119205298, Aging Rate = 0.5066225165562914, precision = 0.984640522875817\n",
      "Model in epoch 30 is saved.\n",
      "\n",
      "Epoch 31: Train Loss = 0.047533879229268494, Recall = 0.9940397350993377, Aging Rate = 0.5036423841059603, Precision = 0.9868507560815253, f1 = 0.9904322005938634\n",
      "Epoch 32: Train Loss = 0.04552012136736453, Recall = 0.9953642384105961, Aging Rate = 0.5039735099337749, Precision = 0.9875164257555847, f1 = 0.9914248021108178\n",
      "Epoch 33: Train Loss = 0.04443306409760027, Recall = 0.9963576158940397, Aging Rate = 0.5041390728476821, Precision = 0.9881773399014778, f1 = 0.9922506183017313\n",
      "Epoch 34: Train Loss = 0.04312635007382229, Recall = 0.9950331125827815, Aging Rate = 0.5043046357615895, Precision = 0.9865397242284963, f1 = 0.9907682162875041\n",
      "Epoch 35: Train Loss = 0.04183678126196987, Recall = 0.9956953642384105, Aging Rate = 0.5038079470198675, Precision = 0.9881695695037792, f1 = 0.9919181923140359\n",
      "Test Loss = 0.038996776356207616, Recall = 0.9970198675496689, Aging Rate = 0.503476821192053, precision = 0.9901348240710293\n",
      "Model in epoch 35 is saved.\n",
      "\n",
      "Epoch 36: Train Loss = 0.041055472799582986, Recall = 0.9966887417218543, Aging Rate = 0.5041390728476821, Precision = 0.9885057471264368, f1 = 0.9925803792250618\n",
      "Epoch 37: Train Loss = 0.04076669898550242, Recall = 0.9960264900662251, Aging Rate = 0.5033112582781457, Precision = 0.9894736842105263, f1 = 0.9927392739273928\n",
      "Epoch 38: Train Loss = 0.03990980266340521, Recall = 0.9970198675496689, Aging Rate = 0.5048013245033113, Precision = 0.9875368973433912, f1 = 0.9922557258197398\n",
      "Epoch 39: Train Loss = 0.03891179906019312, Recall = 0.9973509933774835, Aging Rate = 0.5043046357615895, Precision = 0.9888378200919238, f1 = 0.9930761622156281\n",
      "Epoch 40: Train Loss = 0.038053234402608396, Recall = 0.9970198675496689, Aging Rate = 0.5046357615894039, Precision = 0.9878608923884514, f1 = 0.9924192485168094\n",
      "Test Loss = 0.035710233963088485, Recall = 0.9970198675496689, Aging Rate = 0.5019867549668874, precision = 0.9930738786279684\n",
      "Model in epoch 40 is saved.\n",
      "\n",
      "Epoch 41: Train Loss = 0.03794403906590891, Recall = 0.9970198675496689, Aging Rate = 0.5036423841059603, Precision = 0.9898093359631821, f1 = 0.9934015176509403\n",
      "Epoch 42: Train Loss = 0.03691975322878913, Recall = 0.9966887417218543, Aging Rate = 0.5029801324503311, Precision = 0.9907834101382489, f1 = 0.9937273027401784\n",
      "Epoch 43: Train Loss = 0.03681437155564889, Recall = 0.9963576158940397, Aging Rate = 0.5024834437086093, Precision = 0.9914332784184514, f1 = 0.9938893476465731\n",
      "Epoch 44: Train Loss = 0.03530557268107964, Recall = 0.9980132450331126, Aging Rate = 0.5043046357615895, Precision = 0.989494418910046, f1 = 0.9937355753379492\n",
      "Epoch 45: Train Loss = 0.03544704945178222, Recall = 0.9973509933774835, Aging Rate = 0.5033112582781457, Precision = 0.9907894736842106, f1 = 0.9940594059405942\n",
      "Test Loss = 0.03221989322379725, Recall = 0.997682119205298, Aging Rate = 0.502317880794702, precision = 0.9930784442979564\n",
      "Model in epoch 45 is saved.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 46: Train Loss = 0.03445218088018973, Recall = 0.9980132450331126, Aging Rate = 0.503476821192053, Precision = 0.9911213416639263, f1 = 0.9945553539019963\n",
      "Epoch 47: Train Loss = 0.03382405217317556, Recall = 0.997682119205298, Aging Rate = 0.5033112582781457, Precision = 0.9911184210526316, f1 = 0.9943894389438944\n",
      "Epoch 48: Train Loss = 0.03358217860442518, Recall = 0.9970198675496689, Aging Rate = 0.5028145695364239, Precision = 0.9914389199868291, f1 = 0.9942215618292884\n",
      "Epoch 49: Train Loss = 0.033212577892060315, Recall = 0.997682119205298, Aging Rate = 0.5028145695364239, Precision = 0.9920974646032269, f1 = 0.994881954763084\n",
      "Epoch 50: Train Loss = 0.033410933668052915, Recall = 0.9983443708609272, Aging Rate = 0.5031456953642384, Precision = 0.9921026653504442, f1 = 0.9952137316388844\n",
      "Test Loss = 0.030440627906890894, Recall = 0.9986754966887417, Aging Rate = 0.5033112582781457, precision = 0.9921052631578947\n",
      "\n",
      "Epoch 51: Train Loss = 0.03297770396861809, Recall = 0.9970198675496689, Aging Rate = 0.5024834437086093, Precision = 0.9920922570016475, f1 = 0.9945499587118084\n",
      "Epoch 52: Train Loss = 0.03219458684325218, Recall = 0.9980132450331126, Aging Rate = 0.5031456953642384, Precision = 0.991773609740046, f1 = 0.994883644165704\n",
      "Epoch 53: Train Loss = 0.032196043967115166, Recall = 0.9983443708609272, Aging Rate = 0.5038079470198675, Precision = 0.9907985540584949, f1 = 0.9945571499257793\n",
      "Epoch 54: Train Loss = 0.03181779029600273, Recall = 0.9980132450331126, Aging Rate = 0.5029801324503311, Precision = 0.9921000658327848, f1 = 0.9950478705843513\n",
      "Epoch 55: Train Loss = 0.03126934312333334, Recall = 0.9980132450331126, Aging Rate = 0.5026490066225165, Precision = 0.9927536231884058, f1 = 0.9953764861294584\n",
      "Test Loss = 0.028789879983624086, Recall = 0.9986754966887417, Aging Rate = 0.5018211920529801, precision = 0.9950511382382052\n",
      "Model in epoch 55 is saved.\n",
      "\n",
      "Epoch 56: Train Loss = 0.03086281990176005, Recall = 0.9980132450331126, Aging Rate = 0.502317880794702, Precision = 0.99340804218853, f1 = 0.9957053187974892\n",
      "Epoch 57: Train Loss = 0.031016761237224997, Recall = 0.9983443708609272, Aging Rate = 0.502317880794702, Precision = 0.9937376400791035, f1 = 0.9960356788899902\n",
      "Epoch 58: Train Loss = 0.030866241307053344, Recall = 0.9980132450331126, Aging Rate = 0.5033112582781457, Precision = 0.9914473684210526, f1 = 0.9947194719471948\n",
      "Epoch 59: Train Loss = 0.03068093192202366, Recall = 0.997682119205298, Aging Rate = 0.5024834437086093, Precision = 0.9927512355848435, f1 = 0.9952105697770437\n",
      "Epoch 60: Train Loss = 0.029978618563603093, Recall = 0.9980132450331126, Aging Rate = 0.5026490066225165, Precision = 0.9927536231884058, f1 = 0.9953764861294584\n",
      "Test Loss = 0.02809745723147266, Recall = 0.9980132450331126, Aging Rate = 0.5014900662251656, precision = 0.9950478705843513\n",
      "\n",
      "Epoch 61: Train Loss = 0.03017565117569159, Recall = 0.9983443708609272, Aging Rate = 0.5026490066225165, Precision = 0.9930830039525692, f1 = 0.9957067371202114\n",
      "Epoch 62: Train Loss = 0.02967396869712713, Recall = 0.997682119205298, Aging Rate = 0.502317880794702, Precision = 0.9930784442979564, f1 = 0.9953749587049884\n",
      "Epoch 63: Train Loss = 0.030084398638037656, Recall = 0.9983443708609272, Aging Rate = 0.5028145695364239, Precision = 0.9927560092196246, f1 = 0.9955423476968797\n",
      "Epoch 64: Train Loss = 0.03075413831713184, Recall = 0.997682119205298, Aging Rate = 0.5024834437086093, Precision = 0.9927512355848435, f1 = 0.9952105697770437\n",
      "Epoch 65: Train Loss = 0.029366932666262256, Recall = 0.9986754966887417, Aging Rate = 0.5026490066225165, Precision = 0.9934123847167325, f1 = 0.9960369881109644\n",
      "Test Loss = 0.027380501424634694, Recall = 0.9993377483443708, Aging Rate = 0.5039735099337749, precision = 0.9914586070959264\n",
      "\n",
      "Epoch 66: Train Loss = 0.02871977080473837, Recall = 0.9986754966887417, Aging Rate = 0.5019867549668874, Precision = 0.9947229551451188, f1 = 0.9966953073364176\n",
      "Epoch 67: Train Loss = 0.028874586083439013, Recall = 0.9980132450331126, Aging Rate = 0.502317880794702, Precision = 0.99340804218853, f1 = 0.9957053187974892\n",
      "Epoch 68: Train Loss = 0.02908147650937371, Recall = 0.9986754966887417, Aging Rate = 0.5021523178807947, Precision = 0.9943949884602704, f1 = 0.9965306459606807\n",
      "Epoch 69: Train Loss = 0.02881411836044678, Recall = 0.9990066225165563, Aging Rate = 0.5026490066225165, Precision = 0.9937417654808959, f1 = 0.9963672391017173\n",
      "Epoch 70: Train Loss = 0.028684853952353363, Recall = 0.9986754966887417, Aging Rate = 0.5024834437086093, Precision = 0.9937397034596376, f1 = 0.9962014863748967\n",
      "Test Loss = 0.026732186494481485, Recall = 0.9986754966887417, Aging Rate = 0.5006622516556292, precision = 0.9973544973544973\n",
      "Model in epoch 70 is saved.\n",
      "\n",
      "Epoch 71: Train Loss = 0.02842078304399323, Recall = 0.9986754966887417, Aging Rate = 0.502317880794702, Precision = 0.994067237969677, f1 = 0.9963660389824909\n",
      "Epoch 72: Train Loss = 0.028231592809423705, Recall = 0.9983443708609272, Aging Rate = 0.5019867549668874, Precision = 0.9943931398416886, f1 = 0.9963648380700596\n",
      "Epoch 73: Train Loss = 0.029058403020959026, Recall = 0.9990066225165563, Aging Rate = 0.5021523178807947, Precision = 0.9947246950214309, f1 = 0.996861060631092\n",
      "Epoch 74: Train Loss = 0.027897369190557113, Recall = 0.9983443708609272, Aging Rate = 0.5026490066225165, Precision = 0.9930830039525692, f1 = 0.9957067371202114\n",
      "Epoch 75: Train Loss = 0.028029254068996732, Recall = 0.9980132450331126, Aging Rate = 0.5018211920529801, Precision = 0.9943912900032993, f1 = 0.9961989753759709\n",
      "Test Loss = 0.0264073241452705, Recall = 0.9990066225165563, Aging Rate = 0.5013245033112583, precision = 0.9963672391017173\n",
      "\n",
      "Epoch 76: Train Loss = 0.02807577307157169, Recall = 0.9986754966887417, Aging Rate = 0.502317880794702, Precision = 0.994067237969677, f1 = 0.9963660389824909\n",
      "Epoch 77: Train Loss = 0.028242763630207012, Recall = 0.9986754966887417, Aging Rate = 0.502317880794702, Precision = 0.994067237969677, f1 = 0.9963660389824909\n",
      "Epoch 78: Train Loss = 0.029317515676483413, Recall = 0.9983443708609272, Aging Rate = 0.5019867549668874, Precision = 0.9943931398416886, f1 = 0.9963648380700596\n",
      "Epoch 79: Train Loss = 0.02762829451667552, Recall = 0.9986754966887417, Aging Rate = 0.5026490066225165, Precision = 0.9934123847167325, f1 = 0.9960369881109644\n",
      "Epoch 80: Train Loss = 0.027495076832984456, Recall = 0.9990066225165563, Aging Rate = 0.5019867549668874, Precision = 0.9950527704485488, f1 = 0.9970257766027759\n",
      "Test Loss = 0.025325120003610258, Recall = 0.9986754966887417, Aging Rate = 0.5006622516556292, precision = 0.9973544973544973\n",
      "\n",
      "Epoch 81: Train Loss = 0.0275009199138114, Recall = 0.9990066225165563, Aging Rate = 0.5018211920529801, Precision = 0.9953810623556582, f1 = 0.9971905470170219\n",
      "Epoch 82: Train Loss = 0.027178063251028787, Recall = 0.9993377483443708, Aging Rate = 0.5024834437086093, Precision = 0.9943986820428337, f1 = 0.9968620974401321\n",
      "Epoch 83: Train Loss = 0.02734247592111297, Recall = 0.9980132450331126, Aging Rate = 0.5016556291390728, Precision = 0.9947194719471947, f1 = 0.9963636363636363\n",
      "Epoch 84: Train Loss = 0.027105279276702577, Recall = 0.9986754966887417, Aging Rate = 0.5019867549668874, Precision = 0.9947229551451188, f1 = 0.9966953073364176\n",
      "Epoch 85: Train Loss = 0.027476997175161413, Recall = 0.9980132450331126, Aging Rate = 0.5016556291390728, Precision = 0.9947194719471947, f1 = 0.9963636363636363\n",
      "Test Loss = 0.025798722827770064, Recall = 1.0, Aging Rate = 0.5043046357615895, precision = 0.9914642153644123\n",
      "\n",
      "Epoch 86: Train Loss = 0.02724281009903412, Recall = 0.9993377483443708, Aging Rate = 0.502317880794702, Precision = 0.994726433750824, f1 = 0.9970267591674926\n",
      "Epoch 87: Train Loss = 0.027156471343871377, Recall = 0.9986754966887417, Aging Rate = 0.5021523178807947, Precision = 0.9943949884602704, f1 = 0.9965306459606807\n",
      "Epoch 88: Train Loss = 0.027521734186355642, Recall = 0.9986754966887417, Aging Rate = 0.5016556291390728, Precision = 0.9953795379537954, f1 = 0.9970247933884296\n",
      "Epoch 89: Train Loss = 0.02671985583293517, Recall = 0.9986754966887417, Aging Rate = 0.5014900662251656, Precision = 0.9957081545064378, f1 = 0.9971896181186972\n",
      "Epoch 90: Train Loss = 0.027129200246456445, Recall = 0.9986754966887417, Aging Rate = 0.5013245033112583, Precision = 0.9960369881109643, f1 = 0.9973544973544972\n",
      "Test Loss = 0.027236869442739235, Recall = 0.9993377483443708, Aging Rate = 0.5009933774834437, precision = 0.9973562458691342\n",
      "Model in epoch 90 is saved.\n",
      "\n",
      "Epoch 91: Train Loss = 0.027286760792728293, Recall = 0.9986754966887417, Aging Rate = 0.5016556291390728, Precision = 0.9953795379537954, f1 = 0.9970247933884296\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 92: Train Loss = 0.027386923112123217, Recall = 0.9990066225165563, Aging Rate = 0.5021523178807947, Precision = 0.9947246950214309, f1 = 0.996861060631092\n",
      "Epoch 93: Train Loss = 0.026793643077280348, Recall = 0.9986754966887417, Aging Rate = 0.5013245033112583, Precision = 0.9960369881109643, f1 = 0.9973544973544972\n",
      "Epoch 94: Train Loss = 0.027257357263900585, Recall = 0.9986754966887417, Aging Rate = 0.5026490066225165, Precision = 0.9934123847167325, f1 = 0.9960369881109644\n",
      "Epoch 95: Train Loss = 0.027936395085015834, Recall = 0.9990066225165563, Aging Rate = 0.5014900662251656, Precision = 0.996038296467481, f1 = 0.9975202512812035\n",
      "Test Loss = 0.024816679994002083, Recall = 1.0, Aging Rate = 0.5024834437086093, precision = 0.9950576606260296\n",
      "\n",
      "Epoch 96: Train Loss = 0.02630241425424222, Recall = 0.9996688741721854, Aging Rate = 0.5024834437086093, Precision = 0.9947281713344316, f1 = 0.9971924029727498\n",
      "Epoch 97: Train Loss = 0.0266180320982112, Recall = 0.997682119205298, Aging Rate = 0.5018211920529801, Precision = 0.9940613658858463, f1 = 0.9958684514956206\n",
      "Epoch 98: Train Loss = 0.026814134428832705, Recall = 0.9986754966887417, Aging Rate = 0.5014900662251656, Precision = 0.9957081545064378, f1 = 0.9971896181186972\n",
      "Epoch 99: Train Loss = 0.026750987506662775, Recall = 0.9986754966887417, Aging Rate = 0.5016556291390728, Precision = 0.9953795379537954, f1 = 0.9970247933884296\n",
      "Epoch 100: Train Loss = 0.02637214670266142, Recall = 0.9990066225165563, Aging Rate = 0.5018211920529801, Precision = 0.9953810623556582, f1 = 0.9971905470170219\n",
      "Test Loss = 0.02463651696429742, Recall = 0.9996688741721854, Aging Rate = 0.502317880794702, precision = 0.9950560316413974\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2255c1716c12418b842f0d4b4d7a2a4c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss = 0.6100037159509216, Recall = 0.9708609271523179, Aging Rate = 0.8798013245033113, Precision = 0.5517500940910801, f1 = 0.7036237101031916\n",
      "Epoch 2: Train Loss = 0.4585847682905513, Recall = 0.8927152317880794, Aging Rate = 0.6099337748344371, Precision = 0.7318132464712269, f1 = 0.8042959427207637\n",
      "Epoch 3: Train Loss = 0.3749544091966768, Recall = 0.9019867549668874, Aging Rate = 0.5725165562913908, Precision = 0.7877385772122614, f1 = 0.8410003087372645\n",
      "Epoch 4: Train Loss = 0.3226338721663747, Recall = 0.9165562913907285, Aging Rate = 0.5562913907284768, Precision = 0.8238095238095238, f1 = 0.8677115987460815\n",
      "Epoch 5: Train Loss = 0.28406195581354055, Recall = 0.9281456953642384, Aging Rate = 0.5471854304635762, Precision = 0.8481089258698941, f1 = 0.8863241106719367\n",
      "Test Loss = 0.25249851646012816, Recall = 0.9456953642384106, Aging Rate = 0.5412251655629139, precision = 0.8736616702355461\n",
      "Model in epoch 5 is saved.\n",
      "\n",
      "Epoch 6: Train Loss = 0.23948871783468106, Recall = 0.9447019867549669, Aging Rate = 0.53658940397351, Precision = 0.8802838630052453, f1 = 0.9113560134163872\n",
      "Epoch 7: Train Loss = 0.20823114843952734, Recall = 0.9549668874172186, Aging Rate = 0.5294701986754967, Precision = 0.9018136335209506, f1 = 0.9276294628497909\n",
      "Epoch 8: Train Loss = 0.18195691321859297, Recall = 0.9632450331125828, Aging Rate = 0.5230132450331125, Precision = 0.9208610319721431, f1 = 0.9415763068457679\n",
      "Epoch 9: Train Loss = 0.16081260644047465, Recall = 0.9695364238410596, Aging Rate = 0.5175496688741722, Precision = 0.9366602687140115, f1 = 0.9528148389196226\n",
      "Epoch 10: Train Loss = 0.14262842946494653, Recall = 0.9745033112582782, Aging Rate = 0.5150662251655629, Precision = 0.9459980713596914, f1 = 0.9600391453270266\n",
      "Test Loss = 0.1306159715186681, Recall = 0.976158940397351, Aging Rate = 0.5117549668874172, precision = 0.9537366548042705\n",
      "Model in epoch 10 is saved.\n",
      "\n",
      "Epoch 11: Train Loss = 0.1302238049096619, Recall = 0.9758278145695364, Aging Rate = 0.5120860927152318, Precision = 0.9527966375687035, f1 = 0.9641747096352037\n",
      "Epoch 12: Train Loss = 0.1169092203410256, Recall = 0.9791390728476821, Aging Rate = 0.5112582781456954, Precision = 0.9575777202072538, f1 = 0.9682383759004584\n",
      "Epoch 13: Train Loss = 0.10754646950999633, Recall = 0.9811258278145696, Aging Rate = 0.5091059602649006, Precision = 0.9635772357723578, f1 = 0.9722723543888434\n",
      "Epoch 14: Train Loss = 0.09763529928314765, Recall = 0.9824503311258278, Aging Rate = 0.5084437086092716, Precision = 0.9661348095083034, f1 = 0.9742242653094729\n",
      "Epoch 15: Train Loss = 0.09164116790160438, Recall = 0.9864238410596027, Aging Rate = 0.5084437086092716, Precision = 0.9700423314881146, f1 = 0.9781645050073879\n",
      "Test Loss = 0.08531220970761696, Recall = 0.990728476821192, Aging Rate = 0.5130794701986755, precision = 0.9654727331397225\n",
      "Model in epoch 15 is saved.\n",
      "\n",
      "Epoch 16: Train Loss = 0.08454603066310187, Recall = 0.9877483443708609, Aging Rate = 0.509271523178808, Precision = 0.9697659297789337, f1 = 0.9786745406824147\n",
      "Epoch 17: Train Loss = 0.07939579340302391, Recall = 0.9884105960264901, Aging Rate = 0.5079470198675496, Precision = 0.9729465449804433, f1 = 0.9806176084099869\n",
      "Epoch 18: Train Loss = 0.07579659531448062, Recall = 0.9890728476821192, Aging Rate = 0.5072847682119205, Precision = 0.9748694516971279, f1 = 0.9819197896120974\n",
      "Epoch 19: Train Loss = 0.071198743369603, Recall = 0.9903973509933774, Aging Rate = 0.5072847682119205, Precision = 0.9761749347258486, f1 = 0.9832347140039447\n",
      "Epoch 20: Train Loss = 0.0665162227406407, Recall = 0.9913907284768212, Aging Rate = 0.5061258278145695, Precision = 0.9793915603532876, f1 = 0.9853546157643573\n",
      "Test Loss = 0.06179412981334901, Recall = 0.9923841059602649, Aging Rate = 0.5054635761589404, precision = 0.9816573861775303\n",
      "Model in epoch 20 is saved.\n",
      "\n",
      "Epoch 21: Train Loss = 0.06371646036474121, Recall = 0.9923841059602649, Aging Rate = 0.5066225165562914, Precision = 0.9794117647058823, f1 = 0.9858552631578946\n",
      "Epoch 22: Train Loss = 0.05996944439036167, Recall = 0.9933774834437086, Aging Rate = 0.5059602649006623, Precision = 0.981675392670157, f1 = 0.9874917709019091\n",
      "Epoch 23: Train Loss = 0.05744463339053242, Recall = 0.9943708609271523, Aging Rate = 0.5061258278145695, Precision = 0.9823356231599607, f1 = 0.9883166035872963\n",
      "Epoch 24: Train Loss = 0.05603341759238022, Recall = 0.9927152317880795, Aging Rate = 0.5044701986754967, Precision = 0.9839186084673449, f1 = 0.9882973462996538\n",
      "Epoch 25: Train Loss = 0.05300465309560694, Recall = 0.9947019867549669, Aging Rate = 0.5059602649006623, Precision = 0.9829842931937173, f1 = 0.9888084265964451\n",
      "Test Loss = 0.050047220709110725, Recall = 0.9933774834437086, Aging Rate = 0.5019867549668874, precision = 0.9894459102902374\n",
      "Model in epoch 25 is saved.\n",
      "\n",
      "Epoch 26: Train Loss = 0.050588706974556905, Recall = 0.9947019867549669, Aging Rate = 0.5048013245033113, Precision = 0.9852410626434897, f1 = 0.9899489207447686\n",
      "Epoch 27: Train Loss = 0.049840920729352936, Recall = 0.9966887417218543, Aging Rate = 0.5056291390728477, Precision = 0.9855926653569089, f1 = 0.9911096476786303\n",
      "Epoch 28: Train Loss = 0.048419147892700916, Recall = 0.9950331125827815, Aging Rate = 0.5051324503311259, Precision = 0.9849229760734185, f1 = 0.9899522319222533\n",
      "Epoch 29: Train Loss = 0.04626244038639479, Recall = 0.9953642384105961, Aging Rate = 0.5048013245033113, Precision = 0.9858970154148902, f1 = 0.9906080079090459\n",
      "Epoch 30: Train Loss = 0.04479612022737004, Recall = 0.9973509933774835, Aging Rate = 0.5051324503311259, Precision = 0.9872173058013766, f1 = 0.9922582770548509\n",
      "Test Loss = 0.041978637647155106, Recall = 0.9966887417218543, Aging Rate = 0.5028145695364239, precision = 0.9911096476786302\n",
      "Model in epoch 30 is saved.\n",
      "\n",
      "Epoch 31: Train Loss = 0.04486301989350098, Recall = 0.9956953642384105, Aging Rate = 0.5039735099337749, Precision = 0.9878449408672799, f1 = 0.991754617414248\n",
      "Epoch 32: Train Loss = 0.04317870033004426, Recall = 0.9973509933774835, Aging Rate = 0.5054635761589404, Precision = 0.986570586308549, f1 = 0.9919315000823316\n",
      "Epoch 33: Train Loss = 0.041867011894058705, Recall = 0.9970198675496689, Aging Rate = 0.5039735099337749, Precision = 0.9891590013140604, f1 = 0.9930738786279684\n",
      "Epoch 34: Train Loss = 0.04014005731569221, Recall = 0.9973509933774835, Aging Rate = 0.5049668874172185, Precision = 0.9875409836065574, f1 = 0.9924217462932454\n",
      "Epoch 35: Train Loss = 0.039485167677434076, Recall = 0.9980132450331126, Aging Rate = 0.5051324503311259, Precision = 0.9878728285807932, f1 = 0.9929171470927359\n",
      "Test Loss = 0.036902328477000555, Recall = 0.9983443708609272, Aging Rate = 0.5033112582781457, precision = 0.9917763157894737\n",
      "Model in epoch 35 is saved.\n",
      "\n",
      "Epoch 36: Train Loss = 0.03888266487725523, Recall = 0.9986754966887417, Aging Rate = 0.5046357615894039, Precision = 0.989501312335958, f1 = 0.9940672379696769\n",
      "Epoch 37: Train Loss = 0.03768906309608592, Recall = 0.9980132450331126, Aging Rate = 0.5038079470198675, Precision = 0.9904699309891555, f1 = 0.9942272802243114\n",
      "Epoch 38: Train Loss = 0.037164654084388786, Recall = 0.9980132450331126, Aging Rate = 0.5038079470198675, Precision = 0.9904699309891555, f1 = 0.9942272802243114\n",
      "Epoch 39: Train Loss = 0.036628071342083006, Recall = 0.9983443708609272, Aging Rate = 0.5048013245033113, Precision = 0.9888488028861921, f1 = 0.9935739001482946\n",
      "Epoch 40: Train Loss = 0.03635599480460811, Recall = 0.9973509933774835, Aging Rate = 0.5033112582781457, Precision = 0.9907894736842106, f1 = 0.9940594059405942\n",
      "Test Loss = 0.034224243314060945, Recall = 0.997682119205298, Aging Rate = 0.5008278145695364, precision = 0.9960330578512396\n",
      "Model in epoch 40 is saved.\n",
      "\n",
      "Epoch 41: Train Loss = 0.034843411439696687, Recall = 0.9980132450331126, Aging Rate = 0.5038079470198675, Precision = 0.9904699309891555, f1 = 0.9942272802243114\n",
      "Epoch 42: Train Loss = 0.035212076322132385, Recall = 0.9983443708609272, Aging Rate = 0.503476821192053, Precision = 0.9914501808615587, f1 = 0.9948853324533906\n",
      "Epoch 43: Train Loss = 0.03436195013785599, Recall = 0.9986754966887417, Aging Rate = 0.5041390728476821, Precision = 0.9904761904761905, f1 = 0.9945589447650454\n",
      "Epoch 44: Train Loss = 0.033905291058961916, Recall = 0.9986754966887417, Aging Rate = 0.5036423841059603, Precision = 0.9914529914529915, f1 = 0.9950511382382052\n",
      "Epoch 45: Train Loss = 0.033408974017331144, Recall = 0.9986754966887417, Aging Rate = 0.5033112582781457, Precision = 0.9921052631578947, f1 = 0.9953795379537954\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss = 0.03036547614051806, Recall = 0.9986754966887417, Aging Rate = 0.5028145695364239, precision = 0.9930852815278235\n",
      "\n",
      "Epoch 46: Train Loss = 0.03356862017847844, Recall = 0.9983443708609272, Aging Rate = 0.5033112582781457, Precision = 0.9917763157894737, f1 = 0.995049504950495\n",
      "Epoch 47: Train Loss = 0.03312234577062904, Recall = 0.9980132450331126, Aging Rate = 0.5029801324503311, Precision = 0.9921000658327848, f1 = 0.9950478705843513\n",
      "Epoch 48: Train Loss = 0.032609615450268546, Recall = 0.9983443708609272, Aging Rate = 0.5028145695364239, Precision = 0.9927560092196246, f1 = 0.9955423476968797\n",
      "Epoch 49: Train Loss = 0.032027904797863486, Recall = 0.9983443708609272, Aging Rate = 0.5026490066225165, Precision = 0.9930830039525692, f1 = 0.9957067371202114\n",
      "Epoch 50: Train Loss = 0.03179889935630047, Recall = 0.9980132450331126, Aging Rate = 0.503476821192053, Precision = 0.9911213416639263, f1 = 0.9945553539019963\n",
      "Test Loss = 0.02993876395241314, Recall = 0.9993377483443708, Aging Rate = 0.5039735099337749, precision = 0.9914586070959264\n",
      "\n",
      "Epoch 51: Train Loss = 0.03157772719613369, Recall = 0.9986754966887417, Aging Rate = 0.5026490066225165, Precision = 0.9934123847167325, f1 = 0.9960369881109644\n",
      "Epoch 52: Train Loss = 0.03151181913073489, Recall = 0.9990066225165563, Aging Rate = 0.5036423841059603, Precision = 0.9917817225509533, f1 = 0.9953810623556583\n",
      "Epoch 53: Train Loss = 0.03059914555178573, Recall = 0.9980132450331126, Aging Rate = 0.5029801324503311, Precision = 0.9921000658327848, f1 = 0.9950478705843513\n",
      "Epoch 54: Train Loss = 0.030113801039409954, Recall = 0.9986754966887417, Aging Rate = 0.5029801324503311, Precision = 0.9927583936800527, f1 = 0.9957081545064377\n",
      "Epoch 55: Train Loss = 0.03027964863457427, Recall = 0.9983443708609272, Aging Rate = 0.5024834437086093, Precision = 0.9934102141680395, f1 = 0.9958711808422791\n",
      "Test Loss = 0.027981895043064427, Recall = 0.9990066225165563, Aging Rate = 0.501158940397351, precision = 0.9966963990749917\n",
      "Model in epoch 55 is saved.\n",
      "\n",
      "Epoch 56: Train Loss = 0.030154655375425388, Recall = 0.9986754966887417, Aging Rate = 0.5019867549668874, Precision = 0.9947229551451188, f1 = 0.9966953073364176\n",
      "Epoch 57: Train Loss = 0.030388597559356533, Recall = 0.9990066225165563, Aging Rate = 0.502317880794702, Precision = 0.9943968358602505, f1 = 0.9966963990749917\n",
      "Epoch 58: Train Loss = 0.02947432313928541, Recall = 0.9980132450331126, Aging Rate = 0.5021523178807947, Precision = 0.9937355753379492, f1 = 0.995869816619858\n",
      "Epoch 59: Train Loss = 0.028988066493280677, Recall = 0.9993377483443708, Aging Rate = 0.5026490066225165, Precision = 0.9940711462450593, f1 = 0.9966974900924703\n",
      "Epoch 60: Train Loss = 0.029015569068146067, Recall = 0.9983443708609272, Aging Rate = 0.5014900662251656, Precision = 0.9953780125453945, f1 = 0.9968589849561911\n",
      "Test Loss = 0.026748114057033267, Recall = 1.0, Aging Rate = 0.5024834437086093, precision = 0.9950576606260296\n",
      "\n",
      "Epoch 61: Train Loss = 0.02915712488901536, Recall = 0.9990066225165563, Aging Rate = 0.5026490066225165, Precision = 0.9937417654808959, f1 = 0.9963672391017173\n",
      "Epoch 62: Train Loss = 0.0287872730279403, Recall = 0.9990066225165563, Aging Rate = 0.5026490066225165, Precision = 0.9937417654808959, f1 = 0.9963672391017173\n",
      "Epoch 63: Train Loss = 0.028204452488201342, Recall = 0.9990066225165563, Aging Rate = 0.5019867549668874, Precision = 0.9950527704485488, f1 = 0.9970257766027759\n",
      "Epoch 64: Train Loss = 0.02892963324260238, Recall = 0.9990066225165563, Aging Rate = 0.502317880794702, Precision = 0.9943968358602505, f1 = 0.9966963990749917\n",
      "Epoch 65: Train Loss = 0.028608915049410023, Recall = 0.9986754966887417, Aging Rate = 0.5021523178807947, Precision = 0.9943949884602704, f1 = 0.9965306459606807\n",
      "Test Loss = 0.026502858003638437, Recall = 0.9993377483443708, Aging Rate = 0.5033112582781457, precision = 0.9927631578947368\n",
      "\n",
      "Epoch 66: Train Loss = 0.027985454483932217, Recall = 0.9986754966887417, Aging Rate = 0.502317880794702, Precision = 0.994067237969677, f1 = 0.9963660389824909\n",
      "Epoch 67: Train Loss = 0.02802764294015256, Recall = 0.9986754966887417, Aging Rate = 0.5019867549668874, Precision = 0.9947229551451188, f1 = 0.9966953073364176\n",
      "Epoch 68: Train Loss = 0.027488104522919023, Recall = 0.9986754966887417, Aging Rate = 0.5018211920529801, Precision = 0.9950511382382052, f1 = 0.9968600231366715\n",
      "Epoch 69: Train Loss = 0.028469608442870196, Recall = 0.9986754966887417, Aging Rate = 0.5019867549668874, Precision = 0.9947229551451188, f1 = 0.9966953073364176\n",
      "Epoch 70: Train Loss = 0.028177174716102368, Recall = 0.9983443708609272, Aging Rate = 0.5021523178807947, Precision = 0.9940652818991098, f1 = 0.9962002312902692\n",
      "Test Loss = 0.02650268647499037, Recall = 0.9990066225165563, Aging Rate = 0.501158940397351, precision = 0.9966963990749917\n",
      "\n",
      "Epoch 71: Train Loss = 0.0277090421230193, Recall = 0.9986754966887417, Aging Rate = 0.5018211920529801, Precision = 0.9950511382382052, f1 = 0.9968600231366715\n",
      "Epoch 72: Train Loss = 0.027570666799580815, Recall = 0.9990066225165563, Aging Rate = 0.502317880794702, Precision = 0.9943968358602505, f1 = 0.9966963990749917\n",
      "Epoch 73: Train Loss = 0.027130015737173573, Recall = 0.9993377483443708, Aging Rate = 0.5016556291390728, Precision = 0.996039603960396, f1 = 0.9976859504132232\n",
      "Epoch 74: Train Loss = 0.028141747563090545, Recall = 0.9986754966887417, Aging Rate = 0.5021523178807947, Precision = 0.9943949884602704, f1 = 0.9965306459606807\n",
      "Epoch 75: Train Loss = 0.028339700432901353, Recall = 0.9986754966887417, Aging Rate = 0.5026490066225165, Precision = 0.9934123847167325, f1 = 0.9960369881109644\n",
      "Test Loss = 0.025428315217526542, Recall = 0.9996688741721854, Aging Rate = 0.5014900662251656, precision = 0.9966985803895675\n",
      "Model in epoch 75 is saved.\n",
      "\n",
      "Epoch 76: Train Loss = 0.027801377030200518, Recall = 0.9986754966887417, Aging Rate = 0.5021523178807947, Precision = 0.9943949884602704, f1 = 0.9965306459606807\n",
      "Epoch 77: Train Loss = 0.02747246493764271, Recall = 0.9993377483443708, Aging Rate = 0.5021523178807947, Precision = 0.9950544015825915, f1 = 0.9971914753015033\n",
      "Epoch 78: Train Loss = 0.02676785857422857, Recall = 1.0, Aging Rate = 0.502317880794702, Precision = 0.995385629531971, f1 = 0.9976874793524942\n",
      "Epoch 79: Train Loss = 0.026953422791318387, Recall = 0.9983443708609272, Aging Rate = 0.5018211920529801, Precision = 0.9947212141207522, f1 = 0.9965294992563213\n",
      "Epoch 80: Train Loss = 0.026856058655886462, Recall = 0.9986754966887417, Aging Rate = 0.5016556291390728, Precision = 0.9953795379537954, f1 = 0.9970247933884296\n",
      "Test Loss = 0.025279329369301037, Recall = 1.0, Aging Rate = 0.5024834437086093, precision = 0.9950576606260296\n",
      "\n",
      "Epoch 81: Train Loss = 0.02705986915982717, Recall = 0.9990066225165563, Aging Rate = 0.5018211920529801, Precision = 0.9953810623556582, f1 = 0.9971905470170219\n",
      "Epoch 82: Train Loss = 0.026749556306872938, Recall = 0.9993377483443708, Aging Rate = 0.5021523178807947, Precision = 0.9950544015825915, f1 = 0.9971914753015033\n",
      "Epoch 83: Train Loss = 0.02709542965356088, Recall = 0.9983443708609272, Aging Rate = 0.5018211920529801, Precision = 0.9947212141207522, f1 = 0.9965294992563213\n",
      "Epoch 84: Train Loss = 0.026427949042312358, Recall = 0.9993377483443708, Aging Rate = 0.502317880794702, Precision = 0.994726433750824, f1 = 0.9970267591674926\n",
      "Epoch 85: Train Loss = 0.02647102777630288, Recall = 0.9993377483443708, Aging Rate = 0.5024834437086093, Precision = 0.9943986820428337, f1 = 0.9968620974401321\n",
      "Test Loss = 0.025644621008772725, Recall = 0.9990066225165563, Aging Rate = 0.5009933774834437, precision = 0.9970257766027759\n",
      "\n",
      "Epoch 86: Train Loss = 0.02706437735812159, Recall = 0.9990066225165563, Aging Rate = 0.5021523178807947, Precision = 0.9947246950214309, f1 = 0.996861060631092\n",
      "Epoch 87: Train Loss = 0.026477730842862302, Recall = 0.9990066225165563, Aging Rate = 0.5019867549668874, Precision = 0.9950527704485488, f1 = 0.9970257766027759\n",
      "Epoch 88: Train Loss = 0.02656246709409139, Recall = 0.9986754966887417, Aging Rate = 0.501158940397351, Precision = 0.9963660389824909, f1 = 0.9975194311228708\n",
      "Epoch 89: Train Loss = 0.026911658453230826, Recall = 0.9993377483443708, Aging Rate = 0.5026490066225165, Precision = 0.9940711462450593, f1 = 0.9966974900924703\n",
      "Epoch 90: Train Loss = 0.026928195418999684, Recall = 0.9986754966887417, Aging Rate = 0.5019867549668874, Precision = 0.9947229551451188, f1 = 0.9966953073364176\n",
      "Test Loss = 0.024252560766820877, Recall = 0.9996688741721854, Aging Rate = 0.5014900662251656, precision = 0.9966985803895675\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 91: Train Loss = 0.02608716928011534, Recall = 0.9996688741721854, Aging Rate = 0.502317880794702, Precision = 0.9950560316413974, f1 = 0.9973571192599933\n",
      "Epoch 92: Train Loss = 0.026541874651482562, Recall = 0.9986754966887417, Aging Rate = 0.5014900662251656, Precision = 0.9957081545064378, f1 = 0.9971896181186972\n",
      "Epoch 93: Train Loss = 0.026873178666593223, Recall = 0.9986754966887417, Aging Rate = 0.5019867549668874, Precision = 0.9947229551451188, f1 = 0.9966953073364176\n",
      "Epoch 94: Train Loss = 0.026061908131008907, Recall = 0.9990066225165563, Aging Rate = 0.5016556291390728, Precision = 0.9957095709570957, f1 = 0.9973553719008265\n",
      "Epoch 95: Train Loss = 0.0264593715847328, Recall = 0.9993377483443708, Aging Rate = 0.5018211920529801, Precision = 0.9957109864731112, f1 = 0.9975210708973722\n",
      "Test Loss = 0.02396564053383884, Recall = 1.0, Aging Rate = 0.502317880794702, precision = 0.995385629531971\n",
      "\n",
      "Epoch 96: Train Loss = 0.026369172573977747, Recall = 0.9990066225165563, Aging Rate = 0.5018211920529801, Precision = 0.9953810623556582, f1 = 0.9971905470170219\n",
      "Epoch 97: Train Loss = 0.026054466098843033, Recall = 0.9986754966887417, Aging Rate = 0.5016556291390728, Precision = 0.9953795379537954, f1 = 0.9970247933884296\n",
      "Epoch 98: Train Loss = 0.0263639993817601, Recall = 0.9986754966887417, Aging Rate = 0.5021523178807947, Precision = 0.9943949884602704, f1 = 0.9965306459606807\n",
      "Epoch 99: Train Loss = 0.026551327045192783, Recall = 0.9990066225165563, Aging Rate = 0.5018211920529801, Precision = 0.9953810623556582, f1 = 0.9971905470170219\n",
      "Epoch 100: Train Loss = 0.026539506373421246, Recall = 0.9990066225165563, Aging Rate = 0.5016556291390728, Precision = 0.9957095709570957, f1 = 0.9973553719008265\n",
      "Test Loss = 0.025089202246425166, Recall = 1.0, Aging Rate = 0.5028145695364239, precision = 0.994402370760619\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ae2301f53064cf8b8664490fc566be7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss = 0.6069443965589764, Recall = 0.954635761589404, Aging Rate = 0.8602649006622517, Precision = 0.5548498845265589, f1 = 0.7018013631937683\n",
      "Epoch 2: Train Loss = 0.45774447246892563, Recall = 0.8986754966887417, Aging Rate = 0.6165562913907284, Precision = 0.7287862513426423, f1 = 0.8048635824436536\n",
      "Epoch 3: Train Loss = 0.3783893963753782, Recall = 0.9076158940397351, Aging Rate = 0.5804635761589404, Precision = 0.7818026240730177, f1 = 0.840024517315354\n",
      "Epoch 4: Train Loss = 0.32897572698972083, Recall = 0.9205298013245033, Aging Rate = 0.5612582781456954, Precision = 0.8200589970501475, f1 = 0.8673946957878316\n",
      "Epoch 5: Train Loss = 0.29124961035535823, Recall = 0.9347682119205298, Aging Rate = 0.5576158940397351, Precision = 0.8381828978622328, f1 = 0.8838447088290545\n",
      "Test Loss = 0.2589657536405601, Recall = 0.9334437086092715, Aging Rate = 0.5314569536423841, precision = 0.8781931464174455\n",
      "Model in epoch 5 is saved.\n",
      "\n",
      "Epoch 6: Train Loss = 0.24583185532235152, Recall = 0.9417218543046357, Aging Rate = 0.5379139072847682, Precision = 0.8753462603878116, f1 = 0.9073217419046099\n",
      "Epoch 7: Train Loss = 0.2142605671622106, Recall = 0.9529801324503311, Aging Rate = 0.5344370860927152, Precision = 0.8915737298636927, f1 = 0.9212548015364916\n",
      "Epoch 8: Train Loss = 0.18690309271907174, Recall = 0.9576158940397351, Aging Rate = 0.5241721854304636, Precision = 0.9134554643082754, f1 = 0.9350145489815712\n",
      "Epoch 9: Train Loss = 0.16666632570967768, Recall = 0.9629139072847682, Aging Rate = 0.5206953642384106, Precision = 0.9246422893481717, f1 = 0.943390105433901\n",
      "Epoch 10: Train Loss = 0.14667265136905064, Recall = 0.9705298013245033, Aging Rate = 0.5188741721854304, Precision = 0.935226547543076, f1 = 0.9525511862203445\n",
      "Test Loss = 0.1352723897885013, Recall = 0.980794701986755, Aging Rate = 0.5279801324503312, precision = 0.9288178112260896\n",
      "Model in epoch 10 is saved.\n",
      "\n",
      "Epoch 11: Train Loss = 0.13235186926576475, Recall = 0.9741721854304636, Aging Rate = 0.5155629139072848, Precision = 0.9447655748233783, f1 = 0.9592435604825563\n",
      "Epoch 12: Train Loss = 0.12002996082929586, Recall = 0.9754966887417219, Aging Rate = 0.5117549668874172, Precision = 0.9530896150113232, f1 = 0.9641629847815415\n",
      "Epoch 13: Train Loss = 0.10909345687817264, Recall = 0.9804635761589404, Aging Rate = 0.5105960264900662, Precision = 0.9601167315175098, f1 = 0.970183486238532\n",
      "Epoch 14: Train Loss = 0.1000177001025503, Recall = 0.9821192052980132, Aging Rate = 0.509271523178808, Precision = 0.9642392717815345, f1 = 0.9730971128608924\n",
      "Epoch 15: Train Loss = 0.09301491539604617, Recall = 0.9847682119205298, Aging Rate = 0.5086092715231788, Precision = 0.9680989583333334, f1 = 0.9763624425476034\n",
      "Test Loss = 0.0886782172993319, Recall = 0.9801324503311258, Aging Rate = 0.4991721854304636, precision = 0.9817578772802653\n",
      "Model in epoch 15 is saved.\n",
      "\n",
      "Epoch 16: Train Loss = 0.08741532510874288, Recall = 0.9844370860927152, Aging Rate = 0.5071192052980132, Precision = 0.970617042115573, f1 = 0.9774782179845471\n",
      "Epoch 17: Train Loss = 0.08109766225151668, Recall = 0.9864238410596027, Aging Rate = 0.5074503311258278, Precision = 0.9719412724306689, f1 = 0.9791290057518489\n",
      "Epoch 18: Train Loss = 0.07705168321432657, Recall = 0.9894039735099338, Aging Rate = 0.5067880794701987, Precision = 0.9761515844495263, f1 = 0.9827331031080415\n",
      "Epoch 19: Train Loss = 0.07246211453384122, Recall = 0.990728476821192, Aging Rate = 0.5056291390728477, Precision = 0.9796987557301899, f1 = 0.9851827461310503\n",
      "Epoch 20: Train Loss = 0.06767626953440786, Recall = 0.9903973509933774, Aging Rate = 0.5046357615894039, Precision = 0.9812992125984252, f1 = 0.9858272907053395\n",
      "Test Loss = 0.06488731688024192, Recall = 0.9884105960264901, Aging Rate = 0.5003311258278146, precision = 0.9877564526803442\n",
      "Model in epoch 20 is saved.\n",
      "\n",
      "Epoch 21: Train Loss = 0.0646209215190237, Recall = 0.990728476821192, Aging Rate = 0.5044701986754967, Precision = 0.9819494584837545, f1 = 0.9863194329981869\n",
      "Epoch 22: Train Loss = 0.06241702883448822, Recall = 0.9923841059602649, Aging Rate = 0.5061258278145695, Precision = 0.9803729146221786, f1 = 0.9863419450386705\n",
      "Epoch 23: Train Loss = 0.060236584794837116, Recall = 0.990728476821192, Aging Rate = 0.5036423841059603, Precision = 0.9835634451019066, f1 = 0.9871329594193334\n",
      "Epoch 24: Train Loss = 0.055867090737385466, Recall = 0.993046357615894, Aging Rate = 0.5038079470198675, Precision = 0.9855405849490634, f1 = 0.9892792347022925\n",
      "Epoch 25: Train Loss = 0.05369809518586721, Recall = 0.9940397350993377, Aging Rate = 0.5038079470198675, Precision = 0.9865264541570818, f1 = 0.9902688438066963\n",
      "Test Loss = 0.04985137456004193, Recall = 0.9943708609271523, Aging Rate = 0.5031456953642384, precision = 0.9881539980256664\n",
      "Model in epoch 25 is saved.\n",
      "\n",
      "Epoch 26: Train Loss = 0.051420008080289854, Recall = 0.9943708609271523, Aging Rate = 0.5031456953642384, Precision = 0.9881539980256664, f1 = 0.9912526819607195\n",
      "Epoch 27: Train Loss = 0.04979502895217858, Recall = 0.9950331125827815, Aging Rate = 0.5051324503311259, Precision = 0.9849229760734185, f1 = 0.9899522319222533\n",
      "Epoch 28: Train Loss = 0.04847425271738444, Recall = 0.9960264900662251, Aging Rate = 0.5031456953642384, Precision = 0.9897992760776572, f1 = 0.9929031193266216\n",
      "Epoch 29: Train Loss = 0.04611859403501283, Recall = 0.9950331125827815, Aging Rate = 0.5038079470198675, Precision = 0.9875123233651002, f1 = 0.9912584529111\n",
      "Epoch 30: Train Loss = 0.045307428542746615, Recall = 0.9953642384105961, Aging Rate = 0.5036423841059603, Precision = 0.9881656804733728, f1 = 0.9917518970636755\n",
      "Test Loss = 0.042712645553397814, Recall = 0.997682119205298, Aging Rate = 0.5036423841059603, precision = 0.9904667981591059\n",
      "Model in epoch 30 is saved.\n",
      "\n",
      "Epoch 31: Train Loss = 0.04391478340061295, Recall = 0.9956953642384105, Aging Rate = 0.5031456953642384, Precision = 0.989470220467259, f1 = 0.9925730318534411\n",
      "Epoch 32: Train Loss = 0.04189617899277352, Recall = 0.9966887417218543, Aging Rate = 0.5033112582781457, Precision = 0.9901315789473685, f1 = 0.9933993399339934\n",
      "Epoch 33: Train Loss = 0.041186688820652614, Recall = 0.9966887417218543, Aging Rate = 0.5029801324503311, Precision = 0.9907834101382489, f1 = 0.9937273027401784\n",
      "Epoch 34: Train Loss = 0.04093641859312721, Recall = 0.9960264900662251, Aging Rate = 0.5021523178807947, Precision = 0.9917573359709858, f1 = 0.9938873285973897\n",
      "Epoch 35: Train Loss = 0.039370621528649175, Recall = 0.9960264900662251, Aging Rate = 0.5021523178807947, Precision = 0.9917573359709858, f1 = 0.9938873285973897\n",
      "Test Loss = 0.03704076474470808, Recall = 0.9970198675496689, Aging Rate = 0.5013245033112583, precision = 0.9943857331571995\n",
      "Model in epoch 35 is saved.\n",
      "\n",
      "Epoch 36: Train Loss = 0.038774786864882275, Recall = 0.9966887417218543, Aging Rate = 0.5029801324503311, Precision = 0.9907834101382489, f1 = 0.9937273027401784\n",
      "Epoch 37: Train Loss = 0.03757580157542071, Recall = 0.997682119205298, Aging Rate = 0.502317880794702, Precision = 0.9930784442979564, f1 = 0.9953749587049884\n",
      "Epoch 38: Train Loss = 0.037654368278403946, Recall = 0.9970198675496689, Aging Rate = 0.502317880794702, Precision = 0.9924192485168095, f1 = 0.9947142385199867\n",
      "Epoch 39: Train Loss = 0.03665514489179415, Recall = 0.9970198675496689, Aging Rate = 0.502317880794702, Precision = 0.9924192485168095, f1 = 0.9947142385199867\n",
      "Epoch 40: Train Loss = 0.03550429433978946, Recall = 0.9980132450331126, Aging Rate = 0.5021523178807947, Precision = 0.9937355753379492, f1 = 0.995869816619858\n",
      "Test Loss = 0.033075484315192465, Recall = 0.9986754966887417, Aging Rate = 0.5021523178807947, precision = 0.9943949884602704\n",
      "Model in epoch 40 is saved.\n",
      "\n",
      "Epoch 41: Train Loss = 0.03492086683677522, Recall = 0.9973509933774835, Aging Rate = 0.5019867549668874, Precision = 0.9934036939313984, f1 = 0.9953734302709848\n",
      "Epoch 42: Train Loss = 0.03410606775556179, Recall = 0.9986754966887417, Aging Rate = 0.5031456953642384, Precision = 0.9924317209608424, f1 = 0.9955438191120647\n",
      "Epoch 43: Train Loss = 0.03403500955033776, Recall = 0.9980132450331126, Aging Rate = 0.5019867549668874, Precision = 0.9940633245382586, f1 = 0.9960343688037013\n",
      "Epoch 44: Train Loss = 0.033985460756827665, Recall = 0.9980132450331126, Aging Rate = 0.5024834437086093, Precision = 0.9930807248764415, f1 = 0.9955408753096614\n",
      "Epoch 45: Train Loss = 0.032774991936833656, Recall = 0.9993377483443708, Aging Rate = 0.5028145695364239, Precision = 0.9937438261442213, f1 = 0.9965329370975731\n",
      "Test Loss = 0.03025893766358988, Recall = 1.0, Aging Rate = 0.5028145695364239, precision = 0.994402370760619\n",
      "Model in epoch 45 is saved.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 46: Train Loss = 0.03244323640913758, Recall = 0.9986754966887417, Aging Rate = 0.5018211920529801, Precision = 0.9950511382382052, f1 = 0.9968600231366715\n",
      "Epoch 47: Train Loss = 0.031893603794819474, Recall = 0.9993377483443708, Aging Rate = 0.5028145695364239, Precision = 0.9937438261442213, f1 = 0.9965329370975731\n",
      "Epoch 48: Train Loss = 0.03131423523489213, Recall = 0.9986754966887417, Aging Rate = 0.5016556291390728, Precision = 0.9953795379537954, f1 = 0.9970247933884296\n",
      "Epoch 49: Train Loss = 0.03129477350423668, Recall = 0.9993377483443708, Aging Rate = 0.502317880794702, Precision = 0.994726433750824, f1 = 0.9970267591674926\n",
      "Epoch 50: Train Loss = 0.031727378746334294, Recall = 0.9980132450331126, Aging Rate = 0.502317880794702, Precision = 0.99340804218853, f1 = 0.9957053187974892\n",
      "Test Loss = 0.028418003397666855, Recall = 0.9986754966887417, Aging Rate = 0.5014900662251656, precision = 0.9957081545064378\n",
      "Model in epoch 50 is saved.\n",
      "\n",
      "Epoch 51: Train Loss = 0.030939977278081787, Recall = 0.9986754966887417, Aging Rate = 0.5028145695364239, Precision = 0.9930852815278235, f1 = 0.9958725441637775\n",
      "Epoch 52: Train Loss = 0.030323180770933232, Recall = 0.9980132450331126, Aging Rate = 0.502317880794702, Precision = 0.99340804218853, f1 = 0.9957053187974892\n",
      "Epoch 53: Train Loss = 0.029679360282638217, Recall = 0.9996688741721854, Aging Rate = 0.5019867549668874, Precision = 0.9957124010554089, f1 = 0.9976867151354923\n",
      "Epoch 54: Train Loss = 0.02959424689264092, Recall = 0.9990066225165563, Aging Rate = 0.5021523178807947, Precision = 0.9947246950214309, f1 = 0.996861060631092\n",
      "Epoch 55: Train Loss = 0.030200105397314426, Recall = 0.9986754966887417, Aging Rate = 0.5016556291390728, Precision = 0.9953795379537954, f1 = 0.9970247933884296\n",
      "Test Loss = 0.029723583265448248, Recall = 0.997682119205298, Aging Rate = 0.5001655629139072, precision = 0.9973518702416418\n",
      "Model in epoch 55 is saved.\n",
      "\n",
      "Epoch 56: Train Loss = 0.030801289575482838, Recall = 0.9993377483443708, Aging Rate = 0.5021523178807947, Precision = 0.9950544015825915, f1 = 0.9971914753015033\n",
      "Epoch 57: Train Loss = 0.029870263669664495, Recall = 0.9993377483443708, Aging Rate = 0.502317880794702, Precision = 0.994726433750824, f1 = 0.9970267591674926\n",
      "Epoch 58: Train Loss = 0.029587985676349394, Recall = 0.9996688741721854, Aging Rate = 0.502317880794702, Precision = 0.9950560316413974, f1 = 0.9973571192599933\n",
      "Epoch 59: Train Loss = 0.028000339441346805, Recall = 0.9993377483443708, Aging Rate = 0.5016556291390728, Precision = 0.996039603960396, f1 = 0.9976859504132232\n",
      "Epoch 60: Train Loss = 0.02801594395708564, Recall = 0.9993377483443708, Aging Rate = 0.5016556291390728, Precision = 0.996039603960396, f1 = 0.9976859504132232\n",
      "Test Loss = 0.026543493366596716, Recall = 0.9990066225165563, Aging Rate = 0.5009933774834437, precision = 0.9970257766027759\n",
      "Model in epoch 60 is saved.\n",
      "\n",
      "Epoch 61: Train Loss = 0.02801092276411341, Recall = 0.9996688741721854, Aging Rate = 0.5018211920529801, Precision = 0.9960409105905642, f1 = 0.9978515947777227\n",
      "Epoch 62: Train Loss = 0.02795423133089053, Recall = 0.9986754966887417, Aging Rate = 0.5016556291390728, Precision = 0.9953795379537954, f1 = 0.9970247933884296\n",
      "Epoch 63: Train Loss = 0.02790482547257515, Recall = 0.9990066225165563, Aging Rate = 0.5016556291390728, Precision = 0.9957095709570957, f1 = 0.9973553719008265\n",
      "Epoch 64: Train Loss = 0.028463696722952736, Recall = 0.9993377483443708, Aging Rate = 0.5016556291390728, Precision = 0.996039603960396, f1 = 0.9976859504132232\n",
      "Epoch 65: Train Loss = 0.027348163131846497, Recall = 0.9993377483443708, Aging Rate = 0.5016556291390728, Precision = 0.996039603960396, f1 = 0.9976859504132232\n",
      "Test Loss = 0.025762552439870422, Recall = 1.0, Aging Rate = 0.5019867549668874, precision = 0.996042216358839\n",
      "\n",
      "Epoch 66: Train Loss = 0.0271887889514301, Recall = 0.9993377483443708, Aging Rate = 0.5014900662251656, Precision = 0.9963684384285243, f1 = 0.9978508844437097\n",
      "Epoch 67: Train Loss = 0.02802970071896812, Recall = 0.9993377483443708, Aging Rate = 0.5018211920529801, Precision = 0.9957109864731112, f1 = 0.9975210708973722\n",
      "Epoch 68: Train Loss = 0.027970485011769446, Recall = 0.9986754966887417, Aging Rate = 0.5019867549668874, Precision = 0.9947229551451188, f1 = 0.9966953073364176\n",
      "Epoch 69: Train Loss = 0.027301421406253284, Recall = 0.9996688741721854, Aging Rate = 0.502317880794702, Precision = 0.9950560316413974, f1 = 0.9973571192599933\n",
      "Epoch 70: Train Loss = 0.026839050925676, Recall = 0.9993377483443708, Aging Rate = 0.5014900662251656, Precision = 0.9963684384285243, f1 = 0.9978508844437097\n",
      "Test Loss = 0.026130794622744157, Recall = 0.9986754966887417, Aging Rate = 0.5009933774834437, precision = 0.9966953073364178\n",
      "\n",
      "Epoch 71: Train Loss = 0.027265291424184445, Recall = 0.9993377483443708, Aging Rate = 0.5018211920529801, Precision = 0.9957109864731112, f1 = 0.9975210708973722\n",
      "Epoch 72: Train Loss = 0.027042003331200177, Recall = 0.9990066225165563, Aging Rate = 0.5013245033112583, Precision = 0.9963672391017173, f1 = 0.9976851851851852\n",
      "Epoch 73: Train Loss = 0.02680315865043378, Recall = 0.9993377483443708, Aging Rate = 0.5019867549668874, Precision = 0.9953825857519789, f1 = 0.9973562458691342\n",
      "Epoch 74: Train Loss = 0.02673768682886433, Recall = 0.9990066225165563, Aging Rate = 0.5014900662251656, Precision = 0.996038296467481, f1 = 0.9975202512812035\n",
      "Epoch 75: Train Loss = 0.026609531935575782, Recall = 0.9996688741721854, Aging Rate = 0.5018211920529801, Precision = 0.9960409105905642, f1 = 0.9978515947777227\n",
      "Test Loss = 0.02463182629585661, Recall = 1.0, Aging Rate = 0.5018211920529801, precision = 0.9963708347080171\n",
      "\n",
      "Epoch 76: Train Loss = 0.026962390527227858, Recall = 0.9993377483443708, Aging Rate = 0.5016556291390728, Precision = 0.996039603960396, f1 = 0.9976859504132232\n",
      "Epoch 77: Train Loss = 0.026306743465906737, Recall = 0.9996688741721854, Aging Rate = 0.5014900662251656, Precision = 0.9966985803895675, f1 = 0.9981815176062159\n",
      "Epoch 78: Train Loss = 0.02668324232298807, Recall = 0.9996688741721854, Aging Rate = 0.5014900662251656, Precision = 0.9966985803895675, f1 = 0.9981815176062159\n",
      "Epoch 79: Train Loss = 0.026999311709147416, Recall = 0.9996688741721854, Aging Rate = 0.502317880794702, Precision = 0.9950560316413974, f1 = 0.9973571192599933\n",
      "Epoch 80: Train Loss = 0.02628762216510757, Recall = 1.0, Aging Rate = 0.5019867549668874, Precision = 0.996042216358839, f1 = 0.9980171844018507\n",
      "Test Loss = 0.024535629469037847, Recall = 1.0, Aging Rate = 0.5018211920529801, precision = 0.9963708347080171\n",
      "\n",
      "Epoch 81: Train Loss = 0.026096713900664783, Recall = 0.9996688741721854, Aging Rate = 0.5018211920529801, Precision = 0.9960409105905642, f1 = 0.9978515947777227\n",
      "Epoch 82: Train Loss = 0.025653013584530905, Recall = 0.9996688741721854, Aging Rate = 0.5014900662251656, Precision = 0.9966985803895675, f1 = 0.9981815176062159\n",
      "Epoch 83: Train Loss = 0.025711356177432646, Recall = 0.9990066225165563, Aging Rate = 0.501158940397351, Precision = 0.9966963990749917, f1 = 0.9978501736398214\n",
      "Epoch 84: Train Loss = 0.02587739322951298, Recall = 0.9993377483443708, Aging Rate = 0.5014900662251656, Precision = 0.9963684384285243, f1 = 0.9978508844437097\n",
      "Epoch 85: Train Loss = 0.02648495634561343, Recall = 0.9993377483443708, Aging Rate = 0.5018211920529801, Precision = 0.9957109864731112, f1 = 0.9975210708973722\n",
      "Test Loss = 0.024338292680828776, Recall = 0.9996688741721854, Aging Rate = 0.5013245033112583, precision = 0.9970277410832232\n",
      "Model in epoch 85 is saved.\n",
      "\n",
      "Epoch 86: Train Loss = 0.02621173214241369, Recall = 0.9996688741721854, Aging Rate = 0.5018211920529801, Precision = 0.9960409105905642, f1 = 0.9978515947777227\n",
      "Epoch 87: Train Loss = 0.02603060622385006, Recall = 1.0, Aging Rate = 0.5021523178807947, Precision = 0.9957138147049126, f1 = 0.9978523046423261\n",
      "Epoch 88: Train Loss = 0.025598797984174547, Recall = 0.9996688741721854, Aging Rate = 0.5018211920529801, Precision = 0.9960409105905642, f1 = 0.9978515947777227\n",
      "Epoch 89: Train Loss = 0.02625078864592985, Recall = 0.9996688741721854, Aging Rate = 0.5021523178807947, Precision = 0.9953841081437521, f1 = 0.9975218899719147\n",
      "Epoch 90: Train Loss = 0.02558890919120896, Recall = 1.0, Aging Rate = 0.502317880794702, Precision = 0.995385629531971, f1 = 0.9976874793524942\n",
      "Test Loss = 0.02412568206917371, Recall = 0.9993377483443708, Aging Rate = 0.5014900662251656, precision = 0.9963684384285243\n",
      "\n",
      "Epoch 91: Train Loss = 0.025587392568785623, Recall = 0.9990066225165563, Aging Rate = 0.5013245033112583, Precision = 0.9963672391017173, f1 = 0.9976851851851852\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 92: Train Loss = 0.025843999914775623, Recall = 0.9993377483443708, Aging Rate = 0.5014900662251656, Precision = 0.9963684384285243, f1 = 0.9978508844437097\n",
      "Epoch 93: Train Loss = 0.0252714265483302, Recall = 1.0, Aging Rate = 0.5019867549668874, Precision = 0.996042216358839, f1 = 0.9980171844018507\n",
      "Epoch 94: Train Loss = 0.025458324858487046, Recall = 0.9993377483443708, Aging Rate = 0.5014900662251656, Precision = 0.9963684384285243, f1 = 0.9978508844437097\n",
      "Epoch 95: Train Loss = 0.02532125645323305, Recall = 0.9990066225165563, Aging Rate = 0.5013245033112583, Precision = 0.9963672391017173, f1 = 0.9976851851851852\n",
      "Test Loss = 0.024078072883830164, Recall = 0.9996688741721854, Aging Rate = 0.5013245033112583, precision = 0.9970277410832232\n",
      "\n",
      "Epoch 96: Train Loss = 0.02559566820496755, Recall = 0.9996688741721854, Aging Rate = 0.5016556291390728, Precision = 0.9963696369636964, f1 = 0.9980165289256199\n",
      "Epoch 97: Train Loss = 0.025374104775833767, Recall = 1.0, Aging Rate = 0.502317880794702, Precision = 0.995385629531971, f1 = 0.9976874793524942\n",
      "Epoch 98: Train Loss = 0.025824079800717877, Recall = 0.9990066225165563, Aging Rate = 0.5014900662251656, Precision = 0.996038296467481, f1 = 0.9975202512812035\n",
      "Epoch 99: Train Loss = 0.025726104204524432, Recall = 0.9993377483443708, Aging Rate = 0.5014900662251656, Precision = 0.9963684384285243, f1 = 0.9978508844437097\n",
      "Epoch 100: Train Loss = 0.025217056698751766, Recall = 0.9990066225165563, Aging Rate = 0.5016556291390728, Precision = 0.9957095709570957, f1 = 0.9973553719008265\n",
      "Test Loss = 0.023998061826588302, Recall = 1.0, Aging Rate = 0.5016556291390728, precision = 0.9966996699669967\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f88b04919aea4fe5902bbbd7ff0df287",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss = 0.6284506912263024, Recall = 0.893046357615894, Aging Rate = 0.8344370860927153, Precision = 0.5351190476190476, f1 = 0.6692307692307693\n",
      "Epoch 2: Train Loss = 0.4826057829209511, Recall = 0.9039735099337748, Aging Rate = 0.6347682119205298, Precision = 0.7120500782472613, f1 = 0.7966151152611614\n",
      "Epoch 3: Train Loss = 0.39944098836538805, Recall = 0.9062913907284769, Aging Rate = 0.5872516556291391, Precision = 0.7716380039469974, f1 = 0.8335617481346125\n",
      "Epoch 4: Train Loss = 0.35013154808259167, Recall = 0.9102649006622516, Aging Rate = 0.5564569536423841, Precision = 0.817911335911931, f1 = 0.8616204356683905\n",
      "Epoch 5: Train Loss = 0.3080328728978997, Recall = 0.9225165562913907, Aging Rate = 0.5516556291390728, Precision = 0.8361344537815126, f1 = 0.8772040302267002\n",
      "Test Loss = 0.277551513831347, Recall = 0.9423841059602649, Aging Rate = 0.5493377483443709, precision = 0.8577456298975287\n",
      "Model in epoch 5 is saved.\n",
      "\n",
      "Epoch 6: Train Loss = 0.2643424164380459, Recall = 0.9413907284768211, Aging Rate = 0.5427152317880795, Precision = 0.8672971323978036, f1 = 0.9028262940616067\n",
      "Epoch 7: Train Loss = 0.2304685997449799, Recall = 0.9493377483443709, Aging Rate = 0.5352649006622516, Precision = 0.8867924528301887, f1 = 0.9169998400767633\n",
      "Epoch 8: Train Loss = 0.2020249854649929, Recall = 0.956953642384106, Aging Rate = 0.5283112582781457, Precision = 0.9056722030711376, f1 = 0.9306069876026405\n",
      "Epoch 9: Train Loss = 0.1780425183425676, Recall = 0.9642384105960264, Aging Rate = 0.5201986754966887, Precision = 0.9267982176957352, f1 = 0.9451476793248945\n",
      "Epoch 10: Train Loss = 0.15762931122290377, Recall = 0.9688741721854305, Aging Rate = 0.515728476821192, Precision = 0.9393258426966292, f1 = 0.9538712306438468\n",
      "Test Loss = 0.1443141226144816, Recall = 0.9764900662251655, Aging Rate = 0.5200331125827815, precision = 0.938872970391595\n",
      "Model in epoch 10 is saved.\n",
      "\n",
      "Epoch 11: Train Loss = 0.14146849988706853, Recall = 0.971523178807947, Aging Rate = 0.5139072847682119, Precision = 0.9452319587628866, f1 = 0.9581972566949707\n",
      "Epoch 12: Train Loss = 0.12760496735572815, Recall = 0.9764900662251655, Aging Rate = 0.5124172185430463, Precision = 0.952827140549273, f1 = 0.9645134914145542\n",
      "Epoch 13: Train Loss = 0.1167988926468306, Recall = 0.9774834437086093, Aging Rate = 0.5089403973509934, Precision = 0.9603122966818478, f1 = 0.9688217919264851\n",
      "Epoch 14: Train Loss = 0.107982424523262, Recall = 0.9788079470198675, Aging Rate = 0.5082781456953642, Precision = 0.9628664495114007, f1 = 0.9707717569786535\n",
      "Epoch 15: Train Loss = 0.09899146136463872, Recall = 0.9847682119205298, Aging Rate = 0.5100993377483444, Precision = 0.9652710159039273, f1 = 0.9749221439108344\n",
      "Test Loss = 0.09218394859934485, Recall = 0.9890728476821192, Aging Rate = 0.5112582781456954, precision = 0.9672927461139896\n",
      "Model in epoch 15 is saved.\n",
      "\n",
      "Epoch 16: Train Loss = 0.0909231496666441, Recall = 0.9870860927152317, Aging Rate = 0.508774834437086, Precision = 0.9700618288317605, f1 = 0.9784999179386181\n",
      "Epoch 17: Train Loss = 0.08523357010242955, Recall = 0.9874172185430463, Aging Rate = 0.5084437086092716, Precision = 0.9710192119830674, f1 = 0.9791495649318667\n",
      "Epoch 18: Train Loss = 0.08038448297622187, Recall = 0.9894039735099338, Aging Rate = 0.5076158940397351, Precision = 0.974559686888454, f1 = 0.9819257311863293\n",
      "Epoch 19: Train Loss = 0.07618823982528504, Recall = 0.9894039735099338, Aging Rate = 0.5071192052980132, Precision = 0.9755142017629774, f1 = 0.9824099950682229\n",
      "Epoch 20: Train Loss = 0.07541116437572518, Recall = 0.9887417218543046, Aging Rate = 0.5064569536423841, Precision = 0.9761359921542988, f1 = 0.9823984207928936\n",
      "Test Loss = 0.07089636784712999, Recall = 0.9827814569536424, Aging Rate = 0.49768211920529803, precision = 0.9873586161011311\n",
      "Model in epoch 20 is saved.\n",
      "\n",
      "Epoch 21: Train Loss = 0.06811749972649757, Recall = 0.9927152317880795, Aging Rate = 0.5082781456953642, Precision = 0.9765472312703583, f1 = 0.9845648604269294\n",
      "Epoch 22: Train Loss = 0.06466684228931831, Recall = 0.9923841059602649, Aging Rate = 0.5061258278145695, Precision = 0.9803729146221786, f1 = 0.9863419450386705\n",
      "Epoch 23: Train Loss = 0.06243521786782126, Recall = 0.9923841059602649, Aging Rate = 0.5062913907284768, Precision = 0.9800523217789405, f1 = 0.9861796643632774\n",
      "Epoch 24: Train Loss = 0.059333968581940164, Recall = 0.9937086092715232, Aging Rate = 0.5049668874172185, Precision = 0.9839344262295082, f1 = 0.9887973640856672\n",
      "Epoch 25: Train Loss = 0.05802663723561938, Recall = 0.9943708609271523, Aging Rate = 0.5062913907284768, Precision = 0.9820143884892086, f1 = 0.9881539980256664\n",
      "Test Loss = 0.053315788808445265, Recall = 0.9960264900662251, Aging Rate = 0.5059602649006623, precision = 0.9842931937172775\n",
      "Model in epoch 25 is saved.\n",
      "\n",
      "Epoch 26: Train Loss = 0.055315636789167164, Recall = 0.9943708609271523, Aging Rate = 0.5052980132450331, Precision = 0.9839449541284404, f1 = 0.9891304347826088\n",
      "Epoch 27: Train Loss = 0.05389503084665892, Recall = 0.9950331125827815, Aging Rate = 0.5061258278145695, Precision = 0.9829898593392215, f1 = 0.9889748231035049\n",
      "Epoch 28: Train Loss = 0.05127652151793834, Recall = 0.9950331125827815, Aging Rate = 0.5049668874172185, Precision = 0.9852459016393442, f1 = 0.9901153212520594\n",
      "Epoch 29: Train Loss = 0.04957658806384004, Recall = 0.9947019867549669, Aging Rate = 0.5041390728476821, Precision = 0.9865353037766831, f1 = 0.9906018136850784\n",
      "Epoch 30: Train Loss = 0.048659974257677596, Recall = 0.9947019867549669, Aging Rate = 0.5049668874172185, Precision = 0.9849180327868853, f1 = 0.9897858319604612\n",
      "Test Loss = 0.044997947791356914, Recall = 0.9963576158940397, Aging Rate = 0.5046357615894039, precision = 0.9872047244094488\n",
      "Model in epoch 30 is saved.\n",
      "\n",
      "Epoch 31: Train Loss = 0.04714979319185611, Recall = 0.9956953642384105, Aging Rate = 0.5048013245033113, Precision = 0.9862249918005903, f1 = 0.9909375514911847\n",
      "Epoch 32: Train Loss = 0.04541281397078211, Recall = 0.9960264900662251, Aging Rate = 0.5038079470198675, Precision = 0.9884981925731187, f1 = 0.9922480620155039\n",
      "Epoch 33: Train Loss = 0.044496865417586254, Recall = 0.9953642384105961, Aging Rate = 0.5038079470198675, Precision = 0.9878409464344396, f1 = 0.9915883226125681\n",
      "Epoch 34: Train Loss = 0.0434562920537216, Recall = 0.9966887417218543, Aging Rate = 0.5043046357615895, Precision = 0.9881812212738017, f1 = 0.992416749093307\n",
      "Epoch 35: Train Loss = 0.04268634648907264, Recall = 0.9956953642384105, Aging Rate = 0.5044701986754967, Precision = 0.9868723334427305, f1 = 0.9912642162518542\n",
      "Test Loss = 0.03965584221265174, Recall = 0.9970198675496689, Aging Rate = 0.5024834437086093, precision = 0.9920922570016475\n",
      "Model in epoch 35 is saved.\n",
      "\n",
      "Epoch 36: Train Loss = 0.043354604950803795, Recall = 0.9956953642384105, Aging Rate = 0.5036423841059603, Precision = 0.9884944115713347, f1 = 0.9920818211811284\n",
      "Epoch 37: Train Loss = 0.0409995882469692, Recall = 0.9960264900662251, Aging Rate = 0.5033112582781457, Precision = 0.9894736842105263, f1 = 0.9927392739273928\n",
      "Epoch 38: Train Loss = 0.040110248272979494, Recall = 0.9966887417218543, Aging Rate = 0.5038079470198675, Precision = 0.9891554387117976, f1 = 0.9929078014184397\n",
      "Epoch 39: Train Loss = 0.039155622986176156, Recall = 0.9970198675496689, Aging Rate = 0.5039735099337749, Precision = 0.9891590013140604, f1 = 0.9930738786279684\n",
      "Epoch 40: Train Loss = 0.03815766100259806, Recall = 0.9963576158940397, Aging Rate = 0.5029801324503311, Precision = 0.9904542462146149, f1 = 0.993397160779135\n",
      "Test Loss = 0.03715723831922013, Recall = 0.9983443708609272, Aging Rate = 0.5054635761589404, precision = 0.9875532263347527\n",
      "\n",
      "Epoch 41: Train Loss = 0.03817311849272409, Recall = 0.9960264900662251, Aging Rate = 0.5031456953642384, Precision = 0.9897992760776572, f1 = 0.9929031193266216\n",
      "Epoch 42: Train Loss = 0.037131275917520586, Recall = 0.9970198675496689, Aging Rate = 0.5031456953642384, Precision = 0.9907864429088517, f1 = 0.9938933817461627\n",
      "Epoch 43: Train Loss = 0.037310916451823634, Recall = 0.997682119205298, Aging Rate = 0.5041390728476821, Precision = 0.9894909688013136, f1 = 0.9935696619950536\n",
      "Epoch 44: Train Loss = 0.03591887519158275, Recall = 0.997682119205298, Aging Rate = 0.5038079470198675, Precision = 0.9901413079198159, f1 = 0.9938974105228434\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45: Train Loss = 0.035176813725801497, Recall = 0.9970198675496689, Aging Rate = 0.5031456953642384, Precision = 0.9907864429088517, f1 = 0.9938933817461627\n",
      "Test Loss = 0.03240729978443771, Recall = 0.9980132450331126, Aging Rate = 0.502317880794702, precision = 0.99340804218853\n",
      "Model in epoch 45 is saved.\n",
      "\n",
      "Epoch 46: Train Loss = 0.03533783777067993, Recall = 0.9973509933774835, Aging Rate = 0.5028145695364239, Precision = 0.991768192295028, f1 = 0.9945517582961863\n",
      "Epoch 47: Train Loss = 0.03482896241525941, Recall = 0.9970198675496689, Aging Rate = 0.5031456953642384, Precision = 0.9907864429088517, f1 = 0.9938933817461627\n",
      "Epoch 48: Train Loss = 0.03382252207556308, Recall = 0.997682119205298, Aging Rate = 0.5026490066225165, Precision = 0.9924242424242424, f1 = 0.9950462351387054\n",
      "Epoch 49: Train Loss = 0.0338658175449695, Recall = 0.9966887417218543, Aging Rate = 0.5016556291390728, Precision = 0.9933993399339934, f1 = 0.9950413223140495\n",
      "Epoch 50: Train Loss = 0.0335068951675434, Recall = 0.9966887417218543, Aging Rate = 0.5024834437086093, Precision = 0.9917627677100495, f1 = 0.9942196531791908\n",
      "Test Loss = 0.03074650193089681, Recall = 0.9983443708609272, Aging Rate = 0.5018211920529801, precision = 0.9947212141207522\n",
      "Model in epoch 50 is saved.\n",
      "\n",
      "Epoch 51: Train Loss = 0.0330608346061596, Recall = 0.9973509933774835, Aging Rate = 0.5024834437086093, Precision = 0.9924217462932454, f1 = 0.994880264244426\n",
      "Epoch 52: Train Loss = 0.03260670328969197, Recall = 0.9966887417218543, Aging Rate = 0.5013245033112583, Precision = 0.9940554821664465, f1 = 0.9953703703703705\n",
      "Epoch 53: Train Loss = 0.032396820478684064, Recall = 0.9980132450331126, Aging Rate = 0.502317880794702, Precision = 0.99340804218853, f1 = 0.9957053187974892\n",
      "Epoch 54: Train Loss = 0.03210672033050203, Recall = 0.9970198675496689, Aging Rate = 0.5019867549668874, Precision = 0.9930738786279684, f1 = 0.9950429610046265\n",
      "Epoch 55: Train Loss = 0.03207012073488425, Recall = 0.997682119205298, Aging Rate = 0.502317880794702, Precision = 0.9930784442979564, f1 = 0.9953749587049884\n",
      "Test Loss = 0.0296458063585474, Recall = 0.9973509933774835, Aging Rate = 0.5, precision = 0.9973509933774835\n",
      "Model in epoch 55 is saved.\n",
      "\n",
      "Epoch 56: Train Loss = 0.032095052713886005, Recall = 0.9973509933774835, Aging Rate = 0.502317880794702, Precision = 0.992748846407383, f1 = 0.9950445986124876\n",
      "Epoch 57: Train Loss = 0.03122119747891726, Recall = 0.9983443708609272, Aging Rate = 0.502317880794702, Precision = 0.9937376400791035, f1 = 0.9960356788899902\n",
      "Epoch 58: Train Loss = 0.030623922373680088, Recall = 0.9983443708609272, Aging Rate = 0.502317880794702, Precision = 0.9937376400791035, f1 = 0.9960356788899902\n",
      "Epoch 59: Train Loss = 0.030053600491277428, Recall = 0.9983443708609272, Aging Rate = 0.502317880794702, Precision = 0.9937376400791035, f1 = 0.9960356788899902\n",
      "Epoch 60: Train Loss = 0.0304729999912693, Recall = 0.9980132450331126, Aging Rate = 0.5021523178807947, Precision = 0.9937355753379492, f1 = 0.995869816619858\n",
      "Test Loss = 0.029295474779329554, Recall = 0.9990066225165563, Aging Rate = 0.5028145695364239, precision = 0.9934145538360224\n",
      "\n",
      "Epoch 61: Train Loss = 0.030062177989459194, Recall = 0.9980132450331126, Aging Rate = 0.5019867549668874, Precision = 0.9940633245382586, f1 = 0.9960343688037013\n",
      "Epoch 62: Train Loss = 0.030208661762491755, Recall = 0.9983443708609272, Aging Rate = 0.5026490066225165, Precision = 0.9930830039525692, f1 = 0.9957067371202114\n",
      "Epoch 63: Train Loss = 0.029762209335107676, Recall = 0.9980132450331126, Aging Rate = 0.5018211920529801, Precision = 0.9943912900032993, f1 = 0.9961989753759709\n",
      "Epoch 64: Train Loss = 0.029585383726370255, Recall = 0.9983443708609272, Aging Rate = 0.5019867549668874, Precision = 0.9943931398416886, f1 = 0.9963648380700596\n",
      "Epoch 65: Train Loss = 0.02975041230289352, Recall = 0.9980132450331126, Aging Rate = 0.5014900662251656, Precision = 0.9950478705843513, f1 = 0.9965283517936848\n",
      "Test Loss = 0.027098995869029436, Recall = 0.9990066225165563, Aging Rate = 0.5019867549668874, precision = 0.9950527704485488\n",
      "\n",
      "Epoch 66: Train Loss = 0.029516936093568803, Recall = 0.997682119205298, Aging Rate = 0.502317880794702, Precision = 0.9930784442979564, f1 = 0.9953749587049884\n",
      "Epoch 67: Train Loss = 0.029594546507131184, Recall = 0.9983443708609272, Aging Rate = 0.502317880794702, Precision = 0.9937376400791035, f1 = 0.9960356788899902\n",
      "Epoch 68: Train Loss = 0.028985931339445492, Recall = 0.9983443708609272, Aging Rate = 0.5021523178807947, Precision = 0.9940652818991098, f1 = 0.9962002312902692\n",
      "Epoch 69: Train Loss = 0.02859407158087421, Recall = 0.9980132450331126, Aging Rate = 0.5014900662251656, Precision = 0.9950478705843513, f1 = 0.9965283517936848\n",
      "Epoch 70: Train Loss = 0.028317493333524426, Recall = 0.9983443708609272, Aging Rate = 0.5021523178807947, Precision = 0.9940652818991098, f1 = 0.9962002312902692\n",
      "Test Loss = 0.026341149921448814, Recall = 0.9990066225165563, Aging Rate = 0.5018211920529801, precision = 0.9953810623556582\n",
      "\n",
      "Epoch 71: Train Loss = 0.028041203766567817, Recall = 0.9986754966887417, Aging Rate = 0.5018211920529801, Precision = 0.9950511382382052, f1 = 0.9968600231366715\n",
      "Epoch 72: Train Loss = 0.028455283897404638, Recall = 0.997682119205298, Aging Rate = 0.5018211920529801, Precision = 0.9940613658858463, f1 = 0.9958684514956206\n",
      "Epoch 73: Train Loss = 0.027928316373600076, Recall = 0.9990066225165563, Aging Rate = 0.5026490066225165, Precision = 0.9937417654808959, f1 = 0.9963672391017173\n",
      "Epoch 74: Train Loss = 0.02821645849193169, Recall = 0.9980132450331126, Aging Rate = 0.5014900662251656, Precision = 0.9950478705843513, f1 = 0.9965283517936848\n",
      "Epoch 75: Train Loss = 0.02814712195552343, Recall = 0.9983443708609272, Aging Rate = 0.5014900662251656, Precision = 0.9953780125453945, f1 = 0.9968589849561911\n",
      "Test Loss = 0.02633758813192118, Recall = 0.9990066225165563, Aging Rate = 0.5018211920529801, precision = 0.9953810623556582\n",
      "\n",
      "Epoch 76: Train Loss = 0.02864669951184696, Recall = 0.9986754966887417, Aging Rate = 0.5021523178807947, Precision = 0.9943949884602704, f1 = 0.9965306459606807\n",
      "Epoch 77: Train Loss = 0.027915115624863582, Recall = 0.9980132450331126, Aging Rate = 0.5014900662251656, Precision = 0.9950478705843513, f1 = 0.9965283517936848\n",
      "Epoch 78: Train Loss = 0.02741674113500592, Recall = 0.9993377483443708, Aging Rate = 0.5028145695364239, Precision = 0.9937438261442213, f1 = 0.9965329370975731\n",
      "Epoch 79: Train Loss = 0.027323949565210486, Recall = 0.9986754966887417, Aging Rate = 0.5019867549668874, Precision = 0.9947229551451188, f1 = 0.9966953073364176\n",
      "Epoch 80: Train Loss = 0.02786452540794745, Recall = 0.9983443708609272, Aging Rate = 0.5019867549668874, Precision = 0.9943931398416886, f1 = 0.9963648380700596\n",
      "Test Loss = 0.02609151451792938, Recall = 0.9993377483443708, Aging Rate = 0.5014900662251656, precision = 0.9963684384285243\n",
      "Model in epoch 80 is saved.\n",
      "\n",
      "Epoch 81: Train Loss = 0.027329868485299957, Recall = 0.9986754966887417, Aging Rate = 0.5019867549668874, Precision = 0.9947229551451188, f1 = 0.9966953073364176\n",
      "Epoch 82: Train Loss = 0.027086414451038602, Recall = 0.9986754966887417, Aging Rate = 0.5019867549668874, Precision = 0.9947229551451188, f1 = 0.9966953073364176\n",
      "Epoch 83: Train Loss = 0.02809259954667249, Recall = 0.9986754966887417, Aging Rate = 0.5018211920529801, Precision = 0.9950511382382052, f1 = 0.9968600231366715\n",
      "Epoch 84: Train Loss = 0.02656640795287707, Recall = 0.9986754966887417, Aging Rate = 0.5019867549668874, Precision = 0.9947229551451188, f1 = 0.9966953073364176\n",
      "Epoch 85: Train Loss = 0.02771206619032961, Recall = 0.9990066225165563, Aging Rate = 0.5021523178807947, Precision = 0.9947246950214309, f1 = 0.996861060631092\n",
      "Test Loss = 0.025568676540097653, Recall = 0.9983443708609272, Aging Rate = 0.5001655629139072, precision = 0.9980139026812314\n",
      "Model in epoch 85 is saved.\n",
      "\n",
      "Epoch 86: Train Loss = 0.026652452766599246, Recall = 0.9993377483443708, Aging Rate = 0.5024834437086093, Precision = 0.9943986820428337, f1 = 0.9968620974401321\n",
      "Epoch 87: Train Loss = 0.027116708358786754, Recall = 0.9990066225165563, Aging Rate = 0.5019867549668874, Precision = 0.9950527704485488, f1 = 0.9970257766027759\n",
      "Epoch 88: Train Loss = 0.027104911405519145, Recall = 0.9983443708609272, Aging Rate = 0.5016556291390728, Precision = 0.995049504950495, f1 = 0.9966942148760332\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 89: Train Loss = 0.027082316236977547, Recall = 0.9996688741721854, Aging Rate = 0.5024834437086093, Precision = 0.9947281713344316, f1 = 0.9971924029727498\n",
      "Epoch 90: Train Loss = 0.026837781848793, Recall = 0.9990066225165563, Aging Rate = 0.5018211920529801, Precision = 0.9953810623556582, f1 = 0.9971905470170219\n",
      "Test Loss = 0.024822216757283307, Recall = 0.9996688741721854, Aging Rate = 0.5013245033112583, precision = 0.9970277410832232\n",
      "\n",
      "Epoch 91: Train Loss = 0.026760004934490912, Recall = 0.9983443708609272, Aging Rate = 0.5013245033112583, Precision = 0.9957067371202114, f1 = 0.9970238095238096\n",
      "Epoch 92: Train Loss = 0.026867326909047088, Recall = 0.9990066225165563, Aging Rate = 0.5021523178807947, Precision = 0.9947246950214309, f1 = 0.996861060631092\n",
      "Epoch 93: Train Loss = 0.026988491144598715, Recall = 0.9980132450331126, Aging Rate = 0.5013245033112583, Precision = 0.9953764861294584, f1 = 0.9966931216931217\n",
      "Epoch 94: Train Loss = 0.027141965967633866, Recall = 0.9993377483443708, Aging Rate = 0.5029801324503311, Precision = 0.9934167215273206, f1 = 0.9963684384285243\n",
      "Epoch 95: Train Loss = 0.026477943037618076, Recall = 0.9990066225165563, Aging Rate = 0.5019867549668874, Precision = 0.9950527704485488, f1 = 0.9970257766027759\n",
      "Test Loss = 0.029856225258565898, Recall = 0.9966887417218543, Aging Rate = 0.4986754966887417, precision = 0.99933598937583\n",
      "Model in epoch 95 is saved.\n",
      "\n",
      "Epoch 96: Train Loss = 0.026503179483855797, Recall = 0.9996688741721854, Aging Rate = 0.5014900662251656, Precision = 0.9966985803895675, f1 = 0.9981815176062159\n",
      "Epoch 97: Train Loss = 0.026596903564124707, Recall = 0.9990066225165563, Aging Rate = 0.5019867549668874, Precision = 0.9950527704485488, f1 = 0.9970257766027759\n",
      "Epoch 98: Train Loss = 0.02680644029813097, Recall = 0.9986754966887417, Aging Rate = 0.5016556291390728, Precision = 0.9953795379537954, f1 = 0.9970247933884296\n",
      "Epoch 99: Train Loss = 0.026200459549659924, Recall = 0.9986754966887417, Aging Rate = 0.5018211920529801, Precision = 0.9950511382382052, f1 = 0.9968600231366715\n",
      "Epoch 100: Train Loss = 0.026936879058350002, Recall = 0.9993377483443708, Aging Rate = 0.5021523178807947, Precision = 0.9950544015825915, f1 = 0.9971914753015033\n",
      "Test Loss = 0.024851774436649897, Recall = 0.9996688741721854, Aging Rate = 0.5018211920529801, precision = 0.9960409105905642\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1220368f9b434bf9a9a4392c1235d7ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss = 0.5569896950627005, Recall = 0.9814569536423841, Aging Rate = 0.9582781456953643, Precision = 0.51209398756047, f1 = 0.673024523160763\n",
      "Epoch 2: Train Loss = 0.40087285720749405, Recall = 0.9506622516556291, Aging Rate = 0.6948675496688742, Precision = 0.684060042887777, f1 = 0.7956214493556879\n",
      "Epoch 3: Train Loss = 0.3233372991448207, Recall = 0.9503311258278145, Aging Rate = 0.6289735099337749, Precision = 0.7554619636746512, f1 = 0.8417656547880921\n",
      "Epoch 4: Train Loss = 0.27457065823062365, Recall = 0.9509933774834437, Aging Rate = 0.5902317880794702, Precision = 0.8056100981767181, f1 = 0.872285497342445\n",
      "Epoch 5: Train Loss = 0.23772468012295023, Recall = 0.9625827814569536, Aging Rate = 0.5783112582781457, Precision = 0.8322359003721729, f1 = 0.8926761860893597\n",
      "Test Loss = 0.20402780348891453, Recall = 0.9731788079470198, Aging Rate = 0.5746688741721855, precision = 0.84673004897724\n",
      "Model in epoch 5 is saved.\n",
      "\n",
      "Epoch 6: Train Loss = 0.19169866878860045, Recall = 0.9668874172185431, Aging Rate = 0.5592715231788079, Precision = 0.8644168146832445, f1 = 0.912785245389184\n",
      "Epoch 7: Train Loss = 0.1612874186196864, Recall = 0.9731788079470198, Aging Rate = 0.5417218543046357, Precision = 0.8982273838630807, f1 = 0.9342021614748887\n",
      "Epoch 8: Train Loss = 0.13589176298766736, Recall = 0.9798013245033113, Aging Rate = 0.5337748344370861, Precision = 0.917803970223325, f1 = 0.9477898782831519\n",
      "Epoch 9: Train Loss = 0.11717463674529499, Recall = 0.9844370860927152, Aging Rate = 0.5291390728476821, Precision = 0.9302252816020025, f1 = 0.9565637065637065\n",
      "Epoch 10: Train Loss = 0.0999356463946254, Recall = 0.9867549668874173, Aging Rate = 0.5223509933774835, Precision = 0.9445324881141046, f1 = 0.9651821862348178\n",
      "Test Loss = 0.0904080854543787, Recall = 0.9877483443708609, Aging Rate = 0.5129139072847683, precision = 0.9628792769528728\n",
      "Model in epoch 10 is saved.\n",
      "\n",
      "Epoch 11: Train Loss = 0.08761818752383554, Recall = 0.9903973509933774, Aging Rate = 0.519205298013245, Precision = 0.9537627551020408, f1 = 0.9717348927875242\n",
      "Epoch 12: Train Loss = 0.07661976071185624, Recall = 0.9917218543046358, Aging Rate = 0.5155629139072848, Precision = 0.9617854849068722, f1 = 0.9765242908379524\n",
      "Epoch 13: Train Loss = 0.06871481319729066, Recall = 0.9927152317880795, Aging Rate = 0.5149006622516556, Precision = 0.9639871382636656, f1 = 0.9781402936378466\n",
      "Epoch 14: Train Loss = 0.06083077046255402, Recall = 0.9937086092715232, Aging Rate = 0.5117549668874172, Precision = 0.970883209317373, f1 = 0.9821633120602193\n",
      "Epoch 15: Train Loss = 0.05505776607635005, Recall = 0.9950331125827815, Aging Rate = 0.5114238410596027, Precision = 0.9728067335707349, f1 = 0.9837944017024064\n",
      "Test Loss = 0.04873056396200562, Recall = 0.9963576158940397, Aging Rate = 0.5089403973509934, precision = 0.9788549121665582\n",
      "Model in epoch 15 is saved.\n",
      "\n",
      "Epoch 16: Train Loss = 0.04971135972647477, Recall = 0.9950331125827815, Aging Rate = 0.5084437086092716, Precision = 0.9785086291110388, f1 = 0.9867016910195371\n",
      "Epoch 17: Train Loss = 0.04565737996965844, Recall = 0.9956953642384105, Aging Rate = 0.5091059602649006, Precision = 0.9778861788617886, f1 = 0.9867104183757177\n",
      "Epoch 18: Train Loss = 0.04136698687609458, Recall = 0.9970198675496689, Aging Rate = 0.5082781456953642, Precision = 0.9807817589576547, f1 = 0.9888341543513957\n",
      "Epoch 19: Train Loss = 0.03842606594823054, Recall = 0.997682119205298, Aging Rate = 0.5077814569536424, Precision = 0.9823932181284643, f1 = 0.9899786430096928\n",
      "Epoch 20: Train Loss = 0.035205587164949106, Recall = 0.9973509933774835, Aging Rate = 0.5071192052980132, Precision = 0.9833496571988247, f1 = 0.9903008384021043\n",
      "Test Loss = 0.031031070270927143, Recall = 0.9980132450331126, Aging Rate = 0.5052980132450331, precision = 0.9875491480996068\n",
      "Model in epoch 20 is saved.\n",
      "\n",
      "Epoch 21: Train Loss = 0.0321024999367875, Recall = 0.9980132450331126, Aging Rate = 0.506953642384106, Precision = 0.984323971260614, f1 = 0.9911213416639263\n",
      "Epoch 22: Train Loss = 0.030297697187456864, Recall = 0.9986754966887417, Aging Rate = 0.5064569536423841, Precision = 0.9859431186662307, f1 = 0.9922684652080934\n",
      "Epoch 23: Train Loss = 0.027984023250836806, Recall = 0.997682119205298, Aging Rate = 0.5044701986754967, Precision = 0.9888414834263209, f1 = 0.9932421295533213\n",
      "Epoch 24: Train Loss = 0.025831829233477446, Recall = 0.9980132450331126, Aging Rate = 0.5046357615894039, Precision = 0.9888451443569554, f1 = 0.99340804218853\n",
      "Epoch 25: Train Loss = 0.024294169292791396, Recall = 0.9986754966887417, Aging Rate = 0.5052980132450331, Precision = 0.9882044560943644, f1 = 0.9934123847167325\n",
      "Test Loss = 0.0214485850900609, Recall = 0.9993377483443708, Aging Rate = 0.5026490066225165, precision = 0.9940711462450593\n",
      "Model in epoch 25 is saved.\n",
      "\n",
      "Epoch 26: Train Loss = 0.022560895268885505, Recall = 0.9983443708609272, Aging Rate = 0.5043046357615895, Precision = 0.9898227183191071, f1 = 0.9940652818991098\n",
      "Epoch 27: Train Loss = 0.021527136127088245, Recall = 0.9986754966887417, Aging Rate = 0.5041390728476821, Precision = 0.9904761904761905, f1 = 0.9945589447650454\n",
      "Epoch 28: Train Loss = 0.02011418238417893, Recall = 0.9990066225165563, Aging Rate = 0.5036423841059603, Precision = 0.9917817225509533, f1 = 0.9953810623556583\n",
      "Epoch 29: Train Loss = 0.018502055902946863, Recall = 0.9993377483443708, Aging Rate = 0.5031456953642384, Precision = 0.9930898321816387, f1 = 0.9962039940584255\n",
      "Epoch 30: Train Loss = 0.017905252507659574, Recall = 0.9990066225165563, Aging Rate = 0.502317880794702, Precision = 0.9943968358602505, f1 = 0.9966963990749917\n",
      "Test Loss = 0.01584510285135926, Recall = 1.0, Aging Rate = 0.5028145695364239, precision = 0.994402370760619\n",
      "Model in epoch 30 is saved.\n",
      "\n",
      "Epoch 31: Train Loss = 0.016447714898759954, Recall = 0.9993377483443708, Aging Rate = 0.502317880794702, Precision = 0.994726433750824, f1 = 0.9970267591674926\n",
      "Epoch 32: Train Loss = 0.015673916984275477, Recall = 0.9990066225165563, Aging Rate = 0.5018211920529801, Precision = 0.9953810623556582, f1 = 0.9971905470170219\n",
      "Epoch 33: Train Loss = 0.01454021485880116, Recall = 1.0, Aging Rate = 0.5024834437086093, Precision = 0.9950576606260296, f1 = 0.9975227085053675\n",
      "Epoch 34: Train Loss = 0.013789908162361343, Recall = 0.9993377483443708, Aging Rate = 0.5019867549668874, Precision = 0.9953825857519789, f1 = 0.9973562458691342\n",
      "Epoch 35: Train Loss = 0.013384010176488895, Recall = 0.9993377483443708, Aging Rate = 0.5014900662251656, Precision = 0.9963684384285243, f1 = 0.9978508844437097\n",
      "Test Loss = 0.012038971336916188, Recall = 0.9996688741721854, Aging Rate = 0.5016556291390728, precision = 0.9963696369636964\n",
      "Model in epoch 35 is saved.\n",
      "\n",
      "Epoch 36: Train Loss = 0.01225825035636196, Recall = 0.9996688741721854, Aging Rate = 0.501158940397351, Precision = 0.9973571192599934, f1 = 0.9985116586737225\n",
      "Epoch 37: Train Loss = 0.011669025166786664, Recall = 0.9996688741721854, Aging Rate = 0.5013245033112583, Precision = 0.9970277410832232, f1 = 0.9983465608465608\n",
      "Epoch 38: Train Loss = 0.01091963445015301, Recall = 1.0, Aging Rate = 0.501158940397351, Precision = 0.9976874793524942, f1 = 0.9988424011906731\n",
      "Epoch 39: Train Loss = 0.010880161349396436, Recall = 0.9996688741721854, Aging Rate = 0.5009933774834437, Precision = 0.9976867151354925, f1 = 0.9986768111147866\n",
      "Epoch 40: Train Loss = 0.010173064404913527, Recall = 0.9996688741721854, Aging Rate = 0.5013245033112583, Precision = 0.9970277410832232, f1 = 0.9983465608465608\n",
      "Test Loss = 0.009148018356313965, Recall = 0.9993377483443708, Aging Rate = 0.5, precision = 0.9993377483443708\n",
      "Model in epoch 40 is saved.\n",
      "\n",
      "Epoch 41: Train Loss = 0.009723080478805974, Recall = 0.9996688741721854, Aging Rate = 0.5004966887417218, Precision = 0.9986768111147867, f1 = 0.9991725963925203\n",
      "Epoch 42: Train Loss = 0.009267531987279653, Recall = 0.9996688741721854, Aging Rate = 0.501158940397351, Precision = 0.9973571192599934, f1 = 0.9985116586737225\n",
      "Epoch 43: Train Loss = 0.008975229546464732, Recall = 0.9996688741721854, Aging Rate = 0.5004966887417218, Precision = 0.9986768111147867, f1 = 0.9991725963925203\n",
      "Epoch 44: Train Loss = 0.008668448839842385, Recall = 0.9996688741721854, Aging Rate = 0.5006622516556292, Precision = 0.9983465608465608, f1 = 0.999007279947055\n",
      "Epoch 45: Train Loss = 0.008865908863923407, Recall = 0.9996688741721854, Aging Rate = 0.5006622516556292, Precision = 0.9983465608465608, f1 = 0.999007279947055\n",
      "Test Loss = 0.007402616620853247, Recall = 1.0, Aging Rate = 0.5006622516556292, precision = 0.9986772486772487\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 46: Train Loss = 0.007978904968904738, Recall = 0.9996688741721854, Aging Rate = 0.5009933774834437, Precision = 0.9976867151354925, f1 = 0.9986768111147866\n",
      "Epoch 47: Train Loss = 0.007615888256900358, Recall = 0.9996688741721854, Aging Rate = 0.5004966887417218, Precision = 0.9986768111147867, f1 = 0.9991725963925203\n",
      "Epoch 48: Train Loss = 0.00739432836679236, Recall = 1.0, Aging Rate = 0.5006622516556292, Precision = 0.9986772486772487, f1 = 0.99933818663137\n",
      "Epoch 49: Train Loss = 0.007122237588100086, Recall = 0.9996688741721854, Aging Rate = 0.5, Precision = 0.9996688741721854, f1 = 0.9996688741721854\n",
      "Epoch 50: Train Loss = 0.006665955028737223, Recall = 0.9996688741721854, Aging Rate = 0.5004966887417218, Precision = 0.9986768111147867, f1 = 0.9991725963925203\n",
      "Test Loss = 0.006839977878004016, Recall = 1.0, Aging Rate = 0.5008278145695364, precision = 0.9983471074380166\n",
      "\n",
      "Epoch 51: Train Loss = 0.006910074843920225, Recall = 0.9996688741721854, Aging Rate = 0.5004966887417218, Precision = 0.9986768111147867, f1 = 0.9991725963925203\n",
      "Epoch 52: Train Loss = 0.006438430498465156, Recall = 1.0, Aging Rate = 0.5006622516556292, Precision = 0.9986772486772487, f1 = 0.99933818663137\n",
      "Epoch 53: Train Loss = 0.0065025753890540425, Recall = 0.9996688741721854, Aging Rate = 0.5006622516556292, Precision = 0.9983465608465608, f1 = 0.999007279947055\n",
      "Epoch 54: Train Loss = 0.006169326746503249, Recall = 0.9996688741721854, Aging Rate = 0.5003311258278146, Precision = 0.999007279947055, f1 = 0.9993379675604105\n",
      "Epoch 55: Train Loss = 0.0060458858907592805, Recall = 0.9996688741721854, Aging Rate = 0.5003311258278146, Precision = 0.999007279947055, f1 = 0.9993379675604105\n",
      "Test Loss = 0.005269605527009001, Recall = 1.0, Aging Rate = 0.5004966887417218, precision = 0.9990076083360899\n",
      "Model in epoch 55 is saved.\n",
      "\n",
      "Epoch 56: Train Loss = 0.00559877786069911, Recall = 1.0, Aging Rate = 0.5004966887417218, Precision = 0.9990076083360899, f1 = 0.9995035578355121\n",
      "Epoch 57: Train Loss = 0.00557199643419081, Recall = 1.0, Aging Rate = 0.5006622516556292, Precision = 0.9986772486772487, f1 = 0.99933818663137\n",
      "Epoch 58: Train Loss = 0.005736607694319937, Recall = 0.9996688741721854, Aging Rate = 0.5003311258278146, Precision = 0.999007279947055, f1 = 0.9993379675604105\n",
      "Epoch 59: Train Loss = 0.005408128883553953, Recall = 0.9996688741721854, Aging Rate = 0.5004966887417218, Precision = 0.9986768111147867, f1 = 0.9991725963925203\n",
      "Epoch 60: Train Loss = 0.005641967691604468, Recall = 0.9996688741721854, Aging Rate = 0.5004966887417218, Precision = 0.9986768111147867, f1 = 0.9991725963925203\n",
      "Test Loss = 0.0045889897882593, Recall = 0.9996688741721854, Aging Rate = 0.5001655629139072, precision = 0.9993379675604105\n",
      "Model in epoch 60 is saved.\n",
      "\n",
      "Epoch 61: Train Loss = 0.005285600073549231, Recall = 0.9996688741721854, Aging Rate = 0.5001655629139072, Precision = 0.9993379675604105, f1 = 0.9995033934779011\n",
      "Epoch 62: Train Loss = 0.004927533006431251, Recall = 0.9996688741721854, Aging Rate = 0.5004966887417218, Precision = 0.9986768111147867, f1 = 0.9991725963925203\n",
      "Epoch 63: Train Loss = 0.0051175565822728425, Recall = 1.0, Aging Rate = 0.5006622516556292, Precision = 0.9986772486772487, f1 = 0.99933818663137\n",
      "Epoch 64: Train Loss = 0.004953642154655216, Recall = 0.9996688741721854, Aging Rate = 0.5, Precision = 0.9996688741721854, f1 = 0.9996688741721854\n",
      "Epoch 65: Train Loss = 0.00449409081649948, Recall = 1.0, Aging Rate = 0.5006622516556292, Precision = 0.9986772486772487, f1 = 0.99933818663137\n",
      "Test Loss = 0.004590363142432164, Recall = 0.9996688741721854, Aging Rate = 0.4998344370860927, precision = 1.0\n",
      "Model in epoch 65 is saved.\n",
      "\n",
      "Epoch 66: Train Loss = 0.004883340963575717, Recall = 1.0, Aging Rate = 0.5001655629139072, Precision = 0.9996689837802052, f1 = 0.9998344644926337\n",
      "Epoch 67: Train Loss = 0.004682945937769401, Recall = 0.9996688741721854, Aging Rate = 0.5004966887417218, Precision = 0.9986768111147867, f1 = 0.9991725963925203\n",
      "Epoch 68: Train Loss = 0.004831062737753652, Recall = 0.9996688741721854, Aging Rate = 0.5003311258278146, Precision = 0.999007279947055, f1 = 0.9993379675604105\n",
      "Epoch 69: Train Loss = 0.004812477157445045, Recall = 0.9996688741721854, Aging Rate = 0.5003311258278146, Precision = 0.999007279947055, f1 = 0.9993379675604105\n",
      "Epoch 70: Train Loss = 0.004360443433833044, Recall = 1.0, Aging Rate = 0.5006622516556292, Precision = 0.9986772486772487, f1 = 0.99933818663137\n",
      "Test Loss = 0.0039935068332201595, Recall = 1.0, Aging Rate = 0.5004966887417218, precision = 0.9990076083360899\n",
      "\n",
      "Epoch 71: Train Loss = 0.004826465336334527, Recall = 0.9996688741721854, Aging Rate = 0.5003311258278146, Precision = 0.999007279947055, f1 = 0.9993379675604105\n",
      "Epoch 72: Train Loss = 0.004525281431535814, Recall = 0.9996688741721854, Aging Rate = 0.5003311258278146, Precision = 0.999007279947055, f1 = 0.9993379675604105\n",
      "Epoch 73: Train Loss = 0.004205112327013584, Recall = 1.0, Aging Rate = 0.5006622516556292, Precision = 0.9986772486772487, f1 = 0.99933818663137\n",
      "Epoch 74: Train Loss = 0.004375803085130374, Recall = 1.0, Aging Rate = 0.5006622516556292, Precision = 0.9986772486772487, f1 = 0.99933818663137\n",
      "Epoch 75: Train Loss = 0.0045075467022888316, Recall = 0.9996688741721854, Aging Rate = 0.5001655629139072, Precision = 0.9993379675604105, f1 = 0.9995033934779011\n",
      "Test Loss = 0.003532672734215658, Recall = 1.0, Aging Rate = 0.5004966887417218, precision = 0.9990076083360899\n",
      "\n",
      "Epoch 76: Train Loss = 0.004065482769876916, Recall = 0.9996688741721854, Aging Rate = 0.5003311258278146, Precision = 0.999007279947055, f1 = 0.9993379675604105\n",
      "Epoch 77: Train Loss = 0.004437366390095049, Recall = 0.9996688741721854, Aging Rate = 0.5003311258278146, Precision = 0.999007279947055, f1 = 0.9993379675604105\n",
      "Epoch 78: Train Loss = 0.003997722207044332, Recall = 1.0, Aging Rate = 0.5006622516556292, Precision = 0.9986772486772487, f1 = 0.99933818663137\n",
      "Epoch 79: Train Loss = 0.004417135934684647, Recall = 0.9996688741721854, Aging Rate = 0.5004966887417218, Precision = 0.9986768111147867, f1 = 0.9991725963925203\n",
      "Epoch 80: Train Loss = 0.003905120277962345, Recall = 0.9996688741721854, Aging Rate = 0.5, Precision = 0.9996688741721854, f1 = 0.9996688741721854\n",
      "Test Loss = 0.004622348623707989, Recall = 1.0, Aging Rate = 0.5004966887417218, precision = 0.9990076083360899\n",
      "\n",
      "Epoch 81: Train Loss = 0.004158899838425565, Recall = 1.0, Aging Rate = 0.5004966887417218, Precision = 0.9990076083360899, f1 = 0.9995035578355121\n",
      "Epoch 82: Train Loss = 0.004447320813547499, Recall = 0.9993377483443708, Aging Rate = 0.5003311258278146, Precision = 0.99867637326274, f1 = 0.9990069513406157\n",
      "Epoch 83: Train Loss = 0.003979201148887048, Recall = 0.9996688741721854, Aging Rate = 0.5003311258278146, Precision = 0.999007279947055, f1 = 0.9993379675604105\n",
      "Epoch 84: Train Loss = 0.004248380635106405, Recall = 0.9993377483443708, Aging Rate = 0.5001655629139072, Precision = 0.9990069513406157, f1 = 0.9991723224631683\n",
      "Epoch 85: Train Loss = 0.004160734743422625, Recall = 0.9996688741721854, Aging Rate = 0.5003311258278146, Precision = 0.999007279947055, f1 = 0.9993379675604105\n",
      "Test Loss = 0.0033243334522187118, Recall = 1.0, Aging Rate = 0.5006622516556292, precision = 0.9986772486772487\n",
      "\n",
      "Epoch 86: Train Loss = 0.0038260160331669824, Recall = 1.0, Aging Rate = 0.5006622516556292, Precision = 0.9986772486772487, f1 = 0.99933818663137\n",
      "Epoch 87: Train Loss = 0.0036793290008328215, Recall = 0.9996688741721854, Aging Rate = 0.5001655629139072, Precision = 0.9993379675604105, f1 = 0.9995033934779011\n",
      "Epoch 88: Train Loss = 0.003617789635792473, Recall = 1.0, Aging Rate = 0.5003311258278146, Precision = 0.99933818663137, f1 = 0.9996689837802052\n",
      "Epoch 89: Train Loss = 0.00342664679278009, Recall = 0.9996688741721854, Aging Rate = 0.5003311258278146, Precision = 0.999007279947055, f1 = 0.9993379675604105\n",
      "Epoch 90: Train Loss = 0.004099935489330466, Recall = 0.9996688741721854, Aging Rate = 0.5001655629139072, Precision = 0.9993379675604105, f1 = 0.9995033934779011\n",
      "Test Loss = 0.003178893962862673, Recall = 1.0, Aging Rate = 0.5006622516556292, precision = 0.9986772486772487\n",
      "\n",
      "Epoch 91: Train Loss = 0.0038131459589911907, Recall = 1.0, Aging Rate = 0.5006622516556292, Precision = 0.9986772486772487, f1 = 0.99933818663137\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 92: Train Loss = 0.003550572305399653, Recall = 0.9996688741721854, Aging Rate = 0.5001655629139072, Precision = 0.9993379675604105, f1 = 0.9995033934779011\n",
      "Epoch 93: Train Loss = 0.003944626140303367, Recall = 0.9996688741721854, Aging Rate = 0.5004966887417218, Precision = 0.9986768111147867, f1 = 0.9991725963925203\n",
      "Epoch 94: Train Loss = 0.0036399048950449125, Recall = 1.0, Aging Rate = 0.5004966887417218, Precision = 0.9990076083360899, f1 = 0.9995035578355121\n",
      "Epoch 95: Train Loss = 0.0036859769330958264, Recall = 0.9996688741721854, Aging Rate = 0.5003311258278146, Precision = 0.999007279947055, f1 = 0.9993379675604105\n",
      "Test Loss = 0.0035838591152284023, Recall = 1.0, Aging Rate = 0.5004966887417218, precision = 0.9990076083360899\n",
      "\n",
      "Epoch 96: Train Loss = 0.0037225848782363514, Recall = 0.9996688741721854, Aging Rate = 0.5001655629139072, Precision = 0.9993379675604105, f1 = 0.9995033934779011\n",
      "Epoch 97: Train Loss = 0.0034361823927611113, Recall = 1.0, Aging Rate = 0.5004966887417218, Precision = 0.9990076083360899, f1 = 0.9995035578355121\n",
      "Epoch 98: Train Loss = 0.0036117219911974588, Recall = 0.9996688741721854, Aging Rate = 0.5001655629139072, Precision = 0.9993379675604105, f1 = 0.9995033934779011\n",
      "Epoch 99: Train Loss = 0.0037647929850546337, Recall = 0.9996688741721854, Aging Rate = 0.5003311258278146, Precision = 0.999007279947055, f1 = 0.9993379675604105\n",
      "Epoch 100: Train Loss = 0.003562776856001047, Recall = 0.9996688741721854, Aging Rate = 0.4998344370860927, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.004218688232219772, Recall = 1.0, Aging Rate = 0.5004966887417218, precision = 0.9990076083360899\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f92f15e6b68644a5880a273fb2b92d44",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss = 0.5649455893908115, Recall = 0.9751655629139073, Aging Rate = 0.9508278145695365, Precision = 0.5127981890997736, f1 = 0.6721442428392103\n",
      "Epoch 2: Train Loss = 0.4005602060564306, Recall = 0.9562913907284768, Aging Rate = 0.7072847682119205, Precision = 0.6760299625468165, f1 = 0.7921009325287988\n",
      "Epoch 3: Train Loss = 0.32472027157316147, Recall = 0.9490066225165563, Aging Rate = 0.6268211920529801, Precision = 0.756999471737982, f1 = 0.8421980605348223\n",
      "Epoch 4: Train Loss = 0.2757313114917831, Recall = 0.9539735099337748, Aging Rate = 0.5961920529801324, Precision = 0.8000555401277423, f1 = 0.8702612898353722\n",
      "Epoch 5: Train Loss = 0.24115881531049085, Recall = 0.9579470198675497, Aging Rate = 0.5776490066225165, Precision = 0.8291774147320149, f1 = 0.8889230296512521\n",
      "Test Loss = 0.20342438996627632, Recall = 0.9721854304635762, Aging Rate = 0.5677152317880795, precision = 0.8562263050452027\n",
      "Model in epoch 5 is saved.\n",
      "\n",
      "Epoch 6: Train Loss = 0.18952348494766563, Recall = 0.9695364238410596, Aging Rate = 0.5543046357615894, Precision = 0.8745519713261649, f1 = 0.9195979899497488\n",
      "Epoch 7: Train Loss = 0.1590768096857513, Recall = 0.9764900662251655, Aging Rate = 0.5432119205298013, Precision = 0.8988113380067053, f1 = 0.9360418981114109\n",
      "Epoch 8: Train Loss = 0.13217866721729568, Recall = 0.9791390728476821, Aging Rate = 0.5321192052980133, Precision = 0.9200373366521468, f1 = 0.9486685915944818\n",
      "Epoch 9: Train Loss = 0.11318560303836468, Recall = 0.9814569536423841, Aging Rate = 0.5268211920529802, Precision = 0.9314896291640478, f1 = 0.9558207029990325\n",
      "Epoch 10: Train Loss = 0.09737789473983625, Recall = 0.9860927152317881, Aging Rate = 0.520364238410596, Precision = 0.9475023862551702, f1 = 0.966412461463573\n",
      "Test Loss = 0.08735326862098365, Recall = 0.990728476821192, Aging Rate = 0.5197019867549669, precision = 0.9531697992991398\n",
      "Model in epoch 10 is saved.\n",
      "\n",
      "Epoch 11: Train Loss = 0.08586452079332428, Recall = 0.9877483443708609, Aging Rate = 0.5175496688741722, Precision = 0.9542546385156749, f1 = 0.9707126586397657\n",
      "Epoch 12: Train Loss = 0.07654679590305745, Recall = 0.9890728476821192, Aging Rate = 0.5149006622516556, Precision = 0.9604501607717042, f1 = 0.9745513866231647\n",
      "Epoch 13: Train Loss = 0.06828511552700144, Recall = 0.9903973509933774, Aging Rate = 0.5132450331125827, Precision = 0.9648387096774194, f1 = 0.9774509803921568\n",
      "Epoch 14: Train Loss = 0.06074829407480379, Recall = 0.993046357615894, Aging Rate = 0.5109271523178808, Precision = 0.9718081659105638, f1 = 0.9823124795283328\n",
      "Epoch 15: Train Loss = 0.05600201903984247, Recall = 0.9943708609271523, Aging Rate = 0.5109271523178808, Precision = 0.9731043421905379, f1 = 0.9836226662299378\n",
      "Test Loss = 0.04985450467477176, Recall = 0.9970198675496689, Aging Rate = 0.5102649006622516, precision = 0.9769630110317975\n",
      "Model in epoch 15 is saved.\n",
      "\n",
      "Epoch 16: Train Loss = 0.050770737393605, Recall = 0.9950331125827815, Aging Rate = 0.509271523178808, Precision = 0.9769180754226268, f1 = 0.9858923884514436\n",
      "Epoch 17: Train Loss = 0.04646461041557868, Recall = 0.9953642384105961, Aging Rate = 0.5082781456953642, Precision = 0.9791530944625407, f1 = 0.987192118226601\n",
      "Epoch 18: Train Loss = 0.042562630353187095, Recall = 0.9966887417218543, Aging Rate = 0.5079470198675496, Precision = 0.9810951760104303, f1 = 0.9888304862023654\n",
      "Epoch 19: Train Loss = 0.03994658080157855, Recall = 0.9973509933774835, Aging Rate = 0.5089403973509934, Precision = 0.9798308392973325, f1 = 0.9885132917623892\n",
      "Epoch 20: Train Loss = 0.03690788967793943, Recall = 0.9980132450331126, Aging Rate = 0.5076158940397351, Precision = 0.9830397912589693, f1 = 0.9904699309891555\n",
      "Test Loss = 0.032333266123241146, Recall = 0.9973509933774835, Aging Rate = 0.5059602649006623, precision = 0.9856020942408377\n",
      "Model in epoch 20 is saved.\n",
      "\n",
      "Epoch 21: Train Loss = 0.033741669090378366, Recall = 0.9973509933774835, Aging Rate = 0.5062913907284768, Precision = 0.9849574885546108, f1 = 0.9911154985192497\n",
      "Epoch 22: Train Loss = 0.03158800759358912, Recall = 0.9980132450331126, Aging Rate = 0.5057947019867549, Precision = 0.9865793780687397, f1 = 0.9922633744855966\n",
      "Epoch 23: Train Loss = 0.030547918233749093, Recall = 0.9980132450331126, Aging Rate = 0.5057947019867549, Precision = 0.9865793780687397, f1 = 0.9922633744855966\n",
      "Epoch 24: Train Loss = 0.027933176545216546, Recall = 0.997682119205298, Aging Rate = 0.5051324503311259, Precision = 0.9875450671910849, f1 = 0.9925877120737936\n",
      "Epoch 25: Train Loss = 0.025761152103247233, Recall = 0.9986754966887417, Aging Rate = 0.5054635761589404, Precision = 0.987880773010154, f1 = 0.9932488061913387\n",
      "Test Loss = 0.02254303986860427, Recall = 0.9993377483443708, Aging Rate = 0.5048013245033113, precision = 0.9898327320432929\n",
      "Model in epoch 25 is saved.\n",
      "\n",
      "Epoch 26: Train Loss = 0.023750778832256993, Recall = 0.9993377483443708, Aging Rate = 0.5048013245033113, Precision = 0.9898327320432929, f1 = 0.9945625308947108\n",
      "Epoch 27: Train Loss = 0.02291845614028885, Recall = 0.9990066225165563, Aging Rate = 0.5044701986754967, Precision = 0.9901542500820479, f1 = 0.9945607384209659\n",
      "Epoch 28: Train Loss = 0.021188002676758546, Recall = 0.9993377483443708, Aging Rate = 0.5041390728476821, Precision = 0.9911330049261083, f1 = 0.9952184666117065\n",
      "Epoch 29: Train Loss = 0.01969356100438841, Recall = 0.9996688741721854, Aging Rate = 0.5043046357615895, Precision = 0.9911359159553513, f1 = 0.9953841081437521\n",
      "Epoch 30: Train Loss = 0.01868213301660209, Recall = 0.9993377483443708, Aging Rate = 0.5033112582781457, Precision = 0.9927631578947368, f1 = 0.996039603960396\n",
      "Test Loss = 0.01634449338824149, Recall = 1.0, Aging Rate = 0.5033112582781457, precision = 0.993421052631579\n",
      "Model in epoch 30 is saved.\n",
      "\n",
      "Epoch 31: Train Loss = 0.017508643613943203, Recall = 0.9990066225165563, Aging Rate = 0.5033112582781457, Precision = 0.9924342105263158, f1 = 0.9957095709570958\n",
      "Epoch 32: Train Loss = 0.016317930664645125, Recall = 0.9996688741721854, Aging Rate = 0.5026490066225165, Precision = 0.9944005270092227, f1 = 0.9970277410832232\n",
      "Epoch 33: Train Loss = 0.016005311715755834, Recall = 0.9993377483443708, Aging Rate = 0.503476821192053, Precision = 0.9924366984544558, f1 = 0.995875268107573\n",
      "Epoch 34: Train Loss = 0.01466345570623776, Recall = 0.9996688741721854, Aging Rate = 0.5029801324503311, Precision = 0.9937458854509545, f1 = 0.9966985803895675\n",
      "Epoch 35: Train Loss = 0.014379729709236433, Recall = 0.9996688741721854, Aging Rate = 0.5028145695364239, Precision = 0.9940730984524202, f1 = 0.9968631335644709\n",
      "Test Loss = 0.012253816867407584, Recall = 1.0, Aging Rate = 0.5019867549668874, precision = 0.996042216358839\n",
      "Model in epoch 35 is saved.\n",
      "\n",
      "Epoch 36: Train Loss = 0.013256558497121792, Recall = 1.0, Aging Rate = 0.5026490066225165, Precision = 0.994729907773386, f1 = 0.9973579920739762\n",
      "Epoch 37: Train Loss = 0.012834761198610068, Recall = 0.9993377483443708, Aging Rate = 0.501158940397351, Precision = 0.9970267591674926, f1 = 0.998180916156772\n",
      "Epoch 38: Train Loss = 0.012255199965311596, Recall = 0.9996688741721854, Aging Rate = 0.5018211920529801, Precision = 0.9960409105905642, f1 = 0.9978515947777227\n",
      "Epoch 39: Train Loss = 0.011702789033189515, Recall = 0.9993377483443708, Aging Rate = 0.5019867549668874, Precision = 0.9953825857519789, f1 = 0.9973562458691342\n",
      "Epoch 40: Train Loss = 0.01194668620060019, Recall = 0.9996688741721854, Aging Rate = 0.5021523178807947, Precision = 0.9953841081437521, f1 = 0.9975218899719147\n",
      "Test Loss = 0.013472364390799345, Recall = 1.0, Aging Rate = 0.5051324503311259, precision = 0.989839396919043\n",
      "\n",
      "Epoch 41: Train Loss = 0.011325663546507327, Recall = 0.9996688741721854, Aging Rate = 0.5016556291390728, Precision = 0.9963696369636964, f1 = 0.9980165289256199\n",
      "Epoch 42: Train Loss = 0.009771247821804507, Recall = 1.0, Aging Rate = 0.5013245033112583, Precision = 0.9973579920739762, f1 = 0.9986772486772486\n",
      "Epoch 43: Train Loss = 0.00954730317292624, Recall = 0.9993377483443708, Aging Rate = 0.501158940397351, Precision = 0.9970267591674926, f1 = 0.998180916156772\n",
      "Epoch 44: Train Loss = 0.009755040047727278, Recall = 1.0, Aging Rate = 0.501158940397351, Precision = 0.9976874793524942, f1 = 0.9988424011906731\n",
      "Epoch 45: Train Loss = 0.009045700477019865, Recall = 0.9996688741721854, Aging Rate = 0.5014900662251656, Precision = 0.9966985803895675, f1 = 0.9981815176062159\n",
      "Test Loss = 0.007585105077912476, Recall = 1.0, Aging Rate = 0.5008278145695364, precision = 0.9983471074380166\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model in epoch 45 is saved.\n",
      "\n",
      "Epoch 46: Train Loss = 0.008395806427378923, Recall = 0.9996688741721854, Aging Rate = 0.5009933774834437, Precision = 0.9976867151354925, f1 = 0.9986768111147866\n",
      "Epoch 47: Train Loss = 0.00816774002849957, Recall = 0.9996688741721854, Aging Rate = 0.5004966887417218, Precision = 0.9986768111147867, f1 = 0.9991725963925203\n",
      "Epoch 48: Train Loss = 0.008430515481344122, Recall = 0.9993377483443708, Aging Rate = 0.5003311258278146, Precision = 0.99867637326274, f1 = 0.9990069513406157\n",
      "Epoch 49: Train Loss = 0.007744339779512771, Recall = 0.9996688741721854, Aging Rate = 0.5009933774834437, Precision = 0.9976867151354925, f1 = 0.9986768111147866\n",
      "Epoch 50: Train Loss = 0.007461471603998285, Recall = 0.9996688741721854, Aging Rate = 0.5008278145695364, Precision = 0.9980165289256199, f1 = 0.9988420181968569\n",
      "Test Loss = 0.007247762026771015, Recall = 0.9996688741721854, Aging Rate = 0.5, precision = 0.9996688741721854\n",
      "Model in epoch 50 is saved.\n",
      "\n",
      "Epoch 51: Train Loss = 0.007004098270384484, Recall = 0.9996688741721854, Aging Rate = 0.5004966887417218, Precision = 0.9986768111147867, f1 = 0.9991725963925203\n",
      "Epoch 52: Train Loss = 0.006626749337829699, Recall = 1.0, Aging Rate = 0.5008278145695364, Precision = 0.9983471074380166, f1 = 0.9991728701406121\n",
      "Epoch 53: Train Loss = 0.0068946778555308156, Recall = 0.9993377483443708, Aging Rate = 0.5001655629139072, Precision = 0.9990069513406157, f1 = 0.9991723224631683\n",
      "Epoch 54: Train Loss = 0.006814765961014277, Recall = 1.0, Aging Rate = 0.5009933774834437, Precision = 0.9980171844018506, f1 = 0.9990076083360899\n",
      "Epoch 55: Train Loss = 0.006252552929722908, Recall = 0.9996688741721854, Aging Rate = 0.5006622516556292, Precision = 0.9983465608465608, f1 = 0.999007279947055\n",
      "Test Loss = 0.005367547481487326, Recall = 1.0, Aging Rate = 0.5001655629139072, precision = 0.9996689837802052\n",
      "Model in epoch 55 is saved.\n",
      "\n",
      "Epoch 56: Train Loss = 0.00580327553545057, Recall = 1.0, Aging Rate = 0.5003311258278146, Precision = 0.99933818663137, f1 = 0.9996689837802052\n",
      "Epoch 57: Train Loss = 0.005938701977990321, Recall = 1.0, Aging Rate = 0.5008278145695364, Precision = 0.9983471074380166, f1 = 0.9991728701406121\n",
      "Epoch 58: Train Loss = 0.0059044618141029445, Recall = 1.0, Aging Rate = 0.5006622516556292, Precision = 0.9986772486772487, f1 = 0.99933818663137\n",
      "Epoch 59: Train Loss = 0.005609599595568729, Recall = 1.0, Aging Rate = 0.5003311258278146, Precision = 0.99933818663137, f1 = 0.9996689837802052\n",
      "Epoch 60: Train Loss = 0.005256069927716887, Recall = 1.0, Aging Rate = 0.5003311258278146, Precision = 0.99933818663137, f1 = 0.9996689837802052\n",
      "Test Loss = 0.004646184556926323, Recall = 1.0, Aging Rate = 0.5004966887417218, precision = 0.9990076083360899\n",
      "\n",
      "Epoch 61: Train Loss = 0.005450782322460501, Recall = 1.0, Aging Rate = 0.5003311258278146, Precision = 0.99933818663137, f1 = 0.9996689837802052\n",
      "Epoch 62: Train Loss = 0.00517440860141192, Recall = 1.0, Aging Rate = 0.5006622516556292, Precision = 0.9986772486772487, f1 = 0.99933818663137\n",
      "Epoch 63: Train Loss = 0.005041597580339834, Recall = 1.0, Aging Rate = 0.5008278145695364, Precision = 0.9983471074380166, f1 = 0.9991728701406121\n",
      "Epoch 64: Train Loss = 0.005296561628925485, Recall = 0.9996688741721854, Aging Rate = 0.5001655629139072, Precision = 0.9993379675604105, f1 = 0.9995033934779011\n",
      "Epoch 65: Train Loss = 0.004654600624525488, Recall = 1.0, Aging Rate = 0.5003311258278146, Precision = 0.99933818663137, f1 = 0.9996689837802052\n",
      "Test Loss = 0.004268669031116347, Recall = 1.0, Aging Rate = 0.5001655629139072, precision = 0.9996689837802052\n",
      "\n",
      "Epoch 66: Train Loss = 0.004844071048570932, Recall = 1.0, Aging Rate = 0.5004966887417218, Precision = 0.9990076083360899, f1 = 0.9995035578355121\n",
      "Epoch 67: Train Loss = 0.004522990879436202, Recall = 1.0, Aging Rate = 0.5001655629139072, Precision = 0.9996689837802052, f1 = 0.9998344644926337\n",
      "Epoch 68: Train Loss = 0.004812556961612985, Recall = 1.0, Aging Rate = 0.5006622516556292, Precision = 0.9986772486772487, f1 = 0.99933818663137\n",
      "Epoch 69: Train Loss = 0.004451462373273163, Recall = 1.0, Aging Rate = 0.5003311258278146, Precision = 0.99933818663137, f1 = 0.9996689837802052\n",
      "Epoch 70: Train Loss = 0.004232642903233206, Recall = 1.0, Aging Rate = 0.5001655629139072, Precision = 0.9996689837802052, f1 = 0.9998344644926337\n",
      "Test Loss = 0.0037031318354019465, Recall = 1.0, Aging Rate = 0.5001655629139072, precision = 0.9996689837802052\n",
      "\n",
      "Epoch 71: Train Loss = 0.004480737419984001, Recall = 1.0, Aging Rate = 0.5003311258278146, Precision = 0.99933818663137, f1 = 0.9996689837802052\n",
      "Epoch 72: Train Loss = 0.00419215683066687, Recall = 1.0, Aging Rate = 0.5004966887417218, Precision = 0.9990076083360899, f1 = 0.9995035578355121\n",
      "Epoch 73: Train Loss = 0.00402582862139957, Recall = 1.0, Aging Rate = 0.5001655629139072, Precision = 0.9996689837802052, f1 = 0.9998344644926337\n",
      "Epoch 74: Train Loss = 0.003984350871467432, Recall = 1.0, Aging Rate = 0.5004966887417218, Precision = 0.9990076083360899, f1 = 0.9995035578355121\n",
      "Epoch 75: Train Loss = 0.004167138158948167, Recall = 1.0, Aging Rate = 0.5004966887417218, Precision = 0.9990076083360899, f1 = 0.9995035578355121\n",
      "Test Loss = 0.0037836928333815755, Recall = 1.0, Aging Rate = 0.5001655629139072, precision = 0.9996689837802052\n",
      "\n",
      "Epoch 76: Train Loss = 0.004246630144015645, Recall = 1.0, Aging Rate = 0.5003311258278146, Precision = 0.99933818663137, f1 = 0.9996689837802052\n",
      "Epoch 77: Train Loss = 0.0037591658976693816, Recall = 1.0, Aging Rate = 0.5003311258278146, Precision = 0.99933818663137, f1 = 0.9996689837802052\n",
      "Epoch 78: Train Loss = 0.003776385849156719, Recall = 1.0, Aging Rate = 0.5001655629139072, Precision = 0.9996689837802052, f1 = 0.9998344644926337\n",
      "Epoch 79: Train Loss = 0.0036855569026056703, Recall = 1.0, Aging Rate = 0.5003311258278146, Precision = 0.99933818663137, f1 = 0.9996689837802052\n",
      "Epoch 80: Train Loss = 0.004233655776976552, Recall = 0.9996688741721854, Aging Rate = 0.5004966887417218, Precision = 0.9986768111147867, f1 = 0.9991725963925203\n",
      "Test Loss = 0.003570704951277928, Recall = 1.0, Aging Rate = 0.5001655629139072, precision = 0.9996689837802052\n",
      "\n",
      "Epoch 81: Train Loss = 0.003861482109603108, Recall = 1.0, Aging Rate = 0.5004966887417218, Precision = 0.9990076083360899, f1 = 0.9995035578355121\n",
      "Epoch 82: Train Loss = 0.0038097220324966687, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 83: Train Loss = 0.0035774296101811803, Recall = 1.0, Aging Rate = 0.5001655629139072, Precision = 0.9996689837802052, f1 = 0.9998344644926337\n",
      "Epoch 84: Train Loss = 0.0035012660797882752, Recall = 1.0, Aging Rate = 0.5001655629139072, Precision = 0.9996689837802052, f1 = 0.9998344644926337\n",
      "Epoch 85: Train Loss = 0.0035313230032557683, Recall = 1.0, Aging Rate = 0.5001655629139072, Precision = 0.9996689837802052, f1 = 0.9998344644926337\n",
      "Test Loss = 0.0029842462827025956, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "Model in epoch 85 is saved.\n",
      "\n",
      "Epoch 86: Train Loss = 0.0034957667502778155, Recall = 1.0, Aging Rate = 0.5001655629139072, Precision = 0.9996689837802052, f1 = 0.9998344644926337\n",
      "Epoch 87: Train Loss = 0.003623389598561932, Recall = 1.0, Aging Rate = 0.5003311258278146, Precision = 0.99933818663137, f1 = 0.9996689837802052\n",
      "Epoch 88: Train Loss = 0.003781445814136243, Recall = 1.0, Aging Rate = 0.5001655629139072, Precision = 0.9996689837802052, f1 = 0.9998344644926337\n",
      "Epoch 89: Train Loss = 0.0035891401177481903, Recall = 1.0, Aging Rate = 0.5004966887417218, Precision = 0.9990076083360899, f1 = 0.9995035578355121\n",
      "Epoch 90: Train Loss = 0.0033129598738761337, Recall = 1.0, Aging Rate = 0.5001655629139072, Precision = 0.9996689837802052, f1 = 0.9998344644926337\n",
      "Test Loss = 0.0027624997810695, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 91: Train Loss = 0.0036429337154925854, Recall = 1.0, Aging Rate = 0.5001655629139072, Precision = 0.9996689837802052, f1 = 0.9998344644926337\n",
      "Epoch 92: Train Loss = 0.003427713599968825, Recall = 1.0, Aging Rate = 0.5001655629139072, Precision = 0.9996689837802052, f1 = 0.9998344644926337\n",
      "Epoch 93: Train Loss = 0.0034139307983688367, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 94: Train Loss = 0.003175423367778518, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 95: Train Loss = 0.004100359310025953, Recall = 0.9996688741721854, Aging Rate = 0.5004966887417218, Precision = 0.9986768111147867, f1 = 0.9991725963925203\n",
      "Test Loss = 0.0032613074473284236, Recall = 1.0, Aging Rate = 0.5004966887417218, precision = 0.9990076083360899\n",
      "\n",
      "Epoch 96: Train Loss = 0.0037596120452816715, Recall = 1.0, Aging Rate = 0.5004966887417218, Precision = 0.9990076083360899, f1 = 0.9995035578355121\n",
      "Epoch 97: Train Loss = 0.0030866935982566254, Recall = 1.0, Aging Rate = 0.5003311258278146, Precision = 0.99933818663137, f1 = 0.9996689837802052\n",
      "Epoch 98: Train Loss = 0.0030304526495408043, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 99: Train Loss = 0.0032818143336188713, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 100: Train Loss = 0.0031607890880931883, Recall = 1.0, Aging Rate = 0.5003311258278146, Precision = 0.99933818663137, f1 = 0.9996689837802052\n",
      "Test Loss = 0.0033407811908088376, Recall = 1.0, Aging Rate = 0.5003311258278146, precision = 0.99933818663137\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bece1e1cd2144f099cf719aadab92248",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss = 0.5713769287068323, Recall = 0.9556291390728476, Aging Rate = 0.9337748344370861, Precision = 0.5117021276595745, f1 = 0.6665127020785219\n",
      "Epoch 2: Train Loss = 0.4057560383878796, Recall = 0.9506622516556291, Aging Rate = 0.7119205298013245, Precision = 0.6676744186046512, f1 = 0.7844262295081966\n",
      "Epoch 3: Train Loss = 0.32942228483048497, Recall = 0.9440397350993377, Aging Rate = 0.6301324503311259, Precision = 0.7490803993694167, f1 = 0.8353354819806622\n",
      "Epoch 4: Train Loss = 0.28149157454635926, Recall = 0.9519867549668874, Aging Rate = 0.5995033112582782, Precision = 0.7939795636564485, f1 = 0.8658334588164434\n",
      "Epoch 5: Train Loss = 0.24203954196923616, Recall = 0.9602649006622517, Aging Rate = 0.5824503311258278, Precision = 0.824332006822058, f1 = 0.887121443866626\n",
      "Test Loss = 0.20841454368158682, Recall = 0.9685430463576159, Aging Rate = 0.5670529801324503, precision = 0.8540145985401459\n",
      "Model in epoch 5 is saved.\n",
      "\n",
      "Epoch 6: Train Loss = 0.19669287311320274, Recall = 0.9672185430463576, Aging Rate = 0.5605960264900662, Precision = 0.8626698168930892, f1 = 0.9119575398064315\n",
      "Epoch 7: Train Loss = 0.16394101539194977, Recall = 0.9731788079470198, Aging Rate = 0.5440397350993378, Precision = 0.8944004869141814, f1 = 0.932128131937837\n",
      "Epoch 8: Train Loss = 0.141266853150153, Recall = 0.9791390728476821, Aging Rate = 0.5370860927152318, Precision = 0.9115289765721332, f1 = 0.9441251596424011\n",
      "Epoch 9: Train Loss = 0.12153544293728885, Recall = 0.9814569536423841, Aging Rate = 0.5304635761589404, Precision = 0.9250936329588015, f1 = 0.9524421593830334\n",
      "Epoch 10: Train Loss = 0.10646697301047527, Recall = 0.9854304635761589, Aging Rate = 0.5259933774834437, Precision = 0.9367327667610954, f1 = 0.9604647410037115\n",
      "Test Loss = 0.0964563291791259, Recall = 0.9821192052980132, Aging Rate = 0.5124172185430463, precision = 0.9583198707592891\n",
      "Model in epoch 10 is saved.\n",
      "\n",
      "Epoch 11: Train Loss = 0.0940320461988449, Recall = 0.9867549668874173, Aging Rate = 0.5210264900662251, Precision = 0.9469335875436924, f1 = 0.9664342467974705\n",
      "Epoch 12: Train Loss = 0.08357392676816082, Recall = 0.9890728476821192, Aging Rate = 0.5173841059602649, Precision = 0.95584, f1 = 0.9721724979658259\n",
      "Epoch 13: Train Loss = 0.07487855426325703, Recall = 0.9903973509933774, Aging Rate = 0.5160596026490066, Precision = 0.9595765158806545, f1 = 0.9747433599478572\n",
      "Epoch 14: Train Loss = 0.0680958885033399, Recall = 0.9910596026490066, Aging Rate = 0.5139072847682119, Precision = 0.9642396907216495, f1 = 0.9774657086871326\n",
      "Epoch 15: Train Loss = 0.06137715865247297, Recall = 0.9927152317880795, Aging Rate = 0.5110927152317881, Precision = 0.971169420149012, f1 = 0.981824136237105\n",
      "Test Loss = 0.05652939789737297, Recall = 0.9947019867549669, Aging Rate = 0.5125827814569537, precision = 0.9702842377260982\n",
      "Model in epoch 15 is saved.\n",
      "\n",
      "Epoch 16: Train Loss = 0.05718878063539796, Recall = 0.993046357615894, Aging Rate = 0.5107615894039735, Precision = 0.9721231766612641, f1 = 0.9824733824733825\n",
      "Epoch 17: Train Loss = 0.051956124223818054, Recall = 0.993046357615894, Aging Rate = 0.5094370860927152, Precision = 0.9746506337341566, f1 = 0.9837625061505658\n",
      "Epoch 18: Train Loss = 0.04796642376887088, Recall = 0.9947019867549669, Aging Rate = 0.5089403973509934, Precision = 0.9772283669486012, f1 = 0.9858877584509352\n",
      "Epoch 19: Train Loss = 0.04362228177611204, Recall = 0.9963576158940397, Aging Rate = 0.5091059602649006, Precision = 0.9785365853658536, f1 = 0.9873666940114848\n",
      "Epoch 20: Train Loss = 0.04102513366779744, Recall = 0.9963576158940397, Aging Rate = 0.5086092715231788, Precision = 0.9794921875, f1 = 0.9878529218647406\n",
      "Test Loss = 0.04068360290927998, Recall = 0.9993377483443708, Aging Rate = 0.5144039735099337, precision = 0.9713550048278081\n",
      "Model in epoch 20 is saved.\n",
      "\n",
      "Epoch 21: Train Loss = 0.03810952887037732, Recall = 0.997682119205298, Aging Rate = 0.5089403973509934, Precision = 0.9801561483409239, f1 = 0.988841483426321\n",
      "Epoch 22: Train Loss = 0.03554195061029977, Recall = 0.9970198675496689, Aging Rate = 0.5074503311258278, Precision = 0.9823817292006525, f1 = 0.9896466721446179\n",
      "Epoch 23: Train Loss = 0.03328566641997028, Recall = 0.997682119205298, Aging Rate = 0.5067880794701987, Precision = 0.9843188500490035, f1 = 0.9909554349613551\n",
      "Epoch 24: Train Loss = 0.030772595741594865, Recall = 0.9983443708609272, Aging Rate = 0.5071192052980132, Precision = 0.9843290891283056, f1 = 0.9912871938188395\n",
      "Epoch 25: Train Loss = 0.02894426827004414, Recall = 0.997682119205298, Aging Rate = 0.5048013245033113, Precision = 0.9881928501147917, f1 = 0.9929148129840171\n",
      "Test Loss = 0.02593243546006794, Recall = 0.9996688741721854, Aging Rate = 0.5064569536423841, precision = 0.986923831317424\n",
      "Model in epoch 25 is saved.\n",
      "\n",
      "Epoch 26: Train Loss = 0.027459872893939745, Recall = 0.9983443708609272, Aging Rate = 0.5048013245033113, Precision = 0.9888488028861921, f1 = 0.9935739001482946\n",
      "Epoch 27: Train Loss = 0.02618223860773523, Recall = 0.9973509933774835, Aging Rate = 0.5052980132450331, Precision = 0.9868938401048493, f1 = 0.992094861660079\n",
      "Epoch 28: Train Loss = 0.02397986272263606, Recall = 0.9986754966887417, Aging Rate = 0.5046357615894039, Precision = 0.989501312335958, f1 = 0.9940672379696769\n",
      "Epoch 29: Train Loss = 0.02240661894594202, Recall = 0.9993377483443708, Aging Rate = 0.5048013245033113, Precision = 0.9898327320432929, f1 = 0.9945625308947108\n",
      "Epoch 30: Train Loss = 0.021320967490951352, Recall = 0.9990066225165563, Aging Rate = 0.503476821192053, Precision = 0.9921078592568234, f1 = 0.9955452895561789\n",
      "Test Loss = 0.018743458202737845, Recall = 0.9996688741721854, Aging Rate = 0.503476821192053, precision = 0.9927655376520881\n",
      "Model in epoch 30 is saved.\n",
      "\n",
      "Epoch 31: Train Loss = 0.020185348355760243, Recall = 0.9996688741721854, Aging Rate = 0.5041390728476821, Precision = 0.9914614121510673, f1 = 0.9955482275350371\n",
      "Epoch 32: Train Loss = 0.018813779441923494, Recall = 1.0, Aging Rate = 0.503476821192053, Precision = 0.9930943768497205, f1 = 0.9965352252103613\n",
      "Epoch 33: Train Loss = 0.01789622770017938, Recall = 0.9993377483443708, Aging Rate = 0.5031456953642384, Precision = 0.9930898321816387, f1 = 0.9962039940584255\n",
      "Epoch 34: Train Loss = 0.017300489782324888, Recall = 0.9986754966887417, Aging Rate = 0.5024834437086093, Precision = 0.9937397034596376, f1 = 0.9962014863748967\n",
      "Epoch 35: Train Loss = 0.017177650479242107, Recall = 0.9996688741721854, Aging Rate = 0.5029801324503311, Precision = 0.9937458854509545, f1 = 0.9966985803895675\n",
      "Test Loss = 0.016496074166370937, Recall = 1.0, Aging Rate = 0.5048013245033113, precision = 0.9904886848146933\n",
      "\n",
      "Epoch 36: Train Loss = 0.015834657433411933, Recall = 0.9993377483443708, Aging Rate = 0.5024834437086093, Precision = 0.9943986820428337, f1 = 0.9968620974401321\n",
      "Epoch 37: Train Loss = 0.0146162064894047, Recall = 0.9993377483443708, Aging Rate = 0.5024834437086093, Precision = 0.9943986820428337, f1 = 0.9968620974401321\n",
      "Epoch 38: Train Loss = 0.015097363951264431, Recall = 0.9990066225165563, Aging Rate = 0.5016556291390728, Precision = 0.9957095709570957, f1 = 0.9973553719008265\n",
      "Epoch 39: Train Loss = 0.014001768403100651, Recall = 0.9996688741721854, Aging Rate = 0.5026490066225165, Precision = 0.9944005270092227, f1 = 0.9970277410832232\n",
      "Epoch 40: Train Loss = 0.013508479154995636, Recall = 0.9990066225165563, Aging Rate = 0.5019867549668874, Precision = 0.9950527704485488, f1 = 0.9970257766027759\n",
      "Test Loss = 0.011281008473813336, Recall = 1.0, Aging Rate = 0.5019867549668874, precision = 0.996042216358839\n",
      "Model in epoch 40 is saved.\n",
      "\n",
      "Epoch 41: Train Loss = 0.012371677062196645, Recall = 0.9996688741721854, Aging Rate = 0.5019867549668874, Precision = 0.9957124010554089, f1 = 0.9976867151354923\n",
      "Epoch 42: Train Loss = 0.011647963415313241, Recall = 0.9996688741721854, Aging Rate = 0.5018211920529801, Precision = 0.9960409105905642, f1 = 0.9978515947777227\n",
      "Epoch 43: Train Loss = 0.011600072733712512, Recall = 0.9993377483443708, Aging Rate = 0.5014900662251656, Precision = 0.9963684384285243, f1 = 0.9978508844437097\n",
      "Epoch 44: Train Loss = 0.01113954781005714, Recall = 0.9996688741721854, Aging Rate = 0.5019867549668874, Precision = 0.9957124010554089, f1 = 0.9976867151354923\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45: Train Loss = 0.010727650008552912, Recall = 0.9996688741721854, Aging Rate = 0.5021523178807947, Precision = 0.9953841081437521, f1 = 0.9975218899719147\n",
      "Test Loss = 0.009137275864351663, Recall = 0.9996688741721854, Aging Rate = 0.5009933774834437, precision = 0.9976867151354925\n",
      "Model in epoch 45 is saved.\n",
      "\n",
      "Epoch 46: Train Loss = 0.010145265819961266, Recall = 0.9996688741721854, Aging Rate = 0.5016556291390728, Precision = 0.9963696369636964, f1 = 0.9980165289256199\n",
      "Epoch 47: Train Loss = 0.010109531250011348, Recall = 0.9993377483443708, Aging Rate = 0.5013245033112583, Precision = 0.9966974900924703, f1 = 0.998015873015873\n",
      "Epoch 48: Train Loss = 0.009556139205946335, Recall = 0.9993377483443708, Aging Rate = 0.501158940397351, Precision = 0.9970267591674926, f1 = 0.998180916156772\n",
      "Epoch 49: Train Loss = 0.009271858499342242, Recall = 0.9993377483443708, Aging Rate = 0.5013245033112583, Precision = 0.9966974900924703, f1 = 0.998015873015873\n",
      "Epoch 50: Train Loss = 0.00933327043879259, Recall = 1.0, Aging Rate = 0.5014900662251656, Precision = 0.9970287223506108, f1 = 0.9985121507687221\n",
      "Test Loss = 0.008211977895818009, Recall = 1.0, Aging Rate = 0.5014900662251656, precision = 0.9970287223506108\n",
      "\n",
      "Epoch 51: Train Loss = 0.0086430181422277, Recall = 0.9996688741721854, Aging Rate = 0.5014900662251656, Precision = 0.9966985803895675, f1 = 0.9981815176062159\n",
      "Epoch 52: Train Loss = 0.008392730672282493, Recall = 1.0, Aging Rate = 0.501158940397351, Precision = 0.9976874793524942, f1 = 0.9988424011906731\n",
      "Epoch 53: Train Loss = 0.008503966766181372, Recall = 0.9996688741721854, Aging Rate = 0.501158940397351, Precision = 0.9973571192599934, f1 = 0.9985116586737225\n",
      "Epoch 54: Train Loss = 0.008225475949858198, Recall = 1.0, Aging Rate = 0.5014900662251656, Precision = 0.9970287223506108, f1 = 0.9985121507687221\n",
      "Epoch 55: Train Loss = 0.008279348648652828, Recall = 0.9990066225165563, Aging Rate = 0.5008278145695364, Precision = 0.9973553719008265, f1 = 0.9981803143093465\n",
      "Test Loss = 0.0068560772353400854, Recall = 1.0, Aging Rate = 0.5009933774834437, precision = 0.9980171844018506\n",
      "Model in epoch 55 is saved.\n",
      "\n",
      "Epoch 56: Train Loss = 0.007660336275615834, Recall = 0.9996688741721854, Aging Rate = 0.5013245033112583, Precision = 0.9970277410832232, f1 = 0.9983465608465608\n",
      "Epoch 57: Train Loss = 0.007203849224953462, Recall = 0.9996688741721854, Aging Rate = 0.501158940397351, Precision = 0.9973571192599934, f1 = 0.9985116586737225\n",
      "Epoch 58: Train Loss = 0.007519693279774576, Recall = 1.0, Aging Rate = 0.501158940397351, Precision = 0.9976874793524942, f1 = 0.9988424011906731\n",
      "Epoch 59: Train Loss = 0.00703618795123716, Recall = 0.9996688741721854, Aging Rate = 0.5006622516556292, Precision = 0.9983465608465608, f1 = 0.999007279947055\n",
      "Epoch 60: Train Loss = 0.00646351623651109, Recall = 1.0, Aging Rate = 0.5009933774834437, Precision = 0.9980171844018506, f1 = 0.9990076083360899\n",
      "Test Loss = 0.0061591517124695095, Recall = 0.9993377483443708, Aging Rate = 0.5003311258278146, precision = 0.99867637326274\n",
      "Model in epoch 60 is saved.\n",
      "\n",
      "Epoch 61: Train Loss = 0.006653573919729089, Recall = 0.9993377483443708, Aging Rate = 0.5004966887417218, Precision = 0.9983460138934833, f1 = 0.9988416349495285\n",
      "Epoch 62: Train Loss = 0.006478511359517937, Recall = 0.9996688741721854, Aging Rate = 0.5009933774834437, Precision = 0.9976867151354925, f1 = 0.9986768111147866\n",
      "Epoch 63: Train Loss = 0.0062009800928614, Recall = 1.0, Aging Rate = 0.501158940397351, Precision = 0.9976874793524942, f1 = 0.9988424011906731\n",
      "Epoch 64: Train Loss = 0.006452048199547344, Recall = 0.9993377483443708, Aging Rate = 0.5006622516556292, Precision = 0.998015873015873, f1 = 0.99867637326274\n",
      "Epoch 65: Train Loss = 0.0062701556091474386, Recall = 0.9993377483443708, Aging Rate = 0.5004966887417218, Precision = 0.9983460138934833, f1 = 0.9988416349495285\n",
      "Test Loss = 0.005062962370918484, Recall = 1.0, Aging Rate = 0.501158940397351, precision = 0.9976874793524942\n",
      "\n",
      "Epoch 66: Train Loss = 0.0058921335080009424, Recall = 0.9996688741721854, Aging Rate = 0.5008278145695364, Precision = 0.9980165289256199, f1 = 0.9988420181968569\n",
      "Epoch 67: Train Loss = 0.005792112277191601, Recall = 0.9996688741721854, Aging Rate = 0.5004966887417218, Precision = 0.9986768111147867, f1 = 0.9991725963925203\n",
      "Epoch 68: Train Loss = 0.006369826484730603, Recall = 0.9993377483443708, Aging Rate = 0.5006622516556292, Precision = 0.998015873015873, f1 = 0.99867637326274\n",
      "Epoch 69: Train Loss = 0.00580235161611946, Recall = 0.9996688741721854, Aging Rate = 0.5008278145695364, Precision = 0.9980165289256199, f1 = 0.9988420181968569\n",
      "Epoch 70: Train Loss = 0.005317688886298249, Recall = 1.0, Aging Rate = 0.5006622516556292, Precision = 0.9986772486772487, f1 = 0.99933818663137\n",
      "Test Loss = 0.00460631861012207, Recall = 0.9996688741721854, Aging Rate = 0.5003311258278146, precision = 0.999007279947055\n",
      "Model in epoch 70 is saved.\n",
      "\n",
      "Epoch 71: Train Loss = 0.005736640384975846, Recall = 1.0, Aging Rate = 0.5006622516556292, Precision = 0.9986772486772487, f1 = 0.99933818663137\n",
      "Epoch 72: Train Loss = 0.005366135330636375, Recall = 0.9996688741721854, Aging Rate = 0.5004966887417218, Precision = 0.9986768111147867, f1 = 0.9991725963925203\n",
      "Epoch 73: Train Loss = 0.005667516753842302, Recall = 0.9996688741721854, Aging Rate = 0.5006622516556292, Precision = 0.9983465608465608, f1 = 0.999007279947055\n",
      "Epoch 74: Train Loss = 0.005470596890995242, Recall = 1.0, Aging Rate = 0.5008278145695364, Precision = 0.9983471074380166, f1 = 0.9991728701406121\n",
      "Epoch 75: Train Loss = 0.005896239828885786, Recall = 0.9996688741721854, Aging Rate = 0.5004966887417218, Precision = 0.9986768111147867, f1 = 0.9991725963925203\n",
      "Test Loss = 0.004314487676031345, Recall = 1.0, Aging Rate = 0.5006622516556292, precision = 0.9986772486772487\n",
      "\n",
      "Epoch 76: Train Loss = 0.0051709250787532095, Recall = 0.9996688741721854, Aging Rate = 0.5008278145695364, Precision = 0.9980165289256199, f1 = 0.9988420181968569\n",
      "Epoch 77: Train Loss = 0.005261578887318637, Recall = 0.9996688741721854, Aging Rate = 0.5006622516556292, Precision = 0.9983465608465608, f1 = 0.999007279947055\n",
      "Epoch 78: Train Loss = 0.005875252250779346, Recall = 0.9993377483443708, Aging Rate = 0.5006622516556292, Precision = 0.998015873015873, f1 = 0.99867637326274\n",
      "Epoch 79: Train Loss = 0.005324025130992607, Recall = 1.0, Aging Rate = 0.5008278145695364, Precision = 0.9983471074380166, f1 = 0.9991728701406121\n",
      "Epoch 80: Train Loss = 0.0045747354965879035, Recall = 0.9996688741721854, Aging Rate = 0.5004966887417218, Precision = 0.9986768111147867, f1 = 0.9991725963925203\n",
      "Test Loss = 0.004213951987565945, Recall = 1.0, Aging Rate = 0.5006622516556292, precision = 0.9986772486772487\n",
      "\n",
      "Epoch 81: Train Loss = 0.004992073488773297, Recall = 1.0, Aging Rate = 0.5008278145695364, Precision = 0.9983471074380166, f1 = 0.9991728701406121\n",
      "Epoch 82: Train Loss = 0.004938644111551196, Recall = 1.0, Aging Rate = 0.5008278145695364, Precision = 0.9983471074380166, f1 = 0.9991728701406121\n",
      "Epoch 83: Train Loss = 0.004582379801223511, Recall = 0.9996688741721854, Aging Rate = 0.5008278145695364, Precision = 0.9980165289256199, f1 = 0.9988420181968569\n",
      "Epoch 84: Train Loss = 0.0044585277301734255, Recall = 0.9996688741721854, Aging Rate = 0.5004966887417218, Precision = 0.9986768111147867, f1 = 0.9991725963925203\n",
      "Epoch 85: Train Loss = 0.004321796916400557, Recall = 0.9996688741721854, Aging Rate = 0.5004966887417218, Precision = 0.9986768111147867, f1 = 0.9991725963925203\n",
      "Test Loss = 0.005165398523476691, Recall = 1.0, Aging Rate = 0.5008278145695364, precision = 0.9983471074380166\n",
      "\n",
      "Epoch 86: Train Loss = 0.005935366020618093, Recall = 0.9996688741721854, Aging Rate = 0.5008278145695364, Precision = 0.9980165289256199, f1 = 0.9988420181968569\n",
      "Epoch 87: Train Loss = 0.0049773836543086595, Recall = 0.9996688741721854, Aging Rate = 0.5006622516556292, Precision = 0.9983465608465608, f1 = 0.999007279947055\n",
      "Epoch 88: Train Loss = 0.005065695010125637, Recall = 0.9993377483443708, Aging Rate = 0.5004966887417218, Precision = 0.9983460138934833, f1 = 0.9988416349495285\n",
      "Epoch 89: Train Loss = 0.004698482561017701, Recall = 0.9996688741721854, Aging Rate = 0.5001655629139072, Precision = 0.9993379675604105, f1 = 0.9995033934779011\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 90: Train Loss = 0.004711175308445629, Recall = 1.0, Aging Rate = 0.5008278145695364, Precision = 0.9983471074380166, f1 = 0.9991728701406121\n",
      "Test Loss = 0.004808993120708607, Recall = 1.0, Aging Rate = 0.5006622516556292, precision = 0.9986772486772487\n",
      "\n",
      "Epoch 91: Train Loss = 0.004531291587006868, Recall = 0.9996688741721854, Aging Rate = 0.5004966887417218, Precision = 0.9986768111147867, f1 = 0.9991725963925203\n",
      "Epoch 92: Train Loss = 0.004350113236100185, Recall = 1.0, Aging Rate = 0.5006622516556292, Precision = 0.9986772486772487, f1 = 0.99933818663137\n",
      "Epoch 93: Train Loss = 0.004398234063969148, Recall = 0.9996688741721854, Aging Rate = 0.5004966887417218, Precision = 0.9986768111147867, f1 = 0.9991725963925203\n",
      "Epoch 94: Train Loss = 0.00480915492728957, Recall = 0.9996688741721854, Aging Rate = 0.5006622516556292, Precision = 0.9983465608465608, f1 = 0.999007279947055\n",
      "Epoch 95: Train Loss = 0.004649800295318594, Recall = 0.9996688741721854, Aging Rate = 0.5004966887417218, Precision = 0.9986768111147867, f1 = 0.9991725963925203\n",
      "Test Loss = 0.005160806866189995, Recall = 0.9993377483443708, Aging Rate = 0.5008278145695364, precision = 0.9976859504132232\n",
      "\n",
      "Epoch 96: Train Loss = 0.005248519757281471, Recall = 0.9996688741721854, Aging Rate = 0.5006622516556292, Precision = 0.9983465608465608, f1 = 0.999007279947055\n",
      "Epoch 97: Train Loss = 0.004568242912630964, Recall = 0.9996688741721854, Aging Rate = 0.5008278145695364, Precision = 0.9980165289256199, f1 = 0.9988420181968569\n",
      "Epoch 98: Train Loss = 0.004071549422397519, Recall = 1.0, Aging Rate = 0.5006622516556292, Precision = 0.9986772486772487, f1 = 0.99933818663137\n",
      "Epoch 99: Train Loss = 0.004523276552459262, Recall = 0.9996688741721854, Aging Rate = 0.5004966887417218, Precision = 0.9986768111147867, f1 = 0.9991725963925203\n",
      "Epoch 100: Train Loss = 0.004367698678463106, Recall = 1.0, Aging Rate = 0.5006622516556292, Precision = 0.9986772486772487, f1 = 0.99933818663137\n",
      "Test Loss = 0.004162680817804984, Recall = 1.0, Aging Rate = 0.5006622516556292, precision = 0.9986772486772487\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f56906bad9d040d98d17d3b524126b6a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss = 0.5665239716207744, Recall = 0.9668874172185431, Aging Rate = 0.9470198675496688, Precision = 0.5104895104895105, f1 = 0.6681922196796339\n",
      "Epoch 2: Train Loss = 0.41033968751793665, Recall = 0.9596026490066225, Aging Rate = 0.7178807947019867, Precision = 0.6683579335793358, f1 = 0.7879282218597063\n",
      "Epoch 3: Train Loss = 0.3311248033646716, Recall = 0.9447019867549669, Aging Rate = 0.6301324503311259, Precision = 0.7496058854440357, f1 = 0.8359214767067097\n",
      "Epoch 4: Train Loss = 0.2814530285383692, Recall = 0.9526490066225165, Aging Rate = 0.5985099337748344, Precision = 0.795850622406639, f1 = 0.8672192916352675\n",
      "Epoch 5: Train Loss = 0.24020178637757206, Recall = 0.9619205298013245, Aging Rate = 0.5817880794701987, Precision = 0.8266932270916335, f1 = 0.889194980104071\n",
      "Test Loss = 0.20255250297240074, Recall = 0.9731788079470198, Aging Rate = 0.5748344370860927, precision = 0.8464861751152074\n",
      "Model in epoch 5 is saved.\n",
      "\n",
      "Epoch 6: Train Loss = 0.18869659699351582, Recall = 0.9675496688741722, Aging Rate = 0.5584437086092715, Precision = 0.8662911354876964, f1 = 0.9141248240262787\n",
      "Epoch 7: Train Loss = 0.15364493998075954, Recall = 0.9771523178807947, Aging Rate = 0.5420529801324503, Precision = 0.9013439218081857, f1 = 0.9377184620273276\n",
      "Epoch 8: Train Loss = 0.1278527461535094, Recall = 0.9801324503311258, Aging Rate = 0.5319536423841059, Precision = 0.9212573918456272, f1 = 0.9497834108775871\n",
      "Epoch 9: Train Loss = 0.10814014399880605, Recall = 0.9834437086092715, Aging Rate = 0.5246688741721854, Precision = 0.937204165351846, f1 = 0.9597673291323316\n",
      "Epoch 10: Train Loss = 0.09425895493354229, Recall = 0.9864238410596027, Aging Rate = 0.5220198675496689, Precision = 0.9448144624167459, f1 = 0.9651709055564556\n",
      "Test Loss = 0.08323450941617126, Recall = 0.9880794701986755, Aging Rate = 0.518046357615894, precision = 0.9536593160754234\n",
      "Model in epoch 10 is saved.\n",
      "\n",
      "Epoch 11: Train Loss = 0.08106003460899884, Recall = 0.9887417218543046, Aging Rate = 0.5173841059602649, Precision = 0.95552, f1 = 0.9718470301057771\n",
      "Epoch 12: Train Loss = 0.07206708370455053, Recall = 0.9897350993377484, Aging Rate = 0.515728476821192, Precision = 0.9595505617977528, f1 = 0.9744091279543603\n",
      "Epoch 13: Train Loss = 0.06422895894984142, Recall = 0.9910596026490066, Aging Rate = 0.5120860927152318, Precision = 0.9676689298415777, f1 = 0.9792246033044332\n",
      "Epoch 14: Train Loss = 0.057112875467301996, Recall = 0.9923841059602649, Aging Rate = 0.509271523178808, Precision = 0.9743172951885566, f1 = 0.9832677165354331\n",
      "Epoch 15: Train Loss = 0.05133485839955065, Recall = 0.9947019867549669, Aging Rate = 0.5077814569536424, Precision = 0.9794587544832083, f1 = 0.987021521274848\n",
      "Test Loss = 0.04540355286949518, Recall = 0.9963576158940397, Aging Rate = 0.5086092715231788, precision = 0.9794921875\n",
      "Model in epoch 15 is saved.\n",
      "\n",
      "Epoch 16: Train Loss = 0.04692303878779443, Recall = 0.9956953642384105, Aging Rate = 0.5086092715231788, Precision = 0.9788411458333334, f1 = 0.9871963230466184\n",
      "Epoch 17: Train Loss = 0.042321998482903106, Recall = 0.9953642384105961, Aging Rate = 0.5066225165562914, Precision = 0.9823529411764705, f1 = 0.9888157894736842\n",
      "Epoch 18: Train Loss = 0.03876537371192448, Recall = 0.9973509933774835, Aging Rate = 0.5062913907284768, Precision = 0.9849574885546108, f1 = 0.9911154985192497\n",
      "Epoch 19: Train Loss = 0.03639885610623273, Recall = 0.9970198675496689, Aging Rate = 0.5072847682119205, Precision = 0.9827023498694517, f1 = 0.9898093359631821\n",
      "Epoch 20: Train Loss = 0.03303791343277653, Recall = 0.9966887417218543, Aging Rate = 0.5043046357615895, Precision = 0.9881812212738017, f1 = 0.992416749093307\n",
      "Test Loss = 0.029319570922841695, Recall = 0.997682119205298, Aging Rate = 0.5039735099337749, precision = 0.9898160315374507\n",
      "Model in epoch 20 is saved.\n",
      "\n",
      "Epoch 21: Train Loss = 0.030400804583205293, Recall = 0.997682119205298, Aging Rate = 0.5054635761589404, Precision = 0.9868981329839502, f1 = 0.9922608266095834\n",
      "Epoch 22: Train Loss = 0.028718693435981574, Recall = 0.9986754966887417, Aging Rate = 0.5039735099337749, Precision = 0.9908015768725361, f1 = 0.9947229551451187\n",
      "Epoch 23: Train Loss = 0.026561678427931487, Recall = 0.9986754966887417, Aging Rate = 0.5051324503311259, Precision = 0.9885283513602098, f1 = 0.9935760171306209\n",
      "Epoch 24: Train Loss = 0.024772962945087858, Recall = 0.9990066225165563, Aging Rate = 0.5043046357615895, Precision = 0.9904793171372291, f1 = 0.9947246950214309\n",
      "Epoch 25: Train Loss = 0.023895619266870005, Recall = 0.9986754966887417, Aging Rate = 0.5038079470198675, Precision = 0.9911271771278344, f1 = 0.9948870196272473\n",
      "Test Loss = 0.020595799933576228, Recall = 1.0, Aging Rate = 0.5031456953642384, precision = 0.993747943402435\n",
      "Model in epoch 25 is saved.\n",
      "\n",
      "Epoch 26: Train Loss = 0.021751237318955903, Recall = 0.9993377483443708, Aging Rate = 0.5031456953642384, Precision = 0.9930898321816387, f1 = 0.9962039940584255\n",
      "Epoch 27: Train Loss = 0.02027475627644962, Recall = 0.9996688741721854, Aging Rate = 0.5036423841059603, Precision = 0.9924391847468771, f1 = 0.9960409105905642\n",
      "Epoch 28: Train Loss = 0.01920915435974961, Recall = 0.9993377483443708, Aging Rate = 0.5031456953642384, Precision = 0.9930898321816387, f1 = 0.9962039940584255\n",
      "Epoch 29: Train Loss = 0.0184696682093554, Recall = 0.9986754966887417, Aging Rate = 0.502317880794702, Precision = 0.994067237969677, f1 = 0.9963660389824909\n",
      "Epoch 30: Train Loss = 0.016990154720102714, Recall = 0.9996688741721854, Aging Rate = 0.5029801324503311, Precision = 0.9937458854509545, f1 = 0.9966985803895675\n",
      "Test Loss = 0.0151338576672241, Recall = 1.0, Aging Rate = 0.5029801324503311, precision = 0.9940750493745886\n",
      "Model in epoch 30 is saved.\n",
      "\n",
      "Epoch 31: Train Loss = 0.01619112749664199, Recall = 0.9996688741721854, Aging Rate = 0.502317880794702, Precision = 0.9950560316413974, f1 = 0.9973571192599933\n",
      "Epoch 32: Train Loss = 0.015952324143160654, Recall = 1.0, Aging Rate = 0.5028145695364239, Precision = 0.994402370760619, f1 = 0.9971933300313686\n",
      "Epoch 33: Train Loss = 0.014877555995488798, Recall = 0.9996688741721854, Aging Rate = 0.5024834437086093, Precision = 0.9947281713344316, f1 = 0.9971924029727498\n",
      "Epoch 34: Train Loss = 0.01379215173509638, Recall = 0.9993377483443708, Aging Rate = 0.5024834437086093, Precision = 0.9943986820428337, f1 = 0.9968620974401321\n",
      "Epoch 35: Train Loss = 0.014113830837933038, Recall = 0.9993377483443708, Aging Rate = 0.5021523178807947, Precision = 0.9950544015825915, f1 = 0.9971914753015033\n",
      "Test Loss = 0.012379810073419123, Recall = 1.0, Aging Rate = 0.5024834437086093, precision = 0.9950576606260296\n",
      "Model in epoch 35 is saved.\n",
      "\n",
      "Epoch 36: Train Loss = 0.012772717277537909, Recall = 1.0, Aging Rate = 0.502317880794702, Precision = 0.995385629531971, f1 = 0.9976874793524942\n",
      "Epoch 37: Train Loss = 0.012090999926656288, Recall = 0.9996688741721854, Aging Rate = 0.5014900662251656, Precision = 0.9966985803895675, f1 = 0.9981815176062159\n",
      "Epoch 38: Train Loss = 0.011587632578853148, Recall = 1.0, Aging Rate = 0.5018211920529801, Precision = 0.9963708347080171, f1 = 0.998182118658073\n",
      "Epoch 39: Train Loss = 0.01131770202754349, Recall = 0.9996688741721854, Aging Rate = 0.501158940397351, Precision = 0.9973571192599934, f1 = 0.9985116586737225\n",
      "Epoch 40: Train Loss = 0.010457673176678995, Recall = 0.9996688741721854, Aging Rate = 0.501158940397351, Precision = 0.9973571192599934, f1 = 0.9985116586737225\n",
      "Test Loss = 0.009511824053348295, Recall = 1.0, Aging Rate = 0.5018211920529801, precision = 0.9963708347080171\n",
      "Model in epoch 40 is saved.\n",
      "\n",
      "Epoch 41: Train Loss = 0.010111395101254151, Recall = 1.0, Aging Rate = 0.5016556291390728, Precision = 0.9966996699669967, f1 = 0.9983471074380166\n",
      "Epoch 42: Train Loss = 0.010187703169672596, Recall = 0.9990066225165563, Aging Rate = 0.5006622516556292, Precision = 0.9976851851851852, f1 = 0.9983454665784248\n",
      "Epoch 43: Train Loss = 0.00961387926428918, Recall = 0.9996688741721854, Aging Rate = 0.5013245033112583, Precision = 0.9970277410832232, f1 = 0.9983465608465608\n",
      "Epoch 44: Train Loss = 0.009225669628416268, Recall = 0.9993377483443708, Aging Rate = 0.501158940397351, Precision = 0.9970267591674926, f1 = 0.998180916156772\n",
      "Epoch 45: Train Loss = 0.008810691224929217, Recall = 0.9996688741721854, Aging Rate = 0.501158940397351, Precision = 0.9973571192599934, f1 = 0.9985116586737225\n",
      "Test Loss = 0.007701069893722503, Recall = 0.9996688741721854, Aging Rate = 0.5006622516556292, precision = 0.9983465608465608\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model in epoch 45 is saved.\n",
      "\n",
      "Epoch 46: Train Loss = 0.008780239267731147, Recall = 1.0, Aging Rate = 0.501158940397351, Precision = 0.9976874793524942, f1 = 0.9988424011906731\n",
      "Epoch 47: Train Loss = 0.008148944067047132, Recall = 0.9996688741721854, Aging Rate = 0.5009933774834437, Precision = 0.9976867151354925, f1 = 0.9986768111147866\n",
      "Epoch 48: Train Loss = 0.008314680314271261, Recall = 0.9996688741721854, Aging Rate = 0.501158940397351, Precision = 0.9973571192599934, f1 = 0.9985116586737225\n",
      "Epoch 49: Train Loss = 0.007697488139352657, Recall = 0.9996688741721854, Aging Rate = 0.5008278145695364, Precision = 0.9980165289256199, f1 = 0.9988420181968569\n",
      "Epoch 50: Train Loss = 0.007857903465628624, Recall = 0.9996688741721854, Aging Rate = 0.501158940397351, Precision = 0.9973571192599934, f1 = 0.9985116586737225\n",
      "Test Loss = 0.006727191467232854, Recall = 0.9996688741721854, Aging Rate = 0.5009933774834437, precision = 0.9976867151354925\n",
      "\n",
      "Epoch 51: Train Loss = 0.00868840837844999, Recall = 0.9990066225165563, Aging Rate = 0.501158940397351, Precision = 0.9966963990749917, f1 = 0.9978501736398214\n",
      "Epoch 52: Train Loss = 0.0068544730063009734, Recall = 1.0, Aging Rate = 0.501158940397351, Precision = 0.9976874793524942, f1 = 0.9988424011906731\n",
      "Epoch 53: Train Loss = 0.007103076096106049, Recall = 1.0, Aging Rate = 0.501158940397351, Precision = 0.9976874793524942, f1 = 0.9988424011906731\n",
      "Epoch 54: Train Loss = 0.006866750174158851, Recall = 1.0, Aging Rate = 0.5009933774834437, Precision = 0.9980171844018506, f1 = 0.9990076083360899\n",
      "Epoch 55: Train Loss = 0.007098168394966236, Recall = 0.9996688741721854, Aging Rate = 0.5009933774834437, Precision = 0.9976867151354925, f1 = 0.9986768111147866\n",
      "Test Loss = 0.005815270001574463, Recall = 0.9993377483443708, Aging Rate = 0.5003311258278146, precision = 0.99867637326274\n",
      "Model in epoch 55 is saved.\n",
      "\n",
      "Epoch 56: Train Loss = 0.007253107786585657, Recall = 0.9990066225165563, Aging Rate = 0.501158940397351, Precision = 0.9966963990749917, f1 = 0.9978501736398214\n",
      "Epoch 57: Train Loss = 0.006611142823139563, Recall = 0.9996688741721854, Aging Rate = 0.5008278145695364, Precision = 0.9980165289256199, f1 = 0.9988420181968569\n",
      "Epoch 58: Train Loss = 0.006364778350940011, Recall = 0.9996688741721854, Aging Rate = 0.5009933774834437, Precision = 0.9976867151354925, f1 = 0.9986768111147866\n",
      "Epoch 59: Train Loss = 0.006111974840280631, Recall = 0.9996688741721854, Aging Rate = 0.5009933774834437, Precision = 0.9976867151354925, f1 = 0.9986768111147866\n",
      "Epoch 60: Train Loss = 0.0067333193754913, Recall = 0.9996688741721854, Aging Rate = 0.5006622516556292, Precision = 0.9983465608465608, f1 = 0.999007279947055\n",
      "Test Loss = 0.005957610366113533, Recall = 1.0, Aging Rate = 0.5009933774834437, precision = 0.9980171844018506\n",
      "\n",
      "Epoch 61: Train Loss = 0.006587843358707892, Recall = 0.9996688741721854, Aging Rate = 0.5008278145695364, Precision = 0.9980165289256199, f1 = 0.9988420181968569\n",
      "Epoch 62: Train Loss = 0.005611133573589143, Recall = 1.0, Aging Rate = 0.5009933774834437, Precision = 0.9980171844018506, f1 = 0.9990076083360899\n",
      "Epoch 63: Train Loss = 0.005624084373232939, Recall = 1.0, Aging Rate = 0.5008278145695364, Precision = 0.9983471074380166, f1 = 0.9991728701406121\n",
      "Epoch 64: Train Loss = 0.005438119537560948, Recall = 0.9996688741721854, Aging Rate = 0.5008278145695364, Precision = 0.9980165289256199, f1 = 0.9988420181968569\n",
      "Epoch 65: Train Loss = 0.005404804143684589, Recall = 1.0, Aging Rate = 0.5008278145695364, Precision = 0.9983471074380166, f1 = 0.9991728701406121\n",
      "Test Loss = 0.004505475946634218, Recall = 0.9996688741721854, Aging Rate = 0.5004966887417218, precision = 0.9986768111147867\n",
      "Model in epoch 65 is saved.\n",
      "\n",
      "Epoch 66: Train Loss = 0.005485159378893526, Recall = 0.9996688741721854, Aging Rate = 0.5006622516556292, Precision = 0.9983465608465608, f1 = 0.999007279947055\n",
      "Epoch 67: Train Loss = 0.005511019274049642, Recall = 0.9993377483443708, Aging Rate = 0.5006622516556292, Precision = 0.998015873015873, f1 = 0.99867637326274\n",
      "Epoch 68: Train Loss = 0.005799803511850191, Recall = 1.0, Aging Rate = 0.5009933774834437, Precision = 0.9980171844018506, f1 = 0.9990076083360899\n",
      "Epoch 69: Train Loss = 0.005226997808793819, Recall = 0.9993377483443708, Aging Rate = 0.5003311258278146, Precision = 0.99867637326274, f1 = 0.9990069513406157\n",
      "Epoch 70: Train Loss = 0.005520087325735795, Recall = 0.9996688741721854, Aging Rate = 0.5006622516556292, Precision = 0.9983465608465608, f1 = 0.999007279947055\n",
      "Test Loss = 0.004722325984289907, Recall = 1.0, Aging Rate = 0.5006622516556292, precision = 0.9986772486772487\n",
      "Model in epoch 70 is saved.\n",
      "\n",
      "Epoch 71: Train Loss = 0.004748300606976973, Recall = 1.0, Aging Rate = 0.5008278145695364, Precision = 0.9983471074380166, f1 = 0.9991728701406121\n",
      "Epoch 72: Train Loss = 0.005169487121632162, Recall = 0.9996688741721854, Aging Rate = 0.5004966887417218, Precision = 0.9986768111147867, f1 = 0.9991725963925203\n",
      "Epoch 73: Train Loss = 0.005576195052689225, Recall = 1.0, Aging Rate = 0.5013245033112583, Precision = 0.9973579920739762, f1 = 0.9986772486772486\n",
      "Epoch 74: Train Loss = 0.005314259055002734, Recall = 0.9996688741721854, Aging Rate = 0.5004966887417218, Precision = 0.9986768111147867, f1 = 0.9991725963925203\n",
      "Epoch 75: Train Loss = 0.004479702962839989, Recall = 1.0, Aging Rate = 0.5009933774834437, Precision = 0.9980171844018506, f1 = 0.9990076083360899\n",
      "Test Loss = 0.003839904100584816, Recall = 0.9996688741721854, Aging Rate = 0.5001655629139072, precision = 0.9993379675604105\n",
      "Model in epoch 75 is saved.\n",
      "\n",
      "Epoch 76: Train Loss = 0.004743869719095528, Recall = 0.9996688741721854, Aging Rate = 0.5003311258278146, Precision = 0.999007279947055, f1 = 0.9993379675604105\n",
      "Epoch 77: Train Loss = 0.004496722721143175, Recall = 0.9996688741721854, Aging Rate = 0.5008278145695364, Precision = 0.9980165289256199, f1 = 0.9988420181968569\n",
      "Epoch 78: Train Loss = 0.004750888887176056, Recall = 0.9996688741721854, Aging Rate = 0.5006622516556292, Precision = 0.9983465608465608, f1 = 0.999007279947055\n",
      "Epoch 79: Train Loss = 0.004396377982485373, Recall = 1.0, Aging Rate = 0.5009933774834437, Precision = 0.9980171844018506, f1 = 0.9990076083360899\n",
      "Epoch 80: Train Loss = 0.004780250633850891, Recall = 0.9993377483443708, Aging Rate = 0.5001655629139072, Precision = 0.9990069513406157, f1 = 0.9991723224631683\n",
      "Test Loss = 0.0041935322767691005, Recall = 1.0, Aging Rate = 0.5008278145695364, precision = 0.9983471074380166\n",
      "\n",
      "Epoch 81: Train Loss = 0.004745820672590507, Recall = 1.0, Aging Rate = 0.5008278145695364, Precision = 0.9983471074380166, f1 = 0.9991728701406121\n",
      "Epoch 82: Train Loss = 0.004267296872860351, Recall = 0.9996688741721854, Aging Rate = 0.5004966887417218, Precision = 0.9986768111147867, f1 = 0.9991725963925203\n",
      "Epoch 83: Train Loss = 0.004184871287831408, Recall = 1.0, Aging Rate = 0.5006622516556292, Precision = 0.9986772486772487, f1 = 0.99933818663137\n",
      "Epoch 84: Train Loss = 0.004435258159500281, Recall = 0.9993377483443708, Aging Rate = 0.5003311258278146, Precision = 0.99867637326274, f1 = 0.9990069513406157\n",
      "Epoch 85: Train Loss = 0.004443286965594978, Recall = 0.9996688741721854, Aging Rate = 0.5006622516556292, Precision = 0.9983465608465608, f1 = 0.999007279947055\n",
      "Test Loss = 0.004186395467613633, Recall = 1.0, Aging Rate = 0.5006622516556292, precision = 0.9986772486772487\n",
      "\n",
      "Epoch 86: Train Loss = 0.00402564038676734, Recall = 1.0, Aging Rate = 0.5004966887417218, Precision = 0.9990076083360899, f1 = 0.9995035578355121\n",
      "Epoch 87: Train Loss = 0.004371981663839114, Recall = 0.9996688741721854, Aging Rate = 0.5004966887417218, Precision = 0.9986768111147867, f1 = 0.9991725963925203\n",
      "Epoch 88: Train Loss = 0.004134670404766668, Recall = 1.0, Aging Rate = 0.5006622516556292, Precision = 0.9986772486772487, f1 = 0.99933818663137\n",
      "Epoch 89: Train Loss = 0.00431781076850826, Recall = 0.9996688741721854, Aging Rate = 0.5003311258278146, Precision = 0.999007279947055, f1 = 0.9993379675604105\n",
      "Epoch 90: Train Loss = 0.004648012148882478, Recall = 1.0, Aging Rate = 0.5009933774834437, Precision = 0.9980171844018506, f1 = 0.9990076083360899\n",
      "Test Loss = 0.004201242025472865, Recall = 1.0, Aging Rate = 0.5004966887417218, precision = 0.9990076083360899\n",
      "\n",
      "Epoch 91: Train Loss = 0.004179468548344756, Recall = 0.9993377483443708, Aging Rate = 0.5001655629139072, Precision = 0.9990069513406157, f1 = 0.9991723224631683\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 92: Train Loss = 0.0044045573075776855, Recall = 0.9993377483443708, Aging Rate = 0.5006622516556292, Precision = 0.998015873015873, f1 = 0.99867637326274\n",
      "Epoch 93: Train Loss = 0.004868193319381911, Recall = 1.0, Aging Rate = 0.5009933774834437, Precision = 0.9980171844018506, f1 = 0.9990076083360899\n",
      "Epoch 94: Train Loss = 0.00371245669497066, Recall = 0.9996688741721854, Aging Rate = 0.5003311258278146, Precision = 0.999007279947055, f1 = 0.9993379675604105\n",
      "Epoch 95: Train Loss = 0.004473707684630294, Recall = 0.9996688741721854, Aging Rate = 0.5003311258278146, Precision = 0.999007279947055, f1 = 0.9993379675604105\n",
      "Test Loss = 0.003344343484237494, Recall = 1.0, Aging Rate = 0.5004966887417218, precision = 0.9990076083360899\n",
      "\n",
      "Epoch 96: Train Loss = 0.004164436570868291, Recall = 0.9996688741721854, Aging Rate = 0.5006622516556292, Precision = 0.9983465608465608, f1 = 0.999007279947055\n",
      "Epoch 97: Train Loss = 0.00436660762327347, Recall = 0.9996688741721854, Aging Rate = 0.5001655629139072, Precision = 0.9993379675604105, f1 = 0.9995033934779011\n",
      "Epoch 98: Train Loss = 0.0040044542068973284, Recall = 0.9996688741721854, Aging Rate = 0.5003311258278146, Precision = 0.999007279947055, f1 = 0.9993379675604105\n",
      "Epoch 99: Train Loss = 0.003940474771006366, Recall = 0.9996688741721854, Aging Rate = 0.5003311258278146, Precision = 0.999007279947055, f1 = 0.9993379675604105\n",
      "Epoch 100: Train Loss = 0.003982634060948297, Recall = 0.9996688741721854, Aging Rate = 0.5004966887417218, Precision = 0.9986768111147867, f1 = 0.9991725963925203\n",
      "Test Loss = 0.0044406220643774955, Recall = 0.9996688741721854, Aging Rate = 0.5006622516556292, precision = 0.9983465608465608\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d02df3fa7f8f477da9b13fae86a48193",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss = 0.5454894402169234, Recall = 0.9947019867549669, Aging Rate = 0.9552980132450332, Precision = 0.5206239168110919, f1 = 0.6835039817974973\n",
      "Epoch 2: Train Loss = 0.39490658921121763, Recall = 0.9519867549668874, Aging Rate = 0.6928807947019867, Precision = 0.6869772998805257, f1 = 0.798056904927134\n",
      "Epoch 3: Train Loss = 0.3247777035299516, Recall = 0.9483443708609272, Aging Rate = 0.6289735099337749, Precision = 0.7538826006843906, f1 = 0.8400058659627512\n",
      "Epoch 4: Train Loss = 0.275516766211055, Recall = 0.956953642384106, Aging Rate = 0.5955298013245033, Precision = 0.8034473172087852, f1 = 0.8735076318573373\n",
      "Epoch 5: Train Loss = 0.23711349255596564, Recall = 0.9635761589403974, Aging Rate = 0.5783112582781457, Precision = 0.8330947609504724, f1 = 0.8935974205435283\n",
      "Test Loss = 0.20133540340212008, Recall = 0.9672185430463576, Aging Rate = 0.5506622516556291, precision = 0.8782321106434156\n",
      "Model in epoch 5 is saved.\n",
      "\n",
      "Epoch 6: Train Loss = 0.18774737972297414, Recall = 0.9728476821192052, Aging Rate = 0.5571192052980133, Precision = 0.8731054977711739, f1 = 0.9202819107282693\n",
      "Epoch 7: Train Loss = 0.15528989547727914, Recall = 0.9781456953642385, Aging Rate = 0.5463576158940397, Precision = 0.8951515151515151, f1 = 0.9348101265822785\n",
      "Epoch 8: Train Loss = 0.13136307226111557, Recall = 0.9798013245033113, Aging Rate = 0.5306291390728477, Precision = 0.9232449297971919, f1 = 0.9506827309236947\n",
      "Epoch 9: Train Loss = 0.11251787425863821, Recall = 0.983112582781457, Aging Rate = 0.5235099337748345, Precision = 0.9389626818469323, f1 = 0.9605305726302167\n",
      "Epoch 10: Train Loss = 0.09601232631514404, Recall = 0.9897350993377484, Aging Rate = 0.5205298013245033, Precision = 0.9506997455470738, f1 = 0.9698247890979883\n",
      "Test Loss = 0.08573661320256871, Recall = 0.9920529801324504, Aging Rate = 0.5195364238410596, precision = 0.9547482472912683\n",
      "Model in epoch 10 is saved.\n",
      "\n",
      "Epoch 11: Train Loss = 0.08415923956411564, Recall = 0.9897350993377484, Aging Rate = 0.516887417218543, Precision = 0.9573991031390134, f1 = 0.973298599804624\n",
      "Epoch 12: Train Loss = 0.07710925393941387, Recall = 0.9897350993377484, Aging Rate = 0.5163907284768212, Precision = 0.9583199743507534, f1 = 0.9737742303306728\n",
      "Epoch 13: Train Loss = 0.06774950961008766, Recall = 0.993046357615894, Aging Rate = 0.5139072847682119, Precision = 0.9661726804123711, f1 = 0.9794252122795558\n",
      "Epoch 14: Train Loss = 0.06046255881719242, Recall = 0.9940397350993377, Aging Rate = 0.5120860927152318, Precision = 0.9705787261558357, f1 = 0.9821691477179781\n",
      "Epoch 15: Train Loss = 0.05599698311840461, Recall = 0.9943708609271523, Aging Rate = 0.5102649006622516, Precision = 0.9743672939649578, f1 = 0.984267453294002\n",
      "Test Loss = 0.049219779216295834, Recall = 0.9963576158940397, Aging Rate = 0.510430463576159, precision = 0.9759974051248783\n",
      "Model in epoch 15 is saved.\n",
      "\n",
      "Epoch 16: Train Loss = 0.051446842209787555, Recall = 0.9953642384105961, Aging Rate = 0.5112582781456954, Precision = 0.9734455958549223, f1 = 0.9842829076620826\n",
      "Epoch 17: Train Loss = 0.0462308613225719, Recall = 0.9956953642384105, Aging Rate = 0.5099337748344371, Precision = 0.9762987012987013, f1 = 0.9859016393442623\n",
      "Epoch 18: Train Loss = 0.042685345979715815, Recall = 0.9960264900662251, Aging Rate = 0.508774834437086, Precision = 0.9788480312398308, f1 = 0.9873625471852946\n",
      "Epoch 19: Train Loss = 0.03968385753795406, Recall = 0.9956953642384105, Aging Rate = 0.5076158940397351, Precision = 0.9807566862361383, f1 = 0.9881695695037791\n",
      "Epoch 20: Train Loss = 0.03760247341054954, Recall = 0.9963576158940397, Aging Rate = 0.5076158940397351, Precision = 0.9814090019569471, f1 = 0.9888268156424582\n",
      "Test Loss = 0.03355293668658528, Recall = 0.9970198675496689, Aging Rate = 0.503476821192053, precision = 0.9901348240710293\n",
      "Model in epoch 20 is saved.\n",
      "\n",
      "Epoch 21: Train Loss = 0.03438114043300515, Recall = 0.9970198675496689, Aging Rate = 0.5066225165562914, Precision = 0.9839869281045751, f1 = 0.9904605263157894\n",
      "Epoch 22: Train Loss = 0.032122997803897255, Recall = 0.9963576158940397, Aging Rate = 0.5056291390728477, Precision = 0.9852652259332023, f1 = 0.9907803753704314\n",
      "Epoch 23: Train Loss = 0.030128625444821176, Recall = 0.997682119205298, Aging Rate = 0.5056291390728477, Precision = 0.9865749836280289, f1 = 0.992097464603227\n",
      "Epoch 24: Train Loss = 0.02814966838634172, Recall = 0.9973509933774835, Aging Rate = 0.5049668874172185, Precision = 0.9875409836065574, f1 = 0.9924217462932454\n",
      "Epoch 25: Train Loss = 0.02651741789863599, Recall = 0.9986754966887417, Aging Rate = 0.5061258278145695, Precision = 0.9865881583251553, f1 = 0.9925950304426526\n",
      "Test Loss = 0.023857652122117826, Recall = 0.9983443708609272, Aging Rate = 0.5036423841059603, precision = 0.9911242603550295\n",
      "Model in epoch 25 is saved.\n",
      "\n",
      "Epoch 26: Train Loss = 0.025192422557942913, Recall = 0.9983443708609272, Aging Rate = 0.5046357615894039, Precision = 0.9891732283464567, f1 = 0.9937376400791036\n",
      "Epoch 27: Train Loss = 0.024050521482991066, Recall = 0.9970198675496689, Aging Rate = 0.5026490066225165, Precision = 0.9917654808959157, f1 = 0.9943857331571996\n",
      "Epoch 28: Train Loss = 0.02220589950532708, Recall = 0.9983443708609272, Aging Rate = 0.503476821192053, Precision = 0.9914501808615587, f1 = 0.9948853324533906\n",
      "Epoch 29: Train Loss = 0.021815039158262165, Recall = 0.997682119205298, Aging Rate = 0.502317880794702, Precision = 0.9930784442979564, f1 = 0.9953749587049884\n",
      "Epoch 30: Train Loss = 0.019603278532328194, Recall = 0.9993377483443708, Aging Rate = 0.503476821192053, Precision = 0.9924366984544558, f1 = 0.995875268107573\n",
      "Test Loss = 0.017152600766264445, Recall = 1.0, Aging Rate = 0.5029801324503311, precision = 0.9940750493745886\n",
      "Model in epoch 30 is saved.\n",
      "\n",
      "Epoch 31: Train Loss = 0.01939744824753297, Recall = 0.9986754966887417, Aging Rate = 0.5028145695364239, Precision = 0.9930852815278235, f1 = 0.9958725441637775\n",
      "Epoch 32: Train Loss = 0.017817554640158124, Recall = 0.9990066225165563, Aging Rate = 0.5026490066225165, Precision = 0.9937417654808959, f1 = 0.9963672391017173\n",
      "Epoch 33: Train Loss = 0.016950982295914203, Recall = 0.9993377483443708, Aging Rate = 0.5031456953642384, Precision = 0.9930898321816387, f1 = 0.9962039940584255\n",
      "Epoch 34: Train Loss = 0.016046823492113328, Recall = 0.9990066225165563, Aging Rate = 0.5028145695364239, Precision = 0.9934145538360224, f1 = 0.9962027406306754\n",
      "Epoch 35: Train Loss = 0.015149521214628456, Recall = 1.0, Aging Rate = 0.5028145695364239, Precision = 0.994402370760619, f1 = 0.9971933300313686\n",
      "Test Loss = 0.013895188285876683, Recall = 0.9993377483443708, Aging Rate = 0.501158940397351, precision = 0.9970267591674926\n",
      "Model in epoch 35 is saved.\n",
      "\n",
      "Epoch 36: Train Loss = 0.014331022501978654, Recall = 0.9993377483443708, Aging Rate = 0.5018211920529801, Precision = 0.9957109864731112, f1 = 0.9975210708973722\n",
      "Epoch 37: Train Loss = 0.013856231471807357, Recall = 0.9996688741721854, Aging Rate = 0.5026490066225165, Precision = 0.9944005270092227, f1 = 0.9970277410832232\n",
      "Epoch 38: Train Loss = 0.013153838363802985, Recall = 0.9990066225165563, Aging Rate = 0.5016556291390728, Precision = 0.9957095709570957, f1 = 0.9973553719008265\n",
      "Epoch 39: Train Loss = 0.012800118647861165, Recall = 0.9996688741721854, Aging Rate = 0.5024834437086093, Precision = 0.9947281713344316, f1 = 0.9971924029727498\n",
      "Epoch 40: Train Loss = 0.012236905758522007, Recall = 0.9993377483443708, Aging Rate = 0.5018211920529801, Precision = 0.9957109864731112, f1 = 0.9975210708973722\n",
      "Test Loss = 0.010482044003607817, Recall = 1.0, Aging Rate = 0.501158940397351, precision = 0.9976874793524942\n",
      "Model in epoch 40 is saved.\n",
      "\n",
      "Epoch 41: Train Loss = 0.011458532927890883, Recall = 0.9996688741721854, Aging Rate = 0.5013245033112583, Precision = 0.9970277410832232, f1 = 0.9983465608465608\n",
      "Epoch 42: Train Loss = 0.011326500060443846, Recall = 0.9996688741721854, Aging Rate = 0.5018211920529801, Precision = 0.9960409105905642, f1 = 0.9978515947777227\n",
      "Epoch 43: Train Loss = 0.01082051627288591, Recall = 1.0, Aging Rate = 0.5018211920529801, Precision = 0.9963708347080171, f1 = 0.998182118658073\n",
      "Epoch 44: Train Loss = 0.010395627714298814, Recall = 0.9996688741721854, Aging Rate = 0.5009933774834437, Precision = 0.9976867151354925, f1 = 0.9986768111147866\n",
      "Epoch 45: Train Loss = 0.00994624730310594, Recall = 0.9996688741721854, Aging Rate = 0.5008278145695364, Precision = 0.9980165289256199, f1 = 0.9988420181968569\n",
      "Test Loss = 0.008680247384684765, Recall = 1.0, Aging Rate = 0.5008278145695364, precision = 0.9983471074380166\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model in epoch 45 is saved.\n",
      "\n",
      "Epoch 46: Train Loss = 0.009388408975503007, Recall = 0.9996688741721854, Aging Rate = 0.5008278145695364, Precision = 0.9980165289256199, f1 = 0.9988420181968569\n",
      "Epoch 47: Train Loss = 0.009035783389965628, Recall = 1.0, Aging Rate = 0.501158940397351, Precision = 0.9976874793524942, f1 = 0.9988424011906731\n",
      "Epoch 48: Train Loss = 0.008581314494814847, Recall = 1.0, Aging Rate = 0.5006622516556292, Precision = 0.9986772486772487, f1 = 0.99933818663137\n",
      "Epoch 49: Train Loss = 0.00830465674844404, Recall = 0.9996688741721854, Aging Rate = 0.5008278145695364, Precision = 0.9980165289256199, f1 = 0.9988420181968569\n",
      "Epoch 50: Train Loss = 0.008313383131183141, Recall = 0.9996688741721854, Aging Rate = 0.501158940397351, Precision = 0.9973571192599934, f1 = 0.9985116586737225\n",
      "Test Loss = 0.007276323075955178, Recall = 1.0, Aging Rate = 0.5004966887417218, precision = 0.9990076083360899\n",
      "Model in epoch 50 is saved.\n",
      "\n",
      "Epoch 51: Train Loss = 0.008426643922826313, Recall = 0.9996688741721854, Aging Rate = 0.5008278145695364, Precision = 0.9980165289256199, f1 = 0.9988420181968569\n",
      "Epoch 52: Train Loss = 0.007457833146269353, Recall = 0.9996688741721854, Aging Rate = 0.5006622516556292, Precision = 0.9983465608465608, f1 = 0.999007279947055\n",
      "Epoch 53: Train Loss = 0.007111857809582787, Recall = 1.0, Aging Rate = 0.5006622516556292, Precision = 0.9986772486772487, f1 = 0.99933818663137\n",
      "Epoch 54: Train Loss = 0.007318762925434981, Recall = 0.9996688741721854, Aging Rate = 0.5008278145695364, Precision = 0.9980165289256199, f1 = 0.9988420181968569\n",
      "Epoch 55: Train Loss = 0.007461025708336506, Recall = 0.9996688741721854, Aging Rate = 0.5006622516556292, Precision = 0.9983465608465608, f1 = 0.999007279947055\n",
      "Test Loss = 0.0060295951241220265, Recall = 1.0, Aging Rate = 0.5006622516556292, precision = 0.9986772486772487\n",
      "\n",
      "Epoch 56: Train Loss = 0.006443919250834117, Recall = 1.0, Aging Rate = 0.5008278145695364, Precision = 0.9983471074380166, f1 = 0.9991728701406121\n",
      "Epoch 57: Train Loss = 0.006442585093468823, Recall = 0.9993377483443708, Aging Rate = 0.5, Precision = 0.9993377483443708, f1 = 0.9993377483443708\n",
      "Epoch 58: Train Loss = 0.006450610802761767, Recall = 1.0, Aging Rate = 0.5009933774834437, Precision = 0.9980171844018506, f1 = 0.9990076083360899\n",
      "Epoch 59: Train Loss = 0.005995160508407465, Recall = 1.0, Aging Rate = 0.5004966887417218, Precision = 0.9990076083360899, f1 = 0.9995035578355121\n",
      "Epoch 60: Train Loss = 0.0061739086586710635, Recall = 1.0, Aging Rate = 0.5004966887417218, Precision = 0.9990076083360899, f1 = 0.9995035578355121\n",
      "Test Loss = 0.005080994150126415, Recall = 1.0, Aging Rate = 0.5003311258278146, precision = 0.99933818663137\n",
      "Model in epoch 60 is saved.\n",
      "\n",
      "Epoch 61: Train Loss = 0.005774727844886037, Recall = 0.9996688741721854, Aging Rate = 0.5004966887417218, Precision = 0.9986768111147867, f1 = 0.9991725963925203\n",
      "Epoch 62: Train Loss = 0.005620135611157544, Recall = 1.0, Aging Rate = 0.5004966887417218, Precision = 0.9990076083360899, f1 = 0.9995035578355121\n",
      "Epoch 63: Train Loss = 0.005428408377415297, Recall = 1.0, Aging Rate = 0.5004966887417218, Precision = 0.9990076083360899, f1 = 0.9995035578355121\n",
      "Epoch 64: Train Loss = 0.0054858163113255575, Recall = 0.9996688741721854, Aging Rate = 0.5003311258278146, Precision = 0.999007279947055, f1 = 0.9993379675604105\n",
      "Epoch 65: Train Loss = 0.005248283587445487, Recall = 1.0, Aging Rate = 0.5003311258278146, Precision = 0.99933818663137, f1 = 0.9996689837802052\n",
      "Test Loss = 0.0045530942006542395, Recall = 1.0, Aging Rate = 0.5001655629139072, precision = 0.9996689837802052\n",
      "Model in epoch 65 is saved.\n",
      "\n",
      "Epoch 66: Train Loss = 0.005261508986625253, Recall = 1.0, Aging Rate = 0.5004966887417218, Precision = 0.9990076083360899, f1 = 0.9995035578355121\n",
      "Epoch 67: Train Loss = 0.005075168937432352, Recall = 1.0, Aging Rate = 0.5003311258278146, Precision = 0.99933818663137, f1 = 0.9996689837802052\n",
      "Epoch 68: Train Loss = 0.005262934163040081, Recall = 1.0, Aging Rate = 0.5003311258278146, Precision = 0.99933818663137, f1 = 0.9996689837802052\n",
      "Epoch 69: Train Loss = 0.004739168288790627, Recall = 1.0, Aging Rate = 0.5003311258278146, Precision = 0.99933818663137, f1 = 0.9996689837802052\n",
      "Epoch 70: Train Loss = 0.005156997963169355, Recall = 0.9996688741721854, Aging Rate = 0.5003311258278146, Precision = 0.999007279947055, f1 = 0.9993379675604105\n",
      "Test Loss = 0.004546968921840142, Recall = 1.0, Aging Rate = 0.5006622516556292, precision = 0.9986772486772487\n",
      "\n",
      "Epoch 71: Train Loss = 0.004822369915316042, Recall = 1.0, Aging Rate = 0.5004966887417218, Precision = 0.9990076083360899, f1 = 0.9995035578355121\n",
      "Epoch 72: Train Loss = 0.004489112260214837, Recall = 1.0, Aging Rate = 0.5003311258278146, Precision = 0.99933818663137, f1 = 0.9996689837802052\n",
      "Epoch 73: Train Loss = 0.004630279940374146, Recall = 1.0, Aging Rate = 0.5003311258278146, Precision = 0.99933818663137, f1 = 0.9996689837802052\n",
      "Epoch 74: Train Loss = 0.004824939377556573, Recall = 1.0, Aging Rate = 0.5001655629139072, Precision = 0.9996689837802052, f1 = 0.9998344644926337\n",
      "Epoch 75: Train Loss = 0.004575248808902226, Recall = 1.0, Aging Rate = 0.5003311258278146, Precision = 0.99933818663137, f1 = 0.9996689837802052\n",
      "Test Loss = 0.003957950061924188, Recall = 1.0, Aging Rate = 0.5001655629139072, precision = 0.9996689837802052\n",
      "\n",
      "Epoch 76: Train Loss = 0.004466902730764439, Recall = 1.0, Aging Rate = 0.5001655629139072, Precision = 0.9996689837802052, f1 = 0.9998344644926337\n",
      "Epoch 77: Train Loss = 0.004216477711567816, Recall = 1.0, Aging Rate = 0.5003311258278146, Precision = 0.99933818663137, f1 = 0.9996689837802052\n",
      "Epoch 78: Train Loss = 0.0047830240911995335, Recall = 1.0, Aging Rate = 0.5006622516556292, Precision = 0.9986772486772487, f1 = 0.99933818663137\n",
      "Epoch 79: Train Loss = 0.00486149082441401, Recall = 0.9996688741721854, Aging Rate = 0.5003311258278146, Precision = 0.999007279947055, f1 = 0.9993379675604105\n",
      "Epoch 80: Train Loss = 0.004003210255987202, Recall = 1.0, Aging Rate = 0.5001655629139072, Precision = 0.9996689837802052, f1 = 0.9998344644926337\n",
      "Test Loss = 0.0034216060411086345, Recall = 1.0, Aging Rate = 0.5001655629139072, precision = 0.9996689837802052\n",
      "\n",
      "Epoch 81: Train Loss = 0.0040638966350168585, Recall = 1.0, Aging Rate = 0.5003311258278146, Precision = 0.99933818663137, f1 = 0.9996689837802052\n",
      "Epoch 82: Train Loss = 0.004062560547932686, Recall = 0.9996688741721854, Aging Rate = 0.5001655629139072, Precision = 0.9993379675604105, f1 = 0.9995033934779011\n",
      "Epoch 83: Train Loss = 0.004204222851661065, Recall = 1.0, Aging Rate = 0.5003311258278146, Precision = 0.99933818663137, f1 = 0.9996689837802052\n",
      "Epoch 84: Train Loss = 0.0038301447542100553, Recall = 1.0, Aging Rate = 0.5001655629139072, Precision = 0.9996689837802052, f1 = 0.9998344644926337\n",
      "Epoch 85: Train Loss = 0.003832705793840601, Recall = 1.0, Aging Rate = 0.5001655629139072, Precision = 0.9996689837802052, f1 = 0.9998344644926337\n",
      "Test Loss = 0.003519506607241682, Recall = 1.0, Aging Rate = 0.5001655629139072, precision = 0.9996689837802052\n",
      "\n",
      "Epoch 86: Train Loss = 0.003722312861424408, Recall = 1.0, Aging Rate = 0.5001655629139072, Precision = 0.9996689837802052, f1 = 0.9998344644926337\n",
      "Epoch 87: Train Loss = 0.003896124959793805, Recall = 1.0, Aging Rate = 0.5001655629139072, Precision = 0.9996689837802052, f1 = 0.9998344644926337\n",
      "Epoch 88: Train Loss = 0.0037156771177685025, Recall = 1.0, Aging Rate = 0.5001655629139072, Precision = 0.9996689837802052, f1 = 0.9998344644926337\n",
      "Epoch 89: Train Loss = 0.004506939932370916, Recall = 1.0, Aging Rate = 0.5006622516556292, Precision = 0.9986772486772487, f1 = 0.99933818663137\n",
      "Epoch 90: Train Loss = 0.0039377105946572415, Recall = 1.0, Aging Rate = 0.5001655629139072, Precision = 0.9996689837802052, f1 = 0.9998344644926337\n",
      "Test Loss = 0.0031295905278267843, Recall = 1.0, Aging Rate = 0.5001655629139072, precision = 0.9996689837802052\n",
      "\n",
      "Epoch 91: Train Loss = 0.0038761465454054686, Recall = 1.0, Aging Rate = 0.5001655629139072, Precision = 0.9996689837802052, f1 = 0.9998344644926337\n",
      "Epoch 92: Train Loss = 0.003537158893162249, Recall = 1.0, Aging Rate = 0.5001655629139072, Precision = 0.9996689837802052, f1 = 0.9998344644926337\n",
      "Epoch 93: Train Loss = 0.0037110850898030875, Recall = 1.0, Aging Rate = 0.5003311258278146, Precision = 0.99933818663137, f1 = 0.9996689837802052\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 94: Train Loss = 0.003584079087298635, Recall = 1.0, Aging Rate = 0.5001655629139072, Precision = 0.9996689837802052, f1 = 0.9998344644926337\n",
      "Epoch 95: Train Loss = 0.0036235025050797014, Recall = 1.0, Aging Rate = 0.5001655629139072, Precision = 0.9996689837802052, f1 = 0.9998344644926337\n",
      "Test Loss = 0.002978519326853042, Recall = 1.0, Aging Rate = 0.5001655629139072, precision = 0.9996689837802052\n",
      "\n",
      "Epoch 96: Train Loss = 0.003161147493400321, Recall = 1.0, Aging Rate = 0.5001655629139072, Precision = 0.9996689837802052, f1 = 0.9998344644926337\n",
      "Epoch 97: Train Loss = 0.003321191899182386, Recall = 1.0, Aging Rate = 0.5001655629139072, Precision = 0.9996689837802052, f1 = 0.9998344644926337\n",
      "Epoch 98: Train Loss = 0.0038669100188533003, Recall = 1.0, Aging Rate = 0.5001655629139072, Precision = 0.9996689837802052, f1 = 0.9998344644926337\n",
      "Epoch 99: Train Loss = 0.0038603677229326686, Recall = 1.0, Aging Rate = 0.5001655629139072, Precision = 0.9996689837802052, f1 = 0.9998344644926337\n",
      "Epoch 100: Train Loss = 0.00340111210621548, Recall = 1.0, Aging Rate = 0.5001655629139072, Precision = 0.9996689837802052, f1 = 0.9998344644926337\n",
      "Test Loss = 0.0030230307567630284, Recall = 1.0, Aging Rate = 0.5001655629139072, precision = 0.9996689837802052\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "44a5ab7045124fffb2d39cae3194458e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ce600f497b74693a79445d5db18b34e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss = 0.6098161705405825, Recall = 0.9696110210696921, Aging Rate = 0.9120745542949756, Precision = 0.5315415370946246, f1 = 0.6866571018651362\n",
      "Epoch 2: Train Loss = 0.49842230069965754, Recall = 0.8865478119935171, Aging Rate = 0.6399918962722853, Precision = 0.6926242481798037, f1 = 0.7776790474497957\n",
      "Epoch 3: Train Loss = 0.423403876430598, Recall = 0.8707455429497569, Aging Rate = 0.5676661264181524, Precision = 0.7669521770164168, f1 = 0.8155597722960153\n",
      "Epoch 4: Train Loss = 0.36404295326052066, Recall = 0.8914100486223663, Aging Rate = 0.5445705024311183, Precision = 0.8184523809523809, f1 = 0.8533747090768038\n",
      "Epoch 5: Train Loss = 0.3195877370803437, Recall = 0.9051863857374393, Aging Rate = 0.5332252836304701, Precision = 0.8487841945288754, f1 = 0.8760784313725489\n",
      "Test Loss = 0.28213748504895253, Recall = 0.8987034035656402, Aging Rate = 0.4831847649918963, precision = 0.929979035639413\n",
      "Model in epoch 5 is saved.\n",
      "\n",
      "Epoch 6: Train Loss = 0.2597275791716923, Recall = 0.9270664505672609, Aging Rate = 0.5111426256077796, Precision = 0.9068569163694015, f1 = 0.916850330595071\n",
      "Epoch 7: Train Loss = 0.21722553786331097, Recall = 0.9469205834683955, Aging Rate = 0.505064829821718, Precision = 0.937424789410349, f1 = 0.9421487603305785\n",
      "Epoch 8: Train Loss = 0.1825563004376243, Recall = 0.963128038897893, Aging Rate = 0.5012155591572123, Precision = 0.9607922392886015, f1 = 0.96195872116552\n",
      "Epoch 9: Train Loss = 0.1526479931786729, Recall = 0.9720421393841167, Aging Rate = 0.5022285251215559, Precision = 0.9677289229528035, f1 = 0.9698807357994744\n",
      "Epoch 10: Train Loss = 0.12860013653238936, Recall = 0.9785251215559158, Aging Rate = 0.5012155591572123, Precision = 0.9761519805982215, f1 = 0.9773371104815863\n",
      "Test Loss = 0.11448119580745697, Recall = 0.9821717990275527, Aging Rate = 0.49939222042139386, precision = 0.983367139959432\n",
      "Model in epoch 10 is saved.\n",
      "\n",
      "Epoch 11: Train Loss = 0.11010822621166609, Recall = 0.9825769854132901, Aging Rate = 0.5, Precision = 0.9825769854132901, f1 = 0.9825769854132901\n",
      "Epoch 12: Train Loss = 0.09497639049007595, Recall = 0.9878444084278768, Aging Rate = 0.5016207455429498, Precision = 0.9846526655896607, f1 = 0.9862459546925566\n",
      "Epoch 13: Train Loss = 0.08182172716340137, Recall = 0.9931118314424635, Aging Rate = 0.5022285251215559, Precision = 0.9887051230334812, f1 = 0.9909035779260157\n",
      "Epoch 14: Train Loss = 0.0718108246727836, Recall = 0.9939222042139384, Aging Rate = 0.501418152350081, Precision = 0.9911111111111112, f1 = 0.9925146672061501\n",
      "Epoch 15: Train Loss = 0.06334031245262155, Recall = 0.993517017828201, Aging Rate = 0.5002025931928687, Precision = 0.9931146213041717, f1 = 0.9933157788130442\n",
      "Test Loss = 0.056259876434092006, Recall = 0.9951377633711507, Aging Rate = 0.49959481361426256, precision = 0.9959448499594485\n",
      "Model in epoch 15 is saved.\n",
      "\n",
      "Epoch 16: Train Loss = 0.0551711227835384, Recall = 0.9947325769854133, Aging Rate = 0.5004051863857374, Precision = 0.9939271255060729, f1 = 0.9943296881328473\n",
      "Epoch 17: Train Loss = 0.04923113860564255, Recall = 0.9955429497568882, Aging Rate = 0.5002025931928687, Precision = 0.9951397326852977, f1 = 0.995341300384849\n",
      "Epoch 18: Train Loss = 0.04443340708699373, Recall = 0.9967585089141004, Aging Rate = 0.5002025931928687, Precision = 0.9963547995139733, f1 = 0.9965566133279319\n",
      "Epoch 19: Train Loss = 0.03992957833133988, Recall = 0.9979740680713128, Aging Rate = 0.5004051863857374, Precision = 0.9971659919028341, f1 = 0.9975698663426489\n",
      "Epoch 20: Train Loss = 0.03551617953654626, Recall = 0.9979740680713128, Aging Rate = 0.5006077795786061, Precision = 0.9967624443545123, f1 = 0.9973678882364851\n",
      "Test Loss = 0.03211309111147298, Recall = 0.9983792544570502, Aging Rate = 0.5002025931928687, precision = 0.9979748886188741\n",
      "Model in epoch 20 is saved.\n",
      "\n",
      "Epoch 21: Train Loss = 0.032181598372890266, Recall = 0.9983792544570502, Aging Rate = 0.5, Precision = 0.9983792544570502, f1 = 0.9983792544570502\n",
      "Epoch 22: Train Loss = 0.029148767815489245, Recall = 0.9991896272285251, Aging Rate = 0.5004051863857374, Precision = 0.9983805668016195, f1 = 0.9987849331713246\n",
      "Epoch 23: Train Loss = 0.026565958356342883, Recall = 0.9987844408427877, Aging Rate = 0.4997974068071313, Precision = 0.999189298743413, f1 = 0.9989868287740629\n",
      "Epoch 24: Train Loss = 0.02439253629340731, Recall = 0.9995948136142626, Aging Rate = 0.5002025931928687, Precision = 0.9991899554475496, f1 = 0.9993923435284587\n",
      "Epoch 25: Train Loss = 0.022416481023693587, Recall = 0.9995948136142626, Aging Rate = 0.5006077795786061, Precision = 0.9983812221772562, f1 = 0.998987649321725\n",
      "Test Loss = 0.020470234745059834, Recall = 1.0, Aging Rate = 0.5004051863857374, precision = 0.9991902834008097\n",
      "Model in epoch 25 is saved.\n",
      "\n",
      "Epoch 26: Train Loss = 0.020616518402988365, Recall = 1.0, Aging Rate = 0.5004051863857374, Precision = 0.9991902834008097, f1 = 0.9995949777237748\n",
      "Epoch 27: Train Loss = 0.019152109802517938, Recall = 0.9991896272285251, Aging Rate = 0.5, Precision = 0.9991896272285251, f1 = 0.9991896272285251\n",
      "Epoch 28: Train Loss = 0.01786844514769229, Recall = 1.0, Aging Rate = 0.5004051863857374, Precision = 0.9991902834008097, f1 = 0.9995949777237748\n",
      "Epoch 29: Train Loss = 0.016527648360092597, Recall = 1.0, Aging Rate = 0.5002025931928687, Precision = 0.9995949777237748, f1 = 0.9997974478428194\n",
      "Epoch 30: Train Loss = 0.01545028715293305, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.014665421768660676, Recall = 1.0, Aging Rate = 0.5004051863857374, precision = 0.9991902834008097\n",
      "\n",
      "Epoch 31: Train Loss = 0.014382163554768122, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 32: Train Loss = 0.013423161610592657, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 33: Train Loss = 0.012859671834759667, Recall = 1.0, Aging Rate = 0.5004051863857374, Precision = 0.9991902834008097, f1 = 0.9995949777237748\n",
      "Epoch 34: Train Loss = 0.011765367082792607, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 35: Train Loss = 0.011109512617790428, Recall = 1.0, Aging Rate = 0.5002025931928687, Precision = 0.9995949777237748, f1 = 0.9997974478428194\n",
      "Test Loss = 0.010293318384373787, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "Model in epoch 35 is saved.\n",
      "\n",
      "Epoch 36: Train Loss = 0.010450721116105587, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 37: Train Loss = 0.009859257137683647, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 38: Train Loss = 0.009333866082337145, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 39: Train Loss = 0.008862228224860018, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 40: Train Loss = 0.008480267910923767, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.007892454859636109, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 41: Train Loss = 0.008059519961192552, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 42: Train Loss = 0.00766356298292427, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 43: Train Loss = 0.007336582416424006, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 44: Train Loss = 0.006938337085759524, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 45: Train Loss = 0.0066756644800178575, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.006278106643904356, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 46: Train Loss = 0.006371352130266411, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 47: Train Loss = 0.006116907128904202, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 48: Train Loss = 0.005915266775633276, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 49: Train Loss = 0.005714619886567831, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 50: Train Loss = 0.005441613887048762, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.005099053164065561, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 51: Train Loss = 0.0052895049641521665, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 52: Train Loss = 0.005062247845351793, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 53: Train Loss = 0.004868866220672088, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 54: Train Loss = 0.0047187857515506165, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 55: Train Loss = 0.004571624285869023, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.004302023482815373, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 56: Train Loss = 0.004421393302113808, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 57: Train Loss = 0.0042995905980612705, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 58: Train Loss = 0.004182058911033977, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 59: Train Loss = 0.004044050159841486, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 60: Train Loss = 0.004026890216120542, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0037083535649884655, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 61: Train Loss = 0.0038639150123674923, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 62: Train Loss = 0.003730241369646242, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 63: Train Loss = 0.0036411467091311705, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 64: Train Loss = 0.0035302792845604823, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 65: Train Loss = 0.0034474250441643515, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0032955841923576314, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 66: Train Loss = 0.0033971004533721815, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 67: Train Loss = 0.0032969218070469375, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 68: Train Loss = 0.0032141893185868354, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 69: Train Loss = 0.003165278487538427, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 70: Train Loss = 0.0031503890188202574, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.002933765794950533, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 71: Train Loss = 0.0030358830573281796, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 72: Train Loss = 0.0029571888986461748, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 73: Train Loss = 0.00291770794225111, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 74: Train Loss = 0.0028565944605650354, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 75: Train Loss = 0.0028209225089716418, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0026840344116671353, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 76: Train Loss = 0.002788103293518821, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 77: Train Loss = 0.0027613514729411715, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 78: Train Loss = 0.0026772626067362304, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 79: Train Loss = 0.0026388007217664966, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 80: Train Loss = 0.0026602616995524742, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0024672088007981524, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 81: Train Loss = 0.0026586516575383646, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 82: Train Loss = 0.0025200281908050346, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 83: Train Loss = 0.002523071055430345, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 84: Train Loss = 0.0024771263605554254, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 85: Train Loss = 0.0024381958856134157, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.002358414021409698, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Training Finished at epoch 85.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "196e739e3f494c15a9291244bf562d84",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss = 0.6294835446380534, Recall = 0.9310903931901094, Aging Rate = 0.8976489663558979, Precision = 0.5186272296229397, f1 = 0.6661832946635731\n",
      "Epoch 2: Train Loss = 0.504514548258594, Recall = 0.8937981353871098, Aging Rate = 0.6564653425212809, Precision = 0.6807656684161778, f1 = 0.7728706624605677\n",
      "Epoch 3: Train Loss = 0.4300763595911188, Recall = 0.8601540332387515, Aging Rate = 0.5573571139035266, Precision = 0.7716363636363637, f1 = 0.813494345409239\n",
      "Epoch 4: Train Loss = 0.37153101251296394, Recall = 0.8905553303607621, Aging Rate = 0.546209971625456, Precision = 0.8152133580705009, f1 = 0.8512204571871367\n",
      "Epoch 5: Train Loss = 0.3288827998753158, Recall = 0.9031211998378598, Aging Rate = 0.5301986218078638, Precision = 0.8516819571865444, f1 = 0.8766476490261658\n",
      "Test Loss = 0.29071156607497595, Recall = 0.9331171463315768, Aging Rate = 0.5429671665991083, precision = 0.8592758491974617\n",
      "Model in epoch 5 is saved.\n",
      "\n",
      "Epoch 6: Train Loss = 0.27135112891324775, Recall = 0.9250101337657073, Aging Rate = 0.5170247263883259, Precision = 0.8945511564092513, f1 = 0.9095257074531686\n",
      "Epoch 7: Train Loss = 0.22968517074132672, Recall = 0.9412241588974463, Aging Rate = 0.5107417916497771, Precision = 0.9214285714285714, f1 = 0.9312211750551433\n",
      "Epoch 8: Train Loss = 0.19389459279973253, Recall = 0.9562221321443048, Aging Rate = 0.5052695581678152, Precision = 0.946249498596069, f1 = 0.9512096774193548\n",
      "Epoch 9: Train Loss = 0.16209276855885862, Recall = 0.9695987028779894, Aging Rate = 0.5024321037697609, Precision = 0.9649052037111738, f1 = 0.9672462596037202\n",
      "Epoch 10: Train Loss = 0.13702182242526764, Recall = 0.9752736116740981, Aging Rate = 0.5018240778273206, Precision = 0.9717285945072698, f1 = 0.9734978757839369\n",
      "Test Loss = 0.12245456597125622, Recall = 0.9789217673287394, Aging Rate = 0.5004053506282935, precision = 0.9781287970838396\n",
      "Model in epoch 10 is saved.\n",
      "\n",
      "Epoch 11: Train Loss = 0.11743684761742613, Recall = 0.9817592217267936, Aging Rate = 0.5020267531414674, Precision = 0.9777957206297941, f1 = 0.9797734627831716\n",
      "Epoch 12: Train Loss = 0.10098141895695452, Recall = 0.9874341305229023, Aging Rate = 0.503040129712201, Precision = 0.9814665592264303, f1 = 0.9844413012729845\n",
      "Epoch 13: Train Loss = 0.08712184158567964, Recall = 0.9890555330360762, Aging Rate = 0.5016214025131739, Precision = 0.9858585858585859, f1 = 0.9874544718737353\n",
      "Epoch 14: Train Loss = 0.07655554070440583, Recall = 0.9910822861775436, Aging Rate = 0.5, Precision = 0.9910822861775436, f1 = 0.9910822861775436\n",
      "Epoch 15: Train Loss = 0.06691845828372069, Recall = 0.9918929874341306, Aging Rate = 0.4993919740575598, Precision = 0.9931006493506493, f1 = 0.9924964510241331\n",
      "Test Loss = 0.06012645314278079, Recall = 0.9935143899473045, Aging Rate = 0.4989866234292663, precision = 0.99553208773355\n",
      "Model in epoch 15 is saved.\n",
      "\n",
      "Epoch 16: Train Loss = 0.0595003764307784, Recall = 0.992298338062424, Aging Rate = 0.4989866234292663, Precision = 0.9943135662063363, f1 = 0.9933049300060863\n",
      "Epoch 17: Train Loss = 0.0531398859177046, Recall = 0.9943250912038913, Aging Rate = 0.49918929874341306, Precision = 0.9959399106780349, f1 = 0.995131845841785\n",
      "Epoch 18: Train Loss = 0.047525224851593106, Recall = 0.9951357924604783, Aging Rate = 0.49979732468585325, Precision = 0.9955393349553934, f1 = 0.9953375228055951\n",
      "Epoch 19: Train Loss = 0.04220831516207497, Recall = 0.9979732468585326, Aging Rate = 0.5006080259424402, Precision = 0.9967611336032388, f1 = 0.9973668219566538\n",
      "Epoch 20: Train Loss = 0.03791938993489399, Recall = 0.9979732468585326, Aging Rate = 0.5, Precision = 0.9979732468585326, f1 = 0.9979732468585326\n",
      "Test Loss = 0.03561408475440042, Recall = 0.9995946493717065, Aging Rate = 0.5014187271990271, precision = 0.9967663702506063\n",
      "Model in epoch 20 is saved.\n",
      "\n",
      "Epoch 21: Train Loss = 0.034828129925519334, Recall = 0.9987839481151196, Aging Rate = 0.5002026753141467, Precision = 0.9983792544570502, f1 = 0.998581560283688\n",
      "Epoch 22: Train Loss = 0.031364792957146934, Recall = 0.9995946493717065, Aging Rate = 0.5004053506282935, Precision = 0.9987849331713244, f1 = 0.999189627228525\n",
      "Epoch 23: Train Loss = 0.028871679318412672, Recall = 0.9995946493717065, Aging Rate = 0.5002026753141467, Precision = 0.9991896272285251, f1 = 0.9993920972644377\n",
      "Epoch 24: Train Loss = 0.02645097729037612, Recall = 0.9995946493717065, Aging Rate = 0.5002026753141467, Precision = 0.9991896272285251, f1 = 0.9993920972644377\n",
      "Epoch 25: Train Loss = 0.024071799323905033, Recall = 0.9995946493717065, Aging Rate = 0.5, Precision = 0.9995946493717065, f1 = 0.9995946493717065\n",
      "Test Loss = 0.022167445014351334, Recall = 1.0, Aging Rate = 0.5002026753141467, precision = 0.9995948136142626\n",
      "Model in epoch 25 is saved.\n",
      "\n",
      "Epoch 26: Train Loss = 0.022179842914858954, Recall = 1.0, Aging Rate = 0.5002026753141467, Precision = 0.9995948136142626, f1 = 0.9997973657548125\n",
      "Epoch 27: Train Loss = 0.020314242945244837, Recall = 1.0, Aging Rate = 0.5002026753141467, Precision = 0.9995948136142626, f1 = 0.9997973657548125\n",
      "Epoch 28: Train Loss = 0.01889274651611267, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 29: Train Loss = 0.017495284151447462, Recall = 1.0, Aging Rate = 0.5002026753141467, Precision = 0.9995948136142626, f1 = 0.9997973657548125\n",
      "Epoch 30: Train Loss = 0.016312839505634523, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.015441948015667138, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "Model in epoch 30 is saved.\n",
      "\n",
      "Epoch 31: Train Loss = 0.0153968144864309, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 32: Train Loss = 0.014352768505566701, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 33: Train Loss = 0.01325778668896602, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 34: Train Loss = 0.012368796107309777, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 35: Train Loss = 0.01176450261449797, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.010952519890136887, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 36: Train Loss = 0.011047868043362467, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 37: Train Loss = 0.01048184356100655, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 38: Train Loss = 0.009985890789134907, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 39: Train Loss = 0.00939372568389376, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 40: Train Loss = 0.008966210987577446, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.008232529130154624, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 41: Train Loss = 0.008427611784348856, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 42: Train Loss = 0.008034533528096893, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 43: Train Loss = 0.0075611399466275295, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 44: Train Loss = 0.007319262418118285, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 45: Train Loss = 0.006917110937796639, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0064800913020195295, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 46: Train Loss = 0.006611877811312325, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 47: Train Loss = 0.00635598586622307, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 48: Train Loss = 0.00605545923518516, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 49: Train Loss = 0.005836813239589104, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 50: Train Loss = 0.005668741166719999, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.005322272344565991, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 51: Train Loss = 0.005386895805153351, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 52: Train Loss = 0.005213363693908527, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 53: Train Loss = 0.005019440265077181, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 54: Train Loss = 0.004895664006320629, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 55: Train Loss = 0.004710509687175889, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.00443227239988252, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 56: Train Loss = 0.004572325819396585, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 57: Train Loss = 0.004429631239844446, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 58: Train Loss = 0.004237384779717023, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 59: Train Loss = 0.004115900671166939, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 60: Train Loss = 0.004021367487294904, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0038026540922767352, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 61: Train Loss = 0.003904503451552307, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 62: Train Loss = 0.003837265027819083, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 63: Train Loss = 0.0036961582780373594, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 64: Train Loss = 0.003619481988094919, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 65: Train Loss = 0.003533226592269174, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.003352587423024961, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 66: Train Loss = 0.003453256877952372, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 67: Train Loss = 0.0033419122458875398, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 68: Train Loss = 0.0032676221294321776, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 69: Train Loss = 0.003222492577853138, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 70: Train Loss = 0.0031591680788604546, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0029994885207474363, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 71: Train Loss = 0.0030661526248976436, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 72: Train Loss = 0.003001668524634309, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 73: Train Loss = 0.002954547974704959, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 74: Train Loss = 0.002892160288069169, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 75: Train Loss = 0.0028664785576776653, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0028080398397200054, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 76: Train Loss = 0.0028612916815548796, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 77: Train Loss = 0.0027450534761787053, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 78: Train Loss = 0.0027022684854842243, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 79: Train Loss = 0.0027068415054553887, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 80: Train Loss = 0.0026338289820834132, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0024617670329848632, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Training Finished at epoch 80.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f5b196f0d2d543bf8a33e2941822eddf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss = 0.6263757279443992, Recall = 0.9602756384272395, Aging Rate = 0.935346574787191, Precision = 0.5133261105092091, f1 = 0.6690200508330979\n",
      "Epoch 2: Train Loss = 0.5064321242342316, Recall = 0.8889339278475882, Aging Rate = 0.6528171868666397, Precision = 0.6808444582427817, f1 = 0.7710970464135022\n",
      "Epoch 3: Train Loss = 0.42615172839570636, Recall = 0.8702877989460883, Aging Rate = 0.5605999189298744, Precision = 0.7762111352133044, f1 = 0.8205618192241545\n",
      "Epoch 4: Train Loss = 0.3745852383491623, Recall = 0.8869071747061208, Aging Rate = 0.5419537900283745, Precision = 0.818249813014211, f1 = 0.8511962653180314\n",
      "Epoch 5: Train Loss = 0.32524371754799386, Recall = 0.9027158492095663, Aging Rate = 0.5301986218078638, Precision = 0.8512996941896025, f1 = 0.8762541806020068\n",
      "Test Loss = 0.28848943424746726, Recall = 0.9420348601540333, Aging Rate = 0.5514795297932712, precision = 0.8540977581771407\n",
      "Model in epoch 5 is saved.\n",
      "\n",
      "Epoch 6: Train Loss = 0.2672881614016675, Recall = 0.9319010944466964, Aging Rate = 0.5190514795297932, Precision = 0.8976962124170246, f1 = 0.9144789180588704\n",
      "Epoch 7: Train Loss = 0.22415588181850926, Recall = 0.9440616132955006, Aging Rate = 0.5083096878800162, Precision = 0.9286283891547049, f1 = 0.9362814070351759\n",
      "Epoch 8: Train Loss = 0.1888930576988981, Recall = 0.9566274827725983, Aging Rate = 0.503040129712201, Precision = 0.9508460918614021, f1 = 0.9537280258638109\n",
      "Epoch 9: Train Loss = 0.1603618641710494, Recall = 0.9671665991082287, Aging Rate = 0.500810701256587, Precision = 0.9656009712666936, f1 = 0.9663831510733091\n",
      "Epoch 10: Train Loss = 0.13632948142123405, Recall = 0.9748682610458046, Aging Rate = 0.500810701256587, Precision = 0.9732901659247268, f1 = 0.9740785743215877\n",
      "Test Loss = 0.12303389034437466, Recall = 0.9874341305229023, Aging Rate = 0.5099310903931901, precision = 0.9682034976152624\n",
      "Model in epoch 10 is saved.\n",
      "\n",
      "Epoch 11: Train Loss = 0.11608408134163369, Recall = 0.9817592217267936, Aging Rate = 0.5022294284556141, Precision = 0.9774011299435028, f1 = 0.9795753286147624\n",
      "Epoch 12: Train Loss = 0.09994152862990874, Recall = 0.9841913254965545, Aging Rate = 0.5004053506282935, Precision = 0.9833940866747671, f1 = 0.9837925445705025\n",
      "Epoch 13: Train Loss = 0.08617951666742237, Recall = 0.9874341305229023, Aging Rate = 0.5002026753141467, Precision = 0.9870340356564019, f1 = 0.9872340425531915\n",
      "Epoch 14: Train Loss = 0.07448321705012849, Recall = 0.9914876368058371, Aging Rate = 0.5, Precision = 0.9914876368058371, f1 = 0.9914876368058371\n",
      "Epoch 15: Train Loss = 0.06526941252041066, Recall = 0.992298338062424, Aging Rate = 0.5002026753141467, Precision = 0.9918962722852512, f1 = 0.9920972644376901\n",
      "Test Loss = 0.05821284341290261, Recall = 0.9955411430887718, Aging Rate = 0.5002026753141467, precision = 0.9951377633711507\n",
      "Model in epoch 15 is saved.\n",
      "\n",
      "Epoch 16: Train Loss = 0.05756194846509051, Recall = 0.9955411430887718, Aging Rate = 0.5, Precision = 0.9955411430887718, f1 = 0.9955411430887718\n",
      "Epoch 17: Train Loss = 0.05079004650215992, Recall = 0.9951357924604783, Aging Rate = 0.5, Precision = 0.9951357924604783, f1 = 0.9951357924604783\n",
      "Epoch 18: Train Loss = 0.045485403190922244, Recall = 0.9967571949736522, Aging Rate = 0.49979732468585325, Precision = 0.9971613949716139, f1 = 0.9969592540036488\n",
      "Epoch 19: Train Loss = 0.0406684424972783, Recall = 0.9979732468585326, Aging Rate = 0.5002026753141467, Precision = 0.9975688816855753, f1 = 0.9977710233029381\n",
      "Epoch 20: Train Loss = 0.03622366893578987, Recall = 0.9987839481151196, Aging Rate = 0.5012160518848804, Precision = 0.9963606955115245, f1 = 0.9975708502024292\n",
      "Test Loss = 0.03280643081382358, Recall = 1.0, Aging Rate = 0.5006080259424402, precision = 0.9987854251012146\n",
      "Model in epoch 20 is saved.\n",
      "\n",
      "Epoch 21: Train Loss = 0.03261323474018401, Recall = 0.9995946493717065, Aging Rate = 0.5006080259424402, Precision = 0.9983805668016195, f1 = 0.9989872392140976\n",
      "Epoch 22: Train Loss = 0.02958900731375549, Recall = 1.0, Aging Rate = 0.5006080259424402, Precision = 0.9987854251012146, f1 = 0.9993923435284586\n",
      "Epoch 23: Train Loss = 0.0271534554155964, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 24: Train Loss = 0.02458236846403888, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 25: Train Loss = 0.023019235861273638, Recall = 0.9995946493717065, Aging Rate = 0.5, Precision = 0.9995946493717065, f1 = 0.9995946493717065\n",
      "Test Loss = 0.020578680920894446, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "Model in epoch 25 is saved.\n",
      "\n",
      "Epoch 26: Train Loss = 0.02062016995385875, Recall = 1.0, Aging Rate = 0.5002026753141467, Precision = 0.9995948136142626, f1 = 0.9997973657548125\n",
      "Epoch 27: Train Loss = 0.019122281238998437, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 28: Train Loss = 0.017621943125381227, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 29: Train Loss = 0.016309843263858766, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 30: Train Loss = 0.015136216438319165, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.014007914611291295, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 31: Train Loss = 0.014170357912180876, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 32: Train Loss = 0.013193348901709492, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 33: Train Loss = 0.012381667777689051, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 34: Train Loss = 0.011638540301938553, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 35: Train Loss = 0.011028067345108443, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.010195463769331146, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 36: Train Loss = 0.010332265575078513, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 37: Train Loss = 0.009772933851572657, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 38: Train Loss = 0.009270218421448737, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 39: Train Loss = 0.008768522512827583, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 40: Train Loss = 0.008428204018300996, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.00780364139972728, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 41: Train Loss = 0.007869650256439868, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 42: Train Loss = 0.007560082521579517, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 43: Train Loss = 0.007156676989174053, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 44: Train Loss = 0.006861586906570816, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 45: Train Loss = 0.006579453621835821, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.006180009469057704, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 46: Train Loss = 0.006311139769861222, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 47: Train Loss = 0.0060641135426595305, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 48: Train Loss = 0.005889722768611448, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 49: Train Loss = 0.005677070812389019, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 50: Train Loss = 0.005423345234974415, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.005071974396637675, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 51: Train Loss = 0.005208558088487877, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 52: Train Loss = 0.004996671508975028, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 53: Train Loss = 0.004853887028952915, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 54: Train Loss = 0.0046605983847940215, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 55: Train Loss = 0.004522053759098113, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.004263446847506148, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 56: Train Loss = 0.004374016499234402, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57: Train Loss = 0.004221982826423285, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 58: Train Loss = 0.004124413759919147, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 59: Train Loss = 0.004038116672685212, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 60: Train Loss = 0.0038967795103197946, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.003765890034074949, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 61: Train Loss = 0.0038187912048830114, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 62: Train Loss = 0.003718917364259124, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 63: Train Loss = 0.0036005843542123617, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 64: Train Loss = 0.0035593552138531042, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 65: Train Loss = 0.0035413516553992387, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0032842150271349606, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 66: Train Loss = 0.0033959645446107536, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 67: Train Loss = 0.0033173433364941662, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 68: Train Loss = 0.0032593670122198575, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 69: Train Loss = 0.0031547171242473204, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 70: Train Loss = 0.0030971038069184924, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0029059000037509356, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 71: Train Loss = 0.003067050107090723, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 72: Train Loss = 0.0029767324056409914, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 73: Train Loss = 0.002926533234358154, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 74: Train Loss = 0.0029125592801953963, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 75: Train Loss = 0.002850503868370173, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0027355999839848892, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Training Finished at epoch 75.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "96bee2e354184666b61062eed0551a1d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss = 0.6147043400802349, Recall = 0.9586542359140656, Aging Rate = 0.9268342115930279, Precision = 0.51716597419637, f1 = 0.671875\n",
      "Epoch 2: Train Loss = 0.48911192973325934, Recall = 0.8982569922983381, Aging Rate = 0.6467369274422375, Precision = 0.6944531494829207, f1 = 0.783315659243549\n",
      "Epoch 3: Train Loss = 0.4084824201038215, Recall = 0.866639643291447, Aging Rate = 0.5496554519659506, Precision = 0.7883480825958702, f1 = 0.8256420158331724\n",
      "Epoch 4: Train Loss = 0.3583768876303436, Recall = 0.8824483177948926, Aging Rate = 0.532428050263478, Precision = 0.8287019413779977, f1 = 0.8547310561444839\n",
      "Epoch 5: Train Loss = 0.3141388546903461, Recall = 0.9014997973246859, Aging Rate = 0.523104985812728, Precision = 0.8616815187911662, f1 = 0.8811410459587955\n",
      "Test Loss = 0.2772139522485227, Recall = 0.9193352249695987, Aging Rate = 0.511552492906364, precision = 0.8985736925515055\n",
      "Model in epoch 5 is saved.\n",
      "\n",
      "Epoch 6: Train Loss = 0.26088971344140266, Recall = 0.9241994325091204, Aging Rate = 0.5135792460478313, Precision = 0.8997632202052092, f1 = 0.9118176364727055\n",
      "Epoch 7: Train Loss = 0.2221248607960219, Recall = 0.9440616132955006, Aging Rate = 0.5089177138224564, Precision = 0.9275189167662286, f1 = 0.9357171554841301\n",
      "Epoch 8: Train Loss = 0.18842601017474547, Recall = 0.954600729631131, Aging Rate = 0.5034454803404945, Precision = 0.9480676328502415, f1 = 0.9513229650575642\n",
      "Epoch 9: Train Loss = 0.15839736477706323, Recall = 0.9671665991082287, Aging Rate = 0.5044588569112282, Precision = 0.9586179188429088, f1 = 0.9628732849071833\n",
      "Epoch 10: Train Loss = 0.13466165012732467, Recall = 0.9740575597892177, Aging Rate = 0.5026347790839076, Precision = 0.9689516129032258, f1 = 0.9714978775015162\n",
      "Test Loss = 0.12060337695193088, Recall = 0.9720308066477503, Aging Rate = 0.49412241588974465, precision = 0.9835931091058244\n",
      "Model in epoch 10 is saved.\n",
      "\n",
      "Epoch 11: Train Loss = 0.11517615696656158, Recall = 0.9809485204702068, Aging Rate = 0.5032428050263478, Precision = 0.9746274667740636, f1 = 0.9777777777777779\n",
      "Epoch 12: Train Loss = 0.09778585971416516, Recall = 0.9878394811511958, Aging Rate = 0.503040129712201, Precision = 0.9818694601128123, f1 = 0.9848454233178421\n",
      "Epoch 13: Train Loss = 0.08508019622552719, Recall = 0.9894608836643697, Aging Rate = 0.5006080259424402, Precision = 0.9882591093117409, f1 = 0.9888596313550739\n",
      "Epoch 14: Train Loss = 0.0737003160132466, Recall = 0.9898662342926632, Aging Rate = 0.4995946493717065, Precision = 0.9906693711967546, f1 = 0.9902676399026764\n",
      "Epoch 15: Train Loss = 0.06419280561741954, Recall = 0.9955411430887718, Aging Rate = 0.5010133765707336, Precision = 0.9935275080906149, f1 = 0.9945333063373152\n",
      "Test Loss = 0.05790564699161135, Recall = 0.9975678962302391, Aging Rate = 0.5012160518848804, precision = 0.9951475940153659\n",
      "Model in epoch 15 is saved.\n",
      "\n",
      "Epoch 16: Train Loss = 0.05674967744939231, Recall = 0.9971625456019457, Aging Rate = 0.5014187271990271, Precision = 0.994341147938561, f1 = 0.9957498482088646\n",
      "Epoch 17: Train Loss = 0.05076018140402505, Recall = 0.9975678962302391, Aging Rate = 0.5012160518848804, Precision = 0.9951475940153659, f1 = 0.9963562753036437\n",
      "Epoch 18: Train Loss = 0.04500440780691014, Recall = 0.9983785974868261, Aging Rate = 0.5002026753141467, Precision = 0.9979740680713128, f1 = 0.998176291793313\n",
      "Epoch 19: Train Loss = 0.03988406928139125, Recall = 0.9995946493717065, Aging Rate = 0.5010133765707336, Precision = 0.9975728155339806, f1 = 0.9985827090504151\n",
      "Epoch 20: Train Loss = 0.03565065373817967, Recall = 0.999189298743413, Aging Rate = 0.5004053506282935, Precision = 0.9983799108950993, f1 = 0.9987844408427877\n",
      "Test Loss = 0.033838518858590155, Recall = 1.0, Aging Rate = 0.5014187271990271, precision = 0.9971705739692805\n",
      "Model in epoch 20 is saved.\n",
      "\n",
      "Epoch 21: Train Loss = 0.03248625137228979, Recall = 1.0, Aging Rate = 0.500810701256587, Precision = 0.9983812221772562, f1 = 0.9991899554475496\n",
      "Epoch 22: Train Loss = 0.029161201789975166, Recall = 1.0, Aging Rate = 0.500810701256587, Precision = 0.9983812221772562, f1 = 0.9991899554475496\n",
      "Epoch 23: Train Loss = 0.02662906672067134, Recall = 1.0, Aging Rate = 0.5006080259424402, Precision = 0.9987854251012146, f1 = 0.9993923435284586\n",
      "Epoch 24: Train Loss = 0.025075565720068378, Recall = 1.0, Aging Rate = 0.500810701256587, Precision = 0.9983812221772562, f1 = 0.9991899554475496\n",
      "Epoch 25: Train Loss = 0.022233119171775687, Recall = 1.0, Aging Rate = 0.5004053506282935, Precision = 0.9991899554475496, f1 = 0.9995948136142626\n",
      "Test Loss = 0.0202675582044488, Recall = 1.0, Aging Rate = 0.5002026753141467, precision = 0.9995948136142626\n",
      "Model in epoch 25 is saved.\n",
      "\n",
      "Epoch 26: Train Loss = 0.020686446703037223, Recall = 1.0, Aging Rate = 0.5004053506282935, Precision = 0.9991899554475496, f1 = 0.9995948136142626\n",
      "Epoch 27: Train Loss = 0.018897198898665663, Recall = 1.0, Aging Rate = 0.5006080259424402, Precision = 0.9987854251012146, f1 = 0.9993923435284586\n",
      "Epoch 28: Train Loss = 0.017351054845821, Recall = 1.0, Aging Rate = 0.5002026753141467, Precision = 0.9995948136142626, f1 = 0.9997973657548125\n",
      "Epoch 29: Train Loss = 0.016113996874189202, Recall = 1.0, Aging Rate = 0.5002026753141467, Precision = 0.9995948136142626, f1 = 0.9997973657548125\n",
      "Epoch 30: Train Loss = 0.01504750457378259, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.01394120436637422, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "Model in epoch 30 is saved.\n",
      "\n",
      "Epoch 31: Train Loss = 0.013952662172811473, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 32: Train Loss = 0.013042000663343305, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 33: Train Loss = 0.012223819125765338, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 34: Train Loss = 0.011624428587442812, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 35: Train Loss = 0.010799715735613212, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.010139603969985698, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 36: Train Loss = 0.010188666074172441, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 37: Train Loss = 0.009503522507482433, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 38: Train Loss = 0.009051602601062735, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 39: Train Loss = 0.008663616777765011, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 40: Train Loss = 0.008194108872742736, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0076229261830116895, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 41: Train Loss = 0.007691891619503003, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 42: Train Loss = 0.007348468049267405, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 43: Train Loss = 0.007148707830839774, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 44: Train Loss = 0.006790269757981514, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 45: Train Loss = 0.0063182660469118645, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.006020525710473768, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 46: Train Loss = 0.006162865837317913, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 47: Train Loss = 0.0058504852134452015, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 48: Train Loss = 0.005691389286914031, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 49: Train Loss = 0.005362713169536799, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 50: Train Loss = 0.005204691067088832, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.004893761392964793, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 51: Train Loss = 0.00498657527500118, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 52: Train Loss = 0.004847849666940922, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 53: Train Loss = 0.004632537566913638, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 54: Train Loss = 0.004455546411883084, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 55: Train Loss = 0.004363124513825727, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.004102262925019886, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 56: Train Loss = 0.004190882084642797, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57: Train Loss = 0.004110282641674313, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 58: Train Loss = 0.00398089745354525, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 59: Train Loss = 0.003832935483769084, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 60: Train Loss = 0.0037559672315609894, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0035308508865344993, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 61: Train Loss = 0.0036474878057523395, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 62: Train Loss = 0.003593495293257265, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 63: Train Loss = 0.003451458506990582, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 64: Train Loss = 0.003441569133936139, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 65: Train Loss = 0.00332586740433904, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.003130447487454419, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 66: Train Loss = 0.003224085581711262, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 67: Train Loss = 0.0031373116779879165, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 68: Train Loss = 0.0030668275758290358, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 69: Train Loss = 0.003029527730052897, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 70: Train Loss = 0.0029466914730867577, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0028006102035466143, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 71: Train Loss = 0.0029256009554507814, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 72: Train Loss = 0.0028475778131890343, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 73: Train Loss = 0.002788660835182535, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 74: Train Loss = 0.0027657469569765452, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 75: Train Loss = 0.0027113535164364276, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.002557550108378861, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 76: Train Loss = 0.0026727421476305992, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 77: Train Loss = 0.0026148020691511287, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 78: Train Loss = 0.0026545238547687, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 79: Train Loss = 0.002540333662370849, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 80: Train Loss = 0.002512469753999766, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0023964846159026092, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Training Finished at epoch 80.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2172b2c7ca30433a82b8a455f0f6b9cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss = 0.6431721568977393, Recall = 0.8694770976895014, Aging Rate = 0.840494527766518, Precision = 0.5172413793103449, f1 = 0.6486241306319928\n",
      "Epoch 2: Train Loss = 0.5329432705659638, Recall = 0.8881232265910012, Aging Rate = 0.6888933927847588, Precision = 0.6446013533392174, f1 = 0.747016706443914\n",
      "Epoch 3: Train Loss = 0.45843236754188954, Recall = 0.8471828131333603, Aging Rate = 0.5717470612079448, Precision = 0.7408720311946119, f1 = 0.7904689863842663\n",
      "Epoch 4: Train Loss = 0.40836535037216215, Recall = 0.8751520064856101, Aging Rate = 0.5638427239562221, Precision = 0.776060388209921, f1 = 0.8226328824538007\n",
      "Epoch 5: Train Loss = 0.3621607103906376, Recall = 0.8856911228212404, Aging Rate = 0.5407377381434941, Precision = 0.8189655172413793, f1 = 0.8510223953261927\n",
      "Test Loss = 0.3223081472362639, Recall = 0.9027158492095663, Aging Rate = 0.5229023104985813, precision = 0.8631782945736434\n",
      "Model in epoch 5 is saved.\n",
      "\n",
      "Epoch 6: Train Loss = 0.3028688879935037, Recall = 0.9092014592622618, Aging Rate = 0.5214835832995541, Precision = 0.8717450446949087, f1 = 0.8900793650793651\n",
      "Epoch 7: Train Loss = 0.258100461624004, Recall = 0.9286582894203486, Aging Rate = 0.5156059991892987, Precision = 0.9005503144654088, f1 = 0.9143883456395928\n",
      "Epoch 8: Train Loss = 0.21930413427723047, Recall = 0.9440616132955006, Aging Rate = 0.5089177138224564, Precision = 0.9275189167662286, f1 = 0.9357171554841301\n",
      "Epoch 9: Train Loss = 0.18687036072357396, Recall = 0.9582488852857722, Aging Rate = 0.5083096878800162, Precision = 0.9425837320574163, f1 = 0.9503517587939699\n",
      "Epoch 10: Train Loss = 0.15981323009543347, Recall = 0.9659505472233482, Aging Rate = 0.5048642075395217, Precision = 0.9566439181051787, f1 = 0.9612747075433642\n",
      "Test Loss = 0.14444091358574287, Recall = 0.9679773003648156, Aging Rate = 0.4973652209160924, precision = 0.9731051344743277\n",
      "Model in epoch 10 is saved.\n",
      "\n",
      "Epoch 11: Train Loss = 0.13726584593994587, Recall = 0.977705715443859, Aging Rate = 0.5048642075395217, Precision = 0.9682858289843437, f1 = 0.9729729729729729\n",
      "Epoch 12: Train Loss = 0.11921746230313882, Recall = 0.9801378192136198, Aging Rate = 0.5024321037697609, Precision = 0.9753933037515127, f1 = 0.9777598059037605\n",
      "Epoch 13: Train Loss = 0.10413701430319483, Recall = 0.9870287798946088, Aging Rate = 0.5064856100526955, Precision = 0.974389755902361, f1 = 0.9806685461135723\n",
      "Epoch 14: Train Loss = 0.09101667401335913, Recall = 0.9894608836643697, Aging Rate = 0.5040535062829348, Precision = 0.981503819863289, f1 = 0.9854662898667743\n",
      "Epoch 15: Train Loss = 0.07961915587129793, Recall = 0.9918929874341306, Aging Rate = 0.5024321037697609, Precision = 0.9870915691811214, f1 = 0.9894864536999596\n",
      "Test Loss = 0.07214087718379705, Recall = 0.9951357924604783, Aging Rate = 0.5032428050263478, precision = 0.9887233185662505\n",
      "Model in epoch 15 is saved.\n",
      "\n",
      "Epoch 16: Train Loss = 0.07054265654209078, Recall = 0.9947304418321848, Aging Rate = 0.5018240778273206, Precision = 0.9911147011308562, f1 = 0.9929192797896015\n",
      "Epoch 17: Train Loss = 0.0633216569291516, Recall = 0.9935143899473045, Aging Rate = 0.49878394811511956, Precision = 0.9959366111336855, f1 = 0.994724025974026\n",
      "Epoch 18: Train Loss = 0.0561376714215957, Recall = 0.9963518443453587, Aging Rate = 0.5006080259424402, Precision = 0.9951417004048583, f1 = 0.9957464046992099\n",
      "Epoch 19: Train Loss = 0.05026652367674585, Recall = 0.9967571949736522, Aging Rate = 0.5004053506282935, Precision = 0.995949777237748, f1 = 0.9963533225283631\n",
      "Epoch 20: Train Loss = 0.045879770533899376, Recall = 0.9979732468585326, Aging Rate = 0.5, Precision = 0.9979732468585326, f1 = 0.9979732468585326\n",
      "Test Loss = 0.04139971318282867, Recall = 0.9987839481151196, Aging Rate = 0.49979732468585325, precision = 0.9991889699918897\n",
      "Model in epoch 20 is saved.\n",
      "\n",
      "Epoch 21: Train Loss = 0.04082766017469985, Recall = 0.9995946493717065, Aging Rate = 0.5012160518848804, Precision = 0.9971694298422968, f1 = 0.9983805668016195\n",
      "Epoch 22: Train Loss = 0.0370165802912887, Recall = 0.999189298743413, Aging Rate = 0.5002026753141467, Precision = 0.9987844408427877, f1 = 0.9989868287740629\n",
      "Epoch 23: Train Loss = 0.03358573850846793, Recall = 1.0, Aging Rate = 0.5004053506282935, Precision = 0.9991899554475496, f1 = 0.9995948136142626\n",
      "Epoch 24: Train Loss = 0.030857827863986307, Recall = 1.0, Aging Rate = 0.5002026753141467, Precision = 0.9995948136142626, f1 = 0.9997973657548125\n",
      "Epoch 25: Train Loss = 0.028198066778725633, Recall = 1.0, Aging Rate = 0.5002026753141467, Precision = 0.9995948136142626, f1 = 0.9997973657548125\n",
      "Test Loss = 0.025885428765952515, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "Model in epoch 25 is saved.\n",
      "\n",
      "Epoch 26: Train Loss = 0.025978680342937172, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 27: Train Loss = 0.023747620194316827, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 28: Train Loss = 0.022208760271659012, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 29: Train Loss = 0.020249945518153373, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 30: Train Loss = 0.018880464828957853, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.017704457539897436, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 31: Train Loss = 0.01768891732757711, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 32: Train Loss = 0.016670011110410523, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 33: Train Loss = 0.015498085606603136, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 34: Train Loss = 0.014433705591474727, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 35: Train Loss = 0.01343855814707028, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.01251544161459237, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 36: Train Loss = 0.012691645931722811, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 37: Train Loss = 0.012034922747985646, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 38: Train Loss = 0.011392822412884956, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 39: Train Loss = 0.010792554711774264, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 40: Train Loss = 0.010076904299064571, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.009366249633718163, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 41: Train Loss = 0.009454081290641994, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 42: Train Loss = 0.00908245268324258, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 43: Train Loss = 0.008630915066241663, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 44: Train Loss = 0.008243613282953215, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 45: Train Loss = 0.0077798468157812125, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.007292329966055511, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 46: Train Loss = 0.007448539242033636, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 47: Train Loss = 0.007054073306840226, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 48: Train Loss = 0.006751921562833563, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 49: Train Loss = 0.006533401797026891, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 50: Train Loss = 0.006275712033748071, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.005868947867494353, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 51: Train Loss = 0.006001700347808145, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 52: Train Loss = 0.005726846708887059, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 53: Train Loss = 0.00553847486277824, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 54: Train Loss = 0.005343674791370525, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 55: Train Loss = 0.00516743595452536, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.004908874855170281, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 56: Train Loss = 0.004981337117244889, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 57: Train Loss = 0.004800957283114597, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58: Train Loss = 0.004705725373961877, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 59: Train Loss = 0.0045540558601218795, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 60: Train Loss = 0.004376803024211029, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.004169947760127542, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 61: Train Loss = 0.0042291798444451965, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 62: Train Loss = 0.004152214754232023, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 63: Train Loss = 0.0040120104749479, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 64: Train Loss = 0.003909117701139874, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 65: Train Loss = 0.003775454293347572, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.003578236701492074, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 66: Train Loss = 0.0036983789918007253, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 67: Train Loss = 0.003606508269847152, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 68: Train Loss = 0.00350048026055087, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 69: Train Loss = 0.0034192935242738543, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 70: Train Loss = 0.0033799943779936844, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0031994841303895323, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 71: Train Loss = 0.0032824401419615824, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 72: Train Loss = 0.003187595358961022, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 73: Train Loss = 0.0031529308427359275, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 74: Train Loss = 0.003053659583390194, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 75: Train Loss = 0.003026282869035512, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0028901359117897564, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Training Finished at epoch 75.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3895d26d996947d88b45eb3c57f17849",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss = 0.3546922748343871, Recall = 0.8691247974068071, Aging Rate = 0.5467990275526742, Precision = 0.794738792145239, f1 = 0.8302690149022643\n",
      "Epoch 2: Train Loss = 0.13193076687775904, Recall = 0.9562398703403565, Aging Rate = 0.5024311183144247, Precision = 0.9516129032258065, f1 = 0.9539207760711399\n",
      "Epoch 3: Train Loss = 0.08085913683862894, Recall = 0.9740680713128039, Aging Rate = 0.4989870340356564, Precision = 0.976045473000406, f1 = 0.9750557696207666\n",
      "Epoch 4: Train Loss = 0.06248744703358344, Recall = 0.9793354943273906, Aging Rate = 0.5, Precision = 0.9793354943273906, f1 = 0.9793354943273906\n",
      "Epoch 5: Train Loss = 0.05564468389911339, Recall = 0.9809562398703403, Aging Rate = 0.5012155591572123, Precision = 0.9785772029102667, f1 = 0.9797652772157021\n",
      "Test Loss = 0.01560555734162972, Recall = 0.9983792544570502, Aging Rate = 0.4997974068071313, precision = 0.9987839481151196\n",
      "Model in epoch 5 is saved.\n",
      "\n",
      "Epoch 6: Train Loss = 0.011510769341131929, Recall = 0.9979740680713128, Aging Rate = 0.49959481361426256, Precision = 0.9987834549878345, f1 = 0.9983785974868261\n",
      "Epoch 7: Train Loss = 0.004382285025945819, Recall = 0.9995948136142626, Aging Rate = 0.4997974068071313, Precision = 0, f1 = 0.0\n",
      "Epoch 8: Train Loss = 0.0027586124240038873, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 9: Train Loss = 0.002069144031995941, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 10: Train Loss = 0.001894276533023012, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0016171948214829862, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "Model in epoch 10 is saved.\n",
      "\n",
      "Epoch 11: Train Loss = 0.0022655279257499297, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 12: Train Loss = 0.0020504259973058003, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 13: Train Loss = 0.0019459276174450205, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 14: Train Loss = 0.0031295109689658328, Recall = 1.0, Aging Rate = 0.5002025931928687, Precision = 0.9995949777237748, f1 = 0.9997974478428194\n",
      "Epoch 15: Train Loss = 0.0941294603782964, Recall = 0.9708265802269044, Aging Rate = 0.5076985413290114, Precision = 0.9561053471667997, f1 = 0.9634097305991153\n",
      "Test Loss = 0.036062984864870494, Recall = 0.9959481361426256, Aging Rate = 0.5093192868719612, precision = 0.9777247414478918\n",
      "\n",
      "Epoch 16: Train Loss = 0.03362346130477588, Recall = 0.9886547811993517, Aging Rate = 0.501418152350081, Precision = 0.9858585858585859, f1 = 0.9872547036212825\n",
      "Epoch 17: Train Loss = 0.010579317282301161, Recall = 0.997163695299838, Aging Rate = 0.4997974068071313, Precision = 0.9975678962302391, f1 = 0.9973657548125633\n",
      "Epoch 18: Train Loss = 0.016040322921205632, Recall = 0.9955429497568882, Aging Rate = 0.5010129659643436, Precision = 0.9935301253538212, f1 = 0.9945355191256829\n",
      "Epoch 19: Train Loss = 0.003283560739334286, Recall = 0.9995948136142626, Aging Rate = 0.4997974068071313, Precision = 0, f1 = 0.0\n",
      "Epoch 20: Train Loss = 0.0011235198074052899, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0008879336044988542, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 21: Train Loss = 0.000986060329880475, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 22: Train Loss = 0.0011016240300432548, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 23: Train Loss = 0.0012279808029477337, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 24: Train Loss = 0.0014227479515141375, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 25: Train Loss = 0.001566247656549715, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.001293447143186904, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 26: Train Loss = 0.0016529792110319438, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 27: Train Loss = 0.0025861607192799664, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 28: Train Loss = 0.09021280853929092, Recall = 0.9688006482982172, Aging Rate = 0.5042544570502431, Precision = 0.9606267577340297, f1 = 0.9646963889449264\n",
      "Epoch 29: Train Loss = 0.024610000443637276, Recall = 0.9927066450567261, Aging Rate = 0.5002025931928687, Precision = 0.9923045767517213, f1 = 0.9925055701843225\n",
      "Epoch 30: Train Loss = 0.011583888452693312, Recall = 0.997163695299838, Aging Rate = 0.5002025931928687, Precision = 0.9967598217901985, f1 = 0.9969617176422929\n",
      "Test Loss = 0.003953236021909778, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 31: Train Loss = 0.003863989296097556, Recall = 0.9995948136142626, Aging Rate = 0.5, Precision = 0.9995948136142626, f1 = 0.9995948136142626\n",
      "Epoch 32: Train Loss = 0.0018413249436540248, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 33: Train Loss = 0.0011549049074613645, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 34: Train Loss = 0.0010826363420313734, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 35: Train Loss = 0.001196269178763032, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0011689410242289788, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 36: Train Loss = 0.0014216580754221452, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 37: Train Loss = 0.001781763239670092, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 38: Train Loss = 0.0029654342781547066, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 39: Train Loss = 0.030324061625717113, Recall = 0.9931118314424635, Aging Rate = 0.5032414910858996, Precision = 0.9867149758454107, f1 = 0.989903069466882\n",
      "Epoch 40: Train Loss = 0.04885809862876018, Recall = 0.9837925445705025, Aging Rate = 0.5012155591572123, Precision = 0.9814066289409863, f1 = 0.9825981384055039\n",
      "Test Loss = 0.015070056087281585, Recall = 0.9943273905996759, Aging Rate = 0.49878444084278767, precision = 0.9967506092607636\n",
      "\n",
      "Epoch 41: Train Loss = 0.022704465864652638, Recall = 0.9927066450567261, Aging Rate = 0.5006077795786061, Precision = 0.9915014164305949, f1 = 0.9921036647094553\n",
      "Epoch 42: Train Loss = 0.004416622908216504, Recall = 0.9991896272285251, Aging Rate = 0.5002025931928687, Precision = 0.9987849331713244, f1 = 0.9989872392140976\n",
      "Epoch 43: Train Loss = 0.0013293173299789899, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 44: Train Loss = 0.0010165326463368403, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 45: Train Loss = 0.001063306491411013, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0009493726648871803, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 46: Train Loss = 0.0011582425412475894, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 47: Train Loss = 0.0013846261258881594, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 48: Train Loss = 0.0014345555494930384, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 49: Train Loss = 0.001622761084246819, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 50: Train Loss = 0.0019379056938448422, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0015507246919709893, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 51: Train Loss = 0.0019543533712682863, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 52: Train Loss = 0.002018522844020416, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 53: Train Loss = 0.07378254182760512, Recall = 0.976904376012966, Aging Rate = 0.5046596434359806, Precision = 0.9678843837816138, f1 = 0.9723734623916113\n",
      "Epoch 54: Train Loss = 0.025671396799977247, Recall = 0.9923014586709886, Aging Rate = 0.5012155591572123, Precision = 0.9898949070331448, f1 = 0.9910967219749091\n",
      "Epoch 55: Train Loss = 0.012474914203093023, Recall = 0.9951377633711507, Aging Rate = 0.4991896272285251, Precision = 0.9967532467532467, f1 = 0.9959448499594484\n",
      "Test Loss = 0.007241527502045014, Recall = 0.9983792544570502, Aging Rate = 0.4997974068071313, precision = 0.9987839481151196\n",
      "\n",
      "Epoch 56: Train Loss = 0.005292335367088721, Recall = 0.9987844408427877, Aging Rate = 0.5, Precision = 0.9987844408427877, f1 = 0.9987844408427877\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57: Train Loss = 0.0016139945973992359, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 58: Train Loss = 0.0012059138712889818, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 59: Train Loss = 0.0010594283062677885, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 60: Train Loss = 0.0012441918790126083, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.001152238976308469, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Training Finished at epoch 60.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b313fad0d7e400a9090da2ebb5fb67e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss = 0.35896273721107647, Recall = 0.8694770976895014, Aging Rate = 0.5407377381434941, Precision = 0.8039730134932533, f1 = 0.8354430379746836\n",
      "Epoch 2: Train Loss = 0.15206863216068225, Recall = 0.9481151195784353, Aging Rate = 0.5040535062829348, Precision = 0.9404905508644954, f1 = 0.9442874444893016\n",
      "Epoch 3: Train Loss = 0.09415445457743786, Recall = 0.9704094041345764, Aging Rate = 0.5016214025131739, Precision = 0.9672727272727273, f1 = 0.9688385269121812\n",
      "Epoch 4: Train Loss = 0.06614211988403192, Recall = 0.9781110660721524, Aging Rate = 0.4993919740575598, Precision = 0.979301948051948, f1 = 0.9787061447982154\n",
      "Epoch 5: Train Loss = 0.06381328323652895, Recall = 0.9781110660721524, Aging Rate = 0.49979732468585325, Precision = 0.9785077047850771, f1 = 0.9783093452260287\n",
      "Test Loss = 0.02023094177040727, Recall = 0.9987839481151196, Aging Rate = 0.5020267531414674, precision = 0.994751715785224\n",
      "Model in epoch 5 is saved.\n",
      "\n",
      "Epoch 6: Train Loss = 0.013013927503551247, Recall = 0.9983785974868261, Aging Rate = 0.5004053506282935, Precision = 0.9975698663426489, f1 = 0.9979740680713128\n",
      "Epoch 7: Train Loss = 0.004697882664117463, Recall = 1.0, Aging Rate = 0.5002026753141467, Precision = 0.9995948136142626, f1 = 0.9997973657548125\n",
      "Epoch 8: Train Loss = 0.003017989769307115, Recall = 0.9995946493717065, Aging Rate = 0.49979732468585325, Precision = 0, f1 = 0.0\n",
      "Epoch 9: Train Loss = 0.0020293916203430805, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 10: Train Loss = 0.0018782638751210462, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0015645128053372909, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "Model in epoch 10 is saved.\n",
      "\n",
      "Epoch 11: Train Loss = 0.001962650484051729, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 12: Train Loss = 0.0021071221379940345, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 13: Train Loss = 0.002042292898142277, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 14: Train Loss = 0.0020970615062275225, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 15: Train Loss = 0.0026821927666735097, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.002563753177856941, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 16: Train Loss = 0.08215955984458288, Recall = 0.9752736116740981, Aging Rate = 0.5048642075395217, Precision = 0.9658771577679647, f1 = 0.9705526421944333\n",
      "Epoch 17: Train Loss = 0.03957558716711504, Recall = 0.9878394811511958, Aging Rate = 0.5026347790839076, Precision = 0.9826612903225806, f1 = 0.9852435819688701\n",
      "Epoch 18: Train Loss = 0.016430049124577756, Recall = 0.9955411430887718, Aging Rate = 0.500810701256587, Precision = 0.9939295831647107, f1 = 0.9947347104090726\n",
      "Epoch 19: Train Loss = 0.00816732210254, Recall = 0.9975678962302391, Aging Rate = 0.49979732468585325, Precision = 0.9979724249797243, f1 = 0.9977701196026758\n",
      "Epoch 20: Train Loss = 0.0033772036044594704, Recall = 0.9995946493717065, Aging Rate = 0.5, Precision = 0.9995946493717065, f1 = 0.9995946493717065\n",
      "Test Loss = 0.001127651478306409, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 21: Train Loss = 0.0009784996885648521, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 22: Train Loss = 0.0009077793924354264, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 23: Train Loss = 0.0010098926983722744, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 24: Train Loss = 0.001157037766829071, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 25: Train Loss = 0.0013566389395830828, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0011535622971575975, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 26: Train Loss = 0.0015294490903325266, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 27: Train Loss = 0.0016187723454591102, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 28: Train Loss = 0.0018573632526409068, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 29: Train Loss = 0.00206838114886156, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 30: Train Loss = 0.06928049592764127, Recall = 0.9797324685853263, Aging Rate = 0.5064856100526955, Precision = 0.9671868747499, f1 = 0.9734192509061619\n",
      "Test Loss = 0.044533732939507006, Recall = 0.9789217673287394, Aging Rate = 0.49635184434535873, precision = 0.986116782360147\n",
      "\n",
      "Epoch 31: Train Loss = 0.03719767658848747, Recall = 0.9882448317794893, Aging Rate = 0.500810701256587, Precision = 0.9866450829623634, f1 = 0.9874443094370191\n",
      "Epoch 32: Train Loss = 0.016235123490904793, Recall = 0.9947304418321848, Aging Rate = 0.5006080259424402, Precision = 0.9935222672064777, f1 = 0.9941259874417663\n",
      "Epoch 33: Train Loss = 0.00456239832119724, Recall = 0.9995946493717065, Aging Rate = 0.5004053506282935, Precision = 0.9987849331713244, f1 = 0.999189627228525\n",
      "Epoch 34: Train Loss = 0.001790674936109293, Recall = 1.0, Aging Rate = 0.5002026753141467, Precision = 0.9995948136142626, f1 = 0.9997973657548125\n",
      "Epoch 35: Train Loss = 0.0010581413809818611, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0009056708898529694, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 36: Train Loss = 0.0010770629237968072, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 37: Train Loss = 0.001216946781067805, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 38: Train Loss = 0.0014236515265578773, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 39: Train Loss = 0.0016070046385861163, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 40: Train Loss = 0.0015886506681023962, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0014839232792955323, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 41: Train Loss = 0.0017643209898976114, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 42: Train Loss = 0.0022914598528507163, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 43: Train Loss = 0.010943242368927466, Recall = 0.9979732468585326, Aging Rate = 0.5016214025131739, Precision = 0.9947474747474747, f1 = 0.9963577498988264\n",
      "Epoch 44: Train Loss = 0.10427574099112871, Recall = 0.9679773003648156, Aging Rate = 0.5034454803404945, Precision = 0.961352657004831, f1 = 0.9646536053322562\n",
      "Epoch 45: Train Loss = 0.01832685907785473, Recall = 0.9959464937170652, Aging Rate = 0.500810701256587, Precision = 0.9943342776203966, f1 = 0.9951397326852978\n",
      "Test Loss = 0.007377305299868142, Recall = 0.9983785974868261, Aging Rate = 0.500810701256587, precision = 0.9967624443545123\n",
      "\n",
      "Epoch 46: Train Loss = 0.009144785787584996, Recall = 0.9971625456019457, Aging Rate = 0.49918929874341306, Precision = 0.9987819732034104, f1 = 0.997971602434077\n",
      "Epoch 47: Train Loss = 0.0022484201787475286, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 48: Train Loss = 0.0013401796398582453, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 49: Train Loss = 0.0011185678711650273, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 50: Train Loss = 0.0011951777234448502, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0011533468130044545, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 51: Train Loss = 0.0013700434495440114, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 52: Train Loss = 0.0014493246195648344, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 53: Train Loss = 0.001601272646562745, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 54: Train Loss = 0.0017379978785012097, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 55: Train Loss = 0.0019175481681368814, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.002219544979394461, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 56: Train Loss = 0.006495067806152629, Recall = 0.999189298743413, Aging Rate = 0.500810701256587, Precision = 0.9975718332658843, f1 = 0.9983799108950991\n",
      "Epoch 57: Train Loss = 0.08498450764384118, Recall = 0.9704094041345764, Aging Rate = 0.5018240778273206, Precision = 0.9668820678513732, f1 = 0.9686425247825208\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58: Train Loss = 0.022216981127953013, Recall = 0.9927036886907175, Aging Rate = 0.5002026753141467, Precision = 0.9923014586709886, f1 = 0.9925025329280649\n",
      "Epoch 59: Train Loss = 0.004716531732385766, Recall = 0.999189298743413, Aging Rate = 0.49979732468585325, Precision = 0.9995944849959448, f1 = 0.9993918508007297\n",
      "Epoch 60: Train Loss = 0.0016285179628976717, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0010605628979978438, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Training Finished at epoch 60.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "885b7254164e425ebf756389de7467aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss = 0.3652486837751043, Recall = 0.8731252533441427, Aging Rate = 0.5460072963113093, Precision = 0.799554565701559, f1 = 0.8347219531098624\n",
      "Epoch 2: Train Loss = 0.1563977993568719, Recall = 0.9448723145520875, Aging Rate = 0.5022294284556141, Precision = 0.940677966101695, f1 = 0.9427704752275026\n",
      "Epoch 3: Train Loss = 0.0874277647527295, Recall = 0.9687880016214026, Aging Rate = 0.5004053506282935, Precision = 0.9680032401782098, f1 = 0.9683954619124798\n",
      "Epoch 4: Train Loss = 0.08201459182760809, Recall = 0.9736522091609242, Aging Rate = 0.5010133765707336, Precision = 0.9716828478964401, f1 = 0.9726665316865762\n",
      "Epoch 5: Train Loss = 0.06175243248238127, Recall = 0.9797324685853263, Aging Rate = 0.5002026753141467, Precision = 0.9793354943273906, f1 = 0.979533941236069\n",
      "Test Loss = 0.02367403629727822, Recall = 0.9983785974868261, Aging Rate = 0.5016214025131739, precision = 0.9951515151515151\n",
      "Model in epoch 5 is saved.\n",
      "\n",
      "Epoch 6: Train Loss = 0.0166991339187826, Recall = 0.9951357924604783, Aging Rate = 0.4993919740575598, Precision = 0.9963474025974026, f1 = 0.995741228959643\n",
      "Epoch 7: Train Loss = 0.009233298800571587, Recall = 0.9979732468585326, Aging Rate = 0.49979732468585325, Precision = 0.9983779399837794, f1 = 0.9981755524021894\n",
      "Epoch 8: Train Loss = 0.0033684652416661447, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 9: Train Loss = 0.0021592338541526397, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 10: Train Loss = 0.0021298850254922235, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0016680752654568594, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "Model in epoch 10 is saved.\n",
      "\n",
      "Epoch 11: Train Loss = 0.0019192794371207737, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 12: Train Loss = 0.0018919629654890499, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 13: Train Loss = 0.002098127715130389, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 14: Train Loss = 0.0020899071810592646, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 15: Train Loss = 0.0022929142917794063, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.002726906795562617, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 16: Train Loss = 0.05419821684548112, Recall = 0.984596676124848, Aging Rate = 0.5034454803404945, Precision = 0.9778582930756844, f1 = 0.9812159159765704\n",
      "Epoch 17: Train Loss = 0.04508499989920899, Recall = 0.9854073773814349, Aging Rate = 0.5012160518848804, Precision = 0.9830165790537808, f1 = 0.9842105263157894\n",
      "Epoch 18: Train Loss = 0.02441404177250441, Recall = 0.9918929874341306, Aging Rate = 0.500810701256587, Precision = 0.990287333063537, f1 = 0.9910895099230458\n",
      "Epoch 19: Train Loss = 0.011702626871742968, Recall = 0.9963518443453587, Aging Rate = 0.49979732468585325, Precision = 0.9967558799675588, f1 = 0.9965538212041355\n",
      "Epoch 20: Train Loss = 0.006352993909682569, Recall = 0.9979732468585326, Aging Rate = 0.49979732468585325, Precision = 0.9983779399837794, f1 = 0.9981755524021894\n",
      "Test Loss = 0.00414929874379498, Recall = 1.0, Aging Rate = 0.5006080259424402, precision = 0.9987854251012146\n",
      "\n",
      "Epoch 21: Train Loss = 0.0019512224933857353, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 22: Train Loss = 0.0009565642180706872, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 23: Train Loss = 0.0009202964647527162, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 24: Train Loss = 0.0010118872341769738, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 25: Train Loss = 0.001189434624942043, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0010471384682404546, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 26: Train Loss = 0.0013434718228781458, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 27: Train Loss = 0.0015127054245125677, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 28: Train Loss = 0.0017783186412202161, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 29: Train Loss = 0.001917095313525944, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 30: Train Loss = 0.0019423847241885129, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.001916677838980013, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 31: Train Loss = 0.05939087015472845, Recall = 0.9805431698419133, Aging Rate = 0.5020267531414674, Precision = 0.9765845781186919, f1 = 0.9785598705501617\n",
      "Epoch 32: Train Loss = 0.06889363811217342, Recall = 0.9781110660721524, Aging Rate = 0.503040129712201, Precision = 0.9721998388396454, f1 = 0.9751464942412609\n",
      "Epoch 33: Train Loss = 0.011368775865977405, Recall = 0.9975678962302391, Aging Rate = 0.5, Precision = 0.9975678962302391, f1 = 0.9975678962302391\n",
      "Epoch 34: Train Loss = 0.004295601547386561, Recall = 0.9995946493717065, Aging Rate = 0.5002026753141467, Precision = 0.9991896272285251, f1 = 0.9993920972644377\n",
      "Epoch 35: Train Loss = 0.001456888164621055, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0012922346411498636, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 36: Train Loss = 0.0011817032024796627, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 37: Train Loss = 0.0012024433561713998, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 38: Train Loss = 0.0013612911043243945, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 39: Train Loss = 0.0015330086084687498, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 40: Train Loss = 0.0016275450598444644, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0012977942289240179, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 41: Train Loss = 0.00185661288070782, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 42: Train Loss = 0.0018783686637162465, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 43: Train Loss = 0.0021183581922367897, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 44: Train Loss = 0.041167022461425715, Recall = 0.9882448317794893, Aging Rate = 0.5036481556546413, Precision = 0.9810865191146881, f1 = 0.9846526655896608\n",
      "Epoch 45: Train Loss = 0.053293171522774206, Recall = 0.9821645723550871, Aging Rate = 0.5014187271990271, Precision = 0.9793856103476152, f1 = 0.9807731228496256\n",
      "Test Loss = 0.01748751703273002, Recall = 0.9906769355492501, Aging Rate = 0.49574381840291853, precision = 0.9991823385118561\n",
      "\n",
      "Epoch 46: Train Loss = 0.013111704897774813, Recall = 0.9943250912038913, Aging Rate = 0.4989866234292663, Precision = 0.996344435418359, f1 = 0.9953337390951512\n",
      "Epoch 47: Train Loss = 0.005222618845255572, Recall = 0.9983785974868261, Aging Rate = 0.49979732468585325, Precision = 0.9987834549878345, f1 = 0.9985809852017029\n",
      "Epoch 48: Train Loss = 0.0019423975892141113, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 49: Train Loss = 0.0011710707813348089, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 50: Train Loss = 0.0011327611008771503, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0010385415201891787, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 51: Train Loss = 0.0012316143047210828, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 52: Train Loss = 0.001420524873644118, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 53: Train Loss = 0.001566785655350979, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 54: Train Loss = 0.0017429023972505959, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 55: Train Loss = 0.0016995983653753561, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0018223612933099891, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 56: Train Loss = 0.0021166200382917374, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 57: Train Loss = 0.0024293158061324456, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 58: Train Loss = 0.0838396158590339, Recall = 0.9748682610458046, Aging Rate = 0.5062829347385488, Precision = 0.9627702161729383, f1 = 0.9687814702920442\n",
      "Epoch 59: Train Loss = 0.031135348445282103, Recall = 0.9886501824077827, Aging Rate = 0.5, Precision = 0.9886501824077827, f1 = 0.9886501824077827\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 60: Train Loss = 0.007209997023348208, Recall = 0.9979732468585326, Aging Rate = 0.4993919740575598, Precision = 0.9991883116883117, f1 = 0.9985804096532144\n",
      "Test Loss = 0.009203721618911224, Recall = 1.0, Aging Rate = 0.5024321037697609, precision = 0.9951593384429205\n",
      "\n",
      "Training Finished at epoch 60.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "18e343fe43194184869f9873338df228",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss = 0.35510260483418393, Recall = 0.8751520064856101, Aging Rate = 0.5480340494527767, Precision = 0.7984467455621301, f1 = 0.8350415780313285\n",
      "Epoch 2: Train Loss = 0.1353271081862442, Recall = 0.9566274827725983, Aging Rate = 0.5026347790839076, Precision = 0.9516129032258065, f1 = 0.9541136042045685\n",
      "Epoch 3: Train Loss = 0.08753614586388771, Recall = 0.9700040535062829, Aging Rate = 0.5024321037697609, Precision = 0.9653085921742638, f1 = 0.9676506267691064\n",
      "Epoch 4: Train Loss = 0.061613301952291366, Recall = 0.9813538710985003, Aging Rate = 0.5004053506282935, Precision = 0.9805589307411907, f1 = 0.9809562398703403\n",
      "Epoch 5: Train Loss = 0.05928674743884142, Recall = 0.9793271179570329, Aging Rate = 0.5002026753141467, Precision = 0.9789303079416531, f1 = 0.979128672745694\n",
      "Test Loss = 0.02009159138929786, Recall = 0.9987839481151196, Aging Rate = 0.5020267531414674, precision = 0.994751715785224\n",
      "Model in epoch 5 is saved.\n",
      "\n",
      "Epoch 6: Train Loss = 0.01142983545104127, Recall = 0.9971625456019457, Aging Rate = 0.4995946493717065, Precision = 0.9979716024340771, f1 = 0.9975669099756692\n",
      "Epoch 7: Train Loss = 0.0037325052904998743, Recall = 1.0, Aging Rate = 0.5002026753141467, Precision = 0.9995948136142626, f1 = 0.9997973657548125\n",
      "Epoch 8: Train Loss = 0.002325603951255558, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 9: Train Loss = 0.0019124284013652781, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 10: Train Loss = 0.0018925881381348579, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0017740725342421761, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "Model in epoch 10 is saved.\n",
      "\n",
      "Epoch 11: Train Loss = 0.0019853838847215463, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 12: Train Loss = 0.002026310327878493, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 13: Train Loss = 0.002166780619759356, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 14: Train Loss = 0.0020863988278344964, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 15: Train Loss = 0.0024149322810189827, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0028324895946102847, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 16: Train Loss = 0.0026709653918843158, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 17: Train Loss = 0.094334356127972, Recall = 0.9720308066477503, Aging Rate = 0.5042561815970815, Precision = 0.9638263665594855, f1 = 0.9679112008072654\n",
      "Epoch 18: Train Loss = 0.06029853024622144, Recall = 0.9773003648155655, Aging Rate = 0.5, Precision = 0.9773003648155655, f1 = 0.9773003648155655\n",
      "Epoch 19: Train Loss = 0.015097451637752722, Recall = 0.9943250912038913, Aging Rate = 0.5, Precision = 0.9943250912038913, f1 = 0.9943250912038913\n",
      "Epoch 20: Train Loss = 0.004350394827574582, Recall = 1.0, Aging Rate = 0.5004053506282935, Precision = 0.9991899554475496, f1 = 0.9995948136142626\n",
      "Test Loss = 0.002328209746889483, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 21: Train Loss = 0.0016863891939067459, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 22: Train Loss = 0.0012331472349345206, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 23: Train Loss = 0.0012587662100352883, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 24: Train Loss = 0.0013232864015730024, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 25: Train Loss = 0.0015025056884696735, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0014071779563295552, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 26: Train Loss = 0.0015944069616000511, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 27: Train Loss = 0.0017808157671091948, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 28: Train Loss = 0.001959005154209286, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 29: Train Loss = 0.002437209579647214, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 30: Train Loss = 0.061918906452995734, Recall = 0.9789217673287394, Aging Rate = 0.5048642075395217, Precision = 0.9694901645925331, f1 = 0.9741831383622428\n",
      "Test Loss = 0.058406416807711775, Recall = 0.9902715849209567, Aging Rate = 0.5109444669639238, precision = 0.9690598968663229\n",
      "\n",
      "Epoch 31: Train Loss = 0.045472618757593654, Recall = 0.984596676124848, Aging Rate = 0.5010133765707336, Precision = 0.9826051779935275, f1 = 0.9835999190119458\n",
      "Epoch 32: Train Loss = 0.01336688200420695, Recall = 0.9955411430887718, Aging Rate = 0.4993919740575598, Precision = 0.9967532467532467, f1 = 0.9961468262015819\n",
      "Epoch 33: Train Loss = 0.003546068319653737, Recall = 0.9995946493717065, Aging Rate = 0.5, Precision = 0.9995946493717065, f1 = 0.9995946493717065\n",
      "Epoch 34: Train Loss = 0.001570243738840074, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 35: Train Loss = 0.0010772388320168518, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0008721115717346873, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 36: Train Loss = 0.001083313145349727, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 37: Train Loss = 0.0011948366002823576, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 38: Train Loss = 0.0014196666883937803, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 39: Train Loss = 0.0015441467272956566, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 40: Train Loss = 0.0019440695621930387, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0022897466539243336, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 41: Train Loss = 0.0019625179230997715, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 42: Train Loss = 0.0026184249414775837, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 43: Train Loss = 0.05553845106487219, Recall = 0.9821645723550871, Aging Rate = 0.503850830968788, Precision = 0.9746580852775543, f1 = 0.9783969311528367\n",
      "Epoch 44: Train Loss = 0.032410408181818236, Recall = 0.9898662342926632, Aging Rate = 0.5022294284556141, Precision = 0.9854721549636803, f1 = 0.9876643073811932\n",
      "Epoch 45: Train Loss = 0.018927034830963703, Recall = 0.9951357924604783, Aging Rate = 0.5020267531414674, Precision = 0.9911182882519176, f1 = 0.9931229773462782\n",
      "Test Loss = 0.005666812528617511, Recall = 0.9971625456019457, Aging Rate = 0.49878394811511956, precision = 0.9995936611133686\n",
      "\n",
      "Epoch 46: Train Loss = 0.004137621260330045, Recall = 0.9995946493717065, Aging Rate = 0.5, Precision = 0.9995946493717065, f1 = 0.9995946493717065\n",
      "Epoch 47: Train Loss = 0.001362531645341282, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 48: Train Loss = 0.0010790567545738957, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 49: Train Loss = 0.0012115916136439314, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 50: Train Loss = 0.0012229531893216338, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0012778936661432569, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 51: Train Loss = 0.0013443283210500974, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 52: Train Loss = 0.0015130057335609626, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 53: Train Loss = 0.0016267748820941055, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 54: Train Loss = 0.0017645800654011176, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 55: Train Loss = 0.001891175714649587, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.001880359384701272, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 56: Train Loss = 0.0027265949142201346, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 57: Train Loss = 0.00521188788078227, Recall = 0.9995946493717065, Aging Rate = 0.5002026753141467, Precision = 0.9991896272285251, f1 = 0.9993920972644377\n",
      "Epoch 58: Train Loss = 0.1034081037453386, Recall = 0.9659505472233482, Aging Rate = 0.5058775841102554, Precision = 0.9547275641025641, f1 = 0.9603062663711466\n",
      "Epoch 59: Train Loss = 0.028335669170700555, Recall = 0.9918929874341306, Aging Rate = 0.5006080259424402, Precision = 0.9906882591093117, f1 = 0.9912902572412395\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 60: Train Loss = 0.006916234607564419, Recall = 0.9983785974868261, Aging Rate = 0.4995946493717065, Precision = 0.9991886409736308, f1 = 0.9987834549878345\n",
      "Test Loss = 0.002547326226856799, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Training Finished at epoch 60.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a5fa0ab03b88421db23cfa9e8d75ab36",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss = 0.3810409254688554, Recall = 0.8942034860154033, Aging Rate = 0.5910012160518848, Precision = 0.7565157750342936, f1 = 0.8196173137655581\n",
      "Epoch 2: Train Loss = 0.15089048155295398, Recall = 0.9513579246047832, Aging Rate = 0.5036481556546413, Precision = 0.9444668008048289, f1 = 0.9478998384491115\n",
      "Epoch 3: Train Loss = 0.08825192375038382, Recall = 0.9744629104175111, Aging Rate = 0.5006080259424402, Precision = 0.9732793522267207, f1 = 0.9738707717237188\n",
      "Epoch 4: Train Loss = 0.06654174650638366, Recall = 0.9773003648155655, Aging Rate = 0.49878394811511956, Precision = 0.9796830556684275, f1 = 0.9784902597402597\n",
      "Epoch 5: Train Loss = 0.06336410284453092, Recall = 0.9789217673287394, Aging Rate = 0.5004053506282935, Precision = 0.9781287970838396, f1 = 0.9785251215559156\n",
      "Test Loss = 0.02818460243648008, Recall = 0.9975678962302391, Aging Rate = 0.5026347790839076, precision = 0.9923387096774193\n",
      "Model in epoch 5 is saved.\n",
      "\n",
      "Epoch 6: Train Loss = 0.015977738969413815, Recall = 0.9971625456019457, Aging Rate = 0.4995946493717065, Precision = 0.9979716024340771, f1 = 0.9975669099756692\n",
      "Epoch 7: Train Loss = 0.005085847928593812, Recall = 0.9995946493717065, Aging Rate = 0.49979732468585325, Precision = 0, f1 = 0.0\n",
      "Epoch 8: Train Loss = 0.002879756644751724, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 9: Train Loss = 0.0021053706615611896, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 10: Train Loss = 0.0019301056416790568, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0019748708240126863, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "Model in epoch 10 is saved.\n",
      "\n",
      "Epoch 11: Train Loss = 0.0020048227801052216, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 12: Train Loss = 0.002050942438888187, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 13: Train Loss = 0.0020554573384627406, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 14: Train Loss = 0.0023226427487397804, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 15: Train Loss = 0.0022113571180552424, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0017632166875800382, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 16: Train Loss = 0.0032105756797844768, Recall = 1.0, Aging Rate = 0.5002026753141467, Precision = 0.9995948136142626, f1 = 0.9997973657548125\n",
      "Epoch 17: Train Loss = 0.10106177460538154, Recall = 0.967571949736522, Aging Rate = 0.5050668828536684, Precision = 0.9578651685393258, f1 = 0.9626940915507158\n",
      "Epoch 18: Train Loss = 0.039721752231337365, Recall = 0.9870287798946088, Aging Rate = 0.5010133765707336, Precision = 0.985032362459547, f1 = 0.9860295606398057\n",
      "Epoch 19: Train Loss = 0.006616326307784322, Recall = 0.999189298743413, Aging Rate = 0.5, Precision = 0.999189298743413, f1 = 0.999189298743413\n",
      "Epoch 20: Train Loss = 0.004867393618304604, Recall = 0.999189298743413, Aging Rate = 0.5, Precision = 0.999189298743413, f1 = 0.999189298743413\n",
      "Test Loss = 0.0013768904613970655, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 21: Train Loss = 0.001464544730025967, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 22: Train Loss = 0.0012556833205053777, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 23: Train Loss = 0.0013537906977544288, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 24: Train Loss = 0.0014559906677285947, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 25: Train Loss = 0.0016137273336338264, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0015285941136585748, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 26: Train Loss = 0.0017512057634761079, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 27: Train Loss = 0.0018210389717763407, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 28: Train Loss = 0.0020825184880177115, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 29: Train Loss = 0.001927388245268993, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 30: Train Loss = 0.0022371323255026077, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0030883834338197684, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 31: Train Loss = 0.0916495309033883, Recall = 0.9712201053911633, Aging Rate = 0.5066882853668423, Precision = 0.9584, f1 = 0.9647674652707873\n",
      "Epoch 32: Train Loss = 0.027996946120182414, Recall = 0.9902715849209567, Aging Rate = 0.49918929874341306, Precision = 0.9918798213560698, f1 = 0.9910750507099392\n",
      "Epoch 33: Train Loss = 0.00794485708554751, Recall = 0.9979732468585326, Aging Rate = 0.49979732468585325, Precision = 0.9983779399837794, f1 = 0.9981755524021894\n",
      "Epoch 34: Train Loss = 0.002140843908762673, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 35: Train Loss = 0.0013241854443542891, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.001104995648251687, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 36: Train Loss = 0.0012209301130762336, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 37: Train Loss = 0.0012688142902764822, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 38: Train Loss = 0.0014040971755827421, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 39: Train Loss = 0.0019636032940539747, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 40: Train Loss = 0.0016322615226095729, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0014147601193432438, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 41: Train Loss = 0.001632558312241583, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 42: Train Loss = 0.001845419520404066, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 43: Train Loss = 0.002032890537603451, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 44: Train Loss = 0.0021273869313552587, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 45: Train Loss = 0.0848088514212297, Recall = 0.9716254560194568, Aging Rate = 0.5044588569112282, Precision = 0.9630373644033748, f1 = 0.9673123486682808\n",
      "Test Loss = 0.03766277997350954, Recall = 0.9866234292663154, Aging Rate = 0.5012160518848804, precision = 0.9842296805499393\n",
      "\n",
      "Epoch 46: Train Loss = 0.03071850773104118, Recall = 0.9902715849209567, Aging Rate = 0.5012160518848804, Precision = 0.9878689850384149, f1 = 0.9890688259109313\n",
      "Epoch 47: Train Loss = 0.007784318443952882, Recall = 0.9983785974868261, Aging Rate = 0.5004053506282935, Precision = 0.9975698663426489, f1 = 0.9979740680713128\n",
      "Epoch 48: Train Loss = 0.0020315754216958634, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 49: Train Loss = 0.0011490570854468748, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 50: Train Loss = 0.0010686425486882301, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0009961878884763313, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 51: Train Loss = 0.0011766765419407746, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 52: Train Loss = 0.0012667181391850715, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 53: Train Loss = 0.0013967610001496074, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 54: Train Loss = 0.001472392931967871, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 55: Train Loss = 0.001625426509143897, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0015062289664659464, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 56: Train Loss = 0.0017292676099261212, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 57: Train Loss = 0.0020153524491089963, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 58: Train Loss = 0.0025707075529560327, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 59: Train Loss = 0.06931449693031563, Recall = 0.9793271179570329, Aging Rate = 0.5032428050263478, Precision = 0.973016512283528, f1 = 0.9761616161616162\n",
      "Epoch 60: Train Loss = 0.037723340514921225, Recall = 0.9866234292663154, Aging Rate = 0.5010133765707336, Precision = 0.9846278317152104, f1 = 0.9856246203684957\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss = 0.008765141740378561, Recall = 0.9967571949736522, Aging Rate = 0.4983785974868261, precision = 1.0\n",
      "\n",
      "Training Finished at epoch 60.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b1e2d062d0aa48dfb8464255cf55038b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss = 0.35799671149234524, Recall = 0.9643435980551054, Aging Rate = 0.7206239870340356, Precision = 0.669103176834411, f1 = 0.7900414937759336\n",
      "Epoch 2: Train Loss = 0.1708781544233837, Recall = 0.9582658022690438, Aging Rate = 0.524513776337115, Precision = 0.9134801081498648, f1 = 0.9353371564168479\n",
      "Epoch 3: Train Loss = 0.1119963005788902, Recall = 0.9716369529983793, Aging Rate = 0.5060777957860616, Precision = 0.9599679743795037, f1 = 0.9657672170761176\n",
      "Epoch 4: Train Loss = 0.10240453711108605, Recall = 0.9728525121555915, Aging Rate = 0.5076985413290114, Precision = 0.9581005586592178, f1 = 0.9654201849618014\n",
      "Epoch 5: Train Loss = 0.08972241431836951, Recall = 0.976904376012966, Aging Rate = 0.5093192868719612, Precision = 0.9590294351630867, f1 = 0.9678843837816138\n",
      "Test Loss = 0.06245524007555345, Recall = 0.9951377633711507, Aging Rate = 0.5172204213938412, precision = 0.9620054837446141\n",
      "Model in epoch 5 is saved.\n",
      "\n",
      "Epoch 6: Train Loss = 0.044310719816307, Recall = 0.9923014586709886, Aging Rate = 0.5022285251215559, Precision = 0.9878983461073013, f1 = 0.9900950070749949\n",
      "Epoch 7: Train Loss = 0.031335446086970295, Recall = 0.997163695299838, Aging Rate = 0.5022285251215559, Precision = 0.9927390076643808, f1 = 0.9949464321811199\n",
      "Epoch 8: Train Loss = 0.028816056155525693, Recall = 0.9975688816855753, Aging Rate = 0.5024311183144247, Precision = 0.992741935483871, f1 = 0.9951495553759094\n",
      "Epoch 9: Train Loss = 0.037004987565827714, Recall = 0.9955429497568882, Aging Rate = 0.5040518638573744, Precision = 0.987540192926045, f1 = 0.9915254237288136\n",
      "Epoch 10: Train Loss = 0.04044306532116048, Recall = 0.993517017828201, Aging Rate = 0.5040518638573744, Precision = 0.9855305466237942, f1 = 0.9895076674737692\n",
      "Test Loss = 0.04130127044195367, Recall = 0.9983792544570502, Aging Rate = 0.5145867098865479, precision = 0.9700787401574803\n",
      "Model in epoch 10 is saved.\n",
      "\n",
      "Epoch 11: Train Loss = 0.03038072820324179, Recall = 0.9959481361426256, Aging Rate = 0.5034440842787682, Precision = 0.9891348088531187, f1 = 0.9925297799313547\n",
      "Epoch 12: Train Loss = 0.026405082994428987, Recall = 0.9991896272285251, Aging Rate = 0.502836304700162, Precision = 0.9935535858178888, f1 = 0.9963636363636365\n",
      "Epoch 13: Train Loss = 0.028869489736166726, Recall = 0.9975688816855753, Aging Rate = 0.5030388978930308, Precision = 0.9915424889246879, f1 = 0.9945465562512624\n",
      "Epoch 14: Train Loss = 0.030815290051664872, Recall = 0.9967585089141004, Aging Rate = 0.5046596434359806, Precision = 0.9875551987153753, f1 = 0.9921355111917726\n",
      "Epoch 15: Train Loss = 0.029695773897224637, Recall = 0.9951377633711507, Aging Rate = 0.5020259319286872, Precision = 0.9911218724778047, f1 = 0.9931257581884351\n",
      "Test Loss = 0.025847411408078537, Recall = 0.9991896272285251, Aging Rate = 0.5062803889789304, precision = 0.9867947178871549\n",
      "Model in epoch 15 is saved.\n",
      "\n",
      "Epoch 16: Train Loss = 0.03346709532110772, Recall = 0.9963533225283631, Aging Rate = 0.5052674230145867, Precision = 0.9859663191659984, f1 = 0.9911326078194277\n",
      "Epoch 17: Train Loss = 0.035380574051936786, Recall = 0.9943273905996759, Aging Rate = 0.5032414910858996, Precision = 0.9879227053140096, f1 = 0.9911147011308562\n",
      "Epoch 18: Train Loss = 0.030800843279283476, Recall = 0.9955429497568882, Aging Rate = 0.5044570502431118, Precision = 0.9867469879518073, f1 = 0.991125453812021\n",
      "Epoch 19: Train Loss = 0.027794431206714394, Recall = 0.9967585089141004, Aging Rate = 0.502836304700162, Precision = 0.9911361804995971, f1 = 0.9939393939393939\n",
      "Epoch 20: Train Loss = 0.03914717028620902, Recall = 0.9927066450567261, Aging Rate = 0.5044570502431118, Precision = 0.9839357429718876, f1 = 0.9883017345703913\n",
      "Test Loss = 0.03860538012862833, Recall = 0.9967585089141004, Aging Rate = 0.5095218800648298, precision = 0.9781312127236581\n",
      "\n",
      "Epoch 21: Train Loss = 0.03418228356846921, Recall = 0.993517017828201, Aging Rate = 0.5022285251215559, Precision = 0.9891085114965712, f1 = 0.9913078633515262\n",
      "Epoch 22: Train Loss = 0.029784905629132902, Recall = 0.9959481361426256, Aging Rate = 0.5024311183144247, Precision = 0.9911290322580645, f1 = 0.9935327405012127\n",
      "Epoch 23: Train Loss = 0.036056633777554165, Recall = 0.9943273905996759, Aging Rate = 0.5032414910858996, Precision = 0.9879227053140096, f1 = 0.9911147011308562\n",
      "Epoch 24: Train Loss = 0.025748737010730483, Recall = 0.9979740680713128, Aging Rate = 0.5026337115072933, Precision = 0.992744860943168, f1 = 0.9953525964841382\n",
      "Epoch 25: Train Loss = 0.03174463203976858, Recall = 0.9963533225283631, Aging Rate = 0.5042544570502431, Precision = 0.9879469666532744, f1 = 0.9921323381077265\n",
      "Test Loss = 0.022699256557397653, Recall = 0.9991896272285251, Aging Rate = 0.5032414910858996, precision = 0.9927536231884058\n",
      "Model in epoch 25 is saved.\n",
      "\n",
      "Epoch 26: Train Loss = 0.029840832561061292, Recall = 0.9967585089141004, Aging Rate = 0.5030388978930308, Precision = 0.9907370116794201, f1 = 0.9937386386588568\n",
      "Epoch 27: Train Loss = 0.028185327015092635, Recall = 0.9967585089141004, Aging Rate = 0.5022285251215559, Precision = 0.9923356192012909, f1 = 0.9945421467556095\n",
      "Epoch 28: Train Loss = 0.027524267874259618, Recall = 0.9967585089141004, Aging Rate = 0.502836304700162, Precision = 0.9911361804995971, f1 = 0.9939393939393939\n",
      "Epoch 29: Train Loss = 0.03660681777040518, Recall = 0.9947325769854133, Aging Rate = 0.5040518638573744, Precision = 0.9867363344051447, f1 = 0.9907183212267958\n",
      "Epoch 30: Train Loss = 0.03293547468075779, Recall = 0.9943273905996759, Aging Rate = 0.5032414910858996, Precision = 0.9879227053140096, f1 = 0.9911147011308562\n",
      "Test Loss = 0.016281021881178383, Recall = 0.9991896272285251, Aging Rate = 0.5008103727714749, precision = 0.9975728155339806\n",
      "Model in epoch 30 is saved.\n",
      "\n",
      "Epoch 31: Train Loss = 0.026577166699754556, Recall = 0.9983792544570502, Aging Rate = 0.5022285251215559, Precision = 0.9939491730536507, f1 = 0.9961592884576511\n",
      "Epoch 32: Train Loss = 0.02680871694467998, Recall = 0.9963533225283631, Aging Rate = 0.5008103727714749, Precision = 0.9947411003236246, f1 = 0.9955465587044535\n",
      "Epoch 33: Train Loss = 0.03415528875043558, Recall = 0.9951377633711507, Aging Rate = 0.5044570502431118, Precision = 0.9863453815261044, f1 = 0.990722065348931\n",
      "Epoch 34: Train Loss = 0.037486712778865616, Recall = 0.9943273905996759, Aging Rate = 0.5054700162074555, Precision = 0.983567134268537, f1 = 0.9889179931493048\n",
      "Epoch 35: Train Loss = 0.028180037605511313, Recall = 0.9955429497568882, Aging Rate = 0.5018233387358185, Precision = 0.9919257165926524, f1 = 0.9937310414560161\n",
      "Test Loss = 0.019023839097524385, Recall = 0.9987844408427877, Aging Rate = 0.5006077795786061, precision = 0.9975718332658843\n",
      "\n",
      "Epoch 36: Train Loss = 0.02781084628482885, Recall = 0.997163695299838, Aging Rate = 0.5038492706645057, Precision = 0.989545637314033, f1 = 0.9933400605449041\n",
      "Epoch 37: Train Loss = 0.02108761740507289, Recall = 0.9983792544570502, Aging Rate = 0.5004051863857374, Precision = 0.9975708502024292, f1 = 0.9979748886188741\n",
      "Epoch 38: Train Loss = 0.02938402477633721, Recall = 0.997163695299838, Aging Rate = 0.5036466774716369, Precision = 0.9899436846339501, f1 = 0.9935405732741219\n",
      "Epoch 39: Train Loss = 0.05175769439788242, Recall = 0.9886547811993517, Aging Rate = 0.5089141004862237, Precision = 0.9713375796178344, f1 = 0.9799196787148594\n",
      "Epoch 40: Train Loss = 0.029244774243095514, Recall = 0.9947325769854133, Aging Rate = 0.5032414910858996, Precision = 0.9883252818035426, f1 = 0.9915185783521808\n",
      "Test Loss = 0.018135921077159757, Recall = 0.9983792544570502, Aging Rate = 0.4997974068071313, precision = 0.9987839481151196\n",
      "Model in epoch 40 is saved.\n",
      "\n",
      "Epoch 41: Train Loss = 0.01970759340270605, Recall = 0.9991896272285251, Aging Rate = 0.5010129659643436, Precision = 0.9971694298422968, f1 = 0.9981785063752278\n",
      "Epoch 42: Train Loss = 0.021693606545463373, Recall = 0.9991896272285251, Aging Rate = 0.501418152350081, Precision = 0.9963636363636363, f1 = 0.9977746307910175\n",
      "Epoch 43: Train Loss = 0.022522353303031557, Recall = 0.9991896272285251, Aging Rate = 0.5012155591572123, Precision = 0.9967663702506063, f1 = 0.9979765277215702\n",
      "Epoch 44: Train Loss = 0.032595847864639815, Recall = 0.9963533225283631, Aging Rate = 0.5042544570502431, Precision = 0.9879469666532744, f1 = 0.9921323381077265\n",
      "Epoch 45: Train Loss = 0.05359344869532066, Recall = 0.9858184764991896, Aging Rate = 0.50790113452188, Precision = 0.9704826485839649, f1 = 0.9780904522613066\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss = 0.030564653509065533, Recall = 1.0, Aging Rate = 0.5093192868719612, precision = 0.9817024661893397\n",
      "\n",
      "Epoch 46: Train Loss = 0.025023110736179584, Recall = 0.9963533225283631, Aging Rate = 0.5022285251215559, Precision = 0.9919322307382009, f1 = 0.9941378613300991\n",
      "Epoch 47: Train Loss = 0.022293064457996833, Recall = 0.9983792544570502, Aging Rate = 0.5012155591572123, Precision = 0.9959579628132579, f1 = 0.9971671388101981\n",
      "Epoch 48: Train Loss = 0.026889030580111512, Recall = 0.997163695299838, Aging Rate = 0.5024311183144247, Precision = 0.9923387096774193, f1 = 0.9947453516572352\n",
      "Epoch 49: Train Loss = 0.03444491657979388, Recall = 0.9923014586709886, Aging Rate = 0.5012155591572123, Precision = 0.9898949070331448, f1 = 0.9910967219749091\n",
      "Epoch 50: Train Loss = 0.028031680528814128, Recall = 0.9955429497568882, Aging Rate = 0.5018233387358185, Precision = 0.9919257165926524, f1 = 0.9937310414560161\n",
      "Test Loss = 0.023225223757266225, Recall = 0.9955429497568882, Aging Rate = 0.4991896272285251, precision = 0.9971590909090909\n",
      "\n",
      "Epoch 51: Train Loss = 0.02549912100220084, Recall = 0.9975688816855753, Aging Rate = 0.5008103727714749, Precision = 0.9959546925566343, f1 = 0.9967611336032388\n",
      "Epoch 52: Train Loss = 0.02097727130114356, Recall = 0.9987844408427877, Aging Rate = 0.5018233387358185, Precision = 0.9951554299555915, f1 = 0.9969666329625885\n",
      "Epoch 53: Train Loss = 0.050074644555070554, Recall = 0.9874392220421394, Aging Rate = 0.5042544570502431, Precision = 0.9791080755323424, f1 = 0.9832560016138794\n",
      "Epoch 54: Train Loss = 0.026297780158333298, Recall = 0.9959481361426256, Aging Rate = 0.5024311183144247, Precision = 0.9911290322580645, f1 = 0.9935327405012127\n",
      "Epoch 55: Train Loss = 0.019184879857497335, Recall = 0.9991896272285251, Aging Rate = 0.5010129659643436, Precision = 0.9971694298422968, f1 = 0.9981785063752278\n",
      "Test Loss = 0.017980668428120003, Recall = 0.9991896272285251, Aging Rate = 0.5006077795786061, precision = 0.9979765277215702\n",
      "\n",
      "Epoch 56: Train Loss = 0.022270221676755957, Recall = 0.9987844408427877, Aging Rate = 0.5010129659643436, Precision = 0.9967650626769107, f1 = 0.9977737300141672\n",
      "Epoch 57: Train Loss = 0.04714414443838828, Recall = 0.9890599675850892, Aging Rate = 0.5056726094003241, Precision = 0.9779647435897436, f1 = 0.9834810636583401\n",
      "Epoch 58: Train Loss = 0.03437071922725758, Recall = 0.9939222042139384, Aging Rate = 0.5026337115072933, Precision = 0.988714228133817, f1 = 0.9913113760355629\n",
      "Epoch 59: Train Loss = 0.02158180866813109, Recall = 0.9983792544570502, Aging Rate = 0.5012155591572123, Precision = 0.9959579628132579, f1 = 0.9971671388101981\n",
      "Epoch 60: Train Loss = 0.02254975387732977, Recall = 0.9995948136142626, Aging Rate = 0.5010129659643436, Precision = 0.997573797007683, f1 = 0.9985832827362882\n",
      "Test Loss = 0.017920617474547953, Recall = 0.9995948136142626, Aging Rate = 0.5018233387358185, precision = 0.9959628582963262\n",
      "\n",
      "Epoch 61: Train Loss = 0.021597601989558877, Recall = 0.9979740680713128, Aging Rate = 0.5012155591572123, Precision = 0.9955537590945837, f1 = 0.9967624443545123\n",
      "Epoch 62: Train Loss = 0.029076375019686778, Recall = 0.9963533225283631, Aging Rate = 0.5024311183144247, Precision = 0.9915322580645162, f1 = 0.9939369442198869\n",
      "Epoch 63: Train Loss = 0.03107366089918915, Recall = 0.9931118314424635, Aging Rate = 0.5020259319286872, Precision = 0.9891041162227603, f1 = 0.9911039223615042\n",
      "Epoch 64: Train Loss = 0.03094264932846231, Recall = 0.9947325769854133, Aging Rate = 0.5022285251215559, Precision = 0.9903186768858411, f1 = 0.9925207196280574\n",
      "Epoch 65: Train Loss = 0.02452332008255697, Recall = 0.9979740680713128, Aging Rate = 0.5030388978930308, Precision = 0.9919452275473218, f1 = 0.9949505150474651\n",
      "Test Loss = 0.01659589063382226, Recall = 0.9991896272285251, Aging Rate = 0.4997974068071313, precision = 0.9995946493717065\n",
      "Model in epoch 65 is saved.\n",
      "\n",
      "Epoch 66: Train Loss = 0.02883277813084363, Recall = 0.997163695299838, Aging Rate = 0.502836304700162, Precision = 0.991539081385979, f1 = 0.9943434343434343\n",
      "Epoch 67: Train Loss = 0.028913706758420317, Recall = 0.9955429497568882, Aging Rate = 0.5020259319286872, Precision = 0.9915254237288136, f1 = 0.9935301253538212\n",
      "Epoch 68: Train Loss = 0.026968340025656228, Recall = 0.9975688816855753, Aging Rate = 0.5022285251215559, Precision = 0.9931423961274708, f1 = 0.9953507176066303\n",
      "Epoch 69: Train Loss = 0.029691500874535096, Recall = 0.9947325769854133, Aging Rate = 0.5020259319286872, Precision = 0.9907183212267958, f1 = 0.9927213910230489\n",
      "Epoch 70: Train Loss = 0.023912793737828637, Recall = 0.9983792544570502, Aging Rate = 0.5026337115072933, Precision = 0.9931479242241031, f1 = 0.9957567185289956\n",
      "Test Loss = 0.02525810832444524, Recall = 0.9991896272285251, Aging Rate = 0.5030388978930308, precision = 0.9931534434152235\n",
      "\n",
      "Epoch 71: Train Loss = 0.03251843489072553, Recall = 0.9947325769854133, Aging Rate = 0.5022285251215559, Precision = 0.9903186768858411, f1 = 0.9925207196280574\n",
      "Epoch 72: Train Loss = 0.022154385649645926, Recall = 0.9983792544570502, Aging Rate = 0.5010129659643436, Precision = 0.9963606955115245, f1 = 0.9973689536531066\n",
      "Epoch 73: Train Loss = 0.029674198662611614, Recall = 0.9959481361426256, Aging Rate = 0.5036466774716369, Precision = 0.9887369267900241, f1 = 0.9923294307630198\n",
      "Epoch 74: Train Loss = 0.030857330876458405, Recall = 0.9959481361426256, Aging Rate = 0.5036466774716369, Precision = 0.9887369267900241, f1 = 0.9923294307630198\n",
      "Epoch 75: Train Loss = 0.034479296891504786, Recall = 0.993517017828201, Aging Rate = 0.5034440842787682, Precision = 0.9867203219315895, f1 = 0.9901070058550373\n",
      "Test Loss = 0.017619480181189563, Recall = 0.9987844408427877, Aging Rate = 0.5020259319286872, precision = 0.9947538337368845\n",
      "\n",
      "Epoch 76: Train Loss = 0.021434401095553484, Recall = 0.9979740680713128, Aging Rate = 0.5020259319286872, Precision = 0.9939467312348669, f1 = 0.9959563283461383\n",
      "Epoch 77: Train Loss = 0.02168064188918573, Recall = 0.9987844408427877, Aging Rate = 0.5022285251215559, Precision = 0.9943525615167407, f1 = 0.9965635738831615\n",
      "Epoch 78: Train Loss = 0.06049928493568345, Recall = 0.9850081037277147, Aging Rate = 0.5085089141004863, Precision = 0.9685258964143426, f1 = 0.9766974688629972\n",
      "Epoch 79: Train Loss = 0.02526648917101094, Recall = 0.9959481361426256, Aging Rate = 0.5020259319286872, Precision = 0.9919289749798225, f1 = 0.9939344925192074\n",
      "Epoch 80: Train Loss = 0.022202896150478088, Recall = 0.9991896272285251, Aging Rate = 0.5022285251215559, Precision = 0.9947559499798305, f1 = 0.9969678593086719\n",
      "Test Loss = 0.023288467067265145, Recall = 0.9975688816855753, Aging Rate = 0.49878444084278767, precision = 1.0\n",
      "\n",
      "Epoch 81: Train Loss = 0.019492801671283172, Recall = 0.9991896272285251, Aging Rate = 0.5004051863857374, Precision = 0.9983805668016195, f1 = 0.9987849331713246\n",
      "Epoch 82: Train Loss = 0.028918647575622344, Recall = 0.9963533225283631, Aging Rate = 0.5018233387358185, Precision = 0.9927331449333872, f1 = 0.9945399393326593\n",
      "Epoch 83: Train Loss = 0.033710436376243394, Recall = 0.9951377633711507, Aging Rate = 0.5044570502431118, Precision = 0.9863453815261044, f1 = 0.990722065348931\n",
      "Epoch 84: Train Loss = 0.022844163054899228, Recall = 0.9979740680713128, Aging Rate = 0.5016207455429498, Precision = 0.9947495961227787, f1 = 0.9963592233009709\n",
      "Epoch 85: Train Loss = 0.02967746265087657, Recall = 0.9943273905996759, Aging Rate = 0.5020259319286872, Precision = 0.9903147699757869, f1 = 0.9923170238576627\n",
      "Test Loss = 0.029692697729704058, Recall = 0.9991896272285251, Aging Rate = 0.5099270664505673, precision = 0.9797377830750894\n",
      "\n",
      "Epoch 86: Train Loss = 0.03254064427601171, Recall = 0.9959481361426256, Aging Rate = 0.5044570502431118, Precision = 0.98714859437751, f1 = 0.9915288422751108\n",
      "Epoch 87: Train Loss = 0.02902494751919224, Recall = 0.9951377633711507, Aging Rate = 0.5024311183144247, Precision = 0.9903225806451613, f1 = 0.9927243330638641\n",
      "Epoch 88: Train Loss = 0.021529009630616807, Recall = 0.9987844408427877, Aging Rate = 0.5010129659643436, Precision = 0.9967650626769107, f1 = 0.9977737300141672\n",
      "Epoch 89: Train Loss = 0.021950992871818512, Recall = 0.9983792544570502, Aging Rate = 0.5016207455429498, Precision = 0.9951534733441034, f1 = 0.9967637540453075\n",
      "Epoch 90: Train Loss = 0.037841361727734585, Recall = 0.9927066450567261, Aging Rate = 0.5042544570502431, Precision = 0.9843310566492567, f1 = 0.9885011095420617\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss = 0.024105268951680518, Recall = 0.9979740680713128, Aging Rate = 0.5036466774716369, precision = 0.9907481898632341\n",
      "\n",
      "Epoch 91: Train Loss = 0.040508493693542445, Recall = 0.9906807131280388, Aging Rate = 0.5056726094003241, Precision = 0.9795673076923077, f1 = 0.9850926672038679\n",
      "Epoch 92: Train Loss = 0.024787308741813733, Recall = 0.9983792544570502, Aging Rate = 0.5018233387358185, Precision = 0.994751715785224, f1 = 0.9965621840242669\n",
      "Epoch 93: Train Loss = 0.022354090809701327, Recall = 0.9979740680713128, Aging Rate = 0.5008103727714749, Precision = 0.9963592233009708, f1 = 0.997165991902834\n",
      "Epoch 94: Train Loss = 0.02280969929245921, Recall = 0.9991896272285251, Aging Rate = 0.5020259319286872, Precision = 0.9951573849878934, f1 = 0.9971694298422968\n",
      "Epoch 95: Train Loss = 0.020558050509113548, Recall = 0.9991896272285251, Aging Rate = 0.5010129659643436, Precision = 0.9971694298422968, f1 = 0.9981785063752278\n",
      "Test Loss = 0.017418016958830808, Recall = 0.9991896272285251, Aging Rate = 0.5, precision = 0.9991896272285251\n",
      "\n",
      "Epoch 96: Train Loss = 0.03416564746048887, Recall = 0.9951377633711507, Aging Rate = 0.5044570502431118, Precision = 0.9863453815261044, f1 = 0.990722065348931\n",
      "Epoch 97: Train Loss = 0.03979669762903604, Recall = 0.9906807131280388, Aging Rate = 0.5032414910858996, Precision = 0.9842995169082126, f1 = 0.9874798061389338\n",
      "Epoch 98: Train Loss = 0.037307845642926045, Recall = 0.9923014586709886, Aging Rate = 0.5044570502431118, Precision = 0.9835341365461847, f1 = 0.9878983461073012\n",
      "Epoch 99: Train Loss = 0.020393758465806128, Recall = 0.9983792544570502, Aging Rate = 0.5010129659643436, Precision = 0.9963606955115245, f1 = 0.9973689536531066\n",
      "Epoch 100: Train Loss = 0.019124958860405647, Recall = 1.0, Aging Rate = 0.5012155591572123, Precision = 0.9975747776879548, f1 = 0.9987859166329423\n",
      "Test Loss = 0.01583836517014467, Recall = 1.0, Aging Rate = 0.5004051863857374, precision = 0.9991902834008097\n",
      "Model in epoch 100 is saved.\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "01fcf05320e9404fa708d1422ca91986",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss = 0.34413348161285107, Recall = 0.9278475881637617, Aging Rate = 0.6414673692744224, Precision = 0.7232227488151659, f1 = 0.8128551136363635\n",
      "Epoch 2: Train Loss = 0.15681442205824733, Recall = 0.9598702877989461, Aging Rate = 0.5249290636400487, Precision = 0.9142857142857143, f1 = 0.9365236306110342\n",
      "Epoch 3: Train Loss = 0.1148791779112033, Recall = 0.9724361572760438, Aging Rate = 0.515403323875152, Precision = 0.9433739677546206, f1 = 0.957684630738523\n",
      "Epoch 4: Train Loss = 0.10193048233946277, Recall = 0.9744629104175111, Aging Rate = 0.5156059991892987, Precision = 0.9449685534591195, f1 = 0.9594891239273597\n",
      "Epoch 5: Train Loss = 0.09182741767513544, Recall = 0.9736522091609242, Aging Rate = 0.5093230644507499, Precision = 0.9558296856346996, f1 = 0.9646586345381526\n",
      "Test Loss = 0.06071422841923895, Recall = 0.9975678962302391, Aging Rate = 0.5182407782732064, precision = 0.9624560031286664\n",
      "Model in epoch 5 is saved.\n",
      "\n",
      "Epoch 6: Train Loss = 0.03880579795886207, Recall = 0.9943250912038913, Aging Rate = 0.503040129712201, Precision = 0.9883158742949234, f1 = 0.9913113760355629\n",
      "Epoch 7: Train Loss = 0.02894709351837611, Recall = 0.9959464937170652, Aging Rate = 0.5014187271990271, Precision = 0.9931285367825384, f1 = 0.994535519125683\n",
      "Epoch 8: Train Loss = 0.03875669592728723, Recall = 0.9943250912038913, Aging Rate = 0.5050668828536684, Precision = 0.9843499197431782, f1 = 0.9893123613631781\n",
      "Epoch 9: Train Loss = 0.035259008276596046, Recall = 0.9935143899473045, Aging Rate = 0.5028374543980543, Precision = 0.9879081015719468, f1 = 0.990703314470493\n",
      "Epoch 10: Train Loss = 0.037114639622682154, Recall = 0.993109039319011, Aging Rate = 0.5046615322253749, Precision = 0.9839357429718876, f1 = 0.9885011095420617\n",
      "Test Loss = 0.024175440536960687, Recall = 0.9979732468585326, Aging Rate = 0.5028374543980543, precision = 0.992341797662233\n",
      "Model in epoch 10 is saved.\n",
      "\n",
      "Epoch 11: Train Loss = 0.027586570751778162, Recall = 0.9979732468585326, Aging Rate = 0.5028374543980543, Precision = 0.992341797662233, f1 = 0.9951495553759094\n",
      "Epoch 12: Train Loss = 0.04169212868810908, Recall = 0.9918929874341306, Aging Rate = 0.5042561815970815, Precision = 0.9835209003215434, f1 = 0.9876892028254288\n",
      "Epoch 13: Train Loss = 0.03888986886822119, Recall = 0.9935143899473045, Aging Rate = 0.5044588569112282, Precision = 0.9847328244274809, f1 = 0.9891041162227603\n",
      "Epoch 14: Train Loss = 0.026935436200753705, Recall = 0.9975678962302391, Aging Rate = 0.5018240778273206, Precision = 0.9939418416801292, f1 = 0.9957515678737608\n",
      "Epoch 15: Train Loss = 0.020884043315480633, Recall = 0.9979732468585326, Aging Rate = 0.5, Precision = 0.9979732468585326, f1 = 0.9979732468585326\n",
      "Test Loss = 0.024097080690915353, Recall = 1.0, Aging Rate = 0.5044588569112282, precision = 0.9911611088790679\n",
      "\n",
      "Epoch 16: Train Loss = 0.04591015499745079, Recall = 0.9910822861775436, Aging Rate = 0.506890960680989, Precision = 0.9776089564174331, f1 = 0.9842995169082125\n",
      "Epoch 17: Train Loss = 0.04222182457097083, Recall = 0.9898662342926632, Aging Rate = 0.503040129712201, Precision = 0.983883964544722, f1 = 0.9868660335421299\n",
      "Epoch 18: Train Loss = 0.024500672328336838, Recall = 0.9987839481151196, Aging Rate = 0.5034454803404945, Precision = 0.9919484702093397, f1 = 0.9953544738436678\n",
      "Epoch 19: Train Loss = 0.02689692523273068, Recall = 0.9967571949736522, Aging Rate = 0.5026347790839076, Precision = 0.9915322580645162, f1 = 0.9941378613300992\n",
      "Epoch 20: Train Loss = 0.0317078132316754, Recall = 0.9963518443453587, Aging Rate = 0.5026347790839076, Precision = 0.9911290322580645, f1 = 0.9937335759045887\n",
      "Test Loss = 0.055123348485936655, Recall = 1.0, Aging Rate = 0.5273611674098095, precision = 0.9481168332052268\n",
      "\n",
      "Epoch 21: Train Loss = 0.03509386129101401, Recall = 0.9914876368058371, Aging Rate = 0.5018240778273206, Precision = 0.9878836833602584, f1 = 0.9896823791219908\n",
      "Epoch 22: Train Loss = 0.03678057787024062, Recall = 0.9943250912038913, Aging Rate = 0.5044588569112282, Precision = 0.9855363599839293, f1 = 0.989911218724778\n",
      "Epoch 23: Train Loss = 0.035944500292512054, Recall = 0.993109039319011, Aging Rate = 0.5040535062829348, Precision = 0.9851226377161239, f1 = 0.9890997174000807\n",
      "Epoch 24: Train Loss = 0.03498775307481703, Recall = 0.9943250912038913, Aging Rate = 0.503850830968788, Precision = 0.9867256637168141, f1 = 0.9905108015344235\n",
      "Epoch 25: Train Loss = 0.031157325181610244, Recall = 0.9955411430887718, Aging Rate = 0.503040129712201, Precision = 0.9895245769540693, f1 = 0.9925237421701354\n",
      "Test Loss = 0.062225018740062726, Recall = 1.0, Aging Rate = 0.532428050263478, precision = 0.9390940236010659\n",
      "\n",
      "Epoch 26: Train Loss = 0.03625287712647164, Recall = 0.9939197405755978, Aging Rate = 0.5034454803404945, Precision = 0.9871175523349437, f1 = 0.9905069682892346\n",
      "Epoch 27: Train Loss = 0.027419653416878912, Recall = 0.9967571949736522, Aging Rate = 0.5026347790839076, Precision = 0.9915322580645162, f1 = 0.9941378613300992\n",
      "Epoch 28: Train Loss = 0.03239101989788955, Recall = 0.9947304418321848, Aging Rate = 0.503040129712201, Precision = 0.9887187751813054, f1 = 0.9917154980804203\n",
      "Epoch 29: Train Loss = 0.033845648784579255, Recall = 0.9955411430887718, Aging Rate = 0.5048642075395217, Precision = 0.985949417904456, f1 = 0.990722065348931\n",
      "Epoch 30: Train Loss = 0.03266391695341542, Recall = 0.9947304418321848, Aging Rate = 0.503040129712201, Precision = 0.9887187751813054, f1 = 0.9917154980804203\n",
      "Test Loss = 0.031148868562452824, Recall = 0.9910822861775436, Aging Rate = 0.4955411430887718, precision = 1.0\n",
      "Model in epoch 30 is saved.\n",
      "\n",
      "Epoch 31: Train Loss = 0.026831583562750637, Recall = 0.9963518443453587, Aging Rate = 0.5024321037697609, Precision = 0.991528842275111, f1 = 0.9939344925192074\n",
      "Epoch 32: Train Loss = 0.04778144634425048, Recall = 0.9898662342926632, Aging Rate = 0.5056749087961087, Precision = 0.9787575150300601, f1 = 0.9842805320435308\n",
      "Epoch 33: Train Loss = 0.02504112902329574, Recall = 0.9975678962302391, Aging Rate = 0.5018240778273206, Precision = 0.9939418416801292, f1 = 0.9957515678737608\n",
      "Epoch 34: Train Loss = 0.03212796132837924, Recall = 0.9971625456019457, Aging Rate = 0.5050668828536684, Precision = 0.9871589085072231, f1 = 0.9921355111917726\n",
      "Epoch 35: Train Loss = 0.030422403772724364, Recall = 0.9959464937170652, Aging Rate = 0.5032428050263478, Precision = 0.9895287958115183, f1 = 0.9927272727272728\n",
      "Test Loss = 0.023197779385882637, Recall = 0.9947304418321848, Aging Rate = 0.49878394811511956, precision = 0.9971556277935798\n",
      "\n",
      "Epoch 36: Train Loss = 0.029042346928499708, Recall = 0.9955411430887718, Aging Rate = 0.5024321037697609, Precision = 0.990722065348931, f1 = 0.9931257581884352\n",
      "Epoch 37: Train Loss = 0.028255250133169315, Recall = 0.9963518443453587, Aging Rate = 0.5036481556546413, Precision = 0.9891348088531187, f1 = 0.992730210016155\n",
      "Epoch 38: Train Loss = 0.028441170114611607, Recall = 0.9967571949736522, Aging Rate = 0.5036481556546413, Precision = 0.9895372233400402, f1 = 0.9931340872374798\n",
      "Epoch 39: Train Loss = 0.027611022155972016, Recall = 0.9967571949736522, Aging Rate = 0.5018240778273206, Precision = 0.9931340872374798, f1 = 0.9949423427068582\n",
      "Epoch 40: Train Loss = 0.03332729124508264, Recall = 0.9955411430887718, Aging Rate = 0.5026347790839076, Precision = 0.9903225806451613, f1 = 0.9929250050535678\n",
      "Test Loss = 0.024580127417280166, Recall = 0.9983785974868261, Aging Rate = 0.5034454803404945, precision = 0.9915458937198067\n",
      "\n",
      "Epoch 41: Train Loss = 0.048111646944663765, Recall = 0.9874341305229023, Aging Rate = 0.5072963113092825, Precision = 0.9732321214542549, f1 = 0.9802816901408451\n",
      "Epoch 42: Train Loss = 0.02544060341319591, Recall = 0.9979732468585326, Aging Rate = 0.5022294284556141, Precision = 0.993543179983858, f1 = 0.9957532861476239\n",
      "Epoch 43: Train Loss = 0.022027875470993403, Recall = 0.9975678962302391, Aging Rate = 0.5012160518848804, Precision = 0.9951475940153659, f1 = 0.9963562753036437\n",
      "Epoch 44: Train Loss = 0.036334734477999724, Recall = 0.9927036886907175, Aging Rate = 0.5014187271990271, Precision = 0.9898949070331448, f1 = 0.991297308237199\n",
      "Epoch 45: Train Loss = 0.034070558992471585, Recall = 0.9943250912038913, Aging Rate = 0.5012160518848804, Precision = 0.9919126566922766, f1 = 0.9931174089068826\n",
      "Test Loss = 0.01824954348073817, Recall = 0.9995946493717065, Aging Rate = 0.5026347790839076, precision = 0.9943548387096774\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 46: Train Loss = 0.02368521436435077, Recall = 0.9979732468585326, Aging Rate = 0.500810701256587, Precision = 0.9963577498988264, f1 = 0.9971648440664237\n",
      "Epoch 47: Train Loss = 0.02432375254179719, Recall = 0.9975678962302391, Aging Rate = 0.5010133765707336, Precision = 0.9955501618122977, f1 = 0.996558007693865\n",
      "Epoch 48: Train Loss = 0.051282292930314936, Recall = 0.9870287798946088, Aging Rate = 0.5060802594244022, Precision = 0.9751702042450942, f1 = 0.9810636583400484\n",
      "Epoch 49: Train Loss = 0.027185007611559165, Recall = 0.9975678962302391, Aging Rate = 0.5048642075395217, Precision = 0.9879566439181052, f1 = 0.9927390076643807\n",
      "Epoch 50: Train Loss = 0.02351921634619469, Recall = 0.9983785974868261, Aging Rate = 0.5022294284556141, Precision = 0.9939467312348669, f1 = 0.9961577350859454\n",
      "Test Loss = 0.017704532831683786, Recall = 1.0, Aging Rate = 0.5018240778273206, precision = 0.9963651050080775\n",
      "Model in epoch 50 is saved.\n",
      "\n",
      "Epoch 51: Train Loss = 0.02338796541061559, Recall = 0.999189298743413, Aging Rate = 0.5016214025131739, Precision = 0.9959595959595959, f1 = 0.9975718332658842\n",
      "Epoch 52: Train Loss = 0.02611305174445352, Recall = 0.9979732468585326, Aging Rate = 0.5026347790839076, Precision = 0.992741935483871, f1 = 0.9953507176066303\n",
      "Epoch 53: Train Loss = 0.053389244178709445, Recall = 0.9902715849209567, Aging Rate = 0.5111471422780706, Precision = 0.9686756542426646, f1 = 0.9793545800761677\n",
      "Epoch 54: Train Loss = 0.029997743240338277, Recall = 0.9935143899473045, Aging Rate = 0.5014187271990271, Precision = 0.9907033144704931, f1 = 0.9921068609593199\n",
      "Epoch 55: Train Loss = 0.027508544577149744, Recall = 0.9963518443453587, Aging Rate = 0.5014187271990271, Precision = 0.9935327405012127, f1 = 0.9949402954867437\n",
      "Test Loss = 0.025274844619701833, Recall = 0.999189298743413, Aging Rate = 0.5046615322253749, precision = 0.9899598393574297\n",
      "\n",
      "Epoch 56: Train Loss = 0.02334418887424237, Recall = 0.9979732468585326, Aging Rate = 0.5018240778273206, Precision = 0.994345718901454, f1 = 0.9961561804572122\n",
      "Epoch 57: Train Loss = 0.04701600123210431, Recall = 0.9878394811511958, Aging Rate = 0.5046615322253749, Precision = 0.978714859437751, f1 = 0.9832560016138794\n",
      "Epoch 58: Train Loss = 0.02880836291035564, Recall = 0.9955411430887718, Aging Rate = 0.503850830968788, Precision = 0.9879324215607401, f1 = 0.9917221885725822\n",
      "Epoch 59: Train Loss = 0.023511470592307793, Recall = 0.9987839481151196, Aging Rate = 0.5018240778273206, Precision = 0.9951534733441034, f1 = 0.9969654056241151\n",
      "Epoch 60: Train Loss = 0.021389344331884268, Recall = 0.999189298743413, Aging Rate = 0.5014187271990271, Precision = 0.9963621665319321, f1 = 0.9977737300141671\n",
      "Test Loss = 0.020260757784407103, Recall = 0.9967571949736522, Aging Rate = 0.4983785974868261, precision = 1.0\n",
      "Model in epoch 60 is saved.\n",
      "\n",
      "Epoch 61: Train Loss = 0.024437347635019754, Recall = 0.9983785974868261, Aging Rate = 0.5014187271990271, Precision = 0.9955537590945837, f1 = 0.9969641772920461\n",
      "Epoch 62: Train Loss = 0.0380421139376882, Recall = 0.9939197405755978, Aging Rate = 0.5054722334819619, Precision = 0.983159582999198, f1 = 0.9885103809715783\n",
      "Epoch 63: Train Loss = 0.03477334283083907, Recall = 0.9939197405755978, Aging Rate = 0.5018240778273206, Precision = 0.9903069466882067, f1 = 0.9921100546226987\n",
      "Epoch 64: Train Loss = 0.028307186333929955, Recall = 0.9951357924604783, Aging Rate = 0.5006080259424402, Precision = 0.9939271255060729, f1 = 0.9945310917561271\n",
      "Epoch 65: Train Loss = 0.027488782711781602, Recall = 0.9963518443453587, Aging Rate = 0.5018240778273206, Precision = 0.9927302100161551, f1 = 0.9945377301234068\n",
      "Test Loss = 0.02520665929120081, Recall = 0.9975678962302391, Aging Rate = 0.5032428050263478, precision = 0.9911397503020539\n",
      "\n",
      "Epoch 66: Train Loss = 0.02616119026544307, Recall = 0.9963518443453587, Aging Rate = 0.5020267531414674, Precision = 0.9923294307630198, f1 = 0.9943365695792881\n",
      "Epoch 67: Train Loss = 0.03006763082340414, Recall = 0.9975678962302391, Aging Rate = 0.5044588569112282, Precision = 0.9887505022097228, f1 = 0.9931396287328491\n",
      "Epoch 68: Train Loss = 0.024549112113209287, Recall = 0.9971625456019457, Aging Rate = 0.5012160518848804, Precision = 0.9947432268499797, f1 = 0.9959514170040485\n",
      "Epoch 69: Train Loss = 0.03211709706661645, Recall = 0.9947304418321848, Aging Rate = 0.5026347790839076, Precision = 0.989516129032258, f1 = 0.9921164342025469\n",
      "Epoch 70: Train Loss = 0.034445996977234834, Recall = 0.9927036886907175, Aging Rate = 0.5032428050263478, Precision = 0.9863068868304471, f1 = 0.9894949494949494\n",
      "Test Loss = 0.028556118133758357, Recall = 0.9987839481151196, Aging Rate = 0.5060802594244022, precision = 0.986784140969163\n",
      "\n",
      "Epoch 71: Train Loss = 0.03738909986483203, Recall = 0.992298338062424, Aging Rate = 0.5026347790839076, Precision = 0.9870967741935484, f1 = 0.9896907216494845\n",
      "Epoch 72: Train Loss = 0.02279633167265855, Recall = 0.9987839481151196, Aging Rate = 0.5020267531414674, Precision = 0.994751715785224, f1 = 0.9967637540453075\n",
      "Epoch 73: Train Loss = 0.02075363614248738, Recall = 0.9983785974868261, Aging Rate = 0.5010133765707336, Precision = 0.9963592233009708, f1 = 0.997367888236485\n",
      "Epoch 74: Train Loss = 0.02934977373774199, Recall = 0.9963518443453587, Aging Rate = 0.5010133765707336, Precision = 0.9943365695792881, f1 = 0.9953431868799352\n",
      "Epoch 75: Train Loss = 0.027907402173475936, Recall = 0.9971625456019457, Aging Rate = 0.5024321037697609, Precision = 0.9923356192012909, f1 = 0.9947432268499798\n",
      "Test Loss = 0.02374286181365981, Recall = 1.0, Aging Rate = 0.5054722334819619, precision = 0.9891740176423416\n",
      "\n",
      "Epoch 76: Train Loss = 0.031432973858940005, Recall = 0.9951357924604783, Aging Rate = 0.5026347790839076, Precision = 0.9899193548387096, f1 = 0.9925207196280573\n",
      "Epoch 77: Train Loss = 0.04036371700728428, Recall = 0.9910822861775436, Aging Rate = 0.5044588569112282, Precision = 0.9823222177581358, f1 = 0.986682808716707\n",
      "Epoch 78: Train Loss = 0.024250431620600067, Recall = 0.9979732468585326, Aging Rate = 0.5024321037697609, Precision = 0.9931423961274708, f1 = 0.9955519611807523\n",
      "Epoch 79: Train Loss = 0.02093546529140823, Recall = 0.9983785974868261, Aging Rate = 0.5012160518848804, Precision = 0.9959563283461383, f1 = 0.9971659919028342\n",
      "Epoch 80: Train Loss = 0.02832498598691298, Recall = 0.9971625456019457, Aging Rate = 0.5018240778273206, Precision = 0.9935379644588045, f1 = 0.9953469552903095\n",
      "Test Loss = 0.028788764254549796, Recall = 0.9910822861775436, Aging Rate = 0.4959464937170653, precision = 0.9991826726604005\n",
      "\n",
      "Epoch 81: Train Loss = 0.030475434445880616, Recall = 0.9951357924604783, Aging Rate = 0.5028374543980543, Precision = 0.9895203546956872, f1 = 0.99232012934519\n",
      "Epoch 82: Train Loss = 0.03764268436763975, Recall = 0.9918929874341306, Aging Rate = 0.5032428050263478, Precision = 0.9855014095851792, f1 = 0.9886868686868687\n",
      "Epoch 83: Train Loss = 0.02760300043491661, Recall = 0.9959464937170652, Aging Rate = 0.5006080259424402, Precision = 0.9947368421052631, f1 = 0.9953413003848491\n",
      "Epoch 84: Train Loss = 0.021800228828706986, Recall = 0.999189298743413, Aging Rate = 0.5018240778273206, Precision = 0.9955573505654282, f1 = 0.9973700182075663\n",
      "Epoch 85: Train Loss = 0.024552194171339383, Recall = 0.9983785974868261, Aging Rate = 0.5016214025131739, Precision = 0.9951515151515151, f1 = 0.9967624443545124\n",
      "Test Loss = 0.02799011934658095, Recall = 0.993109039319011, Aging Rate = 0.4965545196595055, precision = 1.0\n",
      "\n",
      "Epoch 86: Train Loss = 0.048315590207495575, Recall = 0.9898662342926632, Aging Rate = 0.5066882853668423, Precision = 0.9768, f1 = 0.9832897120998592\n",
      "Epoch 87: Train Loss = 0.038012291961166456, Recall = 0.992298338062424, Aging Rate = 0.5054722334819619, Precision = 0.9815557337610264, f1 = 0.986897802862326\n",
      "Epoch 88: Train Loss = 0.021905352618963578, Recall = 0.9975678962302391, Aging Rate = 0.5014187271990271, Precision = 0.9947453516572352, f1 = 0.9961546245699251\n",
      "Epoch 89: Train Loss = 0.020708900677016813, Recall = 0.9995946493717065, Aging Rate = 0.5016214025131739, Precision = 0.9963636363636363, f1 = 0.9979765277215702\n",
      "Epoch 90: Train Loss = 0.024880573446634004, Recall = 0.9975678962302391, Aging Rate = 0.5022294284556141, Precision = 0.9931396287328491, f1 = 0.9953488372093023\n",
      "Test Loss = 0.02017015794969349, Recall = 0.9987839481151196, Aging Rate = 0.5012160518848804, precision = 0.9963606955115245\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 91: Train Loss = 0.02667427231962738, Recall = 0.9987839481151196, Aging Rate = 0.5036481556546413, Precision = 0.9915492957746479, f1 = 0.9951534733441033\n",
      "Epoch 92: Train Loss = 0.027961770460284405, Recall = 0.9963518443453587, Aging Rate = 0.5014187271990271, Precision = 0.9935327405012127, f1 = 0.9949402954867437\n",
      "Epoch 93: Train Loss = 0.030190873666872946, Recall = 0.9951357924604783, Aging Rate = 0.5014187271990271, Precision = 0.99232012934519, f1 = 0.993725966403562\n",
      "Epoch 94: Train Loss = 0.039955168121381474, Recall = 0.9902715849209567, Aging Rate = 0.5028374543980543, Precision = 0.9846835953244659, f1 = 0.9874696847210995\n",
      "Epoch 95: Train Loss = 0.031001701825692868, Recall = 0.9943250912038913, Aging Rate = 0.5024321037697609, Precision = 0.9895118999596612, f1 = 0.9919126566922766\n",
      "Test Loss = 0.014462347174298137, Recall = 0.999189298743413, Aging Rate = 0.5006080259424402, precision = 0.9979757085020243\n",
      "\n",
      "Epoch 96: Train Loss = 0.019416953851916212, Recall = 0.9987839481151196, Aging Rate = 0.5012160518848804, Precision = 0.9963606955115245, f1 = 0.9975708502024292\n",
      "Epoch 97: Train Loss = 0.021526760459067033, Recall = 0.9987839481151196, Aging Rate = 0.5006080259424402, Precision = 0.9975708502024292, f1 = 0.9981770305853758\n",
      "Epoch 98: Train Loss = 0.02454970778997823, Recall = 0.9967571949736522, Aging Rate = 0.5010133765707336, Precision = 0.9947411003236246, f1 = 0.9957481271512453\n",
      "Epoch 99: Train Loss = 0.03631896536795775, Recall = 0.9943250912038913, Aging Rate = 0.5034454803404945, Precision = 0.9875201288244766, f1 = 0.9909109270854374\n",
      "Epoch 100: Train Loss = 0.04037103951611546, Recall = 0.9910822861775436, Aging Rate = 0.5034454803404945, Precision = 0.9842995169082126, f1 = 0.987679256715815\n",
      "Test Loss = 0.023113707519152604, Recall = 0.9959464937170652, Aging Rate = 0.49858127280097286, precision = 0.998780487804878\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ecd912722af41d0b77dba402da70136",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss = 0.356614397878728, Recall = 0.946088366436968, Aging Rate = 0.6931495743818403, Precision = 0.6824561403508772, f1 = 0.7929335824698488\n",
      "Epoch 2: Train Loss = 0.1680096594317026, Recall = 0.960680989055533, Aging Rate = 0.5289825699229834, Precision = 0.9080459770114943, f1 = 0.9336222178451841\n",
      "Epoch 3: Train Loss = 0.11910691875458537, Recall = 0.9740575597892177, Aging Rate = 0.5170247263883259, Precision = 0.941983535868287, f1 = 0.9577520924671185\n",
      "Epoch 4: Train Loss = 0.10127628376510374, Recall = 0.9724361572760438, Aging Rate = 0.5101337657073368, Precision = 0.9531187922129519, f1 = 0.9626805778491171\n",
      "Epoch 5: Train Loss = 0.09129218819064557, Recall = 0.9752736116740981, Aging Rate = 0.5079043372517228, Precision = 0.960095770151636, f1 = 0.9676251759501306\n",
      "Test Loss = 0.042515843547106746, Recall = 0.9979732468585326, Aging Rate = 0.5048642075395217, precision = 0.988358089120835\n",
      "Model in epoch 5 is saved.\n",
      "\n",
      "Epoch 6: Train Loss = 0.03795438183431544, Recall = 0.9959464937170652, Aging Rate = 0.5010133765707336, Precision = 0.9939320388349514, f1 = 0.9949382466086252\n",
      "Epoch 7: Train Loss = 0.029068970259990244, Recall = 0.9975678962302391, Aging Rate = 0.5020267531414674, Precision = 0.9935405732741219, f1 = 0.9955501618122977\n",
      "Epoch 8: Train Loss = 0.031104428306324646, Recall = 0.9963518443453587, Aging Rate = 0.503040129712201, Precision = 0.9903303787268332, f1 = 0.9933319862598504\n",
      "Epoch 9: Train Loss = 0.04657998566757729, Recall = 0.9902715849209567, Aging Rate = 0.5052695581678152, Precision = 0.9799438427597272, f1 = 0.9850806451612905\n",
      "Epoch 10: Train Loss = 0.030532401608719208, Recall = 0.9975678962302391, Aging Rate = 0.5020267531414674, Precision = 0.9935405732741219, f1 = 0.9955501618122977\n",
      "Test Loss = 0.027861975151539622, Recall = 0.999189298743413, Aging Rate = 0.5070936359951358, precision = 0.9852118305355716\n",
      "\n",
      "Epoch 11: Train Loss = 0.030814577510899797, Recall = 0.9971625456019457, Aging Rate = 0.5052695581678152, Precision = 0.98676293622142, f1 = 0.9919354838709677\n",
      "Epoch 12: Train Loss = 0.03446503091387581, Recall = 0.9947304418321848, Aging Rate = 0.5032428050263478, Precision = 0.9883205799436166, f1 = 0.9915151515151516\n",
      "Epoch 13: Train Loss = 0.03523252325462435, Recall = 0.9943250912038913, Aging Rate = 0.5040535062829348, Precision = 0.9863289103337354, f1 = 0.9903108599111828\n",
      "Epoch 14: Train Loss = 0.034181021747376014, Recall = 0.9947304418321848, Aging Rate = 0.5032428050263478, Precision = 0.9883205799436166, f1 = 0.9915151515151516\n",
      "Epoch 15: Train Loss = 0.029438854343539846, Recall = 0.9975678962302391, Aging Rate = 0.5036481556546413, Precision = 0.9903420523138833, f1 = 0.9939418416801292\n",
      "Test Loss = 0.03611806587002383, Recall = 1.0, Aging Rate = 0.5117551682205107, precision = 0.977029702970297\n",
      "\n",
      "Epoch 16: Train Loss = 0.02742225420066689, Recall = 0.9967571949736522, Aging Rate = 0.503040129712201, Precision = 0.9907332796132151, f1 = 0.993736108304708\n",
      "Epoch 17: Train Loss = 0.03781544326841952, Recall = 0.9947304418321848, Aging Rate = 0.5054722334819619, Precision = 0.9839615076182838, f1 = 0.9893166700262044\n",
      "Epoch 18: Train Loss = 0.043893869052689036, Recall = 0.9890555330360762, Aging Rate = 0.5042561815970815, Precision = 0.9807073954983923, f1 = 0.9848637739656911\n",
      "Epoch 19: Train Loss = 0.02894749475154538, Recall = 0.9967571949736522, Aging Rate = 0.5036481556546413, Precision = 0.9895372233400402, f1 = 0.9931340872374798\n",
      "Epoch 20: Train Loss = 0.0284776620568355, Recall = 0.9951357924604783, Aging Rate = 0.5012160518848804, Precision = 0.9927213910230489, f1 = 0.9939271255060729\n",
      "Test Loss = 0.029577998270216104, Recall = 1.0, Aging Rate = 0.5070936359951358, precision = 0.9860111910471623\n",
      "\n",
      "Epoch 21: Train Loss = 0.03528270154042274, Recall = 0.9943250912038913, Aging Rate = 0.5046615322253749, Precision = 0.9851405622489959, f1 = 0.98971151906395\n",
      "Epoch 22: Train Loss = 0.03393116543755799, Recall = 0.9935143899473045, Aging Rate = 0.5034454803404945, Precision = 0.9867149758454107, f1 = 0.9901030094930318\n",
      "Epoch 23: Train Loss = 0.0356045071296862, Recall = 0.9955411430887718, Aging Rate = 0.5040535062829348, Precision = 0.987535182951347, f1 = 0.9915220024222849\n",
      "Epoch 24: Train Loss = 0.036048477084459345, Recall = 0.9927036886907175, Aging Rate = 0.5032428050263478, Precision = 0.9863068868304471, f1 = 0.9894949494949494\n",
      "Epoch 25: Train Loss = 0.02991581349556244, Recall = 0.9951357924604783, Aging Rate = 0.5014187271990271, Precision = 0.99232012934519, f1 = 0.993725966403562\n",
      "Test Loss = 0.01828137447247391, Recall = 0.9967571949736522, Aging Rate = 0.4993919740575598, precision = 0.9979707792207793\n",
      "Model in epoch 25 is saved.\n",
      "\n",
      "Epoch 26: Train Loss = 0.02507815198133989, Recall = 0.9971625456019457, Aging Rate = 0.5018240778273206, Precision = 0.9935379644588045, f1 = 0.9953469552903095\n",
      "Epoch 27: Train Loss = 0.034656862209784714, Recall = 0.992298338062424, Aging Rate = 0.5014187271990271, Precision = 0.9894907033144705, f1 = 0.9908925318761385\n",
      "Epoch 28: Train Loss = 0.043687277610168725, Recall = 0.9927036886907175, Aging Rate = 0.5079043372517228, Precision = 0.9772545889864326, f1 = 0.9849185602252162\n",
      "Epoch 29: Train Loss = 0.02518465035275247, Recall = 0.9983785974868261, Aging Rate = 0.5032428050263478, Precision = 0.9919452275473218, f1 = 0.9951515151515152\n",
      "Epoch 30: Train Loss = 0.02685296146012616, Recall = 0.9967571949736522, Aging Rate = 0.500810701256587, Precision = 0.9951436665317686, f1 = 0.9959497772377481\n",
      "Test Loss = 0.034188614696880365, Recall = 1.0, Aging Rate = 0.5109444669639238, precision = 0.978579928599762\n",
      "\n",
      "Epoch 31: Train Loss = 0.03978438810854969, Recall = 0.9927036886907175, Aging Rate = 0.5054722334819619, Precision = 0.9819566960705693, f1 = 0.9873009473896391\n",
      "Epoch 32: Train Loss = 0.028569399204216882, Recall = 0.9951357924604783, Aging Rate = 0.503040129712201, Precision = 0.9891216760676873, f1 = 0.9921196201252779\n",
      "Epoch 33: Train Loss = 0.03288693150441624, Recall = 0.992298338062424, Aging Rate = 0.5012160518848804, Precision = 0.9898908208653457, f1 = 0.9910931174089069\n",
      "Epoch 34: Train Loss = 0.023571908999465475, Recall = 0.9987839481151196, Aging Rate = 0.5016214025131739, Precision = 0.9955555555555555, f1 = 0.9971671388101984\n",
      "Epoch 35: Train Loss = 0.037898282554826614, Recall = 0.9935143899473045, Aging Rate = 0.5052695581678152, Precision = 0.9831528279181708, f1 = 0.9883064516129032\n",
      "Test Loss = 0.027110543934062856, Recall = 0.9955411430887718, Aging Rate = 0.4995946493717065, precision = 0.9963488843813387\n",
      "\n",
      "Epoch 36: Train Loss = 0.030402895166694567, Recall = 0.9943250912038913, Aging Rate = 0.5016214025131739, Precision = 0.9911111111111112, f1 = 0.9927154997976528\n",
      "Epoch 37: Train Loss = 0.030194309446847433, Recall = 0.9943250912038913, Aging Rate = 0.5020267531414674, Precision = 0.9903108599111828, f1 = 0.9923139158576051\n",
      "Epoch 38: Train Loss = 0.03702330325564417, Recall = 0.993109039319011, Aging Rate = 0.5028374543980543, Precision = 0.9875050382910117, f1 = 0.990299110751819\n",
      "Epoch 39: Train Loss = 0.025931691827896543, Recall = 0.9967571949736522, Aging Rate = 0.5022294284556141, Precision = 0.9923325262308313, f1 = 0.9945399393326593\n",
      "Epoch 40: Train Loss = 0.042131481112902484, Recall = 0.9910822861775436, Aging Rate = 0.5044588569112282, Precision = 0.9823222177581358, f1 = 0.986682808716707\n",
      "Test Loss = 0.046551574020067786, Recall = 0.9959464937170652, Aging Rate = 0.5198621807863802, precision = 0.9578947368421052\n",
      "\n",
      "Epoch 41: Train Loss = 0.03038592047081074, Recall = 0.9959464937170652, Aging Rate = 0.503040129712201, Precision = 0.9899274778404512, f1 = 0.9929278642149929\n",
      "Epoch 42: Train Loss = 0.025102155690429107, Recall = 0.9959464937170652, Aging Rate = 0.5010133765707336, Precision = 0.9939320388349514, f1 = 0.9949382466086252\n",
      "Epoch 43: Train Loss = 0.03285434415294397, Recall = 0.9947304418321848, Aging Rate = 0.503850830968788, Precision = 0.9871279163314561, f1 = 0.9909145972138098\n",
      "Epoch 44: Train Loss = 0.03632716529817295, Recall = 0.9955411430887718, Aging Rate = 0.5072963113092825, Precision = 0.9812225329604475, f1 = 0.9883299798792757\n",
      "Epoch 45: Train Loss = 0.03200698706353884, Recall = 0.9939197405755978, Aging Rate = 0.5034454803404945, Precision = 0.9871175523349437, f1 = 0.9905069682892346\n",
      "Test Loss = 0.017571896882399306, Recall = 1.0, Aging Rate = 0.5020267531414674, precision = 0.9959628582963262\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 46: Train Loss = 0.02036938428226443, Recall = 0.999189298743413, Aging Rate = 0.5012160518848804, Precision = 0.9967650626769107, f1 = 0.9979757085020243\n",
      "Epoch 47: Train Loss = 0.03852867883228801, Recall = 0.992298338062424, Aging Rate = 0.5040535062829348, Precision = 0.9843184559710495, f1 = 0.9882922890593459\n",
      "Epoch 48: Train Loss = 0.037465007008511284, Recall = 0.992298338062424, Aging Rate = 0.5028374543980543, Precision = 0.9866989117291415, f1 = 0.9894907033144705\n",
      "Epoch 49: Train Loss = 0.038809588259024856, Recall = 0.9918929874341306, Aging Rate = 0.5034454803404945, Precision = 0.9851046698872786, f1 = 0.9884871743082206\n",
      "Epoch 50: Train Loss = 0.030260662134679393, Recall = 0.9955411430887718, Aging Rate = 0.5024321037697609, Precision = 0.990722065348931, f1 = 0.9931257581884352\n",
      "Test Loss = 0.01824741973334045, Recall = 0.9995946493717065, Aging Rate = 0.5024321037697609, precision = 0.9947559499798305\n",
      "\n",
      "Epoch 51: Train Loss = 0.02101080413314317, Recall = 0.999189298743413, Aging Rate = 0.5014187271990271, Precision = 0.9963621665319321, f1 = 0.9977737300141671\n",
      "Epoch 52: Train Loss = 0.02184781245660772, Recall = 0.9975678962302391, Aging Rate = 0.5004053506282935, Precision = 0.9967598217901985, f1 = 0.997163695299838\n",
      "Epoch 53: Train Loss = 0.036616090205688685, Recall = 0.9951357924604783, Aging Rate = 0.5048642075395217, Precision = 0.9855479727017262, f1 = 0.9903186768858411\n",
      "Epoch 54: Train Loss = 0.03405307628286842, Recall = 0.993109039319011, Aging Rate = 0.5034454803404945, Precision = 0.9863123993558777, f1 = 0.989699050696829\n",
      "Epoch 55: Train Loss = 0.02261449838601533, Recall = 0.9979732468585326, Aging Rate = 0.500810701256587, Precision = 0.9963577498988264, f1 = 0.9971648440664237\n",
      "Test Loss = 0.021199679387983252, Recall = 0.999189298743413, Aging Rate = 0.5002026753141467, precision = 0.9987844408427877\n",
      "Model in epoch 55 is saved.\n",
      "\n",
      "Epoch 56: Train Loss = 0.027230823035780408, Recall = 0.9971625456019457, Aging Rate = 0.5020267531414674, Precision = 0.9931368591037545, f1 = 0.9951456310679612\n",
      "Epoch 57: Train Loss = 0.03328305892163097, Recall = 0.9955411430887718, Aging Rate = 0.5046615322253749, Precision = 0.9863453815261044, f1 = 0.9909219285858383\n",
      "Epoch 58: Train Loss = 0.029963662948294792, Recall = 0.9963518443453587, Aging Rate = 0.5034454803404945, Precision = 0.9895330112721417, f1 = 0.9929307210664512\n",
      "Epoch 59: Train Loss = 0.030962081770267283, Recall = 0.9963518443453587, Aging Rate = 0.5034454803404945, Precision = 0.9895330112721417, f1 = 0.9929307210664512\n",
      "Epoch 60: Train Loss = 0.035777568509088725, Recall = 0.993109039319011, Aging Rate = 0.5026347790839076, Precision = 0.9879032258064516, f1 = 0.9904992925005054\n",
      "Test Loss = 0.031722335660559084, Recall = 0.9987839481151196, Aging Rate = 0.5091203891366032, precision = 0.9808917197452229\n",
      "\n",
      "Epoch 61: Train Loss = 0.034382890103119464, Recall = 0.992298338062424, Aging Rate = 0.5014187271990271, Precision = 0.9894907033144705, f1 = 0.9908925318761385\n",
      "Epoch 62: Train Loss = 0.029196244793976905, Recall = 0.9951357924604783, Aging Rate = 0.5016214025131739, Precision = 0.9919191919191919, f1 = 0.9935248887090247\n",
      "Epoch 63: Train Loss = 0.01883693190818531, Recall = 0.9995946493717065, Aging Rate = 0.5018240778273206, Precision = 0.9959612277867528, f1 = 0.9977746307910176\n",
      "Epoch 64: Train Loss = 0.02374178210079344, Recall = 0.9979732468585326, Aging Rate = 0.5006080259424402, Precision = 0.9967611336032388, f1 = 0.9973668219566538\n",
      "Epoch 65: Train Loss = 0.026659775540431984, Recall = 0.9979732468585326, Aging Rate = 0.5016214025131739, Precision = 0.9947474747474747, f1 = 0.9963577498988264\n",
      "Test Loss = 0.026337293568994044, Recall = 0.9971625456019457, Aging Rate = 0.5, precision = 0.9971625456019457\n",
      "\n",
      "Epoch 66: Train Loss = 0.04784693299495605, Recall = 0.9898662342926632, Aging Rate = 0.506890960680989, Precision = 0.9764094362255098, f1 = 0.9830917874396136\n",
      "Epoch 67: Train Loss = 0.03569722110968057, Recall = 0.9910822861775436, Aging Rate = 0.5034454803404945, Precision = 0.9842995169082126, f1 = 0.987679256715815\n",
      "Epoch 68: Train Loss = 0.036360199810475724, Recall = 0.9939197405755978, Aging Rate = 0.5034454803404945, Precision = 0.9871175523349437, f1 = 0.9905069682892346\n",
      "Epoch 69: Train Loss = 0.02958621381565681, Recall = 0.9955411430887718, Aging Rate = 0.5036481556546413, Precision = 0.9883299798792756, f1 = 0.9919224555735057\n",
      "Epoch 70: Train Loss = 0.023460216501997245, Recall = 0.9975678962302391, Aging Rate = 0.5012160518848804, Precision = 0.9951475940153659, f1 = 0.9963562753036437\n",
      "Test Loss = 0.020449158257265346, Recall = 0.9971625456019457, Aging Rate = 0.49858127280097286, precision = 1.0\n",
      "Model in epoch 70 is saved.\n",
      "\n",
      "Epoch 71: Train Loss = 0.020319478709762594, Recall = 0.9995946493717065, Aging Rate = 0.5014187271990271, Precision = 0.9967663702506063, f1 = 0.9981785063752276\n",
      "Epoch 72: Train Loss = 0.022175918592583277, Recall = 0.9983785974868261, Aging Rate = 0.5, Precision = 0.9983785974868261, f1 = 0.9983785974868261\n",
      "Epoch 73: Train Loss = 0.04450139521598894, Recall = 0.9886501824077827, Aging Rate = 0.5032428050263478, Precision = 0.982279500604108, f1 = 0.9854545454545455\n",
      "Epoch 74: Train Loss = 0.034264884869495194, Recall = 0.993109039319011, Aging Rate = 0.5026347790839076, Precision = 0.9879032258064516, f1 = 0.9904992925005054\n",
      "Epoch 75: Train Loss = 0.02360212583892141, Recall = 0.9967571949736522, Aging Rate = 0.5016214025131739, Precision = 0.9935353535353535, f1 = 0.9951436665317686\n",
      "Test Loss = 0.016435107600546384, Recall = 0.9995946493717065, Aging Rate = 0.5006080259424402, precision = 0.9983805668016195\n",
      "\n",
      "Epoch 76: Train Loss = 0.02151557126652146, Recall = 0.9987839481151196, Aging Rate = 0.500810701256587, Precision = 0.9971671388101983, f1 = 0.997974888618874\n",
      "Epoch 77: Train Loss = 0.020372583371533113, Recall = 1.0, Aging Rate = 0.5020267531414674, Precision = 0.9959628582963262, f1 = 0.9979773462783171\n",
      "Epoch 78: Train Loss = 0.03870065916759231, Recall = 0.9939197405755978, Aging Rate = 0.5060802594244022, Precision = 0.9819783740488587, f1 = 0.9879129734085415\n",
      "Epoch 79: Train Loss = 0.04396362762398381, Recall = 0.9898662342926632, Aging Rate = 0.5048642075395217, Precision = 0.9803291850662385, f1 = 0.9850746268656716\n",
      "Epoch 80: Train Loss = 0.025313017082358717, Recall = 0.9983785974868261, Aging Rate = 0.5028374543980543, Precision = 0.992744860943168, f1 = 0.9955537590945837\n",
      "Test Loss = 0.018857744903113795, Recall = 1.0, Aging Rate = 0.503040129712201, precision = 0.9939564867042707\n",
      "\n",
      "Epoch 81: Train Loss = 0.017455623827174, Recall = 0.9995946493717065, Aging Rate = 0.5006080259424402, Precision = 0.9983805668016195, f1 = 0.9989872392140976\n",
      "Epoch 82: Train Loss = 0.02785692738696033, Recall = 0.9971625456019457, Aging Rate = 0.5026347790839076, Precision = 0.9919354838709677, f1 = 0.9945421467556095\n",
      "Epoch 83: Train Loss = 0.029144870202624466, Recall = 0.9955411430887718, Aging Rate = 0.5018240778273206, Precision = 0.9919224555735057, f1 = 0.9937285049565041\n",
      "Epoch 84: Train Loss = 0.0238646710837765, Recall = 0.9971625456019457, Aging Rate = 0.500810701256587, Precision = 0.9955483609874545, f1 = 0.9963547995139733\n",
      "Epoch 85: Train Loss = 0.02998868948117466, Recall = 0.9967571949736522, Aging Rate = 0.5032428050263478, Precision = 0.9903342730567861, f1 = 0.9935353535353535\n",
      "Test Loss = 0.02168528580404652, Recall = 0.9975678962302391, Aging Rate = 0.5002026753141467, precision = 0.997163695299838\n",
      "\n",
      "Epoch 86: Train Loss = 0.020154504515238206, Recall = 0.9995946493717065, Aging Rate = 0.5014187271990271, Precision = 0.9967663702506063, f1 = 0.9981785063752276\n",
      "Epoch 87: Train Loss = 0.02958656100455836, Recall = 0.9959464937170652, Aging Rate = 0.5026347790839076, Precision = 0.9907258064516129, f1 = 0.9933292904790781\n",
      "Epoch 88: Train Loss = 0.03182323185695289, Recall = 0.9951357924604783, Aging Rate = 0.5026347790839076, Precision = 0.9899193548387096, f1 = 0.9925207196280573\n",
      "Epoch 89: Train Loss = 0.04002984219057434, Recall = 0.9927036886907175, Aging Rate = 0.5050668828536684, Precision = 0.9827447833065811, f1 = 0.9876991328896955\n",
      "Epoch 90: Train Loss = 0.03605000475530271, Recall = 0.9918929874341306, Aging Rate = 0.5034454803404945, Precision = 0.9851046698872786, f1 = 0.9884871743082206\n",
      "Test Loss = 0.022705807807365676, Recall = 0.9967571949736522, Aging Rate = 0.49979732468585325, precision = 0.9971613949716139\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 91: Train Loss = 0.02092290052975727, Recall = 0.9995946493717065, Aging Rate = 0.5026347790839076, Precision = 0.9943548387096774, f1 = 0.9969678593086719\n",
      "Epoch 92: Train Loss = 0.023356695241930153, Recall = 0.9979732468585326, Aging Rate = 0.5014187271990271, Precision = 0.9951495553759094, f1 = 0.9965594009309856\n",
      "Epoch 93: Train Loss = 0.02704318143339789, Recall = 0.9979732468585326, Aging Rate = 0.5022294284556141, Precision = 0.993543179983858, f1 = 0.9957532861476239\n",
      "Epoch 94: Train Loss = 0.03551469850012248, Recall = 0.9914876368058371, Aging Rate = 0.500810701256587, Precision = 0.9898826386078511, f1 = 0.9906844876468206\n",
      "Epoch 95: Train Loss = 0.023635506994998137, Recall = 0.9967571949736522, Aging Rate = 0.5014187271990271, Precision = 0.9939369442198869, f1 = 0.9953450718478041\n",
      "Test Loss = 0.02499656559673697, Recall = 0.9947304418321848, Aging Rate = 0.49878394811511956, precision = 0.9971556277935798\n",
      "\n",
      "Epoch 96: Train Loss = 0.02706261460682929, Recall = 0.9963518443453587, Aging Rate = 0.5004053506282935, Precision = 0.9955447549615228, f1 = 0.9959481361426257\n",
      "Epoch 97: Train Loss = 0.037001826953298414, Recall = 0.9918929874341306, Aging Rate = 0.5032428050263478, Precision = 0.9855014095851792, f1 = 0.9886868686868687\n",
      "Epoch 98: Train Loss = 0.03746434774122948, Recall = 0.992298338062424, Aging Rate = 0.5058775841102554, Precision = 0.9807692307692307, f1 = 0.9865001007455168\n",
      "Epoch 99: Train Loss = 0.026803212553673444, Recall = 0.9963518443453587, Aging Rate = 0.5018240778273206, Precision = 0.9927302100161551, f1 = 0.9945377301234068\n",
      "Epoch 100: Train Loss = 0.02127526680413025, Recall = 0.9983785974868261, Aging Rate = 0.5012160518848804, Precision = 0.9959563283461383, f1 = 0.9971659919028342\n",
      "Test Loss = 0.016405819137182417, Recall = 0.9995946493717065, Aging Rate = 0.49979732468585325, precision = 1.0\n",
      "Model in epoch 100 is saved.\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fbafed7464df408685dee547f6b76990",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss = 0.3505036995376611, Recall = 0.9505472233481962, Aging Rate = 0.6884880421564653, Precision = 0.6903149838092435, f1 = 0.7997953615279673\n",
      "Epoch 2: Train Loss = 0.15965620500051061, Recall = 0.9651398459667613, Aging Rate = 0.5289825699229834, Precision = 0.9122605363984674, f1 = 0.9379554855229467\n",
      "Epoch 3: Train Loss = 0.11967400813880699, Recall = 0.9712201053911633, Aging Rate = 0.5133765707336846, Precision = 0.9459139360442164, f1 = 0.9584\n",
      "Epoch 4: Train Loss = 0.09365234932442051, Recall = 0.977705715443859, Aging Rate = 0.5103364410214836, Precision = 0.9579030976965845, f1 = 0.9677031093279839\n",
      "Epoch 5: Train Loss = 0.08146470144918067, Recall = 0.9805431698419133, Aging Rate = 0.5060802594244022, Precision = 0.9687625150180216, f1 = 0.9746172441579372\n",
      "Test Loss = 0.07535146623789467, Recall = 1.0, Aging Rate = 0.5362788812322659, precision = 0.9323507180650038\n",
      "Model in epoch 5 is saved.\n",
      "\n",
      "Epoch 6: Train Loss = 0.039456371667205586, Recall = 0.9951357924604783, Aging Rate = 0.5040535062829348, Precision = 0.9871330920788098, f1 = 0.9911182882519176\n",
      "Epoch 7: Train Loss = 0.0292245943120401, Recall = 0.9971625456019457, Aging Rate = 0.5018240778273206, Precision = 0.9935379644588045, f1 = 0.9953469552903095\n",
      "Epoch 8: Train Loss = 0.035910428974499614, Recall = 0.9935143899473045, Aging Rate = 0.5026347790839076, Precision = 0.9883064516129032, f1 = 0.9909035779260158\n",
      "Epoch 9: Train Loss = 0.034261567692525675, Recall = 0.9967571949736522, Aging Rate = 0.503850830968788, Precision = 0.9891391794046661, f1 = 0.9929335756107409\n",
      "Epoch 10: Train Loss = 0.03127292082216523, Recall = 0.9959464937170652, Aging Rate = 0.5018240778273206, Precision = 0.9923263327948304, f1 = 0.9941331175399556\n",
      "Test Loss = 0.04097476305706592, Recall = 0.9939197405755978, Aging Rate = 0.5050668828536684, precision = 0.9839486356340289\n",
      "Model in epoch 10 is saved.\n",
      "\n",
      "Epoch 11: Train Loss = 0.04488570752308636, Recall = 0.9910822861775436, Aging Rate = 0.5052695581678152, Precision = 0.9807460890493381, f1 = 0.9858870967741935\n",
      "Epoch 12: Train Loss = 0.0339437125076664, Recall = 0.9955411430887718, Aging Rate = 0.5028374543980543, Precision = 0.9899234179766223, f1 = 0.9927243330638642\n",
      "Epoch 13: Train Loss = 0.03147624346477074, Recall = 0.9959464937170652, Aging Rate = 0.5020267531414674, Precision = 0.9919257165926524, f1 = 0.9939320388349515\n",
      "Epoch 14: Train Loss = 0.03334132275447086, Recall = 0.9947304418321848, Aging Rate = 0.5020267531414674, Precision = 0.9907145740815503, f1 = 0.9927184466019418\n",
      "Epoch 15: Train Loss = 0.02972796784180062, Recall = 0.9963518443453587, Aging Rate = 0.5044588569112282, Precision = 0.9875451988750502, f1 = 0.9919289749798225\n",
      "Test Loss = 0.02346852568386294, Recall = 0.9971625456019457, Aging Rate = 0.5004053506282935, precision = 0.9963547995139733\n",
      "Model in epoch 15 is saved.\n",
      "\n",
      "Epoch 16: Train Loss = 0.029249491784072292, Recall = 0.9959464937170652, Aging Rate = 0.5012160518848804, Precision = 0.9935301253538212, f1 = 0.9947368421052631\n",
      "Epoch 17: Train Loss = 0.05020108511967771, Recall = 0.9874341305229023, Aging Rate = 0.506890960680989, Precision = 0.9740103958416634, f1 = 0.9806763285024155\n",
      "Epoch 18: Train Loss = 0.03185734685539088, Recall = 0.9951357924604783, Aging Rate = 0.5032428050263478, Precision = 0.9887233185662505, f1 = 0.9919191919191919\n",
      "Epoch 19: Train Loss = 0.025678205670412128, Recall = 0.9987839481151196, Aging Rate = 0.5022294284556141, Precision = 0.9943502824858758, f1 = 0.996562184024267\n",
      "Epoch 20: Train Loss = 0.030774102829031293, Recall = 0.9955411430887718, Aging Rate = 0.503850830968788, Precision = 0.9879324215607401, f1 = 0.9917221885725822\n",
      "Test Loss = 0.043241896621284935, Recall = 0.9874341305229023, Aging Rate = 0.49817592217267936, precision = 0.9910496338486574\n",
      "\n",
      "Epoch 21: Train Loss = 0.05511992985558597, Recall = 0.9874341305229023, Aging Rate = 0.5054722334819619, Precision = 0.9767441860465116, f1 = 0.9820600685345697\n",
      "Epoch 22: Train Loss = 0.03379709391813555, Recall = 0.9943250912038913, Aging Rate = 0.5022294284556141, Precision = 0.989911218724778, f1 = 0.99211324570273\n",
      "Epoch 23: Train Loss = 0.020484964194906523, Recall = 0.9995946493717065, Aging Rate = 0.5018240778273206, Precision = 0.9959612277867528, f1 = 0.9977746307910176\n",
      "Epoch 24: Train Loss = 0.021893401436559042, Recall = 0.999189298743413, Aging Rate = 0.5012160518848804, Precision = 0.9967650626769107, f1 = 0.9979757085020243\n",
      "Epoch 25: Train Loss = 0.034490695464820045, Recall = 0.9951357924604783, Aging Rate = 0.5042561815970815, Precision = 0.9867363344051447, f1 = 0.9909182643794148\n",
      "Test Loss = 0.049826490031015455, Recall = 0.999189298743413, Aging Rate = 0.523104985812728, precision = 0.9550561797752809\n",
      "\n",
      "Epoch 26: Train Loss = 0.03549058483645507, Recall = 0.992298338062424, Aging Rate = 0.5016214025131739, Precision = 0.9890909090909091, f1 = 0.990692027519223\n",
      "Epoch 27: Train Loss = 0.029650232172901445, Recall = 0.9967571949736522, Aging Rate = 0.5032428050263478, Precision = 0.9903342730567861, f1 = 0.9935353535353535\n",
      "Epoch 28: Train Loss = 0.027525486227315196, Recall = 0.9975678962302391, Aging Rate = 0.5026347790839076, Precision = 0.9923387096774193, f1 = 0.9949464321811199\n",
      "Epoch 29: Train Loss = 0.02983876705217999, Recall = 0.9951357924604783, Aging Rate = 0.5012160518848804, Precision = 0.9927213910230489, f1 = 0.9939271255060729\n",
      "Epoch 30: Train Loss = 0.035628031341194424, Recall = 0.9947304418321848, Aging Rate = 0.5046615322253749, Precision = 0.9855421686746988, f1 = 0.9901149889045794\n",
      "Test Loss = 0.02593769903366847, Recall = 0.9939197405755978, Aging Rate = 0.4977705715443859, precision = 0.998371335504886\n",
      "Model in epoch 30 is saved.\n",
      "\n",
      "Epoch 31: Train Loss = 0.022655761338065197, Recall = 0.9983785974868261, Aging Rate = 0.5016214025131739, Precision = 0.9951515151515151, f1 = 0.9967624443545124\n",
      "Epoch 32: Train Loss = 0.023541893633358093, Recall = 0.9975678962302391, Aging Rate = 0.5012160518848804, Precision = 0.9951475940153659, f1 = 0.9963562753036437\n",
      "Epoch 33: Train Loss = 0.03966880957269456, Recall = 0.9951357924604783, Aging Rate = 0.5083096878800162, Precision = 0.9788676236044657, f1 = 0.9869346733668342\n",
      "Epoch 34: Train Loss = 0.0525790959691767, Recall = 0.9866234292663154, Aging Rate = 0.5072963113092825, Precision = 0.9724330803036356, f1 = 0.979476861167002\n",
      "Epoch 35: Train Loss = 0.023118644212850155, Recall = 0.9975678962302391, Aging Rate = 0.5018240778273206, Precision = 0.9939418416801292, f1 = 0.9957515678737608\n",
      "Test Loss = 0.014177855098922823, Recall = 0.999189298743413, Aging Rate = 0.5004053506282935, precision = 0.9983799108950993\n",
      "Model in epoch 35 is saved.\n",
      "\n",
      "Epoch 36: Train Loss = 0.021955344213092007, Recall = 0.999189298743413, Aging Rate = 0.5028374543980543, Precision = 0.9935509875050383, f1 = 0.9963621665319321\n",
      "Epoch 37: Train Loss = 0.025424893376167167, Recall = 0.9975678962302391, Aging Rate = 0.5024321037697609, Precision = 0.9927390076643808, f1 = 0.9951475940153659\n",
      "Epoch 38: Train Loss = 0.024451681068842837, Recall = 0.9983785974868261, Aging Rate = 0.5016214025131739, Precision = 0.9951515151515151, f1 = 0.9967624443545124\n",
      "Epoch 39: Train Loss = 0.028554371489045056, Recall = 0.9967571949736522, Aging Rate = 0.5024321037697609, Precision = 0.9919322307382009, f1 = 0.9943388596845936\n",
      "Epoch 40: Train Loss = 0.03397675696949172, Recall = 0.9947304418321848, Aging Rate = 0.5018240778273206, Precision = 0.9911147011308562, f1 = 0.9929192797896015\n",
      "Test Loss = 0.0218841878291073, Recall = 0.999189298743413, Aging Rate = 0.5040535062829348, precision = 0.9911540008041817\n",
      "\n",
      "Epoch 41: Train Loss = 0.04376777356024643, Recall = 0.9886501824077827, Aging Rate = 0.5050668828536684, Precision = 0.9787319422150883, f1 = 0.9836660617059891\n",
      "Epoch 42: Train Loss = 0.03275619183067137, Recall = 0.9947304418321848, Aging Rate = 0.5048642075395217, Precision = 0.9851465274989963, f1 = 0.9899152884227511\n",
      "Epoch 43: Train Loss = 0.020397134770023518, Recall = 0.9987839481151196, Aging Rate = 0.5014187271990271, Precision = 0.9959579628132579, f1 = 0.9973689536531066\n",
      "Epoch 44: Train Loss = 0.022974904834994623, Recall = 0.9987839481151196, Aging Rate = 0.5016214025131739, Precision = 0.9955555555555555, f1 = 0.9971671388101984\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45: Train Loss = 0.035233039461773905, Recall = 0.9927036886907175, Aging Rate = 0.5024321037697609, Precision = 0.9878983461073013, f1 = 0.9902951880307318\n",
      "Test Loss = 0.02958209763715564, Recall = 1.0, Aging Rate = 0.5089177138224564, precision = 0.9824771007566706\n",
      "\n",
      "Epoch 46: Train Loss = 0.02565072724568485, Recall = 0.9975678962302391, Aging Rate = 0.5026347790839076, Precision = 0.9923387096774193, f1 = 0.9949464321811199\n",
      "Epoch 47: Train Loss = 0.021411815073067813, Recall = 0.999189298743413, Aging Rate = 0.5016214025131739, Precision = 0.9959595959595959, f1 = 0.9975718332658842\n",
      "Epoch 48: Train Loss = 0.05274180441575346, Recall = 0.9870287798946088, Aging Rate = 0.5062829347385488, Precision = 0.9747798238590872, f1 = 0.9808660624370594\n",
      "Epoch 49: Train Loss = 0.031097200524362417, Recall = 0.9951357924604783, Aging Rate = 0.503850830968788, Precision = 0.9875301689460981, f1 = 0.991318392893196\n",
      "Epoch 50: Train Loss = 0.025552036125744446, Recall = 0.9967571949736522, Aging Rate = 0.5018240778273206, Precision = 0.9931340872374798, f1 = 0.9949423427068582\n",
      "Test Loss = 0.017052842472952856, Recall = 0.9995946493717065, Aging Rate = 0.5004053506282935, precision = 0.9987849331713244\n",
      "Model in epoch 50 is saved.\n",
      "\n",
      "Epoch 51: Train Loss = 0.019612503288986474, Recall = 0.999189298743413, Aging Rate = 0.5006080259424402, Precision = 0.9979757085020243, f1 = 0.9985821348997367\n",
      "Epoch 52: Train Loss = 0.02660182254622231, Recall = 0.9975678962302391, Aging Rate = 0.5020267531414674, Precision = 0.9935405732741219, f1 = 0.9955501618122977\n",
      "Epoch 53: Train Loss = 0.038239897856957694, Recall = 0.9943250912038913, Aging Rate = 0.5050668828536684, Precision = 0.9843499197431782, f1 = 0.9893123613631781\n",
      "Epoch 54: Train Loss = 0.03451223571810843, Recall = 0.9914876368058371, Aging Rate = 0.503850830968788, Precision = 0.9839098954143202, f1 = 0.9876842317787199\n",
      "Epoch 55: Train Loss = 0.030337818742348057, Recall = 0.9955411430887718, Aging Rate = 0.5016214025131739, Precision = 0.9923232323232323, f1 = 0.9939295831647106\n",
      "Test Loss = 0.027201425188825436, Recall = 0.9995946493717065, Aging Rate = 0.5089177138224564, precision = 0.982078853046595\n",
      "\n",
      "Epoch 56: Train Loss = 0.029368148354060698, Recall = 0.9959464937170652, Aging Rate = 0.5024321037697609, Precision = 0.991125453812021, f1 = 0.9935301253538213\n",
      "Epoch 57: Train Loss = 0.025797707965294746, Recall = 0.9971625456019457, Aging Rate = 0.5014187271990271, Precision = 0.994341147938561, f1 = 0.9957498482088646\n",
      "Epoch 58: Train Loss = 0.02976278281560372, Recall = 0.9963518443453587, Aging Rate = 0.503040129712201, Precision = 0.9903303787268332, f1 = 0.9933319862598504\n",
      "Epoch 59: Train Loss = 0.02164543323735259, Recall = 1.0, Aging Rate = 0.5014187271990271, Precision = 0.9971705739692805, f1 = 0.9985832827362882\n",
      "Epoch 60: Train Loss = 0.04439237368111712, Recall = 0.9906769355492501, Aging Rate = 0.5056749087961087, Precision = 0.9795591182364729, f1 = 0.9850866586054011\n",
      "Test Loss = 0.025893869587451667, Recall = 0.9963518443453587, Aging Rate = 0.5012160518848804, precision = 0.9939344925192074\n",
      "\n",
      "Epoch 61: Train Loss = 0.03792053980305096, Recall = 0.9939197405755978, Aging Rate = 0.5054722334819619, Precision = 0.983159582999198, f1 = 0.9885103809715783\n",
      "Epoch 62: Train Loss = 0.02633273240819084, Recall = 0.9971625456019457, Aging Rate = 0.503040129712201, Precision = 0.9911361804995971, f1 = 0.9941402303495656\n",
      "Epoch 63: Train Loss = 0.022364555466217965, Recall = 0.999189298743413, Aging Rate = 0.5016214025131739, Precision = 0.9959595959595959, f1 = 0.9975718332658842\n",
      "Epoch 64: Train Loss = 0.02615178976869373, Recall = 0.9975678962302391, Aging Rate = 0.5026347790839076, Precision = 0.9923387096774193, f1 = 0.9949464321811199\n",
      "Epoch 65: Train Loss = 0.03883649091593797, Recall = 0.993109039319011, Aging Rate = 0.5050668828536684, Precision = 0.9831460674157303, f1 = 0.9881024400080662\n",
      "Test Loss = 0.03143180642363075, Recall = 0.992298338062424, Aging Rate = 0.4979732468585326, precision = 0.9963369963369964\n",
      "\n",
      "Epoch 66: Train Loss = 0.0380828905326662, Recall = 0.9939197405755978, Aging Rate = 0.5050668828536684, Precision = 0.9839486356340289, f1 = 0.9889090542448075\n",
      "Epoch 67: Train Loss = 0.021226392674966166, Recall = 0.9983785974868261, Aging Rate = 0.5012160518848804, Precision = 0.9959563283461383, f1 = 0.9971659919028342\n",
      "Epoch 68: Train Loss = 0.01973538594335517, Recall = 0.9979732468585326, Aging Rate = 0.5, Precision = 0.9979732468585326, f1 = 0.9979732468585326\n",
      "Epoch 69: Train Loss = 0.02409178842226044, Recall = 0.9975678962302391, Aging Rate = 0.5014187271990271, Precision = 0.9947453516572352, f1 = 0.9961546245699251\n",
      "Epoch 70: Train Loss = 0.0278065921002595, Recall = 0.9979732468585326, Aging Rate = 0.5026347790839076, Precision = 0.992741935483871, f1 = 0.9953507176066303\n",
      "Test Loss = 0.029130142263654374, Recall = 0.9910822861775436, Aging Rate = 0.4955411430887718, precision = 1.0\n",
      "\n",
      "Epoch 71: Train Loss = 0.04582367590158562, Recall = 0.9906769355492501, Aging Rate = 0.5042561815970815, Precision = 0.9823151125401929, f1 = 0.986478304742684\n",
      "Epoch 72: Train Loss = 0.024323511812843483, Recall = 0.9967571949736522, Aging Rate = 0.5004053506282935, Precision = 0.995949777237748, f1 = 0.9963533225283631\n",
      "Epoch 73: Train Loss = 0.047721686319610004, Recall = 0.9854073773814349, Aging Rate = 0.5042561815970815, Precision = 0.9770900321543409, f1 = 0.981231079717457\n",
      "Epoch 74: Train Loss = 0.03141658411583632, Recall = 0.9939197405755978, Aging Rate = 0.5020267531414674, Precision = 0.9899071457408155, f1 = 0.9919093851132686\n",
      "Epoch 75: Train Loss = 0.019019412903630836, Recall = 0.9995946493717065, Aging Rate = 0.500810701256587, Precision = 0.9979765277215702, f1 = 0.9987849331713244\n",
      "Test Loss = 0.014519067947010206, Recall = 1.0, Aging Rate = 0.5002026753141467, precision = 0.9995948136142626\n",
      "Model in epoch 75 is saved.\n",
      "\n",
      "Epoch 76: Train Loss = 0.02015970120969805, Recall = 0.9987839481151196, Aging Rate = 0.5004053506282935, Precision = 0.9979748886188741, f1 = 0.9983792544570502\n",
      "Epoch 77: Train Loss = 0.023976988796738173, Recall = 0.9975678962302391, Aging Rate = 0.5024321037697609, Precision = 0.9927390076643808, f1 = 0.9951475940153659\n",
      "Epoch 78: Train Loss = 0.020539522792216817, Recall = 0.9995946493717065, Aging Rate = 0.500810701256587, Precision = 0.9979765277215702, f1 = 0.9987849331713244\n",
      "Epoch 79: Train Loss = 0.024562299133772593, Recall = 0.9979732468585326, Aging Rate = 0.5026347790839076, Precision = 0.992741935483871, f1 = 0.9953507176066303\n",
      "Epoch 80: Train Loss = 0.06180094075202338, Recall = 0.983785974868261, Aging Rate = 0.5093230644507499, Precision = 0.9657779546358933, f1 = 0.9746987951807228\n",
      "Test Loss = 0.035611319324333125, Recall = 0.9951357924604783, Aging Rate = 0.5062829347385488, precision = 0.9827862289831866\n",
      "\n",
      "Epoch 81: Train Loss = 0.029831830095794213, Recall = 0.9963518443453587, Aging Rate = 0.5032428050263478, Precision = 0.9899315344341523, f1 = 0.9931313131313131\n",
      "Epoch 82: Train Loss = 0.021887009461537942, Recall = 0.9975678962302391, Aging Rate = 0.5018240778273206, Precision = 0.9939418416801292, f1 = 0.9957515678737608\n",
      "Epoch 83: Train Loss = 0.030306920172879944, Recall = 0.9947304418321848, Aging Rate = 0.5034454803404945, Precision = 0.9879227053140096, f1 = 0.9913148858816402\n",
      "Epoch 84: Train Loss = 0.02783720182023873, Recall = 0.9975678962302391, Aging Rate = 0.503040129712201, Precision = 0.991539081385979, f1 = 0.994544352394423\n",
      "Epoch 85: Train Loss = 0.029349046882565115, Recall = 0.9951357924604783, Aging Rate = 0.5020267531414674, Precision = 0.9911182882519176, f1 = 0.9931229773462782\n",
      "Test Loss = 0.028624606895610468, Recall = 0.9910822861775436, Aging Rate = 0.4965545196595055, precision = 0.9979591836734694\n",
      "\n",
      "Epoch 86: Train Loss = 0.024825240977268542, Recall = 0.9983785974868261, Aging Rate = 0.5016214025131739, Precision = 0.9951515151515151, f1 = 0.9967624443545124\n",
      "Epoch 87: Train Loss = 0.03901023999986061, Recall = 0.993109039319011, Aging Rate = 0.5042561815970815, Precision = 0.9847266881028939, f1 = 0.9889001009081736\n",
      "Epoch 88: Train Loss = 0.024159180729022914, Recall = 0.9975678962302391, Aging Rate = 0.5020267531414674, Precision = 0.9935405732741219, f1 = 0.9955501618122977\n",
      "Epoch 89: Train Loss = 0.02452688731772604, Recall = 0.9983785974868261, Aging Rate = 0.503040129712201, Precision = 0.9923448831587429, f1 = 0.9953525964841381\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 90: Train Loss = 0.04039905736102814, Recall = 0.9910822861775436, Aging Rate = 0.5048642075395217, Precision = 0.9815335206744279, f1 = 0.9862847922549415\n",
      "Test Loss = 0.05683546090580864, Recall = 0.993109039319011, Aging Rate = 0.51925415484394, precision = 0.9562841530054644\n",
      "\n",
      "Epoch 91: Train Loss = 0.030403987249721143, Recall = 0.9963518443453587, Aging Rate = 0.5042561815970815, Precision = 0.9879421221864951, f1 = 0.9921291624621595\n",
      "Epoch 92: Train Loss = 0.018799803626316253, Recall = 0.999189298743413, Aging Rate = 0.500810701256587, Precision = 0.9975718332658843, f1 = 0.9983799108950991\n",
      "Epoch 93: Train Loss = 0.025191845345893367, Recall = 0.9987839481151196, Aging Rate = 0.5026347790839076, Precision = 0.9935483870967742, f1 = 0.9961592884576511\n",
      "Epoch 94: Train Loss = 0.036135608139347825, Recall = 0.9943250912038913, Aging Rate = 0.5046615322253749, Precision = 0.9851405622489959, f1 = 0.98971151906395\n",
      "Epoch 95: Train Loss = 0.02363850562831362, Recall = 0.9983785974868261, Aging Rate = 0.5024321037697609, Precision = 0.9935457845905608, f1 = 0.9959563283461383\n",
      "Test Loss = 0.014580489976243253, Recall = 1.0, Aging Rate = 0.5010133765707336, precision = 0.9979773462783171\n",
      "\n",
      "Epoch 96: Train Loss = 0.024588185023488293, Recall = 0.9979732468585326, Aging Rate = 0.5024321037697609, Precision = 0.9931423961274708, f1 = 0.9955519611807523\n",
      "Epoch 97: Train Loss = 0.03344620405769947, Recall = 0.9947304418321848, Aging Rate = 0.5044588569112282, Precision = 0.9859381277621535, f1 = 0.9903147699757869\n",
      "Epoch 98: Train Loss = 0.03878663139463824, Recall = 0.9914876368058371, Aging Rate = 0.5024321037697609, Precision = 0.9866881807180314, f1 = 0.9890820865345734\n",
      "Epoch 99: Train Loss = 0.035984625834212865, Recall = 0.9939197405755978, Aging Rate = 0.5054722334819619, Precision = 0.983159582999198, f1 = 0.9885103809715783\n",
      "Epoch 100: Train Loss = 0.018314878884770874, Recall = 0.9995946493717065, Aging Rate = 0.5002026753141467, Precision = 0.9991896272285251, f1 = 0.9993920972644377\n",
      "Test Loss = 0.01625793090035039, Recall = 0.9987839481151196, Aging Rate = 0.4995946493717065, precision = 0.9995943204868154\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "692ab0414c6d4eac800ea2f97bd816a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss = 0.3246247412634611, Recall = 0.9339278475881637, Aging Rate = 0.6339683826509931, Precision = 0.7365728900255755, f1 = 0.8235924932975872\n",
      "Epoch 2: Train Loss = 0.14773593189434142, Recall = 0.9618970409404135, Aging Rate = 0.5259424402107823, Precision = 0.9144508670520232, f1 = 0.9375740813907546\n",
      "Epoch 3: Train Loss = 0.11366147983458344, Recall = 0.9760843129306851, Aging Rate = 0.5206728820429671, Precision = 0.9373297002724795, f1 = 0.9563145353455123\n",
      "Epoch 4: Train Loss = 0.08852931429236753, Recall = 0.9793271179570329, Aging Rate = 0.511552492906364, Precision = 0.9572107765451664, f1 = 0.9681426567822079\n",
      "Epoch 5: Train Loss = 0.08548834104503172, Recall = 0.9785164167004459, Aging Rate = 0.5117551682205107, Precision = 0.956039603960396, f1 = 0.9671474358974359\n",
      "Test Loss = 0.05253733370798921, Recall = 0.9987839481151196, Aging Rate = 0.513173895419538, precision = 0.9731437598736177\n",
      "Model in epoch 5 is saved.\n",
      "\n",
      "Epoch 6: Train Loss = 0.035347989001351, Recall = 0.9943250912038913, Aging Rate = 0.500810701256587, Precision = 0.9927154997976527, f1 = 0.9935196435803969\n",
      "Epoch 7: Train Loss = 0.03063017881902355, Recall = 0.9963518443453587, Aging Rate = 0.5026347790839076, Precision = 0.9911290322580645, f1 = 0.9937335759045887\n",
      "Epoch 8: Train Loss = 0.030567080258906348, Recall = 0.9983785974868261, Aging Rate = 0.5034454803404945, Precision = 0.9915458937198067, f1 = 0.994950515047465\n",
      "Epoch 9: Train Loss = 0.03669818456616535, Recall = 0.9939197405755978, Aging Rate = 0.5042561815970815, Precision = 0.9855305466237942, f1 = 0.98970736629667\n",
      "Epoch 10: Train Loss = 0.031478918008400594, Recall = 0.9971625456019457, Aging Rate = 0.5026347790839076, Precision = 0.9919354838709677, f1 = 0.9945421467556095\n",
      "Test Loss = 0.02827797147317404, Recall = 0.999189298743413, Aging Rate = 0.5074989866234293, precision = 0.9844249201277955\n",
      "Model in epoch 10 is saved.\n",
      "\n",
      "Epoch 11: Train Loss = 0.0365045328655125, Recall = 0.993109039319011, Aging Rate = 0.5024321037697609, Precision = 0.9883017345703913, f1 = 0.9906995551961181\n",
      "Epoch 12: Train Loss = 0.035161052577961635, Recall = 0.9955411430887718, Aging Rate = 0.5032428050263478, Precision = 0.9891260571888845, f1 = 0.9923232323232324\n",
      "Epoch 13: Train Loss = 0.026797990324477772, Recall = 0.9975678962302391, Aging Rate = 0.5020267531414674, Precision = 0.9935405732741219, f1 = 0.9955501618122977\n",
      "Epoch 14: Train Loss = 0.03815381412394722, Recall = 0.9939197405755978, Aging Rate = 0.5044588569112282, Precision = 0.9851345922057051, f1 = 0.9895076674737691\n",
      "Epoch 15: Train Loss = 0.03609623456729427, Recall = 0.993109039319011, Aging Rate = 0.503040129712201, Precision = 0.9871071716357775, f1 = 0.9900990099009901\n",
      "Test Loss = 0.02970886504995615, Recall = 0.9963518443453587, Aging Rate = 0.5006080259424402, precision = 0.9951417004048583\n",
      "Model in epoch 15 is saved.\n",
      "\n",
      "Epoch 16: Train Loss = 0.029445126254064716, Recall = 0.9967571949736522, Aging Rate = 0.5020267531414674, Precision = 0.9927331449333872, f1 = 0.9947411003236246\n",
      "Epoch 17: Train Loss = 0.027906356913192, Recall = 0.9979732468585326, Aging Rate = 0.5024321037697609, Precision = 0.9931423961274708, f1 = 0.9955519611807523\n",
      "Epoch 18: Train Loss = 0.0340527901373106, Recall = 0.9959464937170652, Aging Rate = 0.5040535062829348, Precision = 0.9879372738238842, f1 = 0.9919257165926523\n",
      "Epoch 19: Train Loss = 0.040162720142349895, Recall = 0.9918929874341306, Aging Rate = 0.5034454803404945, Precision = 0.9851046698872786, f1 = 0.9884871743082206\n",
      "Epoch 20: Train Loss = 0.0222724810617145, Recall = 0.9983785974868261, Aging Rate = 0.5010133765707336, Precision = 0.9963592233009708, f1 = 0.997367888236485\n",
      "Test Loss = 0.01571480513191327, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "Model in epoch 20 is saved.\n",
      "\n",
      "Epoch 21: Train Loss = 0.04013875517224041, Recall = 0.9947304418321848, Aging Rate = 0.5046615322253749, Precision = 0.9855421686746988, f1 = 0.9901149889045794\n",
      "Epoch 22: Train Loss = 0.030812311105137175, Recall = 0.9939197405755978, Aging Rate = 0.5016214025131739, Precision = 0.9907070707070708, f1 = 0.9923108053419668\n",
      "Epoch 23: Train Loss = 0.025911457119543554, Recall = 0.9975678962302391, Aging Rate = 0.500810701256587, Precision = 0.9959530554431404, f1 = 0.9967598217901985\n",
      "Epoch 24: Train Loss = 0.02366113247343063, Recall = 0.9979732468585326, Aging Rate = 0.5016214025131739, Precision = 0.9947474747474747, f1 = 0.9963577498988264\n",
      "Epoch 25: Train Loss = 0.029940074857099364, Recall = 0.9963518443453587, Aging Rate = 0.5040535062829348, Precision = 0.9883393646964214, f1 = 0.9923294307630198\n",
      "Test Loss = 0.03547723348134314, Recall = 0.9959464937170652, Aging Rate = 0.5048642075395217, precision = 0.9863508631071859\n",
      "\n",
      "Epoch 26: Train Loss = 0.04499948654175832, Recall = 0.9910822861775436, Aging Rate = 0.5044588569112282, Precision = 0.9823222177581358, f1 = 0.986682808716707\n",
      "Epoch 27: Train Loss = 0.028429307532808198, Recall = 0.9959464937170652, Aging Rate = 0.5012160518848804, Precision = 0.9935301253538212, f1 = 0.9947368421052631\n",
      "Epoch 28: Train Loss = 0.03137278303437548, Recall = 0.9947304418321848, Aging Rate = 0.5018240778273206, Precision = 0.9911147011308562, f1 = 0.9929192797896015\n",
      "Epoch 29: Train Loss = 0.02227500700465444, Recall = 0.9987839481151196, Aging Rate = 0.5012160518848804, Precision = 0.9963606955115245, f1 = 0.9975708502024292\n",
      "Epoch 30: Train Loss = 0.028160209718821355, Recall = 0.9971625456019457, Aging Rate = 0.5022294284556141, Precision = 0.9927360774818402, f1 = 0.9949443882709808\n",
      "Test Loss = 0.02164907932181831, Recall = 0.9995946493717065, Aging Rate = 0.5032428050263478, precision = 0.9931534434152235\n",
      "\n",
      "Epoch 31: Train Loss = 0.025748421732309103, Recall = 0.9975678962302391, Aging Rate = 0.5010133765707336, Precision = 0.9955501618122977, f1 = 0.996558007693865\n",
      "Epoch 32: Train Loss = 0.028458595377052174, Recall = 0.9975678962302391, Aging Rate = 0.5022294284556141, Precision = 0.9931396287328491, f1 = 0.9953488372093023\n",
      "Epoch 33: Train Loss = 0.040735167672047504, Recall = 0.9943250912038913, Aging Rate = 0.5056749087961087, Precision = 0.9831663326653307, f1 = 0.9887142281338169\n",
      "Epoch 34: Train Loss = 0.042585207539734014, Recall = 0.9914876368058371, Aging Rate = 0.5060802594244022, Precision = 0.9795754905887064, f1 = 0.9854955680902499\n",
      "Epoch 35: Train Loss = 0.025255064111177283, Recall = 0.9975678962302391, Aging Rate = 0.5036481556546413, Precision = 0.9903420523138833, f1 = 0.9939418416801292\n",
      "Test Loss = 0.01655643436277038, Recall = 0.999189298743413, Aging Rate = 0.49979732468585325, precision = 0.9995944849959448\n",
      "\n",
      "Epoch 36: Train Loss = 0.028488386288001367, Recall = 0.9939197405755978, Aging Rate = 0.5, Precision = 0.9939197405755978, f1 = 0.9939197405755978\n",
      "Epoch 37: Train Loss = 0.02946816854719503, Recall = 0.9959464937170652, Aging Rate = 0.5016214025131739, Precision = 0.9927272727272727, f1 = 0.9943342776203965\n",
      "Epoch 38: Train Loss = 0.02555065110222375, Recall = 0.9979732468585326, Aging Rate = 0.5026347790839076, Precision = 0.992741935483871, f1 = 0.9953507176066303\n",
      "Epoch 39: Train Loss = 0.030557570167347926, Recall = 0.9971625456019457, Aging Rate = 0.503850830968788, Precision = 0.9895414320193081, f1 = 0.9933373712901272\n",
      "Epoch 40: Train Loss = 0.030231225926068132, Recall = 0.9959464937170652, Aging Rate = 0.5042561815970815, Precision = 0.987540192926045, f1 = 0.9917255297679112\n",
      "Test Loss = 0.03404211236845761, Recall = 0.999189298743413, Aging Rate = 0.5099310903931901, precision = 0.9797297297297297\n",
      "\n",
      "Epoch 41: Train Loss = 0.0535145616902542, Recall = 0.984596676124848, Aging Rate = 0.5056749087961087, Precision = 0.9735470941883767, f1 = 0.9790407093913744\n",
      "Epoch 42: Train Loss = 0.02543023907940761, Recall = 0.9959464937170652, Aging Rate = 0.5012160518848804, Precision = 0.9935301253538212, f1 = 0.9947368421052631\n",
      "Epoch 43: Train Loss = 0.0177008167564579, Recall = 1.0, Aging Rate = 0.5004053506282935, Precision = 0.9991899554475496, f1 = 0.9995948136142626\n",
      "Epoch 44: Train Loss = 0.026326055342900063, Recall = 0.9975678962302391, Aging Rate = 0.5024321037697609, Precision = 0.9927390076643808, f1 = 0.9951475940153659\n",
      "Epoch 45: Train Loss = 0.03813701965304391, Recall = 0.9918929874341306, Aging Rate = 0.5036481556546413, Precision = 0.9847082494969819, f1 = 0.9882875605815832\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss = 0.03182444688314772, Recall = 0.9975678962302391, Aging Rate = 0.5064856100526955, precision = 0.9847939175670268\n",
      "\n",
      "Epoch 46: Train Loss = 0.03882417586236818, Recall = 0.9927036886907175, Aging Rate = 0.5020267531414674, Precision = 0.9886960032297134, f1 = 0.9906957928802589\n",
      "Epoch 47: Train Loss = 0.02416145133725124, Recall = 0.9979732468585326, Aging Rate = 0.5018240778273206, Precision = 0.994345718901454, f1 = 0.9961561804572122\n",
      "Epoch 48: Train Loss = 0.027081013124482953, Recall = 0.9955411430887718, Aging Rate = 0.5012160518848804, Precision = 0.9931257581884351, f1 = 0.994331983805668\n",
      "Epoch 49: Train Loss = 0.022557056918747823, Recall = 0.9983785974868261, Aging Rate = 0.5016214025131739, Precision = 0.9951515151515151, f1 = 0.9967624443545124\n",
      "Epoch 50: Train Loss = 0.022199471972287787, Recall = 0.9979732468585326, Aging Rate = 0.5, Precision = 0.9979732468585326, f1 = 0.9979732468585326\n",
      "Test Loss = 0.017529608440945203, Recall = 1.0, Aging Rate = 0.5018240778273206, precision = 0.9963651050080775\n",
      "\n",
      "Epoch 51: Train Loss = 0.02649107249095027, Recall = 0.9975678962302391, Aging Rate = 0.5022294284556141, Precision = 0.9931396287328491, f1 = 0.9953488372093023\n",
      "Epoch 52: Train Loss = 0.03635583134718393, Recall = 0.9914876368058371, Aging Rate = 0.503040129712201, Precision = 0.9854955680902499, f1 = 0.9884825217215599\n",
      "Epoch 53: Train Loss = 0.026718054203083267, Recall = 0.9963518443453587, Aging Rate = 0.5020267531414674, Precision = 0.9923294307630198, f1 = 0.9943365695792881\n",
      "Epoch 54: Train Loss = 0.029548882616643825, Recall = 0.9955411430887718, Aging Rate = 0.5024321037697609, Precision = 0.990722065348931, f1 = 0.9931257581884352\n",
      "Epoch 55: Train Loss = 0.03210787517088456, Recall = 0.9947304418321848, Aging Rate = 0.503040129712201, Precision = 0.9887187751813054, f1 = 0.9917154980804203\n",
      "Test Loss = 0.015846188356446796, Recall = 0.9995946493717065, Aging Rate = 0.5, precision = 0.9995946493717065\n",
      "\n",
      "Epoch 56: Train Loss = 0.027098198765968088, Recall = 0.9975678962302391, Aging Rate = 0.5024321037697609, Precision = 0.9927390076643808, f1 = 0.9951475940153659\n",
      "Epoch 57: Train Loss = 0.037872339704160415, Recall = 0.9918929874341306, Aging Rate = 0.5034454803404945, Precision = 0.9851046698872786, f1 = 0.9884871743082206\n",
      "Epoch 58: Train Loss = 0.030331584376920608, Recall = 0.9951357924604783, Aging Rate = 0.5048642075395217, Precision = 0.9855479727017262, f1 = 0.9903186768858411\n",
      "Epoch 59: Train Loss = 0.0252084463685079, Recall = 0.9967571949736522, Aging Rate = 0.5016214025131739, Precision = 0.9935353535353535, f1 = 0.9951436665317686\n",
      "Epoch 60: Train Loss = 0.023453017491749124, Recall = 0.9975678962302391, Aging Rate = 0.5014187271990271, Precision = 0.9947453516572352, f1 = 0.9961546245699251\n",
      "Test Loss = 0.034238049813926016, Recall = 0.999189298743413, Aging Rate = 0.5089177138224564, precision = 0.9816806053365194\n",
      "\n",
      "Epoch 61: Train Loss = 0.0297684946467773, Recall = 0.9951357924604783, Aging Rate = 0.503040129712201, Precision = 0.9891216760676873, f1 = 0.9921196201252779\n",
      "Epoch 62: Train Loss = 0.02096456792534008, Recall = 0.9995946493717065, Aging Rate = 0.5012160518848804, Precision = 0.9971694298422968, f1 = 0.9983805668016195\n",
      "Epoch 63: Train Loss = 0.026498702399653126, Recall = 0.9967571949736522, Aging Rate = 0.5012160518848804, Precision = 0.9943388596845936, f1 = 0.9955465587044534\n",
      "Epoch 64: Train Loss = 0.03618116331610256, Recall = 0.9943250912038913, Aging Rate = 0.5040535062829348, Precision = 0.9863289103337354, f1 = 0.9903108599111828\n",
      "Epoch 65: Train Loss = 0.031006942771565446, Recall = 0.9955411430887718, Aging Rate = 0.503040129712201, Precision = 0.9895245769540693, f1 = 0.9925237421701354\n",
      "Test Loss = 0.017199097725970086, Recall = 0.9987839481151196, Aging Rate = 0.4995946493717065, precision = 0.9995943204868154\n",
      "\n",
      "Epoch 66: Train Loss = 0.025715033715137066, Recall = 0.9971625456019457, Aging Rate = 0.5028374543980543, Precision = 0.9915356711003628, f1 = 0.9943411479385611\n",
      "Epoch 67: Train Loss = 0.0309318689357438, Recall = 0.9943250912038913, Aging Rate = 0.5018240778273206, Precision = 0.9907108239095315, f1 = 0.9925146672061501\n",
      "Epoch 68: Train Loss = 0.021870548236264987, Recall = 0.999189298743413, Aging Rate = 0.5014187271990271, Precision = 0.9963621665319321, f1 = 0.9977737300141671\n",
      "Epoch 69: Train Loss = 0.022853388506534084, Recall = 0.999189298743413, Aging Rate = 0.503040129712201, Precision = 0.9931506849315068, f1 = 0.9961608405738532\n",
      "Epoch 70: Train Loss = 0.04219783064850765, Recall = 0.9914876368058371, Aging Rate = 0.5050668828536684, Precision = 0.9815409309791332, f1 = 0.9864892115345836\n",
      "Test Loss = 0.02894094945669603, Recall = 0.9910822861775436, Aging Rate = 0.496149169031212, precision = 0.9987745098039216\n",
      "\n",
      "Training Finished at epoch 70.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9df607d607d04fa3b9b0db0546a3a641",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f4ad4630664d44f4910362128044c9b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss = 0.3346759832838676, Recall = 0.9092526690391459, Aging Rate = 0.568950177935943, Precision = 0.799061767005473, f1 = 0.8506034124011652\n",
      "Epoch 2: Train Loss = 0.15402803609803903, Recall = 0.9559608540925267, Aging Rate = 0.5126779359430605, Precision = 0.9323210412147506, f1 = 0.9439929716670328\n",
      "Epoch 3: Train Loss = 0.08986272324155022, Recall = 0.9777580071174378, Aging Rate = 0.5046708185053381, Precision = 0.9687086822388717, f1 = 0.9732123090546825\n",
      "Epoch 4: Train Loss = 0.0634001017833175, Recall = 0.9817615658362989, Aging Rate = 0.5033362989323843, Precision = 0.9752540874944764, f1 = 0.9784970073154511\n",
      "Epoch 5: Train Loss = 0.0577880059206507, Recall = 0.979982206405694, Aging Rate = 0.5002224199288257, Precision = 0.9795464650955981, f1 = 0.9797642873026462\n",
      "Test Loss = 0.019837648724620082, Recall = 0.9937722419928826, Aging Rate = 0.4984430604982206, precision = 0.9968763944667559\n",
      "Model in epoch 5 is saved.\n",
      "\n",
      "Epoch 6: Train Loss = 0.02076006492391043, Recall = 0.9928825622775801, Aging Rate = 0.4984430604982206, Precision = 0.9959839357429718, f1 = 0.9944308309200267\n",
      "Epoch 7: Train Loss = 0.007829379196712926, Recall = 0.9986654804270463, Aging Rate = 0.49933274021352314, Precision = 0, f1 = 0.0\n",
      "Epoch 8: Train Loss = 0.004738490967025311, Recall = 0.9991103202846975, Aging Rate = 0.49955516014234874, Precision = 0, f1 = 0.0\n",
      "Epoch 9: Train Loss = 0.003289305913847046, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 10: Train Loss = 0.002779170644371787, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.002496443944278892, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "Model in epoch 10 is saved.\n",
      "\n",
      "Epoch 11: Train Loss = 0.0027335072321538877, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 12: Train Loss = 0.002339098718534373, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 13: Train Loss = 0.0054289933573288904, Recall = 1.0, Aging Rate = 0.5002224199288257, Precision = 0.9995553579368608, f1 = 0.9997776295307983\n",
      "Epoch 14: Train Loss = 0.012834923276826872, Recall = 0.9955516014234875, Aging Rate = 0.5008896797153025, Precision = 0.9937833037300178, f1 = 0.9946666666666666\n",
      "Epoch 15: Train Loss = 0.04418954225439326, Recall = 0.9866548042704626, Aging Rate = 0.5028914590747331, Precision = 0.9809818664307829, f1 = 0.9838101574628522\n",
      "Test Loss = 0.057161128981158243, Recall = 0.998220640569395, Aging Rate = 0.5264679715302492, precision = 0.9480354879594424\n",
      "\n",
      "Epoch 16: Train Loss = 0.020663134725325247, Recall = 0.9959964412811388, Aging Rate = 0.5024466192170819, Precision = 0.9911465250110668, f1 = 0.9935655646771688\n",
      "Epoch 17: Train Loss = 0.00514020116350761, Recall = 0.9986654804270463, Aging Rate = 0.4997775800711744, Precision = 0.9991099243435692, f1 = 0.9988876529477195\n",
      "Epoch 18: Train Loss = 0.009592726032164286, Recall = 0.9986654804270463, Aging Rate = 0.5011120996441281, Precision = 0.9964491788726143, f1 = 0.9975560986447456\n",
      "Epoch 19: Train Loss = 0.00179695873526447, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 20: Train Loss = 0.011021301513446621, Recall = 0.9968861209964412, Aging Rate = 0.5011120996441281, Precision = 0.9946737683089214, f1 = 0.9957787158409241\n",
      "Test Loss = 0.009467440239299633, Recall = 1.0, Aging Rate = 0.501779359430605, precision = 0.9964539007092199\n",
      "\n",
      "Epoch 21: Train Loss = 0.0030330445163169032, Recall = 1.0, Aging Rate = 0.5004448398576512, Precision = 0.9991111111111111, f1 = 0.9995553579368608\n",
      "Epoch 22: Train Loss = 0.004818581086465363, Recall = 0.9995551601423488, Aging Rate = 0.5002224199288257, Precision = 0.9991107158737217, f1 = 0.9993328885923949\n",
      "Epoch 23: Train Loss = 0.010531567767704919, Recall = 0.9968861209964412, Aging Rate = 0.5006672597864769, Precision = 0.9955575299866726, f1 = 0.9962213825294509\n",
      "Epoch 24: Train Loss = 0.003067493388177396, Recall = 1.0, Aging Rate = 0.5008896797153025, Precision = 0.9982238010657194, f1 = 0.9991111111111112\n",
      "Epoch 25: Train Loss = 0.003679192103913677, Recall = 0.9991103202846975, Aging Rate = 0.5, Precision = 0.9991103202846975, f1 = 0.9991103202846975\n",
      "Test Loss = 0.001301407686631888, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 26: Train Loss = 0.0010552895582157595, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 27: Train Loss = 0.0009470586500294652, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 28: Train Loss = 0.0009124854358337369, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 29: Train Loss = 0.0012358505686072242, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 30: Train Loss = 0.0014438934732324633, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0012956750079959605, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 31: Train Loss = 0.0027456549180628485, Recall = 0.9995551601423488, Aging Rate = 0.5, Precision = 0.9995551601423488, f1 = 0.9995551601423488\n",
      "Epoch 32: Train Loss = 0.06291430813775753, Recall = 0.9839857651245552, Aging Rate = 0.5048932384341637, Precision = 0.9744493392070485, f1 = 0.9791943337760071\n",
      "Epoch 33: Train Loss = 0.024664971471624945, Recall = 0.9928825622775801, Aging Rate = 0.5011120996441281, Precision = 0.9906790945406125, f1 = 0.9917796045323262\n",
      "Epoch 34: Train Loss = 0.006105245801061309, Recall = 0.998220640569395, Aging Rate = 0.5002224199288257, Precision = 0.9977767896843042, f1 = 0.9979986657771848\n",
      "Epoch 35: Train Loss = 0.0032241459865681495, Recall = 0.9995551601423488, Aging Rate = 0.5, Precision = 0.9995551601423488, f1 = 0.9995551601423488\n",
      "Test Loss = 0.0016652334971271382, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 36: Train Loss = 0.0012113867559365836, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 37: Train Loss = 0.0008415693301811907, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 38: Train Loss = 0.001019861602685928, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 39: Train Loss = 0.003451183026704566, Recall = 0.9995551601423488, Aging Rate = 0.5, Precision = 0.9995551601423488, f1 = 0.9995551601423488\n",
      "Epoch 40: Train Loss = 0.005915885615523812, Recall = 0.9991103202846975, Aging Rate = 0.5002224199288257, Precision = 0.9986660738105825, f1 = 0.9988881476539915\n",
      "Test Loss = 0.0026399414189693473, Recall = 0.9995551601423488, Aging Rate = 0.4997775800711744, precision = 1.0\n",
      "\n",
      "Epoch 41: Train Loss = 0.006053714397022819, Recall = 0.998220640569395, Aging Rate = 0.5, Precision = 0.998220640569395, f1 = 0.998220640569395\n",
      "Epoch 42: Train Loss = 0.0051175389546375665, Recall = 0.9991103202846975, Aging Rate = 0.5002224199288257, Precision = 0.9986660738105825, f1 = 0.9988881476539915\n",
      "Epoch 43: Train Loss = 0.007497598069307338, Recall = 0.998220640569395, Aging Rate = 0.5006672597864769, Precision = 0.9968902709906708, f1 = 0.9975550122249388\n",
      "Epoch 44: Train Loss = 0.017052526141121634, Recall = 0.9951067615658363, Aging Rate = 0.5011120996441281, Precision = 0.9928983577452286, f1 = 0.9940013330371029\n",
      "Epoch 45: Train Loss = 0.01602870824971436, Recall = 0.99644128113879, Aging Rate = 0.5020017793594306, Precision = 0.9924678777137793, f1 = 0.9944506104328523\n",
      "Test Loss = 0.00777707403083249, Recall = 0.9955516014234875, Aging Rate = 0.498220640569395, precision = 0.9991071428571429\n",
      "\n",
      "Epoch 46: Train Loss = 0.0054082135913074945, Recall = 0.9986654804270463, Aging Rate = 0.4997775800711744, Precision = 0.9991099243435692, f1 = 0.9988876529477195\n",
      "Epoch 47: Train Loss = 0.0010727210351708428, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 48: Train Loss = 0.0006866674250164947, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 49: Train Loss = 0.0007711074769072685, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 50: Train Loss = 0.0009635323679300018, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0009657009284126364, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 51: Train Loss = 0.0028396630992166684, Recall = 0.9995551601423488, Aging Rate = 0.5002224199288257, Precision = 0.9991107158737217, f1 = 0.9993328885923949\n",
      "Epoch 52: Train Loss = 0.0031001322357534196, Recall = 0.9995551601423488, Aging Rate = 0.4997775800711744, Precision = 0, f1 = 0.0\n",
      "Epoch 53: Train Loss = 0.0089548680125744, Recall = 0.9968861209964412, Aging Rate = 0.5004448398576512, Precision = 0.996, f1 = 0.9964428634948866\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 54: Train Loss = 0.028252774821776645, Recall = 0.9924377224199288, Aging Rate = 0.501779359430605, Precision = 0.9889184397163121, f1 = 0.9906749555950267\n",
      "Epoch 55: Train Loss = 0.017392651028177133, Recall = 0.9955516014234875, Aging Rate = 0.5013345195729537, Precision = 0.9929015084294588, f1 = 0.9942247889826744\n",
      "Test Loss = 0.005850589066993253, Recall = 0.998220640569395, Aging Rate = 0.4997775800711744, precision = 0.9986648865153538\n",
      "\n",
      "Epoch 56: Train Loss = 0.00516581843694957, Recall = 0.9986654804270463, Aging Rate = 0.5, Precision = 0.9986654804270463, f1 = 0.9986654804270463\n",
      "Epoch 57: Train Loss = 0.002202565221135004, Recall = 1.0, Aging Rate = 0.5002224199288257, Precision = 0.9995553579368608, f1 = 0.9997776295307983\n",
      "Epoch 58: Train Loss = 0.0006372823682986532, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 59: Train Loss = 0.0006930287108131854, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 60: Train Loss = 0.0008670819812044966, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0007781563867364092, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Training Finished at epoch 60.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e2cd1b4f62546cdb1eb3dd0e8af8f01",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss = 0.348458662257759, Recall = 0.8820649755229194, Aging Rate = 0.5440587449933244, Precision = 0.8106339468302658, f1 = 0.8448422847399829\n",
      "Epoch 2: Train Loss = 0.14551485631934896, Recall = 0.956386292834891, Aging Rate = 0.5046728971962616, Precision = 0.9475308641975309, f1 = 0.9519379844961241\n",
      "Epoch 3: Train Loss = 0.09404387041879964, Recall = 0.9719626168224299, Aging Rate = 0.5022251891410769, Precision = 0.9676561807709348, f1 = 0.9698046181172291\n",
      "Epoch 4: Train Loss = 0.07130085118736659, Recall = 0.9795282599020917, Aging Rate = 0.5013351134846462, Precision = 0.9769196626719929, f1 = 0.9782222222222223\n",
      "Epoch 5: Train Loss = 0.06144239900581469, Recall = 0.9790832220738763, Aging Rate = 0.5004450378282154, Precision = 0.9782125389061805, f1 = 0.9786476868327402\n",
      "Test Loss = 0.020879363632438894, Recall = 0.9946595460614153, Aging Rate = 0.5002225189141077, precision = 0.9942170818505338\n",
      "Model in epoch 5 is saved.\n",
      "\n",
      "Epoch 6: Train Loss = 0.018315571324645306, Recall = 0.9942145082331998, Aging Rate = 0.4979973297730307, Precision = 0.998212689901698, f1 = 0.9962095875139353\n",
      "Epoch 7: Train Loss = 0.01330570793040445, Recall = 0.9959946595460614, Aging Rate = 0.5, Precision = 0.9959946595460614, f1 = 0.9959946595460614\n",
      "Epoch 8: Train Loss = 0.005683135133403265, Recall = 0.9991099243435692, Aging Rate = 0.4997774810858923, Precision = 0.9995547640249333, f1 = 0.9993322946806142\n",
      "Epoch 9: Train Loss = 0.0037272627010334716, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 10: Train Loss = 0.003955894228486277, Recall = 0.9995549621717846, Aging Rate = 0.5002225189141077, Precision = 0.9991103202846975, f1 = 0.9993325917686319\n",
      "Test Loss = 0.0033468542915644993, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "Model in epoch 10 is saved.\n",
      "\n",
      "Epoch 11: Train Loss = 0.0035669072949782205, Recall = 1.0, Aging Rate = 0.5004450378282154, Precision = 0.9991107158737217, f1 = 0.9995551601423488\n",
      "Epoch 12: Train Loss = 0.007436425850984052, Recall = 0.9982198486871384, Aging Rate = 0.5002225189141077, Precision = 0.9977758007117438, f1 = 0.9979977753058954\n",
      "Epoch 13: Train Loss = 0.017849907955850265, Recall = 0.9951045838896306, Aging Rate = 0.5004450378282154, Precision = 0.9942196531791907, f1 = 0.9946619217081851\n",
      "Epoch 14: Train Loss = 0.03361739708184466, Recall = 0.991099243435692, Aging Rate = 0.5024477080551847, Precision = 0.9862710363153233, f1 = 0.9886792452830189\n",
      "Epoch 15: Train Loss = 0.018155939349615353, Recall = 0.9933244325767691, Aging Rate = 0.5013351134846462, Precision = 0.9906790945406125, f1 = 0.992\n",
      "Test Loss = 0.0075696794988449065, Recall = 0.9982198486871384, Aging Rate = 0.5002225189141077, precision = 0.9977758007117438\n",
      "\n",
      "Epoch 16: Train Loss = 0.006670625643385222, Recall = 0.9991099243435692, Aging Rate = 0.5006675567423231, Precision = 0.9977777777777778, f1 = 0.9984434067155882\n",
      "Epoch 17: Train Loss = 0.002813130199067207, Recall = 0.9995549621717846, Aging Rate = 0.5, Precision = 0.9995549621717846, f1 = 0.9995549621717846\n",
      "Epoch 18: Train Loss = 0.0017134370060419373, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 19: Train Loss = 0.0014791289349559082, Recall = 0.9995549621717846, Aging Rate = 0.4997774810858923, Precision = 0, f1 = 0.0\n",
      "Epoch 20: Train Loss = 0.000957382390189387, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0009412854287616286, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 21: Train Loss = 0.001161282908037851, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 22: Train Loss = 0.001497029511141539, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 23: Train Loss = 0.003000485274358808, Recall = 0.9995549621717846, Aging Rate = 0.5, Precision = 0.9995549621717846, f1 = 0.9995549621717846\n",
      "Epoch 24: Train Loss = 0.055464478887693854, Recall = 0.9839786381842457, Aging Rate = 0.504450378282154, Precision = 0.9752977503308337, f1 = 0.9796189632255207\n",
      "Epoch 25: Train Loss = 0.03053217238204037, Recall = 0.991099243435692, Aging Rate = 0.5013351134846462, Precision = 0.9884598313359965, f1 = 0.9897777777777778\n",
      "Test Loss = 0.005822565102544383, Recall = 0.9991099243435692, Aging Rate = 0.5, precision = 0.9991099243435692\n",
      "\n",
      "Epoch 26: Train Loss = 0.010065027517169171, Recall = 0.9977748108589231, Aging Rate = 0.5004450378282154, Precision = 0.9968875055580257, f1 = 0.9973309608540926\n",
      "Epoch 27: Train Loss = 0.002281219780671091, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 28: Train Loss = 0.0008989613824745728, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 29: Train Loss = 0.0008647614188739324, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 30: Train Loss = 0.0010633926961320637, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0009194358977732469, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 31: Train Loss = 0.0011499852325865094, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 32: Train Loss = 0.0013600913100812915, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 33: Train Loss = 0.0015912602693306695, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 34: Train Loss = 0.010070417548227652, Recall = 0.9973297730307076, Aging Rate = 0.5004450378282154, Precision = 0.9964428634948866, f1 = 0.9968861209964412\n",
      "Epoch 35: Train Loss = 0.03984961324412016, Recall = 0.9888740542946151, Aging Rate = 0.5028927458834, Precision = 0.9831858407079646, f1 = 0.9860217439538496\n",
      "Test Loss = 0.02017000702971988, Recall = 0.9977748108589231, Aging Rate = 0.5031152647975078, precision = 0.9915966386554622\n",
      "\n",
      "Epoch 36: Train Loss = 0.026650946311763842, Recall = 0.9915442812639075, Aging Rate = 0.5013351134846462, Precision = 0.9889036839769196, f1 = 0.9902222222222222\n",
      "Epoch 37: Train Loss = 0.00885570049591563, Recall = 0.9977748108589231, Aging Rate = 0.5008900756564308, Precision = 0.9960017769880053, f1 = 0.9968875055580257\n",
      "Epoch 38: Train Loss = 0.008319216532561005, Recall = 0.9977748108589231, Aging Rate = 0.4997774810858923, Precision = 0.9982190560997328, f1 = 0.9979968840418428\n",
      "Epoch 39: Train Loss = 0.009073123968182824, Recall = 0.9991099243435692, Aging Rate = 0.5015576323987538, Precision = 0.9960070984915705, f1 = 0.9975560986447457\n",
      "Epoch 40: Train Loss = 0.0029123659852563068, Recall = 0.9991099243435692, Aging Rate = 0.5, Precision = 0.9991099243435692, f1 = 0.9991099243435692\n",
      "Test Loss = 0.001549467110043142, Recall = 1.0, Aging Rate = 0.5004450378282154, precision = 0.9991107158737217\n",
      "\n",
      "Epoch 41: Train Loss = 0.0011384787289074982, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 42: Train Loss = 0.0006352824424398138, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 43: Train Loss = 0.0006945826634476612, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 44: Train Loss = 0.0009765305646660381, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 45: Train Loss = 0.0015814843293870864, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0014273675478438208, Recall = 1.0, Aging Rate = 0.5002225189141077, precision = 0.9995551601423488\n",
      "\n",
      "Epoch 46: Train Loss = 0.0038281748265131203, Recall = 1.0, Aging Rate = 0.5004450378282154, Precision = 0.9991107158737217, f1 = 0.9995551601423488\n",
      "Epoch 47: Train Loss = 0.031863006223411754, Recall = 0.9919893190921228, Aging Rate = 0.5033377837116155, Precision = 0.9854111405835544, f1 = 0.9886892880904856\n",
      "Epoch 48: Train Loss = 0.02325960768109128, Recall = 0.9924343569203382, Aging Rate = 0.5002225189141077, Precision = 0.9919928825622776, f1 = 0.9922135706340379\n",
      "Epoch 49: Train Loss = 0.0029237889022712014, Recall = 1.0, Aging Rate = 0.5004450378282154, Precision = 0.9991107158737217, f1 = 0.9995551601423488\n",
      "Epoch 50: Train Loss = 0.0008275068518030073, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0006340325541876573, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 51: Train Loss = 0.0008992318773087201, Recall = 1.0, Aging Rate = 0.5002225189141077, Precision = 0.9995551601423488, f1 = 0.999777530589544\n",
      "Epoch 52: Train Loss = 0.0036167814237267463, Recall = 0.9995549621717846, Aging Rate = 0.5002225189141077, Precision = 0.9991103202846975, f1 = 0.9993325917686319\n",
      "Epoch 53: Train Loss = 0.0016229453760706564, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 54: Train Loss = 0.0009713368513263906, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 55: Train Loss = 0.0012561677965245608, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0014363837009357993, Recall = 0.9995549621717846, Aging Rate = 0.4997774810858923, precision = 1.0\n",
      "\n",
      "Epoch 56: Train Loss = 0.021943814262107817, Recall = 0.995549621717846, Aging Rate = 0.5026702269692924, Precision = 0.9902611775121736, f1 = 0.9928983577452286\n",
      "Epoch 57: Train Loss = 0.021111651174304965, Recall = 0.9933244325767691, Aging Rate = 0.5011125945705385, Precision = 0.9911190053285968, f1 = 0.9922204934429872\n",
      "Epoch 58: Train Loss = 0.008612389110723402, Recall = 0.9977748108589231, Aging Rate = 0.4997774810858923, Precision = 0.9982190560997328, f1 = 0.9979968840418428\n",
      "Epoch 59: Train Loss = 0.004048101282404992, Recall = 0.9991099243435692, Aging Rate = 0.5004450378282154, Precision = 0.9982214317474433, f1 = 0.9986654804270463\n",
      "Epoch 60: Train Loss = 0.0036655178995704356, Recall = 0.9995549621717846, Aging Rate = 0.5004450378282154, Precision = 0.9986660738105825, f1 = 0.9991103202846975\n",
      "Test Loss = 0.0007447024678225365, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Training Finished at epoch 60.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e9621351a924c2e8e62a54092ae9972",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss = 0.3400437443931208, Recall = 0.8923008455718736, Aging Rate = 0.5560747663551402, Precision = 0.8023209283713485, f1 = 0.844922039612305\n",
      "Epoch 2: Train Loss = 0.14135519839975771, Recall = 0.9572763684913218, Aging Rate = 0.5082331998219849, Precision = 0.941768826619965, f1 = 0.9494592805120283\n",
      "Epoch 3: Train Loss = 0.08815707285562302, Recall = 0.9728526924788607, Aging Rate = 0.5015576323987538, Precision = 0.9698314108251996, f1 = 0.9713397022883804\n",
      "Epoch 4: Train Loss = 0.06892972739274947, Recall = 0.9813084112149533, Aging Rate = 0.5037828215398309, Precision = 0.973939929328622, f1 = 0.9776102859676347\n",
      "Epoch 5: Train Loss = 0.050725757966293035, Recall = 0.9839786381842457, Aging Rate = 0.4984423676012461, Precision = 0.9870535714285714, f1 = 0.9855137062625363\n",
      "Test Loss = 0.020750546448254352, Recall = 0.9951045838896306, Aging Rate = 0.5011125945705385, precision = 0.9928952042628775\n",
      "Model in epoch 5 is saved.\n",
      "\n",
      "Epoch 6: Train Loss = 0.018769637149773973, Recall = 0.9933244325767691, Aging Rate = 0.4986648865153538, Precision = 0.9959839357429718, f1 = 0.9946524064171124\n",
      "Epoch 7: Train Loss = 0.006846103078269569, Recall = 0.9995549621717846, Aging Rate = 0.5004450378282154, Precision = 0.9986660738105825, f1 = 0.9991103202846975\n",
      "Epoch 8: Train Loss = 0.004152042588776928, Recall = 1.0, Aging Rate = 0.5002225189141077, Precision = 0.9995551601423488, f1 = 0.999777530589544\n",
      "Epoch 9: Train Loss = 0.0033635301767252833, Recall = 0.9995549621717846, Aging Rate = 0.5, Precision = 0.9995549621717846, f1 = 0.9995549621717846\n",
      "Epoch 10: Train Loss = 0.003262664659054884, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.002399987595590618, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "Model in epoch 10 is saved.\n",
      "\n",
      "Epoch 11: Train Loss = 0.0034112311180757252, Recall = 0.9995549621717846, Aging Rate = 0.5002225189141077, Precision = 0.9991103202846975, f1 = 0.9993325917686319\n",
      "Epoch 12: Train Loss = 0.0038375486996941664, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 13: Train Loss = 0.004216074624190436, Recall = 0.9995549621717846, Aging Rate = 0.4997774810858923, Precision = 0, f1 = 0.0\n",
      "Epoch 14: Train Loss = 0.006806437455305874, Recall = 0.9991099243435692, Aging Rate = 0.5002225189141077, Precision = 0.9986654804270463, f1 = 0.9988876529477195\n",
      "Epoch 15: Train Loss = 0.03603626598749245, Recall = 0.9893190921228304, Aging Rate = 0.5022251891410769, Precision = 0.9849357554275587, f1 = 0.9871225577264654\n",
      "Test Loss = 0.010350059728669918, Recall = 0.9964396973742768, Aging Rate = 0.4986648865153538, precision = 0.9991075412762159\n",
      "\n",
      "Epoch 16: Train Loss = 0.01911081983341036, Recall = 0.9942145082331998, Aging Rate = 0.5011125945705385, Precision = 0.9920071047957372, f1 = 0.993109579906646\n",
      "Epoch 17: Train Loss = 0.006976575665132913, Recall = 0.9982198486871384, Aging Rate = 0.4993324432576769, Precision = 0.999554367201426, f1 = 0.9988866622133155\n",
      "Epoch 18: Train Loss = 0.0022517964269793468, Recall = 1.0, Aging Rate = 0.5002225189141077, Precision = 0.9995551601423488, f1 = 0.999777530589544\n",
      "Epoch 19: Train Loss = 0.0011123522597397825, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 20: Train Loss = 0.0014805727722027936, Recall = 1.0, Aging Rate = 0.5002225189141077, Precision = 0.9995551601423488, f1 = 0.999777530589544\n",
      "Test Loss = 0.002271287069454106, Recall = 0.9995549621717846, Aging Rate = 0.4997774810858923, precision = 1.0\n",
      "\n",
      "Epoch 21: Train Loss = 0.016121422346821967, Recall = 0.9982198486871384, Aging Rate = 0.5024477080551847, Precision = 0.9933569530558016, f1 = 0.9957824639289679\n",
      "Epoch 22: Train Loss = 0.009107372334173499, Recall = 0.9977748108589231, Aging Rate = 0.5006675567423231, Precision = 0.9964444444444445, f1 = 0.9971091839003781\n",
      "Epoch 23: Train Loss = 0.01852642427593168, Recall = 0.995549621717846, Aging Rate = 0.5013351134846462, Precision = 0.9928983577452286, f1 = 0.9942222222222223\n",
      "Epoch 24: Train Loss = 0.006340407269732661, Recall = 0.9986648865153538, Aging Rate = 0.5004450378282154, Precision = 0.9977767896843042, f1 = 0.998220640569395\n",
      "Epoch 25: Train Loss = 0.002354050585983506, Recall = 0.9995549621717846, Aging Rate = 0.5, Precision = 0.9995549621717846, f1 = 0.9995549621717846\n",
      "Test Loss = 0.0007749018667344108, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 26: Train Loss = 0.0007746708635444922, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 27: Train Loss = 0.000791362248599744, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 28: Train Loss = 0.0009694280306252012, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 29: Train Loss = 0.00128507446802317, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 30: Train Loss = 0.0013815801412250116, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0019724082927462866, Recall = 1.0, Aging Rate = 0.5002225189141077, precision = 0.9995551601423488\n",
      "\n",
      "Epoch 31: Train Loss = 0.010019277195928227, Recall = 0.9986648865153538, Aging Rate = 0.5006675567423231, Precision = 0.9973333333333333, f1 = 0.9979986657771848\n",
      "Epoch 32: Train Loss = 0.05651141179369961, Recall = 0.9862038273253226, Aging Rate = 0.5057854917668002, Precision = 0.9749230092388913, f1 = 0.9805309734513273\n",
      "Epoch 33: Train Loss = 0.031005524005150255, Recall = 0.9906542056074766, Aging Rate = 0.5015576323987538, Precision = 0.9875776397515528, f1 = 0.9891135303265941\n",
      "Epoch 34: Train Loss = 0.005862981705478416, Recall = 0.9995549621717846, Aging Rate = 0.5011125945705385, Precision = 0.9973357015985791, f1 = 0.9984440986885976\n",
      "Epoch 35: Train Loss = 0.0028105198111950656, Recall = 1.0, Aging Rate = 0.5004450378282154, Precision = 0.9991107158737217, f1 = 0.9995551601423488\n",
      "Test Loss = 0.0007660053948621864, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 36: Train Loss = 0.0007576216468808226, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 37: Train Loss = 0.0006824016443749664, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 38: Train Loss = 0.0007967231992584901, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 39: Train Loss = 0.0010416962780513475, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 40: Train Loss = 0.0010886018823572812, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0010128542693836667, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 41: Train Loss = 0.0012784751487438268, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 42: Train Loss = 0.0014726597304705864, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 43: Train Loss = 0.0015820955750803928, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 44: Train Loss = 0.0017631115274968866, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 45: Train Loss = 0.0017031139043326817, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0014877093533732903, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 46: Train Loss = 0.00403320599694682, Recall = 1.0, Aging Rate = 0.5004450378282154, Precision = 0.9991107158737217, f1 = 0.9995551601423488\n",
      "Epoch 47: Train Loss = 0.05476251646905763, Recall = 0.986648865153538, Aging Rate = 0.5051179350244771, Precision = 0.9766519823788546, f1 = 0.9816249723267656\n",
      "Epoch 48: Train Loss = 0.03498653182490473, Recall = 0.9893190921228304, Aging Rate = 0.5017801513128616, Precision = 0.985809312638581, f1 = 0.9875610839626834\n",
      "Epoch 49: Train Loss = 0.008840361070539636, Recall = 0.9982198486871384, Aging Rate = 0.5008900756564308, Precision = 0.9964460239893381, f1 = 0.9973321476211651\n",
      "Epoch 50: Train Loss = 0.0016835209053829578, Recall = 0.9995549621717846, Aging Rate = 0.4997774810858923, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0008947628413558729, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 51: Train Loss = 0.0008539810880225336, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 52: Train Loss = 0.0008224336674762703, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 53: Train Loss = 0.000962612816541069, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 54: Train Loss = 0.0033001836389393874, Recall = 0.9995549621717846, Aging Rate = 0.5002225189141077, Precision = 0.9991103202846975, f1 = 0.9993325917686319\n",
      "Epoch 55: Train Loss = 0.004148113511825618, Recall = 0.9991099243435692, Aging Rate = 0.5, Precision = 0.9991099243435692, f1 = 0.9991099243435692\n",
      "Test Loss = 0.0035223920228244494, Recall = 0.9995549621717846, Aging Rate = 0.5, precision = 0.9995549621717846\n",
      "\n",
      "Epoch 56: Train Loss = 0.0029494090592598484, Recall = 1.0, Aging Rate = 0.5002225189141077, Precision = 0.9995551601423488, f1 = 0.999777530589544\n",
      "Epoch 57: Train Loss = 0.0022063867764746, Recall = 1.0, Aging Rate = 0.5002225189141077, Precision = 0.9995551601423488, f1 = 0.999777530589544\n",
      "Epoch 58: Train Loss = 0.015202306690955352, Recall = 0.9973297730307076, Aging Rate = 0.5022251891410769, Precision = 0.9929109437306158, f1 = 0.9951154529307282\n",
      "Epoch 59: Train Loss = 0.031831678832849236, Recall = 0.9902091677792613, Aging Rate = 0.5020026702269693, Precision = 0.9862588652482269, f1 = 0.9882300688429936\n",
      "Epoch 60: Train Loss = 0.01036739105385246, Recall = 0.9968847352024922, Aging Rate = 0.5002225189141077, Precision = 0.99644128113879, f1 = 0.996662958843159\n",
      "Test Loss = 0.013843436890190967, Recall = 1.0, Aging Rate = 0.5051179350244771, precision = 0.9898678414096916\n",
      "\n",
      "Training Finished at epoch 60.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b747b8511ba4bc592aec300dd84718a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss = 0.32234647320968923, Recall = 0.897196261682243, Aging Rate = 0.5398308856252781, Precision = 0.830997526793075, f1 = 0.8628290177616091\n",
      "Epoch 2: Train Loss = 0.14501159570358518, Recall = 0.9599465954606141, Aging Rate = 0.5097908322207387, Precision = 0.9415102575294632, f1 = 0.9506390480387835\n",
      "Epoch 3: Train Loss = 0.09172252146423553, Recall = 0.9724076546506453, Aging Rate = 0.5053404539385847, Precision = 0.9621312197269926, f1 = 0.9672421425409474\n",
      "Epoch 4: Train Loss = 0.06931870329203303, Recall = 0.9804183355585224, Aging Rate = 0.5053404539385847, Precision = 0.9700572435050638, f1 = 0.975210270030987\n",
      "Epoch 5: Train Loss = 0.060017573334273364, Recall = 0.9813084112149533, Aging Rate = 0.5037828215398309, Precision = 0.973939929328622, f1 = 0.9776102859676347\n",
      "Test Loss = 0.031278544816411916, Recall = 0.9991099243435692, Aging Rate = 0.5084557187360925, precision = 0.9824945295404814\n",
      "Model in epoch 5 is saved.\n",
      "\n",
      "Epoch 6: Train Loss = 0.016431536998816953, Recall = 0.9964396973742768, Aging Rate = 0.5006675567423231, Precision = 0.9951111111111111, f1 = 0.9957749610851678\n",
      "Epoch 7: Train Loss = 0.009867150231538498, Recall = 0.9977748108589231, Aging Rate = 0.5, Precision = 0.9977748108589231, f1 = 0.9977748108589231\n",
      "Epoch 8: Train Loss = 0.0051182520929782, Recall = 0.9991099243435692, Aging Rate = 0.4997774810858923, Precision = 0.9995547640249333, f1 = 0.9993322946806142\n",
      "Epoch 9: Train Loss = 0.0052487860519579285, Recall = 0.9995549621717846, Aging Rate = 0.5002225189141077, Precision = 0.9991103202846975, f1 = 0.9993325917686319\n",
      "Epoch 10: Train Loss = 0.00296306411253266, Recall = 0.9995549621717846, Aging Rate = 0.5, Precision = 0.9995549621717846, f1 = 0.9995549621717846\n",
      "Test Loss = 0.002535678720557946, Recall = 1.0, Aging Rate = 0.5002225189141077, precision = 0.9995551601423488\n",
      "Model in epoch 10 is saved.\n",
      "\n",
      "Epoch 11: Train Loss = 0.003151839737343951, Recall = 0.9995549621717846, Aging Rate = 0.5002225189141077, Precision = 0.9991103202846975, f1 = 0.9993325917686319\n",
      "Epoch 12: Train Loss = 0.0031016420912450163, Recall = 0.9995549621717846, Aging Rate = 0.5, Precision = 0.9995549621717846, f1 = 0.9995549621717846\n",
      "Epoch 13: Train Loss = 0.01071853576276516, Recall = 0.9977748108589231, Aging Rate = 0.5004450378282154, Precision = 0.9968875055580257, f1 = 0.9973309608540926\n",
      "Epoch 14: Train Loss = 0.01064728094848444, Recall = 0.9986648865153538, Aging Rate = 0.5011125945705385, Precision = 0.9964476021314387, f1 = 0.9975550122249388\n",
      "Epoch 15: Train Loss = 0.023746594668518955, Recall = 0.9919893190921228, Aging Rate = 0.5024477080551847, Precision = 0.9871567759078831, f1 = 0.9895671476137625\n",
      "Test Loss = 0.018012128824440237, Recall = 0.9942145082331998, Aging Rate = 0.49888740542946153, precision = 0.9964317573595004\n",
      "\n",
      "Epoch 16: Train Loss = 0.017812680881213468, Recall = 0.9964396973742768, Aging Rate = 0.5028927458834, Precision = 0.9907079646017699, f1 = 0.9935655646771688\n",
      "Epoch 17: Train Loss = 0.008909050019643518, Recall = 0.9973297730307076, Aging Rate = 0.5002225189141077, Precision = 0.9968861209964412, f1 = 0.9971078976640712\n",
      "Epoch 18: Train Loss = 0.011740358664863918, Recall = 0.9973297730307076, Aging Rate = 0.5020026702269693, Precision = 0.9933510638297872, f1 = 0.995336442371752\n",
      "Epoch 19: Train Loss = 0.00944724512120902, Recall = 0.9977748108589231, Aging Rate = 0.5, Precision = 0.9977748108589231, f1 = 0.9977748108589231\n",
      "Epoch 20: Train Loss = 0.002961493512392989, Recall = 0.9991099243435692, Aging Rate = 0.4997774810858923, Precision = 0.9995547640249333, f1 = 0.9993322946806142\n",
      "Test Loss = 0.0012190109448066842, Recall = 0.9995549621717846, Aging Rate = 0.5, precision = 0.9995549621717846\n",
      "\n",
      "Epoch 21: Train Loss = 0.003000366931474877, Recall = 0.9982198486871384, Aging Rate = 0.5, Precision = 0.9982198486871384, f1 = 0.9982198486871384\n",
      "Epoch 22: Train Loss = 0.013978043171250966, Recall = 0.9959946595460614, Aging Rate = 0.5008900756564308, Precision = 0.9942247889826744, f1 = 0.9951089373054691\n",
      "Epoch 23: Train Loss = 0.0072651364463188735, Recall = 0.9982198486871384, Aging Rate = 0.4997774810858923, Precision = 0.9986642920747997, f1 = 0.9984420209214333\n",
      "Epoch 24: Train Loss = 0.001601870703897126, Recall = 1.0, Aging Rate = 0.5002225189141077, Precision = 0.9995551601423488, f1 = 0.999777530589544\n",
      "Epoch 25: Train Loss = 0.0007495128578104578, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0006385545959871497, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "Model in epoch 25 is saved.\n",
      "\n",
      "Epoch 26: Train Loss = 0.000707455804034714, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 27: Train Loss = 0.0010036699763005148, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 28: Train Loss = 0.001185685683994686, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 29: Train Loss = 0.001235844174289722, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 30: Train Loss = 0.0017161081493711973, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.002445788594954624, Recall = 1.0, Aging Rate = 0.5002225189141077, precision = 0.9995551601423488\n",
      "\n",
      "Epoch 31: Train Loss = 0.033615831725057305, Recall = 0.9902091677792613, Aging Rate = 0.5035603026257232, Precision = 0.9832081307998233, f1 = 0.9866962305986696\n",
      "Epoch 32: Train Loss = 0.05071558790098218, Recall = 0.986648865153538, Aging Rate = 0.5024477080551847, Precision = 0.9818423383525243, f1 = 0.9842397336293006\n",
      "Epoch 33: Train Loss = 0.014659378771484892, Recall = 0.9959946595460614, Aging Rate = 0.4995549621717846, Precision = 0.9968819599109131, f1 = 0.9964381121994657\n",
      "Epoch 34: Train Loss = 0.0032250274606998204, Recall = 0.9995549621717846, Aging Rate = 0.5004450378282154, Precision = 0.9986660738105825, f1 = 0.9991103202846975\n",
      "Epoch 35: Train Loss = 0.0014891926201580994, Recall = 1.0, Aging Rate = 0.5002225189141077, Precision = 0.9995551601423488, f1 = 0.999777530589544\n",
      "Test Loss = 0.0019070850370821622, Recall = 1.0, Aging Rate = 0.5002225189141077, precision = 0.9995551601423488\n",
      "\n",
      "Epoch 36: Train Loss = 0.001964650226644608, Recall = 1.0, Aging Rate = 0.5002225189141077, Precision = 0.9995551601423488, f1 = 0.999777530589544\n",
      "Epoch 37: Train Loss = 0.0018927303251800424, Recall = 0.9995549621717846, Aging Rate = 0.5002225189141077, Precision = 0.9991103202846975, f1 = 0.9993325917686319\n",
      "Epoch 38: Train Loss = 0.0013660610981723255, Recall = 1.0, Aging Rate = 0.5002225189141077, Precision = 0.9995551601423488, f1 = 0.999777530589544\n",
      "Epoch 39: Train Loss = 0.012591614736398266, Recall = 0.9968847352024922, Aging Rate = 0.5013351134846462, Precision = 0.9942299156679982, f1 = 0.9955555555555555\n",
      "Epoch 40: Train Loss = 0.00825729349991377, Recall = 0.9986648865153538, Aging Rate = 0.5006675567423231, Precision = 0.9973333333333333, f1 = 0.9979986657771848\n",
      "Test Loss = 0.0035609600996713824, Recall = 0.9991099243435692, Aging Rate = 0.4997774810858923, precision = 0.9995547640249333\n",
      "\n",
      "Epoch 41: Train Loss = 0.004384231484485467, Recall = 0.9995549621717846, Aging Rate = 0.5004450378282154, Precision = 0.9986660738105825, f1 = 0.9991103202846975\n",
      "Epoch 42: Train Loss = 0.0016256097749725393, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 43: Train Loss = 0.0008398960617009897, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 44: Train Loss = 0.0008623779550379492, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 45: Train Loss = 0.0011358271718927102, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0011094060313440676, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 46: Train Loss = 0.0017216475103833827, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 47: Train Loss = 0.001624257813318055, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 48: Train Loss = 0.002489062683809338, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 49: Train Loss = 0.04576206305837255, Recall = 0.9893190921228304, Aging Rate = 0.5057854917668002, Precision = 0.978002639683238, f1 = 0.9836283185840708\n",
      "Epoch 50: Train Loss = 0.03295356640913435, Recall = 0.9928793947485536, Aging Rate = 0.5028927458834, Precision = 0.9871681415929203, f1 = 0.9900155313956068\n",
      "Test Loss = 0.01119531982511607, Recall = 0.9942145082331998, Aging Rate = 0.497774810858923, precision = 0.9986589181940099\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 51: Train Loss = 0.012024420195256668, Recall = 0.995549621717846, Aging Rate = 0.5002225189141077, Precision = 0.9951067615658363, f1 = 0.9953281423804228\n",
      "Epoch 52: Train Loss = 0.002009357423431948, Recall = 0.9995549621717846, Aging Rate = 0.4997774810858923, Precision = 0, f1 = 0.0\n",
      "Epoch 53: Train Loss = 0.002044284062008133, Recall = 0.9995549621717846, Aging Rate = 0.5, Precision = 0.9995549621717846, f1 = 0.9995549621717846\n",
      "Epoch 54: Train Loss = 0.001104033825818315, Recall = 1.0, Aging Rate = 0.5002225189141077, Precision = 0.9995551601423488, f1 = 0.999777530589544\n",
      "Epoch 55: Train Loss = 0.0007866154300296802, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0006919590482796228, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 56: Train Loss = 0.0008401098024596605, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 57: Train Loss = 0.000911802484115696, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 58: Train Loss = 0.0010769269120364281, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 59: Train Loss = 0.001313232832920249, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 60: Train Loss = 0.001321600081672014, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.001188755461168577, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 61: Train Loss = 0.0017027218968486873, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 62: Train Loss = 0.016860765775538814, Recall = 0.9951045838896306, Aging Rate = 0.5008900756564308, Precision = 0.9933362949800089, f1 = 0.9942196531791907\n",
      "Epoch 63: Train Loss = 0.06340659071530104, Recall = 0.9839786381842457, Aging Rate = 0.5037828215398309, Precision = 0.9765901060070671, f1 = 0.9802704500110839\n",
      "Epoch 64: Train Loss = 0.01236889481908817, Recall = 0.9959946595460614, Aging Rate = 0.5, Precision = 0.9959946595460614, f1 = 0.9959946595460614\n",
      "Epoch 65: Train Loss = 0.003546396242624582, Recall = 1.0, Aging Rate = 0.5011125945705385, Precision = 0.9977797513321492, f1 = 0.9988886419204267\n",
      "Test Loss = 0.0017831687833801944, Recall = 0.9995549621717846, Aging Rate = 0.4997774810858923, precision = 1.0\n",
      "\n",
      "Epoch 66: Train Loss = 0.0013873233665261644, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 67: Train Loss = 0.000842909443099031, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 68: Train Loss = 0.0009498214522970597, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 69: Train Loss = 0.0010040115192190599, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 70: Train Loss = 0.001164234836186267, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0012749306297968595, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 71: Train Loss = 0.001176353526019011, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 72: Train Loss = 0.001367331799879234, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 73: Train Loss = 0.0015513994679199786, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 74: Train Loss = 0.0026321600116275394, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 75: Train Loss = 0.012263479117224507, Recall = 0.9973297730307076, Aging Rate = 0.5013351134846462, Precision = 0.9946737683089214, f1 = 0.9959999999999999\n",
      "Test Loss = 0.014688626650437334, Recall = 0.9959946595460614, Aging Rate = 0.5, precision = 0.9959946595460614\n",
      "\n",
      "Training Finished at epoch 75.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "59cae894bfbe42b49dbcaf816bbcaa67",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss = 0.31579117866213924, Recall = 0.9025367156208278, Aging Rate = 0.5465064530485091, Precision = 0.8257328990228013, f1 = 0.8624282372953435\n",
      "Epoch 2: Train Loss = 0.1393160940507285, Recall = 0.9577214063195372, Aging Rate = 0.5055629728526925, Precision = 0.9471830985915493, f1 = 0.9524231024562957\n",
      "Epoch 3: Train Loss = 0.0856683788366009, Recall = 0.9746328437917223, Aging Rate = 0.5037828215398309, Precision = 0.9673144876325088, f1 = 0.9709598758590113\n",
      "Epoch 4: Train Loss = 0.06263593842599145, Recall = 0.9808633733867379, Aging Rate = 0.5011125945705385, Precision = 0.9786856127886323, f1 = 0.9797732829517671\n",
      "Epoch 5: Train Loss = 0.051636349767095045, Recall = 0.9826435246995995, Aging Rate = 0.5, Precision = 0.9826435246995995, f1 = 0.9826435246995995\n",
      "Test Loss = 0.022714222358182424, Recall = 0.9995549621717846, Aging Rate = 0.5037828215398309, precision = 0.9920494699646644\n",
      "Model in epoch 5 is saved.\n",
      "\n",
      "Epoch 6: Train Loss = 0.014925269497468118, Recall = 0.9951045838896306, Aging Rate = 0.4991099243435692, Precision = 0.9968791796700847, f1 = 0.9959910913140312\n",
      "Epoch 7: Train Loss = 0.005685462292472773, Recall = 0.9986648865153538, Aging Rate = 0.4997774810858923, Precision = 0.9991095280498664, f1 = 0.9988871578010239\n",
      "Epoch 8: Train Loss = 0.0032504265230090174, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 9: Train Loss = 0.0035692997748039672, Recall = 0.9995549621717846, Aging Rate = 0.5, Precision = 0.9995549621717846, f1 = 0.9995549621717846\n",
      "Epoch 10: Train Loss = 0.003493892425890062, Recall = 0.9995549621717846, Aging Rate = 0.5, Precision = 0.9995549621717846, f1 = 0.9995549621717846\n",
      "Test Loss = 0.0034158295957171817, Recall = 1.0, Aging Rate = 0.5002225189141077, precision = 0.9995551601423488\n",
      "Model in epoch 10 is saved.\n",
      "\n",
      "Epoch 11: Train Loss = 0.0030324414033508222, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 12: Train Loss = 0.011901699373366756, Recall = 0.9968847352024922, Aging Rate = 0.5004450378282154, Precision = 0.9959982214317474, f1 = 0.99644128113879\n",
      "Epoch 13: Train Loss = 0.027579079495272905, Recall = 0.9919893190921228, Aging Rate = 0.5013351134846462, Precision = 0.9893475366178429, f1 = 0.9906666666666667\n",
      "Epoch 14: Train Loss = 0.013777245947762471, Recall = 0.9968847352024922, Aging Rate = 0.5015576323987538, Precision = 0.9937888198757764, f1 = 0.9953343701399688\n",
      "Epoch 15: Train Loss = 0.006502781217606115, Recall = 0.9986648865153538, Aging Rate = 0.5004450378282154, Precision = 0.9977767896843042, f1 = 0.998220640569395\n",
      "Test Loss = 0.0028548689404542197, Recall = 0.9991099243435692, Aging Rate = 0.4995549621717846, precision = 1.0\n",
      "\n",
      "Epoch 16: Train Loss = 0.005145486428588463, Recall = 0.9986648865153538, Aging Rate = 0.4997774810858923, Precision = 0.9991095280498664, f1 = 0.9988871578010239\n",
      "Epoch 17: Train Loss = 0.00630348466962997, Recall = 0.9991099243435692, Aging Rate = 0.5004450378282154, Precision = 0.9982214317474433, f1 = 0.9986654804270463\n",
      "Epoch 18: Train Loss = 0.002326744244206808, Recall = 0.9995549621717846, Aging Rate = 0.5002225189141077, Precision = 0.9991103202846975, f1 = 0.9993325917686319\n",
      "Epoch 19: Train Loss = 0.000937099397672528, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 20: Train Loss = 0.0008796903695759887, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0008019624321287747, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "Model in epoch 20 is saved.\n",
      "\n",
      "Epoch 21: Train Loss = 0.0010320817506455572, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 22: Train Loss = 0.001287438756845142, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 23: Train Loss = 0.0014164817735426787, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 24: Train Loss = 0.0044697753950981665, Recall = 0.9991099243435692, Aging Rate = 0.4997774810858923, Precision = 0.9995547640249333, f1 = 0.9993322946806142\n",
      "Epoch 25: Train Loss = 0.0873749532667828, Recall = 0.9750778816199377, Aging Rate = 0.5066755674232309, Precision = 0.9622310057092666, f1 = 0.9686118479221928\n",
      "Test Loss = 0.017247942344687173, Recall = 0.9875389408099688, Aging Rate = 0.4953271028037383, precision = 0.9968553459119497\n",
      "\n",
      "Epoch 26: Train Loss = 0.012747138737699636, Recall = 0.9964396973742768, Aging Rate = 0.5002225189141077, Precision = 0.9959964412811388, f1 = 0.996218020022247\n",
      "Epoch 27: Train Loss = 0.003007338953060009, Recall = 1.0, Aging Rate = 0.5002225189141077, Precision = 0.9995551601423488, f1 = 0.999777530589544\n",
      "Epoch 28: Train Loss = 0.0025566227751030513, Recall = 0.9995549621717846, Aging Rate = 0.5002225189141077, Precision = 0.9991103202846975, f1 = 0.9993325917686319\n",
      "Epoch 29: Train Loss = 0.0015850372610248552, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 30: Train Loss = 0.002451060880903979, Recall = 0.9995549621717846, Aging Rate = 0.5, Precision = 0.9995549621717846, f1 = 0.9995549621717846\n",
      "Test Loss = 0.00322186918933364, Recall = 1.0, Aging Rate = 0.5002225189141077, precision = 0.9995551601423488\n",
      "\n",
      "Epoch 31: Train Loss = 0.0019601523013255784, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 32: Train Loss = 0.002680917347832755, Recall = 0.9995549621717846, Aging Rate = 0.5002225189141077, Precision = 0.9991103202846975, f1 = 0.9993325917686319\n",
      "Epoch 33: Train Loss = 0.002754281765245014, Recall = 0.9995549621717846, Aging Rate = 0.5, Precision = 0.9995549621717846, f1 = 0.9995549621717846\n",
      "Epoch 34: Train Loss = 0.0022959251931408842, Recall = 1.0, Aging Rate = 0.5004450378282154, Precision = 0.9991107158737217, f1 = 0.9995551601423488\n",
      "Epoch 35: Train Loss = 0.028727385175360918, Recall = 0.9915442812639075, Aging Rate = 0.5028927458834, Precision = 0.9858407079646018, f1 = 0.9886842689150211\n",
      "Test Loss = 0.008182620873275197, Recall = 0.9982198486871384, Aging Rate = 0.5008900756564308, precision = 0.9964460239893381\n",
      "\n",
      "Epoch 36: Train Loss = 0.02417764325778928, Recall = 0.9942145082331998, Aging Rate = 0.5024477080551847, Precision = 0.9893711248892826, f1 = 0.9917869034406215\n",
      "Epoch 37: Train Loss = 0.006464401288377422, Recall = 0.9986648865153538, Aging Rate = 0.5002225189141077, Precision = 0.998220640569395, f1 = 0.9984427141268075\n",
      "Epoch 38: Train Loss = 0.00211686648767376, Recall = 0.9991099243435692, Aging Rate = 0.4995549621717846, Precision = 0, f1 = 0.0\n",
      "Epoch 39: Train Loss = 0.001020754721785784, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 40: Train Loss = 0.0010125744427825478, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0011135693141889253, Recall = 1.0, Aging Rate = 0.5002225189141077, precision = 0.9995551601423488\n",
      "\n",
      "Epoch 41: Train Loss = 0.0013369640564495683, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 42: Train Loss = 0.0012694104828434103, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 43: Train Loss = 0.0015141675172582547, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 44: Train Loss = 0.011479714719771768, Recall = 0.9977748108589231, Aging Rate = 0.5006675567423231, Precision = 0.9964444444444445, f1 = 0.9971091839003781\n",
      "Epoch 45: Train Loss = 0.04252632191461898, Recall = 0.9884290164663997, Aging Rate = 0.5037828215398309, Precision = 0.9810070671378092, f1 = 0.9847040567501663\n",
      "Test Loss = 0.009564070371744312, Recall = 0.9977748108589231, Aging Rate = 0.5020026702269693, precision = 0.9937943262411347\n",
      "\n",
      "Epoch 46: Train Loss = 0.008972886589185419, Recall = 0.9968847352024922, Aging Rate = 0.5, Precision = 0.9968847352024922, f1 = 0.9968847352024922\n",
      "Epoch 47: Train Loss = 0.006265320666660739, Recall = 0.9986648865153538, Aging Rate = 0.5008900756564308, Precision = 0.9968902709906708, f1 = 0.9977767896843042\n",
      "Epoch 48: Train Loss = 0.0024268575610355055, Recall = 0.9995549621717846, Aging Rate = 0.5, Precision = 0.9995549621717846, f1 = 0.9995549621717846\n",
      "Epoch 49: Train Loss = 0.002135297721136829, Recall = 0.9995549621717846, Aging Rate = 0.5, Precision = 0.9995549621717846, f1 = 0.9995549621717846\n",
      "Epoch 50: Train Loss = 0.0011747744275997034, Recall = 0.9995549621717846, Aging Rate = 0.5, Precision = 0.9995549621717846, f1 = 0.9995549621717846\n",
      "Test Loss = 0.0015720995168183388, Recall = 1.0, Aging Rate = 0.5002225189141077, precision = 0.9995551601423488\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 51: Train Loss = 0.0014365269096946849, Recall = 1.0, Aging Rate = 0.5002225189141077, Precision = 0.9995551601423488, f1 = 0.999777530589544\n",
      "Epoch 52: Train Loss = 0.001778069805560288, Recall = 0.9995549621717846, Aging Rate = 0.5002225189141077, Precision = 0.9991103202846975, f1 = 0.9993325917686319\n",
      "Epoch 53: Train Loss = 0.0016317183621906235, Recall = 1.0, Aging Rate = 0.5002225189141077, Precision = 0.9995551601423488, f1 = 0.999777530589544\n",
      "Epoch 54: Train Loss = 0.0010270397653660236, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 55: Train Loss = 0.0012536170113673015, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0011857257266170386, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 56: Train Loss = 0.0013150792903816853, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 57: Train Loss = 0.009478930845229981, Recall = 0.9995549621717846, Aging Rate = 0.5022251891410769, Precision = 0.9951262738147985, f1 = 0.9973357015985791\n",
      "Epoch 58: Train Loss = 0.06639259689602327, Recall = 0.9821984868713841, Aging Rate = 0.5051179350244771, Precision = 0.9722466960352423, f1 = 0.9771972548151427\n",
      "Epoch 59: Train Loss = 0.017197887878049007, Recall = 0.9968847352024922, Aging Rate = 0.5020026702269693, Precision = 0.9929078014184397, f1 = 0.9948922940262047\n",
      "Epoch 60: Train Loss = 0.005636121380351348, Recall = 0.9991099243435692, Aging Rate = 0.5006675567423231, Precision = 0.9977777777777778, f1 = 0.9984434067155882\n",
      "Test Loss = 0.004827363948063352, Recall = 1.0, Aging Rate = 0.5008900756564308, precision = 0.998223011994669\n",
      "\n",
      "Epoch 61: Train Loss = 0.0016698387428570223, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 62: Train Loss = 0.0010642520009738346, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 63: Train Loss = 0.000962943222354969, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 64: Train Loss = 0.0011135198062159988, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 65: Train Loss = 0.0009350743232878081, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.000908690643889318, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 66: Train Loss = 0.0010619832639129434, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 67: Train Loss = 0.0013009984254804708, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 68: Train Loss = 0.0013073466259529826, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 69: Train Loss = 0.0016598855028186752, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 70: Train Loss = 0.002469395265160572, Recall = 1.0, Aging Rate = 0.5002225189141077, Precision = 0.9995551601423488, f1 = 0.999777530589544\n",
      "Test Loss = 0.00678557796572871, Recall = 0.9991099243435692, Aging Rate = 0.4997774810858923, precision = 0.9995547640249333\n",
      "\n",
      "Training Finished at epoch 70.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e71bf2dd5a2489d986875c756b66b73",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss = 0.5493335110861212, Recall = 0.902135231316726, Aging Rate = 0.7133007117437722, Precision = 0.6323666978484564, f1 = 0.7435380384967919\n",
      "Epoch 2: Train Loss = 0.33660366569125355, Recall = 0.9061387900355872, Aging Rate = 0.5444839857651246, Precision = 0.8321078431372549, f1 = 0.8675468483816015\n",
      "Epoch 3: Train Loss = 0.2445444012876083, Recall = 0.9421708185053381, Aging Rate = 0.5315836298932385, Precision = 0.8861924686192468, f1 = 0.9133247089262613\n",
      "Epoch 4: Train Loss = 0.1906441594888307, Recall = 0.9555160142348754, Aging Rate = 0.5220195729537367, Precision = 0.9152109075415424, f1 = 0.9349292709466812\n",
      "Epoch 5: Train Loss = 0.15593409615161155, Recall = 0.9670818505338078, Aging Rate = 0.5151245551601423, Precision = 0.9386873920552677, f1 = 0.9526730937773883\n",
      "Test Loss = 0.11860689886736275, Recall = 0.9777580071174378, Aging Rate = 0.510008896797153, precision = 0.9585695595290014\n",
      "Model in epoch 5 is saved.\n",
      "\n",
      "Epoch 6: Train Loss = 0.10963219568610616, Recall = 0.9768683274021353, Aging Rate = 0.5077846975088968, Precision = 0.961892247043364, f1 = 0.9693224453762966\n",
      "Epoch 7: Train Loss = 0.08649231868653535, Recall = 0.9826512455516014, Aging Rate = 0.5040035587188612, Precision = 0.9748455428067079, f1 = 0.9787328311918477\n",
      "Epoch 8: Train Loss = 0.07053100584187541, Recall = 0.9857651245551602, Aging Rate = 0.5026690391459074, Precision = 0.9805309734513274, f1 = 0.9831410825199645\n",
      "Epoch 9: Train Loss = 0.05710505592732879, Recall = 0.9884341637010676, Aging Rate = 0.5006672597864769, Precision = 0.9871168369613506, f1 = 0.9877750611246944\n",
      "Epoch 10: Train Loss = 0.04675842465640599, Recall = 0.9915480427046264, Aging Rate = 0.5011120996441281, Precision = 0.9893475366178429, f1 = 0.9904465674294601\n",
      "Test Loss = 0.04032197509133307, Recall = 0.9933274021352313, Aging Rate = 0.4991103202846975, precision = 0.9950980392156863\n",
      "Model in epoch 10 is saved.\n",
      "\n",
      "Epoch 11: Train Loss = 0.03921056509654293, Recall = 0.9937722419928826, Aging Rate = 0.5004448398576512, Precision = 0.9928888888888889, f1 = 0.9933303690529125\n",
      "Epoch 12: Train Loss = 0.032749743237296035, Recall = 0.9955516014234875, Aging Rate = 0.4997775800711744, Precision = 0.9959946595460614, f1 = 0.9957730812013348\n",
      "Epoch 13: Train Loss = 0.027578215568833504, Recall = 0.9973309608540926, Aging Rate = 0.5002224199288257, Precision = 0.9968875055580257, f1 = 0.9971091839003781\n",
      "Epoch 14: Train Loss = 0.023396513842417463, Recall = 0.9986654804270463, Aging Rate = 0.5008896797153025, Precision = 0.9968916518650088, f1 = 0.9977777777777778\n",
      "Epoch 15: Train Loss = 0.020076196478328458, Recall = 0.9977758007117438, Aging Rate = 0.5006672597864769, Precision = 0.9964460239893381, f1 = 0.9971104689931096\n",
      "Test Loss = 0.017549294070257834, Recall = 0.9991103202846975, Aging Rate = 0.5, precision = 0.9991103202846975\n",
      "Model in epoch 15 is saved.\n",
      "\n",
      "Epoch 16: Train Loss = 0.01747980964572245, Recall = 0.9991103202846975, Aging Rate = 0.5002224199288257, Precision = 0.9986660738105825, f1 = 0.9988881476539915\n",
      "Epoch 17: Train Loss = 0.015338242635647915, Recall = 0.9995551601423488, Aging Rate = 0.5008896797153025, Precision = 0.9977797513321492, f1 = 0.9986666666666667\n",
      "Epoch 18: Train Loss = 0.013768311793786668, Recall = 0.9991103202846975, Aging Rate = 0.5, Precision = 0.9991103202846975, f1 = 0.9991103202846975\n",
      "Epoch 19: Train Loss = 0.011747518090325742, Recall = 0.9995551601423488, Aging Rate = 0.4997775800711744, Precision = 0, f1 = 0.0\n",
      "Epoch 20: Train Loss = 0.010371336867548923, Recall = 0.9995551601423488, Aging Rate = 0.4997775800711744, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.008654095915235659, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "Model in epoch 20 is saved.\n",
      "\n",
      "Epoch 21: Train Loss = 0.00896866718353538, Recall = 0.9995551601423488, Aging Rate = 0.4997775800711744, Precision = 0, f1 = 0.0\n",
      "Epoch 22: Train Loss = 0.0082484246877907, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 23: Train Loss = 0.007298017125344732, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 24: Train Loss = 0.006612072802344304, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 25: Train Loss = 0.005863452938408508, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.005226110366299033, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 26: Train Loss = 0.005394493769092015, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 27: Train Loss = 0.005017118404198478, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 28: Train Loss = 0.00458331644664323, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 29: Train Loss = 0.004408999184623785, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 30: Train Loss = 0.004016823097201747, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.003380098957253547, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 31: Train Loss = 0.003695118483785686, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 32: Train Loss = 0.0034554488215350226, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 33: Train Loss = 0.003325875541336132, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 34: Train Loss = 0.0030684483277336346, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 35: Train Loss = 0.0028648795692574934, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.002557464425362567, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 36: Train Loss = 0.002720544353753885, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 37: Train Loss = 0.002708405134055989, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 38: Train Loss = 0.002506358719686066, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 39: Train Loss = 0.0025875996228628974, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 40: Train Loss = 0.00235929766365781, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0021580845246827263, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 41: Train Loss = 0.00232276255704025, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 42: Train Loss = 0.0021868715836630068, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 43: Train Loss = 0.00209024214613321, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 44: Train Loss = 0.002278385709165811, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 45: Train Loss = 0.0020785828614425165, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0017479127409679026, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 46: Train Loss = 0.0019871272325674835, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 47: Train Loss = 0.0027113957616444213, Recall = 1.0, Aging Rate = 0.5002224199288257, Precision = 0.9995553579368608, f1 = 0.9997776295307983\n",
      "Epoch 48: Train Loss = 0.004027500793999028, Recall = 0.9995551601423488, Aging Rate = 0.5, Precision = 0.9995551601423488, f1 = 0.9995551601423488\n",
      "Epoch 49: Train Loss = 0.001999466059384768, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 50: Train Loss = 0.0015933744653270604, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0014213819692269285, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 51: Train Loss = 0.0016170552746538616, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 52: Train Loss = 0.0016882041116241776, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 53: Train Loss = 0.0016232529102851144, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 54: Train Loss = 0.0016753026551494102, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 55: Train Loss = 0.0017069155127439795, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.001475674434758895, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 56: Train Loss = 0.0016559493420165018, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 57: Train Loss = 0.001678789557733331, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 58: Train Loss = 0.0017727014077976479, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 59: Train Loss = 0.0021691123372460865, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 60: Train Loss = 0.0017612178808283658, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0027126839570452547, Recall = 1.0, Aging Rate = 0.5004448398576512, precision = 0.9991111111111111\n",
      "\n",
      "Epoch 61: Train Loss = 0.0022959205167851944, Recall = 1.0, Aging Rate = 0.5002224199288257, Precision = 0.9995553579368608, f1 = 0.9997776295307983\n",
      "Epoch 62: Train Loss = 0.002539247834932364, Recall = 0.9995551601423488, Aging Rate = 0.4997775800711744, Precision = 0, f1 = 0.0\n",
      "Epoch 63: Train Loss = 0.0015877611790965991, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 64: Train Loss = 0.0014354255791170212, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 65: Train Loss = 0.001493089895958936, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0014266601017530465, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 66: Train Loss = 0.0015527137055548962, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 67: Train Loss = 0.0015212379543448789, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 68: Train Loss = 0.0015849674982681631, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 69: Train Loss = 0.001578094813271734, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 70: Train Loss = 0.0015970480993300596, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0013931194617366584, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Training Finished at epoch 70.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eebf3ce164c94f2e9ec64e3afc12497d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss = 0.5466821862556269, Recall = 0.906097018246551, Aging Rate = 0.7171784601691144, Precision = 0.6317095873409867, f1 = 0.7444241316270568\n",
      "Epoch 2: Train Loss = 0.33595774888090413, Recall = 0.9078771695594126, Aging Rate = 0.5516243880729862, Precision = 0.8229124647035094, f1 = 0.8633093525179856\n",
      "Epoch 3: Train Loss = 0.25896021164041866, Recall = 0.9314641744548287, Aging Rate = 0.5353805073431241, Precision = 0.8699085619285121, f1 = 0.8996346443154954\n",
      "Epoch 4: Train Loss = 0.21232153529663536, Recall = 0.9465954606141522, Aging Rate = 0.5246995994659546, Precision = 0.9020356234096693, f1 = 0.9237785016286646\n",
      "Epoch 5: Train Loss = 0.17436567142532833, Recall = 0.9590565198041834, Aging Rate = 0.5180240320427236, Precision = 0.9256872852233677, f1 = 0.9420765027322404\n",
      "Test Loss = 0.1415199270587154, Recall = 0.9701824655095683, Aging Rate = 0.5198041833555852, precision = 0.9332191780821918\n",
      "Model in epoch 5 is saved.\n",
      "\n",
      "Epoch 6: Train Loss = 0.12889515307806945, Recall = 0.9675122385402759, Aging Rate = 0.5062305295950156, Precision = 0.9556043956043956, f1 = 0.9615214506855373\n",
      "Epoch 7: Train Loss = 0.10351680356115567, Recall = 0.9737427681352915, Aging Rate = 0.5008900756564308, Precision = 0.9720124389160373, f1 = 0.9728768341485104\n",
      "Epoch 8: Train Loss = 0.0838926804525936, Recall = 0.9759679572763685, Aging Rate = 0.4984423676012461, Precision = 0.9790178571428572, f1 = 0.9774905281925563\n",
      "Epoch 9: Train Loss = 0.0672338653006021, Recall = 0.9821984868713841, Aging Rate = 0.4984423676012461, Precision = 0.9852678571428571, f1 = 0.9837307778025406\n",
      "Epoch 10: Train Loss = 0.05503253500807482, Recall = 0.9857587894971073, Aging Rate = 0.4975522919448153, Precision = 0.990608228980322, f1 = 0.988177559669864\n",
      "Test Loss = 0.046282905465199996, Recall = 0.991099243435692, Aging Rate = 0.4982198486871384, precision = 0.9946404644930773\n",
      "Model in epoch 10 is saved.\n",
      "\n",
      "Epoch 11: Train Loss = 0.04597370676666458, Recall = 0.9888740542946151, Aging Rate = 0.4979973297730307, Precision = 0.9928507596067918, f1 = 0.9908584169453735\n",
      "Epoch 12: Train Loss = 0.03880190229914588, Recall = 0.9937694704049844, Aging Rate = 0.4993324432576769, Precision = 0.9950980392156863, f1 = 0.9944333110665775\n",
      "Epoch 13: Train Loss = 0.032875690096927104, Recall = 0.9959946595460614, Aging Rate = 0.4993324432576769, Precision = 0.9973262032085561, f1 = 0.9966599866399466\n",
      "Epoch 14: Train Loss = 0.027541800041927144, Recall = 0.9964396973742768, Aging Rate = 0.4991099243435692, Precision = 0.9982166740971913, f1 = 0.9973273942093541\n",
      "Epoch 15: Train Loss = 0.02425447872112052, Recall = 0.9977748108589231, Aging Rate = 0.5, Precision = 0.9977748108589231, f1 = 0.9977748108589231\n",
      "Test Loss = 0.020384516103195652, Recall = 0.9991099243435692, Aging Rate = 0.5004450378282154, precision = 0.9982214317474433\n",
      "Model in epoch 15 is saved.\n",
      "\n",
      "Epoch 16: Train Loss = 0.021130425131846174, Recall = 0.9977748108589231, Aging Rate = 0.4995549621717846, Precision = 0.9986636971046771, f1 = 0.9982190560997329\n",
      "Epoch 17: Train Loss = 0.01767093362141621, Recall = 0.9986648865153538, Aging Rate = 0.5, Precision = 0.9986648865153538, f1 = 0.9986648865153538\n",
      "Epoch 18: Train Loss = 0.016066270619489894, Recall = 0.9986648865153538, Aging Rate = 0.4995549621717846, Precision = 0.999554565701559, f1 = 0.9991095280498664\n",
      "Epoch 19: Train Loss = 0.01371456980771577, Recall = 0.9995549621717846, Aging Rate = 0.5, Precision = 0.9995549621717846, f1 = 0.9995549621717846\n",
      "Epoch 20: Train Loss = 0.011897695068647967, Recall = 0.9995549621717846, Aging Rate = 0.4997774810858923, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.010317878650512147, Recall = 0.9995549621717846, Aging Rate = 0.5, precision = 0.9995549621717846\n",
      "Model in epoch 20 is saved.\n",
      "\n",
      "Epoch 21: Train Loss = 0.010577037969449121, Recall = 0.9995549621717846, Aging Rate = 0.5, Precision = 0.9995549621717846, f1 = 0.9995549621717846\n",
      "Epoch 22: Train Loss = 0.009487116065259291, Recall = 0.9995549621717846, Aging Rate = 0.4997774810858923, Precision = 0, f1 = 0.0\n",
      "Epoch 23: Train Loss = 0.00860695358287853, Recall = 0.9995549621717846, Aging Rate = 0.4997774810858923, Precision = 0, f1 = 0.0\n",
      "Epoch 24: Train Loss = 0.007681185622920473, Recall = 0.9995549621717846, Aging Rate = 0.4997774810858923, Precision = 0, f1 = 0.0\n",
      "Epoch 25: Train Loss = 0.007104577577884695, Recall = 0.9995549621717846, Aging Rate = 0.4997774810858923, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0061283894620991625, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "Model in epoch 25 is saved.\n",
      "\n",
      "Epoch 26: Train Loss = 0.006253905885309498, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 27: Train Loss = 0.005603529993671813, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 28: Train Loss = 0.005196043329158385, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 29: Train Loss = 0.004819144836150716, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 30: Train Loss = 0.00436368781782506, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0039703823028370226, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 31: Train Loss = 0.004262094663204911, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 32: Train Loss = 0.0038456892329224637, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 33: Train Loss = 0.0036934300226958913, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 34: Train Loss = 0.003469182444366651, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 35: Train Loss = 0.0032911420172692988, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.002877808578331463, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 36: Train Loss = 0.003130801997827652, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 37: Train Loss = 0.0029322517448045647, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 38: Train Loss = 0.0028395781987340493, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 39: Train Loss = 0.0027337492455848135, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 40: Train Loss = 0.0025883369472310524, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.002917301888330199, Recall = 1.0, Aging Rate = 0.5002225189141077, precision = 0.9995551601423488\n",
      "\n",
      "Epoch 41: Train Loss = 0.002767856470108178, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 42: Train Loss = 0.002440751648769545, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 43: Train Loss = 0.0022948845596358174, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 44: Train Loss = 0.0023545908769008234, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 45: Train Loss = 0.002334000594206453, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.002295864488586326, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 46: Train Loss = 0.002470563969352711, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 47: Train Loss = 0.0021321226226793406, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 48: Train Loss = 0.002036604060585025, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 49: Train Loss = 0.0019689601385118553, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 50: Train Loss = 0.0019912576981794055, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0017017402093895658, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 51: Train Loss = 0.001987736335040402, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 52: Train Loss = 0.001983907377338232, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 53: Train Loss = 0.0019468892690848723, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 54: Train Loss = 0.0019184503256211502, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 55: Train Loss = 0.0019326097878580228, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.001593437532922912, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 56: Train Loss = 0.0018717760393627296, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 57: Train Loss = 0.0018607740908857845, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58: Train Loss = 0.002020100829811973, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 59: Train Loss = 0.004587911413613629, Recall = 0.9995549621717846, Aging Rate = 0.5, Precision = 0.9995549621717846, f1 = 0.9995549621717846\n",
      "Epoch 60: Train Loss = 0.0019298736329181523, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0013956155662263631, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 61: Train Loss = 0.001557264287392789, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 62: Train Loss = 0.001440981158142819, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 63: Train Loss = 0.0014755751495280655, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 64: Train Loss = 0.0015011122000528458, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 65: Train Loss = 0.001539524024042405, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0016810707761406645, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 66: Train Loss = 0.0018014928560861907, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 67: Train Loss = 0.0017693383987241976, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 68: Train Loss = 0.003398655354437838, Recall = 0.9995549621717846, Aging Rate = 0.5, Precision = 0.9995549621717846, f1 = 0.9995549621717846\n",
      "Epoch 69: Train Loss = 0.0019130711472735411, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 70: Train Loss = 0.0014096488726191045, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.001230234768478723, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 71: Train Loss = 0.0013654297952640521, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 72: Train Loss = 0.001484291478119041, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 73: Train Loss = 0.001616290761870765, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 74: Train Loss = 0.0016380079612521349, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 75: Train Loss = 0.001572331705493923, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.001315439425764873, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Training Finished at epoch 75.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5260b29993104f09b982aeb5b797e0ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss = 0.5423270422297156, Recall = 0.8647085002225189, Aging Rate = 0.6564307966177125, Precision = 0.6586440677966102, f1 = 0.7477390802385991\n",
      "Epoch 2: Train Loss = 0.3375458328735579, Recall = 0.9065420560747663, Aging Rate = 0.5478415665331553, Precision = 0.8273761169780666, f1 = 0.8651518369080484\n",
      "Epoch 3: Train Loss = 0.25161487501384844, Recall = 0.9350244770805518, Aging Rate = 0.5349354695149088, Precision = 0.8739600665557404, f1 = 0.9034616211567406\n",
      "Epoch 4: Train Loss = 0.2045794762554941, Recall = 0.9470404984423676, Aging Rate = 0.5226969292389854, Precision = 0.9059174116645381, f1 = 0.9260226283724977\n",
      "Epoch 5: Train Loss = 0.1614486120664442, Recall = 0.9621717846016912, Aging Rate = 0.5178015131286159, Precision = 0.9290932531155995, f1 = 0.9453432444250108\n",
      "Test Loss = 0.1309501603676788, Recall = 0.9675122385402759, Aging Rate = 0.5015576323987538, precision = 0.9645075421472937\n",
      "Model in epoch 5 is saved.\n",
      "\n",
      "Epoch 6: Train Loss = 0.12068588786991002, Recall = 0.9719626168224299, Aging Rate = 0.5057854917668002, Precision = 0.9608446986361636, f1 = 0.9663716814159293\n",
      "Epoch 7: Train Loss = 0.09638749316507146, Recall = 0.9799732977303071, Aging Rate = 0.5031152647975078, Precision = 0.9739053516143299, f1 = 0.976929902395741\n",
      "Epoch 8: Train Loss = 0.07839962865943424, Recall = 0.9804183355585224, Aging Rate = 0.4995549621717846, Precision = 0.9812917594654789, f1 = 0.9808548530721283\n",
      "Epoch 9: Train Loss = 0.06375397838947239, Recall = 0.9830885625278148, Aging Rate = 0.4986648865153538, Precision = 0.9857206604194556, f1 = 0.9844028520499108\n",
      "Epoch 10: Train Loss = 0.05236922922860425, Recall = 0.9884290164663997, Aging Rate = 0.4991099243435692, Precision = 0.990191707534552, f1 = 0.9893095768374166\n",
      "Test Loss = 0.04447444682774222, Recall = 0.9924343569203382, Aging Rate = 0.5002225189141077, precision = 0.9919928825622776\n",
      "Model in epoch 10 is saved.\n",
      "\n",
      "Epoch 11: Train Loss = 0.04363494448390307, Recall = 0.9893190921228304, Aging Rate = 0.4982198486871384, Precision = 0.9928539526574364, f1 = 0.9910833704859563\n",
      "Epoch 12: Train Loss = 0.03607270581391609, Recall = 0.9946595460614153, Aging Rate = 0.5008900756564308, Precision = 0.9928920479786761, f1 = 0.9937750111160516\n",
      "Epoch 13: Train Loss = 0.030615762258251085, Recall = 0.9951045838896306, Aging Rate = 0.4997774810858923, Precision = 0.9955476402493322, f1 = 0.9953260627643\n",
      "Epoch 14: Train Loss = 0.025794314430271408, Recall = 0.9968847352024922, Aging Rate = 0.5002225189141077, Precision = 0.99644128113879, f1 = 0.996662958843159\n",
      "Epoch 15: Train Loss = 0.022640863262717068, Recall = 0.9973297730307076, Aging Rate = 0.5, Precision = 0.9973297730307076, f1 = 0.9973297730307076\n",
      "Test Loss = 0.018870107507628266, Recall = 0.9991099243435692, Aging Rate = 0.5004450378282154, precision = 0.9982214317474433\n",
      "Model in epoch 15 is saved.\n",
      "\n",
      "Epoch 16: Train Loss = 0.019153803777203302, Recall = 0.9986648865153538, Aging Rate = 0.5004450378282154, Precision = 0.9977767896843042, f1 = 0.998220640569395\n",
      "Epoch 17: Train Loss = 0.016445691889615314, Recall = 0.9995549621717846, Aging Rate = 0.5008900756564308, Precision = 0.9977787649933363, f1 = 0.9986660738105826\n",
      "Epoch 18: Train Loss = 0.014225869513318626, Recall = 1.0, Aging Rate = 0.5008900756564308, Precision = 0.998223011994669, f1 = 0.9991107158737216\n",
      "Epoch 19: Train Loss = 0.012255510227637831, Recall = 1.0, Aging Rate = 0.5004450378282154, Precision = 0.9991107158737217, f1 = 0.9995551601423488\n",
      "Epoch 20: Train Loss = 0.011018655822841549, Recall = 1.0, Aging Rate = 0.5002225189141077, Precision = 0.9995551601423488, f1 = 0.999777530589544\n",
      "Test Loss = 0.009329703398145036, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "Model in epoch 20 is saved.\n",
      "\n",
      "Epoch 21: Train Loss = 0.0096701127852089, Recall = 1.0, Aging Rate = 0.5002225189141077, Precision = 0.9995551601423488, f1 = 0.999777530589544\n",
      "Epoch 22: Train Loss = 0.008602492177621041, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 23: Train Loss = 0.007769480056672771, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 24: Train Loss = 0.006876426554957681, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 25: Train Loss = 0.006293270153353678, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.005642848015975491, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 26: Train Loss = 0.005768653162239882, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 27: Train Loss = 0.005150169665909869, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 28: Train Loss = 0.0047789277724588465, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 29: Train Loss = 0.004464661194265227, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 30: Train Loss = 0.004175342472488144, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0037073306660580273, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 31: Train Loss = 0.0039277334167432615, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 32: Train Loss = 0.0035366512554012566, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 33: Train Loss = 0.003405153790022971, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 34: Train Loss = 0.0030435938532656936, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 35: Train Loss = 0.0029198047301141794, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.002627321233851466, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 36: Train Loss = 0.002819830679764095, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 37: Train Loss = 0.0026206984219394546, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 38: Train Loss = 0.002572590879846031, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 39: Train Loss = 0.0024296263072011363, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 40: Train Loss = 0.0023319508700495196, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.002073259954661973, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 41: Train Loss = 0.002467827978699883, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 42: Train Loss = 0.0021969161239777193, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 43: Train Loss = 0.002066077124176138, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 44: Train Loss = 0.0021992025883669597, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 45: Train Loss = 0.002022180339505106, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0017618080058135507, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 46: Train Loss = 0.0019478165441158286, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 47: Train Loss = 0.0019721043465885323, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 48: Train Loss = 0.0026548731076652555, Recall = 1.0, Aging Rate = 0.5002225189141077, Precision = 0.9995551601423488, f1 = 0.999777530589544\n",
      "Epoch 49: Train Loss = 0.0022022230104051287, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 50: Train Loss = 0.0019402329519417586, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0015866105117502281, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 51: Train Loss = 0.0017256576781445874, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 52: Train Loss = 0.0016477572534591438, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 53: Train Loss = 0.001705864669537917, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 54: Train Loss = 0.0016325662222068755, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 55: Train Loss = 0.0017557832558316472, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0016450080561563937, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 56: Train Loss = 0.00169321275395965, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 57: Train Loss = 0.0016651498497818966, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 58: Train Loss = 0.001673165858716177, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59: Train Loss = 0.0017224584432471333, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 60: Train Loss = 0.0017416017029714627, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0013730333023590608, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 61: Train Loss = 0.0015664502456502406, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 62: Train Loss = 0.0018344352137451576, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 63: Train Loss = 0.002075394068736439, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 64: Train Loss = 0.001768346577743918, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 65: Train Loss = 0.0014450571622656393, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0013787947808262615, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 66: Train Loss = 0.0015057787351172647, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 67: Train Loss = 0.0015318049570735384, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 68: Train Loss = 0.001623352540472069, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 69: Train Loss = 0.0016598272969710844, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 70: Train Loss = 0.0016229155181569737, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.001385393790493694, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Training Finished at epoch 70.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ca11226b90349979ac280dd5580569f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss = 0.5396456483288983, Recall = 0.8744993324432577, Aging Rate = 0.670894526034713, Precision = 0.6517412935323383, f1 = 0.7468643101482327\n",
      "Epoch 2: Train Loss = 0.33052504835231705, Recall = 0.9052069425901201, Aging Rate = 0.5469514908767246, Precision = 0.8275020341741253, f1 = 0.8646121147715196\n",
      "Epoch 3: Train Loss = 0.24633707288481896, Recall = 0.936359590565198, Aging Rate = 0.5304850912327548, Precision = 0.8825503355704698, f1 = 0.9086590369250701\n",
      "Epoch 4: Train Loss = 0.19464675680260474, Recall = 0.9479305740987984, Aging Rate = 0.5166889185580774, Precision = 0.917312661498708, f1 = 0.9323703217334209\n",
      "Epoch 5: Train Loss = 0.16133429445276593, Recall = 0.9621717846016912, Aging Rate = 0.5129060970182465, Precision = 0.9379609544468547, f1 = 0.9499121265377856\n",
      "Test Loss = 0.12847981178858675, Recall = 0.9746328437917223, Aging Rate = 0.5106809078771696, precision = 0.954248366013072\n",
      "Model in epoch 5 is saved.\n",
      "\n",
      "Epoch 6: Train Loss = 0.1194225031605656, Recall = 0.9710725411659991, Aging Rate = 0.5037828215398309, Precision = 0.9637809187279152, f1 = 0.9674129904677454\n",
      "Epoch 7: Train Loss = 0.09779979106209571, Recall = 0.9737427681352915, Aging Rate = 0.4982198486871384, Precision = 0.9772219740955784, f1 = 0.9754792688363798\n",
      "Epoch 8: Train Loss = 0.08119435664755427, Recall = 0.9795282599020917, Aging Rate = 0.5002225189141077, Precision = 0.9790925266903915, f1 = 0.9793103448275862\n",
      "Epoch 9: Train Loss = 0.06839897521387274, Recall = 0.9830885625278148, Aging Rate = 0.5008900756564308, Precision = 0.9813416259440249, f1 = 0.9822143174744331\n",
      "Epoch 10: Train Loss = 0.05873200004074008, Recall = 0.9848687138406764, Aging Rate = 0.4993324432576769, Precision = 0.9861853832442068, f1 = 0.9855266087731017\n",
      "Test Loss = 0.04947142619647925, Recall = 0.9835336003560302, Aging Rate = 0.49421450823319985, precision = 0.995047276001801\n",
      "Model in epoch 10 is saved.\n",
      "\n",
      "Epoch 11: Train Loss = 0.04816567631538677, Recall = 0.9875389408099688, Aging Rate = 0.4984423676012461, Precision = 0.990625, f1 = 0.9890795631825272\n",
      "Epoch 12: Train Loss = 0.04079076470943971, Recall = 0.9906542056074766, Aging Rate = 0.49888740542946153, Precision = 0.9928635147190009, f1 = 0.9917576297616395\n",
      "Epoch 13: Train Loss = 0.03458822630660822, Recall = 0.9937694704049844, Aging Rate = 0.4991099243435692, Precision = 0.9955416852429781, f1 = 0.9946547884187082\n",
      "Epoch 14: Train Loss = 0.029379535292353584, Recall = 0.9942145082331998, Aging Rate = 0.49888740542946153, Precision = 0.9964317573595004, f1 = 0.9953218979728223\n",
      "Epoch 15: Train Loss = 0.025767772526881883, Recall = 0.9951045838896306, Aging Rate = 0.4986648865153538, Precision = 0.99776885319054, f1 = 0.9964349376114082\n",
      "Test Loss = 0.02177412106154439, Recall = 0.9986648865153538, Aging Rate = 0.5008900756564308, precision = 0.9968902709906708\n",
      "Model in epoch 15 is saved.\n",
      "\n",
      "Epoch 16: Train Loss = 0.0218278396925232, Recall = 0.9964396973742768, Aging Rate = 0.4991099243435692, Precision = 0.9982166740971913, f1 = 0.9973273942093541\n",
      "Epoch 17: Train Loss = 0.019122427782855354, Recall = 0.9977748108589231, Aging Rate = 0.5002225189141077, Precision = 0.9973309608540926, f1 = 0.9975528364849834\n",
      "Epoch 18: Train Loss = 0.0170054038523182, Recall = 0.9986648865153538, Aging Rate = 0.5004450378282154, Precision = 0.9977767896843042, f1 = 0.998220640569395\n",
      "Epoch 19: Train Loss = 0.015747788211336575, Recall = 0.9991099243435692, Aging Rate = 0.5004450378282154, Precision = 0.9982214317474433, f1 = 0.9986654804270463\n",
      "Epoch 20: Train Loss = 0.012683910727633547, Recall = 0.9995549621717846, Aging Rate = 0.5002225189141077, Precision = 0.9991103202846975, f1 = 0.9993325917686319\n",
      "Test Loss = 0.010781713116675296, Recall = 1.0, Aging Rate = 0.5004450378282154, precision = 0.9991107158737217\n",
      "Model in epoch 20 is saved.\n",
      "\n",
      "Epoch 21: Train Loss = 0.011322357634627056, Recall = 0.9995549621717846, Aging Rate = 0.5002225189141077, Precision = 0.9991103202846975, f1 = 0.9993325917686319\n",
      "Epoch 22: Train Loss = 0.010153447686929568, Recall = 0.9995549621717846, Aging Rate = 0.5, Precision = 0.9995549621717846, f1 = 0.9995549621717846\n",
      "Epoch 23: Train Loss = 0.008995060531984522, Recall = 0.9995549621717846, Aging Rate = 0.4997774810858923, Precision = 0, f1 = 0.0\n",
      "Epoch 24: Train Loss = 0.008031048794978717, Recall = 1.0, Aging Rate = 0.5002225189141077, Precision = 0.9995551601423488, f1 = 0.999777530589544\n",
      "Epoch 25: Train Loss = 0.00732664798867599, Recall = 1.0, Aging Rate = 0.5002225189141077, Precision = 0.9995551601423488, f1 = 0.999777530589544\n",
      "Test Loss = 0.006223085122311452, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "Model in epoch 25 is saved.\n",
      "\n",
      "Epoch 26: Train Loss = 0.006714760224302981, Recall = 1.0, Aging Rate = 0.5002225189141077, Precision = 0.9995551601423488, f1 = 0.999777530589544\n",
      "Epoch 27: Train Loss = 0.006215431775444307, Recall = 0.9995549621717846, Aging Rate = 0.5, Precision = 0.9995549621717846, f1 = 0.9995549621717846\n",
      "Epoch 28: Train Loss = 0.005597735534231027, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 29: Train Loss = 0.004877887766217232, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 30: Train Loss = 0.00479160641719188, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.004178648493393616, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 31: Train Loss = 0.004762452101549627, Recall = 0.9995549621717846, Aging Rate = 0.5, Precision = 0.9995549621717846, f1 = 0.9995549621717846\n",
      "Epoch 32: Train Loss = 0.004032553189714295, Recall = 0.9995549621717846, Aging Rate = 0.4997774810858923, Precision = 0, f1 = 0.0\n",
      "Epoch 33: Train Loss = 0.00415010705323327, Recall = 0.9995549621717846, Aging Rate = 0.4997774810858923, Precision = 0, f1 = 0.0\n",
      "Epoch 34: Train Loss = 0.003674749893326566, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 35: Train Loss = 0.0033859766095057694, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.003043242297800524, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 36: Train Loss = 0.003075390862459321, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 37: Train Loss = 0.0031567971627457993, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 38: Train Loss = 0.002887359475049646, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 39: Train Loss = 0.0029082586265549984, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 40: Train Loss = 0.002567471404368009, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.002453864061550917, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 41: Train Loss = 0.0026443896779536034, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 42: Train Loss = 0.0024167069612782985, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 43: Train Loss = 0.002515429971054939, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 44: Train Loss = 0.0023224896371686226, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 45: Train Loss = 0.0022636147766798057, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.00218378197520716, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 46: Train Loss = 0.0021733768601600507, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 47: Train Loss = 0.0020699677688911437, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 48: Train Loss = 0.0020670413052473378, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 49: Train Loss = 0.0020428536826405637, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 50: Train Loss = 0.0023661787562821645, Recall = 1.0, Aging Rate = 0.5002225189141077, Precision = 0.9995551601423488, f1 = 0.999777530589544\n",
      "Test Loss = 0.0022613178480840957, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 51: Train Loss = 0.0023706790437390524, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 52: Train Loss = 0.002042991064455108, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 53: Train Loss = 0.0020087399508789162, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 54: Train Loss = 0.0017373413992502727, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 55: Train Loss = 0.0017254106954881373, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0014676869437380345, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 56: Train Loss = 0.0017918531520666847, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 57: Train Loss = 0.0017866197740141025, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 58: Train Loss = 0.0020022542730556542, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 59: Train Loss = 0.002051051094053329, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 60: Train Loss = 0.001695836542092776, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0013744905057117014, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 61: Train Loss = 0.001599683828126974, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 62: Train Loss = 0.0016901981633991288, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 63: Train Loss = 0.0024527588682116555, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 64: Train Loss = 0.001657249448411863, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 65: Train Loss = 0.0015688284291615557, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.001349061550776643, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 66: Train Loss = 0.0014928952932961263, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 67: Train Loss = 0.0019902660192600125, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 68: Train Loss = 0.0021924105618887015, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 69: Train Loss = 0.0018389418097001528, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 70: Train Loss = 0.0015604904433722726, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.001219617760681987, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 71: Train Loss = 0.0013771964035348815, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 72: Train Loss = 0.0014617257011377903, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 73: Train Loss = 0.0017144105237177944, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 74: Train Loss = 0.002074467067594935, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 75: Train Loss = 0.0019464741154682865, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0016560321814153868, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Training Finished at epoch 75.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a312dcc031ed411582183ee63538b5bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss = 0.5378934090329532, Recall = 0.9167779261237206, Aging Rate = 0.7222963951935915, Precision = 0.6346272335181762, f1 = 0.7500455124704168\n",
      "Epoch 2: Train Loss = 0.32534989023611816, Recall = 0.9154428126390743, Aging Rate = 0.5520694259012016, Precision = 0.8291011688835147, f1 = 0.8701353637901861\n",
      "Epoch 3: Train Loss = 0.23725705329555907, Recall = 0.9394748553627058, Aging Rate = 0.5260347129506008, Precision = 0.8929780033840947, f1 = 0.9156365213619605\n",
      "Epoch 4: Train Loss = 0.183556148047096, Recall = 0.9546061415220294, Aging Rate = 0.5175789942145083, Precision = 0.9221840068787618, f1 = 0.9381150229608571\n",
      "Epoch 5: Train Loss = 0.15429964999808807, Recall = 0.9621717846016912, Aging Rate = 0.5124610591900312, Precision = 0.9387755102040817, f1 = 0.9503296703296703\n",
      "Test Loss = 0.11742773649755668, Recall = 0.9746328437917223, Aging Rate = 0.5071206052514464, precision = 0.9609477841158403\n",
      "Model in epoch 5 is saved.\n",
      "\n",
      "Epoch 6: Train Loss = 0.11051980063524786, Recall = 0.9728526924788607, Aging Rate = 0.5022251891410769, Precision = 0.9685423128046079, f1 = 0.9706927175843694\n",
      "Epoch 7: Train Loss = 0.08856306560619386, Recall = 0.9764129951045839, Aging Rate = 0.4997774810858923, Precision = 0.9768477292965272, f1 = 0.9766303138215001\n",
      "Epoch 8: Train Loss = 0.07407861190852612, Recall = 0.9817534490431686, Aging Rate = 0.5015576323987538, Precision = 0.9787045252883763, f1 = 0.9802266163074873\n",
      "Epoch 9: Train Loss = 0.05888118463662475, Recall = 0.9853137516688919, Aging Rate = 0.4997774810858923, Precision = 0.9857524487978628, f1 = 0.9855330514133096\n",
      "Epoch 10: Train Loss = 0.05037880532358971, Recall = 0.9875389408099688, Aging Rate = 0.49888740542946153, Precision = 0.9897413024085637, f1 = 0.9886388950768545\n",
      "Test Loss = 0.043150442510239806, Recall = 0.9933244325767691, Aging Rate = 0.5022251891410769, precision = 0.9889233495790872\n",
      "Model in epoch 10 is saved.\n",
      "\n",
      "Epoch 11: Train Loss = 0.041749013782635125, Recall = 0.9902091677792613, Aging Rate = 0.4993324432576769, Precision = 0.9915329768270945, f1 = 0.9908706301491873\n",
      "Epoch 12: Train Loss = 0.03455524697475397, Recall = 0.9928793947485536, Aging Rate = 0.4995549621717846, Precision = 0.9937639198218263, f1 = 0.9933214603739982\n",
      "Epoch 13: Train Loss = 0.029370879060594993, Recall = 0.995549621717846, Aging Rate = 0.4997774810858923, Precision = 0.9959928762243989, f1 = 0.9957711996438905\n",
      "Epoch 14: Train Loss = 0.02472759490235015, Recall = 0.9959946595460614, Aging Rate = 0.5, Precision = 0.9959946595460614, f1 = 0.9959946595460614\n",
      "Epoch 15: Train Loss = 0.02151659683419311, Recall = 0.9982198486871384, Aging Rate = 0.5002225189141077, Precision = 0.9977758007117438, f1 = 0.9979977753058954\n",
      "Test Loss = 0.018344739156899104, Recall = 0.9995549621717846, Aging Rate = 0.5004450378282154, precision = 0.9986660738105825\n",
      "Model in epoch 15 is saved.\n",
      "\n",
      "Epoch 16: Train Loss = 0.018757304985533768, Recall = 0.9986648865153538, Aging Rate = 0.5004450378282154, Precision = 0.9977767896843042, f1 = 0.998220640569395\n",
      "Epoch 17: Train Loss = 0.015725869286998536, Recall = 0.9995549621717846, Aging Rate = 0.5002225189141077, Precision = 0.9991103202846975, f1 = 0.9993325917686319\n",
      "Epoch 18: Train Loss = 0.013758811060194975, Recall = 1.0, Aging Rate = 0.5002225189141077, Precision = 0.9995551601423488, f1 = 0.999777530589544\n",
      "Epoch 19: Train Loss = 0.011948318840520524, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 20: Train Loss = 0.010729612629242245, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.009157685838593315, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "Model in epoch 20 is saved.\n",
      "\n",
      "Epoch 21: Train Loss = 0.009417348422417206, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 22: Train Loss = 0.0084862889095927, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 23: Train Loss = 0.0075966320989108846, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 24: Train Loss = 0.006880518475909683, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 25: Train Loss = 0.006364633120525119, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0061206564524397085, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 26: Train Loss = 0.005745609006465218, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 27: Train Loss = 0.005117902273588251, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 28: Train Loss = 0.0047943399270766835, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 29: Train Loss = 0.004228342442516723, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 30: Train Loss = 0.003973936707255546, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0034953468688732592, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 31: Train Loss = 0.0036982481950118104, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 32: Train Loss = 0.003502665210679392, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 33: Train Loss = 0.0033583929408387237, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 34: Train Loss = 0.0032716715094642935, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 35: Train Loss = 0.0029138103306739463, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.002656947238214105, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 36: Train Loss = 0.002820482883730039, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 37: Train Loss = 0.0027253055126660324, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 38: Train Loss = 0.002624550863725772, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 39: Train Loss = 0.0024045637206354313, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 40: Train Loss = 0.002346573681224504, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.00209075783623501, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 41: Train Loss = 0.002359387921364203, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 42: Train Loss = 0.002273407190686658, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 43: Train Loss = 0.0023890345551228565, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 44: Train Loss = 0.002241816611763241, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 45: Train Loss = 0.0020439014925518247, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0019422790957187872, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 46: Train Loss = 0.0023314254207386954, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 47: Train Loss = 0.0019896782417842787, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 48: Train Loss = 0.001837669487219448, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 49: Train Loss = 0.0018324658097877509, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 50: Train Loss = 0.002001205125585709, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0015970266296772406, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 51: Train Loss = 0.001708328854207664, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 52: Train Loss = 0.0024018311302347957, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 53: Train Loss = 0.0018155514844434197, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 54: Train Loss = 0.0019022501481775298, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 55: Train Loss = 0.001716075563261598, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0016648287250720251, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 56: Train Loss = 0.0018318085596035847, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 57: Train Loss = 0.0016512315558467737, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 58: Train Loss = 0.001854525064739917, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 59: Train Loss = 0.00161205095102829, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 60: Train Loss = 0.0016572307151038503, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0015179779560130684, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 61: Train Loss = 0.0016509009433788395, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 62: Train Loss = 0.0017486939286091127, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 63: Train Loss = 0.0015003611651776855, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 64: Train Loss = 0.0017126746619518965, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 65: Train Loss = 0.002005686504748937, Recall = 1.0, Aging Rate = 0.5002225189141077, Precision = 0.9995551601423488, f1 = 0.999777530589544\n",
      "Test Loss = 0.0025791413826112765, Recall = 0.9995549621717846, Aging Rate = 0.4997774810858923, precision = 1.0\n",
      "\n",
      "Epoch 66: Train Loss = 0.0018868124277032928, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 67: Train Loss = 0.0028692372428219307, Recall = 1.0, Aging Rate = 0.5002225189141077, Precision = 0.9995551601423488, f1 = 0.999777530589544\n",
      "Epoch 68: Train Loss = 0.0018208172762622244, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 69: Train Loss = 0.0020496141297401196, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 70: Train Loss = 0.0016127588885316553, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0011756611145737705, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Training Finished at epoch 70.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "59d945ce0ca740e7b6e45a9f6cdf62bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss = 0.6073375392002567, Recall = 0.9359430604982206, Aging Rate = 0.8176156583629893, Precision = 0.5723612622415669, f1 = 0.7103308575286968\n",
      "Epoch 2: Train Loss = 0.42224202058493454, Recall = 0.8901245551601423, Aging Rate = 0.5729537366548043, Precision = 0.7767857142857143, f1 = 0.8296019900497513\n",
      "Epoch 3: Train Loss = 0.32651113122171355, Recall = 0.9172597864768683, Aging Rate = 0.5518238434163701, Precision = 0.8311164852881903, f1 = 0.8720659758934235\n",
      "Epoch 4: Train Loss = 0.27324912598973067, Recall = 0.9332740213523132, Aging Rate = 0.5415925266903915, Precision = 0.8616016427104722, f1 = 0.8960068332265642\n",
      "Epoch 5: Train Loss = 0.23265908616081252, Recall = 0.9426156583629893, Aging Rate = 0.5322508896797153, Precision = 0.885499373171751, f1 = 0.9131652661064426\n",
      "Test Loss = 0.19937598259847783, Recall = 0.9426156583629893, Aging Rate = 0.5102313167259787, precision = 0.9237140366172624\n",
      "Model in epoch 5 is saved.\n",
      "\n",
      "Epoch 6: Train Loss = 0.18868367114101017, Recall = 0.9501779359430605, Aging Rate = 0.5197953736654805, Precision = 0.9139922978177151, f1 = 0.9317339149400218\n",
      "Epoch 7: Train Loss = 0.1576968675406378, Recall = 0.9648576512455516, Aging Rate = 0.5124555160142349, Precision = 0.94140625, f1 = 0.9529876977152899\n",
      "Epoch 8: Train Loss = 0.13598135225077115, Recall = 0.9701957295373665, Aging Rate = 0.5097864768683275, Precision = 0.9515706806282722, f1 = 0.9607929515418503\n",
      "Epoch 9: Train Loss = 0.11593754337669691, Recall = 0.9777580071174378, Aging Rate = 0.5102313167259787, Precision = 0.958151700087184, f1 = 0.9678555702333775\n",
      "Epoch 10: Train Loss = 0.09973235470756517, Recall = 0.9795373665480427, Aging Rate = 0.5008896797153025, Precision = 0.977797513321492, f1 = 0.9786666666666667\n",
      "Test Loss = 0.08969147368151946, Recall = 0.9870996441281139, Aging Rate = 0.5073398576512456, precision = 0.972818939061815\n",
      "Model in epoch 10 is saved.\n",
      "\n",
      "Epoch 11: Train Loss = 0.08684323104993304, Recall = 0.9808718861209964, Aging Rate = 0.5013345195729537, Precision = 0.9782608695652174, f1 = 0.9795646379386939\n",
      "Epoch 12: Train Loss = 0.07753299989363052, Recall = 0.9839857651245552, Aging Rate = 0.5013345195729537, Precision = 0.9813664596273292, f1 = 0.982674366948023\n",
      "Epoch 13: Train Loss = 0.06894602442286192, Recall = 0.9848754448398577, Aging Rate = 0.5, Precision = 0.9848754448398577, f1 = 0.9848754448398577\n",
      "Epoch 14: Train Loss = 0.06142065350589379, Recall = 0.9875444839857651, Aging Rate = 0.5002224199288257, Precision = 0.987105380168964, f1 = 0.9873248832555037\n",
      "Epoch 15: Train Loss = 0.05565310563905383, Recall = 0.9893238434163701, Aging Rate = 0.5004448398576512, Precision = 0.9884444444444445, f1 = 0.9888839484215207\n",
      "Test Loss = 0.05018967360894451, Recall = 0.9915480427046264, Aging Rate = 0.4991103202846975, precision = 0.9933155080213903\n",
      "Model in epoch 15 is saved.\n",
      "\n",
      "Epoch 16: Train Loss = 0.050963973367977825, Recall = 0.9919928825622776, Aging Rate = 0.5011120996441281, Precision = 0.9897913892587661, f1 = 0.9908909131304154\n",
      "Epoch 17: Train Loss = 0.046653372086452, Recall = 0.9942170818505338, Aging Rate = 0.5011120996441281, Precision = 0.9920106524633822, f1 = 0.9931126416351923\n",
      "Epoch 18: Train Loss = 0.0426692701345873, Recall = 0.9955516014234875, Aging Rate = 0.5008896797153025, Precision = 0.9937833037300178, f1 = 0.9946666666666666\n",
      "Epoch 19: Train Loss = 0.039349918455893036, Recall = 0.9968861209964412, Aging Rate = 0.5006672597864769, Precision = 0.9955575299866726, f1 = 0.9962213825294509\n",
      "Epoch 20: Train Loss = 0.03775047115795977, Recall = 0.9959964412811388, Aging Rate = 0.5004448398576512, Precision = 0.9951111111111111, f1 = 0.9955535793686083\n",
      "Test Loss = 0.033228425978553675, Recall = 0.9977758007117438, Aging Rate = 0.5002224199288257, precision = 0.997332147621165\n",
      "Model in epoch 20 is saved.\n",
      "\n",
      "Epoch 21: Train Loss = 0.034165707002543046, Recall = 0.99644128113879, Aging Rate = 0.5002224199288257, Precision = 0.9959982214317474, f1 = 0.9962197020235714\n",
      "Epoch 22: Train Loss = 0.032983946968599145, Recall = 0.9968861209964412, Aging Rate = 0.4997775800711744, Precision = 0.9973297730307076, f1 = 0.9971078976640712\n",
      "Epoch 23: Train Loss = 0.030452629677235443, Recall = 0.9973309608540926, Aging Rate = 0.4997775800711744, Precision = 0.9977748108589231, f1 = 0.9975528364849834\n",
      "Epoch 24: Train Loss = 0.028775815411182484, Recall = 0.9977758007117438, Aging Rate = 0.49955516014234874, Precision = 0.9986642920747997, f1 = 0.9982198486871383\n",
      "Epoch 25: Train Loss = 0.027335195487292213, Recall = 0.9991103202846975, Aging Rate = 0.5006672597864769, Precision = 0.9977787649933363, f1 = 0.9984440986885974\n",
      "Test Loss = 0.02495825565105231, Recall = 0.998220640569395, Aging Rate = 0.49955516014234874, precision = 0.9991095280498664\n",
      "Model in epoch 25 is saved.\n",
      "\n",
      "Epoch 26: Train Loss = 0.026488533369480927, Recall = 0.9977758007117438, Aging Rate = 0.5, Precision = 0.9977758007117438, f1 = 0.9977758007117438\n",
      "Epoch 27: Train Loss = 0.025207054360481342, Recall = 0.9986654804270463, Aging Rate = 0.5002224199288257, Precision = 0.9982214317474433, f1 = 0.9984434067155882\n",
      "Epoch 28: Train Loss = 0.025265493307567576, Recall = 0.9977758007117438, Aging Rate = 0.4991103202846975, Precision = 0.999554367201426, f1 = 0.9986642920747996\n",
      "Epoch 29: Train Loss = 0.02363798298021228, Recall = 0.9991103202846975, Aging Rate = 0.5, Precision = 0.9991103202846975, f1 = 0.9991103202846975\n",
      "Epoch 30: Train Loss = 0.022303932952923284, Recall = 0.9991103202846975, Aging Rate = 0.4997775800711744, Precision = 0.9995549621717846, f1 = 0.9993325917686319\n",
      "Test Loss = 0.021072942856367797, Recall = 0.9991103202846975, Aging Rate = 0.5, precision = 0.9991103202846975\n",
      "Model in epoch 30 is saved.\n",
      "\n",
      "Epoch 31: Train Loss = 0.02208536966733661, Recall = 0.998220640569395, Aging Rate = 0.5, Precision = 0.998220640569395, f1 = 0.998220640569395\n",
      "Epoch 32: Train Loss = 0.021039340678217996, Recall = 0.9995551601423488, Aging Rate = 0.5, Precision = 0.9995551601423488, f1 = 0.9995551601423488\n",
      "Epoch 33: Train Loss = 0.02040853952239947, Recall = 0.9991103202846975, Aging Rate = 0.49955516014234874, Precision = 0, f1 = 0.0\n",
      "Epoch 34: Train Loss = 0.01999626237753235, Recall = 0.9995551601423488, Aging Rate = 0.4997775800711744, Precision = 0, f1 = 0.0\n",
      "Epoch 35: Train Loss = 0.02000475826663267, Recall = 0.9991103202846975, Aging Rate = 0.49955516014234874, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.018091718576768962, Recall = 0.9995551601423488, Aging Rate = 0.4997775800711744, precision = 1.0\n",
      "Model in epoch 35 is saved.\n",
      "\n",
      "Epoch 36: Train Loss = 0.019279818444966845, Recall = 0.9991103202846975, Aging Rate = 0.49955516014234874, Precision = 0, f1 = 0.0\n",
      "Epoch 37: Train Loss = 0.01897324649849078, Recall = 0.9991103202846975, Aging Rate = 0.49955516014234874, Precision = 0, f1 = 0.0\n",
      "Epoch 38: Train Loss = 0.01837147813409673, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 39: Train Loss = 0.018227835427770834, Recall = 0.9991103202846975, Aging Rate = 0.49955516014234874, Precision = 0, f1 = 0.0\n",
      "Epoch 40: Train Loss = 0.017701176266944917, Recall = 0.9995551601423488, Aging Rate = 0.4997775800711744, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.016529621145426165, Recall = 0.9995551601423488, Aging Rate = 0.4997775800711744, precision = 1.0\n",
      "\n",
      "Epoch 41: Train Loss = 0.017716333472246167, Recall = 0.9995551601423488, Aging Rate = 0.4997775800711744, Precision = 0, f1 = 0.0\n",
      "Epoch 42: Train Loss = 0.017636511763193218, Recall = 0.9991103202846975, Aging Rate = 0.49955516014234874, Precision = 0, f1 = 0.0\n",
      "Epoch 43: Train Loss = 0.0173507749411241, Recall = 0.9995551601423488, Aging Rate = 0.4997775800711744, Precision = 0, f1 = 0.0\n",
      "Epoch 44: Train Loss = 0.017029707167576003, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 45: Train Loss = 0.016980245586789587, Recall = 0.9986654804270463, Aging Rate = 0.49933274021352314, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.01591098856419537, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "Model in epoch 45 is saved.\n",
      "\n",
      "Epoch 46: Train Loss = 0.0169912304106132, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 47: Train Loss = 0.016504245409178563, Recall = 0.9991103202846975, Aging Rate = 0.49955516014234874, Precision = 0, f1 = 0.0\n",
      "Epoch 48: Train Loss = 0.01654357345463224, Recall = 0.9995551601423488, Aging Rate = 0.4997775800711744, Precision = 0, f1 = 0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49: Train Loss = 0.016684373118168942, Recall = 0.9995551601423488, Aging Rate = 0.4997775800711744, Precision = 0, f1 = 0.0\n",
      "Epoch 50: Train Loss = 0.016260105394012563, Recall = 0.9995551601423488, Aging Rate = 0.5, Precision = 0.9995551601423488, f1 = 0.9995551601423488\n",
      "Test Loss = 0.014550211239486827, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 51: Train Loss = 0.016234167125672633, Recall = 0.9995551601423488, Aging Rate = 0.5, Precision = 0.9995551601423488, f1 = 0.9995551601423488\n",
      "Epoch 52: Train Loss = 0.016082856545615875, Recall = 1.0, Aging Rate = 0.5002224199288257, Precision = 0.9995553579368608, f1 = 0.9997776295307983\n",
      "Epoch 53: Train Loss = 0.016242196869595618, Recall = 1.0, Aging Rate = 0.5002224199288257, Precision = 0.9995553579368608, f1 = 0.9997776295307983\n",
      "Epoch 54: Train Loss = 0.015957008896468478, Recall = 0.9995551601423488, Aging Rate = 0.5, Precision = 0.9995551601423488, f1 = 0.9995551601423488\n",
      "Epoch 55: Train Loss = 0.015617010959182134, Recall = 0.9995551601423488, Aging Rate = 0.4997775800711744, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.014322956321343408, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 56: Train Loss = 0.015569451672697831, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 57: Train Loss = 0.015528035860548453, Recall = 0.9995551601423488, Aging Rate = 0.5, Precision = 0.9995551601423488, f1 = 0.9995551601423488\n",
      "Epoch 58: Train Loss = 0.015614153434492621, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 59: Train Loss = 0.01533592986672109, Recall = 0.9995551601423488, Aging Rate = 0.4997775800711744, Precision = 0, f1 = 0.0\n",
      "Epoch 60: Train Loss = 0.015326977034639633, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.014297742118190616, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 61: Train Loss = 0.015488726040514126, Recall = 0.9995551601423488, Aging Rate = 0.4997775800711744, Precision = 0, f1 = 0.0\n",
      "Epoch 62: Train Loss = 0.01585396915488608, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 63: Train Loss = 0.01629223043490135, Recall = 0.9991103202846975, Aging Rate = 0.49955516014234874, Precision = 0, f1 = 0.0\n",
      "Epoch 64: Train Loss = 0.015207548678796274, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 65: Train Loss = 0.015247362152113185, Recall = 1.0, Aging Rate = 0.5002224199288257, Precision = 0.9995553579368608, f1 = 0.9997776295307983\n",
      "Test Loss = 0.014092562282689949, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 66: Train Loss = 0.015302434924897138, Recall = 0.9995551601423488, Aging Rate = 0.4997775800711744, Precision = 0, f1 = 0.0\n",
      "Epoch 67: Train Loss = 0.015466543695031006, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 68: Train Loss = 0.014792246459005566, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 69: Train Loss = 0.015653110347900314, Recall = 0.9995551601423488, Aging Rate = 0.5, Precision = 0.9995551601423488, f1 = 0.9995551601423488\n",
      "Epoch 70: Train Loss = 0.015100928759235504, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.013495528944552582, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 71: Train Loss = 0.014803497405769138, Recall = 0.9995551601423488, Aging Rate = 0.4997775800711744, Precision = 0, f1 = 0.0\n",
      "Epoch 72: Train Loss = 0.015377620201942336, Recall = 1.0, Aging Rate = 0.5002224199288257, Precision = 0.9995553579368608, f1 = 0.9997776295307983\n",
      "Epoch 73: Train Loss = 0.015008182162120673, Recall = 0.9995551601423488, Aging Rate = 0.4997775800711744, Precision = 0, f1 = 0.0\n",
      "Epoch 74: Train Loss = 0.015093414311784441, Recall = 0.9995551601423488, Aging Rate = 0.5, Precision = 0.9995551601423488, f1 = 0.9995551601423488\n",
      "Epoch 75: Train Loss = 0.01490444237916495, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.013948226770140841, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 76: Train Loss = 0.014821133940908195, Recall = 0.9991103202846975, Aging Rate = 0.49955516014234874, Precision = 0, f1 = 0.0\n",
      "Epoch 77: Train Loss = 0.01512051762820775, Recall = 0.9995551601423488, Aging Rate = 0.4997775800711744, Precision = 0, f1 = 0.0\n",
      "Epoch 78: Train Loss = 0.015052238671486912, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 79: Train Loss = 0.015250438519378998, Recall = 0.9995551601423488, Aging Rate = 0.4997775800711744, Precision = 0, f1 = 0.0\n",
      "Epoch 80: Train Loss = 0.014932125428976538, Recall = 1.0, Aging Rate = 0.5002224199288257, Precision = 0.9995553579368608, f1 = 0.9997776295307983\n",
      "Test Loss = 0.014624385975195208, Recall = 1.0, Aging Rate = 0.5002224199288257, precision = 0.9995553579368608\n",
      "\n",
      "Epoch 81: Train Loss = 0.01574167825639566, Recall = 0.9995551601423488, Aging Rate = 0.4997775800711744, Precision = 0, f1 = 0.0\n",
      "Epoch 82: Train Loss = 0.014964344463844741, Recall = 0.9995551601423488, Aging Rate = 0.4997775800711744, Precision = 0, f1 = 0.0\n",
      "Epoch 83: Train Loss = 0.014708626027686316, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 84: Train Loss = 0.015132024851080787, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 85: Train Loss = 0.014995834541596552, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.013543921337194502, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 86: Train Loss = 0.014570522973864105, Recall = 0.9995551601423488, Aging Rate = 0.4997775800711744, Precision = 0, f1 = 0.0\n",
      "Epoch 87: Train Loss = 0.015019221900833034, Recall = 1.0, Aging Rate = 0.5002224199288257, Precision = 0.9995553579368608, f1 = 0.9997776295307983\n",
      "Epoch 88: Train Loss = 0.015887446509296358, Recall = 0.9991103202846975, Aging Rate = 0.4997775800711744, Precision = 0.9995549621717846, f1 = 0.9993325917686319\n",
      "Epoch 89: Train Loss = 0.015306162856704823, Recall = 0.9995551601423488, Aging Rate = 0.4997775800711744, Precision = 0, f1 = 0.0\n",
      "Epoch 90: Train Loss = 0.01441796737792653, Recall = 0.9995551601423488, Aging Rate = 0.4997775800711744, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.014551379469312807, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 91: Train Loss = 0.015196314519039253, Recall = 0.9995551601423488, Aging Rate = 0.5002224199288257, Precision = 0.9991107158737217, f1 = 0.9993328885923949\n",
      "Epoch 92: Train Loss = 0.014273043586027368, Recall = 0.9995551601423488, Aging Rate = 0.4997775800711744, Precision = 0, f1 = 0.0\n",
      "Epoch 93: Train Loss = 0.015016047834183397, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 94: Train Loss = 0.01442427121208868, Recall = 0.9995551601423488, Aging Rate = 0.4997775800711744, Precision = 0, f1 = 0.0\n",
      "Epoch 95: Train Loss = 0.0143675454975076, Recall = 1.0, Aging Rate = 0.5002224199288257, Precision = 0.9995553579368608, f1 = 0.9997776295307983\n",
      "Test Loss = 0.01416989449690033, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Training Finished at epoch 95.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "19066012a8954116ada9138477f104f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss = 0.5936778687109775, Recall = 0.9145527369826435, Aging Rate = 0.7850467289719626, Precision = 0.5824829931972789, f1 = 0.7116883116883117\n",
      "Epoch 2: Train Loss = 0.4065539714729834, Recall = 0.8842901646639965, Aging Rate = 0.566533155318202, Precision = 0.7804399057344855, f1 = 0.8291258084706865\n",
      "Epoch 3: Train Loss = 0.3196827092593014, Recall = 0.9167779261237206, Aging Rate = 0.548064085447263, Precision = 0.8363784003248071, f1 = 0.8747346072186837\n",
      "Epoch 4: Train Loss = 0.269747509166406, Recall = 0.9327992879394749, Aging Rate = 0.5358255451713395, Precision = 0.8704318936877077, f1 = 0.9005370569280345\n",
      "Epoch 5: Train Loss = 0.2282049629387985, Recall = 0.9465954606141522, Aging Rate = 0.5298175344904317, Precision = 0.8933221335573288, f1 = 0.9191875540190146\n",
      "Test Loss = 0.19886498484788706, Recall = 0.9603916332888296, Aging Rate = 0.5298175344904317, precision = 0.9063418731625368\n",
      "Model in epoch 5 is saved.\n",
      "\n",
      "Epoch 6: Train Loss = 0.18867374584576158, Recall = 0.960836671117045, Aging Rate = 0.5244770805518469, Precision = 0.9159949087823505, f1 = 0.9378801042571678\n",
      "Epoch 7: Train Loss = 0.1620732119209935, Recall = 0.9670672007120605, Aging Rate = 0.5151312861593236, Precision = 0.9386609071274298, f1 = 0.9526523454625164\n",
      "Epoch 8: Train Loss = 0.13831942259244087, Recall = 0.9715175789942145, Aging Rate = 0.5102358700489542, Precision = 0.9520279110335804, f1 = 0.9616740088105726\n",
      "Epoch 9: Train Loss = 0.11892490498108178, Recall = 0.9737427681352915, Aging Rate = 0.5048954161103694, Precision = 0.9643014543851918, f1 = 0.9689991142604074\n",
      "Epoch 10: Train Loss = 0.10430981498667544, Recall = 0.9781931464174455, Aging Rate = 0.5035603026257232, Precision = 0.971277065841803, f1 = 0.9747228381374723\n",
      "Test Loss = 0.09329498928283976, Recall = 0.9790832220738763, Aging Rate = 0.5017801513128616, precision = 0.975609756097561\n",
      "Model in epoch 10 is saved.\n",
      "\n",
      "Epoch 11: Train Loss = 0.09242593616074755, Recall = 0.9804183355585224, Aging Rate = 0.5004450378282154, Precision = 0.9795464650955981, f1 = 0.9799822064056939\n",
      "Epoch 12: Train Loss = 0.081189533293539, Recall = 0.9804183355585224, Aging Rate = 0.5, Precision = 0.9804183355585224, f1 = 0.9804183355585224\n",
      "Epoch 13: Train Loss = 0.07201974740741807, Recall = 0.9844236760124611, Aging Rate = 0.5, Precision = 0.9844236760124611, f1 = 0.9844236760124611\n",
      "Epoch 14: Train Loss = 0.06444164144366807, Recall = 0.9879839786381842, Aging Rate = 0.5015576323987538, Precision = 0.9849157054125999, f1 = 0.9864474561208622\n",
      "Epoch 15: Train Loss = 0.05887537428708834, Recall = 0.9897641299510458, Aging Rate = 0.5013351134846462, Precision = 0.9871282734132268, f1 = 0.9884444444444445\n",
      "Test Loss = 0.05288936705239412, Recall = 0.9888740542946151, Aging Rate = 0.4968847352024922, precision = 0.9950738916256158\n",
      "Model in epoch 15 is saved.\n",
      "\n",
      "Epoch 16: Train Loss = 0.053240259377344695, Recall = 0.9897641299510458, Aging Rate = 0.4997774810858923, Precision = 0.9902048085485308, f1 = 0.9899844202092143\n",
      "Epoch 17: Train Loss = 0.04818371122285996, Recall = 0.9919893190921228, Aging Rate = 0.4991099243435692, Precision = 0.9937583593401694, f1 = 0.9928730512249443\n",
      "Epoch 18: Train Loss = 0.044572036393387984, Recall = 0.9928793947485536, Aging Rate = 0.4993324432576769, Precision = 0.9942067736185384, f1 = 0.99354264083723\n",
      "Epoch 19: Train Loss = 0.04064262425008884, Recall = 0.9928793947485536, Aging Rate = 0.4986648865153538, Precision = 0.9955377063810799, f1 = 0.9942067736185383\n",
      "Epoch 20: Train Loss = 0.03798378442596888, Recall = 0.9933244325767691, Aging Rate = 0.4991099243435692, Precision = 0.9950958537672759, f1 = 0.9942093541202673\n",
      "Test Loss = 0.034618176619344465, Recall = 0.9982198486871384, Aging Rate = 0.5008900756564308, precision = 0.9964460239893381\n",
      "Model in epoch 20 is saved.\n",
      "\n",
      "Epoch 21: Train Loss = 0.03504843769564356, Recall = 0.995549621717846, Aging Rate = 0.4993324432576769, Precision = 0.9968805704099821, f1 = 0.9962146515252728\n",
      "Epoch 22: Train Loss = 0.033151429945633686, Recall = 0.9973297730307076, Aging Rate = 0.4991099243435692, Precision = 0.9991083370485956, f1 = 0.998218262806236\n",
      "Epoch 23: Train Loss = 0.030945878560457114, Recall = 0.9968847352024922, Aging Rate = 0.4991099243435692, Precision = 0.9986625055728935, f1 = 0.9977728285077951\n",
      "Epoch 24: Train Loss = 0.029071599183729292, Recall = 0.9977748108589231, Aging Rate = 0.4997774810858923, Precision = 0.9982190560997328, f1 = 0.9979968840418428\n",
      "Epoch 25: Train Loss = 0.0281305799727433, Recall = 0.9982198486871384, Aging Rate = 0.4997774810858923, Precision = 0.9986642920747997, f1 = 0.9984420209214333\n",
      "Test Loss = 0.02555841779892557, Recall = 0.9973297730307076, Aging Rate = 0.49888740542946153, precision = 0.9995539696699376\n",
      "Model in epoch 25 is saved.\n",
      "\n",
      "Epoch 26: Train Loss = 0.02644700312288167, Recall = 0.9968847352024922, Aging Rate = 0.4991099243435692, Precision = 0.9986625055728935, f1 = 0.9977728285077951\n",
      "Epoch 27: Train Loss = 0.025377186995893253, Recall = 0.9982198486871384, Aging Rate = 0.4993324432576769, Precision = 0.999554367201426, f1 = 0.9988866622133155\n",
      "Epoch 28: Train Loss = 0.023849173863039155, Recall = 0.9986648865153538, Aging Rate = 0.5002225189141077, Precision = 0.998220640569395, f1 = 0.9984427141268075\n",
      "Epoch 29: Train Loss = 0.02322449806860462, Recall = 0.9982198486871384, Aging Rate = 0.4995549621717846, Precision = 0.9991091314031181, f1 = 0.9986642920747997\n",
      "Epoch 30: Train Loss = 0.02215417177413483, Recall = 0.9986648865153538, Aging Rate = 0.5002225189141077, Precision = 0.998220640569395, f1 = 0.9984427141268075\n",
      "Test Loss = 0.020604595290782932, Recall = 0.9986648865153538, Aging Rate = 0.4993324432576769, precision = 1.0\n",
      "Model in epoch 30 is saved.\n",
      "\n",
      "Epoch 31: Train Loss = 0.02206433416374482, Recall = 0.9986648865153538, Aging Rate = 0.4995549621717846, Precision = 0.999554565701559, f1 = 0.9991095280498664\n",
      "Epoch 32: Train Loss = 0.02065921231729617, Recall = 0.9986648865153538, Aging Rate = 0.4993324432576769, Precision = 0, f1 = 0.0\n",
      "Epoch 33: Train Loss = 0.02047947532334458, Recall = 0.9986648865153538, Aging Rate = 0.4993324432576769, Precision = 0, f1 = 0.0\n",
      "Epoch 34: Train Loss = 0.019804655170564685, Recall = 0.9991099243435692, Aging Rate = 0.4995549621717846, Precision = 0, f1 = 0.0\n",
      "Epoch 35: Train Loss = 0.019139701939877213, Recall = 0.9991099243435692, Aging Rate = 0.4995549621717846, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.017521573383979496, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "Model in epoch 35 is saved.\n",
      "\n",
      "Epoch 36: Train Loss = 0.018950081389342673, Recall = 0.9995549621717846, Aging Rate = 0.4997774810858923, Precision = 0, f1 = 0.0\n",
      "Epoch 37: Train Loss = 0.01866607172692358, Recall = 0.9991099243435692, Aging Rate = 0.4995549621717846, Precision = 0, f1 = 0.0\n",
      "Epoch 38: Train Loss = 0.018412794558887596, Recall = 0.9995549621717846, Aging Rate = 0.4997774810858923, Precision = 0, f1 = 0.0\n",
      "Epoch 39: Train Loss = 0.018513429976260338, Recall = 0.9995549621717846, Aging Rate = 0.5, Precision = 0.9995549621717846, f1 = 0.9995549621717846\n",
      "Epoch 40: Train Loss = 0.01778474231890946, Recall = 0.9991099243435692, Aging Rate = 0.4995549621717846, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.019053789847922102, Recall = 0.9991099243435692, Aging Rate = 0.4995549621717846, precision = 1.0\n",
      "\n",
      "Epoch 41: Train Loss = 0.017471221605963212, Recall = 0.9991099243435692, Aging Rate = 0.4995549621717846, Precision = 0, f1 = 0.0\n",
      "Epoch 42: Train Loss = 0.017879322932185096, Recall = 0.9991099243435692, Aging Rate = 0.5, Precision = 0.9991099243435692, f1 = 0.9991099243435692\n",
      "Epoch 43: Train Loss = 0.017175985958210006, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 44: Train Loss = 0.016775109619896943, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 45: Train Loss = 0.01660983066576478, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.014985479093245867, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 46: Train Loss = 0.01628282242862845, Recall = 0.9995549621717846, Aging Rate = 0.5, Precision = 0.9995549621717846, f1 = 0.9995549621717846\n",
      "Epoch 47: Train Loss = 0.01683598209995632, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 48: Train Loss = 0.016085484435240535, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49: Train Loss = 0.016593128455198496, Recall = 1.0, Aging Rate = 0.5002225189141077, Precision = 0.9995551601423488, f1 = 0.999777530589544\n",
      "Epoch 50: Train Loss = 0.01601143029585156, Recall = 0.9995549621717846, Aging Rate = 0.5, Precision = 0.9995549621717846, f1 = 0.9995549621717846\n",
      "Test Loss = 0.01480496889079743, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 51: Train Loss = 0.015599676976946125, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 52: Train Loss = 0.01587051847695966, Recall = 0.9995549621717846, Aging Rate = 0.4997774810858923, Precision = 0, f1 = 0.0\n",
      "Epoch 53: Train Loss = 0.016034604930146884, Recall = 0.9995549621717846, Aging Rate = 0.4997774810858923, Precision = 0, f1 = 0.0\n",
      "Epoch 54: Train Loss = 0.015914056729069405, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 55: Train Loss = 0.015707999223724678, Recall = 1.0, Aging Rate = 0.5002225189141077, Precision = 0.9995551601423488, f1 = 0.999777530589544\n",
      "Test Loss = 0.014317634377444538, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 56: Train Loss = 0.015471872188064673, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 57: Train Loss = 0.015704609524138675, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 58: Train Loss = 0.016068104504925518, Recall = 1.0, Aging Rate = 0.5002225189141077, Precision = 0.9995551601423488, f1 = 0.999777530589544\n",
      "Epoch 59: Train Loss = 0.015411808068437553, Recall = 1.0, Aging Rate = 0.5002225189141077, Precision = 0.9995551601423488, f1 = 0.999777530589544\n",
      "Epoch 60: Train Loss = 0.015216723854956517, Recall = 0.9991099243435692, Aging Rate = 0.4995549621717846, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.014529925877162892, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 61: Train Loss = 0.015793024538674247, Recall = 1.0, Aging Rate = 0.5002225189141077, Precision = 0.9995551601423488, f1 = 0.999777530589544\n",
      "Epoch 62: Train Loss = 0.015585877453269205, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 63: Train Loss = 0.015331707324071703, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 64: Train Loss = 0.015203017895625972, Recall = 0.9995549621717846, Aging Rate = 0.4997774810858923, Precision = 0, f1 = 0.0\n",
      "Epoch 65: Train Loss = 0.015841935085266177, Recall = 0.9995549621717846, Aging Rate = 0.4997774810858923, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.014397956982576614, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 66: Train Loss = 0.01580234670793554, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 67: Train Loss = 0.01531791433809689, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 68: Train Loss = 0.015165079225055313, Recall = 1.0, Aging Rate = 0.5002225189141077, Precision = 0.9995551601423488, f1 = 0.999777530589544\n",
      "Epoch 69: Train Loss = 0.014975867380065205, Recall = 0.9995549621717846, Aging Rate = 0.4997774810858923, Precision = 0, f1 = 0.0\n",
      "Epoch 70: Train Loss = 0.014888087963137458, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.014206776048111077, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 71: Train Loss = 0.014891080282260483, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 72: Train Loss = 0.01544672707352716, Recall = 0.9995549621717846, Aging Rate = 0.5, Precision = 0.9995549621717846, f1 = 0.9995549621717846\n",
      "Epoch 73: Train Loss = 0.015132598496864094, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 74: Train Loss = 0.015384554962449781, Recall = 1.0, Aging Rate = 0.5002225189141077, Precision = 0.9995551601423488, f1 = 0.999777530589544\n",
      "Epoch 75: Train Loss = 0.015033525555271491, Recall = 0.9995549621717846, Aging Rate = 0.4997774810858923, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.01342451413260283, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 76: Train Loss = 0.014889989042439936, Recall = 0.9995549621717846, Aging Rate = 0.4997774810858923, Precision = 0, f1 = 0.0\n",
      "Epoch 77: Train Loss = 0.014782378100634656, Recall = 0.9995549621717846, Aging Rate = 0.4997774810858923, Precision = 0, f1 = 0.0\n",
      "Epoch 78: Train Loss = 0.014680700259748224, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 79: Train Loss = 0.014504216080237201, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 80: Train Loss = 0.014618978551313328, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.01326170362719481, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 81: Train Loss = 0.01459789381730965, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 82: Train Loss = 0.014836118983467076, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 83: Train Loss = 0.015025596448121254, Recall = 1.0, Aging Rate = 0.5002225189141077, Precision = 0.9995551601423488, f1 = 0.999777530589544\n",
      "Epoch 84: Train Loss = 0.01448781542524755, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 85: Train Loss = 0.015264792397658083, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.015242078519352924, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Training Finished at epoch 85.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "99854241e27e4ab7891c077a2cba1b8c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss = 0.6056294381141026, Recall = 0.9167779261237206, Aging Rate = 0.7903871829105474, Precision = 0.579954954954955, f1 = 0.7104673219520607\n",
      "Epoch 2: Train Loss = 0.41886152142039607, Recall = 0.897196261682243, Aging Rate = 0.5729862038273253, Precision = 0.7829126213592233, f1 = 0.836167565325591\n",
      "Epoch 3: Train Loss = 0.31441587997533293, Recall = 0.9230084557187361, Aging Rate = 0.5493991989319092, Precision = 0.840016200891049, f1 = 0.8795589482612384\n",
      "Epoch 4: Train Loss = 0.2581219417575629, Recall = 0.9381397418780596, Aging Rate = 0.5384957721406319, Precision = 0.8710743801652893, f1 = 0.9033640454253267\n",
      "Epoch 5: Train Loss = 0.2147343211177725, Recall = 0.9465954606141522, Aging Rate = 0.527369826435247, Precision = 0.8974683544303798, f1 = 0.9213775178687459\n",
      "Test Loss = 0.1826852304760647, Recall = 0.9572763684913218, Aging Rate = 0.520694259012016, precision = 0.9192307692307692\n",
      "Model in epoch 5 is saved.\n",
      "\n",
      "Epoch 6: Train Loss = 0.1721450254009414, Recall = 0.9586114819759679, Aging Rate = 0.5135736537605696, Precision = 0.9332755632582322, f1 = 0.9457738748627882\n",
      "Epoch 7: Train Loss = 0.14702814259049518, Recall = 0.9701824655095683, Aging Rate = 0.513351134846462, Precision = 0.9449501517121803, f1 = 0.9574000878348704\n",
      "Epoch 8: Train Loss = 0.12502532125076402, Recall = 0.9724076546506453, Aging Rate = 0.5062305295950156, Precision = 0.9604395604395605, f1 = 0.9663865546218486\n",
      "Epoch 9: Train Loss = 0.10935191793552122, Recall = 0.9750778816199377, Aging Rate = 0.5031152647975078, Precision = 0.9690402476780186, f1 = 0.9720496894409938\n",
      "Epoch 10: Train Loss = 0.09597718923236191, Recall = 0.9786381842456608, Aging Rate = 0.5, Precision = 0.9786381842456608, f1 = 0.9786381842456608\n",
      "Test Loss = 0.09153107000978247, Recall = 0.9879839786381842, Aging Rate = 0.5131286159323543, precision = 0.9627059843885516\n",
      "Model in epoch 10 is saved.\n",
      "\n",
      "Epoch 11: Train Loss = 0.08604429487485486, Recall = 0.9808633733867379, Aging Rate = 0.5008900756564308, Precision = 0.9791203909373611, f1 = 0.9799911071587373\n",
      "Epoch 12: Train Loss = 0.07432742988998274, Recall = 0.9844236760124611, Aging Rate = 0.5, Precision = 0.9844236760124611, f1 = 0.9844236760124611\n",
      "Epoch 13: Train Loss = 0.0670971944331327, Recall = 0.9857587894971073, Aging Rate = 0.4991099243435692, Precision = 0.9875167186803389, f1 = 0.9866369710467707\n",
      "Epoch 14: Train Loss = 0.060790728208988995, Recall = 0.9879839786381842, Aging Rate = 0.4993324432576769, Precision = 0.9893048128342246, f1 = 0.9886439545758183\n",
      "Epoch 15: Train Loss = 0.05520367766943941, Recall = 0.9888740542946151, Aging Rate = 0.4993324432576769, Precision = 0.9901960784313726, f1 = 0.989534624805166\n",
      "Test Loss = 0.04983416713963204, Recall = 0.9915442812639075, Aging Rate = 0.4995549621717846, precision = 0.9924276169265034\n",
      "Model in epoch 15 is saved.\n",
      "\n",
      "Epoch 16: Train Loss = 0.051461387613003236, Recall = 0.9897641299510458, Aging Rate = 0.4993324432576769, Precision = 0.9910873440285205, f1 = 0.9904252950345135\n",
      "Epoch 17: Train Loss = 0.04782380064859038, Recall = 0.9924343569203382, Aging Rate = 0.5004450378282154, Precision = 0.9915518008003558, f1 = 0.9919928825622776\n",
      "Epoch 18: Train Loss = 0.0436976114706591, Recall = 0.9937694704049844, Aging Rate = 0.5004450378282154, Precision = 0.9928857269897733, f1 = 0.9933274021352313\n",
      "Epoch 19: Train Loss = 0.04053302443970507, Recall = 0.9942145082331998, Aging Rate = 0.5, Precision = 0.9942145082331998, f1 = 0.9942145082331998\n",
      "Epoch 20: Train Loss = 0.03809447181139607, Recall = 0.9951045838896306, Aging Rate = 0.4997774810858923, Precision = 0.9955476402493322, f1 = 0.9953260627643\n",
      "Test Loss = 0.03394286037254026, Recall = 0.9959946595460614, Aging Rate = 0.5, precision = 0.9959946595460614\n",
      "Model in epoch 20 is saved.\n",
      "\n",
      "Epoch 21: Train Loss = 0.035135198399029975, Recall = 0.995549621717846, Aging Rate = 0.4997774810858923, Precision = 0.9959928762243989, f1 = 0.9957711996438905\n",
      "Epoch 22: Train Loss = 0.03454938188566597, Recall = 0.995549621717846, Aging Rate = 0.5006675567423231, Precision = 0.9942222222222222, f1 = 0.9948854792083611\n",
      "Epoch 23: Train Loss = 0.03131331815241335, Recall = 0.9959946595460614, Aging Rate = 0.5002225189141077, Precision = 0.9955516014234875, f1 = 0.9957730812013348\n",
      "Epoch 24: Train Loss = 0.029836730588050114, Recall = 0.9968847352024922, Aging Rate = 0.5004450378282154, Precision = 0.9959982214317474, f1 = 0.99644128113879\n",
      "Epoch 25: Train Loss = 0.028651739883062095, Recall = 0.9964396973742768, Aging Rate = 0.4995549621717846, Precision = 0.9973273942093541, f1 = 0.9968833481745325\n",
      "Test Loss = 0.02574015279272741, Recall = 0.9973297730307076, Aging Rate = 0.5, precision = 0.9973297730307076\n",
      "Model in epoch 25 is saved.\n",
      "\n",
      "Epoch 26: Train Loss = 0.02723078369351562, Recall = 0.9973297730307076, Aging Rate = 0.5002225189141077, Precision = 0.9968861209964412, f1 = 0.9971078976640712\n",
      "Epoch 27: Train Loss = 0.0276479201949221, Recall = 0.9968847352024922, Aging Rate = 0.5, Precision = 0.9968847352024922, f1 = 0.9968847352024922\n",
      "Epoch 28: Train Loss = 0.02488709498581472, Recall = 0.9977748108589231, Aging Rate = 0.5, Precision = 0.9977748108589231, f1 = 0.9977748108589231\n",
      "Epoch 29: Train Loss = 0.024235805926382754, Recall = 0.9964396973742768, Aging Rate = 0.4995549621717846, Precision = 0.9973273942093541, f1 = 0.9968833481745325\n",
      "Epoch 30: Train Loss = 0.02284092174218756, Recall = 0.9986648865153538, Aging Rate = 0.5002225189141077, Precision = 0.998220640569395, f1 = 0.9984427141268075\n",
      "Test Loss = 0.02114568518919843, Recall = 0.9991099243435692, Aging Rate = 0.5006675567423231, precision = 0.9977777777777778\n",
      "Model in epoch 30 is saved.\n",
      "\n",
      "Epoch 31: Train Loss = 0.022961077448618934, Recall = 0.9977748108589231, Aging Rate = 0.5002225189141077, Precision = 0.9973309608540926, f1 = 0.9975528364849834\n",
      "Epoch 32: Train Loss = 0.02188140232303326, Recall = 0.9986648865153538, Aging Rate = 0.5004450378282154, Precision = 0.9977767896843042, f1 = 0.998220640569395\n",
      "Epoch 33: Train Loss = 0.02133013647087797, Recall = 0.9982198486871384, Aging Rate = 0.4997774810858923, Precision = 0.9986642920747997, f1 = 0.9984420209214333\n",
      "Epoch 34: Train Loss = 0.020571408787113086, Recall = 0.9991099243435692, Aging Rate = 0.5006675567423231, Precision = 0.9977777777777778, f1 = 0.9984434067155882\n",
      "Epoch 35: Train Loss = 0.020874345909702975, Recall = 0.9991099243435692, Aging Rate = 0.5002225189141077, Precision = 0.9986654804270463, f1 = 0.9988876529477195\n",
      "Test Loss = 0.018507728062182146, Recall = 0.9995549621717846, Aging Rate = 0.5004450378282154, precision = 0.9986660738105825\n",
      "Model in epoch 35 is saved.\n",
      "\n",
      "Epoch 36: Train Loss = 0.020174976977514303, Recall = 0.9991099243435692, Aging Rate = 0.5008900756564308, Precision = 0.9973345179920036, f1 = 0.9982214317474433\n",
      "Epoch 37: Train Loss = 0.019497575308393123, Recall = 1.0, Aging Rate = 0.5004450378282154, Precision = 0.9991107158737217, f1 = 0.9995551601423488\n",
      "Epoch 38: Train Loss = 0.018703733357834217, Recall = 0.9995549621717846, Aging Rate = 0.5004450378282154, Precision = 0.9986660738105825, f1 = 0.9991103202846975\n",
      "Epoch 39: Train Loss = 0.018569972317186684, Recall = 1.0, Aging Rate = 0.5006675567423231, Precision = 0.9986666666666667, f1 = 0.9993328885923949\n",
      "Epoch 40: Train Loss = 0.018227765006711603, Recall = 0.9995549621717846, Aging Rate = 0.5004450378282154, Precision = 0.9986660738105825, f1 = 0.9991103202846975\n",
      "Test Loss = 0.017030885232953187, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "Model in epoch 40 is saved.\n",
      "\n",
      "Epoch 41: Train Loss = 0.017874774392520155, Recall = 1.0, Aging Rate = 0.5006675567423231, Precision = 0.9986666666666667, f1 = 0.9993328885923949\n",
      "Epoch 42: Train Loss = 0.017837978947143396, Recall = 0.9995549621717846, Aging Rate = 0.5002225189141077, Precision = 0.9991103202846975, f1 = 0.9993325917686319\n",
      "Epoch 43: Train Loss = 0.01754540539647958, Recall = 1.0, Aging Rate = 0.5002225189141077, Precision = 0.9995551601423488, f1 = 0.999777530589544\n",
      "Epoch 44: Train Loss = 0.017602806263878897, Recall = 0.9995549621717846, Aging Rate = 0.5002225189141077, Precision = 0.9991103202846975, f1 = 0.9993325917686319\n",
      "Epoch 45: Train Loss = 0.017391294209037057, Recall = 0.9995549621717846, Aging Rate = 0.4997774810858923, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.015838914366814498, Recall = 1.0, Aging Rate = 0.5002225189141077, precision = 0.9995551601423488\n",
      "\n",
      "Epoch 46: Train Loss = 0.017030837421330762, Recall = 0.9995549621717846, Aging Rate = 0.5, Precision = 0.9995549621717846, f1 = 0.9995549621717846\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 47: Train Loss = 0.017695186548614746, Recall = 0.9995549621717846, Aging Rate = 0.5002225189141077, Precision = 0.9991103202846975, f1 = 0.9993325917686319\n",
      "Epoch 48: Train Loss = 0.01692793828206867, Recall = 1.0, Aging Rate = 0.5004450378282154, Precision = 0.9991107158737217, f1 = 0.9995551601423488\n",
      "Epoch 49: Train Loss = 0.016539056151674277, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 50: Train Loss = 0.01688874486218732, Recall = 0.9995549621717846, Aging Rate = 0.5, Precision = 0.9995549621717846, f1 = 0.9995549621717846\n",
      "Test Loss = 0.01510359453386368, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 51: Train Loss = 0.016164232934872787, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 52: Train Loss = 0.016360515111026947, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 53: Train Loss = 0.01642337809828689, Recall = 1.0, Aging Rate = 0.5004450378282154, Precision = 0.9991107158737217, f1 = 0.9995551601423488\n",
      "Epoch 54: Train Loss = 0.016396258563519478, Recall = 0.9991099243435692, Aging Rate = 0.4997774810858923, Precision = 0.9995547640249333, f1 = 0.9993322946806142\n",
      "Epoch 55: Train Loss = 0.0170282837990746, Recall = 0.9991099243435692, Aging Rate = 0.4995549621717846, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.016105242718457115, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 56: Train Loss = 0.01687429388665893, Recall = 0.9995549621717846, Aging Rate = 0.5, Precision = 0.9995549621717846, f1 = 0.9995549621717846\n",
      "Epoch 57: Train Loss = 0.015595884013856365, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 58: Train Loss = 0.015806260122078284, Recall = 1.0, Aging Rate = 0.5002225189141077, Precision = 0.9995551601423488, f1 = 0.999777530589544\n",
      "Epoch 59: Train Loss = 0.015848613562353342, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 60: Train Loss = 0.015879881740259658, Recall = 1.0, Aging Rate = 0.5006675567423231, Precision = 0.9986666666666667, f1 = 0.9993328885923949\n",
      "Test Loss = 0.01427889172763667, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 61: Train Loss = 0.016369940969607248, Recall = 0.9995549621717846, Aging Rate = 0.5, Precision = 0.9995549621717846, f1 = 0.9995549621717846\n",
      "Epoch 62: Train Loss = 0.015657683400893987, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 63: Train Loss = 0.015618947677357387, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 64: Train Loss = 0.01527966995788618, Recall = 1.0, Aging Rate = 0.5002225189141077, Precision = 0.9995551601423488, f1 = 0.999777530589544\n",
      "Epoch 65: Train Loss = 0.015942824300163864, Recall = 0.9995549621717846, Aging Rate = 0.4997774810858923, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.014221272487267952, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 66: Train Loss = 0.015337708494018781, Recall = 1.0, Aging Rate = 0.5002225189141077, Precision = 0.9995551601423488, f1 = 0.999777530589544\n",
      "Epoch 67: Train Loss = 0.015306133890054493, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 68: Train Loss = 0.015892899653227346, Recall = 1.0, Aging Rate = 0.5006675567423231, Precision = 0.9986666666666667, f1 = 0.9993328885923949\n",
      "Epoch 69: Train Loss = 0.01533044616450959, Recall = 1.0, Aging Rate = 0.5002225189141077, Precision = 0.9995551601423488, f1 = 0.999777530589544\n",
      "Epoch 70: Train Loss = 0.014962678588263634, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.013628687198109292, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 71: Train Loss = 0.015445149085858714, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 72: Train Loss = 0.015732584866431087, Recall = 1.0, Aging Rate = 0.5004450378282154, Precision = 0.9991107158737217, f1 = 0.9995551601423488\n",
      "Epoch 73: Train Loss = 0.015268542107508004, Recall = 1.0, Aging Rate = 0.5002225189141077, Precision = 0.9995551601423488, f1 = 0.999777530589544\n",
      "Epoch 74: Train Loss = 0.015207681564293375, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 75: Train Loss = 0.015055665858239134, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.013577306257667784, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 76: Train Loss = 0.015602568667638976, Recall = 0.9995549621717846, Aging Rate = 0.5002225189141077, Precision = 0.9991103202846975, f1 = 0.9993325917686319\n",
      "Epoch 77: Train Loss = 0.015495904466418303, Recall = 0.9995549621717846, Aging Rate = 0.5, Precision = 0.9995549621717846, f1 = 0.9995549621717846\n",
      "Epoch 78: Train Loss = 0.0149662583149575, Recall = 0.9995549621717846, Aging Rate = 0.4997774810858923, Precision = 0, f1 = 0.0\n",
      "Epoch 79: Train Loss = 0.01475875755700705, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 80: Train Loss = 0.015002641992243094, Recall = 1.0, Aging Rate = 0.5002225189141077, Precision = 0.9995551601423488, f1 = 0.999777530589544\n",
      "Test Loss = 0.013735750724089427, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 81: Train Loss = 0.01500756689855057, Recall = 0.9995549621717846, Aging Rate = 0.4997774810858923, Precision = 0, f1 = 0.0\n",
      "Epoch 82: Train Loss = 0.014630211690879287, Recall = 1.0, Aging Rate = 0.5002225189141077, Precision = 0.9995551601423488, f1 = 0.999777530589544\n",
      "Epoch 83: Train Loss = 0.01490423304592908, Recall = 0.9995549621717846, Aging Rate = 0.4997774810858923, Precision = 0, f1 = 0.0\n",
      "Epoch 84: Train Loss = 0.014804072991016843, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 85: Train Loss = 0.015046800219822338, Recall = 1.0, Aging Rate = 0.5002225189141077, Precision = 0.9995551601423488, f1 = 0.999777530589544\n",
      "Test Loss = 0.013627800205577386, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 86: Train Loss = 0.014860993873744103, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 87: Train Loss = 0.015812551980721297, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 88: Train Loss = 0.014998954632926715, Recall = 1.0, Aging Rate = 0.5002225189141077, Precision = 0.9995551601423488, f1 = 0.999777530589544\n",
      "Epoch 89: Train Loss = 0.01456485894514048, Recall = 0.9995549621717846, Aging Rate = 0.4997774810858923, Precision = 0, f1 = 0.0\n",
      "Epoch 90: Train Loss = 0.01446173597636173, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.014103670891757323, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Training Finished at epoch 90.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "672a7ac88fa0403abef2e876d9c14722",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss = 0.6032240579644998, Recall = 0.9385847797062751, Aging Rate = 0.8230974632843792, Precision = 0.570154095701541, f1 = 0.7093844601412713\n",
      "Epoch 2: Train Loss = 0.4212492832579929, Recall = 0.8802848242100578, Aging Rate = 0.5614152202937249, Precision = 0.7839873166864844, f1 = 0.8293501048218029\n",
      "Epoch 3: Train Loss = 0.3168152080584379, Recall = 0.9154428126390743, Aging Rate = 0.5462839341344015, Precision = 0.8378818737270876, f1 = 0.8749468311356869\n",
      "Epoch 4: Train Loss = 0.2600867102079302, Recall = 0.9310191366266133, Aging Rate = 0.5349354695149088, Precision = 0.870216306156406, f1 = 0.8995914857019996\n",
      "Epoch 5: Train Loss = 0.22560626176871032, Recall = 0.9461504227859368, Aging Rate = 0.5291499777481086, Precision = 0.8940285954583683, f1 = 0.9193513513513513\n",
      "Test Loss = 0.1930193474651391, Recall = 0.9581664441477525, Aging Rate = 0.5298175344904317, precision = 0.9042419151616967\n",
      "Model in epoch 5 is saved.\n",
      "\n",
      "Epoch 6: Train Loss = 0.18218438403575643, Recall = 0.9572763684913218, Aging Rate = 0.5213618157543392, Precision = 0.9180537772087067, f1 = 0.9372549019607843\n",
      "Epoch 7: Train Loss = 0.1543186754983003, Recall = 0.9679572763684913, Aging Rate = 0.5151312861593236, Precision = 0.9395248380129589, f1 = 0.9535291538798772\n",
      "Epoch 8: Train Loss = 0.1328213438623791, Recall = 0.9701824655095683, Aging Rate = 0.5046728971962616, Precision = 0.9611992945326279, f1 = 0.9656699889258028\n",
      "Epoch 9: Train Loss = 0.11485847529698649, Recall = 0.9755229194481531, Aging Rate = 0.5055629728526925, Precision = 0.9647887323943662, f1 = 0.9701261341004647\n",
      "Epoch 10: Train Loss = 0.10068221715360574, Recall = 0.9764129951045839, Aging Rate = 0.49888740542946153, Precision = 0.9785905441570026, f1 = 0.9775005569169081\n",
      "Test Loss = 0.08969645945891626, Recall = 0.9821984868713841, Aging Rate = 0.5033377837116155, precision = 0.9756852343059239\n",
      "Model in epoch 10 is saved.\n",
      "\n",
      "Epoch 11: Train Loss = 0.08798229731503306, Recall = 0.9821984868713841, Aging Rate = 0.5011125945705385, Precision = 0.9800177619893428, f1 = 0.9811069126472549\n",
      "Epoch 12: Train Loss = 0.07724275524530297, Recall = 0.9826435246995995, Aging Rate = 0.4991099243435692, Precision = 0.9843958983504235, f1 = 0.9835189309576837\n",
      "Epoch 13: Train Loss = 0.07122188568460076, Recall = 0.9826435246995995, Aging Rate = 0.4984423676012461, Precision = 0.9857142857142858, f1 = 0.9841765099175396\n",
      "Epoch 14: Train Loss = 0.06325451361407532, Recall = 0.9853137516688919, Aging Rate = 0.49888740542946153, Precision = 0.9875111507582516, f1 = 0.9864112274448653\n",
      "Epoch 15: Train Loss = 0.05691432726412388, Recall = 0.986648865153538, Aging Rate = 0.49888740542946153, Precision = 0.9888492417484389, f1 = 0.9877478280240587\n",
      "Test Loss = 0.0510483653772445, Recall = 0.9919893190921228, Aging Rate = 0.5011125945705385, precision = 0.9897868561278863\n",
      "Model in epoch 15 is saved.\n",
      "\n",
      "Epoch 16: Train Loss = 0.052672087290735845, Recall = 0.9897641299510458, Aging Rate = 0.4991099243435692, Precision = 0.9915292019616585, f1 = 0.9906458797327393\n",
      "Epoch 17: Train Loss = 0.04750448393726221, Recall = 0.9902091677792613, Aging Rate = 0.4995549621717846, Precision = 0.9910913140311804, f1 = 0.9906500445235975\n",
      "Epoch 18: Train Loss = 0.0441339494893431, Recall = 0.991099243435692, Aging Rate = 0.4986648865153538, Precision = 0.9937527889335118, f1 = 0.9924242424242424\n",
      "Epoch 19: Train Loss = 0.041475683112488254, Recall = 0.9915442812639075, Aging Rate = 0.4982198486871384, Precision = 0.9950870924519875, f1 = 0.9933125278644672\n",
      "Epoch 20: Train Loss = 0.03778612690272732, Recall = 0.9946595460614153, Aging Rate = 0.4993324432576769, Precision = 0.9959893048128342, f1 = 0.9953239812959251\n",
      "Test Loss = 0.0340663912541531, Recall = 0.9968847352024922, Aging Rate = 0.5002225189141077, precision = 0.99644128113879\n",
      "Model in epoch 20 is saved.\n",
      "\n",
      "Epoch 21: Train Loss = 0.035586043715669306, Recall = 0.9959946595460614, Aging Rate = 0.5002225189141077, Precision = 0.9955516014234875, f1 = 0.9957730812013348\n",
      "Epoch 22: Train Loss = 0.03231445535798576, Recall = 0.9959946595460614, Aging Rate = 0.4995549621717846, Precision = 0.9968819599109131, f1 = 0.9964381121994657\n",
      "Epoch 23: Train Loss = 0.030755728302489505, Recall = 0.9982198486871384, Aging Rate = 0.5008900756564308, Precision = 0.9964460239893381, f1 = 0.9973321476211651\n",
      "Epoch 24: Train Loss = 0.028941132111659728, Recall = 0.9977748108589231, Aging Rate = 0.5, Precision = 0.9977748108589231, f1 = 0.9977748108589231\n",
      "Epoch 25: Train Loss = 0.027679976128940322, Recall = 0.9977748108589231, Aging Rate = 0.5, Precision = 0.9977748108589231, f1 = 0.9977748108589231\n",
      "Test Loss = 0.025490224862518472, Recall = 0.9986648865153538, Aging Rate = 0.5, precision = 0.9986648865153538\n",
      "Model in epoch 25 is saved.\n",
      "\n",
      "Epoch 26: Train Loss = 0.027307289926493544, Recall = 0.9977748108589231, Aging Rate = 0.4997774810858923, Precision = 0.9982190560997328, f1 = 0.9979968840418428\n",
      "Epoch 27: Train Loss = 0.026166737714594185, Recall = 0.9986648865153538, Aging Rate = 0.5002225189141077, Precision = 0.998220640569395, f1 = 0.9984427141268075\n",
      "Epoch 28: Train Loss = 0.024657395146505324, Recall = 0.9982198486871384, Aging Rate = 0.5, Precision = 0.9982198486871384, f1 = 0.9982198486871384\n",
      "Epoch 29: Train Loss = 0.024074944864807657, Recall = 0.9991099243435692, Aging Rate = 0.5004450378282154, Precision = 0.9982214317474433, f1 = 0.9986654804270463\n",
      "Epoch 30: Train Loss = 0.02280054861347265, Recall = 0.9991099243435692, Aging Rate = 0.5, Precision = 0.9991099243435692, f1 = 0.9991099243435692\n",
      "Test Loss = 0.02103869899324857, Recall = 1.0, Aging Rate = 0.5002225189141077, precision = 0.9995551601423488\n",
      "Model in epoch 30 is saved.\n",
      "\n",
      "Epoch 31: Train Loss = 0.02195266315661301, Recall = 0.9991099243435692, Aging Rate = 0.5, Precision = 0.9991099243435692, f1 = 0.9991099243435692\n",
      "Epoch 32: Train Loss = 0.02145523203700171, Recall = 0.9991099243435692, Aging Rate = 0.5004450378282154, Precision = 0.9982214317474433, f1 = 0.9986654804270463\n",
      "Epoch 33: Train Loss = 0.02065210274624185, Recall = 0.9995549621717846, Aging Rate = 0.5002225189141077, Precision = 0.9991103202846975, f1 = 0.9993325917686319\n",
      "Epoch 34: Train Loss = 0.020326560538910365, Recall = 0.9995549621717846, Aging Rate = 0.4997774810858923, Precision = 0, f1 = 0.0\n",
      "Epoch 35: Train Loss = 0.020060917442149728, Recall = 0.9991099243435692, Aging Rate = 0.4997774810858923, Precision = 0.9995547640249333, f1 = 0.9993322946806142\n",
      "Test Loss = 0.0187048403816451, Recall = 0.9995549621717846, Aging Rate = 0.5002225189141077, precision = 0.9991103202846975\n",
      "\n",
      "Epoch 36: Train Loss = 0.019713690130161905, Recall = 0.9995549621717846, Aging Rate = 0.5002225189141077, Precision = 0.9991103202846975, f1 = 0.9993325917686319\n",
      "Epoch 37: Train Loss = 0.01896415959959116, Recall = 0.9991099243435692, Aging Rate = 0.4995549621717846, Precision = 0, f1 = 0.0\n",
      "Epoch 38: Train Loss = 0.018614462493497318, Recall = 0.9995549621717846, Aging Rate = 0.4997774810858923, Precision = 0, f1 = 0.0\n",
      "Epoch 39: Train Loss = 0.018420328518345082, Recall = 0.9986648865153538, Aging Rate = 0.4995549621717846, Precision = 0.999554565701559, f1 = 0.9991095280498664\n",
      "Epoch 40: Train Loss = 0.018377017805085057, Recall = 0.9995549621717846, Aging Rate = 0.5, Precision = 0.9995549621717846, f1 = 0.9995549621717846\n",
      "Test Loss = 0.016746552647798126, Recall = 0.9995549621717846, Aging Rate = 0.4997774810858923, precision = 1.0\n",
      "Model in epoch 40 is saved.\n",
      "\n",
      "Epoch 41: Train Loss = 0.018024824846089946, Recall = 0.9995549621717846, Aging Rate = 0.4997774810858923, Precision = 0, f1 = 0.0\n",
      "Epoch 42: Train Loss = 0.01785599796908017, Recall = 0.9991099243435692, Aging Rate = 0.4997774810858923, Precision = 0.9995547640249333, f1 = 0.9993322946806142\n",
      "Epoch 43: Train Loss = 0.017529746413713344, Recall = 0.9995549621717846, Aging Rate = 0.4997774810858923, Precision = 0, f1 = 0.0\n",
      "Epoch 44: Train Loss = 0.01729203044869168, Recall = 0.9995549621717846, Aging Rate = 0.4997774810858923, Precision = 0, f1 = 0.0\n",
      "Epoch 45: Train Loss = 0.017022613275167832, Recall = 0.9995549621717846, Aging Rate = 0.4997774810858923, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.016246653073660043, Recall = 0.9995549621717846, Aging Rate = 0.4997774810858923, precision = 1.0\n",
      "\n",
      "Epoch 46: Train Loss = 0.01787443566631358, Recall = 0.9995549621717846, Aging Rate = 0.4997774810858923, Precision = 0, f1 = 0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 47: Train Loss = 0.017273670348409657, Recall = 0.9995549621717846, Aging Rate = 0.4997774810858923, Precision = 0, f1 = 0.0\n",
      "Epoch 48: Train Loss = 0.017109718406676556, Recall = 1.0, Aging Rate = 0.5002225189141077, Precision = 0.9995551601423488, f1 = 0.999777530589544\n",
      "Epoch 49: Train Loss = 0.016897285017249155, Recall = 0.9995549621717846, Aging Rate = 0.4997774810858923, Precision = 0, f1 = 0.0\n",
      "Epoch 50: Train Loss = 0.016796297104022053, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.015090818370600834, Recall = 0.9995549621717846, Aging Rate = 0.4997774810858923, precision = 1.0\n",
      "\n",
      "Epoch 51: Train Loss = 0.016211736003541262, Recall = 0.9991099243435692, Aging Rate = 0.4995549621717846, Precision = 0, f1 = 0.0\n",
      "Epoch 52: Train Loss = 0.01617773302342091, Recall = 0.9995549621717846, Aging Rate = 0.4997774810858923, Precision = 0, f1 = 0.0\n",
      "Epoch 53: Train Loss = 0.016248917189506714, Recall = 0.9991099243435692, Aging Rate = 0.4997774810858923, Precision = 0.9995547640249333, f1 = 0.9993322946806142\n",
      "Epoch 54: Train Loss = 0.016369604048019498, Recall = 0.9995549621717846, Aging Rate = 0.4997774810858923, Precision = 0, f1 = 0.0\n",
      "Epoch 55: Train Loss = 0.016345110941971733, Recall = 0.9995549621717846, Aging Rate = 0.4997774810858923, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.014585439141874558, Recall = 0.9995549621717846, Aging Rate = 0.4997774810858923, precision = 1.0\n",
      "\n",
      "Epoch 56: Train Loss = 0.016072712942682667, Recall = 0.9995549621717846, Aging Rate = 0.4997774810858923, Precision = 0, f1 = 0.0\n",
      "Epoch 57: Train Loss = 0.01571903017013403, Recall = 0.9995549621717846, Aging Rate = 0.4997774810858923, Precision = 0, f1 = 0.0\n",
      "Epoch 58: Train Loss = 0.015546867903487771, Recall = 0.9995549621717846, Aging Rate = 0.4997774810858923, Precision = 0, f1 = 0.0\n",
      "Epoch 59: Train Loss = 0.015691251889812876, Recall = 0.9995549621717846, Aging Rate = 0.4997774810858923, Precision = 0, f1 = 0.0\n",
      "Epoch 60: Train Loss = 0.016257989873946322, Recall = 1.0, Aging Rate = 0.5002225189141077, Precision = 0.9995551601423488, f1 = 0.999777530589544\n",
      "Test Loss = 0.01445972123840251, Recall = 0.9995549621717846, Aging Rate = 0.4997774810858923, precision = 1.0\n",
      "\n",
      "Epoch 61: Train Loss = 0.01606158863191054, Recall = 0.9995549621717846, Aging Rate = 0.4997774810858923, Precision = 0, f1 = 0.0\n",
      "Epoch 62: Train Loss = 0.015699721698727562, Recall = 0.9995549621717846, Aging Rate = 0.4997774810858923, Precision = 0, f1 = 0.0\n",
      "Epoch 63: Train Loss = 0.016318020665737114, Recall = 0.9995549621717846, Aging Rate = 0.5, Precision = 0.9995549621717846, f1 = 0.9995549621717846\n",
      "Epoch 64: Train Loss = 0.015329529983076485, Recall = 0.9995549621717846, Aging Rate = 0.4997774810858923, Precision = 0, f1 = 0.0\n",
      "Epoch 65: Train Loss = 0.015430790321212586, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.014105233748438865, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "Model in epoch 65 is saved.\n",
      "\n",
      "Epoch 66: Train Loss = 0.0156597938499665, Recall = 0.9991099243435692, Aging Rate = 0.4995549621717846, Precision = 0, f1 = 0.0\n",
      "Epoch 67: Train Loss = 0.016209120266587138, Recall = 0.9995549621717846, Aging Rate = 0.5, Precision = 0.9995549621717846, f1 = 0.9995549621717846\n",
      "Epoch 68: Train Loss = 0.015551623637557136, Recall = 0.9995549621717846, Aging Rate = 0.4997774810858923, Precision = 0, f1 = 0.0\n",
      "Epoch 69: Train Loss = 0.014867079399051962, Recall = 0.9995549621717846, Aging Rate = 0.4997774810858923, Precision = 0, f1 = 0.0\n",
      "Epoch 70: Train Loss = 0.014960957291935171, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.015801823156266992, Recall = 1.0, Aging Rate = 0.5002225189141077, precision = 0.9995551601423488\n",
      "\n",
      "Epoch 71: Train Loss = 0.01515511701875758, Recall = 0.9995549621717846, Aging Rate = 0.5, Precision = 0.9995549621717846, f1 = 0.9995549621717846\n",
      "Epoch 72: Train Loss = 0.016592532787579772, Recall = 0.9995549621717846, Aging Rate = 0.4997774810858923, Precision = 0, f1 = 0.0\n",
      "Epoch 73: Train Loss = 0.01482527616919148, Recall = 0.9995549621717846, Aging Rate = 0.5, Precision = 0.9995549621717846, f1 = 0.9995549621717846\n",
      "Epoch 74: Train Loss = 0.015920412488377885, Recall = 0.9991099243435692, Aging Rate = 0.4997774810858923, Precision = 0.9995547640249333, f1 = 0.9993322946806142\n",
      "Epoch 75: Train Loss = 0.015364762723883577, Recall = 0.9995549621717846, Aging Rate = 0.4997774810858923, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.013662491938738384, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 76: Train Loss = 0.014764513278278076, Recall = 0.9995549621717846, Aging Rate = 0.4997774810858923, Precision = 0, f1 = 0.0\n",
      "Epoch 77: Train Loss = 0.015662296255283693, Recall = 0.9995549621717846, Aging Rate = 0.4997774810858923, Precision = 0, f1 = 0.0\n",
      "Epoch 78: Train Loss = 0.01506159355607784, Recall = 1.0, Aging Rate = 0.5002225189141077, Precision = 0.9995551601423488, f1 = 0.999777530589544\n",
      "Epoch 79: Train Loss = 0.015147605237584606, Recall = 0.9995549621717846, Aging Rate = 0.5, Precision = 0.9995549621717846, f1 = 0.9995549621717846\n",
      "Epoch 80: Train Loss = 0.014727895725874912, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.013736200273123167, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 81: Train Loss = 0.014529097826532195, Recall = 0.9995549621717846, Aging Rate = 0.4997774810858923, Precision = 0, f1 = 0.0\n",
      "Epoch 82: Train Loss = 0.015372209594111258, Recall = 0.9991099243435692, Aging Rate = 0.4995549621717846, Precision = 0, f1 = 0.0\n",
      "Epoch 83: Train Loss = 0.015894482613544918, Recall = 0.9991099243435692, Aging Rate = 0.4997774810858923, Precision = 0.9995547640249333, f1 = 0.9993322946806142\n",
      "Epoch 84: Train Loss = 0.01503962626772745, Recall = 0.9995549621717846, Aging Rate = 0.4997774810858923, Precision = 0, f1 = 0.0\n",
      "Epoch 85: Train Loss = 0.015069303744811188, Recall = 0.9995549621717846, Aging Rate = 0.4997774810858923, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.013320886063699092, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 86: Train Loss = 0.014671137052433567, Recall = 0.9995549621717846, Aging Rate = 0.4997774810858923, Precision = 0, f1 = 0.0\n",
      "Epoch 87: Train Loss = 0.015072412252538884, Recall = 0.9995549621717846, Aging Rate = 0.4997774810858923, Precision = 0, f1 = 0.0\n",
      "Epoch 88: Train Loss = 0.014704384320860287, Recall = 0.9995549621717846, Aging Rate = 0.4997774810858923, Precision = 0, f1 = 0.0\n",
      "Epoch 89: Train Loss = 0.015166313490864763, Recall = 0.9995549621717846, Aging Rate = 0.5, Precision = 0.9995549621717846, f1 = 0.9995549621717846\n",
      "Epoch 90: Train Loss = 0.014801249391733804, Recall = 0.9995549621717846, Aging Rate = 0.4997774810858923, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.013925201271573172, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 91: Train Loss = 0.015301528888699421, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 92: Train Loss = 0.014799209762137494, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 93: Train Loss = 0.015361147878826673, Recall = 0.9995549621717846, Aging Rate = 0.4997774810858923, Precision = 0, f1 = 0.0\n",
      "Epoch 94: Train Loss = 0.015037736703749891, Recall = 0.9995549621717846, Aging Rate = 0.4997774810858923, Precision = 0, f1 = 0.0\n",
      "Epoch 95: Train Loss = 0.01474795917908669, Recall = 0.9995549621717846, Aging Rate = 0.4997774810858923, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.01340206571148802, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 96: Train Loss = 0.015328649933602036, Recall = 0.9995549621717846, Aging Rate = 0.4997774810858923, Precision = 0, f1 = 0.0\n",
      "Epoch 97: Train Loss = 0.015149914138980664, Recall = 0.9995549621717846, Aging Rate = 0.4997774810858923, Precision = 0, f1 = 0.0\n",
      "Epoch 98: Train Loss = 0.014416534582117318, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 99: Train Loss = 0.014459492739217051, Recall = 0.9995549621717846, Aging Rate = 0.4997774810858923, Precision = 0, f1 = 0.0\n",
      "Epoch 100: Train Loss = 0.014993810874518152, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.013767243076147347, Recall = 0.9995549621717846, Aging Rate = 0.4997774810858923, precision = 1.0\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56dbbbea5950492e8ed175eb745d24c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss = 0.5955541262135381, Recall = 0.9190031152647975, Aging Rate = 0.7828215398308856, Precision = 0.5869812393405344, f1 = 0.7163920208152645\n",
      "Epoch 2: Train Loss = 0.40990072061047855, Recall = 0.8900756564307967, Aging Rate = 0.5718736092567869, Precision = 0.7782101167315175, f1 = 0.8303923603902845\n",
      "Epoch 3: Train Loss = 0.3109661207153471, Recall = 0.9252336448598131, Aging Rate = 0.5471740097908322, Precision = 0.8454656364375762, f1 = 0.8835529111772205\n",
      "Epoch 4: Train Loss = 0.25880938932850034, Recall = 0.9341344014241211, Aging Rate = 0.5360480640854473, Precision = 0.871315898713159, f1 = 0.9016323024054984\n",
      "Epoch 5: Train Loss = 0.22400093777581856, Recall = 0.947485536270583, Aging Rate = 0.5307076101468625, Precision = 0.8926624737945492, f1 = 0.9192573402417962\n",
      "Test Loss = 0.18984775937195084, Recall = 0.9523809523809523, Aging Rate = 0.5131286159323543, precision = 0.9280138768430182\n",
      "Model in epoch 5 is saved.\n",
      "\n",
      "Epoch 6: Train Loss = 0.17825400375715086, Recall = 0.9595015576323987, Aging Rate = 0.5173564753004005, Precision = 0.9273118279569893, f1 = 0.9431321084864392\n",
      "Epoch 7: Train Loss = 0.15230785131215732, Recall = 0.9626168224299065, Aging Rate = 0.5080106809078772, Precision = 0.9474375821287779, f1 = 0.9549668874172186\n",
      "Epoch 8: Train Loss = 0.12886412337614686, Recall = 0.9741878059635068, Aging Rate = 0.5077881619937694, Precision = 0.9592462751971954, f1 = 0.9666593066902185\n",
      "Epoch 9: Train Loss = 0.11431234549775779, Recall = 0.9741878059635068, Aging Rate = 0.5033377837116155, Precision = 0.9677276746242264, f1 = 0.9709469948990908\n",
      "Epoch 10: Train Loss = 0.09726689687279738, Recall = 0.9773030707610146, Aging Rate = 0.5, Precision = 0.9773030707610146, f1 = 0.9773030707610146\n",
      "Test Loss = 0.08766733358966863, Recall = 0.9795282599020917, Aging Rate = 0.5004450378282154, precision = 0.9786571809693198\n",
      "Model in epoch 10 is saved.\n",
      "\n",
      "Epoch 11: Train Loss = 0.08717886880073326, Recall = 0.9799732977303071, Aging Rate = 0.5011125945705385, Precision = 0.977797513321492, f1 = 0.9788841964881084\n",
      "Epoch 12: Train Loss = 0.07891508706766179, Recall = 0.9848687138406764, Aging Rate = 0.5020026702269693, Precision = 0.9809397163120568, f1 = 0.9829002886964245\n",
      "Epoch 13: Train Loss = 0.068654015375128, Recall = 0.9839786381842457, Aging Rate = 0.4997774810858923, Precision = 0.9844167408726625, f1 = 0.9841976407745382\n",
      "Epoch 14: Train Loss = 0.06368873887092313, Recall = 0.9870939029817535, Aging Rate = 0.5008900756564308, Precision = 0.9853398489560196, f1 = 0.9862160960426857\n",
      "Epoch 15: Train Loss = 0.056642725846544076, Recall = 0.9870939029817535, Aging Rate = 0.4995549621717846, Precision = 0.9879732739420936, f1 = 0.98753339269813\n",
      "Test Loss = 0.051112074346928583, Recall = 0.9928793947485536, Aging Rate = 0.5020026702269693, precision = 0.9889184397163121\n",
      "Model in epoch 15 is saved.\n",
      "\n",
      "Epoch 16: Train Loss = 0.051990273922124755, Recall = 0.9879839786381842, Aging Rate = 0.49888740542946153, Precision = 0.9901873327386262, f1 = 0.9890844286032523\n",
      "Epoch 17: Train Loss = 0.048211226776958466, Recall = 0.9919893190921228, Aging Rate = 0.5, Precision = 0.9919893190921228, f1 = 0.9919893190921228\n",
      "Epoch 18: Train Loss = 0.044095686528687485, Recall = 0.9928793947485536, Aging Rate = 0.4997774810858923, Precision = 0.9933214603739983, f1 = 0.9931003783663476\n",
      "Epoch 19: Train Loss = 0.040937724653805525, Recall = 0.9937694704049844, Aging Rate = 0.4993324432576769, Precision = 0.9950980392156863, f1 = 0.9944333110665775\n",
      "Epoch 20: Train Loss = 0.03810748914907416, Recall = 0.9946595460614153, Aging Rate = 0.4997774810858923, Precision = 0.9951024042742653, f1 = 0.9948809258847097\n",
      "Test Loss = 0.03546509798906303, Recall = 0.9973297730307076, Aging Rate = 0.5015576323987538, precision = 0.9942324755989352\n",
      "Model in epoch 20 is saved.\n",
      "\n",
      "Epoch 21: Train Loss = 0.03544414083547575, Recall = 0.995549621717846, Aging Rate = 0.5004450378282154, Precision = 0.9946642952423299, f1 = 0.9951067615658362\n",
      "Epoch 22: Train Loss = 0.03342447767277055, Recall = 0.9959946595460614, Aging Rate = 0.5004450378282154, Precision = 0.9951089373054691, f1 = 0.9955516014234875\n",
      "Epoch 23: Train Loss = 0.032354420198531325, Recall = 0.9968847352024922, Aging Rate = 0.5004450378282154, Precision = 0.9959982214317474, f1 = 0.99644128113879\n",
      "Epoch 24: Train Loss = 0.029592886228076234, Recall = 0.9964396973742768, Aging Rate = 0.5002225189141077, Precision = 0.9959964412811388, f1 = 0.996218020022247\n",
      "Epoch 25: Train Loss = 0.028210953013116803, Recall = 0.9968847352024922, Aging Rate = 0.4997774810858923, Precision = 0.9973285841495992, f1 = 0.9971066102826619\n",
      "Test Loss = 0.02593532101506915, Recall = 0.9982198486871384, Aging Rate = 0.5004450378282154, precision = 0.997332147621165\n",
      "Model in epoch 25 is saved.\n",
      "\n",
      "Epoch 26: Train Loss = 0.027255503581376753, Recall = 0.9973297730307076, Aging Rate = 0.5004450378282154, Precision = 0.9964428634948866, f1 = 0.9968861209964412\n",
      "Epoch 27: Train Loss = 0.026124230804420015, Recall = 0.9986648865153538, Aging Rate = 0.5006675567423231, Precision = 0.9973333333333333, f1 = 0.9979986657771848\n",
      "Epoch 28: Train Loss = 0.02536934044114287, Recall = 0.9977748108589231, Aging Rate = 0.5006675567423231, Precision = 0.9964444444444445, f1 = 0.9971091839003781\n",
      "Epoch 29: Train Loss = 0.023675688939905983, Recall = 0.9995549621717846, Aging Rate = 0.5006675567423231, Precision = 0.9982222222222222, f1 = 0.9988881476539916\n",
      "Epoch 30: Train Loss = 0.02309130919366929, Recall = 0.9991099243435692, Aging Rate = 0.5002225189141077, Precision = 0.9986654804270463, f1 = 0.9988876529477195\n",
      "Test Loss = 0.024920908714307643, Recall = 1.0, Aging Rate = 0.5013351134846462, precision = 0.9973368841544608\n",
      "Model in epoch 30 is saved.\n",
      "\n",
      "Epoch 31: Train Loss = 0.02331264566631783, Recall = 0.9986648865153538, Aging Rate = 0.5, Precision = 0.9986648865153538, f1 = 0.9986648865153538\n",
      "Epoch 32: Train Loss = 0.022075486501648152, Recall = 0.9986648865153538, Aging Rate = 0.4997774810858923, Precision = 0.9991095280498664, f1 = 0.9988871578010239\n",
      "Epoch 33: Train Loss = 0.02133553742725795, Recall = 0.9995549621717846, Aging Rate = 0.5006675567423231, Precision = 0.9982222222222222, f1 = 0.9988881476539916\n",
      "Epoch 34: Train Loss = 0.020319820036444336, Recall = 0.9991099243435692, Aging Rate = 0.5002225189141077, Precision = 0.9986654804270463, f1 = 0.9988876529477195\n",
      "Epoch 35: Train Loss = 0.01982674522729094, Recall = 0.9995549621717846, Aging Rate = 0.5002225189141077, Precision = 0.9991103202846975, f1 = 0.9993325917686319\n",
      "Test Loss = 0.01844200967804002, Recall = 1.0, Aging Rate = 0.5004450378282154, precision = 0.9991107158737217\n",
      "Model in epoch 35 is saved.\n",
      "\n",
      "Epoch 36: Train Loss = 0.019864087298091353, Recall = 1.0, Aging Rate = 0.5002225189141077, Precision = 0.9995551601423488, f1 = 0.999777530589544\n",
      "Epoch 37: Train Loss = 0.01882850271320152, Recall = 1.0, Aging Rate = 0.5004450378282154, Precision = 0.9991107158737217, f1 = 0.9995551601423488\n",
      "Epoch 38: Train Loss = 0.018701144636280812, Recall = 1.0, Aging Rate = 0.5002225189141077, Precision = 0.9995551601423488, f1 = 0.999777530589544\n",
      "Epoch 39: Train Loss = 0.018540900124342216, Recall = 1.0, Aging Rate = 0.5002225189141077, Precision = 0.9995551601423488, f1 = 0.999777530589544\n",
      "Epoch 40: Train Loss = 0.018303449573612872, Recall = 1.0, Aging Rate = 0.5002225189141077, Precision = 0.9995551601423488, f1 = 0.999777530589544\n",
      "Test Loss = 0.016598364319212976, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "Model in epoch 40 is saved.\n",
      "\n",
      "Epoch 41: Train Loss = 0.01809213719151261, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 42: Train Loss = 0.01758050506675063, Recall = 0.9995549621717846, Aging Rate = 0.4997774810858923, Precision = 0, f1 = 0.0\n",
      "Epoch 43: Train Loss = 0.017550280935230072, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 44: Train Loss = 0.017356142295589964, Recall = 1.0, Aging Rate = 0.5002225189141077, Precision = 0.9995551601423488, f1 = 0.999777530589544\n",
      "Epoch 45: Train Loss = 0.017097978683169493, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.015513182994895078, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 46: Train Loss = 0.016591519817401555, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 47: Train Loss = 0.016798834994926046, Recall = 0.9991099243435692, Aging Rate = 0.4995549621717846, Precision = 0, f1 = 0.0\n",
      "Epoch 48: Train Loss = 0.016628525885709813, Recall = 1.0, Aging Rate = 0.5002225189141077, Precision = 0.9995551601423488, f1 = 0.999777530589544\n",
      "Epoch 49: Train Loss = 0.01635467064118035, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 50: Train Loss = 0.016560590566514356, Recall = 0.9995549621717846, Aging Rate = 0.4997774810858923, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.014949149484893296, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 51: Train Loss = 0.016215937674247827, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 52: Train Loss = 0.01602719769811877, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 53: Train Loss = 0.016184541454823034, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 54: Train Loss = 0.015888297891813778, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 55: Train Loss = 0.01598686519405101, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.014454968067231738, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 56: Train Loss = 0.015892390834858112, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 57: Train Loss = 0.01627648569242287, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 58: Train Loss = 0.015643886440115662, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 59: Train Loss = 0.015631368470804714, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 60: Train Loss = 0.015720933979575268, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.014175638944013389, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 61: Train Loss = 0.01545876541233389, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 62: Train Loss = 0.015674235998446882, Recall = 0.9995549621717846, Aging Rate = 0.4997774810858923, Precision = 0, f1 = 0.0\n",
      "Epoch 63: Train Loss = 0.015268976878893736, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 64: Train Loss = 0.015349662454461436, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 65: Train Loss = 0.015439410061870992, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.015690556560316826, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 66: Train Loss = 0.01587071085579173, Recall = 1.0, Aging Rate = 0.5002225189141077, Precision = 0.9995551601423488, f1 = 0.999777530589544\n",
      "Epoch 67: Train Loss = 0.01568185132076449, Recall = 1.0, Aging Rate = 0.5002225189141077, Precision = 0.9995551601423488, f1 = 0.999777530589544\n",
      "Epoch 68: Train Loss = 0.01592515974127761, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 69: Train Loss = 0.01482881891280479, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 70: Train Loss = 0.015263099444704317, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.014328275489507714, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 71: Train Loss = 0.015323789211667322, Recall = 0.9991099243435692, Aging Rate = 0.4995549621717846, Precision = 0, f1 = 0.0\n",
      "Epoch 72: Train Loss = 0.014774987581847083, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 73: Train Loss = 0.015034194854156515, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 74: Train Loss = 0.014912919113582434, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 75: Train Loss = 0.014932206605155308, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.01425093902721769, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 76: Train Loss = 0.0156284563987784, Recall = 1.0, Aging Rate = 0.5002225189141077, Precision = 0.9995551601423488, f1 = 0.999777530589544\n",
      "Epoch 77: Train Loss = 0.014641270418636896, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 78: Train Loss = 0.01494023533853813, Recall = 1.0, Aging Rate = 0.5002225189141077, Precision = 0.9995551601423488, f1 = 0.999777530589544\n",
      "Epoch 79: Train Loss = 0.014606643035430933, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 80: Train Loss = 0.014713601522150972, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.013819845261497396, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 81: Train Loss = 0.014644445354905614, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 82: Train Loss = 0.014637380666802022, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 83: Train Loss = 0.014548247546192987, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 84: Train Loss = 0.014940298908867992, Recall = 1.0, Aging Rate = 0.5002225189141077, Precision = 0.9995551601423488, f1 = 0.999777530589544\n",
      "Epoch 85: Train Loss = 0.014760984523154705, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.013573835734452042, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 86: Train Loss = 0.014859940882185313, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 87: Train Loss = 0.014825557514405086, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 88: Train Loss = 0.014381972305695507, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 89: Train Loss = 0.01461606098585159, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 90: Train Loss = 0.014864311195432503, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.013409858021154025, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Training Finished at epoch 90.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f47fef2d65fc4b01baeafb1866fdea3c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3edf1648e95f45b8bc38643ce9d91000",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss = 0.581690652067902, Recall = 0.9299820466786356, Aging Rate = 0.8666219839142091, Precision = 0.534158288218613, f1 = 0.6785655804814148\n",
      "Epoch 2: Train Loss = 0.3835749322010855, Recall = 0.9340215439856373, Aging Rate = 0.6400804289544236, Precision = 0.7263525305410122, f1 = 0.8172000785391713\n",
      "Epoch 3: Train Loss = 0.2814991812390659, Recall = 0.9515260323159784, Aging Rate = 0.5869079535299374, Precision = 0.8070041872858774, f1 = 0.8733264675592174\n",
      "Epoch 4: Train Loss = 0.2153251271252125, Recall = 0.9645421903052065, Aging Rate = 0.5598748882931188, Precision = 0.8575418994413407, f1 = 0.9079002957329954\n",
      "Epoch 5: Train Loss = 0.16637670561684573, Recall = 0.9721723518850988, Aging Rate = 0.5344057193923145, Precision = 0.9055183946488294, f1 = 0.9376623376623376\n",
      "Test Loss = 0.1280578344833968, Recall = 0.9887791741472173, Aging Rate = 0.5346291331546024, precision = 0.9206017551190974\n",
      "Model in epoch 5 is saved.\n",
      "\n",
      "Epoch 6: Train Loss = 0.11604829193812806, Recall = 0.9851885098743267, Aging Rate = 0.5236818588025023, Precision = 0.9364334470989761, f1 = 0.9601924759405074\n",
      "Epoch 7: Train Loss = 0.08721674643490226, Recall = 0.9923698384201077, Aging Rate = 0.5151921358355674, Precision = 0.9588031222896791, f1 = 0.9752977503308337\n",
      "Epoch 8: Train Loss = 0.06763826901387752, Recall = 0.9950628366247756, Aging Rate = 0.5084897229669347, Precision = 0.9740773286467487, f1 = 0.9844582593250444\n",
      "Epoch 9: Train Loss = 0.05324331706954071, Recall = 0.9968581687612208, Aging Rate = 0.5060321715817694, Precision = 0.9805739514348786, f1 = 0.9886490095704429\n",
      "Epoch 10: Train Loss = 0.042369893539806795, Recall = 0.9982046678635548, Aging Rate = 0.5031277926720286, Precision = 0.9875666074600356, f1 = 0.9928571428571429\n",
      "Test Loss = 0.036555896372508535, Recall = 0.9964093357271095, Aging Rate = 0.49977658623771226, precision = 0.9924005364327224\n",
      "Model in epoch 10 is saved.\n",
      "\n",
      "Epoch 11: Train Loss = 0.034937857366412535, Recall = 0.998653500897666, Aging Rate = 0.5022341376228776, Precision = 0.9897686832740213, f1 = 0.9941912421805182\n",
      "Epoch 12: Train Loss = 0.028553004365770598, Recall = 1.0, Aging Rate = 0.5022341376228776, Precision = 0.9911032028469751, f1 = 0.9955317247542449\n",
      "Epoch 13: Train Loss = 0.023570320896897548, Recall = 0.9995511669658886, Aging Rate = 0.5004468275245755, Precision = 0.9941964285714285, f1 = 0.9968666069829901\n",
      "Epoch 14: Train Loss = 0.020028277414320728, Recall = 1.0, Aging Rate = 0.49977658623771226, Precision = 0.9959767545820295, f1 = 0.9979843225083986\n",
      "Epoch 15: Train Loss = 0.01734441030900376, Recall = 1.0, Aging Rate = 0.49955317247542447, Precision = 0.9964221824686941, f1 = 0.9982078853046595\n",
      "Test Loss = 0.015103414215287318, Recall = 1.0, Aging Rate = 0.49865951742627346, precision = 0.9982078853046595\n",
      "Model in epoch 15 is saved.\n",
      "\n",
      "Epoch 16: Train Loss = 0.015318039593297632, Recall = 1.0, Aging Rate = 0.499106344950849, Precision = 0.9973142345568488, f1 = 0.9986553115194979\n",
      "Epoch 17: Train Loss = 0.013042851561768659, Recall = 1.0, Aging Rate = 0.4988829311885612, Precision = 0.9977608598298253, f1 = 0.9988791750728536\n",
      "Epoch 18: Train Loss = 0.01165746259682007, Recall = 1.0, Aging Rate = 0.49865951742627346, Precision = 0.9982078853046595, f1 = 0.9991031390134528\n",
      "Epoch 19: Train Loss = 0.010148167906460536, Recall = 1.0, Aging Rate = 0.4982126899016979, Precision = 0.9991031390134529, f1 = 0.9995513683266039\n",
      "Epoch 20: Train Loss = 0.008848660757850067, Recall = 1.0, Aging Rate = 0.4982126899016979, Precision = 0.9991031390134529, f1 = 0.9995513683266039\n",
      "Test Loss = 0.007684766079388206, Recall = 1.0, Aging Rate = 0.4982126899016979, precision = 0.9991031390134529\n",
      "Model in epoch 20 is saved.\n",
      "\n",
      "Epoch 21: Train Loss = 0.0079695001058114, Recall = 1.0, Aging Rate = 0.4984361036639857, Precision = 0.9986553115194979, f1 = 0.999327203408836\n",
      "Epoch 22: Train Loss = 0.007283645893644352, Recall = 1.0, Aging Rate = 0.4982126899016979, Precision = 0.9991031390134529, f1 = 0.9995513683266039\n",
      "Epoch 23: Train Loss = 0.006665194710888055, Recall = 1.0, Aging Rate = 0.4982126899016979, Precision = 0.9991031390134529, f1 = 0.9995513683266039\n",
      "Epoch 24: Train Loss = 0.006087418350992829, Recall = 1.0, Aging Rate = 0.4982126899016979, Precision = 0.9991031390134529, f1 = 0.9995513683266039\n",
      "Epoch 25: Train Loss = 0.005493588334447151, Recall = 1.0, Aging Rate = 0.4982126899016979, Precision = 0.9991031390134529, f1 = 0.9995513683266039\n",
      "Test Loss = 0.005158359458265532, Recall = 1.0, Aging Rate = 0.4979892761394102, precision = 0.9995513683266039\n",
      "Model in epoch 25 is saved.\n",
      "\n",
      "Epoch 26: Train Loss = 0.005054316125140993, Recall = 1.0, Aging Rate = 0.4979892761394102, Precision = 0.9995513683266039, f1 = 0.9997756338344178\n",
      "Epoch 27: Train Loss = 0.004532382138351426, Recall = 1.0, Aging Rate = 0.4979892761394102, Precision = 0.9995513683266039, f1 = 0.9997756338344178\n",
      "Epoch 28: Train Loss = 0.004167370224776041, Recall = 1.0, Aging Rate = 0.4979892761394102, Precision = 0.9995513683266039, f1 = 0.9997756338344178\n",
      "Epoch 29: Train Loss = 0.003923625785356406, Recall = 1.0, Aging Rate = 0.4979892761394102, Precision = 0.9995513683266039, f1 = 0.9997756338344178\n",
      "Epoch 30: Train Loss = 0.0037705597925058983, Recall = 1.0, Aging Rate = 0.4979892761394102, Precision = 0.9995513683266039, f1 = 0.9997756338344178\n",
      "Test Loss = 0.003171504826607038, Recall = 1.0, Aging Rate = 0.4979892761394102, precision = 0.9995513683266039\n",
      "\n",
      "Epoch 31: Train Loss = 0.0034430830552591423, Recall = 1.0, Aging Rate = 0.4979892761394102, Precision = 0.9995513683266039, f1 = 0.9997756338344178\n",
      "Epoch 32: Train Loss = 0.0032911401909299135, Recall = 1.0, Aging Rate = 0.4979892761394102, Precision = 0.9995513683266039, f1 = 0.9997756338344178\n",
      "Epoch 33: Train Loss = 0.0031873888882930734, Recall = 1.0, Aging Rate = 0.49776586237712245, Precision = 0, f1 = 0.0\n",
      "Epoch 34: Train Loss = 0.002892282868421722, Recall = 1.0, Aging Rate = 0.49776586237712245, Precision = 0, f1 = 0.0\n",
      "Epoch 35: Train Loss = 0.0028891222783671467, Recall = 1.0, Aging Rate = 0.49776586237712245, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0024823065085829276, Recall = 1.0, Aging Rate = 0.49776586237712245, precision = 1.0\n",
      "Model in epoch 35 is saved.\n",
      "\n",
      "Epoch 36: Train Loss = 0.00257821623816457, Recall = 1.0, Aging Rate = 0.49776586237712245, Precision = 0, f1 = 0.0\n",
      "Epoch 37: Train Loss = 0.002466495932430242, Recall = 1.0, Aging Rate = 0.49776586237712245, Precision = 0, f1 = 0.0\n",
      "Epoch 38: Train Loss = 0.0023407512741834193, Recall = 1.0, Aging Rate = 0.49776586237712245, Precision = 0, f1 = 0.0\n",
      "Epoch 39: Train Loss = 0.0022414249242753643, Recall = 1.0, Aging Rate = 0.49776586237712245, Precision = 0, f1 = 0.0\n",
      "Epoch 40: Train Loss = 0.0022689269868518833, Recall = 1.0, Aging Rate = 0.49776586237712245, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.002139740540721754, Recall = 1.0, Aging Rate = 0.49776586237712245, precision = 1.0\n",
      "\n",
      "Epoch 41: Train Loss = 0.0021927788809118286, Recall = 1.0, Aging Rate = 0.49776586237712245, Precision = 0, f1 = 0.0\n",
      "Epoch 42: Train Loss = 0.0021056697319592147, Recall = 1.0, Aging Rate = 0.49776586237712245, Precision = 0, f1 = 0.0\n",
      "Epoch 43: Train Loss = 0.002057930024010333, Recall = 1.0, Aging Rate = 0.49776586237712245, Precision = 0, f1 = 0.0\n",
      "Epoch 44: Train Loss = 0.0020356479819141613, Recall = 1.0, Aging Rate = 0.49776586237712245, Precision = 0, f1 = 0.0\n",
      "Epoch 45: Train Loss = 0.0019984300222524154, Recall = 1.0, Aging Rate = 0.49776586237712245, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0016751580932398158, Recall = 1.0, Aging Rate = 0.49776586237712245, precision = 1.0\n",
      "\n",
      "Epoch 46: Train Loss = 0.0018906602176144334, Recall = 1.0, Aging Rate = 0.49776586237712245, Precision = 0, f1 = 0.0\n",
      "Epoch 47: Train Loss = 0.0019849493247673243, Recall = 1.0, Aging Rate = 0.49776586237712245, Precision = 0, f1 = 0.0\n",
      "Epoch 48: Train Loss = 0.0018640751528060122, Recall = 1.0, Aging Rate = 0.49776586237712245, Precision = 0, f1 = 0.0\n",
      "Epoch 49: Train Loss = 0.0018621097377920066, Recall = 1.0, Aging Rate = 0.49776586237712245, Precision = 0, f1 = 0.0\n",
      "Epoch 50: Train Loss = 0.0017609145222656209, Recall = 1.0, Aging Rate = 0.49776586237712245, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0022478904977725474, Recall = 1.0, Aging Rate = 0.49776586237712245, precision = 1.0\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 51: Train Loss = 0.0018056444746755908, Recall = 1.0, Aging Rate = 0.49776586237712245, Precision = 0, f1 = 0.0\n",
      "Epoch 52: Train Loss = 0.001811700118041886, Recall = 1.0, Aging Rate = 0.49776586237712245, Precision = 0, f1 = 0.0\n",
      "Epoch 53: Train Loss = 0.0017783187899465562, Recall = 1.0, Aging Rate = 0.49776586237712245, Precision = 0, f1 = 0.0\n",
      "Epoch 54: Train Loss = 0.0017950082542349762, Recall = 1.0, Aging Rate = 0.49776586237712245, Precision = 0, f1 = 0.0\n",
      "Epoch 55: Train Loss = 0.001855394649743814, Recall = 1.0, Aging Rate = 0.49776586237712245, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0014804551436984454, Recall = 1.0, Aging Rate = 0.49776586237712245, precision = 1.0\n",
      "\n",
      "Epoch 56: Train Loss = 0.0017697643022568125, Recall = 1.0, Aging Rate = 0.49776586237712245, Precision = 0, f1 = 0.0\n",
      "Epoch 57: Train Loss = 0.0016613611869282614, Recall = 1.0, Aging Rate = 0.49776586237712245, Precision = 0, f1 = 0.0\n",
      "Epoch 58: Train Loss = 0.0016619479760171395, Recall = 1.0, Aging Rate = 0.49776586237712245, Precision = 0, f1 = 0.0\n",
      "Epoch 59: Train Loss = 0.0016816347854926024, Recall = 1.0, Aging Rate = 0.49776586237712245, Precision = 0, f1 = 0.0\n",
      "Epoch 60: Train Loss = 0.0016983329439976846, Recall = 1.0, Aging Rate = 0.49776586237712245, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.001963377670552232, Recall = 1.0, Aging Rate = 0.49776586237712245, precision = 1.0\n",
      "\n",
      "Epoch 61: Train Loss = 0.0017403125041663826, Recall = 1.0, Aging Rate = 0.49776586237712245, Precision = 0, f1 = 0.0\n",
      "Epoch 62: Train Loss = 0.0018293293479287379, Recall = 1.0, Aging Rate = 0.49776586237712245, Precision = 0, f1 = 0.0\n",
      "Epoch 63: Train Loss = 0.001642509012577108, Recall = 1.0, Aging Rate = 0.49776586237712245, Precision = 0, f1 = 0.0\n",
      "Epoch 64: Train Loss = 0.001544279409439317, Recall = 1.0, Aging Rate = 0.49776586237712245, Precision = 0, f1 = 0.0\n",
      "Epoch 65: Train Loss = 0.0015651100837201933, Recall = 1.0, Aging Rate = 0.49776586237712245, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0013247487192242751, Recall = 1.0, Aging Rate = 0.49776586237712245, precision = 1.0\n",
      "\n",
      "Epoch 66: Train Loss = 0.0021627144665408203, Recall = 1.0, Aging Rate = 0.49776586237712245, Precision = 0, f1 = 0.0\n",
      "Epoch 67: Train Loss = 0.0015756161422597725, Recall = 1.0, Aging Rate = 0.49776586237712245, Precision = 0, f1 = 0.0\n",
      "Epoch 68: Train Loss = 0.0014317807945059954, Recall = 1.0, Aging Rate = 0.49776586237712245, Precision = 0, f1 = 0.0\n",
      "Epoch 69: Train Loss = 0.0014561774872677855, Recall = 1.0, Aging Rate = 0.49776586237712245, Precision = 0, f1 = 0.0\n",
      "Epoch 70: Train Loss = 0.0014454958790004373, Recall = 1.0, Aging Rate = 0.49776586237712245, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.001414362286807182, Recall = 1.0, Aging Rate = 0.49776586237712245, precision = 1.0\n",
      "\n",
      "Epoch 71: Train Loss = 0.001555602591804381, Recall = 1.0, Aging Rate = 0.49776586237712245, Precision = 0, f1 = 0.0\n",
      "Epoch 72: Train Loss = 0.001568366925838013, Recall = 1.0, Aging Rate = 0.49776586237712245, Precision = 0, f1 = 0.0\n",
      "Epoch 73: Train Loss = 0.0015038505080156028, Recall = 1.0, Aging Rate = 0.49776586237712245, Precision = 0, f1 = 0.0\n",
      "Epoch 74: Train Loss = 0.0016405057520759597, Recall = 1.0, Aging Rate = 0.49776586237712245, Precision = 0, f1 = 0.0\n",
      "Epoch 75: Train Loss = 0.001595967118936267, Recall = 1.0, Aging Rate = 0.49776586237712245, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0014456849026313124, Recall = 1.0, Aging Rate = 0.49776586237712245, precision = 1.0\n",
      "\n",
      "Epoch 76: Train Loss = 0.0020143101322676877, Recall = 1.0, Aging Rate = 0.49776586237712245, Precision = 0, f1 = 0.0\n",
      "Epoch 77: Train Loss = 0.002129976243368276, Recall = 1.0, Aging Rate = 0.4979892761394102, Precision = 0.9995513683266039, f1 = 0.9997756338344178\n",
      "Epoch 78: Train Loss = 0.001453792019919896, Recall = 1.0, Aging Rate = 0.49776586237712245, Precision = 0, f1 = 0.0\n",
      "Epoch 79: Train Loss = 0.0013239240685084183, Recall = 1.0, Aging Rate = 0.49776586237712245, Precision = 0, f1 = 0.0\n",
      "Epoch 80: Train Loss = 0.0014772751219603929, Recall = 1.0, Aging Rate = 0.49776586237712245, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0014757379606304569, Recall = 1.0, Aging Rate = 0.49776586237712245, precision = 1.0\n",
      "\n",
      "Epoch 81: Train Loss = 0.0015570622801421156, Recall = 1.0, Aging Rate = 0.49776586237712245, Precision = 0, f1 = 0.0\n",
      "Epoch 82: Train Loss = 0.0014777447491712782, Recall = 1.0, Aging Rate = 0.49776586237712245, Precision = 0, f1 = 0.0\n",
      "Epoch 83: Train Loss = 0.001811898710460829, Recall = 1.0, Aging Rate = 0.49776586237712245, Precision = 0, f1 = 0.0\n",
      "Epoch 84: Train Loss = 0.0016668235537824093, Recall = 1.0, Aging Rate = 0.49776586237712245, Precision = 0, f1 = 0.0\n",
      "Epoch 85: Train Loss = 0.0013664069240001448, Recall = 1.0, Aging Rate = 0.49776586237712245, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0013185420616216113, Recall = 1.0, Aging Rate = 0.49776586237712245, precision = 1.0\n",
      "\n",
      "Training Finished at epoch 85.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd1d7aab3ebe4aa2bea1beab77a6c4d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss = 0.5547954654627006, Recall = 0.9838347552761563, Aging Rate = 0.9126256983240223, Precision = 0.5364838393731636, f1 = 0.6943432102677864\n",
      "Epoch 2: Train Loss = 0.3658930705978884, Recall = 0.9357880556802873, Aging Rate = 0.6308379888268156, Precision = 0.7382217499114417, f1 = 0.8253465346534653\n",
      "Epoch 3: Train Loss = 0.2736594035105998, Recall = 0.9519533004041311, Aging Rate = 0.5818994413407821, Precision = 0.8141321044546851, f1 = 0.8776650796936452\n",
      "Epoch 4: Train Loss = 0.20739800790834692, Recall = 0.9649753030983386, Aging Rate = 0.5564245810055866, Precision = 0.8630522088353414, f1 = 0.9111723553105788\n",
      "Epoch 5: Train Loss = 0.16294418557396148, Recall = 0.9775482712168837, Aging Rate = 0.5401117318435754, Precision = 0.9007033512618949, f1 = 0.9375538329026701\n",
      "Test Loss = 0.12700874100517295, Recall = 0.9910193084867535, Aging Rate = 0.5387709497206704, precision = 0.9153878058896724\n",
      "Model in epoch 5 is saved.\n",
      "\n",
      "Epoch 6: Train Loss = 0.11226928868273783, Recall = 0.9905702739110912, Aging Rate = 0.5242458100558659, Precision = 0.9403239556692242, f1 = 0.964793352285152\n",
      "Epoch 7: Train Loss = 0.08589156981953029, Recall = 0.9941625505163898, Aging Rate = 0.5182122905027933, Precision = 0.9547218628719275, f1 = 0.9740431148262207\n",
      "Epoch 8: Train Loss = 0.0663005132065805, Recall = 0.997305792546026, Aging Rate = 0.5108379888268156, Precision = 0.9715660542432196, f1 = 0.9842676711721693\n",
      "Epoch 9: Train Loss = 0.05226965644589349, Recall = 0.998652896273013, Aging Rate = 0.5077094972067039, Precision = 0.9788732394366197, f1 = 0.988664147588353\n",
      "Epoch 10: Train Loss = 0.041561858391795076, Recall = 0.9995509654243376, Aging Rate = 0.5056983240223464, Precision = 0.9836500220945648, f1 = 0.9915367483296215\n",
      "Test Loss = 0.03464820925957997, Recall = 1.0, Aging Rate = 0.5030167597765363, precision = 0.9893380719680143\n",
      "Model in epoch 10 is saved.\n",
      "\n",
      "Epoch 11: Train Loss = 0.03447076950576052, Recall = 0.9995509654243376, Aging Rate = 0.5027932960893855, Precision = 0.9893333333333333, f1 = 0.9944159035068125\n",
      "Epoch 12: Train Loss = 0.028095327413448407, Recall = 1.0, Aging Rate = 0.5012290502793296, Precision = 0.992866696388765, f1 = 0.9964205816554809\n",
      "Epoch 13: Train Loss = 0.023489118833823243, Recall = 1.0, Aging Rate = 0.5001117318435754, Precision = 0.9950848972296693, f1 = 0.9975363941769316\n",
      "Epoch 14: Train Loss = 0.019412669492000975, Recall = 1.0, Aging Rate = 0.49966480446927375, Precision = 0.9959749552772809, f1 = 0.9979834192247368\n",
      "Epoch 15: Train Loss = 0.016978975249943455, Recall = 1.0, Aging Rate = 0.4994413407821229, Precision = 0.996420581655481, f1 = 0.9982070820259973\n",
      "Test Loss = 0.014507957570379672, Recall = 1.0, Aging Rate = 0.4987709497206704, precision = 0.9977598566308243\n",
      "Model in epoch 15 is saved.\n",
      "\n",
      "Epoch 16: Train Loss = 0.01437888184655978, Recall = 1.0, Aging Rate = 0.4987709497206704, Precision = 0.9977598566308243, f1 = 0.99887867234806\n",
      "Epoch 17: Train Loss = 0.012508682534931093, Recall = 1.0, Aging Rate = 0.49854748603351956, Precision = 0.9982070820259973, f1 = 0.9991027366532077\n",
      "Epoch 18: Train Loss = 0.011104625990645512, Recall = 1.0, Aging Rate = 0.49854748603351956, Precision = 0.9982070820259973, f1 = 0.9991027366532077\n",
      "Epoch 19: Train Loss = 0.009585953899997406, Recall = 1.0, Aging Rate = 0.4981005586592179, Precision = 0.9991027366532077, f1 = 0.9995511669658886\n",
      "Epoch 20: Train Loss = 0.008517779384703276, Recall = 1.0, Aging Rate = 0.4983240223463687, Precision = 0.9986547085201793, f1 = 0.9993269015032533\n",
      "Test Loss = 0.007325613300768689, Recall = 1.0, Aging Rate = 0.49787709497206706, precision = 0.9995511669658886\n",
      "Model in epoch 20 is saved.\n",
      "\n",
      "Epoch 21: Train Loss = 0.007648697092650489, Recall = 1.0, Aging Rate = 0.4983240223463687, Precision = 0.9986547085201793, f1 = 0.9993269015032533\n",
      "Epoch 22: Train Loss = 0.006973108759919941, Recall = 1.0, Aging Rate = 0.49787709497206706, Precision = 0.9995511669658886, f1 = 0.9997755331088665\n",
      "Epoch 23: Train Loss = 0.006137621434166112, Recall = 1.0, Aging Rate = 0.4981005586592179, Precision = 0.9991027366532077, f1 = 0.9995511669658886\n",
      "Epoch 24: Train Loss = 0.005574412182202386, Recall = 1.0, Aging Rate = 0.49787709497206706, Precision = 0.9995511669658886, f1 = 0.9997755331088665\n",
      "Epoch 25: Train Loss = 0.005215300304305287, Recall = 1.0, Aging Rate = 0.49787709497206706, Precision = 0.9995511669658886, f1 = 0.9997755331088665\n",
      "Test Loss = 0.004468160678200715, Recall = 1.0, Aging Rate = 0.4976536312849162, precision = 1.0\n",
      "Model in epoch 25 is saved.\n",
      "\n",
      "Epoch 26: Train Loss = 0.004607172426013224, Recall = 1.0, Aging Rate = 0.4976536312849162, Precision = 0, f1 = 0.0\n",
      "Epoch 27: Train Loss = 0.004327268007539171, Recall = 1.0, Aging Rate = 0.4976536312849162, Precision = 0, f1 = 0.0\n",
      "Epoch 28: Train Loss = 0.004050200155717659, Recall = 1.0, Aging Rate = 0.49787709497206706, Precision = 0.9995511669658886, f1 = 0.9997755331088665\n",
      "Epoch 29: Train Loss = 0.003823808203113146, Recall = 1.0, Aging Rate = 0.4976536312849162, Precision = 0, f1 = 0.0\n",
      "Epoch 30: Train Loss = 0.003539898424154387, Recall = 1.0, Aging Rate = 0.4976536312849162, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.003044445582733141, Recall = 1.0, Aging Rate = 0.4976536312849162, precision = 1.0\n",
      "\n",
      "Epoch 31: Train Loss = 0.003201696944407411, Recall = 1.0, Aging Rate = 0.4976536312849162, Precision = 0, f1 = 0.0\n",
      "Epoch 32: Train Loss = 0.003071419632260027, Recall = 1.0, Aging Rate = 0.4976536312849162, Precision = 0, f1 = 0.0\n",
      "Epoch 33: Train Loss = 0.0029324473403186105, Recall = 1.0, Aging Rate = 0.4976536312849162, Precision = 0, f1 = 0.0\n",
      "Epoch 34: Train Loss = 0.0027544499392616016, Recall = 1.0, Aging Rate = 0.4976536312849162, Precision = 0, f1 = 0.0\n",
      "Epoch 35: Train Loss = 0.0027176327965425214, Recall = 1.0, Aging Rate = 0.4976536312849162, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.002447335490795612, Recall = 1.0, Aging Rate = 0.4976536312849162, precision = 1.0\n",
      "\n",
      "Epoch 36: Train Loss = 0.002432032370414356, Recall = 1.0, Aging Rate = 0.4976536312849162, Precision = 0, f1 = 0.0\n",
      "Epoch 37: Train Loss = 0.002373784619445949, Recall = 1.0, Aging Rate = 0.4976536312849162, Precision = 0, f1 = 0.0\n",
      "Epoch 38: Train Loss = 0.002313919792877895, Recall = 1.0, Aging Rate = 0.4976536312849162, Precision = 0, f1 = 0.0\n",
      "Epoch 39: Train Loss = 0.0022392240517861185, Recall = 1.0, Aging Rate = 0.4976536312849162, Precision = 0, f1 = 0.0\n",
      "Epoch 40: Train Loss = 0.0021730088728724576, Recall = 1.0, Aging Rate = 0.4976536312849162, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0018816759072597966, Recall = 1.0, Aging Rate = 0.4976536312849162, precision = 1.0\n",
      "\n",
      "Epoch 41: Train Loss = 0.0020724867822019665, Recall = 1.0, Aging Rate = 0.4976536312849162, Precision = 0, f1 = 0.0\n",
      "Epoch 42: Train Loss = 0.0019865880560067445, Recall = 1.0, Aging Rate = 0.4976536312849162, Precision = 0, f1 = 0.0\n",
      "Epoch 43: Train Loss = 0.0021387398101691177, Recall = 1.0, Aging Rate = 0.4976536312849162, Precision = 0, f1 = 0.0\n",
      "Epoch 44: Train Loss = 0.0019537285392240275, Recall = 1.0, Aging Rate = 0.4976536312849162, Precision = 0, f1 = 0.0\n",
      "Epoch 45: Train Loss = 0.001972667605709805, Recall = 1.0, Aging Rate = 0.4976536312849162, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0017981317910943284, Recall = 1.0, Aging Rate = 0.4976536312849162, precision = 1.0\n",
      "\n",
      "Epoch 46: Train Loss = 0.001919382883381494, Recall = 1.0, Aging Rate = 0.4976536312849162, Precision = 0, f1 = 0.0\n",
      "Epoch 47: Train Loss = 0.0020037828963614126, Recall = 1.0, Aging Rate = 0.4976536312849162, Precision = 0, f1 = 0.0\n",
      "Epoch 48: Train Loss = 0.0019282357271646238, Recall = 1.0, Aging Rate = 0.4976536312849162, Precision = 0, f1 = 0.0\n",
      "Epoch 49: Train Loss = 0.0019576883250223107, Recall = 1.0, Aging Rate = 0.4976536312849162, Precision = 0, f1 = 0.0\n",
      "Epoch 50: Train Loss = 0.0017591291968840793, Recall = 1.0, Aging Rate = 0.4976536312849162, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.001520566223423366, Recall = 1.0, Aging Rate = 0.4976536312849162, precision = 1.0\n",
      "\n",
      "Epoch 51: Train Loss = 0.0017108162188663163, Recall = 1.0, Aging Rate = 0.4976536312849162, Precision = 0, f1 = 0.0\n",
      "Epoch 52: Train Loss = 0.001734117383095722, Recall = 1.0, Aging Rate = 0.4976536312849162, Precision = 0, f1 = 0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 53: Train Loss = 0.0018380804322972145, Recall = 1.0, Aging Rate = 0.4976536312849162, Precision = 0, f1 = 0.0\n",
      "Epoch 54: Train Loss = 0.0018819467359685533, Recall = 1.0, Aging Rate = 0.4976536312849162, Precision = 0, f1 = 0.0\n",
      "Epoch 55: Train Loss = 0.0016740879552522101, Recall = 1.0, Aging Rate = 0.4976536312849162, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0014328660288508252, Recall = 1.0, Aging Rate = 0.4976536312849162, precision = 1.0\n",
      "\n",
      "Epoch 56: Train Loss = 0.001773831688164208, Recall = 1.0, Aging Rate = 0.4976536312849162, Precision = 0, f1 = 0.0\n",
      "Epoch 57: Train Loss = 0.001775114651738182, Recall = 1.0, Aging Rate = 0.4976536312849162, Precision = 0, f1 = 0.0\n",
      "Epoch 58: Train Loss = 0.0018981215291963525, Recall = 1.0, Aging Rate = 0.4976536312849162, Precision = 0, f1 = 0.0\n",
      "Epoch 59: Train Loss = 0.0018021533384076293, Recall = 1.0, Aging Rate = 0.4976536312849162, Precision = 0, f1 = 0.0\n",
      "Epoch 60: Train Loss = 0.0015132425779700487, Recall = 1.0, Aging Rate = 0.4976536312849162, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0012965045176321567, Recall = 1.0, Aging Rate = 0.4976536312849162, precision = 1.0\n",
      "\n",
      "Epoch 61: Train Loss = 0.0015283096779408402, Recall = 1.0, Aging Rate = 0.4976536312849162, Precision = 0, f1 = 0.0\n",
      "Epoch 62: Train Loss = 0.0017880927793182142, Recall = 1.0, Aging Rate = 0.4976536312849162, Precision = 0, f1 = 0.0\n",
      "Epoch 63: Train Loss = 0.001749596777450106, Recall = 1.0, Aging Rate = 0.4976536312849162, Precision = 0, f1 = 0.0\n",
      "Epoch 64: Train Loss = 0.0014964668273759287, Recall = 1.0, Aging Rate = 0.4976536312849162, Precision = 0, f1 = 0.0\n",
      "Epoch 65: Train Loss = 0.0015599205021293802, Recall = 1.0, Aging Rate = 0.4976536312849162, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0014066218256731857, Recall = 1.0, Aging Rate = 0.4976536312849162, precision = 1.0\n",
      "\n",
      "Epoch 66: Train Loss = 0.0016454117630956976, Recall = 1.0, Aging Rate = 0.4976536312849162, Precision = 0, f1 = 0.0\n",
      "Epoch 67: Train Loss = 0.0019335056455837116, Recall = 1.0, Aging Rate = 0.4976536312849162, Precision = 0, f1 = 0.0\n",
      "Epoch 68: Train Loss = 0.0015119258857555897, Recall = 1.0, Aging Rate = 0.4976536312849162, Precision = 0, f1 = 0.0\n",
      "Epoch 69: Train Loss = 0.0016474486325019399, Recall = 1.0, Aging Rate = 0.4976536312849162, Precision = 0, f1 = 0.0\n",
      "Epoch 70: Train Loss = 0.0015018911245955394, Recall = 1.0, Aging Rate = 0.4976536312849162, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0017332697981791623, Recall = 1.0, Aging Rate = 0.4976536312849162, precision = 1.0\n",
      "\n",
      "Epoch 71: Train Loss = 0.001558735869127695, Recall = 1.0, Aging Rate = 0.4976536312849162, Precision = 0, f1 = 0.0\n",
      "Epoch 72: Train Loss = 0.0015125945181060354, Recall = 1.0, Aging Rate = 0.4976536312849162, Precision = 0, f1 = 0.0\n",
      "Epoch 73: Train Loss = 0.0016681868827501155, Recall = 1.0, Aging Rate = 0.4976536312849162, Precision = 0, f1 = 0.0\n",
      "Epoch 74: Train Loss = 0.001956277071672632, Recall = 1.0, Aging Rate = 0.4976536312849162, Precision = 0, f1 = 0.0\n",
      "Epoch 75: Train Loss = 0.0025867762195997397, Recall = 0.9995509654243376, Aging Rate = 0.4976536312849162, Precision = 0.9995509654243376, f1 = 0.9995509654243376\n",
      "Test Loss = 0.0066513928252287914, Recall = 1.0, Aging Rate = 0.49921787709497206, precision = 0.9968666069829901\n",
      "\n",
      "Training Finished at epoch 75.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "04750e5239824616b272c0e18a1ca01d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss = 0.5560316712097083, Recall = 0.9726088908845981, Aging Rate = 0.8831284916201118, Precision = 0.5480769230769231, f1 = 0.7010843178507851\n",
      "Epoch 2: Train Loss = 0.36657457703984647, Recall = 0.939380332285586, Aging Rate = 0.6324022346368715, Precision = 0.7392226148409894, f1 = 0.8273680047458967\n",
      "Epoch 3: Train Loss = 0.2717671618215199, Recall = 0.9564436461607544, Aging Rate = 0.5836871508379888, Precision = 0.8154670750382849, f1 = 0.8803471791692499\n",
      "Epoch 4: Train Loss = 0.21106477903254206, Recall = 0.9726088908845981, Aging Rate = 0.5653631284916201, Precision = 0.8561264822134388, f1 = 0.9106579777170486\n",
      "Epoch 5: Train Loss = 0.16736552667018423, Recall = 0.9739559946115851, Aging Rate = 0.5439106145251397, Precision = 0.891125718981101, f1 = 0.9307015661875133\n",
      "Test Loss = 0.12913757712314916, Recall = 0.9928154467894028, Aging Rate = 0.5354189944134078, precision = 0.922787979966611\n",
      "Model in epoch 5 is saved.\n",
      "\n",
      "Epoch 6: Train Loss = 0.11681850675431044, Recall = 0.9905702739110912, Aging Rate = 0.5255865921787709, Precision = 0.9379251700680272, f1 = 0.9635291548373007\n",
      "Epoch 7: Train Loss = 0.08873553957769324, Recall = 0.9941625505163898, Aging Rate = 0.515754189944134, Precision = 0.9592720970537262, f1 = 0.9764057331863286\n",
      "Epoch 8: Train Loss = 0.06915574555956451, Recall = 0.9950606196677144, Aging Rate = 0.5112849162011173, Precision = 0.9685314685314685, f1 = 0.9816168327796235\n",
      "Epoch 9: Train Loss = 0.054003529987355185, Recall = 0.997305792546026, Aging Rate = 0.5074860335195531, Precision = 0.9779832672831352, f1 = 0.9875500222321032\n",
      "Epoch 10: Train Loss = 0.04375681160173936, Recall = 0.997305792546026, Aging Rate = 0.504804469273743, Precision = 0.983178397521027, f1 = 0.990191707534552\n",
      "Test Loss = 0.03729311951462117, Recall = 1.0, Aging Rate = 0.5050279329608939, precision = 0.9853982300884956\n",
      "Model in epoch 10 is saved.\n",
      "\n",
      "Epoch 11: Train Loss = 0.03551239476398716, Recall = 0.9995509654243376, Aging Rate = 0.503463687150838, Precision = 0.9880159786950732, f1 = 0.9937499999999999\n",
      "Epoch 12: Train Loss = 0.02967522492871604, Recall = 0.9991019308486754, Aging Rate = 0.5010055865921788, Precision = 0.9924174843889384, f1 = 0.9957484895949876\n",
      "Epoch 13: Train Loss = 0.02519495094205414, Recall = 0.9995509654243376, Aging Rate = 0.5001117318435754, Precision = 0.9946380697050938, f1 = 0.9970884658454647\n",
      "Epoch 14: Train Loss = 0.021054369321706908, Recall = 0.9995509654243376, Aging Rate = 0.49988826815642456, Precision = 0.9950827000447027, f1 = 0.9973118279569892\n",
      "Epoch 15: Train Loss = 0.018141754878965837, Recall = 1.0, Aging Rate = 0.5001117318435754, Precision = 0.9950848972296693, f1 = 0.9975363941769316\n",
      "Test Loss = 0.01613099031941185, Recall = 1.0, Aging Rate = 0.4983240223463687, precision = 0.9986547085201793\n",
      "Model in epoch 15 is saved.\n",
      "\n",
      "Epoch 16: Train Loss = 0.016004339293394676, Recall = 1.0, Aging Rate = 0.49921787709497206, Precision = 0.9968666069829901, f1 = 0.9984308451019951\n",
      "Epoch 17: Train Loss = 0.013584022666093524, Recall = 1.0, Aging Rate = 0.49854748603351956, Precision = 0.9982070820259973, f1 = 0.9991027366532077\n",
      "Epoch 18: Train Loss = 0.01248982387381559, Recall = 1.0, Aging Rate = 0.4987709497206704, Precision = 0.9977598566308243, f1 = 0.99887867234806\n",
      "Epoch 19: Train Loss = 0.010813585592527463, Recall = 1.0, Aging Rate = 0.49854748603351956, Precision = 0.9982070820259973, f1 = 0.9991027366532077\n",
      "Epoch 20: Train Loss = 0.009265700869844946, Recall = 1.0, Aging Rate = 0.4981005586592179, Precision = 0.9991027366532077, f1 = 0.9995511669658886\n",
      "Test Loss = 0.008227432333765416, Recall = 1.0, Aging Rate = 0.4983240223463687, precision = 0.9986547085201793\n",
      "\n",
      "Epoch 21: Train Loss = 0.008366777779919475, Recall = 1.0, Aging Rate = 0.4981005586592179, Precision = 0.9991027366532077, f1 = 0.9995511669658886\n",
      "Epoch 22: Train Loss = 0.007498207482816288, Recall = 1.0, Aging Rate = 0.4983240223463687, Precision = 0.9986547085201793, f1 = 0.9993269015032533\n",
      "Epoch 23: Train Loss = 0.006754572411489221, Recall = 1.0, Aging Rate = 0.4981005586592179, Precision = 0.9991027366532077, f1 = 0.9995511669658886\n",
      "Epoch 24: Train Loss = 0.006220575021423774, Recall = 1.0, Aging Rate = 0.4981005586592179, Precision = 0.9991027366532077, f1 = 0.9995511669658886\n",
      "Epoch 25: Train Loss = 0.005682292582685721, Recall = 1.0, Aging Rate = 0.49787709497206706, Precision = 0.9995511669658886, f1 = 0.9997755331088665\n",
      "Test Loss = 0.004964529305316674, Recall = 1.0, Aging Rate = 0.49787709497206706, precision = 0.9995511669658886\n",
      "Model in epoch 25 is saved.\n",
      "\n",
      "Epoch 26: Train Loss = 0.005256345359889489, Recall = 1.0, Aging Rate = 0.49787709497206706, Precision = 0.9995511669658886, f1 = 0.9997755331088665\n",
      "Epoch 27: Train Loss = 0.004824621497169553, Recall = 1.0, Aging Rate = 0.4976536312849162, Precision = 0, f1 = 0.0\n",
      "Epoch 28: Train Loss = 0.0043609473401649375, Recall = 1.0, Aging Rate = 0.49787709497206706, Precision = 0.9995511669658886, f1 = 0.9997755331088665\n",
      "Epoch 29: Train Loss = 0.004131813058213398, Recall = 1.0, Aging Rate = 0.49787709497206706, Precision = 0.9995511669658886, f1 = 0.9997755331088665\n",
      "Epoch 30: Train Loss = 0.003682745120815891, Recall = 1.0, Aging Rate = 0.4976536312849162, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.003327974865639676, Recall = 1.0, Aging Rate = 0.4976536312849162, precision = 1.0\n",
      "Model in epoch 30 is saved.\n",
      "\n",
      "Epoch 31: Train Loss = 0.003541838009867755, Recall = 1.0, Aging Rate = 0.4976536312849162, Precision = 0, f1 = 0.0\n",
      "Epoch 32: Train Loss = 0.003391062927187821, Recall = 1.0, Aging Rate = 0.4976536312849162, Precision = 0, f1 = 0.0\n",
      "Epoch 33: Train Loss = 0.0033627889444791405, Recall = 1.0, Aging Rate = 0.49787709497206706, Precision = 0.9995511669658886, f1 = 0.9997755331088665\n",
      "Epoch 34: Train Loss = 0.002878642699852919, Recall = 1.0, Aging Rate = 0.4976536312849162, Precision = 0, f1 = 0.0\n",
      "Epoch 35: Train Loss = 0.002746481917819331, Recall = 1.0, Aging Rate = 0.4976536312849162, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0024470724237760184, Recall = 1.0, Aging Rate = 0.4976536312849162, precision = 1.0\n",
      "\n",
      "Epoch 36: Train Loss = 0.0027154105987046017, Recall = 1.0, Aging Rate = 0.4976536312849162, Precision = 0, f1 = 0.0\n",
      "Epoch 37: Train Loss = 0.002541473679473447, Recall = 1.0, Aging Rate = 0.4976536312849162, Precision = 0, f1 = 0.0\n",
      "Epoch 38: Train Loss = 0.002450331398520057, Recall = 1.0, Aging Rate = 0.4976536312849162, Precision = 0, f1 = 0.0\n",
      "Epoch 39: Train Loss = 0.00245703396210499, Recall = 1.0, Aging Rate = 0.4976536312849162, Precision = 0, f1 = 0.0\n",
      "Epoch 40: Train Loss = 0.002246750648232312, Recall = 1.0, Aging Rate = 0.4976536312849162, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0019970001684574607, Recall = 1.0, Aging Rate = 0.4976536312849162, precision = 1.0\n",
      "\n",
      "Epoch 41: Train Loss = 0.0021845377523805843, Recall = 1.0, Aging Rate = 0.4976536312849162, Precision = 0, f1 = 0.0\n",
      "Epoch 42: Train Loss = 0.0022899858694648443, Recall = 1.0, Aging Rate = 0.4976536312849162, Precision = 0, f1 = 0.0\n",
      "Epoch 43: Train Loss = 0.0020985284914892145, Recall = 1.0, Aging Rate = 0.4976536312849162, Precision = 0, f1 = 0.0\n",
      "Epoch 44: Train Loss = 0.0020061922185747316, Recall = 1.0, Aging Rate = 0.4976536312849162, Precision = 0, f1 = 0.0\n",
      "Epoch 45: Train Loss = 0.001952081180370137, Recall = 1.0, Aging Rate = 0.4976536312849162, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0018226695997255475, Recall = 1.0, Aging Rate = 0.4976536312849162, precision = 1.0\n",
      "\n",
      "Epoch 46: Train Loss = 0.0020740080076431097, Recall = 1.0, Aging Rate = 0.4976536312849162, Precision = 0, f1 = 0.0\n",
      "Epoch 47: Train Loss = 0.0020390892662784325, Recall = 1.0, Aging Rate = 0.4976536312849162, Precision = 0, f1 = 0.0\n",
      "Epoch 48: Train Loss = 0.0018879223794691972, Recall = 1.0, Aging Rate = 0.4976536312849162, Precision = 0, f1 = 0.0\n",
      "Epoch 49: Train Loss = 0.002039585173671139, Recall = 1.0, Aging Rate = 0.4976536312849162, Precision = 0, f1 = 0.0\n",
      "Epoch 50: Train Loss = 0.0021321231374964536, Recall = 1.0, Aging Rate = 0.4976536312849162, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0030861718038762997, Recall = 1.0, Aging Rate = 0.49787709497206706, precision = 0.9995511669658886\n",
      "\n",
      "Epoch 51: Train Loss = 0.0020693820486542397, Recall = 1.0, Aging Rate = 0.4976536312849162, Precision = 0, f1 = 0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 52: Train Loss = 0.001669330504858169, Recall = 1.0, Aging Rate = 0.4976536312849162, Precision = 0, f1 = 0.0\n",
      "Epoch 53: Train Loss = 0.0018385955929111002, Recall = 1.0, Aging Rate = 0.4976536312849162, Precision = 0, f1 = 0.0\n",
      "Epoch 54: Train Loss = 0.001707881417037014, Recall = 1.0, Aging Rate = 0.4976536312849162, Precision = 0, f1 = 0.0\n",
      "Epoch 55: Train Loss = 0.001762729330891067, Recall = 1.0, Aging Rate = 0.4976536312849162, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0015375058106328855, Recall = 1.0, Aging Rate = 0.4976536312849162, precision = 1.0\n",
      "\n",
      "Epoch 56: Train Loss = 0.0017359363887063618, Recall = 1.0, Aging Rate = 0.4976536312849162, Precision = 0, f1 = 0.0\n",
      "Epoch 57: Train Loss = 0.0017216599040649123, Recall = 1.0, Aging Rate = 0.4976536312849162, Precision = 0, f1 = 0.0\n",
      "Epoch 58: Train Loss = 0.0016592169311625998, Recall = 1.0, Aging Rate = 0.4976536312849162, Precision = 0, f1 = 0.0\n",
      "Epoch 59: Train Loss = 0.0016035717226013375, Recall = 1.0, Aging Rate = 0.4976536312849162, Precision = 0, f1 = 0.0\n",
      "Epoch 60: Train Loss = 0.0016299983372849375, Recall = 1.0, Aging Rate = 0.4976536312849162, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0015363994254028249, Recall = 1.0, Aging Rate = 0.4976536312849162, precision = 1.0\n",
      "\n",
      "Epoch 61: Train Loss = 0.002180639313866889, Recall = 1.0, Aging Rate = 0.4976536312849162, Precision = 0, f1 = 0.0\n",
      "Epoch 62: Train Loss = 0.0017287522263034097, Recall = 1.0, Aging Rate = 0.4976536312849162, Precision = 0, f1 = 0.0\n",
      "Epoch 63: Train Loss = 0.0014759166400317707, Recall = 1.0, Aging Rate = 0.4976536312849162, Precision = 0, f1 = 0.0\n",
      "Epoch 64: Train Loss = 0.00159032290117222, Recall = 1.0, Aging Rate = 0.4976536312849162, Precision = 0, f1 = 0.0\n",
      "Epoch 65: Train Loss = 0.0017642953945323824, Recall = 1.0, Aging Rate = 0.4976536312849162, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0015642223707478305, Recall = 1.0, Aging Rate = 0.4976536312849162, precision = 1.0\n",
      "\n",
      "Epoch 66: Train Loss = 0.0016419472786800822, Recall = 1.0, Aging Rate = 0.4976536312849162, Precision = 0, f1 = 0.0\n",
      "Epoch 67: Train Loss = 0.0015434152255219787, Recall = 1.0, Aging Rate = 0.4976536312849162, Precision = 0, f1 = 0.0\n",
      "Epoch 68: Train Loss = 0.001836194289359134, Recall = 1.0, Aging Rate = 0.4976536312849162, Precision = 0, f1 = 0.0\n",
      "Epoch 69: Train Loss = 0.002224585152538129, Recall = 1.0, Aging Rate = 0.49787709497206706, Precision = 0.9995511669658886, f1 = 0.9997755331088665\n",
      "Epoch 70: Train Loss = 0.0025870636976506123, Recall = 1.0, Aging Rate = 0.49787709497206706, Precision = 0.9995511669658886, f1 = 0.9997755331088665\n",
      "Test Loss = 0.0042308162485754025, Recall = 1.0, Aging Rate = 0.4976536312849162, precision = 1.0\n",
      "\n",
      "Epoch 71: Train Loss = 0.0020977116372129312, Recall = 1.0, Aging Rate = 0.4976536312849162, Precision = 0, f1 = 0.0\n",
      "Epoch 72: Train Loss = 0.0012758014584740613, Recall = 1.0, Aging Rate = 0.4976536312849162, Precision = 0, f1 = 0.0\n",
      "Epoch 73: Train Loss = 0.0013006132147561072, Recall = 1.0, Aging Rate = 0.4976536312849162, Precision = 0, f1 = 0.0\n",
      "Epoch 74: Train Loss = 0.0013443653412454622, Recall = 1.0, Aging Rate = 0.4976536312849162, Precision = 0, f1 = 0.0\n",
      "Epoch 75: Train Loss = 0.0014237926538263619, Recall = 1.0, Aging Rate = 0.4976536312849162, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0013067219101605345, Recall = 1.0, Aging Rate = 0.4976536312849162, precision = 1.0\n",
      "\n",
      "Epoch 76: Train Loss = 0.001460829406570872, Recall = 1.0, Aging Rate = 0.4976536312849162, Precision = 0, f1 = 0.0\n",
      "Epoch 77: Train Loss = 0.0015782703328929718, Recall = 1.0, Aging Rate = 0.4976536312849162, Precision = 0, f1 = 0.0\n",
      "Epoch 78: Train Loss = 0.0014704757084674591, Recall = 1.0, Aging Rate = 0.4976536312849162, Precision = 0, f1 = 0.0\n",
      "Epoch 79: Train Loss = 0.001683020771210545, Recall = 1.0, Aging Rate = 0.4976536312849162, Precision = 0, f1 = 0.0\n",
      "Epoch 80: Train Loss = 0.0015927219611212777, Recall = 1.0, Aging Rate = 0.4976536312849162, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0013407963088469049, Recall = 1.0, Aging Rate = 0.4976536312849162, precision = 1.0\n",
      "\n",
      "Training Finished at epoch 80.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ba5669684684343b362500dd7915b09",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss = 0.5671183386861279, Recall = 0.9766502020655591, Aging Rate = 0.9112849162011173, Precision = 0.5333496812162825, f1 = 0.6899286280729579\n",
      "Epoch 2: Train Loss = 0.3789050635479016, Recall = 0.9416255051638976, Aging Rate = 0.641340782122905, Precision = 0.7306620209059234, f1 = 0.8228369629193644\n",
      "Epoch 3: Train Loss = 0.2834463976281981, Recall = 0.9510552312528064, Aging Rate = 0.5856983240223463, Precision = 0.8080885158336513, f1 = 0.8737623762376237\n",
      "Epoch 4: Train Loss = 0.21610030516565845, Recall = 0.9654243376740009, Aging Rate = 0.5557541899441341, Precision = 0.8644953759549658, f1 = 0.9121764955451845\n",
      "Epoch 5: Train Loss = 0.1737393155111281, Recall = 0.9788953749438707, Aging Rate = 0.5481564245810056, Precision = 0.8887077048512027, f1 = 0.9316239316239316\n",
      "Test Loss = 0.13785141816352334, Recall = 0.9784463403682083, Aging Rate = 0.5115083798882681, precision = 0.9519440803844473\n",
      "Model in epoch 5 is saved.\n",
      "\n",
      "Epoch 6: Train Loss = 0.11736068041131482, Recall = 0.9869779973057925, Aging Rate = 0.5251396648044693, Precision = 0.9353191489361702, f1 = 0.9604544461437623\n",
      "Epoch 7: Train Loss = 0.08842338832896515, Recall = 0.9941625505163898, Aging Rate = 0.518659217877095, Precision = 0.9538991813873331, f1 = 0.9736147757255937\n",
      "Epoch 8: Train Loss = 0.06728493069387015, Recall = 0.997305792546026, Aging Rate = 0.510391061452514, Precision = 0.9724168126094571, f1 = 0.9847040567501663\n",
      "Epoch 9: Train Loss = 0.053334087662856675, Recall = 0.997305792546026, Aging Rate = 0.5054748603351955, Precision = 0.9818744473916887, f1 = 0.9895299621296503\n",
      "Epoch 10: Train Loss = 0.04263433540083843, Recall = 0.9991019308486754, Aging Rate = 0.5041340782122905, Precision = 0.9862588652482269, f1 = 0.9926388579076512\n",
      "Test Loss = 0.03615026024591656, Recall = 0.9995509654243376, Aging Rate = 0.5005586592178771, precision = 0.99375\n",
      "Model in epoch 10 is saved.\n",
      "\n",
      "Epoch 11: Train Loss = 0.034655746912906286, Recall = 0.9995509654243376, Aging Rate = 0.5025698324022346, Precision = 0.989773232547799, f1 = 0.9946380697050937\n",
      "Epoch 12: Train Loss = 0.028822582223395395, Recall = 0.9995509654243376, Aging Rate = 0.5014525139664805, Precision = 0.9919786096256684, f1 = 0.9957503914113173\n",
      "Epoch 13: Train Loss = 0.024317446018896956, Recall = 0.9995509654243376, Aging Rate = 0.5003351955307263, Precision = 0.994193836534167, f1 = 0.9968652037617555\n",
      "Epoch 14: Train Loss = 0.021133240056770475, Recall = 1.0, Aging Rate = 0.49966480446927375, Precision = 0.9959749552772809, f1 = 0.9979834192247368\n",
      "Epoch 15: Train Loss = 0.01800074928216428, Recall = 0.9995509654243376, Aging Rate = 0.4994413407821229, Precision = 0.9959731543624161, f1 = 0.9977588525324966\n",
      "Test Loss = 0.015076325401122677, Recall = 1.0, Aging Rate = 0.49899441340782125, precision = 0.9973130317957905\n",
      "Model in epoch 15 is saved.\n",
      "\n",
      "Epoch 16: Train Loss = 0.015121795505951236, Recall = 1.0, Aging Rate = 0.49899441340782125, Precision = 0.9973130317957905, f1 = 0.9986547085201793\n",
      "Epoch 17: Train Loss = 0.013177252736504518, Recall = 1.0, Aging Rate = 0.4987709497206704, Precision = 0.9977598566308243, f1 = 0.99887867234806\n",
      "Epoch 18: Train Loss = 0.011539858305337708, Recall = 1.0, Aging Rate = 0.49854748603351956, Precision = 0.9982070820259973, f1 = 0.9991027366532077\n",
      "Epoch 19: Train Loss = 0.01009690754011523, Recall = 1.0, Aging Rate = 0.4983240223463687, Precision = 0.9986547085201793, f1 = 0.9993269015032533\n",
      "Epoch 20: Train Loss = 0.00914720868764643, Recall = 1.0, Aging Rate = 0.4983240223463687, Precision = 0.9986547085201793, f1 = 0.9993269015032533\n",
      "Test Loss = 0.007893308392262825, Recall = 1.0, Aging Rate = 0.4983240223463687, precision = 0.9986547085201793\n",
      "Model in epoch 20 is saved.\n",
      "\n",
      "Epoch 21: Train Loss = 0.007958630019143306, Recall = 1.0, Aging Rate = 0.4981005586592179, Precision = 0.9991027366532077, f1 = 0.9995511669658886\n",
      "Epoch 22: Train Loss = 0.0074996611696548305, Recall = 1.0, Aging Rate = 0.49787709497206706, Precision = 0.9995511669658886, f1 = 0.9997755331088665\n",
      "Epoch 23: Train Loss = 0.0065797030747810886, Recall = 1.0, Aging Rate = 0.49787709497206706, Precision = 0.9995511669658886, f1 = 0.9997755331088665\n",
      "Epoch 24: Train Loss = 0.005987832352685529, Recall = 1.0, Aging Rate = 0.4983240223463687, Precision = 0.9986547085201793, f1 = 0.9993269015032533\n",
      "Epoch 25: Train Loss = 0.0054773922134502976, Recall = 1.0, Aging Rate = 0.49787709497206706, Precision = 0.9995511669658886, f1 = 0.9997755331088665\n",
      "Test Loss = 0.0048748508291371045, Recall = 1.0, Aging Rate = 0.49787709497206706, precision = 0.9995511669658886\n",
      "Model in epoch 25 is saved.\n",
      "\n",
      "Epoch 26: Train Loss = 0.0049722267078579135, Recall = 1.0, Aging Rate = 0.4976536312849162, Precision = 0, f1 = 0.0\n",
      "Epoch 27: Train Loss = 0.004552455017546077, Recall = 1.0, Aging Rate = 0.49787709497206706, Precision = 0.9995511669658886, f1 = 0.9997755331088665\n",
      "Epoch 28: Train Loss = 0.004255792863729446, Recall = 1.0, Aging Rate = 0.49787709497206706, Precision = 0.9995511669658886, f1 = 0.9997755331088665\n",
      "Epoch 29: Train Loss = 0.004012712381946641, Recall = 1.0, Aging Rate = 0.49787709497206706, Precision = 0.9995511669658886, f1 = 0.9997755331088665\n",
      "Epoch 30: Train Loss = 0.0036477075849644133, Recall = 1.0, Aging Rate = 0.49787709497206706, Precision = 0.9995511669658886, f1 = 0.9997755331088665\n",
      "Test Loss = 0.0033332746613812347, Recall = 1.0, Aging Rate = 0.4976536312849162, precision = 1.0\n",
      "Model in epoch 30 is saved.\n",
      "\n",
      "Epoch 31: Train Loss = 0.0034704470560578994, Recall = 1.0, Aging Rate = 0.49787709497206706, Precision = 0.9995511669658886, f1 = 0.9997755331088665\n",
      "Epoch 32: Train Loss = 0.0032317084921575957, Recall = 1.0, Aging Rate = 0.4976536312849162, Precision = 0, f1 = 0.0\n",
      "Epoch 33: Train Loss = 0.003004011079700216, Recall = 1.0, Aging Rate = 0.4976536312849162, Precision = 0, f1 = 0.0\n",
      "Epoch 34: Train Loss = 0.0028778173618393237, Recall = 1.0, Aging Rate = 0.4976536312849162, Precision = 0, f1 = 0.0\n",
      "Epoch 35: Train Loss = 0.002731382552529139, Recall = 1.0, Aging Rate = 0.4976536312849162, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0027439477837087807, Recall = 1.0, Aging Rate = 0.49787709497206706, precision = 0.9995511669658886\n",
      "\n",
      "Epoch 36: Train Loss = 0.0027560642614502815, Recall = 1.0, Aging Rate = 0.49787709497206706, Precision = 0.9995511669658886, f1 = 0.9997755331088665\n",
      "Epoch 37: Train Loss = 0.002613595556155596, Recall = 1.0, Aging Rate = 0.4976536312849162, Precision = 0, f1 = 0.0\n",
      "Epoch 38: Train Loss = 0.0024010613686066933, Recall = 1.0, Aging Rate = 0.4976536312849162, Precision = 0, f1 = 0.0\n",
      "Epoch 39: Train Loss = 0.0022881998765859855, Recall = 1.0, Aging Rate = 0.4976536312849162, Precision = 0, f1 = 0.0\n",
      "Epoch 40: Train Loss = 0.002176076531951321, Recall = 1.0, Aging Rate = 0.4976536312849162, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0020497301561945226, Recall = 1.0, Aging Rate = 0.4976536312849162, precision = 1.0\n",
      "\n",
      "Epoch 41: Train Loss = 0.002169641836770087, Recall = 1.0, Aging Rate = 0.4976536312849162, Precision = 0, f1 = 0.0\n",
      "Epoch 42: Train Loss = 0.002111650477267552, Recall = 1.0, Aging Rate = 0.4976536312849162, Precision = 0, f1 = 0.0\n",
      "Epoch 43: Train Loss = 0.0021366647673854034, Recall = 1.0, Aging Rate = 0.4976536312849162, Precision = 0, f1 = 0.0\n",
      "Epoch 44: Train Loss = 0.0020509978801053663, Recall = 1.0, Aging Rate = 0.4976536312849162, Precision = 0, f1 = 0.0\n",
      "Epoch 45: Train Loss = 0.0019899349696101756, Recall = 1.0, Aging Rate = 0.4976536312849162, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0018147495673584372, Recall = 1.0, Aging Rate = 0.4976536312849162, precision = 1.0\n",
      "\n",
      "Epoch 46: Train Loss = 0.001979076237750744, Recall = 1.0, Aging Rate = 0.4976536312849162, Precision = 0, f1 = 0.0\n",
      "Epoch 47: Train Loss = 0.0019032557656228875, Recall = 1.0, Aging Rate = 0.4976536312849162, Precision = 0, f1 = 0.0\n",
      "Epoch 48: Train Loss = 0.0019058004252654214, Recall = 1.0, Aging Rate = 0.4976536312849162, Precision = 0, f1 = 0.0\n",
      "Epoch 49: Train Loss = 0.001802245664290626, Recall = 1.0, Aging Rate = 0.4976536312849162, Precision = 0, f1 = 0.0\n",
      "Epoch 50: Train Loss = 0.0018088627551739525, Recall = 1.0, Aging Rate = 0.4976536312849162, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0016734490649743454, Recall = 1.0, Aging Rate = 0.4976536312849162, precision = 1.0\n",
      "\n",
      "Epoch 51: Train Loss = 0.0018989568744010848, Recall = 1.0, Aging Rate = 0.4976536312849162, Precision = 0, f1 = 0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 52: Train Loss = 0.0017044710172028099, Recall = 1.0, Aging Rate = 0.4976536312849162, Precision = 0, f1 = 0.0\n",
      "Epoch 53: Train Loss = 0.0017174805003327615, Recall = 1.0, Aging Rate = 0.4976536312849162, Precision = 0, f1 = 0.0\n",
      "Epoch 54: Train Loss = 0.0019838777720387088, Recall = 1.0, Aging Rate = 0.4976536312849162, Precision = 0, f1 = 0.0\n",
      "Epoch 55: Train Loss = 0.00215950100349689, Recall = 1.0, Aging Rate = 0.4976536312849162, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0019021195061400783, Recall = 1.0, Aging Rate = 0.4976536312849162, precision = 1.0\n",
      "\n",
      "Epoch 56: Train Loss = 0.0016758096412178025, Recall = 1.0, Aging Rate = 0.4976536312849162, Precision = 0, f1 = 0.0\n",
      "Epoch 57: Train Loss = 0.0015708421211164216, Recall = 1.0, Aging Rate = 0.4976536312849162, Precision = 0, f1 = 0.0\n",
      "Epoch 58: Train Loss = 0.0018667047037404841, Recall = 1.0, Aging Rate = 0.4976536312849162, Precision = 0, f1 = 0.0\n",
      "Epoch 59: Train Loss = 0.001705045761935954, Recall = 1.0, Aging Rate = 0.4976536312849162, Precision = 0, f1 = 0.0\n",
      "Epoch 60: Train Loss = 0.0015791331329929263, Recall = 1.0, Aging Rate = 0.4976536312849162, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0013475509118106653, Recall = 1.0, Aging Rate = 0.4976536312849162, precision = 1.0\n",
      "\n",
      "Epoch 61: Train Loss = 0.0016980570010963162, Recall = 1.0, Aging Rate = 0.4976536312849162, Precision = 0, f1 = 0.0\n",
      "Epoch 62: Train Loss = 0.0015582061426287423, Recall = 1.0, Aging Rate = 0.4976536312849162, Precision = 0, f1 = 0.0\n",
      "Epoch 63: Train Loss = 0.0016762795580249259, Recall = 1.0, Aging Rate = 0.4976536312849162, Precision = 0, f1 = 0.0\n",
      "Epoch 64: Train Loss = 0.0016779626882504983, Recall = 1.0, Aging Rate = 0.4976536312849162, Precision = 0, f1 = 0.0\n",
      "Epoch 65: Train Loss = 0.0016522278891246786, Recall = 1.0, Aging Rate = 0.4976536312849162, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0020132170315811087, Recall = 1.0, Aging Rate = 0.4976536312849162, precision = 1.0\n",
      "\n",
      "Epoch 66: Train Loss = 0.0016895322668152813, Recall = 1.0, Aging Rate = 0.4976536312849162, Precision = 0, f1 = 0.0\n",
      "Epoch 67: Train Loss = 0.0015705634406949888, Recall = 1.0, Aging Rate = 0.4976536312849162, Precision = 0, f1 = 0.0\n",
      "Epoch 68: Train Loss = 0.0021971676762179374, Recall = 1.0, Aging Rate = 0.49787709497206706, Precision = 0.9995511669658886, f1 = 0.9997755331088665\n",
      "Epoch 69: Train Loss = 0.0016381318055551145, Recall = 1.0, Aging Rate = 0.4976536312849162, Precision = 0, f1 = 0.0\n",
      "Epoch 70: Train Loss = 0.0026549953024823988, Recall = 0.9995509654243376, Aging Rate = 0.4976536312849162, Precision = 0.9995509654243376, f1 = 0.9995509654243376\n",
      "Test Loss = 0.0015688590764187734, Recall = 1.0, Aging Rate = 0.49787709497206706, precision = 0.9995511669658886\n",
      "\n",
      "Epoch 71: Train Loss = 0.0017281192596663602, Recall = 1.0, Aging Rate = 0.49787709497206706, Precision = 0.9995511669658886, f1 = 0.9997755331088665\n",
      "Epoch 72: Train Loss = 0.0013632065290455086, Recall = 1.0, Aging Rate = 0.4976536312849162, Precision = 0, f1 = 0.0\n",
      "Epoch 73: Train Loss = 0.0014594191894736453, Recall = 1.0, Aging Rate = 0.4976536312849162, Precision = 0, f1 = 0.0\n",
      "Epoch 74: Train Loss = 0.0015058992181868193, Recall = 1.0, Aging Rate = 0.4976536312849162, Precision = 0, f1 = 0.0\n",
      "Epoch 75: Train Loss = 0.0014523164545544864, Recall = 1.0, Aging Rate = 0.4976536312849162, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0014209764769727458, Recall = 1.0, Aging Rate = 0.4976536312849162, precision = 1.0\n",
      "\n",
      "Epoch 76: Train Loss = 0.0015228936704676911, Recall = 1.0, Aging Rate = 0.4976536312849162, Precision = 0, f1 = 0.0\n",
      "Epoch 77: Train Loss = 0.0016213795631426756, Recall = 1.0, Aging Rate = 0.4976536312849162, Precision = 0, f1 = 0.0\n",
      "Epoch 78: Train Loss = 0.0014657978368038571, Recall = 1.0, Aging Rate = 0.4976536312849162, Precision = 0, f1 = 0.0\n",
      "Epoch 79: Train Loss = 0.0015818587654236414, Recall = 1.0, Aging Rate = 0.4976536312849162, Precision = 0, f1 = 0.0\n",
      "Epoch 80: Train Loss = 0.0016452773467653208, Recall = 1.0, Aging Rate = 0.4976536312849162, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.001956673547932514, Recall = 1.0, Aging Rate = 0.4976536312849162, precision = 1.0\n",
      "\n",
      "Training Finished at epoch 80.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "53d9f12c7a4f4ee4b3e5b04f7f902e96",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss = 0.551987459646257, Recall = 0.9654243376740009, Aging Rate = 0.8712849162011174, Precision = 0.5514234419081816, f1 = 0.701926216127979\n",
      "Epoch 2: Train Loss = 0.3619340812493969, Recall = 0.9429726088908846, Aging Rate = 0.6301675977653631, Precision = 0.7446808510638298, f1 = 0.8321775312066574\n",
      "Epoch 3: Train Loss = 0.2717582871227957, Recall = 0.958688819039066, Aging Rate = 0.5865921787709497, Precision = 0.8133333333333334, f1 = 0.8800494641384996\n",
      "Epoch 4: Train Loss = 0.20865196725509685, Recall = 0.9712617871576111, Aging Rate = 0.5642458100558659, Precision = 0.8566336633663366, f1 = 0.9103535353535354\n",
      "Epoch 5: Train Loss = 0.16789490154335618, Recall = 0.979344409519533, Aging Rate = 0.546145251396648, Precision = 0.8923895253682488, f1 = 0.9338471419396276\n",
      "Test Loss = 0.12902108204098386, Recall = 0.9964077233947014, Aging Rate = 0.5432402234636872, precision = 0.9127930892636775\n",
      "Model in epoch 5 is saved.\n",
      "\n",
      "Epoch 6: Train Loss = 0.11540421179552984, Recall = 0.9941625505163898, Aging Rate = 0.5273743016759777, Precision = 0.938135593220339, f1 = 0.9653368214519293\n",
      "Epoch 7: Train Loss = 0.08789688583026385, Recall = 0.994611585092052, Aging Rate = 0.5197765363128491, Precision = 0.9522785898538263, f1 = 0.9729848451570392\n",
      "Epoch 8: Train Loss = 0.0679889957440299, Recall = 0.995958688819039, Aging Rate = 0.5101675977653631, Precision = 0.9715286903197548, f1 = 0.9835920177383591\n",
      "Epoch 9: Train Loss = 0.05356634956498386, Recall = 0.997305792546026, Aging Rate = 0.5063687150837989, Precision = 0.9801412180052956, f1 = 0.9886490095704429\n",
      "Epoch 10: Train Loss = 0.0432505249694073, Recall = 0.9982038616973506, Aging Rate = 0.5039106145251396, Precision = 0.985809312638581, f1 = 0.9919678714859439\n",
      "Test Loss = 0.03556443469900659, Recall = 0.998652896273013, Aging Rate = 0.5016759776536313, precision = 0.9906458797327394\n",
      "Model in epoch 10 is saved.\n",
      "\n",
      "Epoch 11: Train Loss = 0.03535573559599882, Recall = 0.9991019308486754, Aging Rate = 0.5030167597765363, Precision = 0.9884495779653487, f1 = 0.9937472085752569\n",
      "Epoch 12: Train Loss = 0.028695810330646665, Recall = 0.9991019308486754, Aging Rate = 0.5014525139664805, Precision = 0.9915329768270945, f1 = 0.9953030641914561\n",
      "Epoch 13: Train Loss = 0.024012454631608292, Recall = 1.0, Aging Rate = 0.5001117318435754, Precision = 0.9950848972296693, f1 = 0.9975363941769316\n",
      "Epoch 14: Train Loss = 0.020406727019551745, Recall = 1.0, Aging Rate = 0.49988826815642456, Precision = 0.9955297273133661, f1 = 0.9977598566308243\n",
      "Epoch 15: Train Loss = 0.017357221780833917, Recall = 1.0, Aging Rate = 0.4987709497206704, Precision = 0.9977598566308243, f1 = 0.99887867234806\n",
      "Test Loss = 0.014847936320155027, Recall = 1.0, Aging Rate = 0.49854748603351956, precision = 0.9982070820259973\n",
      "Model in epoch 15 is saved.\n",
      "\n",
      "Epoch 16: Train Loss = 0.01483736624472967, Recall = 1.0, Aging Rate = 0.49854748603351956, Precision = 0.9982070820259973, f1 = 0.9991027366532077\n",
      "Epoch 17: Train Loss = 0.01285234901554591, Recall = 1.0, Aging Rate = 0.4981005586592179, Precision = 0.9991027366532077, f1 = 0.9995511669658886\n",
      "Epoch 18: Train Loss = 0.010959634347168427, Recall = 1.0, Aging Rate = 0.49787709497206706, Precision = 0.9995511669658886, f1 = 0.9997755331088665\n",
      "Epoch 19: Train Loss = 0.009840813605062788, Recall = 1.0, Aging Rate = 0.4981005586592179, Precision = 0.9991027366532077, f1 = 0.9995511669658886\n",
      "Epoch 20: Train Loss = 0.00846224046223823, Recall = 1.0, Aging Rate = 0.49787709497206706, Precision = 0.9995511669658886, f1 = 0.9997755331088665\n",
      "Test Loss = 0.008429404446782347, Recall = 1.0, Aging Rate = 0.49787709497206706, precision = 0.9995511669658886\n",
      "Model in epoch 20 is saved.\n",
      "\n",
      "Epoch 21: Train Loss = 0.007758039297463174, Recall = 1.0, Aging Rate = 0.49787709497206706, Precision = 0.9995511669658886, f1 = 0.9997755331088665\n",
      "Epoch 22: Train Loss = 0.006886452087123135, Recall = 1.0, Aging Rate = 0.49787709497206706, Precision = 0.9995511669658886, f1 = 0.9997755331088665\n",
      "Epoch 23: Train Loss = 0.006377041181393342, Recall = 1.0, Aging Rate = 0.49787709497206706, Precision = 0.9995511669658886, f1 = 0.9997755331088665\n",
      "Epoch 24: Train Loss = 0.005574303219646382, Recall = 1.0, Aging Rate = 0.49787709497206706, Precision = 0.9995511669658886, f1 = 0.9997755331088665\n",
      "Epoch 25: Train Loss = 0.005133283955861902, Recall = 1.0, Aging Rate = 0.4976536312849162, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.004560851644745419, Recall = 1.0, Aging Rate = 0.4976536312849162, precision = 1.0\n",
      "Model in epoch 25 is saved.\n",
      "\n",
      "Epoch 26: Train Loss = 0.004634755339952155, Recall = 1.0, Aging Rate = 0.49787709497206706, Precision = 0.9995511669658886, f1 = 0.9997755331088665\n",
      "Epoch 27: Train Loss = 0.004351781567132007, Recall = 1.0, Aging Rate = 0.4976536312849162, Precision = 0, f1 = 0.0\n",
      "Epoch 28: Train Loss = 0.003996225660458707, Recall = 1.0, Aging Rate = 0.4976536312849162, Precision = 0, f1 = 0.0\n",
      "Epoch 29: Train Loss = 0.0036729944707544824, Recall = 1.0, Aging Rate = 0.4976536312849162, Precision = 0, f1 = 0.0\n",
      "Epoch 30: Train Loss = 0.0034372833133388997, Recall = 1.0, Aging Rate = 0.4976536312849162, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.003255725735616376, Recall = 1.0, Aging Rate = 0.4976536312849162, precision = 1.0\n",
      "\n",
      "Epoch 31: Train Loss = 0.003281864929221071, Recall = 1.0, Aging Rate = 0.4976536312849162, Precision = 0, f1 = 0.0\n",
      "Epoch 32: Train Loss = 0.003051377635907028, Recall = 1.0, Aging Rate = 0.4976536312849162, Precision = 0, f1 = 0.0\n",
      "Epoch 33: Train Loss = 0.002876016849693556, Recall = 1.0, Aging Rate = 0.4976536312849162, Precision = 0, f1 = 0.0\n",
      "Epoch 34: Train Loss = 0.0027821232830616514, Recall = 1.0, Aging Rate = 0.4976536312849162, Precision = 0, f1 = 0.0\n",
      "Epoch 35: Train Loss = 0.002557477860206832, Recall = 1.0, Aging Rate = 0.4976536312849162, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0022821939887489352, Recall = 1.0, Aging Rate = 0.4976536312849162, precision = 1.0\n",
      "\n",
      "Epoch 36: Train Loss = 0.0025210707860494124, Recall = 1.0, Aging Rate = 0.4976536312849162, Precision = 0, f1 = 0.0\n",
      "Epoch 37: Train Loss = 0.0023172598530918193, Recall = 1.0, Aging Rate = 0.4976536312849162, Precision = 0, f1 = 0.0\n",
      "Epoch 38: Train Loss = 0.002313795916335501, Recall = 1.0, Aging Rate = 0.4976536312849162, Precision = 0, f1 = 0.0\n",
      "Epoch 39: Train Loss = 0.002204936667548378, Recall = 1.0, Aging Rate = 0.4976536312849162, Precision = 0, f1 = 0.0\n",
      "Epoch 40: Train Loss = 0.002177719307345385, Recall = 1.0, Aging Rate = 0.4976536312849162, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.001992785439425923, Recall = 1.0, Aging Rate = 0.4976536312849162, precision = 1.0\n",
      "\n",
      "Epoch 41: Train Loss = 0.0020397448358152, Recall = 1.0, Aging Rate = 0.4976536312849162, Precision = 0, f1 = 0.0\n",
      "Epoch 42: Train Loss = 0.0020780091378161444, Recall = 1.0, Aging Rate = 0.4976536312849162, Precision = 0, f1 = 0.0\n",
      "Epoch 43: Train Loss = 0.0020077021438212202, Recall = 1.0, Aging Rate = 0.4976536312849162, Precision = 0, f1 = 0.0\n",
      "Epoch 44: Train Loss = 0.0019318217372355265, Recall = 1.0, Aging Rate = 0.4976536312849162, Precision = 0, f1 = 0.0\n",
      "Epoch 45: Train Loss = 0.0018554849070418814, Recall = 1.0, Aging Rate = 0.4976536312849162, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0018968302600980637, Recall = 1.0, Aging Rate = 0.4976536312849162, precision = 1.0\n",
      "\n",
      "Epoch 46: Train Loss = 0.0019171344138182408, Recall = 1.0, Aging Rate = 0.4976536312849162, Precision = 0, f1 = 0.0\n",
      "Epoch 47: Train Loss = 0.001810626007678955, Recall = 1.0, Aging Rate = 0.4976536312849162, Precision = 0, f1 = 0.0\n",
      "Epoch 48: Train Loss = 0.0018244862582472118, Recall = 1.0, Aging Rate = 0.4976536312849162, Precision = 0, f1 = 0.0\n",
      "Epoch 49: Train Loss = 0.0017585555462988729, Recall = 1.0, Aging Rate = 0.4976536312849162, Precision = 0, f1 = 0.0\n",
      "Epoch 50: Train Loss = 0.0017953337190214898, Recall = 1.0, Aging Rate = 0.4976536312849162, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0019879258726853565, Recall = 1.0, Aging Rate = 0.4976536312849162, precision = 1.0\n",
      "\n",
      "Epoch 51: Train Loss = 0.0017322383151394862, Recall = 1.0, Aging Rate = 0.4976536312849162, Precision = 0, f1 = 0.0\n",
      "Epoch 52: Train Loss = 0.0021695876962312772, Recall = 1.0, Aging Rate = 0.49787709497206706, Precision = 0.9995511669658886, f1 = 0.9997755331088665\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 53: Train Loss = 0.0018464112629354333, Recall = 1.0, Aging Rate = 0.4976536312849162, Precision = 0, f1 = 0.0\n",
      "Epoch 54: Train Loss = 0.0016717019051511112, Recall = 1.0, Aging Rate = 0.4976536312849162, Precision = 0, f1 = 0.0\n",
      "Epoch 55: Train Loss = 0.0014928314193183108, Recall = 1.0, Aging Rate = 0.4976536312849162, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.00132150894134987, Recall = 1.0, Aging Rate = 0.4976536312849162, precision = 1.0\n",
      "\n",
      "Epoch 56: Train Loss = 0.0015636018422489476, Recall = 1.0, Aging Rate = 0.4976536312849162, Precision = 0, f1 = 0.0\n",
      "Epoch 57: Train Loss = 0.0016135583205575217, Recall = 1.0, Aging Rate = 0.4976536312849162, Precision = 0, f1 = 0.0\n",
      "Epoch 58: Train Loss = 0.00161378607122675, Recall = 1.0, Aging Rate = 0.4976536312849162, Precision = 0, f1 = 0.0\n",
      "Epoch 59: Train Loss = 0.0015616400746430931, Recall = 1.0, Aging Rate = 0.4976536312849162, Precision = 0, f1 = 0.0\n",
      "Epoch 60: Train Loss = 0.0016306267824419383, Recall = 1.0, Aging Rate = 0.4976536312849162, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0013682008644971767, Recall = 1.0, Aging Rate = 0.4976536312849162, precision = 1.0\n",
      "\n",
      "Epoch 61: Train Loss = 0.0017253445258998837, Recall = 1.0, Aging Rate = 0.4976536312849162, Precision = 0, f1 = 0.0\n",
      "Epoch 62: Train Loss = 0.0015320867827479524, Recall = 1.0, Aging Rate = 0.4976536312849162, Precision = 0, f1 = 0.0\n",
      "Epoch 63: Train Loss = 0.0015340004472176455, Recall = 1.0, Aging Rate = 0.4976536312849162, Precision = 0, f1 = 0.0\n",
      "Epoch 64: Train Loss = 0.0016512710696564956, Recall = 1.0, Aging Rate = 0.4976536312849162, Precision = 0, f1 = 0.0\n",
      "Epoch 65: Train Loss = 0.0016696520712403528, Recall = 1.0, Aging Rate = 0.4976536312849162, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0014526958601788602, Recall = 1.0, Aging Rate = 0.4976536312849162, precision = 1.0\n",
      "\n",
      "Epoch 66: Train Loss = 0.0017138267049628345, Recall = 1.0, Aging Rate = 0.4976536312849162, Precision = 0, f1 = 0.0\n",
      "Epoch 67: Train Loss = 0.0015749395586154814, Recall = 1.0, Aging Rate = 0.4976536312849162, Precision = 0, f1 = 0.0\n",
      "Epoch 68: Train Loss = 0.001511565222295636, Recall = 1.0, Aging Rate = 0.4976536312849162, Precision = 0, f1 = 0.0\n",
      "Epoch 69: Train Loss = 0.0014353256184586932, Recall = 1.0, Aging Rate = 0.4976536312849162, Precision = 0, f1 = 0.0\n",
      "Epoch 70: Train Loss = 0.00171619158467101, Recall = 1.0, Aging Rate = 0.4976536312849162, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0029001760142517157, Recall = 1.0, Aging Rate = 0.4981005586592179, precision = 0.9991027366532077\n",
      "\n",
      "Epoch 71: Train Loss = 0.0017541743883103466, Recall = 1.0, Aging Rate = 0.4976536312849162, Precision = 0, f1 = 0.0\n",
      "Epoch 72: Train Loss = 0.0014685864222636603, Recall = 1.0, Aging Rate = 0.4976536312849162, Precision = 0, f1 = 0.0\n",
      "Epoch 73: Train Loss = 0.0013916833285637742, Recall = 1.0, Aging Rate = 0.4976536312849162, Precision = 0, f1 = 0.0\n",
      "Epoch 74: Train Loss = 0.0014682782824312509, Recall = 1.0, Aging Rate = 0.4976536312849162, Precision = 0, f1 = 0.0\n",
      "Epoch 75: Train Loss = 0.0018347760946515884, Recall = 1.0, Aging Rate = 0.4976536312849162, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0015336875945288044, Recall = 1.0, Aging Rate = 0.4976536312849162, precision = 1.0\n",
      "\n",
      "Training Finished at epoch 75.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d8224aa644924dba880799df9bc05daa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss = 0.3613069396369472, Recall = 0.868491921005386, Aging Rate = 0.5359696157283289, Precision = 0.8065860775323052, f1 = 0.8363950724011239\n",
      "Epoch 2: Train Loss = 0.15132347014304035, Recall = 0.9515260323159784, Aging Rate = 0.5080428954423593, Precision = 0.9322779243623571, f1 = 0.941803642825411\n",
      "Epoch 3: Train Loss = 0.09612013974873694, Recall = 0.9694793536804309, Aging Rate = 0.501787310098302, Precision = 0.9617097061442564, f1 = 0.9655789003129192\n",
      "Epoch 4: Train Loss = 0.07343104629843122, Recall = 0.9784560143626571, Aging Rate = 0.5033512064343163, Precision = 0.9675987572126055, f1 = 0.9729970988618611\n",
      "Epoch 5: Train Loss = 0.04684393560984925, Recall = 0.9869838420107719, Aging Rate = 0.5024575513851653, Precision = 0.9777678968430413, f1 = 0.9823542550815277\n",
      "Test Loss = 0.016756050139698896, Recall = 0.998653500897666, Aging Rate = 0.5002234137622877, precision = 0.9937472085752568\n",
      "Model in epoch 5 is saved.\n",
      "\n",
      "Epoch 6: Train Loss = 0.013384820884251776, Recall = 0.9977558348294434, Aging Rate = 0.4979892761394102, Precision = 0.9973082099596231, f1 = 0.9975319721785955\n",
      "Epoch 7: Train Loss = 0.005008416497535584, Recall = 1.0, Aging Rate = 0.4979892761394102, Precision = 0.9995513683266039, f1 = 0.9997756338344178\n",
      "Epoch 8: Train Loss = 0.0032254792779011585, Recall = 1.0, Aging Rate = 0.49776586237712245, Precision = 0, f1 = 0.0\n",
      "Epoch 9: Train Loss = 0.0023166389434791474, Recall = 1.0, Aging Rate = 0.49776586237712245, Precision = 0, f1 = 0.0\n",
      "Epoch 10: Train Loss = 0.002030854146691227, Recall = 1.0, Aging Rate = 0.49776586237712245, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.001588605030161396, Recall = 1.0, Aging Rate = 0.49776586237712245, precision = 1.0\n",
      "Model in epoch 10 is saved.\n",
      "\n",
      "Epoch 11: Train Loss = 0.0022160504742586274, Recall = 1.0, Aging Rate = 0.49776586237712245, Precision = 0, f1 = 0.0\n",
      "Epoch 12: Train Loss = 0.002462853557306198, Recall = 1.0, Aging Rate = 0.49776586237712245, Precision = 0, f1 = 0.0\n",
      "Epoch 13: Train Loss = 0.0035114922365997656, Recall = 1.0, Aging Rate = 0.4982126899016979, Precision = 0.9991031390134529, f1 = 0.9995513683266039\n",
      "Epoch 14: Train Loss = 0.03407668983676139, Recall = 0.9914721723518851, Aging Rate = 0.5002234137622877, Precision = 0.9866011612326931, f1 = 0.9890306693530333\n",
      "Epoch 15: Train Loss = 0.025918656148239506, Recall = 0.9932675044883303, Aging Rate = 0.49865951742627346, Precision = 0.9914874551971327, f1 = 0.9923766816143498\n",
      "Test Loss = 0.013333069790617444, Recall = 0.998653500897666, Aging Rate = 0.4979892761394102, precision = 0.9982054733064154\n",
      "\n",
      "Epoch 16: Train Loss = 0.00547405448997097, Recall = 0.9991023339317774, Aging Rate = 0.49776586237712245, Precision = 0.9991023339317774, f1 = 0.9991023339317774\n",
      "Epoch 17: Train Loss = 0.001156453172746177, Recall = 1.0, Aging Rate = 0.49776586237712245, Precision = 0, f1 = 0.0\n",
      "Epoch 18: Train Loss = 0.0010162342292001974, Recall = 1.0, Aging Rate = 0.49776586237712245, Precision = 0, f1 = 0.0\n",
      "Epoch 19: Train Loss = 0.0007378608241162934, Recall = 1.0, Aging Rate = 0.49776586237712245, Precision = 0, f1 = 0.0\n",
      "Epoch 20: Train Loss = 0.0008628873538514691, Recall = 1.0, Aging Rate = 0.49776586237712245, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0008155628138906768, Recall = 1.0, Aging Rate = 0.49776586237712245, precision = 1.0\n",
      "\n",
      "Epoch 21: Train Loss = 0.0010408733441253876, Recall = 1.0, Aging Rate = 0.49776586237712245, Precision = 0, f1 = 0.0\n",
      "Epoch 22: Train Loss = 0.001252178639657063, Recall = 1.0, Aging Rate = 0.49776586237712245, Precision = 0, f1 = 0.0\n",
      "Epoch 23: Train Loss = 0.0020826563253246375, Recall = 1.0, Aging Rate = 0.4979892761394102, Precision = 0.9995513683266039, f1 = 0.9997756338344178\n",
      "Epoch 24: Train Loss = 0.06430002918859762, Recall = 0.9802513464991023, Aging Rate = 0.5013404825737265, Precision = 0.9732620320855615, f1 = 0.9767441860465117\n",
      "Epoch 25: Train Loss = 0.014671008204758314, Recall = 0.9968581687612208, Aging Rate = 0.4988829311885612, Precision = 0.9946260635915808, f1 = 0.9957408652768437\n",
      "Test Loss = 0.003385967168548345, Recall = 1.0, Aging Rate = 0.4979892761394102, precision = 0.9995513683266039\n",
      "\n",
      "Epoch 26: Train Loss = 0.0046785113185734035, Recall = 0.9995511669658886, Aging Rate = 0.4979892761394102, Precision = 0.9991027366532077, f1 = 0.9993269015032532\n",
      "Epoch 27: Train Loss = 0.0011228481206191508, Recall = 1.0, Aging Rate = 0.49776586237712245, Precision = 0, f1 = 0.0\n",
      "Epoch 28: Train Loss = 0.0008298170046840892, Recall = 1.0, Aging Rate = 0.49776586237712245, Precision = 0, f1 = 0.0\n",
      "Epoch 29: Train Loss = 0.0008937101851744282, Recall = 1.0, Aging Rate = 0.49776586237712245, Precision = 0, f1 = 0.0\n",
      "Epoch 30: Train Loss = 0.0009775537075940935, Recall = 1.0, Aging Rate = 0.49776586237712245, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0009685281156805711, Recall = 1.0, Aging Rate = 0.49776586237712245, precision = 1.0\n",
      "\n",
      "Epoch 31: Train Loss = 0.0011022930399500585, Recall = 1.0, Aging Rate = 0.49776586237712245, Precision = 0, f1 = 0.0\n",
      "Epoch 32: Train Loss = 0.0011780866142112672, Recall = 1.0, Aging Rate = 0.49776586237712245, Precision = 0, f1 = 0.0\n",
      "Epoch 33: Train Loss = 0.0013382265459116918, Recall = 1.0, Aging Rate = 0.49776586237712245, Precision = 0, f1 = 0.0\n",
      "Epoch 34: Train Loss = 0.001402140064647719, Recall = 1.0, Aging Rate = 0.49776586237712245, Precision = 0, f1 = 0.0\n",
      "Epoch 35: Train Loss = 0.0014928831969378675, Recall = 1.0, Aging Rate = 0.49776586237712245, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0015308014174400628, Recall = 1.0, Aging Rate = 0.49776586237712245, precision = 1.0\n",
      "\n",
      "Epoch 36: Train Loss = 0.06340431937135563, Recall = 0.9847396768402155, Aging Rate = 0.5029043789097408, Precision = 0.9746779209240337, f1 = 0.9796829649475329\n",
      "Epoch 37: Train Loss = 0.0425893905231566, Recall = 0.9856373429084381, Aging Rate = 0.49955317247542447, Precision = 0.9821109123434705, f1 = 0.9838709677419355\n",
      "Epoch 38: Train Loss = 0.009784097265796711, Recall = 0.9982046678635548, Aging Rate = 0.4982126899016979, Precision = 0.9973094170403587, f1 = 0.9977568416330193\n",
      "Epoch 39: Train Loss = 0.0014243858270376248, Recall = 1.0, Aging Rate = 0.49776586237712245, Precision = 0, f1 = 0.0\n",
      "Epoch 40: Train Loss = 0.0009676076277155825, Recall = 1.0, Aging Rate = 0.49776586237712245, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0008774277027650595, Recall = 1.0, Aging Rate = 0.49776586237712245, precision = 1.0\n",
      "\n",
      "Epoch 41: Train Loss = 0.0009702731591692632, Recall = 1.0, Aging Rate = 0.49776586237712245, Precision = 0, f1 = 0.0\n",
      "Epoch 42: Train Loss = 0.0009818805965396864, Recall = 1.0, Aging Rate = 0.49776586237712245, Precision = 0, f1 = 0.0\n",
      "Epoch 43: Train Loss = 0.0010250757470846815, Recall = 1.0, Aging Rate = 0.49776586237712245, Precision = 0, f1 = 0.0\n",
      "Epoch 44: Train Loss = 0.0011338647785808782, Recall = 1.0, Aging Rate = 0.49776586237712245, Precision = 0, f1 = 0.0\n",
      "Epoch 45: Train Loss = 0.0012143670902333627, Recall = 1.0, Aging Rate = 0.49776586237712245, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.001115690796876158, Recall = 1.0, Aging Rate = 0.49776586237712245, precision = 1.0\n",
      "\n",
      "Epoch 46: Train Loss = 0.0019292902660001006, Recall = 0.9995511669658886, Aging Rate = 0.49754244861483465, Precision = 0, f1 = 0.0\n",
      "Epoch 47: Train Loss = 0.003869645182464448, Recall = 1.0, Aging Rate = 0.4979892761394102, Precision = 0.9995513683266039, f1 = 0.9997756338344178\n",
      "Epoch 48: Train Loss = 0.001308128889400422, Recall = 1.0, Aging Rate = 0.49776586237712245, Precision = 0, f1 = 0.0\n",
      "Epoch 49: Train Loss = 0.0012273681046269748, Recall = 1.0, Aging Rate = 0.49776586237712245, Precision = 0, f1 = 0.0\n",
      "Epoch 50: Train Loss = 0.0012918231033797478, Recall = 1.0, Aging Rate = 0.49776586237712245, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0012720678764427875, Recall = 1.0, Aging Rate = 0.49776586237712245, precision = 1.0\n",
      "\n",
      "Epoch 51: Train Loss = 0.0043244175606684376, Recall = 0.9982046678635548, Aging Rate = 0.4970956210902592, Precision = 0.9995505617977528, f1 = 0.9988771614641815\n",
      "Epoch 52: Train Loss = 0.07576694614000093, Recall = 0.9802513464991023, Aging Rate = 0.5051385165326184, Precision = 0.9659442724458205, f1 = 0.9730452216529294\n",
      "Epoch 53: Train Loss = 0.01639570744256772, Recall = 0.9964093357271095, Aging Rate = 0.49977658623771226, Precision = 0.9924005364327224, f1 = 0.9944008958566629\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 54: Train Loss = 0.0030537165278590505, Recall = 0.9995511669658886, Aging Rate = 0.4979892761394102, Precision = 0.9991027366532077, f1 = 0.9993269015032532\n",
      "Epoch 55: Train Loss = 0.003750425040071882, Recall = 0.998653500897666, Aging Rate = 0.49754244861483465, Precision = 0.9991019308486754, f1 = 0.9988776655443322\n",
      "Test Loss = 0.0028541726770771668, Recall = 1.0, Aging Rate = 0.4979892761394102, precision = 0.9995513683266039\n",
      "\n",
      "Epoch 56: Train Loss = 0.0021067096253980194, Recall = 1.0, Aging Rate = 0.4979892761394102, Precision = 0.9995513683266039, f1 = 0.9997756338344178\n",
      "Epoch 57: Train Loss = 0.0009611777910172866, Recall = 1.0, Aging Rate = 0.49776586237712245, Precision = 0, f1 = 0.0\n",
      "Epoch 58: Train Loss = 0.0008853071670828619, Recall = 1.0, Aging Rate = 0.49776586237712245, Precision = 0, f1 = 0.0\n",
      "Epoch 59: Train Loss = 0.0009187847034426421, Recall = 1.0, Aging Rate = 0.49776586237712245, Precision = 0, f1 = 0.0\n",
      "Epoch 60: Train Loss = 0.0010827812792731648, Recall = 1.0, Aging Rate = 0.49776586237712245, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0009751346575469111, Recall = 1.0, Aging Rate = 0.49776586237712245, precision = 1.0\n",
      "\n",
      "Training Finished at epoch 60.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "346bd07351fe454a8468ebe163c74276",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss = 0.38460363663108654, Recall = 0.8612483161203413, Aging Rate = 0.5506145251396648, Precision = 0.7784090909090909, f1 = 0.8177360903858454\n",
      "Epoch 2: Train Loss = 0.16831248899411888, Recall = 0.9470139200718455, Aging Rate = 0.5115083798882681, Precision = 0.9213630406290957, f1 = 0.9340124003542959\n",
      "Epoch 3: Train Loss = 0.11069740237179082, Recall = 0.9690166142792995, Aging Rate = 0.5072625698324023, Precision = 0.9506607929515418, f1 = 0.9597509450744941\n",
      "Epoch 4: Train Loss = 0.0741179639617158, Recall = 0.9730579254602605, Aging Rate = 0.4994413407821229, Precision = 0.9695749440715884, f1 = 0.9713133124159571\n",
      "Epoch 5: Train Loss = 0.06786334818385167, Recall = 0.9806915132465199, Aging Rate = 0.5045810055865921, Precision = 0.9672276350752879, f1 = 0.9739130434782608\n",
      "Test Loss = 0.019190667650386607, Recall = 0.9995509654243376, Aging Rate = 0.49966480446927375, precision = 0.9955277280858676\n",
      "Model in epoch 5 is saved.\n",
      "\n",
      "Epoch 6: Train Loss = 0.012841082596657121, Recall = 0.9982038616973506, Aging Rate = 0.4987709497206704, Precision = 0.9959677419354839, f1 = 0.9970845481049563\n",
      "Epoch 7: Train Loss = 0.005109865079587065, Recall = 1.0, Aging Rate = 0.4981005586592179, Precision = 0.9991027366532077, f1 = 0.9995511669658886\n",
      "Epoch 8: Train Loss = 0.003458783889824119, Recall = 1.0, Aging Rate = 0.4976536312849162, Precision = 0, f1 = 0.0\n",
      "Epoch 9: Train Loss = 0.0034775138443970646, Recall = 0.9995509654243376, Aging Rate = 0.49743016759776537, Precision = 0, f1 = 0.0\n",
      "Epoch 10: Train Loss = 0.002771330195421863, Recall = 1.0, Aging Rate = 0.4976536312849162, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0020376968729002767, Recall = 1.0, Aging Rate = 0.4976536312849162, precision = 1.0\n",
      "Model in epoch 10 is saved.\n",
      "\n",
      "Epoch 11: Train Loss = 0.00251799203822254, Recall = 1.0, Aging Rate = 0.4976536312849162, Precision = 0, f1 = 0.0\n",
      "Epoch 12: Train Loss = 0.012133635325596652, Recall = 0.9968567579703638, Aging Rate = 0.49787709497206706, Precision = 0.9964093357271095, f1 = 0.9966329966329966\n",
      "Epoch 13: Train Loss = 0.018874747198538117, Recall = 0.994611585092052, Aging Rate = 0.49899441340782125, Precision = 0.9919390953873712, f1 = 0.9932735426008968\n",
      "Epoch 14: Train Loss = 0.011240791377491791, Recall = 0.9977548271216884, Aging Rate = 0.4987709497206704, Precision = 0.9955197132616488, f1 = 0.9966360170441804\n",
      "Epoch 15: Train Loss = 0.007534588917702249, Recall = 0.9982038616973506, Aging Rate = 0.49854748603351956, Precision = 0.9964141640519946, f1 = 0.9973082099596231\n",
      "Test Loss = 0.0026814124855087996, Recall = 1.0, Aging Rate = 0.4976536312849162, precision = 1.0\n",
      "\n",
      "Epoch 16: Train Loss = 0.0023146896765635, Recall = 1.0, Aging Rate = 0.49787709497206706, Precision = 0.9995511669658886, f1 = 0.9997755331088665\n",
      "Epoch 17: Train Loss = 0.0010282311548203147, Recall = 1.0, Aging Rate = 0.4976536312849162, Precision = 0, f1 = 0.0\n",
      "Epoch 18: Train Loss = 0.0009039432364489945, Recall = 1.0, Aging Rate = 0.4976536312849162, Precision = 0, f1 = 0.0\n",
      "Epoch 19: Train Loss = 0.0009885890736093734, Recall = 1.0, Aging Rate = 0.4976536312849162, Precision = 0, f1 = 0.0\n",
      "Epoch 20: Train Loss = 0.0011655670540490547, Recall = 1.0, Aging Rate = 0.4976536312849162, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0012204486220377866, Recall = 1.0, Aging Rate = 0.4976536312849162, precision = 1.0\n",
      "\n",
      "Epoch 21: Train Loss = 0.001447220254564585, Recall = 1.0, Aging Rate = 0.4976536312849162, Precision = 0, f1 = 0.0\n",
      "Epoch 22: Train Loss = 0.06215913781781769, Recall = 0.9806915132465199, Aging Rate = 0.5025698324022346, Precision = 0.9710982658959537, f1 = 0.9758713136729222\n",
      "Epoch 23: Train Loss = 0.04154352564062903, Recall = 0.9896722047597665, Aging Rate = 0.5023463687150838, Precision = 0.9804270462633452, f1 = 0.9850279329608939\n",
      "Epoch 24: Train Loss = 0.009555726627358782, Recall = 0.9968567579703638, Aging Rate = 0.49787709497206706, Precision = 0.9964093357271095, f1 = 0.9966329966329966\n",
      "Epoch 25: Train Loss = 0.005037488146592712, Recall = 0.9991019308486754, Aging Rate = 0.4981005586592179, Precision = 0.9982054733064154, f1 = 0.998653500897666\n",
      "Test Loss = 0.002881066755608879, Recall = 1.0, Aging Rate = 0.49787709497206706, precision = 0.9995511669658886\n",
      "\n",
      "Epoch 26: Train Loss = 0.0019747929659141386, Recall = 1.0, Aging Rate = 0.49787709497206706, Precision = 0.9995511669658886, f1 = 0.9997755331088665\n",
      "Epoch 27: Train Loss = 0.0007882041384741748, Recall = 1.0, Aging Rate = 0.4976536312849162, Precision = 0, f1 = 0.0\n",
      "Epoch 28: Train Loss = 0.0007486657182004449, Recall = 1.0, Aging Rate = 0.4976536312849162, Precision = 0, f1 = 0.0\n",
      "Epoch 29: Train Loss = 0.000878932501264853, Recall = 1.0, Aging Rate = 0.4976536312849162, Precision = 0, f1 = 0.0\n",
      "Epoch 30: Train Loss = 0.0010386683029713181, Recall = 1.0, Aging Rate = 0.4976536312849162, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.001012469597041149, Recall = 1.0, Aging Rate = 0.4976536312849162, precision = 1.0\n",
      "\n",
      "Epoch 31: Train Loss = 0.0011308312525337967, Recall = 1.0, Aging Rate = 0.4976536312849162, Precision = 0, f1 = 0.0\n",
      "Epoch 32: Train Loss = 0.0021519460229400818, Recall = 1.0, Aging Rate = 0.4976536312849162, Precision = 0, f1 = 0.0\n",
      "Epoch 33: Train Loss = 0.014614749226261284, Recall = 0.997305792546026, Aging Rate = 0.4994413407821229, Precision = 0.9937360178970918, f1 = 0.9955177050649933\n",
      "Epoch 34: Train Loss = 0.040005603964601816, Recall = 0.9874270318814549, Aging Rate = 0.49988826815642456, Precision = 0.9830129637907913, f1 = 0.9852150537634409\n",
      "Epoch 35: Train Loss = 0.01283315059234643, Recall = 0.9977548271216884, Aging Rate = 0.49921787709497206, Precision = 0.9946284691136974, f1 = 0.9961891952477023\n",
      "Test Loss = 0.002184572078953575, Recall = 1.0, Aging Rate = 0.4976536312849162, precision = 1.0\n",
      "\n",
      "Epoch 36: Train Loss = 0.0013541414919920661, Recall = 1.0, Aging Rate = 0.4976536312849162, Precision = 0, f1 = 0.0\n",
      "Epoch 37: Train Loss = 0.0007574906238281902, Recall = 1.0, Aging Rate = 0.4976536312849162, Precision = 0, f1 = 0.0\n",
      "Epoch 38: Train Loss = 0.0007973030092475634, Recall = 1.0, Aging Rate = 0.4976536312849162, Precision = 0, f1 = 0.0\n",
      "Epoch 39: Train Loss = 0.0009453285941021652, Recall = 1.0, Aging Rate = 0.4976536312849162, Precision = 0, f1 = 0.0\n",
      "Epoch 40: Train Loss = 0.0009720473399765623, Recall = 1.0, Aging Rate = 0.4976536312849162, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0010217955537132565, Recall = 1.0, Aging Rate = 0.4976536312849162, precision = 1.0\n",
      "\n",
      "Epoch 41: Train Loss = 0.00900639144755775, Recall = 0.9982038616973506, Aging Rate = 0.4987709497206704, Precision = 0.9959677419354839, f1 = 0.9970845481049563\n",
      "Epoch 42: Train Loss = 0.015494209033613973, Recall = 0.9964077233947014, Aging Rate = 0.4983240223463687, Precision = 0.9950672645739911, f1 = 0.9957370428539377\n",
      "Epoch 43: Train Loss = 0.017659696641914007, Recall = 0.9964077233947014, Aging Rate = 0.5003351955307263, Precision = 0.9910674408217954, f1 = 0.993730407523511\n",
      "Epoch 44: Train Loss = 0.028794753849298263, Recall = 0.9937135159407274, Aging Rate = 0.49921787709497206, Precision = 0.9905998209489705, f1 = 0.9921542255099755\n",
      "Epoch 45: Train Loss = 0.007782003729429887, Recall = 0.998652896273013, Aging Rate = 0.49854748603351956, Precision = 0.9968623935454953, f1 = 0.9977568416330193\n",
      "Test Loss = 0.006789936306496156, Recall = 0.9995509654243376, Aging Rate = 0.4983240223463687, precision = 0.9982062780269059\n",
      "\n",
      "Epoch 46: Train Loss = 0.008815602234424243, Recall = 0.9977548271216884, Aging Rate = 0.49787709497206706, Precision = 0.9973070017953322, f1 = 0.9975308641975309\n",
      "Epoch 47: Train Loss = 0.005649145544121594, Recall = 0.9995509654243376, Aging Rate = 0.4983240223463687, Precision = 0.9982062780269059, f1 = 0.9988781691720888\n",
      "Epoch 48: Train Loss = 0.0006714343315760434, Recall = 1.0, Aging Rate = 0.4976536312849162, Precision = 0, f1 = 0.0\n",
      "Epoch 49: Train Loss = 0.0005958703055967416, Recall = 1.0, Aging Rate = 0.4976536312849162, Precision = 0, f1 = 0.0\n",
      "Epoch 50: Train Loss = 0.0006665628726331402, Recall = 1.0, Aging Rate = 0.4976536312849162, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0006976908885525259, Recall = 1.0, Aging Rate = 0.4976536312849162, precision = 1.0\n",
      "\n",
      "Epoch 51: Train Loss = 0.0007993349814839536, Recall = 1.0, Aging Rate = 0.4976536312849162, Precision = 0, f1 = 0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 52: Train Loss = 0.000997254590025203, Recall = 1.0, Aging Rate = 0.4976536312849162, Precision = 0, f1 = 0.0\n",
      "Epoch 53: Train Loss = 0.0011987821537709936, Recall = 1.0, Aging Rate = 0.4976536312849162, Precision = 0, f1 = 0.0\n",
      "Epoch 54: Train Loss = 0.00504305284069695, Recall = 0.9991019308486754, Aging Rate = 0.49787709497206706, Precision = 0.998653500897666, f1 = 0.9988776655443322\n",
      "Epoch 55: Train Loss = 0.028084892278027268, Recall = 0.9910193084867535, Aging Rate = 0.49899441340782125, Precision = 0.9883564711150918, f1 = 0.9896860986547085\n",
      "Test Loss = 0.02967075162457937, Recall = 0.9995509654243376, Aging Rate = 0.5092737430167598, precision = 0.9767441860465116\n",
      "\n",
      "Epoch 56: Train Loss = 0.01908053589391642, Recall = 0.9955096542433768, Aging Rate = 0.5001117318435754, Precision = 0.9906166219839142, f1 = 0.9930571108622621\n",
      "Epoch 57: Train Loss = 0.027283197161559452, Recall = 0.9932644813650651, Aging Rate = 0.5001117318435754, Precision = 0.9883824843610366, f1 = 0.9908174692049272\n",
      "Epoch 58: Train Loss = 0.008836189592569318, Recall = 0.9982038616973506, Aging Rate = 0.4983240223463687, Precision = 0.9968609865470852, f1 = 0.9975319721785955\n",
      "Epoch 59: Train Loss = 0.0020566927283409172, Recall = 1.0, Aging Rate = 0.4983240223463687, Precision = 0.9986547085201793, f1 = 0.9993269015032533\n",
      "Epoch 60: Train Loss = 0.0012119501998632438, Recall = 0.9995509654243376, Aging Rate = 0.4976536312849162, Precision = 0.9995509654243376, f1 = 0.9995509654243376\n",
      "Test Loss = 0.0011252403596751705, Recall = 0.9995509654243376, Aging Rate = 0.49743016759776537, precision = 1.0\n",
      "\n",
      "Training Finished at epoch 60.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "38c96c3fcb9a4d9e9f067eff7eb27cd0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss = 0.34818087907143813, Recall = 0.8850471486304445, Aging Rate = 0.5486033519553073, Precision = 0.8028513238289205, f1 = 0.841947885519009\n",
      "Epoch 2: Train Loss = 0.1424219683312171, Recall = 0.960035922766053, Aging Rate = 0.5077094972067039, Precision = 0.9410211267605634, f1 = 0.9504334296510336\n",
      "Epoch 3: Train Loss = 0.08330733445519842, Recall = 0.9726088908845981, Aging Rate = 0.5023463687150838, Precision = 0.9635231316725978, f1 = 0.9680446927374302\n",
      "Epoch 4: Train Loss = 0.057525772625507586, Recall = 0.9824876515491693, Aging Rate = 0.5003351955307263, Precision = 0.9772219740955784, f1 = 0.9798477384684281\n",
      "Epoch 5: Train Loss = 0.05941498574181642, Recall = 0.9824876515491693, Aging Rate = 0.5025698324022346, Precision = 0.9728768341485104, f1 = 0.9776586237712243\n",
      "Test Loss = 0.027206805382111218, Recall = 1.0, Aging Rate = 0.5052513966480446, precision = 0.9849624060150376\n",
      "Model in epoch 5 is saved.\n",
      "\n",
      "Epoch 6: Train Loss = 0.011064942462120059, Recall = 0.997305792546026, Aging Rate = 0.4972067039106145, Precision = 0.9982022471910112, f1 = 0.9977538185085355\n",
      "Epoch 7: Train Loss = 0.003616986165431916, Recall = 1.0, Aging Rate = 0.49787709497206706, Precision = 0.9995511669658886, f1 = 0.9997755331088665\n",
      "Epoch 8: Train Loss = 0.0023862566524211256, Recall = 1.0, Aging Rate = 0.4976536312849162, Precision = 0, f1 = 0.0\n",
      "Epoch 9: Train Loss = 0.002379796225369476, Recall = 1.0, Aging Rate = 0.4976536312849162, Precision = 0, f1 = 0.0\n",
      "Epoch 10: Train Loss = 0.001985956816699918, Recall = 1.0, Aging Rate = 0.4976536312849162, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0019660635815163313, Recall = 1.0, Aging Rate = 0.4976536312849162, precision = 1.0\n",
      "Model in epoch 10 is saved.\n",
      "\n",
      "Epoch 11: Train Loss = 0.0032883191406310602, Recall = 1.0, Aging Rate = 0.49787709497206706, Precision = 0.9995511669658886, f1 = 0.9997755331088665\n",
      "Epoch 12: Train Loss = 0.005920265436058021, Recall = 1.0, Aging Rate = 0.4983240223463687, Precision = 0.9986547085201793, f1 = 0.9993269015032533\n",
      "Epoch 13: Train Loss = 0.004031753710122498, Recall = 0.9995509654243376, Aging Rate = 0.4976536312849162, Precision = 0.9995509654243376, f1 = 0.9995509654243376\n",
      "Epoch 14: Train Loss = 0.00994380421228915, Recall = 0.997305792546026, Aging Rate = 0.49787709497206706, Precision = 0.9968581687612208, f1 = 0.9970819304152637\n",
      "Epoch 15: Train Loss = 0.02380466123553794, Recall = 0.9932644813650651, Aging Rate = 0.5003351955307263, Precision = 0.9879410451094238, f1 = 0.9905956112852663\n",
      "Test Loss = 0.09883943021276644, Recall = 0.9371351594072743, Aging Rate = 0.46681564245810053, precision = 0.9990426041168023\n",
      "\n",
      "Epoch 16: Train Loss = 0.029416385973652814, Recall = 0.9928154467894028, Aging Rate = 0.5010055865921788, Precision = 0.9861730597680642, f1 = 0.9894831058402327\n",
      "Epoch 17: Train Loss = 0.004325745488424635, Recall = 0.9995509654243376, Aging Rate = 0.49787709497206706, Precision = 0.9991023339317774, f1 = 0.9993265993265993\n",
      "Epoch 18: Train Loss = 0.002153770882927672, Recall = 0.9995509654243376, Aging Rate = 0.4976536312849162, Precision = 0.9995509654243376, f1 = 0.9995509654243376\n",
      "Epoch 19: Train Loss = 0.0008176410680262153, Recall = 1.0, Aging Rate = 0.4976536312849162, Precision = 0, f1 = 0.0\n",
      "Epoch 20: Train Loss = 0.000741015233011011, Recall = 1.0, Aging Rate = 0.4976536312849162, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0007576641127045719, Recall = 1.0, Aging Rate = 0.4976536312849162, precision = 1.0\n",
      "\n",
      "Epoch 21: Train Loss = 0.0008025931374152977, Recall = 1.0, Aging Rate = 0.4976536312849162, Precision = 0, f1 = 0.0\n",
      "Epoch 22: Train Loss = 0.001014201095582678, Recall = 1.0, Aging Rate = 0.4976536312849162, Precision = 0, f1 = 0.0\n",
      "Epoch 23: Train Loss = 0.0013333559688440831, Recall = 1.0, Aging Rate = 0.4976536312849162, Precision = 0, f1 = 0.0\n",
      "Epoch 24: Train Loss = 0.0014884907837473273, Recall = 1.0, Aging Rate = 0.4976536312849162, Precision = 0, f1 = 0.0\n",
      "Epoch 25: Train Loss = 0.03869357789226667, Recall = 0.9869779973057925, Aging Rate = 0.5007821229050279, Precision = 0.9808121374386435, f1 = 0.9838854073410922\n",
      "Test Loss = 0.04036585390484533, Recall = 0.9883251010327795, Aging Rate = 0.49988826815642456, precision = 0.983907018328118\n",
      "\n",
      "Epoch 26: Train Loss = 0.037050471293360164, Recall = 0.9905702739110912, Aging Rate = 0.5005586592178771, Precision = 0.9848214285714286, f1 = 0.9876874860085069\n",
      "Epoch 27: Train Loss = 0.011773613486048771, Recall = 0.9977548271216884, Aging Rate = 0.49988826815642456, Precision = 0.9932945909700491, f1 = 0.9955197132616487\n",
      "Epoch 28: Train Loss = 0.003369166957014162, Recall = 0.9995509654243376, Aging Rate = 0.4981005586592179, Precision = 0.9986541049798116, f1 = 0.9991023339317774\n",
      "Epoch 29: Train Loss = 0.0009618314697768789, Recall = 1.0, Aging Rate = 0.4976536312849162, Precision = 0, f1 = 0.0\n",
      "Epoch 30: Train Loss = 0.001111242978211867, Recall = 1.0, Aging Rate = 0.4976536312849162, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0007486595131077039, Recall = 1.0, Aging Rate = 0.4976536312849162, precision = 1.0\n",
      "\n",
      "Epoch 31: Train Loss = 0.0007465119686370518, Recall = 1.0, Aging Rate = 0.4976536312849162, Precision = 0, f1 = 0.0\n",
      "Epoch 32: Train Loss = 0.0012415588489868912, Recall = 1.0, Aging Rate = 0.4976536312849162, Precision = 0, f1 = 0.0\n",
      "Epoch 33: Train Loss = 0.0009629494173051634, Recall = 1.0, Aging Rate = 0.4976536312849162, Precision = 0, f1 = 0.0\n",
      "Epoch 34: Train Loss = 0.0010384156295051537, Recall = 1.0, Aging Rate = 0.4976536312849162, Precision = 0, f1 = 0.0\n",
      "Epoch 35: Train Loss = 0.001176106544398812, Recall = 1.0, Aging Rate = 0.4976536312849162, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0011300381160648176, Recall = 1.0, Aging Rate = 0.4976536312849162, precision = 1.0\n",
      "\n",
      "Epoch 36: Train Loss = 0.0013330607731402565, Recall = 1.0, Aging Rate = 0.4976536312849162, Precision = 0, f1 = 0.0\n",
      "Epoch 37: Train Loss = 0.022798860282663192, Recall = 0.9941625505163898, Aging Rate = 0.4983240223463687, Precision = 0.9928251121076234, f1 = 0.9934933811981155\n",
      "Epoch 38: Train Loss = 0.05647085688300639, Recall = 0.9865289627301302, Aging Rate = 0.5032402234636871, Precision = 0.9755772646536413, f1 = 0.981022549676267\n",
      "Epoch 39: Train Loss = 0.006221423822626805, Recall = 0.998652896273013, Aging Rate = 0.49743016759776537, Precision = 0.9991015274034142, f1 = 0.9988771614641814\n",
      "Epoch 40: Train Loss = 0.0010799013980398965, Recall = 1.0, Aging Rate = 0.49787709497206706, Precision = 0.9995511669658886, f1 = 0.9997755331088665\n",
      "Test Loss = 0.001216393710080243, Recall = 0.9995509654243376, Aging Rate = 0.49743016759776537, precision = 1.0\n",
      "\n",
      "Epoch 41: Train Loss = 0.0025958601559652795, Recall = 1.0, Aging Rate = 0.49787709497206706, Precision = 0.9995511669658886, f1 = 0.9997755331088665\n",
      "Epoch 42: Train Loss = 0.003711866580532583, Recall = 0.9991019308486754, Aging Rate = 0.49787709497206706, Precision = 0.998653500897666, f1 = 0.9988776655443322\n",
      "Epoch 43: Train Loss = 0.0025740463183880602, Recall = 1.0, Aging Rate = 0.49787709497206706, Precision = 0.9995511669658886, f1 = 0.9997755331088665\n",
      "Epoch 44: Train Loss = 0.000920762390135033, Recall = 1.0, Aging Rate = 0.4976536312849162, Precision = 0, f1 = 0.0\n",
      "Epoch 45: Train Loss = 0.0009102697202457146, Recall = 1.0, Aging Rate = 0.4976536312849162, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0010049121723544143, Recall = 1.0, Aging Rate = 0.4976536312849162, precision = 1.0\n",
      "\n",
      "Epoch 46: Train Loss = 0.0010936517280646127, Recall = 1.0, Aging Rate = 0.4976536312849162, Precision = 0, f1 = 0.0\n",
      "Epoch 47: Train Loss = 0.005167134564718513, Recall = 0.9995509654243376, Aging Rate = 0.4976536312849162, Precision = 0.9995509654243376, f1 = 0.9995509654243376\n",
      "Epoch 48: Train Loss = 0.006336670218649523, Recall = 0.998652896273013, Aging Rate = 0.49787709497206706, Precision = 0.9982046678635548, f1 = 0.998428731762065\n",
      "Epoch 49: Train Loss = 0.030328472922946322, Recall = 0.9923664122137404, Aging Rate = 0.5001117318435754, Precision = 0.9874888293118856, f1 = 0.9899216125419933\n",
      "Epoch 50: Train Loss = 0.006890210607063088, Recall = 0.9991019308486754, Aging Rate = 0.4981005586592179, Precision = 0.9982054733064154, f1 = 0.998653500897666\n",
      "Test Loss = 0.0019705886256428406, Recall = 1.0, Aging Rate = 0.49787709497206706, precision = 0.9995511669658886\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 51: Train Loss = 0.0013108683617489006, Recall = 1.0, Aging Rate = 0.4976536312849162, Precision = 0, f1 = 0.0\n",
      "Epoch 52: Train Loss = 0.0017936139217156438, Recall = 0.9995509654243376, Aging Rate = 0.4976536312849162, Precision = 0.9995509654243376, f1 = 0.9995509654243376\n",
      "Epoch 53: Train Loss = 0.0009589799341105715, Recall = 1.0, Aging Rate = 0.4976536312849162, Precision = 0, f1 = 0.0\n",
      "Epoch 54: Train Loss = 0.0010414207940947203, Recall = 1.0, Aging Rate = 0.4976536312849162, Precision = 0, f1 = 0.0\n",
      "Epoch 55: Train Loss = 0.005414088140632021, Recall = 0.9991019308486754, Aging Rate = 0.4976536312849162, Precision = 0.9991019308486754, f1 = 0.9991019308486754\n",
      "Test Loss = 0.011107952595121285, Recall = 0.9995509654243376, Aging Rate = 0.5018994413407821, precision = 0.9910952804986642\n",
      "\n",
      "Epoch 56: Train Loss = 0.017270140507201243, Recall = 0.9964077233947014, Aging Rate = 0.5001117318435754, Precision = 0.9915102770330653, f1 = 0.9939529675251959\n",
      "Epoch 57: Train Loss = 0.026403207546464226, Recall = 0.9941625505163898, Aging Rate = 0.5007821229050279, Precision = 0.9879518072289156, f1 = 0.9910474485228289\n",
      "Epoch 58: Train Loss = 0.00593971376733948, Recall = 0.9982038616973506, Aging Rate = 0.49743016759776537, Precision = 0.9986522911051213, f1 = 0.9984280260498539\n",
      "Epoch 59: Train Loss = 0.0018148769361978948, Recall = 0.9995509654243376, Aging Rate = 0.4976536312849162, Precision = 0.9995509654243376, f1 = 0.9995509654243376\n",
      "Epoch 60: Train Loss = 0.0009378166667539522, Recall = 1.0, Aging Rate = 0.4976536312849162, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0005977208380764298, Recall = 1.0, Aging Rate = 0.4976536312849162, precision = 1.0\n",
      "\n",
      "Training Finished at epoch 60.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d13fad92beaf4ff38a90be02f3fe5b39",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss = 0.3385678532503171, Recall = 0.899416255051639, Aging Rate = 0.5515083798882682, Precision = 0.8115883306320908, f1 = 0.8532481363152289\n",
      "Epoch 2: Train Loss = 0.1231879153531357, Recall = 0.9645262685226762, Aging Rate = 0.5065921787709498, Precision = 0.9475077194530216, f1 = 0.9559412550066755\n",
      "Epoch 3: Train Loss = 0.07932345238269707, Recall = 0.9775482712168837, Aging Rate = 0.5023463687150838, Precision = 0.9684163701067615, f1 = 0.9729608938547485\n",
      "Epoch 4: Train Loss = 0.04882003177019804, Recall = 0.9842837898518186, Aging Rate = 0.4976536312849162, Precision = 0.9842837898518186, f1 = 0.9842837898518186\n",
      "Epoch 5: Train Loss = 0.0454899624822526, Recall = 0.9860799281544679, Aging Rate = 0.5016759776536313, Precision = 0.978173719376392, f1 = 0.9821109123434705\n",
      "Test Loss = 0.016741351703306734, Recall = 0.9995509654243376, Aging Rate = 0.5018994413407821, precision = 0.9910952804986642\n",
      "Model in epoch 5 is saved.\n",
      "\n",
      "Epoch 6: Train Loss = 0.013577157105865508, Recall = 0.997305792546026, Aging Rate = 0.4994413407821229, Precision = 0.9937360178970918, f1 = 0.9955177050649933\n",
      "Epoch 7: Train Loss = 0.005091660443547718, Recall = 0.9995509654243376, Aging Rate = 0.4981005586592179, Precision = 0.9986541049798116, f1 = 0.9991023339317774\n",
      "Epoch 8: Train Loss = 0.002176992879145097, Recall = 1.0, Aging Rate = 0.4976536312849162, Precision = 0, f1 = 0.0\n",
      "Epoch 9: Train Loss = 0.0024249229567546876, Recall = 0.9995509654243376, Aging Rate = 0.4976536312849162, Precision = 0.9995509654243376, f1 = 0.9995509654243376\n",
      "Epoch 10: Train Loss = 0.0025803862187189345, Recall = 1.0, Aging Rate = 0.49787709497206706, Precision = 0.9995511669658886, f1 = 0.9997755331088665\n",
      "Test Loss = 0.004782958348130797, Recall = 0.9977548271216884, Aging Rate = 0.496536312849162, precision = 1.0\n",
      "Model in epoch 10 is saved.\n",
      "\n",
      "Epoch 11: Train Loss = 0.003922998507054492, Recall = 0.9995509654243376, Aging Rate = 0.49787709497206706, Precision = 0.9991023339317774, f1 = 0.9993265993265993\n",
      "Epoch 12: Train Loss = 0.001697269688885888, Recall = 1.0, Aging Rate = 0.4976536312849162, Precision = 0, f1 = 0.0\n",
      "Epoch 13: Train Loss = 0.001485036901619764, Recall = 1.0, Aging Rate = 0.4976536312849162, Precision = 0, f1 = 0.0\n",
      "Epoch 14: Train Loss = 0.0014701829804887984, Recall = 1.0, Aging Rate = 0.4976536312849162, Precision = 0, f1 = 0.0\n",
      "Epoch 15: Train Loss = 0.0015988128620763075, Recall = 1.0, Aging Rate = 0.4976536312849162, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0015586357569977558, Recall = 1.0, Aging Rate = 0.4976536312849162, precision = 1.0\n",
      "Model in epoch 15 is saved.\n",
      "\n",
      "Epoch 16: Train Loss = 0.0022344984948718346, Recall = 1.0, Aging Rate = 0.4976536312849162, Precision = 0, f1 = 0.0\n",
      "Epoch 17: Train Loss = 0.08140669838218383, Recall = 0.9726088908845981, Aging Rate = 0.49988826815642456, Precision = 0.9682610639248994, f1 = 0.9704301075268819\n",
      "Epoch 18: Train Loss = 0.02784488889071362, Recall = 0.9923664122137404, Aging Rate = 0.5016759776536313, Precision = 0.9844097995545658, f1 = 0.9883720930232558\n",
      "Epoch 19: Train Loss = 0.0065643716323600465, Recall = 0.998652896273013, Aging Rate = 0.4981005586592179, Precision = 0.9977568416330193, f1 = 0.9982046678635548\n",
      "Epoch 20: Train Loss = 0.002033432468436346, Recall = 0.9995509654243376, Aging Rate = 0.4976536312849162, Precision = 0.9995509654243376, f1 = 0.9995509654243376\n",
      "Test Loss = 0.0009938539864037539, Recall = 1.0, Aging Rate = 0.49787709497206706, precision = 0.9995511669658886\n",
      "\n",
      "Epoch 21: Train Loss = 0.0009357042600499602, Recall = 1.0, Aging Rate = 0.4976536312849162, Precision = 0, f1 = 0.0\n",
      "Epoch 22: Train Loss = 0.0008779001453964238, Recall = 1.0, Aging Rate = 0.4976536312849162, Precision = 0, f1 = 0.0\n",
      "Epoch 23: Train Loss = 0.0010096363357512811, Recall = 1.0, Aging Rate = 0.4976536312849162, Precision = 0, f1 = 0.0\n",
      "Epoch 24: Train Loss = 0.0011165149193309123, Recall = 1.0, Aging Rate = 0.4976536312849162, Precision = 0, f1 = 0.0\n",
      "Epoch 25: Train Loss = 0.0012062819141051707, Recall = 1.0, Aging Rate = 0.4976536312849162, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0011520081598509373, Recall = 1.0, Aging Rate = 0.4976536312849162, precision = 1.0\n",
      "\n",
      "Epoch 26: Train Loss = 0.020098756888683615, Recall = 0.9932644813650651, Aging Rate = 0.49787709497206706, Precision = 0.992818671454219, f1 = 0.9930415263748595\n",
      "Epoch 27: Train Loss = 0.06187992999007582, Recall = 0.9896722047597665, Aging Rate = 0.5070391061452514, Precision = 0.9713530189510797, f1 = 0.9804270462633452\n",
      "Epoch 28: Train Loss = 0.009811573825859824, Recall = 0.9982038616973506, Aging Rate = 0.4976536312849162, Precision = 0.9982038616973506, f1 = 0.9982038616973506\n",
      "Epoch 29: Train Loss = 0.0027944561337021976, Recall = 0.9995509654243376, Aging Rate = 0.49787709497206706, Precision = 0.9991023339317774, f1 = 0.9993265993265993\n",
      "Epoch 30: Train Loss = 0.0011174131277558398, Recall = 1.0, Aging Rate = 0.4976536312849162, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0009017536980256063, Recall = 1.0, Aging Rate = 0.4976536312849162, precision = 1.0\n",
      "\n",
      "Epoch 31: Train Loss = 0.0011379297900757643, Recall = 1.0, Aging Rate = 0.4976536312849162, Precision = 0, f1 = 0.0\n",
      "Epoch 32: Train Loss = 0.0010463319726447008, Recall = 1.0, Aging Rate = 0.4976536312849162, Precision = 0, f1 = 0.0\n",
      "Epoch 33: Train Loss = 0.0010614103823900223, Recall = 1.0, Aging Rate = 0.4976536312849162, Precision = 0, f1 = 0.0\n",
      "Epoch 34: Train Loss = 0.001152196382796756, Recall = 1.0, Aging Rate = 0.4976536312849162, Precision = 0, f1 = 0.0\n",
      "Epoch 35: Train Loss = 0.0013392592907243268, Recall = 1.0, Aging Rate = 0.4976536312849162, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.001526503080720675, Recall = 1.0, Aging Rate = 0.49787709497206706, precision = 0.9995511669658886\n",
      "\n",
      "Epoch 36: Train Loss = 0.0021235290987354667, Recall = 1.0, Aging Rate = 0.4976536312849162, Precision = 0, f1 = 0.0\n",
      "Epoch 37: Train Loss = 0.0017520682524639968, Recall = 1.0, Aging Rate = 0.4976536312849162, Precision = 0, f1 = 0.0\n",
      "Epoch 38: Train Loss = 0.015413541462605393, Recall = 0.9968567579703638, Aging Rate = 0.49921787709497206, Precision = 0.9937332139659804, f1 = 0.9952925353059853\n",
      "Epoch 39: Train Loss = 0.05820529865766953, Recall = 0.9815895823978447, Aging Rate = 0.5018994413407821, Precision = 0.9732858414959928, f1 = 0.9774200760116254\n",
      "Epoch 40: Train Loss = 0.011331779465453919, Recall = 0.9982038616973506, Aging Rate = 0.49988826815642456, Precision = 0.9937416182387125, f1 = 0.9959677419354838\n",
      "Test Loss = 0.005172985295749493, Recall = 1.0, Aging Rate = 0.4983240223463687, precision = 0.9986547085201793\n",
      "\n",
      "Epoch 41: Train Loss = 0.0025958034394090402, Recall = 0.9995509654243376, Aging Rate = 0.4976536312849162, Precision = 0.9995509654243376, f1 = 0.9995509654243376\n",
      "Epoch 42: Train Loss = 0.0011624177954388606, Recall = 1.0, Aging Rate = 0.4976536312849162, Precision = 0, f1 = 0.0\n",
      "Epoch 43: Train Loss = 0.0007195735061229024, Recall = 1.0, Aging Rate = 0.4976536312849162, Precision = 0, f1 = 0.0\n",
      "Epoch 44: Train Loss = 0.000789122764455602, Recall = 1.0, Aging Rate = 0.4976536312849162, Precision = 0, f1 = 0.0\n",
      "Epoch 45: Train Loss = 0.0009383239843440372, Recall = 1.0, Aging Rate = 0.4976536312849162, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0008647285681608128, Recall = 1.0, Aging Rate = 0.4976536312849162, precision = 1.0\n",
      "\n",
      "Epoch 46: Train Loss = 0.0011614766324656968, Recall = 1.0, Aging Rate = 0.4976536312849162, Precision = 0, f1 = 0.0\n",
      "Epoch 47: Train Loss = 0.0011909757713740431, Recall = 1.0, Aging Rate = 0.4976536312849162, Precision = 0, f1 = 0.0\n",
      "Epoch 48: Train Loss = 0.0014314247373564367, Recall = 1.0, Aging Rate = 0.4976536312849162, Precision = 0, f1 = 0.0\n",
      "Epoch 49: Train Loss = 0.03413990120335831, Recall = 0.9887741356084419, Aging Rate = 0.5018994413407821, Precision = 0.9804096170970614, f1 = 0.9845741113346747\n",
      "Epoch 50: Train Loss = 0.028183969725443663, Recall = 0.9923664122137404, Aging Rate = 0.5005586592178771, Precision = 0.9866071428571429, f1 = 0.9894783971345422\n",
      "Test Loss = 0.010143419572505996, Recall = 0.9964077233947014, Aging Rate = 0.4963128491620112, precision = 0.9990995047276002\n",
      "\n",
      "Epoch 51: Train Loss = 0.003929279600712341, Recall = 0.9995509654243376, Aging Rate = 0.4983240223463687, Precision = 0.9982062780269059, f1 = 0.9988781691720888\n",
      "Epoch 52: Train Loss = 0.0023830465178913307, Recall = 1.0, Aging Rate = 0.4981005586592179, Precision = 0.9991027366532077, f1 = 0.9995511669658886\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 53: Train Loss = 0.0008119205198791814, Recall = 1.0, Aging Rate = 0.4976536312849162, Precision = 0, f1 = 0.0\n",
      "Epoch 54: Train Loss = 0.0007415989507640082, Recall = 1.0, Aging Rate = 0.4976536312849162, Precision = 0, f1 = 0.0\n",
      "Epoch 55: Train Loss = 0.0008465833221848367, Recall = 1.0, Aging Rate = 0.4976536312849162, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0008149400989358527, Recall = 1.0, Aging Rate = 0.4976536312849162, precision = 1.0\n",
      "\n",
      "Epoch 56: Train Loss = 0.0009927301526501484, Recall = 1.0, Aging Rate = 0.4976536312849162, Precision = 0, f1 = 0.0\n",
      "Epoch 57: Train Loss = 0.0010712365935070117, Recall = 1.0, Aging Rate = 0.4976536312849162, Precision = 0, f1 = 0.0\n",
      "Epoch 58: Train Loss = 0.0010921855816518752, Recall = 1.0, Aging Rate = 0.4976536312849162, Precision = 0, f1 = 0.0\n",
      "Epoch 59: Train Loss = 0.0012489486940714984, Recall = 1.0, Aging Rate = 0.4976536312849162, Precision = 0, f1 = 0.0\n",
      "Epoch 60: Train Loss = 0.001633968477309083, Recall = 1.0, Aging Rate = 0.49787709497206706, Precision = 0.9995511669658886, f1 = 0.9997755331088665\n",
      "Test Loss = 0.0012818361098446242, Recall = 1.0, Aging Rate = 0.4976536312849162, precision = 1.0\n",
      "\n",
      "Epoch 61: Train Loss = 0.02112322544096319, Recall = 0.9937135159407274, Aging Rate = 0.4983240223463687, Precision = 0.9923766816143498, f1 = 0.9930446488669509\n",
      "Epoch 62: Train Loss = 0.04368911792336854, Recall = 0.9874270318814549, Aging Rate = 0.5003351955307263, Precision = 0.9821348816435909, f1 = 0.9847738468428123\n",
      "Epoch 63: Train Loss = 0.004912366114697269, Recall = 0.9995509654243376, Aging Rate = 0.49787709497206706, Precision = 0.9991023339317774, f1 = 0.9993265993265993\n",
      "Epoch 64: Train Loss = 0.0011754328415172393, Recall = 1.0, Aging Rate = 0.4976536312849162, Precision = 0, f1 = 0.0\n",
      "Epoch 65: Train Loss = 0.0008555875297027052, Recall = 1.0, Aging Rate = 0.4976536312849162, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0007533398588375297, Recall = 1.0, Aging Rate = 0.4976536312849162, precision = 1.0\n",
      "\n",
      "Training Finished at epoch 65.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "03b5db608c98497f93c435ff7f4420a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss = 0.33820817468885606, Recall = 0.8926807364167041, Aging Rate = 0.5468156424581005, Precision = 0.8124233755619126, f1 = 0.85066324347454\n",
      "Epoch 2: Train Loss = 0.1298347283391979, Recall = 0.962730130220027, Aging Rate = 0.5092737430167598, Precision = 0.9407634927599825, f1 = 0.9516200621393698\n",
      "Epoch 3: Train Loss = 0.08217326302601638, Recall = 0.9757521329142343, Aging Rate = 0.5012290502793296, Precision = 0.968791796700847, f1 = 0.9722595078299776\n",
      "Epoch 4: Train Loss = 0.057991088521380664, Recall = 0.9811405478221823, Aging Rate = 0.49966480446927375, Precision = 0.9771914132379249, f1 = 0.9791619986556127\n",
      "Epoch 5: Train Loss = 0.04372411983014818, Recall = 0.9838347552761563, Aging Rate = 0.49743016759776537, Precision = 0.9842767295597484, f1 = 0.9840556927913766\n",
      "Test Loss = 0.011975299503300443, Recall = 0.9995509654243376, Aging Rate = 0.4987709497206704, precision = 0.9973118279569892\n",
      "Model in epoch 5 is saved.\n",
      "\n",
      "Epoch 6: Train Loss = 0.008202218496859823, Recall = 0.9991019308486754, Aging Rate = 0.4983240223463687, Precision = 0.9977578475336323, f1 = 0.9984294368409243\n",
      "Epoch 7: Train Loss = 0.0025193235724540065, Recall = 1.0, Aging Rate = 0.4976536312849162, Precision = 0, f1 = 0.0\n",
      "Epoch 8: Train Loss = 0.0021061739166314043, Recall = 1.0, Aging Rate = 0.4976536312849162, Precision = 0, f1 = 0.0\n",
      "Epoch 9: Train Loss = 0.0026599818889530345, Recall = 0.9995509654243376, Aging Rate = 0.4976536312849162, Precision = 0.9995509654243376, f1 = 0.9995509654243376\n",
      "Epoch 10: Train Loss = 0.0036830369119828974, Recall = 0.9995509654243376, Aging Rate = 0.4976536312849162, Precision = 0.9995509654243376, f1 = 0.9995509654243376\n",
      "Test Loss = 0.003882822355036962, Recall = 0.997305792546026, Aging Rate = 0.4963128491620112, precision = 1.0\n",
      "Model in epoch 10 is saved.\n",
      "\n",
      "Epoch 11: Train Loss = 0.004941801883425959, Recall = 0.9991019308486754, Aging Rate = 0.49743016759776537, Precision = 0.9995507637017071, f1 = 0.999326296878509\n",
      "Epoch 12: Train Loss = 0.0020402387888092733, Recall = 1.0, Aging Rate = 0.4976536312849162, Precision = 0, f1 = 0.0\n",
      "Epoch 13: Train Loss = 0.0018465180314723507, Recall = 1.0, Aging Rate = 0.4976536312849162, Precision = 0, f1 = 0.0\n",
      "Epoch 14: Train Loss = 0.001672499845657685, Recall = 1.0, Aging Rate = 0.4976536312849162, Precision = 0, f1 = 0.0\n",
      "Epoch 15: Train Loss = 0.0017672529357860083, Recall = 1.0, Aging Rate = 0.4976536312849162, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0018133127304345536, Recall = 1.0, Aging Rate = 0.4976536312849162, precision = 1.0\n",
      "Model in epoch 15 is saved.\n",
      "\n",
      "Epoch 16: Train Loss = 0.0017759543294399228, Recall = 1.0, Aging Rate = 0.4976536312849162, Precision = 0, f1 = 0.0\n",
      "Epoch 17: Train Loss = 0.05918286186440031, Recall = 0.9815895823978447, Aging Rate = 0.5025698324022346, Precision = 0.9719875500222321, f1 = 0.9767649687220734\n",
      "Epoch 18: Train Loss = 0.03923769474237658, Recall = 0.9896722047597665, Aging Rate = 0.5005586592178771, Precision = 0.9839285714285714, f1 = 0.9867920304454891\n",
      "Epoch 19: Train Loss = 0.009370891902200336, Recall = 0.998652896273013, Aging Rate = 0.4994413407821229, Precision = 0.9950782997762864, f1 = 0.9968623935454952\n",
      "Epoch 20: Train Loss = 0.0019021320009510443, Recall = 1.0, Aging Rate = 0.4976536312849162, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0011021896772341563, Recall = 1.0, Aging Rate = 0.4976536312849162, precision = 1.0\n",
      "\n",
      "Epoch 21: Train Loss = 0.0008612802851939959, Recall = 1.0, Aging Rate = 0.4976536312849162, Precision = 0, f1 = 0.0\n",
      "Epoch 22: Train Loss = 0.0009248430794104933, Recall = 1.0, Aging Rate = 0.4976536312849162, Precision = 0, f1 = 0.0\n",
      "Epoch 23: Train Loss = 0.0010225370372047222, Recall = 1.0, Aging Rate = 0.4976536312849162, Precision = 0, f1 = 0.0\n",
      "Epoch 24: Train Loss = 0.001185350727391372, Recall = 1.0, Aging Rate = 0.4976536312849162, Precision = 0, f1 = 0.0\n",
      "Epoch 25: Train Loss = 0.0012280363004977227, Recall = 1.0, Aging Rate = 0.4976536312849162, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.001290607876729678, Recall = 1.0, Aging Rate = 0.4976536312849162, precision = 1.0\n",
      "\n",
      "Epoch 26: Train Loss = 0.0014966136707492464, Recall = 1.0, Aging Rate = 0.4976536312849162, Precision = 0, f1 = 0.0\n",
      "Epoch 27: Train Loss = 0.023972809997142693, Recall = 0.9932644813650651, Aging Rate = 0.5007821229050279, Precision = 0.9870593485051317, f1 = 0.9901521933751118\n",
      "Epoch 28: Train Loss = 0.03185379148736679, Recall = 0.9914683430624158, Aging Rate = 0.49921787709497206, Precision = 0.9883616830796778, f1 = 0.9899125756556826\n",
      "Epoch 29: Train Loss = 0.011247343198661615, Recall = 0.998652896273013, Aging Rate = 0.49899441340782125, Precision = 0.9959695476936856, f1 = 0.9973094170403588\n",
      "Epoch 30: Train Loss = 0.0031369608725218216, Recall = 0.9995509654243376, Aging Rate = 0.49787709497206706, Precision = 0.9991023339317774, f1 = 0.9993265993265993\n",
      "Test Loss = 0.001301077534834849, Recall = 1.0, Aging Rate = 0.4976536312849162, precision = 1.0\n",
      "\n",
      "Epoch 31: Train Loss = 0.0010176298120995598, Recall = 1.0, Aging Rate = 0.4976536312849162, Precision = 0, f1 = 0.0\n",
      "Epoch 32: Train Loss = 0.000734264762426971, Recall = 1.0, Aging Rate = 0.4976536312849162, Precision = 0, f1 = 0.0\n",
      "Epoch 33: Train Loss = 0.0008017298971516127, Recall = 1.0, Aging Rate = 0.4976536312849162, Precision = 0, f1 = 0.0\n",
      "Epoch 34: Train Loss = 0.001083105420940894, Recall = 1.0, Aging Rate = 0.4976536312849162, Precision = 0, f1 = 0.0\n",
      "Epoch 35: Train Loss = 0.001192440719593462, Recall = 1.0, Aging Rate = 0.4976536312849162, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.000989374115961661, Recall = 1.0, Aging Rate = 0.4976536312849162, precision = 1.0\n",
      "\n",
      "Epoch 36: Train Loss = 0.0011819550554481382, Recall = 1.0, Aging Rate = 0.4976536312849162, Precision = 0, f1 = 0.0\n",
      "Epoch 37: Train Loss = 0.03231855532601892, Recall = 0.9932644813650651, Aging Rate = 0.5016759776536313, Precision = 0.9853006681514477, f1 = 0.9892665474060823\n",
      "Epoch 38: Train Loss = 0.03905411356555392, Recall = 0.9869779973057925, Aging Rate = 0.49854748603351956, Precision = 0.9852084267144778, f1 = 0.9860924181247197\n",
      "Epoch 39: Train Loss = 0.0029061080379328332, Recall = 1.0, Aging Rate = 0.49787709497206706, Precision = 0.9995511669658886, f1 = 0.9997755331088665\n",
      "Epoch 40: Train Loss = 0.0010956809596306847, Recall = 1.0, Aging Rate = 0.4976536312849162, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0007438053820001264, Recall = 1.0, Aging Rate = 0.4976536312849162, precision = 1.0\n",
      "\n",
      "Epoch 41: Train Loss = 0.0008721148760146435, Recall = 1.0, Aging Rate = 0.4976536312849162, Precision = 0, f1 = 0.0\n",
      "Epoch 42: Train Loss = 0.0008796088567118072, Recall = 1.0, Aging Rate = 0.4976536312849162, Precision = 0, f1 = 0.0\n",
      "Epoch 43: Train Loss = 0.0010337987411298982, Recall = 1.0, Aging Rate = 0.4976536312849162, Precision = 0, f1 = 0.0\n",
      "Epoch 44: Train Loss = 0.0015523179241601773, Recall = 1.0, Aging Rate = 0.4976536312849162, Precision = 0, f1 = 0.0\n",
      "Epoch 45: Train Loss = 0.0012263942383978952, Recall = 1.0, Aging Rate = 0.4976536312849162, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.001393128421805362, Recall = 1.0, Aging Rate = 0.4976536312849162, precision = 1.0\n",
      "\n",
      "Epoch 46: Train Loss = 0.0013822730853581312, Recall = 1.0, Aging Rate = 0.4976536312849162, Precision = 0, f1 = 0.0\n",
      "Epoch 47: Train Loss = 0.0014267374953130187, Recall = 1.0, Aging Rate = 0.4976536312849162, Precision = 0, f1 = 0.0\n",
      "Epoch 48: Train Loss = 0.0017918454636377413, Recall = 1.0, Aging Rate = 0.4976536312849162, Precision = 0, f1 = 0.0\n",
      "Epoch 49: Train Loss = 0.01917997414402289, Recall = 0.994611585092052, Aging Rate = 0.49988826815642456, Precision = 0.9901654000894055, f1 = 0.9923835125448028\n",
      "Epoch 50: Train Loss = 0.0689930970145275, Recall = 0.9811405478221823, Aging Rate = 0.5032402234636871, Precision = 0.9702486678507993, f1 = 0.9756642107613307\n",
      "Test Loss = 0.010356990543906916, Recall = 0.9932644813650651, Aging Rate = 0.4947486033519553, precision = 0.999096657633243\n",
      "\n",
      "Epoch 51: Train Loss = 0.005649983093413061, Recall = 0.9982038616973506, Aging Rate = 0.49743016759776537, Precision = 0.9986522911051213, f1 = 0.9984280260498539\n",
      "Epoch 52: Train Loss = 0.0021057747334616477, Recall = 0.9995509654243376, Aging Rate = 0.49743016759776537, Precision = 0, f1 = 0.0\n",
      "Epoch 53: Train Loss = 0.0013524310886027426, Recall = 1.0, Aging Rate = 0.49787709497206706, Precision = 0.9995511669658886, f1 = 0.9997755331088665\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 54: Train Loss = 0.00201583663711855, Recall = 0.9995509654243376, Aging Rate = 0.49787709497206706, Precision = 0.9991023339317774, f1 = 0.9993265993265993\n",
      "Epoch 55: Train Loss = 0.0023178722367845684, Recall = 1.0, Aging Rate = 0.49787709497206706, Precision = 0.9995511669658886, f1 = 0.9997755331088665\n",
      "Test Loss = 0.0011090766265858278, Recall = 1.0, Aging Rate = 0.4976536312849162, precision = 1.0\n",
      "\n",
      "Epoch 56: Train Loss = 0.0013920491160668807, Recall = 1.0, Aging Rate = 0.4976536312849162, Precision = 0, f1 = 0.0\n",
      "Epoch 57: Train Loss = 0.0037701359895375352, Recall = 0.9995509654243376, Aging Rate = 0.4983240223463687, Precision = 0.9982062780269059, f1 = 0.9988781691720888\n",
      "Epoch 58: Train Loss = 0.004454962037992794, Recall = 0.9991019308486754, Aging Rate = 0.4983240223463687, Precision = 0.9977578475336323, f1 = 0.9984294368409243\n",
      "Epoch 59: Train Loss = 0.002684821139568432, Recall = 1.0, Aging Rate = 0.49787709497206706, Precision = 0.9995511669658886, f1 = 0.9997755331088665\n",
      "Epoch 60: Train Loss = 0.001162791264102945, Recall = 1.0, Aging Rate = 0.4976536312849162, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0009531680451362659, Recall = 1.0, Aging Rate = 0.4976536312849162, precision = 1.0\n",
      "\n",
      "Epoch 61: Train Loss = 0.001191970383431034, Recall = 1.0, Aging Rate = 0.4976536312849162, Precision = 0, f1 = 0.0\n",
      "Epoch 62: Train Loss = 0.025913494161054408, Recall = 0.9923664122137404, Aging Rate = 0.4987709497206704, Precision = 0.9901433691756273, f1 = 0.9912536443148688\n",
      "Epoch 63: Train Loss = 0.02016022090389076, Recall = 0.9941625505163898, Aging Rate = 0.49966480446927375, Precision = 0.9901610017889088, f1 = 0.9921577414295317\n",
      "Epoch 64: Train Loss = 0.0031708316441479674, Recall = 1.0, Aging Rate = 0.4981005586592179, Precision = 0.9991027366532077, f1 = 0.9995511669658886\n",
      "Epoch 65: Train Loss = 0.002881410455685005, Recall = 0.9995509654243376, Aging Rate = 0.49787709497206706, Precision = 0.9991023339317774, f1 = 0.9993265993265993\n",
      "Test Loss = 0.0008764035931421579, Recall = 1.0, Aging Rate = 0.4976536312849162, precision = 1.0\n",
      "\n",
      "Training Finished at epoch 65.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6454e4853d3462fb32726fbf155230b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss = 0.44950094467513363, Recall = 0.8622082585278277, Aging Rate = 0.5871313672922251, Precision = 0.7309741248097412, f1 = 0.7911861614497528\n",
      "Epoch 2: Train Loss = 0.21523029175424704, Recall = 0.940754039497307, Aging Rate = 0.5218945487042002, Precision = 0.8972602739726028, f1 = 0.9184925503943908\n",
      "Epoch 3: Train Loss = 0.1333969311124518, Recall = 0.9654398563734291, Aging Rate = 0.5078194816800715, Precision = 0.9463264408271007, f1 = 0.9557876027549433\n",
      "Epoch 4: Train Loss = 0.10269634183945668, Recall = 0.9735188509874326, Aging Rate = 0.506478999106345, Precision = 0.956771063078959, f1 = 0.9650723025583983\n",
      "Epoch 5: Train Loss = 0.08367026005010184, Recall = 0.9824955116696589, Aging Rate = 0.5046916890080428, Precision = 0.9690128375387339, f1 = 0.9757075997325606\n",
      "Test Loss = 0.04090771613387895, Recall = 0.9973070017953322, Aging Rate = 0.5026809651474531, precision = 0.9875555555555555\n",
      "Model in epoch 5 is saved.\n",
      "\n",
      "Epoch 6: Train Loss = 0.03815220789759153, Recall = 0.992818671454219, Aging Rate = 0.49865951742627346, Precision = 0.9910394265232975, f1 = 0.9919282511210762\n",
      "Epoch 7: Train Loss = 0.026485645124843547, Recall = 0.9973070017953322, Aging Rate = 0.4984361036639857, Precision = 0.9959659345584939, f1 = 0.9966360170441803\n",
      "Epoch 8: Train Loss = 0.025041622951147383, Recall = 0.9968581687612208, Aging Rate = 0.4984361036639857, Precision = 0.9955177050649933, f1 = 0.9961874859834042\n",
      "Epoch 9: Train Loss = 0.022781830640564656, Recall = 0.9977558348294434, Aging Rate = 0.4979892761394102, Precision = 0.9973082099596231, f1 = 0.9975319721785955\n",
      "Epoch 10: Train Loss = 0.020799699351790765, Recall = 0.998653500897666, Aging Rate = 0.4982126899016979, Precision = 0.9977578475336323, f1 = 0.9982054733064155\n",
      "Test Loss = 0.02075630991692198, Recall = 0.9955116696588869, Aging Rate = 0.49575513851653263, precision = 0.9995493465525012\n",
      "Model in epoch 10 is saved.\n",
      "\n",
      "Epoch 11: Train Loss = 0.021882762990132892, Recall = 0.9977558348294434, Aging Rate = 0.4984361036639857, Precision = 0.9964141640519946, f1 = 0.9970845481049563\n",
      "Epoch 12: Train Loss = 0.022138829864861178, Recall = 0.998653500897666, Aging Rate = 0.49865951742627346, Precision = 0.9968637992831542, f1 = 0.9977578475336323\n",
      "Epoch 13: Train Loss = 0.019785444317110903, Recall = 0.998653500897666, Aging Rate = 0.4982126899016979, Precision = 0.9977578475336323, f1 = 0.9982054733064155\n",
      "Epoch 14: Train Loss = 0.018703009064331772, Recall = 0.9991023339317774, Aging Rate = 0.4984361036639857, Precision = 0.9977588525324966, f1 = 0.9984301412872841\n",
      "Epoch 15: Train Loss = 0.026641300841966198, Recall = 0.9964093357271095, Aging Rate = 0.5, Precision = 0.9919571045576407, f1 = 0.9941782355575459\n",
      "Test Loss = 0.02001081577105193, Recall = 0.9991023339317774, Aging Rate = 0.499106344950849, precision = 0.9964189794091316\n",
      "\n",
      "Epoch 16: Train Loss = 0.027303175885859506, Recall = 0.9959605026929982, Aging Rate = 0.4988829311885612, Precision = 0.9937304075235109, f1 = 0.9948442053351265\n",
      "Epoch 17: Train Loss = 0.02245315388294471, Recall = 0.9982046678635548, Aging Rate = 0.49955317247542447, Precision = 0.9946332737030411, f1 = 0.996415770609319\n",
      "Epoch 18: Train Loss = 0.01782221325620729, Recall = 0.9991023339317774, Aging Rate = 0.4988829311885612, Precision = 0.9968652037617555, f1 = 0.9979825151311364\n",
      "Epoch 19: Train Loss = 0.02071675770084596, Recall = 0.9964093357271095, Aging Rate = 0.4982126899016979, Precision = 0.9955156950672646, f1 = 0.9959623149394348\n",
      "Epoch 20: Train Loss = 0.01805772905265438, Recall = 0.9991023339317774, Aging Rate = 0.49865951742627346, Precision = 0.9973118279569892, f1 = 0.998206278026906\n",
      "Test Loss = 0.01512011748815989, Recall = 1.0, Aging Rate = 0.4979892761394102, precision = 0.9995513683266039\n",
      "Model in epoch 20 is saved.\n",
      "\n",
      "Epoch 21: Train Loss = 0.0177830572791857, Recall = 1.0, Aging Rate = 0.4984361036639857, Precision = 0.9986553115194979, f1 = 0.999327203408836\n",
      "Epoch 22: Train Loss = 0.02047999507070946, Recall = 0.9982046678635548, Aging Rate = 0.4982126899016979, Precision = 0.9973094170403587, f1 = 0.9977568416330193\n",
      "Epoch 23: Train Loss = 0.021529611532174392, Recall = 0.9964093357271095, Aging Rate = 0.4988829311885612, Precision = 0.9941782355575459, f1 = 0.9952925353059853\n",
      "Epoch 24: Train Loss = 0.026612321499125888, Recall = 0.9964093357271095, Aging Rate = 0.499106344950849, Precision = 0.9937332139659804, f1 = 0.9950694755714927\n",
      "Epoch 25: Train Loss = 0.027614491729530188, Recall = 0.9955116696588869, Aging Rate = 0.49977658623771226, Precision = 0.9915064818953956, f1 = 0.9935050391937291\n",
      "Test Loss = 0.01855954232728034, Recall = 0.9973070017953322, Aging Rate = 0.4968722073279714, precision = 0.9991007194244604\n",
      "\n",
      "Epoch 26: Train Loss = 0.021712522174733573, Recall = 0.9977558348294434, Aging Rate = 0.49977658623771226, Precision = 0.9937416182387125, f1 = 0.9957446808510638\n",
      "Epoch 27: Train Loss = 0.020242632174459922, Recall = 0.9968581687612208, Aging Rate = 0.4984361036639857, Precision = 0.9955177050649933, f1 = 0.9961874859834042\n",
      "Epoch 28: Train Loss = 0.02064753138028265, Recall = 0.9977558348294434, Aging Rate = 0.4984361036639857, Precision = 0.9964141640519946, f1 = 0.9970845481049563\n",
      "Epoch 29: Train Loss = 0.017778269956562537, Recall = 0.9973070017953322, Aging Rate = 0.49754244861483465, Precision = 0.9977548271216884, f1 = 0.9975308641975309\n",
      "Epoch 30: Train Loss = 0.0200275113511501, Recall = 0.9995511669658886, Aging Rate = 0.499106344950849, Precision = 0.9968666069829901, f1 = 0.9982070820259972\n",
      "Test Loss = 0.014084459392318937, Recall = 1.0, Aging Rate = 0.4979892761394102, precision = 0.9995513683266039\n",
      "\n",
      "Epoch 31: Train Loss = 0.015818382985390542, Recall = 0.9991023339317774, Aging Rate = 0.49776586237712245, Precision = 0.9991023339317774, f1 = 0.9991023339317774\n",
      "Epoch 32: Train Loss = 0.023013504336890204, Recall = 0.9973070017953322, Aging Rate = 0.49865951742627346, Precision = 0.9955197132616488, f1 = 0.9964125560538117\n",
      "Epoch 33: Train Loss = 0.01967828220440619, Recall = 0.9991023339317774, Aging Rate = 0.4988829311885612, Precision = 0.9968652037617555, f1 = 0.9979825151311364\n",
      "Epoch 34: Train Loss = 0.01500305924165105, Recall = 1.0, Aging Rate = 0.4984361036639857, Precision = 0.9986553115194979, f1 = 0.999327203408836\n",
      "Epoch 35: Train Loss = 0.017611371927542595, Recall = 0.9991023339317774, Aging Rate = 0.4984361036639857, Precision = 0.9977588525324966, f1 = 0.9984301412872841\n",
      "Test Loss = 0.018114384902945792, Recall = 1.0, Aging Rate = 0.5002234137622877, precision = 0.9950870924519875\n",
      "\n",
      "Epoch 36: Train Loss = 0.02300930825928501, Recall = 0.9968581687612208, Aging Rate = 0.4982126899016979, Precision = 0.9959641255605381, f1 = 0.9964109466128309\n",
      "Epoch 37: Train Loss = 0.017103454562518296, Recall = 0.9991023339317774, Aging Rate = 0.4982126899016979, Precision = 0.9982062780269059, f1 = 0.9986541049798117\n",
      "Epoch 38: Train Loss = 0.018022135993710473, Recall = 0.9995511669658886, Aging Rate = 0.499106344950849, Precision = 0.9968666069829901, f1 = 0.9982070820259972\n",
      "Epoch 39: Train Loss = 0.019490641499332703, Recall = 0.9995511669658886, Aging Rate = 0.499106344950849, Precision = 0.9968666069829901, f1 = 0.9982070820259972\n",
      "Epoch 40: Train Loss = 0.024726105958782635, Recall = 0.9959605026929982, Aging Rate = 0.49865951742627346, Precision = 0.9941756272401434, f1 = 0.995067264573991\n",
      "Test Loss = 0.023642713611011692, Recall = 1.0, Aging Rate = 0.5024575513851653, precision = 0.9906625166740773\n",
      "\n",
      "Epoch 41: Train Loss = 0.0222770434082673, Recall = 0.9973070017953322, Aging Rate = 0.4988829311885612, Precision = 0.9950738916256158, f1 = 0.9961891952477023\n",
      "Epoch 42: Train Loss = 0.029194306387458666, Recall = 0.9950628366247756, Aging Rate = 0.49865951742627346, Precision = 0.9932795698924731, f1 = 0.994170403587444\n",
      "Epoch 43: Train Loss = 0.02228618597976324, Recall = 0.9968581687612208, Aging Rate = 0.49955317247542447, Precision = 0.9932915921288015, f1 = 0.9950716845878136\n",
      "Epoch 44: Train Loss = 0.016246462500486874, Recall = 0.998653500897666, Aging Rate = 0.4979892761394102, Precision = 0.9982054733064154, f1 = 0.9984294368409243\n",
      "Epoch 45: Train Loss = 0.01509980173736571, Recall = 0.9995511669658886, Aging Rate = 0.4982126899016979, Precision = 0.9986547085201793, f1 = 0.9991027366532076\n",
      "Test Loss = 0.01237316250091983, Recall = 0.9995511669658886, Aging Rate = 0.4979892761394102, precision = 0.9991027366532077\n",
      "\n",
      "Epoch 46: Train Loss = 0.020356051908461403, Recall = 0.9977558348294434, Aging Rate = 0.49776586237712245, Precision = 0.9977558348294434, f1 = 0.9977558348294434\n",
      "Epoch 47: Train Loss = 0.0188173002116482, Recall = 0.998653500897666, Aging Rate = 0.49932975871313673, Precision = 0.9955257270693513, f1 = 0.9970871611023976\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 48: Train Loss = 0.023271548584223433, Recall = 0.9973070017953322, Aging Rate = 0.4988829311885612, Precision = 0.9950738916256158, f1 = 0.9961891952477023\n",
      "Epoch 49: Train Loss = 0.022031711124822537, Recall = 0.9973070017953322, Aging Rate = 0.4984361036639857, Precision = 0.9959659345584939, f1 = 0.9966360170441803\n",
      "Epoch 50: Train Loss = 0.015544457555855887, Recall = 0.9991023339317774, Aging Rate = 0.49776586237712245, Precision = 0.9991023339317774, f1 = 0.9991023339317774\n",
      "Test Loss = 0.011278529064704841, Recall = 1.0, Aging Rate = 0.49776586237712245, precision = 1.0\n",
      "Model in epoch 50 is saved.\n",
      "\n",
      "Epoch 51: Train Loss = 0.015096953722970416, Recall = 0.9995511669658886, Aging Rate = 0.4979892761394102, Precision = 0.9991027366532077, f1 = 0.9993269015032532\n",
      "Epoch 52: Train Loss = 0.019340254096738774, Recall = 0.9982046678635548, Aging Rate = 0.49776586237712245, Precision = 0.9982046678635548, f1 = 0.9982046678635548\n",
      "Epoch 53: Train Loss = 0.021430518158559186, Recall = 0.9977558348294434, Aging Rate = 0.49932975871313673, Precision = 0.9946308724832215, f1 = 0.9961909029800583\n",
      "Epoch 54: Train Loss = 0.021533003314111093, Recall = 0.998653500897666, Aging Rate = 0.4988829311885612, Precision = 0.9964173757277206, f1 = 0.9975341851602779\n",
      "Epoch 55: Train Loss = 0.021314809088852388, Recall = 0.998653500897666, Aging Rate = 0.5, Precision = 0.9941912421805184, f1 = 0.9964173757277205\n",
      "Test Loss = 0.017132191207189982, Recall = 0.9995511669658886, Aging Rate = 0.49865951742627346, precision = 0.9977598566308243\n",
      "\n",
      "Epoch 56: Train Loss = 0.015731308564304027, Recall = 0.9991023339317774, Aging Rate = 0.4984361036639857, Precision = 0.9977588525324966, f1 = 0.9984301412872841\n",
      "Epoch 57: Train Loss = 0.016477533483792887, Recall = 0.9991023339317774, Aging Rate = 0.49754244861483465, Precision = 0.9995509654243376, f1 = 0.9993265993265993\n",
      "Epoch 58: Train Loss = 0.01605150178724016, Recall = 1.0, Aging Rate = 0.49865951742627346, Precision = 0.9982078853046595, f1 = 0.9991031390134528\n",
      "Epoch 59: Train Loss = 0.01977981462695164, Recall = 0.9991023339317774, Aging Rate = 0.49865951742627346, Precision = 0.9973118279569892, f1 = 0.998206278026906\n",
      "Epoch 60: Train Loss = 0.017678712919134715, Recall = 0.9991023339317774, Aging Rate = 0.49955317247542447, Precision = 0.9955277280858676, f1 = 0.9973118279569891\n",
      "Test Loss = 0.016966601706362123, Recall = 0.9982046678635548, Aging Rate = 0.4968722073279714, precision = 1.0\n",
      "\n",
      "Epoch 61: Train Loss = 0.01927843834735433, Recall = 0.9991023339317774, Aging Rate = 0.49776586237712245, Precision = 0.9991023339317774, f1 = 0.9991023339317774\n",
      "Epoch 62: Train Loss = 0.022029352386859085, Recall = 0.9982046678635548, Aging Rate = 0.49865951742627346, Precision = 0.996415770609319, f1 = 0.9973094170403587\n",
      "Epoch 63: Train Loss = 0.018502379707672482, Recall = 0.998653500897666, Aging Rate = 0.4984361036639857, Precision = 0.997310623038996, f1 = 0.9979816102265081\n",
      "Epoch 64: Train Loss = 0.01839022132650457, Recall = 0.9991023339317774, Aging Rate = 0.4982126899016979, Precision = 0.9982062780269059, f1 = 0.9986541049798117\n",
      "Epoch 65: Train Loss = 0.016381722123389588, Recall = 0.9995511669658886, Aging Rate = 0.4988829311885612, Precision = 0.9973130317957905, f1 = 0.9984308451019951\n",
      "Test Loss = 0.021636950221641773, Recall = 1.0, Aging Rate = 0.5, precision = 0.9955317247542449\n",
      "\n",
      "Epoch 66: Train Loss = 0.020930284424497677, Recall = 0.9982046678635548, Aging Rate = 0.4988829311885612, Precision = 0.9959695476936856, f1 = 0.9970858551894195\n",
      "Epoch 67: Train Loss = 0.018760942631768158, Recall = 0.9982046678635548, Aging Rate = 0.4982126899016979, Precision = 0.9973094170403587, f1 = 0.9977568416330193\n",
      "Epoch 68: Train Loss = 0.019959801483409974, Recall = 0.9991023339317774, Aging Rate = 0.4984361036639857, Precision = 0.9977588525324966, f1 = 0.9984301412872841\n",
      "Epoch 69: Train Loss = 0.018420758080386603, Recall = 0.9973070017953322, Aging Rate = 0.4973190348525469, Precision = 0.9982030548068284, f1 = 0.9977548271216884\n",
      "Epoch 70: Train Loss = 0.02088935584099539, Recall = 0.998653500897666, Aging Rate = 0.49955317247542447, Precision = 0.9950805008944544, f1 = 0.996863799283154\n",
      "Test Loss = 0.016673154964164178, Recall = 0.9995511669658886, Aging Rate = 0.499106344950849, precision = 0.9968666069829901\n",
      "\n",
      "Epoch 71: Train Loss = 0.018148785846522603, Recall = 0.9991023339317774, Aging Rate = 0.4984361036639857, Precision = 0.9977588525324966, f1 = 0.9984301412872841\n",
      "Epoch 72: Train Loss = 0.014812375081767984, Recall = 0.9995511669658886, Aging Rate = 0.4979892761394102, Precision = 0.9991027366532077, f1 = 0.9993269015032532\n",
      "Epoch 73: Train Loss = 0.01785115288925075, Recall = 0.9991023339317774, Aging Rate = 0.4984361036639857, Precision = 0.9977588525324966, f1 = 0.9984301412872841\n",
      "Epoch 74: Train Loss = 0.01847025251700156, Recall = 0.9982046678635548, Aging Rate = 0.4984361036639857, Precision = 0.9968623935454953, f1 = 0.9975330791657323\n",
      "Epoch 75: Train Loss = 0.02429926355466766, Recall = 0.9977558348294434, Aging Rate = 0.5, Precision = 0.9932975871313673, f1 = 0.9955217196596508\n",
      "Test Loss = 0.019460296405644104, Recall = 0.9991023339317774, Aging Rate = 0.5006702412868632, precision = 0.9933065595716198\n",
      "\n",
      "Epoch 76: Train Loss = 0.02373915565407388, Recall = 0.9973070017953322, Aging Rate = 0.5, Precision = 0.9928507596067918, f1 = 0.9950738916256159\n",
      "Epoch 77: Train Loss = 0.019247653514606226, Recall = 0.9973070017953322, Aging Rate = 0.49932975871313673, Precision = 0.9941834451901566, f1 = 0.9957427739188887\n",
      "Epoch 78: Train Loss = 0.01786417987237587, Recall = 0.9982046678635548, Aging Rate = 0.49776586237712245, Precision = 0.9982046678635548, f1 = 0.9982046678635548\n",
      "Epoch 79: Train Loss = 0.01445181784407303, Recall = 0.9995511669658886, Aging Rate = 0.49776586237712245, Precision = 0.9995511669658886, f1 = 0.9995511669658886\n",
      "Epoch 80: Train Loss = 0.01501659209023532, Recall = 0.9995511669658886, Aging Rate = 0.4979892761394102, Precision = 0.9991027366532077, f1 = 0.9993269015032532\n",
      "Test Loss = 0.021891066527378624, Recall = 1.0, Aging Rate = 0.5008936550491511, precision = 0.9937555753791257\n",
      "\n",
      "Epoch 81: Train Loss = 0.01860142694211917, Recall = 0.9995511669658886, Aging Rate = 0.4984361036639857, Precision = 0.9982070820259973, f1 = 0.99887867234806\n",
      "Epoch 82: Train Loss = 0.017393537944347545, Recall = 0.9991023339317774, Aging Rate = 0.49865951742627346, Precision = 0.9973118279569892, f1 = 0.998206278026906\n",
      "Epoch 83: Train Loss = 0.016532553449752505, Recall = 0.9991023339317774, Aging Rate = 0.4979892761394102, Precision = 0.9986541049798116, f1 = 0.9988781691720889\n",
      "Epoch 84: Train Loss = 0.026335164100610858, Recall = 0.9968581687612208, Aging Rate = 0.499106344950849, Precision = 0.9941808415398389, f1 = 0.9955177050649933\n",
      "Epoch 85: Train Loss = 0.02351109700242492, Recall = 0.998653500897666, Aging Rate = 0.49932975871313673, Precision = 0.9955257270693513, f1 = 0.9970871611023976\n",
      "Test Loss = 0.013894804026781714, Recall = 0.9995511669658886, Aging Rate = 0.49865951742627346, precision = 0.9977598566308243\n",
      "\n",
      "Epoch 86: Train Loss = 0.016841052934008054, Recall = 0.998653500897666, Aging Rate = 0.4982126899016979, Precision = 0.9977578475336323, f1 = 0.9982054733064155\n",
      "Epoch 87: Train Loss = 0.014790557384810563, Recall = 0.9995511669658886, Aging Rate = 0.4984361036639857, Precision = 0.9982070820259973, f1 = 0.99887867234806\n",
      "Epoch 88: Train Loss = 0.02568189886675763, Recall = 0.9968581687612208, Aging Rate = 0.5008936550491511, Precision = 0.9906333630686887, f1 = 0.9937360178970918\n",
      "Epoch 89: Train Loss = 0.021816055028232428, Recall = 0.9968581687612208, Aging Rate = 0.49955317247542447, Precision = 0.9932915921288015, f1 = 0.9950716845878136\n",
      "Epoch 90: Train Loss = 0.02667231108973317, Recall = 0.9964093357271095, Aging Rate = 0.5011170688114388, Precision = 0.9897458760588498, f1 = 0.9930664280921494\n",
      "Test Loss = 0.013293479976241774, Recall = 1.0, Aging Rate = 0.4984361036639857, precision = 0.9986553115194979\n",
      "\n",
      "Epoch 91: Train Loss = 0.015521553841896416, Recall = 0.9991023339317774, Aging Rate = 0.4982126899016979, Precision = 0.9982062780269059, f1 = 0.9986541049798117\n",
      "Epoch 92: Train Loss = 0.025381496855265015, Recall = 0.9977558348294434, Aging Rate = 0.5, Precision = 0.9932975871313673, f1 = 0.9955217196596508\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 93: Train Loss = 0.015922774937772877, Recall = 0.9991023339317774, Aging Rate = 0.49754244861483465, Precision = 0.9995509654243376, f1 = 0.9993265993265993\n",
      "Epoch 94: Train Loss = 0.014520349425460953, Recall = 0.9995511669658886, Aging Rate = 0.4984361036639857, Precision = 0.9982070820259973, f1 = 0.99887867234806\n",
      "Epoch 95: Train Loss = 0.016105936922572412, Recall = 1.0, Aging Rate = 0.4982126899016979, Precision = 0.9991031390134529, f1 = 0.9995513683266039\n",
      "Test Loss = 0.017531557208371545, Recall = 0.9977558348294434, Aging Rate = 0.49664879356568364, precision = 1.0\n",
      "\n",
      "Epoch 96: Train Loss = 0.01809701754464381, Recall = 0.9995511669658886, Aging Rate = 0.4984361036639857, Precision = 0.9982070820259973, f1 = 0.99887867234806\n",
      "Epoch 97: Train Loss = 0.01803574033441077, Recall = 0.9982046678635548, Aging Rate = 0.4982126899016979, Precision = 0.9973094170403587, f1 = 0.9977568416330193\n",
      "Epoch 98: Train Loss = 0.016943977134497013, Recall = 0.9995511669658886, Aging Rate = 0.4984361036639857, Precision = 0.9982070820259973, f1 = 0.99887867234806\n",
      "Epoch 99: Train Loss = 0.01824448464423338, Recall = 0.9982046678635548, Aging Rate = 0.49754244861483465, Precision = 0.998652896273013, f1 = 0.998428731762065\n",
      "Epoch 100: Train Loss = 0.019873327750403024, Recall = 0.9982046678635548, Aging Rate = 0.49865951742627346, Precision = 0.996415770609319, f1 = 0.9973094170403587\n",
      "Test Loss = 0.01637836071305556, Recall = 1.0, Aging Rate = 0.5, precision = 0.9955317247542449\n",
      "\n",
      "Training Finished at epoch 100.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "49476eb8f4fd4d0f88e5e80ae8279baa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss = 0.45198382405595405, Recall = 0.8441850022451729, Aging Rate = 0.5671508379888268, Precision = 0.7407407407407407, f1 = 0.789087093389297\n",
      "Epoch 2: Train Loss = 0.22153508991003037, Recall = 0.9371351594072743, Aging Rate = 0.5217877094972067, Precision = 0.8937901498929336, f1 = 0.9149495835160018\n",
      "Epoch 3: Train Loss = 0.14304579000899245, Recall = 0.958688819039066, Aging Rate = 0.5094972067039106, Precision = 0.9364035087719298, f1 = 0.9474151320168627\n",
      "Epoch 4: Train Loss = 0.10662683008103398, Recall = 0.9681185451279749, Aging Rate = 0.5012290502793296, Precision = 0.96121266161391, f1 = 0.9646532438478748\n",
      "Epoch 5: Train Loss = 0.09517630896754771, Recall = 0.9757521329142343, Aging Rate = 0.5063687150837989, Precision = 0.9589585172109444, f1 = 0.9672824393501\n",
      "Test Loss = 0.06288659845817023, Recall = 0.9779973057925461, Aging Rate = 0.488268156424581, precision = 0.9967963386727688\n",
      "Model in epoch 5 is saved.\n",
      "\n",
      "Epoch 6: Train Loss = 0.050578473311895765, Recall = 0.9905702739110912, Aging Rate = 0.5016759776536313, Precision = 0.9826280623608018, f1 = 0.9865831842576029\n",
      "Epoch 7: Train Loss = 0.030750191191304996, Recall = 0.9977548271216884, Aging Rate = 0.5005586592178771, Precision = 0.9919642857142857, f1 = 0.9948511305126484\n",
      "Epoch 8: Train Loss = 0.02487926359657802, Recall = 0.998652896273013, Aging Rate = 0.4981005586592179, Precision = 0.9977568416330193, f1 = 0.9982046678635548\n",
      "Epoch 9: Train Loss = 0.024392435399180686, Recall = 0.9995509654243376, Aging Rate = 0.49921787709497206, Precision = 0.9964189794091316, f1 = 0.9979825151311364\n",
      "Epoch 10: Train Loss = 0.02752420418900984, Recall = 0.997305792546026, Aging Rate = 0.49854748603351956, Precision = 0.9955177050649933, f1 = 0.9964109466128309\n",
      "Test Loss = 0.02486814465019956, Recall = 0.9941625505163898, Aging Rate = 0.4947486033519553, precision = 1.0\n",
      "Model in epoch 10 is saved.\n",
      "\n",
      "Epoch 11: Train Loss = 0.0209687897592117, Recall = 0.9982038616973506, Aging Rate = 0.49854748603351956, Precision = 0.9964141640519946, f1 = 0.9973082099596231\n",
      "Epoch 12: Train Loss = 0.023521882438792864, Recall = 0.998652896273013, Aging Rate = 0.4994413407821229, Precision = 0.9950782997762864, f1 = 0.9968623935454952\n",
      "Epoch 13: Train Loss = 0.021943165628686964, Recall = 0.9982038616973506, Aging Rate = 0.49854748603351956, Precision = 0.9964141640519946, f1 = 0.9973082099596231\n",
      "Epoch 14: Train Loss = 0.026769847340423966, Recall = 0.995958688819039, Aging Rate = 0.49899441340782125, Precision = 0.9932825794894761, f1 = 0.9946188340807175\n",
      "Epoch 15: Train Loss = 0.025835122093974545, Recall = 0.9964077233947014, Aging Rate = 0.49988826815642456, Precision = 0.991953509164059, f1 = 0.9941756272401433\n",
      "Test Loss = 0.022384142108136714, Recall = 0.997305792546026, Aging Rate = 0.496536312849162, precision = 0.9995499549954996\n",
      "Model in epoch 15 is saved.\n",
      "\n",
      "Epoch 16: Train Loss = 0.02389345194291136, Recall = 0.9977548271216884, Aging Rate = 0.5001117318435754, Precision = 0.9928507596067918, f1 = 0.9952967525195968\n",
      "Epoch 17: Train Loss = 0.018678803050567985, Recall = 0.9991019308486754, Aging Rate = 0.49899441340782125, Precision = 0.9964173757277206, f1 = 0.9977578475336323\n",
      "Epoch 18: Train Loss = 0.019284028657738057, Recall = 0.9991019308486754, Aging Rate = 0.4987709497206704, Precision = 0.9968637992831542, f1 = 0.9979816102265081\n",
      "Epoch 19: Train Loss = 0.020948699670297475, Recall = 0.9977548271216884, Aging Rate = 0.4976536312849162, Precision = 0.9977548271216884, f1 = 0.9977548271216884\n",
      "Epoch 20: Train Loss = 0.020797597531166823, Recall = 0.9991019308486754, Aging Rate = 0.4987709497206704, Precision = 0.9968637992831542, f1 = 0.9979816102265081\n",
      "Test Loss = 0.017713786095131044, Recall = 0.9977548271216884, Aging Rate = 0.4969832402234637, precision = 0.9991007194244604\n",
      "\n",
      "Epoch 21: Train Loss = 0.020851320313008802, Recall = 0.9991019308486754, Aging Rate = 0.49988826815642456, Precision = 0.9946356727760394, f1 = 0.9968637992831542\n",
      "Epoch 22: Train Loss = 0.02126312532238454, Recall = 0.998652896273013, Aging Rate = 0.49854748603351956, Precision = 0.9968623935454953, f1 = 0.9977568416330193\n",
      "Epoch 23: Train Loss = 0.02117018983350786, Recall = 0.998652896273013, Aging Rate = 0.4987709497206704, Precision = 0.996415770609319, f1 = 0.9975330791657323\n",
      "Epoch 24: Train Loss = 0.019032959496009284, Recall = 0.9991019308486754, Aging Rate = 0.49966480446927375, Precision = 0.9950805008944544, f1 = 0.9970871611023975\n",
      "Epoch 25: Train Loss = 0.020658519407474128, Recall = 0.9991019308486754, Aging Rate = 0.4987709497206704, Precision = 0.9968637992831542, f1 = 0.9979816102265081\n",
      "Test Loss = 0.017263798586316614, Recall = 1.0, Aging Rate = 0.4994413407821229, precision = 0.996420581655481\n",
      "\n",
      "Epoch 26: Train Loss = 0.025463191351161322, Recall = 0.9977548271216884, Aging Rate = 0.49988826815642456, Precision = 0.9932945909700491, f1 = 0.9955197132616487\n",
      "Epoch 27: Train Loss = 0.03036441346453555, Recall = 0.9928154467894028, Aging Rate = 0.4983240223463687, Precision = 0.9914798206278027, f1 = 0.9921471842046219\n",
      "Epoch 28: Train Loss = 0.019026057232774837, Recall = 0.9977548271216884, Aging Rate = 0.49743016759776537, Precision = 0.9982030548068284, f1 = 0.9979788906355267\n",
      "Epoch 29: Train Loss = 0.01733708006168544, Recall = 0.998652896273013, Aging Rate = 0.4976536312849162, Precision = 0.998652896273013, f1 = 0.998652896273013\n",
      "Epoch 30: Train Loss = 0.0184706118411525, Recall = 0.9995509654243376, Aging Rate = 0.4983240223463687, Precision = 0.9982062780269059, f1 = 0.9988781691720888\n",
      "Test Loss = 0.014451052075949128, Recall = 0.998652896273013, Aging Rate = 0.4983240223463687, precision = 0.9973094170403587\n",
      "\n",
      "Epoch 31: Train Loss = 0.01539064250199655, Recall = 0.9991019308486754, Aging Rate = 0.4976536312849162, Precision = 0.9991019308486754, f1 = 0.9991019308486754\n",
      "Epoch 32: Train Loss = 0.019020828681285153, Recall = 0.9991019308486754, Aging Rate = 0.49899441340782125, Precision = 0.9964173757277206, f1 = 0.9977578475336323\n",
      "Epoch 33: Train Loss = 0.02059705775293558, Recall = 0.998652896273013, Aging Rate = 0.49921787709497206, Precision = 0.9955237242614146, f1 = 0.9970858551894194\n",
      "Epoch 34: Train Loss = 0.019945364011316326, Recall = 0.9991019308486754, Aging Rate = 0.49899441340782125, Precision = 0.9964173757277206, f1 = 0.9977578475336323\n",
      "Epoch 35: Train Loss = 0.021384789524964115, Recall = 0.9968567579703638, Aging Rate = 0.4972067039106145, Precision = 0.9977528089887641, f1 = 0.9973045822102427\n",
      "Test Loss = 0.01691618116978327, Recall = 1.0, Aging Rate = 0.4976536312849162, precision = 1.0\n",
      "Model in epoch 35 is saved.\n",
      "\n",
      "Epoch 36: Train Loss = 0.01986697909094435, Recall = 0.9991019308486754, Aging Rate = 0.49899441340782125, Precision = 0.9964173757277206, f1 = 0.9977578475336323\n",
      "Epoch 37: Train Loss = 0.020964270423494236, Recall = 0.9977548271216884, Aging Rate = 0.4983240223463687, Precision = 0.9964125560538116, f1 = 0.9970832398474311\n",
      "Epoch 38: Train Loss = 0.015976420728770716, Recall = 1.0, Aging Rate = 0.49854748603351956, Precision = 0.9982070820259973, f1 = 0.9991027366532077\n",
      "Epoch 39: Train Loss = 0.019739384947126137, Recall = 0.998652896273013, Aging Rate = 0.4981005586592179, Precision = 0.9977568416330193, f1 = 0.9982046678635548\n",
      "Epoch 40: Train Loss = 0.02190635609289621, Recall = 0.9982038616973506, Aging Rate = 0.49899441340782125, Precision = 0.9955217196596506, f1 = 0.9968609865470852\n",
      "Test Loss = 0.03438883327363922, Recall = 0.9901212393354288, Aging Rate = 0.4929608938547486, precision = 0.9995466908431551\n",
      "\n",
      "Epoch 41: Train Loss = 0.021294266466654877, Recall = 0.9977548271216884, Aging Rate = 0.4981005586592179, Precision = 0.996859578286227, f1 = 0.9973070017953322\n",
      "Epoch 42: Train Loss = 0.018838017040957285, Recall = 0.998652896273013, Aging Rate = 0.4983240223463687, Precision = 0.9973094170403587, f1 = 0.9979807045097598\n",
      "Epoch 43: Train Loss = 0.019345742949810108, Recall = 0.998652896273013, Aging Rate = 0.49899441340782125, Precision = 0.9959695476936856, f1 = 0.9973094170403588\n",
      "Epoch 44: Train Loss = 0.03209661167510395, Recall = 0.9968567579703638, Aging Rate = 0.5014525139664805, Precision = 0.9893048128342246, f1 = 0.9930664280921494\n",
      "Epoch 45: Train Loss = 0.026945272647468738, Recall = 0.994611585092052, Aging Rate = 0.4987709497206704, Precision = 0.9923835125448028, f1 = 0.9934962996187486\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss = 0.012380129371941422, Recall = 0.9995509654243376, Aging Rate = 0.49787709497206706, precision = 0.9991023339317774\n",
      "\n",
      "Epoch 46: Train Loss = 0.019369988702029488, Recall = 0.9977548271216884, Aging Rate = 0.49854748603351956, Precision = 0.9959659345584939, f1 = 0.9968595782862271\n",
      "Epoch 47: Train Loss = 0.01847234235379283, Recall = 0.9977548271216884, Aging Rate = 0.4981005586592179, Precision = 0.996859578286227, f1 = 0.9973070017953322\n",
      "Epoch 48: Train Loss = 0.01617416436487403, Recall = 0.9995509654243376, Aging Rate = 0.49854748603351956, Precision = 0.9977588525324966, f1 = 0.9986541049798116\n",
      "Epoch 49: Train Loss = 0.019009954369101443, Recall = 0.9991019308486754, Aging Rate = 0.4983240223463687, Precision = 0.9977578475336323, f1 = 0.9984294368409243\n",
      "Epoch 50: Train Loss = 0.01885837298490149, Recall = 0.998652896273013, Aging Rate = 0.4981005586592179, Precision = 0.9977568416330193, f1 = 0.9982046678635548\n",
      "Test Loss = 0.013442509919404983, Recall = 0.9995509654243376, Aging Rate = 0.4976536312849162, precision = 0.9995509654243376\n",
      "\n",
      "Epoch 51: Train Loss = 0.01781760658673401, Recall = 0.998652896273013, Aging Rate = 0.4981005586592179, Precision = 0.9977568416330193, f1 = 0.9982046678635548\n",
      "Epoch 52: Train Loss = 0.01663069776691205, Recall = 0.9995509654243376, Aging Rate = 0.4981005586592179, Precision = 0.9986541049798116, f1 = 0.9991023339317774\n",
      "Epoch 53: Train Loss = 0.016592925494567975, Recall = 0.9991019308486754, Aging Rate = 0.4972067039106145, Precision = 0, f1 = 0.0\n",
      "Epoch 54: Train Loss = 0.017733589613487602, Recall = 0.9995509654243376, Aging Rate = 0.49854748603351956, Precision = 0.9977588525324966, f1 = 0.9986541049798116\n",
      "Epoch 55: Train Loss = 0.019384027047280494, Recall = 0.998652896273013, Aging Rate = 0.4981005586592179, Precision = 0.9977568416330193, f1 = 0.9982046678635548\n",
      "Test Loss = 0.01421686580685597, Recall = 1.0, Aging Rate = 0.4981005586592179, precision = 0.9991027366532077\n",
      "\n",
      "Epoch 56: Train Loss = 0.01666000616617043, Recall = 1.0, Aging Rate = 0.4981005586592179, Precision = 0.9991027366532077, f1 = 0.9995511669658886\n",
      "Epoch 57: Train Loss = 0.018337997732340624, Recall = 0.9991019308486754, Aging Rate = 0.4983240223463687, Precision = 0.9977578475336323, f1 = 0.9984294368409243\n",
      "Epoch 58: Train Loss = 0.027987845732346594, Recall = 0.9968567579703638, Aging Rate = 0.49988826815642456, Precision = 0.9924005364327224, f1 = 0.9946236559139785\n",
      "Epoch 59: Train Loss = 0.04689118925731775, Recall = 0.9901212393354288, Aging Rate = 0.5032402234636871, Precision = 0.9791296625222025, f1 = 0.9845947756195579\n",
      "Epoch 60: Train Loss = 0.019650084317438095, Recall = 0.9977548271216884, Aging Rate = 0.4983240223463687, Precision = 0.9964125560538116, f1 = 0.9970832398474311\n",
      "Test Loss = 0.021941263633233874, Recall = 1.0, Aging Rate = 0.5012290502793296, precision = 0.992866696388765\n",
      "\n",
      "Epoch 61: Train Loss = 0.015308385649956138, Recall = 0.9991019308486754, Aging Rate = 0.49787709497206706, Precision = 0.998653500897666, f1 = 0.9988776655443322\n",
      "Epoch 62: Train Loss = 0.014572453003522404, Recall = 0.9995509654243376, Aging Rate = 0.49787709497206706, Precision = 0.9991023339317774, f1 = 0.9993265993265993\n",
      "Epoch 63: Train Loss = 0.018702733248222473, Recall = 0.9982038616973506, Aging Rate = 0.49787709497206706, Precision = 0.9977558348294434, f1 = 0.997979797979798\n",
      "Epoch 64: Train Loss = 0.02027849702029255, Recall = 0.9995509654243376, Aging Rate = 0.4994413407821229, Precision = 0.9959731543624161, f1 = 0.9977588525324966\n",
      "Epoch 65: Train Loss = 0.019883457108624488, Recall = 0.9991019308486754, Aging Rate = 0.49921787709497206, Precision = 0.9959713518352731, f1 = 0.9975341851602781\n",
      "Test Loss = 0.01567939145438498, Recall = 0.9968567579703638, Aging Rate = 0.4960893854748603, precision = 1.0\n",
      "\n",
      "Epoch 66: Train Loss = 0.015671614526911487, Recall = 1.0, Aging Rate = 0.49899441340782125, Precision = 0.9973130317957905, f1 = 0.9986547085201793\n",
      "Epoch 67: Train Loss = 0.014574561395458669, Recall = 1.0, Aging Rate = 0.4983240223463687, Precision = 0.9986547085201793, f1 = 0.9993269015032533\n",
      "Epoch 68: Train Loss = 0.0161387199375716, Recall = 0.9991019308486754, Aging Rate = 0.4981005586592179, Precision = 0.9982054733064154, f1 = 0.998653500897666\n",
      "Epoch 69: Train Loss = 0.020001301770020463, Recall = 0.9995509654243376, Aging Rate = 0.49854748603351956, Precision = 0.9977588525324966, f1 = 0.9986541049798116\n",
      "Epoch 70: Train Loss = 0.020388809332634483, Recall = 0.998652896273013, Aging Rate = 0.49921787709497206, Precision = 0.9955237242614146, f1 = 0.9970858551894194\n",
      "Test Loss = 0.016015675216705105, Recall = 1.0, Aging Rate = 0.4981005586592179, precision = 0.9991027366532077\n",
      "\n",
      "Epoch 71: Train Loss = 0.023961501275111177, Recall = 0.995958688819039, Aging Rate = 0.49743016759776537, Precision = 0.9964061096136568, f1 = 0.996182348978217\n",
      "Epoch 72: Train Loss = 0.02081992576242159, Recall = 0.9977548271216884, Aging Rate = 0.4983240223463687, Precision = 0.9964125560538116, f1 = 0.9970832398474311\n",
      "Epoch 73: Train Loss = 0.01587366337674623, Recall = 0.9995509654243376, Aging Rate = 0.49899441340782125, Precision = 0.9968652037617555, f1 = 0.9982062780269058\n",
      "Epoch 74: Train Loss = 0.015534038207800695, Recall = 0.9995509654243376, Aging Rate = 0.49854748603351956, Precision = 0.9977588525324966, f1 = 0.9986541049798116\n",
      "Epoch 75: Train Loss = 0.017390902491088687, Recall = 1.0, Aging Rate = 0.4983240223463687, Precision = 0.9986547085201793, f1 = 0.9993269015032533\n",
      "Test Loss = 0.015319907042775407, Recall = 1.0, Aging Rate = 0.4987709497206704, precision = 0.9977598566308243\n",
      "\n",
      "Epoch 76: Train Loss = 0.017711255510634218, Recall = 0.998652896273013, Aging Rate = 0.49787709497206706, Precision = 0.9982046678635548, f1 = 0.998428731762065\n",
      "Epoch 77: Train Loss = 0.017457582934150815, Recall = 0.9982038616973506, Aging Rate = 0.49743016759776537, Precision = 0.9986522911051213, f1 = 0.9984280260498539\n",
      "Epoch 78: Train Loss = 0.01904232427977317, Recall = 0.9991019308486754, Aging Rate = 0.4994413407821229, Precision = 0.9955257270693513, f1 = 0.997310623038996\n",
      "Epoch 79: Train Loss = 0.021849991180960027, Recall = 0.9968567579703638, Aging Rate = 0.4987709497206704, Precision = 0.9946236559139785, f1 = 0.9957389549226283\n",
      "Epoch 80: Train Loss = 0.016077665801904055, Recall = 0.9991019308486754, Aging Rate = 0.49787709497206706, Precision = 0.998653500897666, f1 = 0.9988776655443322\n",
      "Test Loss = 0.018546214184031806, Recall = 0.997305792546026, Aging Rate = 0.4963128491620112, precision = 1.0\n",
      "\n",
      "Epoch 81: Train Loss = 0.01864705628294019, Recall = 0.9991019308486754, Aging Rate = 0.49787709497206706, Precision = 0.998653500897666, f1 = 0.9988776655443322\n",
      "Epoch 82: Train Loss = 0.027560269772049104, Recall = 0.9928154467894028, Aging Rate = 0.4969832402234637, Precision = 0.9941546762589928, f1 = 0.993484610199955\n",
      "Epoch 83: Train Loss = 0.03241217068661858, Recall = 0.9941625505163898, Aging Rate = 0.5005586592178771, Precision = 0.9883928571428572, f1 = 0.9912693082605777\n",
      "Epoch 84: Train Loss = 0.016495862458338284, Recall = 0.9977548271216884, Aging Rate = 0.49787709497206706, Precision = 0.9973070017953322, f1 = 0.9975308641975309\n",
      "Epoch 85: Train Loss = 0.018847317117261154, Recall = 0.9982038616973506, Aging Rate = 0.49854748603351956, Precision = 0.9964141640519946, f1 = 0.9973082099596231\n",
      "Test Loss = 0.012143193126744565, Recall = 1.0, Aging Rate = 0.49854748603351956, precision = 0.9982070820259973\n",
      "\n",
      "Training Finished at epoch 85.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3112c5263ab24130a744ef3611c5d830",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss = 0.4158837610649663, Recall = 0.8432869330938483, Aging Rate = 0.5347486033519553, Precision = 0.7847889678228166, f1 = 0.8129870129870131\n",
      "Epoch 2: Train Loss = 0.1803405922751187, Recall = 0.9479119892231702, Aging Rate = 0.5150837988826815, Precision = 0.9158351409978308, f1 = 0.9315975286849073\n",
      "Epoch 3: Train Loss = 0.11801315523392661, Recall = 0.9699146834306241, Aging Rate = 0.5097206703910615, Precision = 0.9469530907496712, f1 = 0.9582963620230701\n",
      "Epoch 4: Train Loss = 0.08911451844696226, Recall = 0.9797934440951953, Aging Rate = 0.5063687150837989, Precision = 0.9629302736098853, f1 = 0.9712886712664144\n",
      "Epoch 5: Train Loss = 0.07212785806735801, Recall = 0.9829366861248316, Aging Rate = 0.5052513966480446, Precision = 0.9681556833259619, f1 = 0.9754901960784313\n",
      "Test Loss = 0.040837591779132126, Recall = 0.9932644813650651, Aging Rate = 0.5025698324022346, precision = 0.9835482436638506\n",
      "Model in epoch 5 is saved.\n",
      "\n",
      "Epoch 6: Train Loss = 0.0352894953288679, Recall = 0.995958688819039, Aging Rate = 0.4987709497206704, Precision = 0.9937275985663082, f1 = 0.9948418928010764\n",
      "Epoch 7: Train Loss = 0.02305016021488765, Recall = 0.998652896273013, Aging Rate = 0.4994413407821229, Precision = 0.9950782997762864, f1 = 0.9968623935454952\n",
      "Epoch 8: Train Loss = 0.02211501217400395, Recall = 0.998652896273013, Aging Rate = 0.4983240223463687, Precision = 0.9973094170403587, f1 = 0.9979807045097598\n",
      "Epoch 9: Train Loss = 0.02162611843487404, Recall = 0.998652896273013, Aging Rate = 0.49854748603351956, Precision = 0.9968623935454953, f1 = 0.9977568416330193\n",
      "Epoch 10: Train Loss = 0.02009715468565512, Recall = 1.0, Aging Rate = 0.4987709497206704, Precision = 0.9977598566308243, f1 = 0.99887867234806\n",
      "Test Loss = 0.01669337246171589, Recall = 0.9982038616973506, Aging Rate = 0.4976536312849162, precision = 0.9982038616973506\n",
      "Model in epoch 10 is saved.\n",
      "\n",
      "Epoch 11: Train Loss = 0.020086955696177883, Recall = 0.998652896273013, Aging Rate = 0.4987709497206704, Precision = 0.996415770609319, f1 = 0.9975330791657323\n",
      "Epoch 12: Train Loss = 0.019323420834066813, Recall = 0.9991019308486754, Aging Rate = 0.4983240223463687, Precision = 0.9977578475336323, f1 = 0.9984294368409243\n",
      "Epoch 13: Train Loss = 0.020514593504827115, Recall = 0.9995509654243376, Aging Rate = 0.49921787709497206, Precision = 0.9964189794091316, f1 = 0.9979825151311364\n",
      "Epoch 14: Train Loss = 0.025558508168801914, Recall = 0.9964077233947014, Aging Rate = 0.4994413407821229, Precision = 0.992841163310962, f1 = 0.9946212460779918\n",
      "Epoch 15: Train Loss = 0.021961421181536253, Recall = 0.998652896273013, Aging Rate = 0.49966480446927375, Precision = 0.9946332737030411, f1 = 0.996639032041228\n",
      "Test Loss = 0.017976942072367535, Recall = 0.9982038616973506, Aging Rate = 0.4981005586592179, precision = 0.9973082099596231\n",
      "\n",
      "Epoch 16: Train Loss = 0.020212143696844577, Recall = 0.9977548271216884, Aging Rate = 0.4983240223463687, Precision = 0.9964125560538116, f1 = 0.9970832398474311\n",
      "Epoch 17: Train Loss = 0.0181228116691612, Recall = 0.998652896273013, Aging Rate = 0.49787709497206706, Precision = 0.9982046678635548, f1 = 0.998428731762065\n",
      "Epoch 18: Train Loss = 0.0193700484361229, Recall = 0.9982038616973506, Aging Rate = 0.4987709497206704, Precision = 0.9959677419354839, f1 = 0.9970845481049563\n",
      "Epoch 19: Train Loss = 0.04846952311111895, Recall = 0.9905702739110912, Aging Rate = 0.503463687150838, Precision = 0.979138925876609, f1 = 0.9848214285714286\n",
      "Epoch 20: Train Loss = 0.02482218721350811, Recall = 0.9955096542433768, Aging Rate = 0.5001117318435754, Precision = 0.9906166219839142, f1 = 0.9930571108622621\n",
      "Test Loss = 0.01840251054843711, Recall = 0.998652896273013, Aging Rate = 0.49966480446927375, precision = 0.9946332737030411\n",
      "\n",
      "Epoch 21: Train Loss = 0.018361269810221383, Recall = 0.9991019308486754, Aging Rate = 0.49854748603351956, Precision = 0.997310623038996, f1 = 0.9982054733064154\n",
      "Epoch 22: Train Loss = 0.015308706255515194, Recall = 0.998652896273013, Aging Rate = 0.49787709497206706, Precision = 0.9982046678635548, f1 = 0.998428731762065\n",
      "Epoch 23: Train Loss = 0.016009623444529886, Recall = 0.9995509654243376, Aging Rate = 0.49854748603351956, Precision = 0.9977588525324966, f1 = 0.9986541049798116\n",
      "Epoch 24: Train Loss = 0.016652556713982667, Recall = 0.998652896273013, Aging Rate = 0.49787709497206706, Precision = 0.9982046678635548, f1 = 0.998428731762065\n",
      "Epoch 25: Train Loss = 0.02032989870736053, Recall = 0.998652896273013, Aging Rate = 0.4987709497206704, Precision = 0.996415770609319, f1 = 0.9975330791657323\n",
      "Test Loss = 0.026119058513441564, Recall = 0.9910193084867535, Aging Rate = 0.49318435754189943, precision = 1.0\n",
      "\n",
      "Epoch 26: Train Loss = 0.01987165921685083, Recall = 0.9977548271216884, Aging Rate = 0.4981005586592179, Precision = 0.996859578286227, f1 = 0.9973070017953322\n",
      "Epoch 27: Train Loss = 0.019860216198104054, Recall = 0.998652896273013, Aging Rate = 0.49854748603351956, Precision = 0.9968623935454953, f1 = 0.9977568416330193\n",
      "Epoch 28: Train Loss = 0.024005940718441036, Recall = 0.997305792546026, Aging Rate = 0.49854748603351956, Precision = 0.9955177050649933, f1 = 0.9964109466128309\n",
      "Epoch 29: Train Loss = 0.018305347404708076, Recall = 0.9968567579703638, Aging Rate = 0.4969832402234637, Precision = 0.9982014388489209, f1 = 0.9975286452482589\n",
      "Epoch 30: Train Loss = 0.018094233294022814, Recall = 0.9991019308486754, Aging Rate = 0.49899441340782125, Precision = 0.9964173757277206, f1 = 0.9977578475336323\n",
      "Test Loss = 0.019759355138508634, Recall = 0.995958688819039, Aging Rate = 0.4956424581005587, precision = 1.0\n",
      "Model in epoch 30 is saved.\n",
      "\n",
      "Epoch 31: Train Loss = 0.019757814588826462, Recall = 0.998652896273013, Aging Rate = 0.49787709497206706, Precision = 0.9982046678635548, f1 = 0.998428731762065\n",
      "Epoch 32: Train Loss = 0.029708651769594106, Recall = 0.9964077233947014, Aging Rate = 0.5001117318435754, Precision = 0.9915102770330653, f1 = 0.9939529675251959\n",
      "Epoch 33: Train Loss = 0.02140356482865091, Recall = 0.9977548271216884, Aging Rate = 0.4983240223463687, Precision = 0.9964125560538116, f1 = 0.9970832398474311\n",
      "Epoch 34: Train Loss = 0.017342272765684726, Recall = 0.998652896273013, Aging Rate = 0.49787709497206706, Precision = 0.9982046678635548, f1 = 0.998428731762065\n",
      "Epoch 35: Train Loss = 0.02048440867712378, Recall = 0.998652896273013, Aging Rate = 0.49921787709497206, Precision = 0.9955237242614146, f1 = 0.9970858551894194\n",
      "Test Loss = 0.025323508172061856, Recall = 1.0, Aging Rate = 0.5025698324022346, precision = 0.9902178746109382\n",
      "\n",
      "Epoch 36: Train Loss = 0.018319049830335145, Recall = 0.9977548271216884, Aging Rate = 0.49743016759776537, Precision = 0.9982030548068284, f1 = 0.9979788906355267\n",
      "Epoch 37: Train Loss = 0.015886218050005715, Recall = 0.9995509654243376, Aging Rate = 0.4983240223463687, Precision = 0.9982062780269059, f1 = 0.9988781691720888\n",
      "Epoch 38: Train Loss = 0.016467324220601407, Recall = 0.998652896273013, Aging Rate = 0.49787709497206706, Precision = 0.9982046678635548, f1 = 0.998428731762065\n",
      "Epoch 39: Train Loss = 0.019738791410150475, Recall = 0.9977548271216884, Aging Rate = 0.49787709497206706, Precision = 0.9973070017953322, f1 = 0.9975308641975309\n",
      "Epoch 40: Train Loss = 0.017755289125209413, Recall = 1.0, Aging Rate = 0.49899441340782125, Precision = 0.9973130317957905, f1 = 0.9986547085201793\n",
      "Test Loss = 0.013704315280156762, Recall = 0.9995509654243376, Aging Rate = 0.4976536312849162, precision = 0.9995509654243376\n",
      "Model in epoch 40 is saved.\n",
      "\n",
      "Epoch 41: Train Loss = 0.016449812862959653, Recall = 0.9977548271216884, Aging Rate = 0.4972067039106145, Precision = 0.9986516853932584, f1 = 0.9982030548068285\n",
      "Epoch 42: Train Loss = 0.021267188890894365, Recall = 0.9982038616973506, Aging Rate = 0.49787709497206706, Precision = 0.9977558348294434, f1 = 0.997979797979798\n",
      "Epoch 43: Train Loss = 0.020194174132450334, Recall = 0.9977548271216884, Aging Rate = 0.4981005586592179, Precision = 0.996859578286227, f1 = 0.9973070017953322\n",
      "Epoch 44: Train Loss = 0.020321773534547016, Recall = 0.9977548271216884, Aging Rate = 0.49854748603351956, Precision = 0.9959659345584939, f1 = 0.9968595782862271\n",
      "Epoch 45: Train Loss = 0.02453867213769332, Recall = 0.9968567579703638, Aging Rate = 0.4981005586592179, Precision = 0.9959623149394348, f1 = 0.9964093357271095\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss = 0.018930619694084428, Recall = 0.994611585092052, Aging Rate = 0.4958659217877095, precision = 0.9981973862100045\n",
      "\n",
      "Epoch 46: Train Loss = 0.02565444430658937, Recall = 0.9950606196677144, Aging Rate = 0.4983240223463687, Precision = 0.9937219730941704, f1 = 0.9943908458604442\n",
      "Epoch 47: Train Loss = 0.02182454231106702, Recall = 0.998652896273013, Aging Rate = 0.5003351955307263, Precision = 0.9933005806163466, f1 = 0.9959695476936856\n",
      "Epoch 48: Train Loss = 0.015238359301200126, Recall = 0.9991019308486754, Aging Rate = 0.4983240223463687, Precision = 0.9977578475336323, f1 = 0.9984294368409243\n",
      "Epoch 49: Train Loss = 0.01832854185877732, Recall = 0.9991019308486754, Aging Rate = 0.4981005586592179, Precision = 0.9982054733064154, f1 = 0.998653500897666\n",
      "Epoch 50: Train Loss = 0.015991881909317145, Recall = 0.998652896273013, Aging Rate = 0.49743016759776537, Precision = 0.9991015274034142, f1 = 0.9988771614641814\n",
      "Test Loss = 0.014640532909325382, Recall = 1.0, Aging Rate = 0.4981005586592179, precision = 0.9991027366532077\n",
      "\n",
      "Epoch 51: Train Loss = 0.017072826492178707, Recall = 0.9991019308486754, Aging Rate = 0.4976536312849162, Precision = 0.9991019308486754, f1 = 0.9991019308486754\n",
      "Epoch 52: Train Loss = 0.015935560391601905, Recall = 1.0, Aging Rate = 0.4987709497206704, Precision = 0.9977598566308243, f1 = 0.99887867234806\n",
      "Epoch 53: Train Loss = 0.020119213032322888, Recall = 0.998652896273013, Aging Rate = 0.49899441340782125, Precision = 0.9959695476936856, f1 = 0.9973094170403588\n",
      "Epoch 54: Train Loss = 0.016812381853437957, Recall = 0.9982038616973506, Aging Rate = 0.4972067039106145, Precision = 0.9991011235955056, f1 = 0.9986522911051212\n",
      "Epoch 55: Train Loss = 0.01714318233183143, Recall = 0.9991019308486754, Aging Rate = 0.49787709497206706, Precision = 0.998653500897666, f1 = 0.9988776655443322\n",
      "Test Loss = 0.01560400964619394, Recall = 0.9995509654243376, Aging Rate = 0.49743016759776537, precision = 1.0\n",
      "Model in epoch 55 is saved.\n",
      "\n",
      "Epoch 56: Train Loss = 0.016007140650096553, Recall = 0.9995509654243376, Aging Rate = 0.49743016759776537, Precision = 0, f1 = 0.0\n",
      "Epoch 57: Train Loss = 0.01793845681588077, Recall = 0.9991019308486754, Aging Rate = 0.4981005586592179, Precision = 0.9982054733064154, f1 = 0.998653500897666\n",
      "Epoch 58: Train Loss = 0.024442379698573543, Recall = 0.995958688819039, Aging Rate = 0.49854748603351956, Precision = 0.9941730165844913, f1 = 0.9950650515926425\n",
      "Epoch 59: Train Loss = 0.02953386421060429, Recall = 0.9964077233947014, Aging Rate = 0.5007821229050279, Precision = 0.9901829540383758, f1 = 0.9932855863921216\n",
      "Epoch 60: Train Loss = 0.022587908046455357, Recall = 0.9977548271216884, Aging Rate = 0.4994413407821229, Precision = 0.9941834451901566, f1 = 0.995965934558494\n",
      "Test Loss = 0.01369284029363254, Recall = 1.0, Aging Rate = 0.4981005586592179, precision = 0.9991027366532077\n",
      "\n",
      "Epoch 61: Train Loss = 0.014216314416441172, Recall = 0.9995509654243376, Aging Rate = 0.49787709497206706, Precision = 0.9991023339317774, f1 = 0.9993265993265993\n",
      "Epoch 62: Train Loss = 0.013780270120618063, Recall = 1.0, Aging Rate = 0.49787709497206706, Precision = 0.9995511669658886, f1 = 0.9997755331088665\n",
      "Epoch 63: Train Loss = 0.02064201286593296, Recall = 0.9977548271216884, Aging Rate = 0.49854748603351956, Precision = 0.9959659345584939, f1 = 0.9968595782862271\n",
      "Epoch 64: Train Loss = 0.02208556405762887, Recall = 0.9964077233947014, Aging Rate = 0.49787709497206706, Precision = 0.9959605026929982, f1 = 0.9961840628507296\n",
      "Epoch 65: Train Loss = 0.018343402297969637, Recall = 0.9982038616973506, Aging Rate = 0.4981005586592179, Precision = 0.9973082099596231, f1 = 0.9977558348294433\n",
      "Test Loss = 0.015442705589799242, Recall = 1.0, Aging Rate = 0.4983240223463687, precision = 0.9986547085201793\n",
      "\n",
      "Epoch 66: Train Loss = 0.014808124309228786, Recall = 1.0, Aging Rate = 0.49854748603351956, Precision = 0.9982070820259973, f1 = 0.9991027366532077\n",
      "Epoch 67: Train Loss = 0.015917618114438804, Recall = 0.9991019308486754, Aging Rate = 0.4981005586592179, Precision = 0.9982054733064154, f1 = 0.998653500897666\n",
      "Epoch 68: Train Loss = 0.016468373667760935, Recall = 0.9995509654243376, Aging Rate = 0.4981005586592179, Precision = 0.9986541049798116, f1 = 0.9991023339317774\n",
      "Epoch 69: Train Loss = 0.02500650539536383, Recall = 0.9977548271216884, Aging Rate = 0.49921787709497206, Precision = 0.9946284691136974, f1 = 0.9961891952477023\n",
      "Epoch 70: Train Loss = 0.02067735297428496, Recall = 0.9982038616973506, Aging Rate = 0.49854748603351956, Precision = 0.9964141640519946, f1 = 0.9973082099596231\n",
      "Test Loss = 0.01800346325042361, Recall = 0.9977548271216884, Aging Rate = 0.4969832402234637, precision = 0.9991007194244604\n",
      "\n",
      "Epoch 71: Train Loss = 0.013915851343235823, Recall = 1.0, Aging Rate = 0.4983240223463687, Precision = 0.9986547085201793, f1 = 0.9993269015032533\n",
      "Epoch 72: Train Loss = 0.018638302866140558, Recall = 0.9968567579703638, Aging Rate = 0.49743016759776537, Precision = 0.9973045822102425, f1 = 0.9970806198068717\n",
      "Epoch 73: Train Loss = 0.020866412826756525, Recall = 0.997305792546026, Aging Rate = 0.4981005586592179, Precision = 0.9964109466128309, f1 = 0.9968581687612209\n",
      "Epoch 74: Train Loss = 0.01563425014118076, Recall = 0.9982038616973506, Aging Rate = 0.49787709497206706, Precision = 0.9977558348294434, f1 = 0.997979797979798\n",
      "Epoch 75: Train Loss = 0.014749993348088344, Recall = 1.0, Aging Rate = 0.4983240223463687, Precision = 0.9986547085201793, f1 = 0.9993269015032533\n",
      "Test Loss = 0.02238602743343601, Recall = 0.9995509654243376, Aging Rate = 0.49743016759776537, precision = 1.0\n",
      "\n",
      "Epoch 76: Train Loss = 0.017260886557275357, Recall = 1.0, Aging Rate = 0.49921787709497206, Precision = 0.9968666069829901, f1 = 0.9984308451019951\n",
      "Epoch 77: Train Loss = 0.02045399583043666, Recall = 0.9977548271216884, Aging Rate = 0.49743016759776537, Precision = 0.9982030548068284, f1 = 0.9979788906355267\n",
      "Epoch 78: Train Loss = 0.01736240568149356, Recall = 0.9991019308486754, Aging Rate = 0.49854748603351956, Precision = 0.997310623038996, f1 = 0.9982054733064154\n",
      "Epoch 79: Train Loss = 0.01653504552954402, Recall = 0.9982038616973506, Aging Rate = 0.4972067039106145, Precision = 0.9991011235955056, f1 = 0.9986522911051212\n",
      "Epoch 80: Train Loss = 0.018303542550049682, Recall = 0.997305792546026, Aging Rate = 0.4972067039106145, Precision = 0.9982022471910112, f1 = 0.9977538185085355\n",
      "Test Loss = 0.018004362961932932, Recall = 0.9995509654243376, Aging Rate = 0.49787709497206706, precision = 0.9991023339317774\n",
      "\n",
      "Epoch 81: Train Loss = 0.01994658478644973, Recall = 0.998652896273013, Aging Rate = 0.4981005586592179, Precision = 0.9977568416330193, f1 = 0.9982046678635548\n",
      "Epoch 82: Train Loss = 0.01593866886872819, Recall = 0.998652896273013, Aging Rate = 0.4981005586592179, Precision = 0.9977568416330193, f1 = 0.9982046678635548\n",
      "Epoch 83: Train Loss = 0.01967636869543924, Recall = 0.9991019308486754, Aging Rate = 0.4983240223463687, Precision = 0.9977578475336323, f1 = 0.9984294368409243\n",
      "Epoch 84: Train Loss = 0.018694304735633913, Recall = 0.997305792546026, Aging Rate = 0.4983240223463687, Precision = 0.9959641255605381, f1 = 0.9966345075162665\n",
      "Epoch 85: Train Loss = 0.020807636574160453, Recall = 0.997305792546026, Aging Rate = 0.4981005586592179, Precision = 0.9964109466128309, f1 = 0.9968581687612209\n",
      "Test Loss = 0.01625437520839815, Recall = 0.9977548271216884, Aging Rate = 0.49675977653631287, precision = 0.9995501574448943\n",
      "\n",
      "Epoch 86: Train Loss = 0.01844048760706486, Recall = 0.9977548271216884, Aging Rate = 0.4981005586592179, Precision = 0.996859578286227, f1 = 0.9973070017953322\n",
      "Epoch 87: Train Loss = 0.019917936114875297, Recall = 0.997305792546026, Aging Rate = 0.4976536312849162, Precision = 0.997305792546026, f1 = 0.997305792546026\n",
      "Epoch 88: Train Loss = 0.016336197123014727, Recall = 0.9991019308486754, Aging Rate = 0.4987709497206704, Precision = 0.9968637992831542, f1 = 0.9979816102265081\n",
      "Epoch 89: Train Loss = 0.018069020022934708, Recall = 1.0, Aging Rate = 0.4987709497206704, Precision = 0.9977598566308243, f1 = 0.99887867234806\n",
      "Epoch 90: Train Loss = 0.017150719700454002, Recall = 0.9995509654243376, Aging Rate = 0.49899441340782125, Precision = 0.9968652037617555, f1 = 0.9982062780269058\n",
      "Test Loss = 0.01698281563735208, Recall = 0.9968567579703638, Aging Rate = 0.4963128491620112, precision = 0.9995497523638001\n",
      "\n",
      "Epoch 91: Train Loss = 0.019800993771443155, Recall = 0.998652896273013, Aging Rate = 0.49854748603351956, Precision = 0.9968623935454953, f1 = 0.9977568416330193\n",
      "Epoch 92: Train Loss = 0.015028251823683024, Recall = 0.9995509654243376, Aging Rate = 0.4983240223463687, Precision = 0.9982062780269059, f1 = 0.9988781691720888\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 93: Train Loss = 0.01532539391317847, Recall = 0.9995509654243376, Aging Rate = 0.4976536312849162, Precision = 0.9995509654243376, f1 = 0.9995509654243376\n",
      "Epoch 94: Train Loss = 0.01804063214603083, Recall = 0.9991019308486754, Aging Rate = 0.4987709497206704, Precision = 0.9968637992831542, f1 = 0.9979816102265081\n",
      "Epoch 95: Train Loss = 0.017862249611143292, Recall = 0.9995509654243376, Aging Rate = 0.4981005586592179, Precision = 0.9986541049798116, f1 = 0.9991023339317774\n",
      "Test Loss = 0.016127534286436422, Recall = 1.0, Aging Rate = 0.4994413407821229, precision = 0.996420581655481\n",
      "\n",
      "Epoch 96: Train Loss = 0.01599337560192333, Recall = 0.9995509654243376, Aging Rate = 0.4983240223463687, Precision = 0.9982062780269059, f1 = 0.9988781691720888\n",
      "Epoch 97: Train Loss = 0.02108333884920488, Recall = 0.9977548271216884, Aging Rate = 0.49854748603351956, Precision = 0.9959659345584939, f1 = 0.9968595782862271\n",
      "Epoch 98: Train Loss = 0.02640445863567917, Recall = 0.9955096542433768, Aging Rate = 0.49899441340782125, Precision = 0.9928347514554411, f1 = 0.994170403587444\n",
      "Epoch 99: Train Loss = 0.021358688169434748, Recall = 0.997305792546026, Aging Rate = 0.49854748603351956, Precision = 0.9955177050649933, f1 = 0.9964109466128309\n",
      "Epoch 100: Train Loss = 0.01828699646736157, Recall = 0.9995509654243376, Aging Rate = 0.49899441340782125, Precision = 0.9968652037617555, f1 = 0.9982062780269058\n",
      "Test Loss = 0.016772982599890098, Recall = 0.9995509654243376, Aging Rate = 0.49854748603351956, precision = 0.9977588525324966\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d2718f5930f94073b3dc89c36f84905f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss = 0.4432956240763211, Recall = 0.8522676246070947, Aging Rate = 0.5729608938547486, Precision = 0.7402496099843994, f1 = 0.7923189313295762\n",
      "Epoch 2: Train Loss = 0.2067023174756066, Recall = 0.9398293668612483, Aging Rate = 0.5188826815642458, Precision = 0.9013781223083549, f1 = 0.9202022422510441\n",
      "Epoch 3: Train Loss = 0.119940292319106, Recall = 0.9672204759766502, Aging Rate = 0.5065921787709498, Precision = 0.9501543890604323, f1 = 0.9586114819759679\n",
      "Epoch 4: Train Loss = 0.08424431026481384, Recall = 0.9811405478221823, Aging Rate = 0.5041340782122905, Precision = 0.9685283687943262, f1 = 0.9747936649565024\n",
      "Epoch 5: Train Loss = 0.07656610204021358, Recall = 0.9824876515491693, Aging Rate = 0.503463687150838, Precision = 0.9711495783399912, f1 = 0.9767857142857143\n",
      "Test Loss = 0.03819304937590434, Recall = 0.997305792546026, Aging Rate = 0.4987709497206704, precision = 0.9950716845878136\n",
      "Model in epoch 5 is saved.\n",
      "\n",
      "Epoch 6: Train Loss = 0.03166313289139191, Recall = 0.9977548271216884, Aging Rate = 0.49966480446927375, Precision = 0.9937388193202147, f1 = 0.9957427739188887\n",
      "Epoch 7: Train Loss = 0.023680003834003843, Recall = 0.9991019308486754, Aging Rate = 0.49899441340782125, Precision = 0.9964173757277206, f1 = 0.9977578475336323\n",
      "Epoch 8: Train Loss = 0.020340120625479262, Recall = 0.9991019308486754, Aging Rate = 0.4983240223463687, Precision = 0.9977578475336323, f1 = 0.9984294368409243\n",
      "Epoch 9: Train Loss = 0.0215283442659085, Recall = 0.9991019308486754, Aging Rate = 0.4983240223463687, Precision = 0.9977578475336323, f1 = 0.9984294368409243\n",
      "Epoch 10: Train Loss = 0.02026686014326591, Recall = 1.0, Aging Rate = 0.4987709497206704, Precision = 0.9977598566308243, f1 = 0.99887867234806\n",
      "Test Loss = 0.017103534724625797, Recall = 1.0, Aging Rate = 0.4983240223463687, precision = 0.9986547085201793\n",
      "Model in epoch 10 is saved.\n",
      "\n",
      "Epoch 11: Train Loss = 0.021682913341460615, Recall = 0.9982038616973506, Aging Rate = 0.49854748603351956, Precision = 0.9964141640519946, f1 = 0.9973082099596231\n",
      "Epoch 12: Train Loss = 0.02023093167421871, Recall = 0.9995509654243376, Aging Rate = 0.4976536312849162, Precision = 0.9995509654243376, f1 = 0.9995509654243376\n",
      "Epoch 13: Train Loss = 0.01741616793309843, Recall = 0.9991019308486754, Aging Rate = 0.4981005586592179, Precision = 0.9982054733064154, f1 = 0.998653500897666\n",
      "Epoch 14: Train Loss = 0.018100233584559165, Recall = 0.9991019308486754, Aging Rate = 0.49854748603351956, Precision = 0.997310623038996, f1 = 0.9982054733064154\n",
      "Epoch 15: Train Loss = 0.01757687075968894, Recall = 0.998652896273013, Aging Rate = 0.4972067039106145, Precision = 0.9995505617977528, f1 = 0.9991015274034142\n",
      "Test Loss = 0.01865086796938041, Recall = 1.0, Aging Rate = 0.49854748603351956, precision = 0.9982070820259973\n",
      "\n",
      "Epoch 16: Train Loss = 0.021416019137178718, Recall = 0.9995509654243376, Aging Rate = 0.4994413407821229, Precision = 0.9959731543624161, f1 = 0.9977588525324966\n",
      "Epoch 17: Train Loss = 0.020058757399713526, Recall = 0.998652896273013, Aging Rate = 0.49787709497206706, Precision = 0.9982046678635548, f1 = 0.998428731762065\n",
      "Epoch 18: Train Loss = 0.019224243532429193, Recall = 0.998652896273013, Aging Rate = 0.49854748603351956, Precision = 0.9968623935454953, f1 = 0.9977568416330193\n",
      "Epoch 19: Train Loss = 0.022351890808210692, Recall = 0.998652896273013, Aging Rate = 0.49854748603351956, Precision = 0.9968623935454953, f1 = 0.9977568416330193\n",
      "Epoch 20: Train Loss = 0.018119715763328794, Recall = 0.998652896273013, Aging Rate = 0.4981005586592179, Precision = 0.9977568416330193, f1 = 0.9982046678635548\n",
      "Test Loss = 0.013649763944636843, Recall = 1.0, Aging Rate = 0.4987709497206704, precision = 0.9977598566308243\n",
      "\n",
      "Epoch 21: Train Loss = 0.017890920502097247, Recall = 0.9991019308486754, Aging Rate = 0.4981005586592179, Precision = 0.9982054733064154, f1 = 0.998653500897666\n",
      "Epoch 22: Train Loss = 0.017686495606126732, Recall = 0.998652896273013, Aging Rate = 0.49787709497206706, Precision = 0.9982046678635548, f1 = 0.998428731762065\n",
      "Epoch 23: Train Loss = 0.019064973417940088, Recall = 0.9977548271216884, Aging Rate = 0.4981005586592179, Precision = 0.996859578286227, f1 = 0.9973070017953322\n",
      "Epoch 24: Train Loss = 0.030491274116592033, Recall = 0.9941625505163898, Aging Rate = 0.49966480446927375, Precision = 0.9901610017889088, f1 = 0.9921577414295317\n",
      "Epoch 25: Train Loss = 0.017337231065391163, Recall = 0.9991019308486754, Aging Rate = 0.49854748603351956, Precision = 0.997310623038996, f1 = 0.9982054733064154\n",
      "Test Loss = 0.013875043737239011, Recall = 1.0, Aging Rate = 0.4976536312849162, precision = 1.0\n",
      "Model in epoch 25 is saved.\n",
      "\n",
      "Epoch 26: Train Loss = 0.018133783764596092, Recall = 0.9995509654243376, Aging Rate = 0.49854748603351956, Precision = 0.9977588525324966, f1 = 0.9986541049798116\n",
      "Epoch 27: Train Loss = 0.016063146241134106, Recall = 0.9995509654243376, Aging Rate = 0.4976536312849162, Precision = 0.9995509654243376, f1 = 0.9995509654243376\n",
      "Epoch 28: Train Loss = 0.020502502550709182, Recall = 0.998652896273013, Aging Rate = 0.4987709497206704, Precision = 0.996415770609319, f1 = 0.9975330791657323\n",
      "Epoch 29: Train Loss = 0.019499186329002487, Recall = 0.9982038616973506, Aging Rate = 0.4983240223463687, Precision = 0.9968609865470852, f1 = 0.9975319721785955\n",
      "Epoch 30: Train Loss = 0.02245422796996612, Recall = 0.9982038616973506, Aging Rate = 0.49854748603351956, Precision = 0.9964141640519946, f1 = 0.9973082099596231\n",
      "Test Loss = 0.018067818328779836, Recall = 0.9968567579703638, Aging Rate = 0.496536312849162, precision = 0.9990999099909991\n",
      "\n",
      "Epoch 31: Train Loss = 0.017034477137820015, Recall = 0.9995509654243376, Aging Rate = 0.49787709497206706, Precision = 0.9991023339317774, f1 = 0.9993265993265993\n",
      "Epoch 32: Train Loss = 0.018421681623635347, Recall = 0.9991019308486754, Aging Rate = 0.49787709497206706, Precision = 0.998653500897666, f1 = 0.9988776655443322\n",
      "Epoch 33: Train Loss = 0.0195076646098045, Recall = 0.9977548271216884, Aging Rate = 0.49854748603351956, Precision = 0.9959659345584939, f1 = 0.9968595782862271\n",
      "Epoch 34: Train Loss = 0.01890211279956655, Recall = 0.9991019308486754, Aging Rate = 0.4987709497206704, Precision = 0.9968637992831542, f1 = 0.9979816102265081\n",
      "Epoch 35: Train Loss = 0.01805171303908918, Recall = 0.998652896273013, Aging Rate = 0.49787709497206706, Precision = 0.9982046678635548, f1 = 0.998428731762065\n",
      "Test Loss = 0.01764632951801216, Recall = 1.0, Aging Rate = 0.49988826815642456, precision = 0.9955297273133661\n",
      "\n",
      "Epoch 36: Train Loss = 0.01997403752350108, Recall = 0.9991019308486754, Aging Rate = 0.4994413407821229, Precision = 0.9955257270693513, f1 = 0.997310623038996\n",
      "Epoch 37: Train Loss = 0.02214089396945591, Recall = 0.9968567579703638, Aging Rate = 0.4981005586592179, Precision = 0.9959623149394348, f1 = 0.9964093357271095\n",
      "Epoch 38: Train Loss = 0.018884328328822246, Recall = 0.9977548271216884, Aging Rate = 0.49787709497206706, Precision = 0.9973070017953322, f1 = 0.9975308641975309\n",
      "Epoch 39: Train Loss = 0.0146660391178877, Recall = 0.9991019308486754, Aging Rate = 0.4976536312849162, Precision = 0.9991019308486754, f1 = 0.9991019308486754\n",
      "Epoch 40: Train Loss = 0.016472764133824317, Recall = 0.9995509654243376, Aging Rate = 0.4981005586592179, Precision = 0.9986541049798116, f1 = 0.9991023339317774\n",
      "Test Loss = 0.013350549776877104, Recall = 0.9995509654243376, Aging Rate = 0.49743016759776537, precision = 1.0\n",
      "\n",
      "Epoch 41: Train Loss = 0.016328522632491654, Recall = 0.9995509654243376, Aging Rate = 0.4981005586592179, Precision = 0.9986541049798116, f1 = 0.9991023339317774\n",
      "Epoch 42: Train Loss = 0.01634072489682689, Recall = 0.998652896273013, Aging Rate = 0.49743016759776537, Precision = 0.9991015274034142, f1 = 0.9988771614641814\n",
      "Epoch 43: Train Loss = 0.01796868862927626, Recall = 0.9995509654243376, Aging Rate = 0.4983240223463687, Precision = 0.9982062780269059, f1 = 0.9988781691720888\n",
      "Epoch 44: Train Loss = 0.017705530621236264, Recall = 0.998652896273013, Aging Rate = 0.4987709497206704, Precision = 0.996415770609319, f1 = 0.9975330791657323\n",
      "Epoch 45: Train Loss = 0.021608036036431456, Recall = 0.9982038616973506, Aging Rate = 0.4994413407821229, Precision = 0.9946308724832215, f1 = 0.9964141640519946\n",
      "Test Loss = 0.014839813134024262, Recall = 1.0, Aging Rate = 0.4976536312849162, precision = 1.0\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 46: Train Loss = 0.01815745064957515, Recall = 0.9977548271216884, Aging Rate = 0.4976536312849162, Precision = 0.9977548271216884, f1 = 0.9977548271216884\n",
      "Epoch 47: Train Loss = 0.01843195717594477, Recall = 0.9991019308486754, Aging Rate = 0.4987709497206704, Precision = 0.9968637992831542, f1 = 0.9979816102265081\n",
      "Epoch 48: Train Loss = 0.01879027383537266, Recall = 0.998652896273013, Aging Rate = 0.4987709497206704, Precision = 0.996415770609319, f1 = 0.9975330791657323\n",
      "Epoch 49: Train Loss = 0.01897098399990098, Recall = 0.9977548271216884, Aging Rate = 0.49743016759776537, Precision = 0.9982030548068284, f1 = 0.9979788906355267\n",
      "Epoch 50: Train Loss = 0.01815919964090406, Recall = 0.9995509654243376, Aging Rate = 0.4987709497206704, Precision = 0.9973118279569892, f1 = 0.998430141287284\n",
      "Test Loss = 0.014065992357261354, Recall = 1.0, Aging Rate = 0.4981005586592179, precision = 0.9991027366532077\n",
      "\n",
      "Epoch 51: Train Loss = 0.016843864941064206, Recall = 0.9977548271216884, Aging Rate = 0.49743016759776537, Precision = 0.9982030548068284, f1 = 0.9979788906355267\n",
      "Epoch 52: Train Loss = 0.01858995790088643, Recall = 0.9995509654243376, Aging Rate = 0.4981005586592179, Precision = 0.9986541049798116, f1 = 0.9991023339317774\n",
      "Epoch 53: Train Loss = 0.015958447059273052, Recall = 1.0, Aging Rate = 0.4981005586592179, Precision = 0.9991027366532077, f1 = 0.9995511669658886\n",
      "Epoch 54: Train Loss = 0.0174646403061944, Recall = 0.9995509654243376, Aging Rate = 0.4983240223463687, Precision = 0.9982062780269059, f1 = 0.9988781691720888\n",
      "Epoch 55: Train Loss = 0.020512851828802896, Recall = 0.998652896273013, Aging Rate = 0.4981005586592179, Precision = 0.9977568416330193, f1 = 0.9982046678635548\n",
      "Test Loss = 0.013496433281698706, Recall = 0.9991019308486754, Aging Rate = 0.4972067039106145, precision = 1.0\n",
      "\n",
      "Epoch 56: Train Loss = 0.01895541800508619, Recall = 0.9982038616973506, Aging Rate = 0.49787709497206706, Precision = 0.9977558348294434, f1 = 0.997979797979798\n",
      "Epoch 57: Train Loss = 0.02351787739251246, Recall = 0.9968567579703638, Aging Rate = 0.49921787709497206, Precision = 0.9937332139659804, f1 = 0.9952925353059853\n",
      "Epoch 58: Train Loss = 0.025544826869941292, Recall = 0.9968567579703638, Aging Rate = 0.49899441340782125, Precision = 0.9941782355575459, f1 = 0.9955156950672647\n",
      "Epoch 59: Train Loss = 0.018496910826870182, Recall = 0.9991019308486754, Aging Rate = 0.4994413407821229, Precision = 0.9955257270693513, f1 = 0.997310623038996\n",
      "Epoch 60: Train Loss = 0.014551856624139421, Recall = 0.9982038616973506, Aging Rate = 0.49675977653631287, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.01602454796308579, Recall = 1.0, Aging Rate = 0.4983240223463687, precision = 0.9986547085201793\n",
      "\n",
      "Epoch 61: Train Loss = 0.01918784831655758, Recall = 0.998652896273013, Aging Rate = 0.4981005586592179, Precision = 0.9977568416330193, f1 = 0.9982046678635548\n",
      "Epoch 62: Train Loss = 0.017770938330522464, Recall = 0.9995509654243376, Aging Rate = 0.4981005586592179, Precision = 0.9986541049798116, f1 = 0.9991023339317774\n",
      "Epoch 63: Train Loss = 0.01819788384162847, Recall = 0.9982038616973506, Aging Rate = 0.4976536312849162, Precision = 0.9982038616973506, f1 = 0.9982038616973506\n",
      "Epoch 64: Train Loss = 0.015318839089664001, Recall = 0.9995509654243376, Aging Rate = 0.4983240223463687, Precision = 0.9982062780269059, f1 = 0.9988781691720888\n",
      "Epoch 65: Train Loss = 0.01812970494133467, Recall = 0.9991019308486754, Aging Rate = 0.4983240223463687, Precision = 0.9977578475336323, f1 = 0.9984294368409243\n",
      "Test Loss = 0.01950501354962754, Recall = 0.9977548271216884, Aging Rate = 0.496536312849162, precision = 1.0\n",
      "\n",
      "Epoch 66: Train Loss = 0.016900703757168862, Recall = 0.998652896273013, Aging Rate = 0.49787709497206706, Precision = 0.9982046678635548, f1 = 0.998428731762065\n",
      "Epoch 67: Train Loss = 0.01707344389494571, Recall = 0.9995509654243376, Aging Rate = 0.4983240223463687, Precision = 0.9982062780269059, f1 = 0.9988781691720888\n",
      "Epoch 68: Train Loss = 0.015885225796666225, Recall = 0.9982038616973506, Aging Rate = 0.4969832402234637, Precision = 0.9995503597122302, f1 = 0.9988766569310267\n",
      "Epoch 69: Train Loss = 0.01590508361976573, Recall = 0.9991019308486754, Aging Rate = 0.49787709497206706, Precision = 0.998653500897666, f1 = 0.9988776655443322\n",
      "Epoch 70: Train Loss = 0.0172632345199252, Recall = 0.9982038616973506, Aging Rate = 0.4972067039106145, Precision = 0.9991011235955056, f1 = 0.9986522911051212\n",
      "Test Loss = 0.015748090359210636, Recall = 1.0, Aging Rate = 0.4976536312849162, precision = 1.0\n",
      "\n",
      "Epoch 71: Train Loss = 0.016204712234812076, Recall = 0.9991019308486754, Aging Rate = 0.49787709497206706, Precision = 0.998653500897666, f1 = 0.9988776655443322\n",
      "Epoch 72: Train Loss = 0.01777921296947495, Recall = 0.9991019308486754, Aging Rate = 0.4981005586592179, Precision = 0.9982054733064154, f1 = 0.998653500897666\n",
      "Epoch 73: Train Loss = 0.018584746324649737, Recall = 0.998652896273013, Aging Rate = 0.4981005586592179, Precision = 0.9977568416330193, f1 = 0.9982046678635548\n",
      "Epoch 74: Train Loss = 0.01878978787021264, Recall = 0.9977548271216884, Aging Rate = 0.49743016759776537, Precision = 0.9982030548068284, f1 = 0.9979788906355267\n",
      "Epoch 75: Train Loss = 0.01731289471869029, Recall = 0.9991019308486754, Aging Rate = 0.4994413407821229, Precision = 0.9955257270693513, f1 = 0.997310623038996\n",
      "Test Loss = 0.01370995250202757, Recall = 1.0, Aging Rate = 0.4981005586592179, precision = 0.9991027366532077\n",
      "\n",
      "Training Finished at epoch 75.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c83b61b34164757aa766accf9e7ebfb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss = 0.43612690187699305, Recall = 0.8648405927256398, Aging Rate = 0.5769832402234637, Precision = 0.7459333849728892, f1 = 0.8009981285090454\n",
      "Epoch 2: Train Loss = 0.20677371787458826, Recall = 0.9389312977099237, Aging Rate = 0.5191061452513966, Precision = 0.9001291433491175, f1 = 0.9191208791208791\n",
      "Epoch 3: Train Loss = 0.12457156510659437, Recall = 0.9703637180062865, Aging Rate = 0.5088268156424581, Precision = 0.9490557751427317, f1 = 0.9595914742451156\n",
      "Epoch 4: Train Loss = 0.1003499193098292, Recall = 0.9717108217332735, Aging Rate = 0.5063687150837989, Precision = 0.9549867608120035, f1 = 0.963276207433786\n",
      "Epoch 5: Train Loss = 0.07496959454520455, Recall = 0.9820386169735069, Aging Rate = 0.5025698324022346, Precision = 0.9724321920853712, f1 = 0.9772117962466487\n",
      "Test Loss = 0.03765677390235096, Recall = 0.9991019308486754, Aging Rate = 0.5025698324022346, precision = 0.9893285904846598\n",
      "Model in epoch 5 is saved.\n",
      "\n",
      "Epoch 6: Train Loss = 0.032895916432724985, Recall = 0.9950606196677144, Aging Rate = 0.49899441340782125, Precision = 0.9923869234214062, f1 = 0.9937219730941703\n",
      "Epoch 7: Train Loss = 0.023640239700342024, Recall = 0.998652896273013, Aging Rate = 0.49854748603351956, Precision = 0.9968623935454953, f1 = 0.9977568416330193\n",
      "Epoch 8: Train Loss = 0.023202473825915566, Recall = 0.998652896273013, Aging Rate = 0.4983240223463687, Precision = 0.9973094170403587, f1 = 0.9979807045097598\n",
      "Epoch 9: Train Loss = 0.020980517172863363, Recall = 0.9991019308486754, Aging Rate = 0.4983240223463687, Precision = 0.9977578475336323, f1 = 0.9984294368409243\n",
      "Epoch 10: Train Loss = 0.019817943063944413, Recall = 0.998652896273013, Aging Rate = 0.4983240223463687, Precision = 0.9973094170403587, f1 = 0.9979807045097598\n",
      "Test Loss = 0.01786331444853844, Recall = 1.0, Aging Rate = 0.4983240223463687, precision = 0.9986547085201793\n",
      "Model in epoch 10 is saved.\n",
      "\n",
      "Epoch 11: Train Loss = 0.021869651810916442, Recall = 0.9995509654243376, Aging Rate = 0.49921787709497206, Precision = 0.9964189794091316, f1 = 0.9979825151311364\n",
      "Epoch 12: Train Loss = 0.020052266470130597, Recall = 1.0, Aging Rate = 0.49854748603351956, Precision = 0.9982070820259973, f1 = 0.9991027366532077\n",
      "Epoch 13: Train Loss = 0.0194377239358575, Recall = 0.9995509654243376, Aging Rate = 0.4981005586592179, Precision = 0.9986541049798116, f1 = 0.9991023339317774\n",
      "Epoch 14: Train Loss = 0.016378624672746527, Recall = 0.9991019308486754, Aging Rate = 0.4976536312849162, Precision = 0.9991019308486754, f1 = 0.9991019308486754\n",
      "Epoch 15: Train Loss = 0.019670240931712383, Recall = 0.9995509654243376, Aging Rate = 0.4981005586592179, Precision = 0.9986541049798116, f1 = 0.9991023339317774\n",
      "Test Loss = 0.01670283085973569, Recall = 1.0, Aging Rate = 0.49899441340782125, precision = 0.9973130317957905\n",
      "\n",
      "Epoch 16: Train Loss = 0.02312277401833894, Recall = 0.997305792546026, Aging Rate = 0.49854748603351956, Precision = 0.9955177050649933, f1 = 0.9964109466128309\n",
      "Epoch 17: Train Loss = 0.018317122323719483, Recall = 0.9991019308486754, Aging Rate = 0.49854748603351956, Precision = 0.997310623038996, f1 = 0.9982054733064154\n",
      "Epoch 18: Train Loss = 0.01814150417858329, Recall = 0.998652896273013, Aging Rate = 0.49854748603351956, Precision = 0.9968623935454953, f1 = 0.9977568416330193\n",
      "Epoch 19: Train Loss = 0.02013650340865777, Recall = 0.9982038616973506, Aging Rate = 0.4976536312849162, Precision = 0.9982038616973506, f1 = 0.9982038616973506\n",
      "Epoch 20: Train Loss = 0.01937891042411494, Recall = 0.9995509654243376, Aging Rate = 0.4994413407821229, Precision = 0.9959731543624161, f1 = 0.9977588525324966\n",
      "Test Loss = 0.02227085432693279, Recall = 0.9964077233947014, Aging Rate = 0.4960893854748603, precision = 0.9995495495495496\n",
      "\n",
      "Epoch 21: Train Loss = 0.02062475213916275, Recall = 0.9982038616973506, Aging Rate = 0.4987709497206704, Precision = 0.9959677419354839, f1 = 0.9970845481049563\n",
      "Epoch 22: Train Loss = 0.017291116046006454, Recall = 0.998652896273013, Aging Rate = 0.4981005586592179, Precision = 0.9977568416330193, f1 = 0.9982046678635548\n",
      "Epoch 23: Train Loss = 0.01711294378148777, Recall = 0.9995509654243376, Aging Rate = 0.49787709497206706, Precision = 0.9991023339317774, f1 = 0.9993265993265993\n",
      "Epoch 24: Train Loss = 0.024696589585539348, Recall = 0.9968567579703638, Aging Rate = 0.49854748603351956, Precision = 0.9950694755714926, f1 = 0.9959623149394348\n",
      "Epoch 25: Train Loss = 0.023225859520155625, Recall = 0.997305792546026, Aging Rate = 0.49988826815642456, Precision = 0.9928475637013858, f1 = 0.9950716845878137\n",
      "Test Loss = 0.011970204475788431, Recall = 1.0, Aging Rate = 0.4976536312849162, precision = 1.0\n",
      "Model in epoch 25 is saved.\n",
      "\n",
      "Epoch 26: Train Loss = 0.015413034542063095, Recall = 0.9991019308486754, Aging Rate = 0.4983240223463687, Precision = 0.9977578475336323, f1 = 0.9984294368409243\n",
      "Epoch 27: Train Loss = 0.01568097984740854, Recall = 1.0, Aging Rate = 0.4983240223463687, Precision = 0.9986547085201793, f1 = 0.9993269015032533\n",
      "Epoch 28: Train Loss = 0.017616699890925566, Recall = 0.998652896273013, Aging Rate = 0.49743016759776537, Precision = 0.9991015274034142, f1 = 0.9988771614641814\n",
      "Epoch 29: Train Loss = 0.015904571180486812, Recall = 0.9995509654243376, Aging Rate = 0.4981005586592179, Precision = 0.9986541049798116, f1 = 0.9991023339317774\n",
      "Epoch 30: Train Loss = 0.015849405039289145, Recall = 0.998652896273013, Aging Rate = 0.49743016759776537, Precision = 0.9991015274034142, f1 = 0.9988771614641814\n",
      "Test Loss = 0.014738719068342747, Recall = 0.9995509654243376, Aging Rate = 0.4981005586592179, precision = 0.9986541049798116\n",
      "\n",
      "Epoch 31: Train Loss = 0.01981657243723976, Recall = 0.998652896273013, Aging Rate = 0.4983240223463687, Precision = 0.9973094170403587, f1 = 0.9979807045097598\n",
      "Epoch 32: Train Loss = 0.026107022072599587, Recall = 0.9977548271216884, Aging Rate = 0.5005586592178771, Precision = 0.9919642857142857, f1 = 0.9948511305126484\n",
      "Epoch 33: Train Loss = 0.014912685302798975, Recall = 0.9991019308486754, Aging Rate = 0.4987709497206704, Precision = 0.9968637992831542, f1 = 0.9979816102265081\n",
      "Epoch 34: Train Loss = 0.017307647960520655, Recall = 0.9995509654243376, Aging Rate = 0.4987709497206704, Precision = 0.9973118279569892, f1 = 0.998430141287284\n",
      "Epoch 35: Train Loss = 0.01674719477082764, Recall = 0.9991019308486754, Aging Rate = 0.4981005586592179, Precision = 0.9982054733064154, f1 = 0.998653500897666\n",
      "Test Loss = 0.017385349359841987, Recall = 0.997305792546026, Aging Rate = 0.4963128491620112, precision = 1.0\n",
      "\n",
      "Epoch 36: Train Loss = 0.016304871089048892, Recall = 0.9995509654243376, Aging Rate = 0.4981005586592179, Precision = 0.9986541049798116, f1 = 0.9991023339317774\n",
      "Epoch 37: Train Loss = 0.015745758073373212, Recall = 0.9995509654243376, Aging Rate = 0.49854748603351956, Precision = 0.9977588525324966, f1 = 0.9986541049798116\n",
      "Epoch 38: Train Loss = 0.01987609722011582, Recall = 0.9977548271216884, Aging Rate = 0.4976536312849162, Precision = 0.9977548271216884, f1 = 0.9977548271216884\n",
      "Epoch 39: Train Loss = 0.024506734641861982, Recall = 0.9968567579703638, Aging Rate = 0.49743016759776537, Precision = 0.9973045822102425, f1 = 0.9970806198068717\n",
      "Epoch 40: Train Loss = 0.024445890079163972, Recall = 0.997305792546026, Aging Rate = 0.49921787709497206, Precision = 0.9941808415398389, f1 = 0.9957408652768439\n",
      "Test Loss = 0.0179236237271871, Recall = 1.0, Aging Rate = 0.49921787709497206, precision = 0.9968666069829901\n",
      "\n",
      "Epoch 41: Train Loss = 0.017398350597385256, Recall = 0.9995509654243376, Aging Rate = 0.4983240223463687, Precision = 0.9982062780269059, f1 = 0.9988781691720888\n",
      "Epoch 42: Train Loss = 0.013219917140193492, Recall = 0.9995509654243376, Aging Rate = 0.4976536312849162, Precision = 0.9995509654243376, f1 = 0.9995509654243376\n",
      "Epoch 43: Train Loss = 0.016377250776943547, Recall = 1.0, Aging Rate = 0.4987709497206704, Precision = 0.9977598566308243, f1 = 0.99887867234806\n",
      "Epoch 44: Train Loss = 0.01921205797841429, Recall = 0.998652896273013, Aging Rate = 0.4976536312849162, Precision = 0.998652896273013, f1 = 0.998652896273013\n",
      "Epoch 45: Train Loss = 0.016679440990673096, Recall = 0.9982038616973506, Aging Rate = 0.4976536312849162, Precision = 0.9982038616973506, f1 = 0.9982038616973506\n",
      "Test Loss = 0.01424264723133275, Recall = 1.0, Aging Rate = 0.4987709497206704, precision = 0.9977598566308243\n",
      "\n",
      "Epoch 46: Train Loss = 0.01647155005464008, Recall = 0.9995509654243376, Aging Rate = 0.4981005586592179, Precision = 0.9986541049798116, f1 = 0.9991023339317774\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 47: Train Loss = 0.016016738832662893, Recall = 0.998652896273013, Aging Rate = 0.49787709497206706, Precision = 0.9982046678635548, f1 = 0.998428731762065\n",
      "Epoch 48: Train Loss = 0.019497725602301806, Recall = 0.9995509654243376, Aging Rate = 0.4983240223463687, Precision = 0.9982062780269059, f1 = 0.9988781691720888\n",
      "Epoch 49: Train Loss = 0.018243094041277576, Recall = 0.9995509654243376, Aging Rate = 0.4981005586592179, Precision = 0.9986541049798116, f1 = 0.9991023339317774\n",
      "Epoch 50: Train Loss = 0.01643504430420239, Recall = 0.998652896273013, Aging Rate = 0.4983240223463687, Precision = 0.9973094170403587, f1 = 0.9979807045097598\n",
      "Test Loss = 0.01552498340315326, Recall = 1.0, Aging Rate = 0.4983240223463687, precision = 0.9986547085201793\n",
      "\n",
      "Epoch 51: Train Loss = 0.018819300042850345, Recall = 0.9991019308486754, Aging Rate = 0.4987709497206704, Precision = 0.9968637992831542, f1 = 0.9979816102265081\n",
      "Epoch 52: Train Loss = 0.017568512866117436, Recall = 0.9991019308486754, Aging Rate = 0.4981005586592179, Precision = 0.9982054733064154, f1 = 0.998653500897666\n",
      "Epoch 53: Train Loss = 0.02865915324310018, Recall = 0.995958688819039, Aging Rate = 0.49988826815642456, Precision = 0.9915064818953956, f1 = 0.9937275985663082\n",
      "Epoch 54: Train Loss = 0.019123942868669606, Recall = 0.9982038616973506, Aging Rate = 0.49854748603351956, Precision = 0.9964141640519946, f1 = 0.9973082099596231\n",
      "Epoch 55: Train Loss = 0.01478928592243341, Recall = 0.9991019308486754, Aging Rate = 0.4976536312849162, Precision = 0.9991019308486754, f1 = 0.9991019308486754\n",
      "Test Loss = 0.012274127601536625, Recall = 1.0, Aging Rate = 0.4976536312849162, precision = 1.0\n",
      "\n",
      "Epoch 56: Train Loss = 0.014374228297581886, Recall = 0.9995509654243376, Aging Rate = 0.4976536312849162, Precision = 0.9995509654243376, f1 = 0.9995509654243376\n",
      "Epoch 57: Train Loss = 0.01578165146787573, Recall = 0.9995509654243376, Aging Rate = 0.49787709497206706, Precision = 0.9991023339317774, f1 = 0.9993265993265993\n",
      "Epoch 58: Train Loss = 0.015163349336918507, Recall = 0.9995509654243376, Aging Rate = 0.4976536312849162, Precision = 0.9995509654243376, f1 = 0.9995509654243376\n",
      "Epoch 59: Train Loss = 0.01885854278613069, Recall = 0.9991019308486754, Aging Rate = 0.4981005586592179, Precision = 0.9982054733064154, f1 = 0.998653500897666\n",
      "Epoch 60: Train Loss = 0.03047534798277157, Recall = 0.9964077233947014, Aging Rate = 0.5010055865921788, Precision = 0.9897413024085637, f1 = 0.9930633251286641\n",
      "Test Loss = 0.015620707062036632, Recall = 0.9995509654243376, Aging Rate = 0.5012290502793296, precision = 0.9924208649130629\n",
      "\n",
      "Epoch 61: Train Loss = 0.01535624471581515, Recall = 0.998652896273013, Aging Rate = 0.4981005586592179, Precision = 0.9977568416330193, f1 = 0.9982046678635548\n",
      "Epoch 62: Train Loss = 0.014226639927599018, Recall = 0.9991019308486754, Aging Rate = 0.4972067039106145, Precision = 0, f1 = 0.0\n",
      "Epoch 63: Train Loss = 0.01667369489188634, Recall = 1.0, Aging Rate = 0.49921787709497206, Precision = 0.9968666069829901, f1 = 0.9984308451019951\n",
      "Epoch 64: Train Loss = 0.016865209540008832, Recall = 0.9991019308486754, Aging Rate = 0.49787709497206706, Precision = 0.998653500897666, f1 = 0.9988776655443322\n",
      "Epoch 65: Train Loss = 0.015234824438584583, Recall = 1.0, Aging Rate = 0.4976536312849162, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.013833534775832513, Recall = 1.0, Aging Rate = 0.4976536312849162, precision = 1.0\n",
      "\n",
      "Epoch 66: Train Loss = 0.015103260877869982, Recall = 0.9995509654243376, Aging Rate = 0.49743016759776537, Precision = 0, f1 = 0.0\n",
      "Epoch 67: Train Loss = 0.015538750611370502, Recall = 0.998652896273013, Aging Rate = 0.4976536312849162, Precision = 0.998652896273013, f1 = 0.998652896273013\n",
      "Epoch 68: Train Loss = 0.0180534983755157, Recall = 0.9991019308486754, Aging Rate = 0.4976536312849162, Precision = 0.9991019308486754, f1 = 0.9991019308486754\n",
      "Epoch 69: Train Loss = 0.01645785307522093, Recall = 0.9991019308486754, Aging Rate = 0.49787709497206706, Precision = 0.998653500897666, f1 = 0.9988776655443322\n",
      "Epoch 70: Train Loss = 0.015109786220602483, Recall = 0.9991019308486754, Aging Rate = 0.49787709497206706, Precision = 0.998653500897666, f1 = 0.9988776655443322\n",
      "Test Loss = 0.01357639367915898, Recall = 0.9995509654243376, Aging Rate = 0.4976536312849162, precision = 0.9995509654243376\n",
      "\n",
      "Epoch 71: Train Loss = 0.018297246527238933, Recall = 0.998652896273013, Aging Rate = 0.49787709497206706, Precision = 0.9982046678635548, f1 = 0.998428731762065\n",
      "Epoch 72: Train Loss = 0.015324437569764406, Recall = 0.9991019308486754, Aging Rate = 0.4981005586592179, Precision = 0.9982054733064154, f1 = 0.998653500897666\n",
      "Epoch 73: Train Loss = 0.01940726343583961, Recall = 0.997305792546026, Aging Rate = 0.49743016759776537, Precision = 0.9977538185085355, f1 = 0.9975297552211992\n",
      "Epoch 74: Train Loss = 0.020369941917919247, Recall = 0.998652896273013, Aging Rate = 0.4981005586592179, Precision = 0.9977568416330193, f1 = 0.9982046678635548\n",
      "Epoch 75: Train Loss = 0.01600752731275292, Recall = 0.9991019308486754, Aging Rate = 0.4981005586592179, Precision = 0.9982054733064154, f1 = 0.998653500897666\n",
      "Test Loss = 0.014934138729752109, Recall = 1.0, Aging Rate = 0.4976536312849162, precision = 1.0\n",
      "\n",
      "Training Finished at epoch 75.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a9b65e1b0df4c83902dde9b0b88dd97",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc545774360743f2b8d9ae0db2c46a63",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss = 0.39835594152730414, Recall = 0.9087924115286392, Aging Rate = 0.6532371216676689, Precision = 0.7643448910708807, f1 = 0.8303333333333334\n",
      "Epoch 2: Train Loss = 0.29219523892418897, Recall = 0.9343305363006202, Aging Rate = 0.6101423130887953, Precision = 0.8413272010512484, f1 = 0.8853932584269663\n",
      "Epoch 3: Train Loss = 0.2606193372764337, Recall = 0.9441809558555272, Aging Rate = 0.6009220284626178, Precision = 0.8632421614409607, f1 = 0.901899285589824\n",
      "Epoch 4: Train Loss = 0.24872459464057411, Recall = 0.9496534111638089, Aging Rate = 0.5991180597314091, Precision = 0.8708598193375711, f1 = 0.9085514834205934\n",
      "Epoch 5: Train Loss = 0.24810453975193486, Recall = 0.9525720539948924, Aging Rate = 0.6037282020444978, Precision = 0.8668658698539177, f1 = 0.9077003302624718\n",
      "Test Loss = 0.20540204419296904, Recall = 0.9806639912440716, Aging Rate = 0.605131288835438, precision = 0.8903610467042067\n",
      "Model in epoch 5 is saved.\n",
      "\n",
      "Epoch 6: Train Loss = 0.2134405162553554, Recall = 0.9620576431959139, Aging Rate = 0.5884946883142914, Precision = 0.8981607629427792, f1 = 0.929011802008103\n",
      "Epoch 7: Train Loss = 0.18776951577028309, Recall = 0.9682597592119664, Aging Rate = 0.5824814592102626, Precision = 0.9132828630419821, f1 = 0.9399681246679653\n",
      "Epoch 8: Train Loss = 0.18991446629163616, Recall = 0.9671652681503101, Aging Rate = 0.5824814592102626, Precision = 0.9122505161734342, f1 = 0.9389056136001416\n",
      "Epoch 9: Train Loss = 0.18689636038166413, Recall = 0.9660707770886537, Aging Rate = 0.5772699939867709, Precision = 0.9194444444444444, f1 = 0.9421811065646681\n",
      "Epoch 10: Train Loss = 0.18983516591982078, Recall = 0.9671652681503101, Aging Rate = 0.5804770495089197, Precision = 0.9154005524861878, f1 = 0.9405712258293418\n",
      "Test Loss = 0.1862050944535664, Recall = 0.9886902590295512, Aging Rate = 0.620765684505913, precision = 0.8750403616402971\n",
      "\n",
      "Epoch 11: Train Loss = 0.18109460920244783, Recall = 0.9715432323969354, Aging Rate = 0.5804770495089197, Precision = 0.9195441988950276, f1 = 0.9448288096505233\n",
      "Epoch 12: Train Loss = 0.18660786734193138, Recall = 0.9671652681503101, Aging Rate = 0.580076167568651, Precision = 0.9160331720801659, f1 = 0.940905057675244\n",
      "Epoch 13: Train Loss = 0.1849208224611833, Recall = 0.9668004377964247, Aging Rate = 0.5796752856283824, Precision = 0.9163208852005532, f1 = 0.9408840759808274\n",
      "Epoch 14: Train Loss = 0.18278631183254765, Recall = 0.9697190806275082, Aging Rate = 0.5804770495089197, Precision = 0.9178176795580111, f1 = 0.9430548163916977\n",
      "Epoch 15: Train Loss = 0.1769015308724159, Recall = 0.9686245895658518, Aging Rate = 0.578071757867308, Precision = 0.9205963938973648, f1 = 0.9440000000000001\n",
      "Test Loss = 0.1750168029131548, Recall = 0.9897847500912076, Aging Rate = 0.6157546602525557, precision = 0.8831380208333334\n",
      "\n",
      "Epoch 16: Train Loss = 0.1822341023340424, Recall = 0.97117840204305, Aging Rate = 0.5818801362998597, Precision = 0.9169824319669307, f1 = 0.9433026222537207\n",
      "Epoch 17: Train Loss = 0.18217067399724354, Recall = 0.9697190806275082, Aging Rate = 0.580076167568651, Precision = 0.9184519695922598, f1 = 0.9433895297249334\n",
      "Epoch 18: Train Loss = 0.1869277376812239, Recall = 0.9697190806275082, Aging Rate = 0.5818801362998597, Precision = 0.9156045470203238, f1 = 0.9418851878100637\n",
      "Epoch 19: Train Loss = 0.18565463810699165, Recall = 0.9708135716891645, Aging Rate = 0.5828823411505312, Precision = 0.9150618982118295, f1 = 0.942113648433351\n",
      "Epoch 20: Train Loss = 0.18052375945043267, Recall = 0.967894928858081, Aging Rate = 0.5782721988374424, Precision = 0.9195840554592721, f1 = 0.9431212228937079\n",
      "Test Loss = 0.17612309173260263, Recall = 0.9649762860269975, Aging Rate = 0.5710563239126077, precision = 0.9283959283959284\n",
      "Model in epoch 20 is saved.\n",
      "\n",
      "Epoch 21: Train Loss = 0.18268770798458367, Recall = 0.97117840204305, Aging Rate = 0.580076167568651, Precision = 0.9198341395991707, f1 = 0.9448092280390417\n",
      "Epoch 22: Train Loss = 0.18522856619129155, Recall = 0.9704487413352791, Aging Rate = 0.580076167568651, Precision = 0.9191430545957153, f1 = 0.9440993788819876\n",
      "Epoch 23: Train Loss = 0.1794862718668412, Recall = 0.9704487413352791, Aging Rate = 0.5788735217478452, Precision = 0.9210526315789473, f1 = 0.9451057026114763\n",
      "Epoch 24: Train Loss = 0.18113229989909915, Recall = 0.9730025538124772, Aging Rate = 0.5804770495089197, Precision = 0.9209254143646409, f1 = 0.9462480042575838\n",
      "Epoch 25: Train Loss = 0.1754016442865426, Recall = 0.9689894199197373, Aging Rate = 0.5748647023451593, Precision = 0.9260808926080892, f1 = 0.9470493849170976\n",
      "Test Loss = 0.15859537040764354, Recall = 0.9824881430134987, Aging Rate = 0.576668671076368, precision = 0.9360444907890163\n",
      "Model in epoch 25 is saved.\n",
      "\n",
      "Epoch 26: Train Loss = 0.17466431956213302, Recall = 0.9726377234585918, Aging Rate = 0.5770695530166366, Precision = 0.9260159777700591, f1 = 0.9487544483985766\n",
      "Epoch 27: Train Loss = 0.1721995367443999, Recall = 0.9762860269974462, Aging Rate = 0.5788735217478452, Precision = 0.9265927977839336, f1 = 0.9507905489429739\n",
      "Epoch 28: Train Loss = 0.17833793565323272, Recall = 0.9689894199197373, Aging Rate = 0.5782721988374424, Precision = 0.9206239168110919, f1 = 0.9441876999644507\n",
      "Epoch 29: Train Loss = 0.17507078302518284, Recall = 0.9726377234585918, Aging Rate = 0.580076167568651, Precision = 0.9212163096060816, f1 = 0.9462289263531499\n",
      "Epoch 30: Train Loss = 0.18020000639540515, Recall = 0.9730025538124772, Aging Rate = 0.5802766085387854, Precision = 0.9212435233160622, f1 = 0.9464158977998581\n",
      "Test Loss = 0.1675362510049981, Recall = 0.9894199197373221, Aging Rate = 0.601122469432752, precision = 0.9043014338112704\n",
      "\n",
      "Epoch 31: Train Loss = 0.17749760607711107, Recall = 0.9722728931047063, Aging Rate = 0.5790739627179795, Precision = 0.9224645205953618, f1 = 0.9467140319715809\n",
      "Epoch 32: Train Loss = 0.17617598036518792, Recall = 0.9762860269974462, Aging Rate = 0.5784726398075767, Precision = 0.9272349272349273, f1 = 0.951128487648836\n",
      "Epoch 33: Train Loss = 0.17509931204050905, Recall = 0.9700839109813937, Aging Rate = 0.5764682301062337, Precision = 0.924547983310153, f1 = 0.9467687377603704\n",
      "Epoch 34: Train Loss = 0.18087262345903932, Recall = 0.9704487413352791, Aging Rate = 0.5812788133894567, Precision = 0.9172413793103448, f1 = 0.9430951958872541\n",
      "Epoch 35: Train Loss = 0.1711182902417935, Recall = 0.9751915359357899, Aging Rate = 0.5760673481659652, Precision = 0.930062630480167, f1 = 0.9520926090828139\n",
      "Test Loss = 0.16049154453751655, Recall = 0.9784750091207588, Aging Rate = 0.5818801362998597, precision = 0.9238718566999655\n",
      "\n",
      "Epoch 36: Train Loss = 0.17425880574868233, Recall = 0.973732214520248, Aging Rate = 0.5768691120465023, Precision = 0.9273801250868658, f1 = 0.9499911016195053\n",
      "Epoch 37: Train Loss = 0.1750332283505363, Recall = 0.9740970448741335, Aging Rate = 0.5822810182401282, Precision = 0.919104991394148, f1 = 0.9458023379383634\n",
      "Epoch 38: Train Loss = 0.18123196465956182, Recall = 0.97117840204305, Aging Rate = 0.5810783724193225, Precision = 0.9182476716109003, f1 = 0.9439716312056736\n",
      "Epoch 39: Train Loss = 0.1727495884567971, Recall = 0.977745348412988, Aging Rate = 0.5788735217478452, Precision = 0.9279778393351801, f1 = 0.9522117605258483\n",
      "Epoch 40: Train Loss = 0.17610288377627983, Recall = 0.9715432323969354, Aging Rate = 0.5816796953297254, Precision = 0.9176430048242591, f1 = 0.9438242069821017\n",
      "Test Loss = 0.16272344082850784, Recall = 0.9719080627508209, Aging Rate = 0.5640408899579074, precision = 0.9466950959488273\n",
      "Model in epoch 40 is saved.\n",
      "\n",
      "Epoch 41: Train Loss = 0.176067584217204, Recall = 0.9733673841663626, Aging Rate = 0.5784726398075767, Precision = 0.9244629244629244, f1 = 0.9482850542029501\n",
      "Epoch 42: Train Loss = 0.1752552610136364, Recall = 0.9740970448741335, Aging Rate = 0.5814792543595911, Precision = 0.9203722854188211, f1 = 0.9464728819567529\n",
      "Epoch 43: Train Loss = 0.17600688780027918, Recall = 0.973732214520248, Aging Rate = 0.5776708759270395, Precision = 0.9260929909784872, f1 = 0.9493153121109728\n",
      "Epoch 44: Train Loss = 0.18158766531285983, Recall = 0.9700839109813937, Aging Rate = 0.580076167568651, Precision = 0.9187975120939875, f1 = 0.9437444543034605\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45: Train Loss = 0.17405176655542257, Recall = 0.9719080627508209, Aging Rate = 0.578071757867308, Precision = 0.9237170596393898, f1 = 0.9472\n",
      "Test Loss = 0.15544906667625769, Recall = 0.9795695001824152, Aging Rate = 0.574664261375025, precision = 0.9365190094175095\n",
      "\n",
      "Epoch 46: Train Loss = 0.17471510513879226, Recall = 0.973732214520248, Aging Rate = 0.5808779314491882, Precision = 0.9209799861973775, f1 = 0.9466217414435184\n",
      "Epoch 47: Train Loss = 0.18081054085927967, Recall = 0.9708135716891645, Aging Rate = 0.5814792543595911, Precision = 0.9172699069286453, f1 = 0.9432825239276852\n",
      "Epoch 48: Train Loss = 0.1731790488828134, Recall = 0.9751915359357899, Aging Rate = 0.5806774904790539, Precision = 0.9226786330686918, f1 = 0.9482085846044698\n",
      "Epoch 49: Train Loss = 0.17559509191980915, Recall = 0.9770156877052171, Aging Rate = 0.5836841050310684, Precision = 0.9196428571428571, f1 = 0.9474615248540598\n",
      "Epoch 50: Train Loss = 0.17839301369619837, Recall = 0.974461875228019, Aging Rate = 0.5822810182401282, Precision = 0.9194492254733219, f1 = 0.9461565710237337\n",
      "Test Loss = 0.1546617933237426, Recall = 0.9799343305363006, Aging Rate = 0.5734616155542193, precision = 0.9388325760223698\n",
      "\n",
      "Epoch 51: Train Loss = 0.1810478555711722, Recall = 0.9722728931047063, Aging Rate = 0.580076167568651, Precision = 0.9208707671043538, f1 = 0.9458740017746229\n",
      "Epoch 52: Train Loss = 0.17620645073390145, Recall = 0.9719080627508209, Aging Rate = 0.576668671076368, Precision = 0.9259645464025026, f1 = 0.9483802064791742\n",
      "Epoch 53: Train Loss = 0.17555394349069053, Recall = 0.973732214520248, Aging Rate = 0.5790739627179795, Precision = 0.9238490827275874, f1 = 0.9481349911190053\n",
      "Epoch 54: Train Loss = 0.17796246459236076, Recall = 0.9697190806275082, Aging Rate = 0.5762677891360994, Precision = 0.9245217391304348, f1 = 0.9465811965811965\n",
      "Epoch 55: Train Loss = 0.17822458775291034, Recall = 0.9708135716891645, Aging Rate = 0.5778713168971737, Precision = 0.922996878251821, f1 = 0.9463015647226172\n",
      "Test Loss = 0.1830147080292179, Recall = 0.9558555271798613, Aging Rate = 0.5429945880938064, precision = 0.9671465485418974\n",
      "Model in epoch 55 is saved.\n",
      "\n",
      "Epoch 56: Train Loss = 0.17488766039127482, Recall = 0.974461875228019, Aging Rate = 0.5794748446582482, Precision = 0.9239017640954686, f1 = 0.9485085227272726\n",
      "Epoch 57: Train Loss = 0.1747502181675277, Recall = 0.97117840204305, Aging Rate = 0.5778713168971737, Precision = 0.9233437391605966, f1 = 0.9466571834992888\n",
      "Epoch 58: Train Loss = 0.18381522930404376, Recall = 0.9668004377964247, Aging Rate = 0.5782721988374424, Precision = 0.9185441941074524, f1 = 0.9420547458229648\n",
      "Epoch 59: Train Loss = 0.17854921552163133, Recall = 0.9693542502736228, Aging Rate = 0.5804770495089197, Precision = 0.9174723756906077, f1 = 0.9427000177399326\n",
      "Epoch 60: Train Loss = 0.17747137308311883, Recall = 0.9708135716891645, Aging Rate = 0.5776708759270395, Precision = 0.9233171408743928, f1 = 0.9464698559487819\n",
      "Test Loss = 0.16548685264607713, Recall = 0.9883254286756659, Aging Rate = 0.5951092403287231, precision = 0.9124284270798249\n",
      "\n",
      "Epoch 61: Train Loss = 0.17244463983387812, Recall = 0.9748267055819044, Aging Rate = 0.5822810182401282, Precision = 0.9197934595524957, f1 = 0.9465108041091037\n",
      "Epoch 62: Train Loss = 0.17763336545230152, Recall = 0.9726377234585918, Aging Rate = 0.5812788133894567, Precision = 0.9193103448275862, f1 = 0.9452224782839922\n",
      "Epoch 63: Train Loss = 0.17355346357112753, Recall = 0.9748267055819044, Aging Rate = 0.5798757265985167, Precision = 0.9236087106809541, f1 = 0.9485268015619455\n",
      "Epoch 64: Train Loss = 0.17321075614647055, Recall = 0.9751915359357899, Aging Rate = 0.5806774904790539, Precision = 0.9226786330686918, f1 = 0.9482085846044698\n",
      "Epoch 65: Train Loss = 0.17412103412086344, Recall = 0.9755563662896753, Aging Rate = 0.580076167568651, Precision = 0.9239806496199032, f1 = 0.9490683229813665\n",
      "Test Loss = 0.16487791279760575, Recall = 0.9671652681503101, Aging Rate = 0.5592303066746843, precision = 0.9501792114695341\n",
      "\n",
      "Epoch 66: Train Loss = 0.17375600744038072, Recall = 0.9700839109813937, Aging Rate = 0.5742633794347565, Precision = 0.9280977312390924, f1 = 0.9486264716375311\n",
      "Epoch 67: Train Loss = 0.17199173181693525, Recall = 0.9751915359357899, Aging Rate = 0.578071757867308, Precision = 0.9268377253814147, f1 = 0.9504000000000001\n",
      "Epoch 68: Train Loss = 0.17848275249122403, Recall = 0.9708135716891645, Aging Rate = 0.5810783724193225, Precision = 0.917902725077613, f1 = 0.9436170212765956\n",
      "Epoch 69: Train Loss = 0.17389846377046345, Recall = 0.9722728931047063, Aging Rate = 0.5788735217478452, Precision = 0.9227839335180056, f1 = 0.9468822170900694\n",
      "Epoch 70: Train Loss = 0.17965275580561885, Recall = 0.9715432323969354, Aging Rate = 0.5792744036881139, Precision = 0.9214532871972319, f1 = 0.9458355531877108\n",
      "Test Loss = 0.17656594007986298, Recall = 0.9930682232761766, Aging Rate = 0.6187612748045701, precision = 0.8817622287010042\n",
      "\n",
      "Epoch 71: Train Loss = 0.17652892389895325, Recall = 0.9759211966435607, Aging Rate = 0.5818801362998597, Precision = 0.9214605580434033, f1 = 0.9479092841956058\n",
      "Epoch 72: Train Loss = 0.1768215543630248, Recall = 0.9759211966435607, Aging Rate = 0.5790739627179795, Precision = 0.9259259259259259, f1 = 0.9502664298401421\n",
      "Epoch 73: Train Loss = 0.1764430219692466, Recall = 0.9770156877052171, Aging Rate = 0.5806774904790539, Precision = 0.9244045564376941, f1 = 0.9499822632139058\n",
      "Epoch 74: Train Loss = 0.17422771765978357, Recall = 0.9755563662896753, Aging Rate = 0.5816796953297254, Precision = 0.9214334941419711, f1 = 0.9477228424596845\n",
      "Epoch 75: Train Loss = 0.17192767657254449, Recall = 0.9722728931047063, Aging Rate = 0.5736620565243535, Precision = 0.9311670160726765, f1 = 0.9512761020881672\n",
      "Test Loss = 0.18793162380341993, Recall = 0.9952572053994893, Aging Rate = 0.6289837642814191, precision = 0.8693435309114086\n",
      "\n",
      "Epoch 76: Train Loss = 0.1739879285830442, Recall = 0.9726377234585918, Aging Rate = 0.5784726398075767, Precision = 0.9237699237699237, f1 = 0.9475741958414785\n",
      "Epoch 77: Train Loss = 0.17958007147470345, Recall = 0.9700839109813937, Aging Rate = 0.5774704349569052, Precision = 0.9229434224227698, f1 = 0.9459267164710068\n",
      "Epoch 78: Train Loss = 0.17596308058465643, Recall = 0.9802991608901861, Aging Rate = 0.5856885147324113, Precision = 0.9195756331279945, f1 = 0.9489669786332333\n",
      "Epoch 79: Train Loss = 0.1741355115592205, Recall = 0.9748267055819044, Aging Rate = 0.5770695530166366, Precision = 0.9281000347342827, f1 = 0.9508896797153025\n",
      "Epoch 80: Train Loss = 0.17719312559079253, Recall = 0.9704487413352791, Aging Rate = 0.5776708759270395, Precision = 0.922970159611381, f1 = 0.9461141739285079\n",
      "Test Loss = 0.1613535297451002, Recall = 0.9759211966435607, Aging Rate = 0.5758669071958308, precision = 0.9310824921684651\n",
      "\n",
      "Epoch 81: Train Loss = 0.17736847932555197, Recall = 0.9722728931047063, Aging Rate = 0.5792744036881139, Precision = 0.9221453287197232, f1 = 0.9465459065885279\n",
      "Epoch 82: Train Loss = 0.17460818682071275, Recall = 0.97117840204305, Aging Rate = 0.5790739627179795, Precision = 0.9214260989961924, f1 = 0.9456483126110123\n",
      "Epoch 83: Train Loss = 0.17744480774454707, Recall = 0.97117840204305, Aging Rate = 0.5782721988374424, Precision = 0.9227036395147313, f1 = 0.9463206541059367\n",
      "Epoch 84: Train Loss = 0.17300812968165488, Recall = 0.9759211966435607, Aging Rate = 0.5796752856283824, Precision = 0.9249654218533887, f1 = 0.9497603408485709\n",
      "Epoch 85: Train Loss = 0.17757185938023068, Recall = 0.9700839109813937, Aging Rate = 0.5776708759270395, Precision = 0.9226231783483692, f1 = 0.945758491908234\n",
      "Test Loss = 0.16230463785694127, Recall = 0.9839474644290405, Aging Rate = 0.5844858689116055, precision = 0.9248971193415638\n",
      "\n",
      "Epoch 86: Train Loss = 0.174307531053878, Recall = 0.9726377234585918, Aging Rate = 0.5798757265985167, Precision = 0.9215347390252333, f1 = 0.9463968761093361\n",
      "Epoch 87: Train Loss = 0.17594115296294727, Recall = 0.9715432323969354, Aging Rate = 0.5784726398075767, Precision = 0.9227304227304227, f1 = 0.9465079082992712\n",
      "Epoch 88: Train Loss = 0.17300553350750633, Recall = 0.973732214520248, Aging Rate = 0.580076167568651, Precision = 0.9222529371112647, f1 = 0.9472937000887311\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 89: Train Loss = 0.17523333634587562, Recall = 0.9751915359357899, Aging Rate = 0.5808779314491882, Precision = 0.922360248447205, f1 = 0.9480404327008335\n",
      "Epoch 90: Train Loss = 0.1775426518423664, Recall = 0.9719080627508209, Aging Rate = 0.5802766085387854, Precision = 0.9202072538860103, f1 = 0.9453513129879346\n",
      "Test Loss = 0.16068236199785363, Recall = 0.9762860269974462, Aging Rate = 0.5696532371216677, precision = 0.9415904292751583\n",
      "\n",
      "Epoch 91: Train Loss = 0.17284473044005155, Recall = 0.9751915359357899, Aging Rate = 0.5790739627179795, Precision = 0.9252336448598131, f1 = 0.9495559502664299\n",
      "Epoch 92: Train Loss = 0.17516475245968854, Recall = 0.9708135716891645, Aging Rate = 0.5788735217478452, Precision = 0.921398891966759, f1 = 0.9454610055071948\n",
      "Epoch 93: Train Loss = 0.17722180487218805, Recall = 0.9697190806275082, Aging Rate = 0.5792744036881139, Precision = 0.9197231833910035, f1 = 0.9440596696856686\n",
      "Epoch 94: Train Loss = 0.17912338735895278, Recall = 0.9751915359357899, Aging Rate = 0.5806774904790539, Precision = 0.9226786330686918, f1 = 0.9482085846044698\n",
      "Epoch 95: Train Loss = 0.17053447155728801, Recall = 0.9755563662896753, Aging Rate = 0.5796752856283824, Precision = 0.9246196403872753, f1 = 0.9494052902538612\n",
      "Test Loss = 0.18208856465200499, Recall = 0.9478292593943816, Aging Rate = 0.5383844457807175, precision = 0.9672375279225615\n",
      "\n",
      "Epoch 96: Train Loss = 0.17804046714740757, Recall = 0.974461875228019, Aging Rate = 0.5802766085387854, Precision = 0.9226252158894646, f1 = 0.9478353442157559\n",
      "Epoch 97: Train Loss = 0.1765925147193399, Recall = 0.9715432323969354, Aging Rate = 0.5788735217478452, Precision = 0.9220914127423823, f1 = 0.946171611298632\n",
      "Epoch 98: Train Loss = 0.16966371317680623, Recall = 0.9719080627508209, Aging Rate = 0.5750651433152937, Precision = 0.9285465318926455, f1 = 0.9497326203208556\n",
      "Epoch 99: Train Loss = 0.17545625179898502, Recall = 0.9719080627508209, Aging Rate = 0.5804770495089197, Precision = 0.919889502762431, f1 = 0.9451836083022885\n",
      "Epoch 100: Train Loss = 0.17962121367335057, Recall = 0.9726377234585918, Aging Rate = 0.5792744036881139, Precision = 0.9224913494809689, f1 = 0.9469010832889363\n",
      "Test Loss = 0.16530241376234453, Recall = 0.9850419554906968, Aging Rate = 0.5961114451793946, precision = 0.9078681909885676\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d3e1064942ea4c6789623297d97c55f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss = 0.40359453108750837, Recall = 0.9029551258664721, Aging Rate = 0.6476247745039087, Precision = 0.766016713091922, f1 = 0.8288680509042197\n",
      "Epoch 2: Train Loss = 0.30660978762485575, Recall = 0.929222911346224, Aging Rate = 0.6115453998797354, Precision = 0.8348082595870207, f1 = 0.8794889502762431\n",
      "Epoch 3: Train Loss = 0.27094373893680446, Recall = 0.9405326523166727, Aging Rate = 0.6023251152535578, Precision = 0.8579034941763727, f1 = 0.8973198746954402\n",
      "Epoch 4: Train Loss = 0.27621486009445617, Recall = 0.9379788398394746, Aging Rate = 0.6057326117458408, Precision = 0.8507610853739246, f1 = 0.8922436231129619\n",
      "Epoch 5: Train Loss = 0.2593352928097584, Recall = 0.9438161255016417, Aging Rate = 0.6003207055522148, Precision = 0.8637729549248748, f1 = 0.9020223152022315\n",
      "Test Loss = 0.23953031837091965, Recall = 0.9843122947829259, Aging Rate = 0.6584485868911606, precision = 0.8213089802130898\n",
      "Model in epoch 5 is saved.\n",
      "\n",
      "Epoch 6: Train Loss = 0.21020606122530158, Recall = 0.9616928128420285, Aging Rate = 0.5884946883142914, Precision = 0.8978201634877384, f1 = 0.9286595032587633\n",
      "Epoch 7: Train Loss = 0.19769538735000516, Recall = 0.9624224735497994, Aging Rate = 0.5804770495089197, Precision = 0.9109116022099447, f1 = 0.9359588433563952\n",
      "Epoch 8: Train Loss = 0.1928653554499185, Recall = 0.9675300985041956, Aging Rate = 0.5836841050310684, Precision = 0.9107142857142857, f1 = 0.9382628692729523\n",
      "Epoch 9: Train Loss = 0.19082211279384023, Recall = 0.9653411163808829, Aging Rate = 0.5804770495089197, Precision = 0.9136740331491713, f1 = 0.9387972325705163\n",
      "Epoch 10: Train Loss = 0.1833974134589895, Recall = 0.9682597592119664, Aging Rate = 0.580076167568651, Precision = 0.917069799585349, f1 = 0.9419698314108251\n",
      "Test Loss = 0.17861910178394208, Recall = 0.9598686610726013, Aging Rate = 0.5512126678693124, precision = 0.9567272727272728\n",
      "Model in epoch 10 is saved.\n",
      "\n",
      "Epoch 11: Train Loss = 0.18679330078035586, Recall = 0.9675300985041956, Aging Rate = 0.5788735217478452, Precision = 0.9182825484764543, f1 = 0.9422632794457274\n",
      "Epoch 12: Train Loss = 0.1841186585939344, Recall = 0.9686245895658518, Aging Rate = 0.5816796953297254, Precision = 0.9148862853204687, f1 = 0.9409888357256778\n",
      "Epoch 13: Train Loss = 0.18466895363521518, Recall = 0.9693542502736228, Aging Rate = 0.5792744036881139, Precision = 0.9193771626297578, f1 = 0.9437044929852602\n",
      "Epoch 14: Train Loss = 0.18118941583789214, Recall = 0.9689894199197373, Aging Rate = 0.5792744036881139, Precision = 0.9190311418685121, f1 = 0.9433493162848519\n",
      "Epoch 15: Train Loss = 0.1753246139374327, Recall = 0.97117840204305, Aging Rate = 0.5764682301062337, Precision = 0.9255910987482615, f1 = 0.9478369236247107\n",
      "Test Loss = 0.18279332887567243, Recall = 0.9952572053994893, Aging Rate = 0.6307877330126278, precision = 0.8668573244359707\n",
      "\n",
      "Epoch 16: Train Loss = 0.1882170261260765, Recall = 0.9668004377964247, Aging Rate = 0.5818801362998597, Precision = 0.9128487771271099, f1 = 0.9390503189227497\n",
      "Epoch 17: Train Loss = 0.17730880110087963, Recall = 0.9715432323969354, Aging Rate = 0.5774704349569052, Precision = 0.9243318292259632, f1 = 0.9473496976165067\n",
      "Epoch 18: Train Loss = 0.17916148929061668, Recall = 0.9722728931047063, Aging Rate = 0.5806774904790539, Precision = 0.9199171556782879, f1 = 0.9453706988293721\n",
      "Epoch 19: Train Loss = 0.18392327023450922, Recall = 0.9686245895658518, Aging Rate = 0.578673080777711, Precision = 0.9196397644613786, f1 = 0.9434968017057568\n",
      "Epoch 20: Train Loss = 0.1824973257343285, Recall = 0.9726377234585918, Aging Rate = 0.5838845460012027, Precision = 0.9152076896670099, f1 = 0.9430491687301026\n",
      "Test Loss = 0.1862563176969532, Recall = 0.9952572053994893, Aging Rate = 0.6313890559230306, precision = 0.866031746031746\n",
      "\n",
      "Epoch 21: Train Loss = 0.17988795926579734, Recall = 0.97117840204305, Aging Rate = 0.5824814592102626, Precision = 0.9160357880247764, f1 = 0.942801487515495\n",
      "Epoch 22: Train Loss = 0.18181263613758214, Recall = 0.9671652681503101, Aging Rate = 0.5792744036881139, Precision = 0.9173010380622837, f1 = 0.9415734327828095\n",
      "Epoch 23: Train Loss = 0.1746220275846314, Recall = 0.9748267055819044, Aging Rate = 0.578071757867308, Precision = 0.926490984743412, f1 = 0.9500444444444445\n",
      "Epoch 24: Train Loss = 0.17333527183838562, Recall = 0.9722728931047063, Aging Rate = 0.578673080777711, Precision = 0.9231035677173537, f1 = 0.9470504619758351\n",
      "Epoch 25: Train Loss = 0.18127706959936227, Recall = 0.9697190806275082, Aging Rate = 0.5778713168971737, Precision = 0.9219562955254943, f1 = 0.9452347083926032\n",
      "Test Loss = 0.19818283277299606, Recall = 0.9131703757752645, Aging Rate = 0.5143315293646021, precision = 0.975448168355417\n",
      "\n",
      "Epoch 26: Train Loss = 0.1745319039429995, Recall = 0.9730025538124772, Aging Rate = 0.5804770495089197, Precision = 0.9209254143646409, f1 = 0.9462480042575838\n",
      "Epoch 27: Train Loss = 0.1789435104661677, Recall = 0.9664356074425392, Aging Rate = 0.5770695530166366, Precision = 0.9201111497047586, f1 = 0.9427046263345196\n",
      "Epoch 28: Train Loss = 0.1794694750533359, Recall = 0.9708135716891645, Aging Rate = 0.5794748446582482, Precision = 0.9204427533725354, f1 = 0.9449573863636362\n",
      "Epoch 29: Train Loss = 0.17475956363282766, Recall = 0.9700839109813937, Aging Rate = 0.5764682301062337, Precision = 0.924547983310153, f1 = 0.9467687377603704\n",
      "Epoch 30: Train Loss = 0.17639395795459378, Recall = 0.9708135716891645, Aging Rate = 0.5796752856283824, Precision = 0.9201244813278008, f1 = 0.9447896325226345\n",
      "Test Loss = 0.15581252167699905, Recall = 0.9857716161984678, Aging Rate = 0.5776708759270395, precision = 0.9375433726578765\n",
      "\n",
      "Epoch 31: Train Loss = 0.17552496961492126, Recall = 0.9675300985041956, Aging Rate = 0.5738624974944879, Precision = 0.9263010827803004, f1 = 0.9464668094218416\n",
      "Epoch 32: Train Loss = 0.1820998843852636, Recall = 0.9689894199197373, Aging Rate = 0.5794748446582482, Precision = 0.9187132480110688, f1 = 0.9431818181818181\n",
      "Epoch 33: Train Loss = 0.17310697651203324, Recall = 0.9770156877052171, Aging Rate = 0.5774704349569052, Precision = 0.9295383547379382, f1 = 0.9526858769121309\n",
      "Epoch 34: Train Loss = 0.17594136004100033, Recall = 0.974461875228019, Aging Rate = 0.5826819001803969, Precision = 0.9188166494668043, f1 = 0.9458215297450426\n",
      "Epoch 35: Train Loss = 0.17570874251919583, Recall = 0.9719080627508209, Aging Rate = 0.5778713168971737, Precision = 0.9240374609781478, f1 = 0.9473684210526316\n",
      "Test Loss = 0.15878620995240356, Recall = 0.983582634075155, Aging Rate = 0.5806774904790539, precision = 0.9306178805661028\n",
      "\n",
      "Epoch 36: Train Loss = 0.1720144438269287, Recall = 0.973732214520248, Aging Rate = 0.5768691120465023, Precision = 0.9273801250868658, f1 = 0.9499911016195053\n",
      "Epoch 37: Train Loss = 0.18027296817943075, Recall = 0.967894928858081, Aging Rate = 0.5790739627179795, Precision = 0.9183108341986846, f1 = 0.9424511545293073\n",
      "Epoch 38: Train Loss = 0.17996521088027553, Recall = 0.9697190806275082, Aging Rate = 0.5776708759270395, Precision = 0.9222761970853574, f1 = 0.9454028098879601\n",
      "Epoch 39: Train Loss = 0.17725917880193195, Recall = 0.9697190806275082, Aging Rate = 0.5762677891360994, Precision = 0.9245217391304348, f1 = 0.9465811965811965\n",
      "Epoch 40: Train Loss = 0.17963374924907036, Recall = 0.9708135716891645, Aging Rate = 0.5792744036881139, Precision = 0.9207612456747405, f1 = 0.945125199786894\n",
      "Test Loss = 0.1513590355791819, Recall = 0.9872309376140095, Aging Rate = 0.578071757867308, precision = 0.9382801664355063\n",
      "\n",
      "Epoch 41: Train Loss = 0.17806235000589707, Recall = 0.9704487413352791, Aging Rate = 0.5788735217478452, Precision = 0.9210526315789473, f1 = 0.9451057026114763\n",
      "Epoch 42: Train Loss = 0.18194582745937624, Recall = 0.9693542502736228, Aging Rate = 0.5816796953297254, Precision = 0.9155754651964163, f1 = 0.9416976785397838\n",
      "Epoch 43: Train Loss = 0.17514438239312835, Recall = 0.9733673841663626, Aging Rate = 0.5776708759270395, Precision = 0.9257460097154754, f1 = 0.9489596300906988\n",
      "Epoch 44: Train Loss = 0.17761743445032271, Recall = 0.9708135716891645, Aging Rate = 0.5756664662256965, Precision = 0.9265320334261838, f1 = 0.9481560662747194\n",
      "Epoch 45: Train Loss = 0.17684345408799199, Recall = 0.9770156877052171, Aging Rate = 0.582080577269994, Precision = 0.9221763085399449, f1 = 0.9488042515500443\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss = 0.15256797934485283, Recall = 0.9839474644290405, Aging Rate = 0.5736620565243535, precision = 0.9423480083857443\n",
      "\n",
      "Epoch 46: Train Loss = 0.17620271522276243, Recall = 0.9730025538124772, Aging Rate = 0.578071757867308, Precision = 0.9247572815533981, f1 = 0.9482666666666667\n",
      "Epoch 47: Train Loss = 0.17822853558244867, Recall = 0.9730025538124772, Aging Rate = 0.5806774904790539, Precision = 0.9206075250258888, f1 = 0.9460801702731465\n",
      "Epoch 48: Train Loss = 0.1736768805764438, Recall = 0.9748267055819044, Aging Rate = 0.5794748446582482, Precision = 0.924247665167762, f1 = 0.9488636363636364\n",
      "Epoch 49: Train Loss = 0.17803772746035176, Recall = 0.9697190806275082, Aging Rate = 0.5788735217478452, Precision = 0.9203601108033241, f1 = 0.9443950968200391\n",
      "Epoch 50: Train Loss = 0.18077142552768904, Recall = 0.9700839109813937, Aging Rate = 0.5812788133894567, Precision = 0.916896551724138, f1 = 0.9427406488211312\n",
      "Test Loss = 0.15972880128749412, Recall = 0.9865012769062386, Aging Rate = 0.5836841050310684, precision = 0.9285714285714286\n",
      "\n",
      "Epoch 51: Train Loss = 0.17241849201753973, Recall = 0.9733673841663626, Aging Rate = 0.575265584285428, Precision = 0.929616724738676, f1 = 0.950989128497594\n",
      "Epoch 52: Train Loss = 0.18006954723541616, Recall = 0.9682597592119664, Aging Rate = 0.5808779314491882, Precision = 0.9158040027605245, f1 = 0.9413016492285867\n",
      "Epoch 53: Train Loss = 0.17415838165473402, Recall = 0.9719080627508209, Aging Rate = 0.5784726398075767, Precision = 0.9230769230769231, f1 = 0.9468633374800072\n",
      "Epoch 54: Train Loss = 0.17728999038453713, Recall = 0.9733673841663626, Aging Rate = 0.5802766085387854, Precision = 0.9215889464594128, f1 = 0.9467707594038326\n",
      "Epoch 55: Train Loss = 0.17259530171133708, Recall = 0.9751915359357899, Aging Rate = 0.5796752856283824, Precision = 0.9242738589211619, f1 = 0.9490502396591515\n",
      "Test Loss = 0.16382034332617462, Recall = 0.9897847500912076, Aging Rate = 0.6007215874924835, precision = 0.9052385719052386\n",
      "\n",
      "Epoch 56: Train Loss = 0.17663953373106717, Recall = 0.9722728931047063, Aging Rate = 0.5784726398075767, Precision = 0.9234234234234234, f1 = 0.9472187666607428\n",
      "Epoch 57: Train Loss = 0.17582642220111522, Recall = 0.9708135716891645, Aging Rate = 0.5778713168971737, Precision = 0.922996878251821, f1 = 0.9463015647226172\n",
      "Epoch 58: Train Loss = 0.17400448507537677, Recall = 0.973732214520248, Aging Rate = 0.5778713168971737, Precision = 0.9257717655220257, f1 = 0.9491465149359887\n",
      "Epoch 59: Train Loss = 0.17606490486058618, Recall = 0.974461875228019, Aging Rate = 0.5804770495089197, Precision = 0.9223066298342542, f1 = 0.9476671988646442\n",
      "Epoch 60: Train Loss = 0.17267229685051738, Recall = 0.9715432323969354, Aging Rate = 0.576668671076368, Precision = 0.9256169621133125, f1 = 0.9480242079031683\n",
      "Test Loss = 0.16267314137199115, Recall = 0.9708135716891645, Aging Rate = 0.5536179595109241, precision = 0.9634322954380884\n",
      "Model in epoch 60 is saved.\n",
      "\n",
      "Epoch 61: Train Loss = 0.17549301734529055, Recall = 0.9726377234585918, Aging Rate = 0.5784726398075767, Precision = 0.9237699237699237, f1 = 0.9475741958414785\n",
      "Epoch 62: Train Loss = 0.176283228636911, Recall = 0.9730025538124772, Aging Rate = 0.5796752856283824, Precision = 0.9221991701244814, f1 = 0.9469199360908931\n",
      "Epoch 63: Train Loss = 0.17784422712344927, Recall = 0.9704487413352791, Aging Rate = 0.5822810182401282, Precision = 0.9156626506024096, f1 = 0.9422600070846617\n",
      "Epoch 64: Train Loss = 0.1725538629948149, Recall = 0.9762860269974462, Aging Rate = 0.5844858689116055, Precision = 0.9176954732510288, f1 = 0.9460844970832597\n",
      "Epoch 65: Train Loss = 0.17865049928175852, Recall = 0.9700839109813937, Aging Rate = 0.576668671076368, Precision = 0.924226624956552, f1 = 0.9466002135991457\n",
      "Test Loss = 0.17891177226968316, Recall = 0.9854067858445823, Aging Rate = 0.6033273201042293, precision = 0.8973421926910299\n",
      "\n",
      "Epoch 66: Train Loss = 0.1754131681439059, Recall = 0.9726377234585918, Aging Rate = 0.578071757867308, Precision = 0.9244105409153953, f1 = 0.9479111111111111\n",
      "Epoch 67: Train Loss = 0.17614552722136848, Recall = 0.9715432323969354, Aging Rate = 0.5776708759270395, Precision = 0.9240111034004164, f1 = 0.9471812199893295\n",
      "Epoch 68: Train Loss = 0.1813793594298011, Recall = 0.9671652681503101, Aging Rate = 0.5808779314491882, Precision = 0.9147688060731539, f1 = 0.9402376307856003\n",
      "Epoch 69: Train Loss = 0.17628445377579718, Recall = 0.9730025538124772, Aging Rate = 0.578673080777711, Precision = 0.9237963283685486, f1 = 0.9477611940298507\n",
      "Epoch 70: Train Loss = 0.17663803696035024, Recall = 0.974461875228019, Aging Rate = 0.5824814592102626, Precision = 0.9191328286304198, f1 = 0.9459890207189657\n",
      "Test Loss = 0.16593274926794008, Recall = 0.9850419554906968, Aging Rate = 0.5874924834636199, precision = 0.9211873080859775\n",
      "\n",
      "Epoch 71: Train Loss = 0.17292771777401325, Recall = 0.9740970448741335, Aging Rate = 0.5764682301062337, Precision = 0.9283727399165508, f1 = 0.9506854192629517\n",
      "Epoch 72: Train Loss = 0.1861039445888401, Recall = 0.9686245895658518, Aging Rate = 0.5810783724193225, Precision = 0.9158330458778889, f1 = 0.9414893617021277\n",
      "Epoch 73: Train Loss = 0.1736523366853741, Recall = 0.9766508573513316, Aging Rate = 0.582080577269994, Precision = 0.921831955922865, f1 = 0.9484499557130204\n",
      "Epoch 74: Train Loss = 0.17964407783408612, Recall = 0.9682597592119664, Aging Rate = 0.5772699939867709, Precision = 0.9215277777777777, f1 = 0.9443159580145881\n",
      "Epoch 75: Train Loss = 0.18082376557412952, Recall = 0.9697190806275082, Aging Rate = 0.578673080777711, Precision = 0.9206789054381711, f1 = 0.9445628997867803\n",
      "Test Loss = 0.1876823544191631, Recall = 0.9376140094855892, Aging Rate = 0.5323712166766887, precision = 0.9676204819277109\n",
      "\n",
      "Epoch 76: Train Loss = 0.17929600255060205, Recall = 0.9671652681503101, Aging Rate = 0.5784726398075767, Precision = 0.9185724185724186, f1 = 0.9422427581304426\n",
      "Epoch 77: Train Loss = 0.17840233446660944, Recall = 0.9708135716891645, Aging Rate = 0.576668671076368, Precision = 0.9249217935349322, f1 = 0.947312210751157\n",
      "Epoch 78: Train Loss = 0.17078777603501905, Recall = 0.9751915359357899, Aging Rate = 0.5804770495089197, Precision = 0.9229972375690608, f1 = 0.9483767961681747\n",
      "Epoch 79: Train Loss = 0.1734034516429538, Recall = 0.9719080627508209, Aging Rate = 0.5782721988374424, Precision = 0.9233968804159446, f1 = 0.9470316388197654\n",
      "Epoch 80: Train Loss = 0.17184846744159343, Recall = 0.973732214520248, Aging Rate = 0.578673080777711, Precision = 0.9244890890197437, f1 = 0.9484719260838664\n",
      "Test Loss = 0.16645976361339043, Recall = 0.9799343305363006, Aging Rate = 0.5842854279414712, precision = 0.9214408233276158\n",
      "\n",
      "Epoch 81: Train Loss = 0.17903207403776233, Recall = 0.9719080627508209, Aging Rate = 0.5758669071958308, Precision = 0.9272537417333797, f1 = 0.9490559315995725\n",
      "Epoch 82: Train Loss = 0.17787709569651466, Recall = 0.973732214520248, Aging Rate = 0.5810783724193225, Precision = 0.9206622973439117, f1 = 0.9464539007092199\n",
      "Epoch 83: Train Loss = 0.17292323787684527, Recall = 0.9759211966435607, Aging Rate = 0.5802766085387854, Precision = 0.924006908462867, f1 = 0.9492547906316536\n",
      "Epoch 84: Train Loss = 0.1774049493336539, Recall = 0.9708135716891645, Aging Rate = 0.575265584285428, Precision = 0.927177700348432, f1 = 0.9484940295847443\n",
      "Epoch 85: Train Loss = 0.1811087744332526, Recall = 0.964611455673112, Aging Rate = 0.5782721988374424, Precision = 0.9164644714038128, f1 = 0.9399217916814788\n",
      "Test Loss = 0.1610669067846699, Recall = 0.9850419554906968, Aging Rate = 0.5921026257767088, precision = 0.9140148950575491\n",
      "\n",
      "Epoch 86: Train Loss = 0.17403923496559165, Recall = 0.97117840204305, Aging Rate = 0.5764682301062337, Precision = 0.9255910987482615, f1 = 0.9478369236247107\n",
      "Epoch 87: Train Loss = 0.17135436281540944, Recall = 0.9781101787668735, Aging Rate = 0.5806774904790539, Precision = 0.9254401104590956, f1 = 0.9510464703795671\n",
      "Epoch 88: Train Loss = 0.17575525356679528, Recall = 0.9730025538124772, Aging Rate = 0.5814792543595911, Precision = 0.9193381592554292, f1 = 0.945409429280397\n",
      "Epoch 89: Train Loss = 0.17474275991682015, Recall = 0.9722728931047063, Aging Rate = 0.5784726398075767, Precision = 0.9234234234234234, f1 = 0.9472187666607428\n",
      "Epoch 90: Train Loss = 0.17123376202203391, Recall = 0.9730025538124772, Aging Rate = 0.5772699939867709, Precision = 0.9260416666666667, f1 = 0.9489414694894147\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss = 0.15573476179075232, Recall = 0.9843122947829259, Aging Rate = 0.5812788133894567, precision = 0.9303448275862068\n",
      "\n",
      "Epoch 91: Train Loss = 0.1783309990895203, Recall = 0.9689894199197373, Aging Rate = 0.576668671076368, Precision = 0.9231838720889816, f1 = 0.9455322178711285\n",
      "Epoch 92: Train Loss = 0.18063937586960513, Recall = 0.9697190806275082, Aging Rate = 0.5772699939867709, Precision = 0.9229166666666667, f1 = 0.9457391923145348\n",
      "Epoch 93: Train Loss = 0.17774312928435462, Recall = 0.9700839109813937, Aging Rate = 0.5806774904790539, Precision = 0.9178460476354849, f1 = 0.943242284498049\n",
      "Epoch 94: Train Loss = 0.17687928767404043, Recall = 0.9719080627508209, Aging Rate = 0.5754660252555622, Precision = 0.9278996865203761, f1 = 0.9493941553813257\n",
      "Epoch 95: Train Loss = 0.17772500976803643, Recall = 0.97117840204305, Aging Rate = 0.580076167568651, Precision = 0.9198341395991707, f1 = 0.9448092280390417\n",
      "Test Loss = 0.15959898466205139, Recall = 0.9854067858445823, Aging Rate = 0.5842854279414712, precision = 0.9265866209262436\n",
      "\n",
      "Epoch 96: Train Loss = 0.17266023350779866, Recall = 0.9726377234585918, Aging Rate = 0.5778713168971737, Precision = 0.9247311827956989, f1 = 0.9480796586059744\n",
      "Epoch 97: Train Loss = 0.18114614933520096, Recall = 0.9660707770886537, Aging Rate = 0.5790739627179795, Precision = 0.9165801315334026, f1 = 0.9406749555950267\n",
      "Epoch 98: Train Loss = 0.17520843348884946, Recall = 0.9730025538124772, Aging Rate = 0.5772699939867709, Precision = 0.9260416666666667, f1 = 0.9489414694894147\n",
      "Epoch 99: Train Loss = 0.17662494637237855, Recall = 0.9697190806275082, Aging Rate = 0.5776708759270395, Precision = 0.9222761970853574, f1 = 0.9454028098879601\n",
      "Epoch 100: Train Loss = 0.17597563808500516, Recall = 0.9704487413352791, Aging Rate = 0.5796752856283824, Precision = 0.9197786998616874, f1 = 0.9444345819279247\n",
      "Test Loss = 0.17929215033311455, Recall = 0.9408974826705582, Aging Rate = 0.532571657646823, precision = 0.9706435829883328\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e2e226a197347988a8c93b1273e30ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss = 0.39459456381828373, Recall = 0.9175483400218898, Aging Rate = 0.6600521146522349, Precision = 0.7637412693592469, f1 = 0.8336095459065297\n",
      "Epoch 2: Train Loss = 0.30246702156173944, Recall = 0.9339657059467348, Aging Rate = 0.6155542192824214, Precision = 0.8336046890263757, f1 = 0.88093599449415\n",
      "Epoch 3: Train Loss = 0.27500678981490256, Recall = 0.9401678219627873, Aging Rate = 0.605131288835438, Precision = 0.8535939052666446, f1 = 0.8947916666666668\n",
      "Epoch 4: Train Loss = 0.2475055679634115, Recall = 0.9449106165632981, Aging Rate = 0.5890960112246943, Precision = 0.8812521265736645, f1 = 0.9119718309859155\n",
      "Epoch 5: Train Loss = 0.24503808217539436, Recall = 0.9500182415176943, Aging Rate = 0.5995189416716777, Precision = 0.8706118355065195, f1 = 0.9085833914863922\n",
      "Test Loss = 0.21040245678554342, Recall = 0.9387085005472455, Aging Rate = 0.5548206053317298, precision = 0.9295520231213873\n",
      "Model in epoch 5 is saved.\n",
      "\n",
      "Epoch 6: Train Loss = 0.2106668234265718, Recall = 0.9587741700109449, Aging Rate = 0.5868911605532171, Precision = 0.8975409836065574, f1 = 0.9271476450873171\n",
      "Epoch 7: Train Loss = 0.20171693739204805, Recall = 0.9602334914264867, Aging Rate = 0.5836841050310684, Precision = 0.9038461538461539, f1 = 0.9311869803644084\n",
      "Epoch 8: Train Loss = 0.2012235328844827, Recall = 0.9584093396570594, Aging Rate = 0.5830827821206654, Precision = 0.9030594706084565, f1 = 0.9299115044247787\n",
      "Epoch 9: Train Loss = 0.18946010412565809, Recall = 0.9638817949653411, Aging Rate = 0.5796752856283824, Precision = 0.9135546334716459, f1 = 0.9380436712231491\n",
      "Epoch 10: Train Loss = 0.1888024061410502, Recall = 0.9627873039036848, Aging Rate = 0.5778713168971737, Precision = 0.9153659382587582, f1 = 0.9384779516358462\n",
      "Test Loss = 0.18092400666216518, Recall = 0.9671652681503101, Aging Rate = 0.5798757265985167, precision = 0.9163498098859315\n",
      "Model in epoch 10 is saved.\n",
      "\n",
      "Epoch 11: Train Loss = 0.1841783957273264, Recall = 0.9664356074425392, Aging Rate = 0.5816796953297254, Precision = 0.9128187456926258, f1 = 0.9388623072833598\n",
      "Epoch 12: Train Loss = 0.1897404120372947, Recall = 0.9649762860269975, Aging Rate = 0.5812788133894567, Precision = 0.9120689655172414, f1 = 0.9377769898954086\n",
      "Epoch 13: Train Loss = 0.19065969611640732, Recall = 0.9627873039036848, Aging Rate = 0.5818801362998597, Precision = 0.9090595935239407, f1 = 0.935152374202693\n",
      "Epoch 14: Train Loss = 0.19363731586710917, Recall = 0.9605983217803721, Aging Rate = 0.5748647023451593, Precision = 0.9180613668061367, f1 = 0.938848279550722\n",
      "Epoch 15: Train Loss = 0.17858296972067567, Recall = 0.9719080627508209, Aging Rate = 0.5828823411505312, Precision = 0.9160935350756534, f1 = 0.9431757833244823\n",
      "Test Loss = 0.1646500122549539, Recall = 0.97117840204305, Aging Rate = 0.5762677891360994, precision = 0.9259130434782609\n",
      "Model in epoch 15 is saved.\n",
      "\n",
      "Epoch 16: Train Loss = 0.18542634869749644, Recall = 0.9689894199197373, Aging Rate = 0.5824814592102626, Precision = 0.9139710942876806, f1 = 0.9406764653798476\n",
      "Epoch 17: Train Loss = 0.19111858243202967, Recall = 0.9689894199197373, Aging Rate = 0.5852876327921427, Precision = 0.9095890410958904, f1 = 0.9383501148207031\n",
      "Epoch 18: Train Loss = 0.19046472441005574, Recall = 0.9664356074425392, Aging Rate = 0.5838845460012027, Precision = 0.9093717816683831, f1 = 0.9370357269189954\n",
      "Epoch 19: Train Loss = 0.18365305433963386, Recall = 0.97117840204305, Aging Rate = 0.5828823411505312, Precision = 0.9154057771664375, f1 = 0.9424676933970615\n",
      "Epoch 20: Train Loss = 0.18746406993124762, Recall = 0.9657059467347683, Aging Rate = 0.5814792543595911, Precision = 0.9124439848328163, f1 = 0.9383197447713577\n",
      "Test Loss = 0.20255889358119558, Recall = 0.9281284202845677, Aging Rate = 0.5245540188414511, precision = 0.9721054642720672\n",
      "Model in epoch 20 is saved.\n",
      "\n",
      "Epoch 21: Train Loss = 0.1822192480895533, Recall = 0.9660707770886537, Aging Rate = 0.5796752856283824, Precision = 0.9156293222683264, f1 = 0.9401739747914077\n",
      "Epoch 22: Train Loss = 0.18286351807897855, Recall = 0.9675300985041956, Aging Rate = 0.578071757867308, Precision = 0.9195561719833565, f1 = 0.9429333333333335\n",
      "Epoch 23: Train Loss = 0.18063508381249074, Recall = 0.97117840204305, Aging Rate = 0.578673080777711, Precision = 0.9220644267405611, f1 = 0.9459843638948117\n",
      "Epoch 24: Train Loss = 0.1797748600930053, Recall = 0.9704487413352791, Aging Rate = 0.5802766085387854, Precision = 0.918825561312608, f1 = 0.943931866572037\n",
      "Epoch 25: Train Loss = 0.18608366417715178, Recall = 0.9649762860269975, Aging Rate = 0.578673080777711, Precision = 0.9161759612054036, f1 = 0.9399431414356789\n",
      "Test Loss = 0.16441891557301996, Recall = 0.9883254286756659, Aging Rate = 0.5961114451793946, precision = 0.9108944182918628\n",
      "\n",
      "Epoch 26: Train Loss = 0.18137608184188897, Recall = 0.9693542502736228, Aging Rate = 0.5816796953297254, Precision = 0.9155754651964163, f1 = 0.9416976785397838\n",
      "Epoch 27: Train Loss = 0.18730510411663462, Recall = 0.9675300985041956, Aging Rate = 0.5824814592102626, Precision = 0.9125946317962835, f1 = 0.9392597839560829\n",
      "Epoch 28: Train Loss = 0.1775949521434166, Recall = 0.97117840204305, Aging Rate = 0.5808779314491882, Precision = 0.9185645272601795, f1 = 0.9441390317432169\n",
      "Epoch 29: Train Loss = 0.18022882781577843, Recall = 0.9657059467347683, Aging Rate = 0.5788735217478452, Precision = 0.9165512465373962, f1 = 0.9404867649671345\n",
      "Epoch 30: Train Loss = 0.18902422100944732, Recall = 0.9642466253192266, Aging Rate = 0.5802766085387854, Precision = 0.9129533678756476, f1 = 0.9378992193044713\n",
      "Test Loss = 0.16605868048504469, Recall = 0.964611455673112, Aging Rate = 0.5558228101824013, precision = 0.9534799855751893\n",
      "\n",
      "Epoch 31: Train Loss = 0.18292994468830753, Recall = 0.9642466253192266, Aging Rate = 0.5782721988374424, Precision = 0.9161178509532062, f1 = 0.9395662993245645\n",
      "Epoch 32: Train Loss = 0.17484042999751107, Recall = 0.97117840204305, Aging Rate = 0.5772699939867709, Precision = 0.9243055555555556, f1 = 0.9471624266144815\n",
      "Epoch 33: Train Loss = 0.1782793109994968, Recall = 0.9693542502736228, Aging Rate = 0.5790739627179795, Precision = 0.9196953963309104, f1 = 0.9438721136767318\n",
      "Epoch 34: Train Loss = 0.18175518686259096, Recall = 0.9686245895658518, Aging Rate = 0.5760673481659652, Precision = 0.9237995824634656, f1 = 0.9456812110418522\n",
      "Epoch 35: Train Loss = 0.18204537301353615, Recall = 0.9682597592119664, Aging Rate = 0.580076167568651, Precision = 0.917069799585349, f1 = 0.9419698314108251\n",
      "Test Loss = 0.1695287259858222, Recall = 0.9653411163808829, Aging Rate = 0.5552214872719984, precision = 0.9552346570397112\n",
      "Model in epoch 35 is saved.\n",
      "\n",
      "Epoch 36: Train Loss = 0.1814268237216173, Recall = 0.9635169646114556, Aging Rate = 0.5736620565243535, Precision = 0.9227812718378756, f1 = 0.9427092628948777\n",
      "Epoch 37: Train Loss = 0.18596978986471158, Recall = 0.9675300985041956, Aging Rate = 0.5806774904790539, Precision = 0.9154297549188816, f1 = 0.9407591344448386\n",
      "Epoch 38: Train Loss = 0.18331810406702845, Recall = 0.9697190806275082, Aging Rate = 0.5794748446582482, Precision = 0.9194050501556554, f1 = 0.9438920454545454\n",
      "Epoch 39: Train Loss = 0.17683612226866413, Recall = 0.9700839109813937, Aging Rate = 0.5768691120465023, Precision = 0.923905489923558, f1 = 0.9464317494216052\n",
      "Epoch 40: Train Loss = 0.1786605302079404, Recall = 0.9693542502736228, Aging Rate = 0.5772699939867709, Precision = 0.9225694444444444, f1 = 0.9453833837395481\n",
      "Test Loss = 0.16273184797763346, Recall = 0.9795695001824152, Aging Rate = 0.5792744036881139, precision = 0.9290657439446367\n",
      "\n",
      "Epoch 41: Train Loss = 0.18340044119334648, Recall = 0.9689894199197373, Aging Rate = 0.5816796953297254, Precision = 0.9152308752584425, f1 = 0.9413432571327309\n",
      "Epoch 42: Train Loss = 0.17636818485213177, Recall = 0.97117840204305, Aging Rate = 0.5828823411505312, Precision = 0.9154057771664375, f1 = 0.9424676933970615\n",
      "Epoch 43: Train Loss = 0.17820481392694013, Recall = 0.9733673841663626, Aging Rate = 0.578071757867308, Precision = 0.9251040221914009, f1 = 0.9486222222222221\n",
      "Epoch 44: Train Loss = 0.1783640643361098, Recall = 0.9689894199197373, Aging Rate = 0.5788735217478452, Precision = 0.9196675900277008, f1 = 0.9436844910286019\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45: Train Loss = 0.1803792412539335, Recall = 0.967894928858081, Aging Rate = 0.580076167568651, Precision = 0.9167242570836213, f1 = 0.9416149068322982\n",
      "Test Loss = 0.1679072048620366, Recall = 0.9828529733673842, Aging Rate = 0.5989176187612748, precision = 0.9016064257028112\n",
      "\n",
      "Epoch 46: Train Loss = 0.17932208055340232, Recall = 0.967894928858081, Aging Rate = 0.5762677891360994, Precision = 0.9227826086956522, f1 = 0.9448005698005698\n",
      "Epoch 47: Train Loss = 0.17938719332027014, Recall = 0.9740970448741335, Aging Rate = 0.5806774904790539, Precision = 0.9216430790472903, f1 = 0.9471443774388081\n",
      "Epoch 48: Train Loss = 0.17751163823239238, Recall = 0.9689894199197373, Aging Rate = 0.5792744036881139, Precision = 0.9190311418685121, f1 = 0.9433493162848519\n",
      "Epoch 49: Train Loss = 0.18495444028129987, Recall = 0.967894928858081, Aging Rate = 0.5822810182401282, Precision = 0.9132530120481928, f1 = 0.9397803754870705\n",
      "Epoch 50: Train Loss = 0.17756946160597847, Recall = 0.9722728931047063, Aging Rate = 0.5774704349569052, Precision = 0.9250260326275599, f1 = 0.9480611881892566\n",
      "Test Loss = 0.17705264598830092, Recall = 0.9912440715067493, Aging Rate = 0.6167568651032271, precision = 0.8830029249268768\n",
      "\n",
      "Epoch 51: Train Loss = 0.1802177956041436, Recall = 0.9675300985041956, Aging Rate = 0.5796752856283824, Precision = 0.91701244813278, f1 = 0.9415941771702468\n",
      "Epoch 52: Train Loss = 0.18203429538158503, Recall = 0.9686245895658518, Aging Rate = 0.5818801362998597, Precision = 0.9145711333103685, f1 = 0.940822111977321\n",
      "Epoch 53: Train Loss = 0.18004517613240534, Recall = 0.9693542502736228, Aging Rate = 0.5808779314491882, Precision = 0.916839199447895, f1 = 0.9423656676715729\n",
      "Epoch 54: Train Loss = 0.1829703134617315, Recall = 0.9682597592119664, Aging Rate = 0.5788735217478452, Precision = 0.9189750692520776, f1 = 0.9429738852371647\n",
      "Epoch 55: Train Loss = 0.17865194326072878, Recall = 0.9653411163808829, Aging Rate = 0.5784726398075767, Precision = 0.9168399168399168, f1 = 0.940465612226764\n",
      "Test Loss = 0.19610627554394386, Recall = 0.9310470631156512, Aging Rate = 0.5263579875726598, precision = 0.9718202589489718\n",
      "\n",
      "Epoch 56: Train Loss = 0.17998038668698457, Recall = 0.9689894199197373, Aging Rate = 0.5792744036881139, Precision = 0.9190311418685121, f1 = 0.9433493162848519\n",
      "Epoch 57: Train Loss = 0.17924514445137418, Recall = 0.9704487413352791, Aging Rate = 0.5844858689116055, Precision = 0.9122085048010974, f1 = 0.9404277885805197\n",
      "Epoch 58: Train Loss = 0.1823785244152144, Recall = 0.9715432323969354, Aging Rate = 0.5814792543595911, Precision = 0.9179593243709065, f1 = 0.9439914923785891\n",
      "Epoch 59: Train Loss = 0.1769261831575607, Recall = 0.9708135716891645, Aging Rate = 0.5784726398075767, Precision = 0.922037422037422, f1 = 0.9457970499377998\n",
      "Epoch 60: Train Loss = 0.17235670101788364, Recall = 0.9730025538124772, Aging Rate = 0.578673080777711, Precision = 0.9237963283685486, f1 = 0.9477611940298507\n",
      "Test Loss = 0.17147866635767964, Recall = 0.9587741700109449, Aging Rate = 0.5540188414511926, precision = 0.9507959479015919\n",
      "\n",
      "Epoch 61: Train Loss = 0.18092785560312957, Recall = 0.9697190806275082, Aging Rate = 0.5814792543595911, Precision = 0.9162357807652534, f1 = 0.9422190712513293\n",
      "Epoch 62: Train Loss = 0.18457184116678838, Recall = 0.9719080627508209, Aging Rate = 0.5824814592102626, Precision = 0.9167240192704749, f1 = 0.9435098282273773\n",
      "Epoch 63: Train Loss = 0.17932660848433948, Recall = 0.9715432323969354, Aging Rate = 0.5810783724193225, Precision = 0.9185926181441877, f1 = 0.9443262411347517\n",
      "Epoch 64: Train Loss = 0.17576470952887982, Recall = 0.9730025538124772, Aging Rate = 0.5832832230907997, Precision = 0.9164948453608247, f1 = 0.9439037338524155\n",
      "Epoch 65: Train Loss = 0.17702195255018996, Recall = 0.9733673841663626, Aging Rate = 0.5804770495089197, Precision = 0.9212707182320442, f1 = 0.9466028029093491\n",
      "Test Loss = 0.15890960516899041, Recall = 0.9773805180591025, Aging Rate = 0.5770695530166366, precision = 0.930531434525877\n",
      "\n",
      "Epoch 66: Train Loss = 0.1787640171147559, Recall = 0.973732214520248, Aging Rate = 0.5812788133894567, Precision = 0.920344827586207, f1 = 0.9462861194823613\n",
      "Epoch 67: Train Loss = 0.18239044464824433, Recall = 0.9700839109813937, Aging Rate = 0.5810783724193225, Precision = 0.9172128320110383, f1 = 0.9429078014184397\n",
      "Epoch 68: Train Loss = 0.1746756766393921, Recall = 0.97117840204305, Aging Rate = 0.5788735217478452, Precision = 0.9217451523545707, f1 = 0.9458163084029135\n",
      "Epoch 69: Train Loss = 0.17753300956648466, Recall = 0.9682597592119664, Aging Rate = 0.5776708759270395, Precision = 0.9208882720333103, f1 = 0.9439800818068647\n",
      "Epoch 70: Train Loss = 0.1804768595165756, Recall = 0.9715432323969354, Aging Rate = 0.5804770495089197, Precision = 0.9195441988950276, f1 = 0.9448288096505233\n",
      "Test Loss = 0.17145917122434293, Recall = 0.9638817949653411, Aging Rate = 0.5514131088394468, precision = 0.96037804434751\n",
      "Model in epoch 70 is saved.\n",
      "\n",
      "Epoch 71: Train Loss = 0.17775361089823263, Recall = 0.9730025538124772, Aging Rate = 0.5808779314491882, Precision = 0.9202898550724637, f1 = 0.9459123958148609\n",
      "Epoch 72: Train Loss = 0.1774604030582202, Recall = 0.9668004377964247, Aging Rate = 0.5740629384646222, Precision = 0.9252793296089385, f1 = 0.9455842997323819\n",
      "Epoch 73: Train Loss = 0.1834441386260306, Recall = 0.9686245895658518, Aging Rate = 0.5846863098817399, Precision = 0.9101816935207405, f1 = 0.9384941675503712\n",
      "Epoch 74: Train Loss = 0.17592635923706473, Recall = 0.9726377234585918, Aging Rate = 0.5762677891360994, Precision = 0.927304347826087, f1 = 0.9494301994301995\n",
      "Epoch 75: Train Loss = 0.180251859336058, Recall = 0.9708135716891645, Aging Rate = 0.5796752856283824, Precision = 0.9201244813278008, f1 = 0.9447896325226345\n",
      "Test Loss = 0.18734613761356583, Recall = 0.9306822327617658, Aging Rate = 0.5259571056323913, precision = 0.9721798780487805\n",
      "\n",
      "Epoch 76: Train Loss = 0.17982640292582852, Recall = 0.9700839109813937, Aging Rate = 0.5802766085387854, Precision = 0.9184801381692573, f1 = 0.9435770049680624\n",
      "Epoch 77: Train Loss = 0.1717958528780703, Recall = 0.9719080627508209, Aging Rate = 0.5778713168971737, Precision = 0.9240374609781478, f1 = 0.9473684210526316\n",
      "Epoch 78: Train Loss = 0.17399717479986043, Recall = 0.9733673841663626, Aging Rate = 0.5810783724193225, Precision = 0.9203173508106244, f1 = 0.9460992907801419\n",
      "Epoch 79: Train Loss = 0.1721678560871857, Recall = 0.9719080627508209, Aging Rate = 0.5772699939867709, Precision = 0.925, f1 = 0.9478740437644548\n",
      "Epoch 80: Train Loss = 0.17671984524926626, Recall = 0.9689894199197373, Aging Rate = 0.5770695530166366, Precision = 0.922542549496353, f1 = 0.9451957295373665\n",
      "Test Loss = 0.1674385147979776, Recall = 0.9788398394746443, Aging Rate = 0.5730607336139507, precision = 0.9384400139909059\n",
      "\n",
      "Epoch 81: Train Loss = 0.17903305380180476, Recall = 0.9668004377964247, Aging Rate = 0.5790739627179795, Precision = 0.9172724125995154, f1 = 0.9413854351687388\n",
      "Epoch 82: Train Loss = 0.17970748010953363, Recall = 0.967894928858081, Aging Rate = 0.578673080777711, Precision = 0.9189470038101836, f1 = 0.9427860696517413\n",
      "Epoch 83: Train Loss = 0.18173376766049712, Recall = 0.97117840204305, Aging Rate = 0.5818801362998597, Precision = 0.9169824319669307, f1 = 0.9433026222537207\n",
      "Epoch 84: Train Loss = 0.18493357689341458, Recall = 0.9616928128420285, Aging Rate = 0.576668671076368, Precision = 0.916232186305179, f1 = 0.9384122463510146\n",
      "Epoch 85: Train Loss = 0.17498615360207442, Recall = 0.9722728931047063, Aging Rate = 0.5798757265985167, Precision = 0.9211890770826132, f1 = 0.9460418885339014\n",
      "Test Loss = 0.16164218535951824, Recall = 0.9850419554906968, Aging Rate = 0.5892964521948286, precision = 0.9183673469387755\n",
      "\n",
      "Epoch 86: Train Loss = 0.1757921380774725, Recall = 0.9740970448741335, Aging Rate = 0.5830827821206654, Precision = 0.9178411825369542, f1 = 0.9451327433628317\n",
      "Epoch 87: Train Loss = 0.1719242027232871, Recall = 0.9748267055819044, Aging Rate = 0.5772699939867709, Precision = 0.9277777777777778, f1 = 0.9507205123643481\n",
      "Epoch 88: Train Loss = 0.17829389505776788, Recall = 0.9700839109813937, Aging Rate = 0.5802766085387854, Precision = 0.9184801381692573, f1 = 0.9435770049680624\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 89: Train Loss = 0.1805893953588688, Recall = 0.9686245895658518, Aging Rate = 0.5794748446582482, Precision = 0.9183673469387755, f1 = 0.9428267045454546\n",
      "Epoch 90: Train Loss = 0.17576588772418003, Recall = 0.9722728931047063, Aging Rate = 0.580076167568651, Precision = 0.9208707671043538, f1 = 0.9458740017746229\n",
      "Test Loss = 0.1703508126667588, Recall = 0.9642466253192266, Aging Rate = 0.5548206053317298, precision = 0.9548410404624278\n",
      "\n",
      "Epoch 91: Train Loss = 0.17532824706543804, Recall = 0.9697190806275082, Aging Rate = 0.5772699939867709, Precision = 0.9229166666666667, f1 = 0.9457391923145348\n",
      "Epoch 92: Train Loss = 0.17848028258567442, Recall = 0.9733673841663626, Aging Rate = 0.5808779314491882, Precision = 0.9206349206349206, f1 = 0.9462670686291894\n",
      "Epoch 93: Train Loss = 0.17862176506857186, Recall = 0.9715432323969354, Aging Rate = 0.5796752856283824, Precision = 0.9208160442600276, f1 = 0.9454997337120539\n",
      "Epoch 94: Train Loss = 0.18110202306179274, Recall = 0.9686245895658518, Aging Rate = 0.5806774904790539, Precision = 0.916465308940283, f1 = 0.9418233416105002\n",
      "Epoch 95: Train Loss = 0.17471840371945072, Recall = 0.9704487413352791, Aging Rate = 0.5782721988374424, Precision = 0.9220103986135182, f1 = 0.9456096693921081\n",
      "Test Loss = 0.15789696680541315, Recall = 0.973732214520248, Aging Rate = 0.5660452996592503, precision = 0.9451133144475921\n",
      "\n",
      "Epoch 96: Train Loss = 0.18082087152908408, Recall = 0.9686245895658518, Aging Rate = 0.5806774904790539, Precision = 0.916465308940283, f1 = 0.9418233416105002\n",
      "Epoch 97: Train Loss = 0.1757647084685647, Recall = 0.9722728931047063, Aging Rate = 0.5778713168971737, Precision = 0.9243843218869233, f1 = 0.9477240398293031\n",
      "Epoch 98: Train Loss = 0.1691579872891262, Recall = 0.9770156877052171, Aging Rate = 0.576668671076368, Precision = 0.9308307264511644, f1 = 0.9533641865432539\n",
      "Epoch 99: Train Loss = 0.1785715847825163, Recall = 0.9682597592119664, Aging Rate = 0.578071757867308, Precision = 0.920249653259362, f1 = 0.9436444444444445\n",
      "Epoch 100: Train Loss = 0.18364090119867674, Recall = 0.9689894199197373, Aging Rate = 0.5842854279414712, Precision = 0.9111492281303603, f1 = 0.9391796322489392\n",
      "Test Loss = 0.16971569073883605, Recall = 0.977745348412988, Aging Rate = 0.578071757867308, precision = 0.9292649098474342\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "80c2dbbdd0024d33877a1134b3ced5f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss = 0.4164411355281168, Recall = 0.9025902955125866, Aging Rate = 0.6592503507716977, Precision = 0.7522043174217087, f1 = 0.8205638474295192\n",
      "Epoch 2: Train Loss = 0.3248399730243863, Recall = 0.9186428310835462, Aging Rate = 0.6123471637602727, Precision = 0.8242225859247135, f1 = 0.8688750862663907\n",
      "Epoch 3: Train Loss = 0.2794397958720655, Recall = 0.9376140094855892, Aging Rate = 0.6049308478653037, Precision = 0.851557322730285, f1 = 0.8925160618162876\n",
      "Epoch 4: Train Loss = 0.26757012181003437, Recall = 0.9408974826705582, Aging Rate = 0.5979154139106033, Precision = 0.8645658732819309, f1 = 0.9011180992313067\n",
      "Epoch 5: Train Loss = 0.2617167488806805, Recall = 0.9401678219627873, Aging Rate = 0.5953096812988575, Precision = 0.8676767676767677, f1 = 0.9024689196287866\n",
      "Test Loss = 0.2186911567242166, Recall = 0.9890550893834367, Aging Rate = 0.6319903788334336, precision = 0.8598160482080558\n",
      "Model in epoch 5 is saved.\n",
      "\n",
      "Epoch 6: Train Loss = 0.21891814978346363, Recall = 0.9565851878876322, Aging Rate = 0.5882942473441571, Precision = 0.8933560477001704, f1 = 0.9238900634249472\n",
      "Epoch 7: Train Loss = 0.19889120891985948, Recall = 0.967894928858081, Aging Rate = 0.5913008618961716, Precision = 0.8993220338983051, f1 = 0.932349323493235\n",
      "Epoch 8: Train Loss = 0.19679721216205415, Recall = 0.9649762860269975, Aging Rate = 0.5828823411505312, Precision = 0.9095598349381018, f1 = 0.9364489290139848\n",
      "Epoch 9: Train Loss = 0.1875753107464464, Recall = 0.9668004377964247, Aging Rate = 0.5784726398075767, Precision = 0.9182259182259183, f1 = 0.9418873289497067\n",
      "Epoch 10: Train Loss = 0.18575292898726192, Recall = 0.9682597592119664, Aging Rate = 0.5788735217478452, Precision = 0.9189750692520776, f1 = 0.9429738852371647\n",
      "Test Loss = 0.17519025454410786, Recall = 0.9850419554906968, Aging Rate = 0.5999198236119463, precision = 0.9021049114600735\n",
      "Model in epoch 10 is saved.\n",
      "\n",
      "Epoch 11: Train Loss = 0.18995475179298676, Recall = 0.964611455673112, Aging Rate = 0.582080577269994, Precision = 0.9104683195592287, f1 = 0.9367581930912311\n",
      "Epoch 12: Train Loss = 0.18583336995799213, Recall = 0.967894928858081, Aging Rate = 0.5792744036881139, Precision = 0.917993079584775, f1 = 0.9422837861836263\n",
      "Epoch 13: Train Loss = 0.18247786225214538, Recall = 0.9653411163808829, Aging Rate = 0.5764682301062337, Precision = 0.9200278164116829, f1 = 0.9421399323482286\n",
      "Epoch 14: Train Loss = 0.1851630142120255, Recall = 0.9635169646114556, Aging Rate = 0.5774704349569052, Precision = 0.9166955918083999, f1 = 0.9395233013162576\n",
      "Epoch 15: Train Loss = 0.1898850245600259, Recall = 0.9660707770886537, Aging Rate = 0.5818801362998597, Precision = 0.9121598346538065, f1 = 0.9383416017009214\n",
      "Test Loss = 0.16227100192186325, Recall = 0.9740970448741335, Aging Rate = 0.562437362196833, precision = 0.9515324305060584\n",
      "Model in epoch 15 is saved.\n",
      "\n",
      "Epoch 16: Train Loss = 0.18117503528844428, Recall = 0.9668004377964247, Aging Rate = 0.5784726398075767, Precision = 0.9182259182259183, f1 = 0.9418873289497067\n",
      "Epoch 17: Train Loss = 0.18662635370339295, Recall = 0.9660707770886537, Aging Rate = 0.5806774904790539, Precision = 0.9140490162236796, f1 = 0.9393401915572898\n",
      "Epoch 18: Train Loss = 0.17859468539651446, Recall = 0.9704487413352791, Aging Rate = 0.5788735217478452, Precision = 0.9210526315789473, f1 = 0.9451057026114763\n",
      "Epoch 19: Train Loss = 0.19058272709682103, Recall = 0.9649762860269975, Aging Rate = 0.5830827821206654, Precision = 0.9092471639738742, f1 = 0.9362831858407079\n",
      "Epoch 20: Train Loss = 0.17956789446620192, Recall = 0.9700839109813937, Aging Rate = 0.5798757265985167, Precision = 0.9191151054268925, f1 = 0.9439119630812922\n",
      "Test Loss = 0.1895628189557921, Recall = 0.9609631521342575, Aging Rate = 0.5522148727199839, precision = 0.9560798548094374\n",
      "\n",
      "Epoch 21: Train Loss = 0.17911094428602167, Recall = 0.9715432323969354, Aging Rate = 0.5802766085387854, Precision = 0.9198618307426597, f1 = 0.9449964513839603\n",
      "Epoch 22: Train Loss = 0.18119075314915953, Recall = 0.9708135716891645, Aging Rate = 0.5802766085387854, Precision = 0.9191709844559586, f1 = 0.9442867281760114\n",
      "Epoch 23: Train Loss = 0.18206071103950092, Recall = 0.97117840204305, Aging Rate = 0.5828823411505312, Precision = 0.9154057771664375, f1 = 0.9424676933970615\n",
      "Epoch 24: Train Loss = 0.18512695170244536, Recall = 0.967894928858081, Aging Rate = 0.5824814592102626, Precision = 0.9129387474191328, f1 = 0.9396139543120242\n",
      "Epoch 25: Train Loss = 0.18437394395837997, Recall = 0.9708135716891645, Aging Rate = 0.5812788133894567, Precision = 0.9175862068965517, f1 = 0.9434497429533771\n",
      "Test Loss = 0.1752478591866282, Recall = 0.9518423932871215, Aging Rate = 0.5385848867508519, precision = 0.9709713435057685\n",
      "Model in epoch 25 is saved.\n",
      "\n",
      "Epoch 26: Train Loss = 0.1785490848952865, Recall = 0.9719080627508209, Aging Rate = 0.5796752856283824, Precision = 0.921161825726141, f1 = 0.9458547843067637\n",
      "Epoch 27: Train Loss = 0.18438411389486326, Recall = 0.9693542502736228, Aging Rate = 0.5836841050310684, Precision = 0.9124313186813187, f1 = 0.9400318415000884\n",
      "Epoch 28: Train Loss = 0.17866051030985744, Recall = 0.9715432323969354, Aging Rate = 0.5812788133894567, Precision = 0.9182758620689655, f1 = 0.944158837085623\n",
      "Epoch 29: Train Loss = 0.1793773072196955, Recall = 0.9715432323969354, Aging Rate = 0.582080577269994, Precision = 0.9170110192837465, f1 = 0.9434898139946856\n",
      "Epoch 30: Train Loss = 0.1773334197217655, Recall = 0.9726377234585918, Aging Rate = 0.5796752856283824, Precision = 0.9218533886583679, f1 = 0.9465648854961832\n",
      "Test Loss = 0.1986205735613287, Recall = 0.9970813571689164, Aging Rate = 0.6502305071156544, precision = 0.8424784217016029\n",
      "\n",
      "Epoch 31: Train Loss = 0.18361402111078318, Recall = 0.9730025538124772, Aging Rate = 0.5824814592102626, Precision = 0.9177563661390227, f1 = 0.944572339295201\n",
      "Epoch 32: Train Loss = 0.18312665001737688, Recall = 0.9657059467347683, Aging Rate = 0.578673080777711, Precision = 0.9168687218565985, f1 = 0.9406538734896944\n",
      "Epoch 33: Train Loss = 0.18211623854258657, Recall = 0.9708135716891645, Aging Rate = 0.5806774904790539, Precision = 0.918536416983086, f1 = 0.9439517559418232\n",
      "Epoch 34: Train Loss = 0.18243344313612345, Recall = 0.9660707770886537, Aging Rate = 0.5810783724193225, Precision = 0.9134184201448775, f1 = 0.9390070921985816\n",
      "Epoch 35: Train Loss = 0.17928212768485777, Recall = 0.9740970448741335, Aging Rate = 0.5816796953297254, Precision = 0.9200551343900758, f1 = 0.9463051568314725\n",
      "Test Loss = 0.17301964138123574, Recall = 0.9894199197373221, Aging Rate = 0.6111445179394668, precision = 0.8894719580190227\n",
      "\n",
      "Epoch 36: Train Loss = 0.17330238362858258, Recall = 0.9730025538124772, Aging Rate = 0.5774704349569052, Precision = 0.9257202360291565, f1 = 0.9487726787620065\n",
      "Epoch 37: Train Loss = 0.18517198074458954, Recall = 0.9671652681503101, Aging Rate = 0.5826819001803969, Precision = 0.911936704506364, f1 = 0.9387393767705383\n",
      "Epoch 38: Train Loss = 0.17605850593041122, Recall = 0.9730025538124772, Aging Rate = 0.5802766085387854, Precision = 0.9212435233160622, f1 = 0.9464158977998581\n",
      "Epoch 39: Train Loss = 0.18062408179146275, Recall = 0.9700839109813937, Aging Rate = 0.5808779314491882, Precision = 0.9175293305728088, f1 = 0.9430750133002306\n",
      "Epoch 40: Train Loss = 0.17487004701564107, Recall = 0.9671652681503101, Aging Rate = 0.5738624974944879, Precision = 0.9259517988124345, f1 = 0.9461099214846538\n",
      "Test Loss = 0.198222980891853, Recall = 0.9919737322145202, Aging Rate = 0.6361996392062538, precision = 0.8566477630749842\n",
      "\n",
      "Epoch 41: Train Loss = 0.17625831713308956, Recall = 0.9730025538124772, Aging Rate = 0.5782721988374424, Precision = 0.9244367417677642, f1 = 0.9480981158905083\n",
      "Epoch 42: Train Loss = 0.17865845741430442, Recall = 0.9697190806275082, Aging Rate = 0.5792744036881139, Precision = 0.9197231833910035, f1 = 0.9440596696856686\n",
      "Epoch 43: Train Loss = 0.17216056285138168, Recall = 0.9740970448741335, Aging Rate = 0.5802766085387854, Precision = 0.9222797927461139, f1 = 0.9474804826117814\n",
      "Epoch 44: Train Loss = 0.1759467087753265, Recall = 0.9730025538124772, Aging Rate = 0.578071757867308, Precision = 0.9247572815533981, f1 = 0.9482666666666667\n",
      "Epoch 45: Train Loss = 0.1778353785173428, Recall = 0.9733673841663626, Aging Rate = 0.5802766085387854, Precision = 0.9215889464594128, f1 = 0.9467707594038326\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss = 0.17318678438651536, Recall = 0.9573148485954032, Aging Rate = 0.5532170775706554, precision = 0.9507246376811594\n",
      "\n",
      "Epoch 46: Train Loss = 0.17454830817109143, Recall = 0.9730025538124772, Aging Rate = 0.5794748446582482, Precision = 0.9225181598062954, f1 = 0.9470880681818182\n",
      "Epoch 47: Train Loss = 0.18256320020471029, Recall = 0.9719080627508209, Aging Rate = 0.585488073762277, Precision = 0.9120164327285176, f1 = 0.9410102437301306\n",
      "Epoch 48: Train Loss = 0.17519772900419642, Recall = 0.9726377234585918, Aging Rate = 0.5778713168971737, Precision = 0.9247311827956989, f1 = 0.9480796586059744\n",
      "Epoch 49: Train Loss = 0.17439494361306843, Recall = 0.9730025538124772, Aging Rate = 0.5756664662256965, Precision = 0.9286211699164345, f1 = 0.9502939604489579\n",
      "Epoch 50: Train Loss = 0.17683169993018072, Recall = 0.9733673841663626, Aging Rate = 0.5808779314491882, Precision = 0.9206349206349206, f1 = 0.9462670686291894\n",
      "Test Loss = 0.16904983055880707, Recall = 0.9865012769062386, Aging Rate = 0.6001202645820806, precision = 0.9031396125584502\n",
      "\n",
      "Epoch 51: Train Loss = 0.17426744081926718, Recall = 0.9715432323969354, Aging Rate = 0.5798757265985167, Precision = 0.9204977531973729, f1 = 0.9453319133830316\n",
      "Epoch 52: Train Loss = 0.18143084759815203, Recall = 0.9671652681503101, Aging Rate = 0.5784726398075767, Precision = 0.9185724185724186, f1 = 0.9422427581304426\n",
      "Epoch 53: Train Loss = 0.17524476277073153, Recall = 0.97117840204305, Aging Rate = 0.5758669071958308, Precision = 0.9265576052906369, f1 = 0.9483434271464196\n",
      "Epoch 54: Train Loss = 0.17402362156831852, Recall = 0.9700839109813937, Aging Rate = 0.5774704349569052, Precision = 0.9229434224227698, f1 = 0.9459267164710068\n",
      "Epoch 55: Train Loss = 0.18137879626357645, Recall = 0.9689894199197373, Aging Rate = 0.5782721988374424, Precision = 0.9206239168110919, f1 = 0.9441876999644507\n",
      "Test Loss = 0.16110879649652893, Recall = 0.9795695001824152, Aging Rate = 0.5654439767488475, precision = 0.9517901453385325\n",
      "\n",
      "Epoch 56: Train Loss = 0.1728450685775359, Recall = 0.9722728931047063, Aging Rate = 0.574664261375025, Precision = 0.9295430763864667, f1 = 0.9504279600570613\n",
      "Epoch 57: Train Loss = 0.18216320800772887, Recall = 0.9682597592119664, Aging Rate = 0.5810783724193225, Precision = 0.9154880993446016, f1 = 0.9411347517730496\n",
      "Epoch 58: Train Loss = 0.17663474539867932, Recall = 0.97117840204305, Aging Rate = 0.5796752856283824, Precision = 0.9204702627939142, f1 = 0.9451446831173442\n",
      "Epoch 59: Train Loss = 0.17976079908669843, Recall = 0.9700839109813937, Aging Rate = 0.5816796953297254, Precision = 0.9162646450723639, f1 = 0.9424065213538898\n",
      "Epoch 60: Train Loss = 0.17874142495920148, Recall = 0.9704487413352791, Aging Rate = 0.5764682301062337, Precision = 0.9248956884561892, f1 = 0.9471247997151505\n",
      "Test Loss = 0.16523674035160735, Recall = 0.9653411163808829, Aging Rate = 0.5614351573461616, precision = 0.9446626204926812\n",
      "\n",
      "Epoch 61: Train Loss = 0.18324509076363435, Recall = 0.9660707770886537, Aging Rate = 0.5776708759270395, Precision = 0.9188063844552394, f1 = 0.9418459896852214\n",
      "Epoch 62: Train Loss = 0.17567557889776256, Recall = 0.9759211966435607, Aging Rate = 0.5810783724193225, Precision = 0.9227319765436357, f1 = 0.9485815602836879\n",
      "Epoch 63: Train Loss = 0.17515953066449863, Recall = 0.9726377234585918, Aging Rate = 0.5784726398075767, Precision = 0.9237699237699237, f1 = 0.9475741958414785\n",
      "Epoch 64: Train Loss = 0.1857508397706885, Recall = 0.9715432323969354, Aging Rate = 0.5840849869713369, Precision = 0.9138641043239534, f1 = 0.9418213969938108\n",
      "Epoch 65: Train Loss = 0.17779628102742112, Recall = 0.9668004377964247, Aging Rate = 0.5764682301062337, Precision = 0.9214186369958275, f1 = 0.9435641801673491\n",
      "Test Loss = 0.1608729292731004, Recall = 0.9817584823057278, Aging Rate = 0.5760673481659652, precision = 0.9363256784968684\n",
      "\n",
      "Epoch 66: Train Loss = 0.17380264340505067, Recall = 0.9766508573513316, Aging Rate = 0.5812788133894567, Precision = 0.9231034482758621, f1 = 0.9491224960113455\n",
      "Epoch 67: Train Loss = 0.18354490332306925, Recall = 0.9668004377964247, Aging Rate = 0.5810783724193225, Precision = 0.9141083132114523, f1 = 0.9397163120567376\n",
      "Epoch 68: Train Loss = 0.1743081373928496, Recall = 0.9722728931047063, Aging Rate = 0.5792744036881139, Precision = 0.9221453287197232, f1 = 0.9465459065885279\n",
      "Epoch 69: Train Loss = 0.17842371714308689, Recall = 0.9697190806275082, Aging Rate = 0.5792744036881139, Precision = 0.9197231833910035, f1 = 0.9440596696856686\n",
      "Epoch 70: Train Loss = 0.17609543163806504, Recall = 0.9693542502736228, Aging Rate = 0.5750651433152937, Precision = 0.9261066573719066, f1 = 0.9472370766488414\n",
      "Test Loss = 0.17753758925274776, Recall = 0.9449106165632981, Aging Rate = 0.5353778312287032, precision = 0.9696742792961438\n",
      "\n",
      "Epoch 71: Train Loss = 0.18379641730934948, Recall = 0.9675300985041956, Aging Rate = 0.5812788133894567, Precision = 0.9144827586206896, f1 = 0.9402588193582698\n",
      "Epoch 72: Train Loss = 0.1766107361543439, Recall = 0.974461875228019, Aging Rate = 0.5844858689116055, Precision = 0.9159807956104252, f1 = 0.9443167756761535\n",
      "Epoch 73: Train Loss = 0.17666185214013416, Recall = 0.9715432323969354, Aging Rate = 0.5778713168971737, Precision = 0.9236906000693722, f1 = 0.9470128022759602\n",
      "Epoch 74: Train Loss = 0.17357663449447316, Recall = 0.9715432323969354, Aging Rate = 0.5774704349569052, Precision = 0.9243318292259632, f1 = 0.9473496976165067\n",
      "Epoch 75: Train Loss = 0.17793010085624023, Recall = 0.967894928858081, Aging Rate = 0.5774704349569052, Precision = 0.9208608122179799, f1 = 0.9437922447527571\n",
      "Test Loss = 0.16675417118952782, Recall = 0.9649762860269975, Aging Rate = 0.5576267789136099, precision = 0.9507548526240115\n",
      "\n",
      "Training Finished at epoch 75.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b34e79464da84cee9d6c0c30c1887947",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss = 0.3949241810496941, Recall = 0.904014598540146, Aging Rate = 0.6457497995188453, Precision = 0.7690158335920522, f1 = 0.8310686126488843\n",
      "Epoch 2: Train Loss = 0.31609581095415207, Recall = 0.9222627737226278, Aging Rate = 0.6104651162790697, Precision = 0.8298850574712644, f1 = 0.8736387208297319\n",
      "Epoch 3: Train Loss = 0.27488447060179694, Recall = 0.9408759124087591, Aging Rate = 0.6090617481956696, Precision = 0.8485845951283739, f1 = 0.8923502942194531\n",
      "Epoch 4: Train Loss = 0.26859740222226935, Recall = 0.9328467153284672, Aging Rate = 0.5966319165998396, Precision = 0.8588709677419355, f1 = 0.8943317004898531\n",
      "Epoch 5: Train Loss = 0.2521871688634563, Recall = 0.9470802919708029, Aging Rate = 0.6004410585404972, Precision = 0.8664440734557596, f1 = 0.9049694856146469\n",
      "Test Loss = 0.21297182405625903, Recall = 0.9857664233576642, Aging Rate = 0.6194867682437851, precision = 0.8741100323624595\n",
      "Model in epoch 5 is saved.\n",
      "\n",
      "Epoch 6: Train Loss = 0.20252002083786794, Recall = 0.9682481751824817, Aging Rate = 0.5890136327185245, Precision = 0.902995234853642, f1 = 0.9344839732300105\n",
      "Epoch 7: Train Loss = 0.18999356485502952, Recall = 0.9656934306569344, Aging Rate = 0.5821972734562951, Precision = 0.9111570247933884, f1 = 0.9376328844790929\n",
      "Epoch 8: Train Loss = 0.1948709817365732, Recall = 0.964963503649635, Aging Rate = 0.5852044907778668, Precision = 0.9057896539910928, f1 = 0.9344407139070507\n",
      "Epoch 9: Train Loss = 0.18721919907697604, Recall = 0.9686131386861314, Aging Rate = 0.5817963111467522, Precision = 0.9145416953824949, f1 = 0.9408011343495214\n",
      "Epoch 10: Train Loss = 0.18909709008579362, Recall = 0.9653284671532847, Aging Rate = 0.5819967923015237, Precision = 0.9111264209438512, f1 = 0.937444621655148\n",
      "Test Loss = 0.16212392636031844, Recall = 0.9857664233576642, Aging Rate = 0.5900160384923817, precision = 0.9177709819911655\n",
      "Model in epoch 10 is saved.\n",
      "\n",
      "Epoch 11: Train Loss = 0.18564682176042388, Recall = 0.9678832116788321, Aging Rate = 0.5803929430633521, Precision = 0.9160621761658031, f1 = 0.941259982253771\n",
      "Epoch 12: Train Loss = 0.18151876325595828, Recall = 0.9671532846715328, Aging Rate = 0.5789895749799518, Precision = 0.917590027700831, f1 = 0.9417199715707177\n",
      "Epoch 13: Train Loss = 0.18633747723404656, Recall = 0.9697080291970803, Aging Rate = 0.5817963111467522, Precision = 0.9155754651964163, f1 = 0.9418645870258774\n",
      "Epoch 14: Train Loss = 0.18212445825935844, Recall = 0.9697080291970803, Aging Rate = 0.5809943865276664, Precision = 0.916839199447895, f1 = 0.9425328130542745\n",
      "Epoch 15: Train Loss = 0.1799964592661395, Recall = 0.9748175182481752, Aging Rate = 0.5813953488372093, Precision = 0.9210344827586207, f1 = 0.9471631205673758\n",
      "Test Loss = 0.16298247312151534, Recall = 0.9653284671532847, Aging Rate = 0.5533279871692061, precision = 0.9583333333333334\n",
      "Model in epoch 15 is saved.\n",
      "\n",
      "Epoch 16: Train Loss = 0.18337472455924095, Recall = 0.9656934306569344, Aging Rate = 0.5777866880513232, Precision = 0.9181124219292158, f1 = 0.9413020277481323\n",
      "Epoch 17: Train Loss = 0.1871284302846852, Recall = 0.974087591240876, Aging Rate = 0.5874097834803529, Precision = 0.9109215017064847, f1 = 0.9414462081128748\n",
      "Epoch 18: Train Loss = 0.18117757808378246, Recall = 0.972992700729927, Aging Rate = 0.5815958299919808, Precision = 0.9189934505342985, f1 = 0.9452224782839922\n",
      "Epoch 19: Train Loss = 0.18508167292417865, Recall = 0.9697080291970803, Aging Rate = 0.5842020850040096, Precision = 0.9118050789293068, f1 = 0.9398655818889282\n",
      "Epoch 20: Train Loss = 0.18492250003476285, Recall = 0.9656934306569344, Aging Rate = 0.5771852445870088, Precision = 0.9190691212226467, f1 = 0.9418045915643354\n",
      "Test Loss = 0.16907702493925714, Recall = 0.954014598540146, Aging Rate = 0.5455092221331195, precision = 0.9606762219772143\n",
      "\n",
      "Epoch 21: Train Loss = 0.17708267806861147, Recall = 0.9726277372262774, Aging Rate = 0.5809943865276664, Precision = 0.9195997239475501, f1 = 0.9453706988293722\n",
      "Epoch 22: Train Loss = 0.18510842547955852, Recall = 0.9686131386861314, Aging Rate = 0.5819967923015237, Precision = 0.9142266620737168, f1 = 0.9406344143186248\n",
      "Epoch 23: Train Loss = 0.18596558456862555, Recall = 0.9638686131386861, Aging Rate = 0.5791900561347233, Precision = 0.9141571478020076, f1 = 0.938354947592823\n",
      "Epoch 24: Train Loss = 0.17506157845234813, Recall = 0.974087591240876, Aging Rate = 0.5799919807538091, Precision = 0.9225717248530937, f1 = 0.9476300372803124\n",
      "Epoch 25: Train Loss = 0.17764678892605573, Recall = 0.9708029197080292, Aging Rate = 0.5779871692060946, Precision = 0.9226500173430454, f1 = 0.9461141739285079\n",
      "Test Loss = 0.17242280870030763, Recall = 0.974087591240876, Aging Rate = 0.5775862068965517, precision = 0.9264144394307532\n",
      "\n",
      "Epoch 26: Train Loss = 0.18422260655817646, Recall = 0.9678832116788321, Aging Rate = 0.5783881315156375, Precision = 0.9192374350086655, f1 = 0.9429333333333333\n",
      "Epoch 27: Train Loss = 0.17612156620863062, Recall = 0.9751824817518249, Aging Rate = 0.5836006415396953, Precision = 0.9178976296805221, f1 = 0.9456733321536012\n",
      "Epoch 28: Train Loss = 0.1741093471825553, Recall = 0.9748175182481752, Aging Rate = 0.5821972734562951, Precision = 0.9197658402203857, f1 = 0.9464918497519489\n",
      "Epoch 29: Train Loss = 0.1793325049287334, Recall = 0.9726277372262774, Aging Rate = 0.5840016038492382, Precision = 0.9148644009612084, f1 = 0.942862197063506\n",
      "Epoch 30: Train Loss = 0.17573428113363032, Recall = 0.9693430656934306, Aging Rate = 0.5755813953488372, Precision = 0.92511320097527, f1 = 0.9467118160755659\n",
      "Test Loss = 0.1588662891337273, Recall = 0.9799270072992701, Aging Rate = 0.5699679230152366, precision = 0.9444249032711924\n",
      "\n",
      "Epoch 31: Train Loss = 0.17757686318974544, Recall = 0.9708029197080292, Aging Rate = 0.5771852445870088, Precision = 0.9239319208058353, f1 = 0.9467876846413953\n",
      "Epoch 32: Train Loss = 0.18900414886671538, Recall = 0.9660583941605839, Aging Rate = 0.5836006415396953, Precision = 0.9093095156303675, f1 = 0.936825340647673\n",
      "Epoch 33: Train Loss = 0.1800262276157916, Recall = 0.9718978102189781, Aging Rate = 0.5803929430633521, Precision = 0.9198618307426597, f1 = 0.9451641526175687\n",
      "Epoch 34: Train Loss = 0.17839741990053853, Recall = 0.9715328467153285, Aging Rate = 0.5773857257417803, Precision = 0.9243055555555556, f1 = 0.9473309608540926\n",
      "Epoch 35: Train Loss = 0.17825369950333117, Recall = 0.9682481751824817, Aging Rate = 0.5771852445870088, Precision = 0.9215005210142411, f1 = 0.9442961381028652\n",
      "Test Loss = 0.16351568487374996, Recall = 0.9795620437956204, Aging Rate = 0.5761828388131516, precision = 0.9338900487125957\n",
      "\n",
      "Epoch 36: Train Loss = 0.17423672496125328, Recall = 0.9733576642335766, Aging Rate = 0.5787890938251804, Precision = 0.9237963283685486, f1 = 0.9479296250222143\n",
      "Epoch 37: Train Loss = 0.17715499230452128, Recall = 0.9718978102189781, Aging Rate = 0.5789895749799518, Precision = 0.9220914127423823, f1 = 0.9463397299218195\n",
      "Epoch 38: Train Loss = 0.1743325899506724, Recall = 0.9722627737226277, Aging Rate = 0.5771852445870088, Precision = 0.9253212921153178, f1 = 0.9482114255205553\n",
      "Epoch 39: Train Loss = 0.17641465960977168, Recall = 0.9675182481751825, Aging Rate = 0.5751804330392943, Precision = 0.9240153363541304, f1 = 0.9452665359244072\n",
      "Epoch 40: Train Loss = 0.18001176229265087, Recall = 0.9755474452554744, Aging Rate = 0.5815958299919808, Precision = 0.921406411582213, f1 = 0.9477043077468534\n",
      "Test Loss = 0.17354760680470163, Recall = 0.9631386861313869, Aging Rate = 0.553728949478749, precision = 0.9554670528602462\n",
      "\n",
      "Epoch 41: Train Loss = 0.18058072920790078, Recall = 0.9693430656934306, Aging Rate = 0.5795910184442662, Precision = 0.9187132480110688, f1 = 0.9433493162848516\n",
      "Epoch 42: Train Loss = 0.17775594496258565, Recall = 0.974087591240876, Aging Rate = 0.5811948676824379, Precision = 0.9206622973439117, f1 = 0.9466217414435184\n",
      "Epoch 43: Train Loss = 0.17673066902514353, Recall = 0.9711678832116788, Aging Rate = 0.5799919807538091, Precision = 0.9198064293121327, f1 = 0.9447896325226344\n",
      "Epoch 44: Train Loss = 0.18018813332081224, Recall = 0.9708029197080292, Aging Rate = 0.5831996792301524, Precision = 0.9144035751117222, f1 = 0.9417596034696406\n",
      "Epoch 45: Train Loss = 0.1807781505340945, Recall = 0.9693430656934306, Aging Rate = 0.576383319967923, Precision = 0.9238260869565217, f1 = 0.9460373998219056\n",
      "Test Loss = 0.16670916826369386, Recall = 0.9766423357664233, Aging Rate = 0.5651563753007217, precision = 0.9492727917701312\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 46: Train Loss = 0.18057508113007595, Recall = 0.9697080291970803, Aging Rate = 0.5811948676824379, Precision = 0.9165229389444636, f1 = 0.9423656676715729\n",
      "Epoch 47: Train Loss = 0.1766972902687244, Recall = 0.9726277372262774, Aging Rate = 0.5815958299919808, Precision = 0.9186487418131679, f1 = 0.9448679312178692\n",
      "Epoch 48: Train Loss = 0.17267632264563249, Recall = 0.9759124087591241, Aging Rate = 0.5781876503608661, Precision = 0.9271844660194175, f1 = 0.9509246088193456\n",
      "Epoch 49: Train Loss = 0.17735419690656776, Recall = 0.9718978102189781, Aging Rate = 0.5775862068965517, Precision = 0.9243318292259632, f1 = 0.9475182351894681\n",
      "Epoch 50: Train Loss = 0.17679632699480033, Recall = 0.968978102189781, Aging Rate = 0.5781876503608661, Precision = 0.9205963938973648, f1 = 0.944167852062589\n",
      "Test Loss = 0.15924496614130002, Recall = 0.9890510948905109, Aging Rate = 0.596832397754611, precision = 0.9103123950285522\n",
      "\n",
      "Epoch 51: Train Loss = 0.17756093956034186, Recall = 0.9671532846715328, Aging Rate = 0.5781876503608661, Precision = 0.9188626907073509, f1 = 0.9423897581792319\n",
      "Epoch 52: Train Loss = 0.17725135060960806, Recall = 0.9759124087591241, Aging Rate = 0.5852044907778668, Precision = 0.9160671462829736, f1 = 0.9450432938681745\n",
      "Epoch 53: Train Loss = 0.1755955231337903, Recall = 0.9715328467153285, Aging Rate = 0.5797914995990376, Precision = 0.9204702627939142, f1 = 0.9453124999999999\n",
      "Epoch 54: Train Loss = 0.179012351425151, Recall = 0.9711678832116788, Aging Rate = 0.5795910184442662, Precision = 0.9204427533725354, f1 = 0.9451251997868939\n",
      "Epoch 55: Train Loss = 0.1818735322047924, Recall = 0.9718978102189781, Aging Rate = 0.584803528468324, Precision = 0.9129242372300308, f1 = 0.9414884214247835\n",
      "Test Loss = 0.16494673570586665, Recall = 0.9631386861313869, Aging Rate = 0.54971932638332, precision = 0.962436177972283\n",
      "Model in epoch 55 is saved.\n",
      "\n",
      "Epoch 56: Train Loss = 0.17647610787592033, Recall = 0.9722627737226277, Aging Rate = 0.5747794707297514, Precision = 0.9291942797349145, f1 = 0.9502407704654896\n",
      "Epoch 57: Train Loss = 0.17634651170029292, Recall = 0.972992700729927, Aging Rate = 0.5813953488372093, Precision = 0.9193103448275862, f1 = 0.9453900709219858\n",
      "Epoch 58: Train Loss = 0.17605300209430474, Recall = 0.968978102189781, Aging Rate = 0.5775862068965517, Precision = 0.9215550156195765, f1 = 0.9446717665895749\n",
      "Epoch 59: Train Loss = 0.17435541232777482, Recall = 0.9737226277372263, Aging Rate = 0.576383319967923, Precision = 0.928, f1 = 0.9503116651825467\n",
      "Epoch 60: Train Loss = 0.1785650452376368, Recall = 0.9733576642335766, Aging Rate = 0.5795910184442662, Precision = 0.9225181598062954, f1 = 0.9472562599893446\n",
      "Test Loss = 0.18911306074885434, Recall = 0.9981751824817519, Aging Rate = 0.6369286287089013, precision = 0.8608750393452943\n",
      "\n",
      "Epoch 61: Train Loss = 0.1734402235403191, Recall = 0.972992700729927, Aging Rate = 0.5783881315156375, Precision = 0.9240901213171577, f1 = 0.9479111111111111\n",
      "Epoch 62: Train Loss = 0.17527591570339493, Recall = 0.9722627737226277, Aging Rate = 0.578588612670409, Precision = 0.9230769230769231, f1 = 0.9470316388197654\n",
      "Epoch 63: Train Loss = 0.17385320144361177, Recall = 0.972992700729927, Aging Rate = 0.5805934242181235, Precision = 0.9205801104972375, f1 = 0.9460610361958837\n",
      "Epoch 64: Train Loss = 0.1710497978432425, Recall = 0.9718978102189781, Aging Rate = 0.5765838011226945, Precision = 0.9259388038942976, f1 = 0.9483618233618235\n",
      "Epoch 65: Train Loss = 0.17756883411667493, Recall = 0.974087591240876, Aging Rate = 0.5783881315156375, Precision = 0.9251299826689775, f1 = 0.9489777777777777\n",
      "Test Loss = 0.16190410892343943, Recall = 0.9744525547445255, Aging Rate = 0.557738572574178, precision = 0.9597411933860532\n",
      "Model in epoch 65 is saved.\n",
      "\n",
      "Epoch 66: Train Loss = 0.180358671434612, Recall = 0.968978102189781, Aging Rate = 0.5781876503608661, Precision = 0.9205963938973648, f1 = 0.944167852062589\n",
      "Epoch 67: Train Loss = 0.1736120211667028, Recall = 0.9726277372262774, Aging Rate = 0.5781876503608661, Precision = 0.9240638002773925, f1 = 0.947724039829303\n",
      "Epoch 68: Train Loss = 0.17353883190879654, Recall = 0.9737226277372263, Aging Rate = 0.578588612670409, Precision = 0.9244629244629244, f1 = 0.9484536082474226\n",
      "Epoch 69: Train Loss = 0.17244399705216132, Recall = 0.9759124087591241, Aging Rate = 0.5795910184442662, Precision = 0.9249394673123487, f1 = 0.9497424968922039\n",
      "Epoch 70: Train Loss = 0.17845768375738966, Recall = 0.9704379562043796, Aging Rate = 0.5795910184442662, Precision = 0.9197509512279488, f1 = 0.944414846386077\n",
      "Test Loss = 0.17203877967839826, Recall = 0.9952554744525547, Aging Rate = 0.6180834001603849, precision = 0.8845280570872527\n",
      "\n",
      "Epoch 71: Train Loss = 0.1778632317338835, Recall = 0.9718978102189781, Aging Rate = 0.5791900561347233, Precision = 0.9217722395292489, f1 = 0.9461716112986321\n",
      "Epoch 72: Train Loss = 0.1771819087846239, Recall = 0.9737226277372263, Aging Rate = 0.5781876503608661, Precision = 0.9251040221914009, f1 = 0.9487908961593172\n",
      "Epoch 73: Train Loss = 0.17044357913034672, Recall = 0.9755474452554744, Aging Rate = 0.5775862068965517, Precision = 0.9278028462339466, f1 = 0.9510763209393346\n",
      "Epoch 74: Train Loss = 0.173822494882436, Recall = 0.9744525547445255, Aging Rate = 0.5801924619085806, Precision = 0.9225984796129924, f1 = 0.9478168264110756\n",
      "Epoch 75: Train Loss = 0.18155337349118092, Recall = 0.9722627737226277, Aging Rate = 0.5862068965517241, Precision = 0.9110807113543091, f1 = 0.9406779661016949\n",
      "Test Loss = 0.16143848022271273, Recall = 0.9708029197080292, Aging Rate = 0.5625501202886929, precision = 0.9479686386315039\n",
      "\n",
      "Epoch 76: Train Loss = 0.1788225377571516, Recall = 0.9678832116788321, Aging Rate = 0.5789895749799518, Precision = 0.9182825484764543, f1 = 0.9424307036247335\n",
      "Epoch 77: Train Loss = 0.1738839938627211, Recall = 0.9748175182481752, Aging Rate = 0.5777866880513232, Precision = 0.9267869535045108, f1 = 0.9501956599075062\n",
      "Epoch 78: Train Loss = 0.17343980018960636, Recall = 0.9766423357664233, Aging Rate = 0.5789895749799518, Precision = 0.9265927977839336, f1 = 0.9509594882729211\n",
      "Epoch 79: Train Loss = 0.17289661804293285, Recall = 0.9718978102189781, Aging Rate = 0.5777866880513232, Precision = 0.9240111034004164, f1 = 0.9473496976165066\n",
      "Epoch 80: Train Loss = 0.17726039590124332, Recall = 0.9718978102189781, Aging Rate = 0.5811948676824379, Precision = 0.9185926181441877, f1 = 0.9444937045575458\n",
      "Test Loss = 0.15541197317738292, Recall = 0.9744525547445255, Aging Rate = 0.5663592622293504, precision = 0.9451327433628318\n",
      "\n",
      "Epoch 81: Train Loss = 0.17887621387875166, Recall = 0.972992700729927, Aging Rate = 0.582598235765838, Precision = 0.9174122505161735, f1 = 0.9443854055968828\n",
      "Epoch 82: Train Loss = 0.17585223474642134, Recall = 0.9755474452554744, Aging Rate = 0.5836006415396953, Precision = 0.9182411542425284, f1 = 0.9460272518138382\n",
      "Epoch 83: Train Loss = 0.17248694065722256, Recall = 0.9737226277372263, Aging Rate = 0.5789895749799518, Precision = 0.9238227146814404, f1 = 0.9481165600568585\n",
      "Epoch 84: Train Loss = 0.17082326832349146, Recall = 0.9748175182481752, Aging Rate = 0.5791900561347233, Precision = 0.9245413637937002, f1 = 0.9490140344643809\n",
      "Epoch 85: Train Loss = 0.17594983210636314, Recall = 0.9766423357664233, Aging Rate = 0.5817963111467522, Precision = 0.9221226740179187, f1 = 0.9485997873094647\n",
      "Test Loss = 0.15928592744978695, Recall = 0.968978102189781, Aging Rate = 0.5563352044907779, precision = 0.9567567567567568\n",
      "\n",
      "Epoch 86: Train Loss = 0.17666055711394038, Recall = 0.968978102189781, Aging Rate = 0.5789895749799518, Precision = 0.9193213296398892, f1 = 0.9434968017057569\n",
      "Epoch 87: Train Loss = 0.17760921383773984, Recall = 0.9726277372262774, Aging Rate = 0.5797914995990376, Precision = 0.9215076071922544, f1 = 0.9463778409090908\n",
      "Epoch 88: Train Loss = 0.17438352434226007, Recall = 0.9718978102189781, Aging Rate = 0.5789895749799518, Precision = 0.9220914127423823, f1 = 0.9463397299218195\n",
      "Epoch 89: Train Loss = 0.1722077578067206, Recall = 0.9762773722627737, Aging Rate = 0.5813953488372093, Precision = 0.9224137931034483, f1 = 0.9485815602836879\n",
      "Epoch 90: Train Loss = 0.17717449218871217, Recall = 0.9708029197080292, Aging Rate = 0.5787890938251804, Precision = 0.9213716660893662, f1 = 0.9454416207570642\n",
      "Test Loss = 0.16395312440137244, Recall = 0.987956204379562, Aging Rate = 0.5974338412189254, precision = 0.9083892617449665\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 91: Train Loss = 0.17665968988308833, Recall = 0.9708029197080292, Aging Rate = 0.5811948676824379, Precision = 0.9175577785443256, f1 = 0.9434296861145594\n",
      "Epoch 92: Train Loss = 0.17458016137983098, Recall = 0.9733576642335766, Aging Rate = 0.5797914995990376, Precision = 0.9221991701244814, f1 = 0.9470880681818181\n",
      "Epoch 93: Train Loss = 0.17973684118619992, Recall = 0.9704379562043796, Aging Rate = 0.5831996792301524, Precision = 0.914059814369199, f1 = 0.9414055585059302\n",
      "Epoch 94: Train Loss = 0.17339534461856748, Recall = 0.9759124087591241, Aging Rate = 0.5775862068965517, Precision = 0.9281499479347449, f1 = 0.9514321295143213\n",
      "Epoch 95: Train Loss = 0.17868281112208592, Recall = 0.9700729927007299, Aging Rate = 0.582598235765838, Precision = 0.9146593255333793, f1 = 0.9415515409139213\n",
      "Test Loss = 0.16272753425713243, Recall = 0.9901459854014598, Aging Rate = 0.5936246992782679, precision = 0.9162445119891929\n",
      "\n",
      "Epoch 96: Train Loss = 0.17269313359317917, Recall = 0.9751824817518249, Aging Rate = 0.5797914995990376, Precision = 0.9239280774550485, f1 = 0.9488636363636365\n",
      "Epoch 97: Train Loss = 0.1713252478811678, Recall = 0.9773722627737226, Aging Rate = 0.5777866880513232, Precision = 0.9292158223455933, f1 = 0.9526858769121309\n",
      "Epoch 98: Train Loss = 0.18272760338370286, Recall = 0.9697080291970803, Aging Rate = 0.5811948676824379, Precision = 0.9165229389444636, f1 = 0.9423656676715729\n",
      "Epoch 99: Train Loss = 0.17897155780551333, Recall = 0.9708029197080292, Aging Rate = 0.5805934242181235, Precision = 0.9185082872928176, f1 = 0.943931866572037\n",
      "Epoch 100: Train Loss = 0.17000310749126227, Recall = 0.9766423357664233, Aging Rate = 0.5787890938251804, Precision = 0.9269137512989262, f1 = 0.9511284876488358\n",
      "Test Loss = 0.1822836843305047, Recall = 0.9408759124087591, Aging Rate = 0.5316760224538893, precision = 0.9720965309200603\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f659baa70eb4cd8b45b229dfebab24a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss = 0.5236738175780961, Recall = 0.9992703392922291, Aging Rate = 0.996592503507717, Precision = 0.5508849557522124, f1 = 0.7102294826915597\n",
      "Epoch 2: Train Loss = 0.3783167132241235, Recall = 0.9733673841663626, Aging Rate = 0.7821206654640208, Precision = 0.6837519220912353, f1 = 0.8032515429775704\n",
      "Epoch 3: Train Loss = 0.3007357900398101, Recall = 0.9649762860269975, Aging Rate = 0.6792944477851273, Precision = 0.7804662142224845, f1 = 0.8629690048939641\n",
      "Epoch 4: Train Loss = 0.2578604279825601, Recall = 0.9689894199197373, Aging Rate = 0.656043295249549, Precision = 0.8114879315612588, f1 = 0.8832723644828732\n",
      "Epoch 5: Train Loss = 0.22814095165751505, Recall = 0.9686245895658518, Aging Rate = 0.6390058127881338, Precision = 0.832810539523212, f1 = 0.8955979085849215\n",
      "Test Loss = 0.19941455857874182, Recall = 0.9810288215979569, Aging Rate = 0.6283824413710163, precision = 0.8577352472089315\n",
      "Model in epoch 5 is saved.\n",
      "\n",
      "Epoch 6: Train Loss = 0.18930032568253646, Recall = 0.9802991608901861, Aging Rate = 0.6215674483864502, Precision = 0.8664946791357626, f1 = 0.9198904484765491\n",
      "Epoch 7: Train Loss = 0.1633468587350979, Recall = 0.9828529733673842, Aging Rate = 0.607937462417318, Precision = 0.8882294757665677, f1 = 0.9331485971596813\n",
      "Epoch 8: Train Loss = 0.14139915013222495, Recall = 0.9865012769062386, Aging Rate = 0.5989176187612748, Precision = 0.9049531459170014, f1 = 0.9439692791063014\n",
      "Epoch 9: Train Loss = 0.12287101329065894, Recall = 0.9872309376140095, Aging Rate = 0.5892964521948286, Precision = 0.9204081632653062, f1 = 0.9526491814821335\n",
      "Epoch 10: Train Loss = 0.10923093281675852, Recall = 0.9883254286756659, Aging Rate = 0.5816796953297254, Precision = 0.9334941419710544, f1 = 0.960127591706539\n",
      "Test Loss = 0.09835487826956754, Recall = 0.9872309376140095, Aging Rate = 0.5654439767488475, precision = 0.9592343140730237\n",
      "Model in epoch 10 is saved.\n",
      "\n",
      "Epoch 11: Train Loss = 0.09457801674573114, Recall = 0.9919737322145202, Aging Rate = 0.5774704349569052, Precision = 0.9437695244706699, f1 = 0.9672714336535041\n",
      "Epoch 12: Train Loss = 0.08498842950920037, Recall = 0.9919737322145202, Aging Rate = 0.5734616155542193, Precision = 0.9503670045438658, f1 = 0.9707247411638701\n",
      "Epoch 13: Train Loss = 0.07604899222923917, Recall = 0.9937978839839474, Aging Rate = 0.5700541190619363, Precision = 0.9578059071729957, f1 = 0.9754700089525515\n",
      "Epoch 14: Train Loss = 0.06921889385334307, Recall = 0.9948923750456038, Aging Rate = 0.5648426538384446, Precision = 0.9677075940383251, f1 = 0.9811117107393416\n",
      "Epoch 15: Train Loss = 0.06293080068077823, Recall = 0.9956220357533747, Aging Rate = 0.5652435357787132, Precision = 0.9677304964539007, f1 = 0.9814781514116165\n",
      "Test Loss = 0.0569338396753116, Recall = 0.9948923750456038, Aging Rate = 0.5584285427941471, precision = 0.9788226848528356\n",
      "Model in epoch 15 is saved.\n",
      "\n",
      "Epoch 16: Train Loss = 0.05785404715300992, Recall = 0.9963516964611455, Aging Rate = 0.5614351573461616, Precision = 0.9750089253837915, f1 = 0.9855647780584625\n",
      "Epoch 17: Train Loss = 0.05239442799529324, Recall = 0.996716526815031, Aging Rate = 0.5628382441371016, Precision = 0.9729344729344729, f1 = 0.9846819246711119\n",
      "Epoch 18: Train Loss = 0.04948613966863149, Recall = 0.9970813571689164, Aging Rate = 0.5592303066746843, Precision = 0.9795698924731183, f1 = 0.9882480564093292\n",
      "Epoch 19: Train Loss = 0.04590842054025949, Recall = 0.9974461875228019, Aging Rate = 0.55902986570455, Precision = 0.980279670132664, f1 = 0.9887884267631103\n",
      "Epoch 20: Train Loss = 0.04326756376124236, Recall = 0.9981758482305728, Aging Rate = 0.5582281018240128, Precision = 0.9824057450628366, f1 = 0.990228013029316\n",
      "Test Loss = 0.04062497070610619, Recall = 0.9981758482305728, Aging Rate = 0.5520144317498497, precision = 0.9934640522875817\n",
      "Model in epoch 20 is saved.\n",
      "\n",
      "Epoch 21: Train Loss = 0.040823685554505634, Recall = 0.9974461875228019, Aging Rate = 0.5552214872719984, Precision = 0.9870036101083033, f1 = 0.9921974233351478\n",
      "Epoch 22: Train Loss = 0.039458327185034774, Recall = 0.9981758482305728, Aging Rate = 0.5558228101824013, Precision = 0.9866570501262171, f1 = 0.9923830250272035\n",
      "Epoch 23: Train Loss = 0.036868888007409346, Recall = 0.9989055089383436, Aging Rate = 0.555622369212267, Precision = 0.9877344877344877, f1 = 0.9932885906040269\n",
      "Epoch 24: Train Loss = 0.035806101395721115, Recall = 0.9978110178766874, Aging Rate = 0.5532170775706554, Precision = 0.9909420289855072, f1 = 0.9943646609707326\n",
      "Epoch 25: Train Loss = 0.033980670074621834, Recall = 0.9978110178766874, Aging Rate = 0.5536179595109241, Precision = 0.9902244750181028, f1 = 0.9940032709431219\n",
      "Test Loss = 0.035294238481678834, Recall = 0.9974461875228019, Aging Rate = 0.550210463018641, precision = 0.9959927140255009\n",
      "Model in epoch 25 is saved.\n",
      "\n",
      "Epoch 26: Train Loss = 0.03379424901686252, Recall = 0.9985406785844583, Aging Rate = 0.5538184004810583, Precision = 0.9905899384726746, f1 = 0.9945494186046512\n",
      "Epoch 27: Train Loss = 0.031438705685932475, Recall = 0.9985406785844583, Aging Rate = 0.5530166366005211, Precision = 0.9920260964117433, f1 = 0.9952727272727273\n",
      "Epoch 28: Train Loss = 0.03072445927642168, Recall = 0.9992703392922291, Aging Rate = 0.5538184004810583, Precision = 0.991313789359392, f1 = 0.9952761627906976\n",
      "Epoch 29: Train Loss = 0.029890585980830033, Recall = 1.0, Aging Rate = 0.5538184004810583, Precision = 0.9920376402461093, f1 = 0.9960029069767442\n",
      "Epoch 30: Train Loss = 0.028456344167478078, Recall = 0.9996351696461145, Aging Rate = 0.5540188414511926, Precision = 0.9913169319826338, f1 = 0.9954586739327883\n",
      "Test Loss = 0.026508633384104363, Recall = 0.9989055089383436, Aging Rate = 0.5510122268991782, precision = 0.9959985449254274\n",
      "Model in epoch 30 is saved.\n",
      "\n",
      "Epoch 31: Train Loss = 0.02802418509942899, Recall = 0.9996351696461145, Aging Rate = 0.5530166366005211, Precision = 0.9931134469010511, f1 = 0.9963636363636365\n",
      "Epoch 32: Train Loss = 0.027023008168281307, Recall = 0.9985406785844583, Aging Rate = 0.5516135498095811, Precision = 0.9945494186046512, f1 = 0.9965410522483161\n",
      "Epoch 33: Train Loss = 0.026491718327166992, Recall = 0.9996351696461145, Aging Rate = 0.5526157546602526, Precision = 0.9938338774029742, f1 = 0.9967260822117134\n",
      "Epoch 34: Train Loss = 0.026120214924099786, Recall = 0.9996351696461145, Aging Rate = 0.5518139907797154, Precision = 0.995277878677806, f1 = 0.9974517655624318\n",
      "Epoch 35: Train Loss = 0.026418436416453746, Recall = 0.9992703392922291, Aging Rate = 0.5522148727199839, Precision = 0.9941923774954627, f1 = 0.9967248908296942\n",
      "Test Loss = 0.023434944233191972, Recall = 0.9996351696461145, Aging Rate = 0.5516135498095811, precision = 0.9956395348837209\n",
      "Model in epoch 35 is saved.\n",
      "\n",
      "Epoch 36: Train Loss = 0.025373522031512413, Recall = 0.9992703392922291, Aging Rate = 0.5526157546602526, Precision = 0.9934711643090316, f1 = 0.9963623135685704\n",
      "Epoch 37: Train Loss = 0.025280446228924985, Recall = 0.9992703392922291, Aging Rate = 0.5520144317498497, Precision = 0.9945533769063181, f1 = 0.9969062784349408\n",
      "Epoch 38: Train Loss = 0.024418230431920113, Recall = 1.0, Aging Rate = 0.5522148727199839, Precision = 0.9949183303085299, f1 = 0.99745269286754\n",
      "Epoch 39: Train Loss = 0.02431634415518272, Recall = 0.9992703392922291, Aging Rate = 0.5518139907797154, Precision = 0.9949146385760989, f1 = 0.9970877320713507\n",
      "Epoch 40: Train Loss = 0.023769897559803674, Recall = 0.9992703392922291, Aging Rate = 0.5518139907797154, Precision = 0.9949146385760989, f1 = 0.9970877320713507\n",
      "Test Loss = 0.022575176128694602, Recall = 0.9992703392922291, Aging Rate = 0.5506113449589096, precision = 0.9970877320713506\n",
      "Model in epoch 40 is saved.\n",
      "\n",
      "Epoch 41: Train Loss = 0.02364264157451174, Recall = 0.9992703392922291, Aging Rate = 0.5516135498095811, Precision = 0.9952761627906976, f1 = 0.9972692517749864\n",
      "Epoch 42: Train Loss = 0.022924636653983824, Recall = 0.9996351696461145, Aging Rate = 0.5522148727199839, Precision = 0.9945553539019963, f1 = 0.9970887918486172\n",
      "Epoch 43: Train Loss = 0.023086411429699423, Recall = 0.9996351696461145, Aging Rate = 0.5518139907797154, Precision = 0.995277878677806, f1 = 0.9974517655624318\n",
      "Epoch 44: Train Loss = 0.02348086204716559, Recall = 1.0, Aging Rate = 0.5518139907797154, Precision = 0.9956411187795132, f1 = 0.9978157990535128\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45: Train Loss = 0.02300587905084389, Recall = 0.9996351696461145, Aging Rate = 0.5520144317498497, Precision = 0.9949164851125636, f1 = 0.997270245677889\n",
      "Test Loss = 0.020515110136858566, Recall = 1.0, Aging Rate = 0.5516135498095811, precision = 0.9960029069767442\n",
      "\n",
      "Epoch 46: Train Loss = 0.022476887507007604, Recall = 0.9996351696461145, Aging Rate = 0.5518139907797154, Precision = 0.995277878677806, f1 = 0.9974517655624318\n",
      "Epoch 47: Train Loss = 0.022567313905199775, Recall = 1.0, Aging Rate = 0.5524153136901183, Precision = 0.9945573294629898, f1 = 0.9972712388575588\n",
      "Epoch 48: Train Loss = 0.021948284752357817, Recall = 0.9996351696461145, Aging Rate = 0.5512126678693124, Precision = 0.9963636363636363, f1 = 0.9979967219085777\n",
      "Epoch 49: Train Loss = 0.02354396438932856, Recall = 0.9996351696461145, Aging Rate = 0.5526157546602526, Precision = 0.9938338774029742, f1 = 0.9967260822117134\n",
      "Epoch 50: Train Loss = 0.02296767212334019, Recall = 0.9992703392922291, Aging Rate = 0.5516135498095811, Precision = 0.9952761627906976, f1 = 0.9972692517749864\n",
      "Test Loss = 0.02010572859059775, Recall = 1.0, Aging Rate = 0.5510122268991782, precision = 0.9970898508548564\n",
      "Model in epoch 50 is saved.\n",
      "\n",
      "Epoch 51: Train Loss = 0.022160876652468155, Recall = 0.9996351696461145, Aging Rate = 0.5520144317498497, Precision = 0.9949164851125636, f1 = 0.997270245677889\n",
      "Epoch 52: Train Loss = 0.021278209803227578, Recall = 0.9992703392922291, Aging Rate = 0.5512126678693124, Precision = 0.996, f1 = 0.9976324895283191\n",
      "Epoch 53: Train Loss = 0.021955974006158816, Recall = 0.9992703392922291, Aging Rate = 0.5510122268991782, Precision = 0.9963623135685704, f1 = 0.9978142076502732\n",
      "Epoch 54: Train Loss = 0.02155697498247281, Recall = 0.9996351696461145, Aging Rate = 0.5510122268991782, Precision = 0.9967260822117133, f1 = 0.9981785063752276\n",
      "Epoch 55: Train Loss = 0.02148809083183941, Recall = 0.9996351696461145, Aging Rate = 0.5510122268991782, Precision = 0.9967260822117133, f1 = 0.9981785063752276\n",
      "Test Loss = 0.020256382705355173, Recall = 1.0, Aging Rate = 0.5508117859290439, precision = 0.99745269286754\n",
      "Model in epoch 55 is saved.\n",
      "\n",
      "Epoch 56: Train Loss = 0.021197666973920976, Recall = 1.0, Aging Rate = 0.5516135498095811, Precision = 0.9960029069767442, f1 = 0.9979974513016566\n",
      "Epoch 57: Train Loss = 0.02129359135251529, Recall = 1.0, Aging Rate = 0.5514131088394468, Precision = 0.9963649581970193, f1 = 0.9981791697013839\n",
      "Epoch 58: Train Loss = 0.020927288763465515, Recall = 1.0, Aging Rate = 0.5512126678693124, Precision = 0.9967272727272727, f1 = 0.9983609542888363\n",
      "Epoch 59: Train Loss = 0.021094822836862488, Recall = 0.9996351696461145, Aging Rate = 0.5506113449589096, Precision = 0.9974517655624318, f1 = 0.9985422740524781\n",
      "Epoch 60: Train Loss = 0.021012223590561874, Recall = 0.9996351696461145, Aging Rate = 0.5514131088394468, Precision = 0.9960014540167212, f1 = 0.9978150036416606\n",
      "Test Loss = 0.019068668213762352, Recall = 1.0, Aging Rate = 0.5510122268991782, precision = 0.9970898508548564\n",
      "\n",
      "Epoch 61: Train Loss = 0.021207943783449874, Recall = 0.9992703392922291, Aging Rate = 0.5512126678693124, Precision = 0.996, f1 = 0.9976324895283191\n",
      "Epoch 62: Train Loss = 0.020780217439185632, Recall = 0.9996351696461145, Aging Rate = 0.5504109039887753, Precision = 0.9978150036416606, f1 = 0.9987242573355203\n",
      "Epoch 63: Train Loss = 0.02171308827457853, Recall = 0.9996351696461145, Aging Rate = 0.5512126678693124, Precision = 0.9963636363636363, f1 = 0.9979967219085777\n",
      "Epoch 64: Train Loss = 0.020817050839126362, Recall = 0.9996351696461145, Aging Rate = 0.5504109039887753, Precision = 0.9978150036416606, f1 = 0.9987242573355203\n",
      "Epoch 65: Train Loss = 0.02107027371254025, Recall = 1.0, Aging Rate = 0.5520144317498497, Precision = 0.995279593318809, f1 = 0.9976342129208371\n",
      "Test Loss = 0.020306957028037108, Recall = 0.9996351696461145, Aging Rate = 0.5500100220485067, precision = 0.9985422740524781\n",
      "Model in epoch 65 is saved.\n",
      "\n",
      "Epoch 66: Train Loss = 0.020511659859452084, Recall = 0.9996351696461145, Aging Rate = 0.5508117859290439, Precision = 0.9970887918486172, f1 = 0.998360357077792\n",
      "Epoch 67: Train Loss = 0.020330777931282674, Recall = 0.9996351696461145, Aging Rate = 0.5508117859290439, Precision = 0.9970887918486172, f1 = 0.998360357077792\n",
      "Epoch 68: Train Loss = 0.020196148174398406, Recall = 1.0, Aging Rate = 0.5516135498095811, Precision = 0.9960029069767442, f1 = 0.9979974513016566\n",
      "Epoch 69: Train Loss = 0.020546204943077722, Recall = 0.9996351696461145, Aging Rate = 0.5510122268991782, Precision = 0.9967260822117133, f1 = 0.9981785063752276\n",
      "Epoch 70: Train Loss = 0.020828072728742625, Recall = 0.9996351696461145, Aging Rate = 0.5514131088394468, Precision = 0.9960014540167212, f1 = 0.9978150036416606\n",
      "Test Loss = 0.019635671224780372, Recall = 1.0, Aging Rate = 0.5512126678693124, precision = 0.9967272727272727\n",
      "\n",
      "Epoch 71: Train Loss = 0.020572621824462876, Recall = 0.9992703392922291, Aging Rate = 0.5512126678693124, Precision = 0.996, f1 = 0.9976324895283191\n",
      "Epoch 72: Train Loss = 0.020748435129297832, Recall = 0.9996351696461145, Aging Rate = 0.5506113449589096, Precision = 0.9974517655624318, f1 = 0.9985422740524781\n",
      "Epoch 73: Train Loss = 0.020742768757411153, Recall = 1.0, Aging Rate = 0.5518139907797154, Precision = 0.9956411187795132, f1 = 0.9978157990535128\n",
      "Epoch 74: Train Loss = 0.02096267664865911, Recall = 0.9996351696461145, Aging Rate = 0.5508117859290439, Precision = 0.9970887918486172, f1 = 0.998360357077792\n",
      "Epoch 75: Train Loss = 0.020345386962775394, Recall = 0.9996351696461145, Aging Rate = 0.5506113449589096, Precision = 0.9974517655624318, f1 = 0.9985422740524781\n",
      "Test Loss = 0.018568681023968654, Recall = 1.0, Aging Rate = 0.5508117859290439, precision = 0.99745269286754\n",
      "\n",
      "Epoch 76: Train Loss = 0.020553339114063582, Recall = 1.0, Aging Rate = 0.5512126678693124, Precision = 0.9967272727272727, f1 = 0.9983609542888363\n",
      "Epoch 77: Train Loss = 0.02119441287721606, Recall = 0.9996351696461145, Aging Rate = 0.5514131088394468, Precision = 0.9960014540167212, f1 = 0.9978150036416606\n",
      "Epoch 78: Train Loss = 0.020365339872425604, Recall = 0.9996351696461145, Aging Rate = 0.5512126678693124, Precision = 0.9963636363636363, f1 = 0.9979967219085777\n",
      "Epoch 79: Train Loss = 0.0204155224818407, Recall = 0.9996351696461145, Aging Rate = 0.5506113449589096, Precision = 0.9974517655624318, f1 = 0.9985422740524781\n",
      "Epoch 80: Train Loss = 0.020450028769132798, Recall = 1.0, Aging Rate = 0.5516135498095811, Precision = 0.9960029069767442, f1 = 0.9979974513016566\n",
      "Test Loss = 0.01867861107386026, Recall = 1.0, Aging Rate = 0.5516135498095811, precision = 0.9960029069767442\n",
      "\n",
      "Epoch 81: Train Loss = 0.019506019484688556, Recall = 1.0, Aging Rate = 0.5510122268991782, Precision = 0.9970898508548564, f1 = 0.9985428051001822\n",
      "Epoch 82: Train Loss = 0.020372747096213843, Recall = 1.0, Aging Rate = 0.5512126678693124, Precision = 0.9967272727272727, f1 = 0.9983609542888363\n",
      "Epoch 83: Train Loss = 0.02051730002848759, Recall = 0.9996351696461145, Aging Rate = 0.5514131088394468, Precision = 0.9960014540167212, f1 = 0.9978150036416606\n",
      "Epoch 84: Train Loss = 0.019893357167713004, Recall = 0.9996351696461145, Aging Rate = 0.5514131088394468, Precision = 0.9960014540167212, f1 = 0.9978150036416606\n",
      "Epoch 85: Train Loss = 0.020712865531850755, Recall = 0.9996351696461145, Aging Rate = 0.5510122268991782, Precision = 0.9967260822117133, f1 = 0.9981785063752276\n",
      "Test Loss = 0.018929903974727103, Recall = 1.0, Aging Rate = 0.5514131088394468, precision = 0.9963649581970193\n",
      "\n",
      "Epoch 86: Train Loss = 0.02048691316593814, Recall = 1.0, Aging Rate = 0.5514131088394468, Precision = 0.9963649581970193, f1 = 0.9981791697013839\n",
      "Epoch 87: Train Loss = 0.020391680476083786, Recall = 1.0, Aging Rate = 0.5514131088394468, Precision = 0.9963649581970193, f1 = 0.9981791697013839\n",
      "Epoch 88: Train Loss = 0.020054269677797536, Recall = 1.0, Aging Rate = 0.5512126678693124, Precision = 0.9967272727272727, f1 = 0.9983609542888363\n",
      "Epoch 89: Train Loss = 0.019872629244793726, Recall = 0.9996351696461145, Aging Rate = 0.5510122268991782, Precision = 0.9967260822117133, f1 = 0.9981785063752276\n",
      "Epoch 90: Train Loss = 0.020613729462810093, Recall = 1.0, Aging Rate = 0.5518139907797154, Precision = 0.9956411187795132, f1 = 0.9978157990535128\n",
      "Test Loss = 0.018783510372895388, Recall = 1.0, Aging Rate = 0.5504109039887753, precision = 0.9981791697013839\n",
      "\n",
      "Epoch 91: Train Loss = 0.0202856412331771, Recall = 0.9996351696461145, Aging Rate = 0.5508117859290439, Precision = 0.9970887918486172, f1 = 0.998360357077792\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 92: Train Loss = 0.02009058724637081, Recall = 1.0, Aging Rate = 0.5512126678693124, Precision = 0.9967272727272727, f1 = 0.9983609542888363\n",
      "Epoch 93: Train Loss = 0.01995191739349034, Recall = 0.9996351696461145, Aging Rate = 0.5508117859290439, Precision = 0.9970887918486172, f1 = 0.998360357077792\n",
      "Epoch 94: Train Loss = 0.020292137564498, Recall = 1.0, Aging Rate = 0.5516135498095811, Precision = 0.9960029069767442, f1 = 0.9979974513016566\n",
      "Epoch 95: Train Loss = 0.020514957073088053, Recall = 0.9996351696461145, Aging Rate = 0.5510122268991782, Precision = 0.9967260822117133, f1 = 0.9981785063752276\n",
      "Test Loss = 0.01802871683394056, Recall = 1.0, Aging Rate = 0.5510122268991782, precision = 0.9970898508548564\n",
      "\n",
      "Epoch 96: Train Loss = 0.02002834288246958, Recall = 1.0, Aging Rate = 0.5510122268991782, Precision = 0.9970898508548564, f1 = 0.9985428051001822\n",
      "Epoch 97: Train Loss = 0.019987663586797013, Recall = 0.9996351696461145, Aging Rate = 0.5514131088394468, Precision = 0.9960014540167212, f1 = 0.9978150036416606\n",
      "Epoch 98: Train Loss = 0.02006466930448758, Recall = 1.0, Aging Rate = 0.5514131088394468, Precision = 0.9963649581970193, f1 = 0.9981791697013839\n",
      "Epoch 99: Train Loss = 0.01966812936814999, Recall = 0.9996351696461145, Aging Rate = 0.5506113449589096, Precision = 0.9974517655624318, f1 = 0.9985422740524781\n",
      "Epoch 100: Train Loss = 0.020257744514009093, Recall = 1.0, Aging Rate = 0.5508117859290439, Precision = 0.99745269286754, f1 = 0.9987247221716159\n",
      "Test Loss = 0.019701702267306376, Recall = 1.0, Aging Rate = 0.5516135498095811, precision = 0.9960029069767442\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "85bbac2ab0cf4116a79b2feb6bf3b0f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss = 0.548812580839812, Recall = 0.9452754469171835, Aging Rate = 0.9390659450791742, Precision = 0.5530416221985058, f1 = 0.6978184756261783\n",
      "Epoch 2: Train Loss = 0.3942838100566011, Recall = 0.9759211966435607, Aging Rate = 0.8139907797153738, Precision = 0.6587047525240088, f1 = 0.7865333725374889\n",
      "Epoch 3: Train Loss = 0.31481693990007387, Recall = 0.964611455673112, Aging Rate = 0.6919222289035879, Precision = 0.7659327925840093, f1 = 0.8538672694978202\n",
      "Epoch 4: Train Loss = 0.2740783102020373, Recall = 0.9638817949653411, Aging Rate = 0.6652635798757266, Precision = 0.7960228984633926, f1 = 0.871947194719472\n",
      "Epoch 5: Train Loss = 0.24292359160478522, Recall = 0.9671652681503101, Aging Rate = 0.6476247745039087, Precision = 0.8204890126895698, f1 = 0.8878097789685198\n",
      "Test Loss = 0.21917589495358378, Recall = 0.9704487413352791, Aging Rate = 0.6317899378632993, precision = 0.8439086294416244\n",
      "Model in epoch 5 is saved.\n",
      "\n",
      "Epoch 6: Train Loss = 0.20926238553728077, Recall = 0.9719080627508209, Aging Rate = 0.6325917017438364, Precision = 0.844106463878327, f1 = 0.9035102594539597\n",
      "Epoch 7: Train Loss = 0.1829354983934971, Recall = 0.9751915359357899, Aging Rate = 0.6181599518941672, Precision = 0.8667315175097277, f1 = 0.9177682403433476\n",
      "Epoch 8: Train Loss = 0.15934028660911767, Recall = 0.9810288215979569, Aging Rate = 0.6063339346562437, Precision = 0.8889256198347107, f1 = 0.9327089836975372\n",
      "Epoch 9: Train Loss = 0.13842328487452824, Recall = 0.983582634075155, Aging Rate = 0.5955101222689918, Precision = 0.9074385728710872, f1 = 0.9439775910364145\n",
      "Epoch 10: Train Loss = 0.1220753155238023, Recall = 0.9854067858445823, Aging Rate = 0.5864902786129484, Precision = 0.9231032125768968, f1 = 0.9532380448208929\n",
      "Test Loss = 0.11009574168387672, Recall = 0.9854067858445823, Aging Rate = 0.5778713168971737, precision = 0.9368713146028442\n",
      "Model in epoch 10 is saved.\n",
      "\n",
      "Epoch 11: Train Loss = 0.10797751579029714, Recall = 0.9875957679678949, Aging Rate = 0.5802766085387854, Precision = 0.9350604490500863, f1 = 0.9606103619588361\n",
      "Epoch 12: Train Loss = 0.0962912040792658, Recall = 0.990879241152864, Aging Rate = 0.5742633794347565, Precision = 0.9479930191972077, f1 = 0.9689618266143418\n",
      "Epoch 13: Train Loss = 0.08657407649361698, Recall = 0.9923385625684057, Aging Rate = 0.5740629384646222, Precision = 0.9497206703910615, f1 = 0.9705619982158786\n",
      "Epoch 14: Train Loss = 0.07738455742042034, Recall = 0.9930682232761766, Aging Rate = 0.5666466225696533, Precision = 0.9628581535196321, f1 = 0.9777298850574713\n",
      "Epoch 15: Train Loss = 0.07079888812303065, Recall = 0.9934330536300621, Aging Rate = 0.5640408899579074, Precision = 0.9676616915422885, f1 = 0.9803780378037803\n",
      "Test Loss = 0.06383433516887176, Recall = 0.9941627143378329, Aging Rate = 0.5586289837642814, precision = 0.9777538571941156\n",
      "Model in epoch 15 is saved.\n",
      "\n",
      "Epoch 16: Train Loss = 0.06513609508219356, Recall = 0.9945275446917183, Aging Rate = 0.5640408899579074, Precision = 0.968727789623312, f1 = 0.9814581458145814\n",
      "Epoch 17: Train Loss = 0.05911648333353422, Recall = 0.9952572053994893, Aging Rate = 0.5608338344357586, Precision = 0.9749821300929236, f1 = 0.9850153457302762\n",
      "Epoch 18: Train Loss = 0.05599626405345674, Recall = 0.996716526815031, Aging Rate = 0.5612347163760273, Precision = 0.9757142857142858, f1 = 0.9861035914094928\n",
      "Epoch 19: Train Loss = 0.05158298464794751, Recall = 0.9956220357533747, Aging Rate = 0.5582281018240128, Precision = 0.9798922800718133, f1 = 0.9876945349258053\n",
      "Epoch 20: Train Loss = 0.04817354391478517, Recall = 0.9959868661072602, Aging Rate = 0.5588294247344158, Precision = 0.9791965566714491, f1 = 0.9875203472599023\n",
      "Test Loss = 0.04439855536670359, Recall = 0.9963516964611455, Aging Rate = 0.5540188414511926, precision = 0.9880607814761215\n",
      "Model in epoch 20 is saved.\n",
      "\n",
      "Epoch 21: Train Loss = 0.046820524410921674, Recall = 0.996716526815031, Aging Rate = 0.5578272198837443, Precision = 0.9816744520301832, f1 = 0.9891383055756697\n",
      "Epoch 22: Train Loss = 0.04262656107915263, Recall = 0.9974461875228019, Aging Rate = 0.5570254560032071, Precision = 0.9838071248650594, f1 = 0.9905797101449275\n",
      "Epoch 23: Train Loss = 0.041086705738301865, Recall = 0.9974461875228019, Aging Rate = 0.5560232511525356, Precision = 0.9855803893294881, f1 = 0.9914777878513146\n",
      "Epoch 24: Train Loss = 0.0384970900215661, Recall = 0.9981758482305728, Aging Rate = 0.555622369212267, Precision = 0.987012987012987, f1 = 0.9925630328314893\n",
      "Epoch 25: Train Loss = 0.037281991677210524, Recall = 0.9978110178766874, Aging Rate = 0.5554219282421327, Precision = 0.9870083002526164, f1 = 0.9923802612481858\n",
      "Test Loss = 0.03375890677786227, Recall = 0.9989055089383436, Aging Rate = 0.5532170775706554, precision = 0.9920289855072464\n",
      "Model in epoch 25 is saved.\n",
      "\n",
      "Epoch 26: Train Loss = 0.035731707034099794, Recall = 0.9974461875228019, Aging Rate = 0.5530166366005211, Precision = 0.9909387459224357, f1 = 0.9941818181818183\n",
      "Epoch 27: Train Loss = 0.03399686123425353, Recall = 0.9981758482305728, Aging Rate = 0.5534175185407897, Precision = 0.9909453096704093, f1 = 0.994547437295529\n",
      "Epoch 28: Train Loss = 0.03263617825606085, Recall = 0.9992703392922291, Aging Rate = 0.5540188414511926, Precision = 0.9909551374819102, f1 = 0.9950953678474114\n",
      "Epoch 29: Train Loss = 0.03148510650331952, Recall = 0.9989055089383436, Aging Rate = 0.5536179595109241, Precision = 0.9913106444605359, f1 = 0.9950935853170997\n",
      "Epoch 30: Train Loss = 0.030474295091846466, Recall = 0.9992703392922291, Aging Rate = 0.5528161956303869, Precision = 0.9931109499637418, f1 = 0.9961811238406982\n",
      "Test Loss = 0.02813471628416096, Recall = 0.9996351696461145, Aging Rate = 0.5528161956303869, precision = 0.9934735315445975\n",
      "Model in epoch 30 is saved.\n",
      "\n",
      "Epoch 31: Train Loss = 0.0295002004566628, Recall = 0.9989055089383436, Aging Rate = 0.5520144317498497, Precision = 0.9941902687000727, f1 = 0.9965423111919928\n",
      "Epoch 32: Train Loss = 0.028968939675276924, Recall = 0.9996351696461145, Aging Rate = 0.5528161956303869, Precision = 0.9934735315445975, f1 = 0.9965448263320604\n",
      "Epoch 33: Train Loss = 0.028137926542435174, Recall = 0.9989055089383436, Aging Rate = 0.5524153136901183, Precision = 0.9934687953555879, f1 = 0.9961797344005822\n",
      "Epoch 34: Train Loss = 0.027463616052480804, Recall = 0.9996351696461145, Aging Rate = 0.5520144317498497, Precision = 0.9949164851125636, f1 = 0.997270245677889\n",
      "Epoch 35: Train Loss = 0.026771107757616004, Recall = 0.9989055089383436, Aging Rate = 0.5518139907797154, Precision = 0.9945513984743916, f1 = 0.9967236985802693\n",
      "Test Loss = 0.024403609630369333, Recall = 1.0, Aging Rate = 0.5522148727199839, precision = 0.9949183303085299\n",
      "Model in epoch 35 is saved.\n",
      "\n",
      "Epoch 36: Train Loss = 0.026588779142192525, Recall = 0.9992703392922291, Aging Rate = 0.5514131088394468, Precision = 0.9956379498364231, f1 = 0.9974508375819373\n",
      "Epoch 37: Train Loss = 0.025282456102564643, Recall = 1.0, Aging Rate = 0.5526157546602526, Precision = 0.9941965904969169, f1 = 0.9970898508548564\n",
      "Epoch 38: Train Loss = 0.02497852422889881, Recall = 0.9992703392922291, Aging Rate = 0.5522148727199839, Precision = 0.9941923774954627, f1 = 0.9967248908296942\n",
      "Epoch 39: Train Loss = 0.025346390681225926, Recall = 0.9992703392922291, Aging Rate = 0.5520144317498497, Precision = 0.9945533769063181, f1 = 0.9969062784349408\n",
      "Epoch 40: Train Loss = 0.02416214119515287, Recall = 0.9996351696461145, Aging Rate = 0.5514131088394468, Precision = 0.9960014540167212, f1 = 0.9978150036416606\n",
      "Test Loss = 0.02204796531524955, Recall = 1.0, Aging Rate = 0.5518139907797154, precision = 0.9956411187795132\n",
      "Model in epoch 40 is saved.\n",
      "\n",
      "Epoch 41: Train Loss = 0.0244102317572542, Recall = 0.9989055089383436, Aging Rate = 0.5514131088394468, Precision = 0.995274445656125, f1 = 0.997086671522214\n",
      "Epoch 42: Train Loss = 0.02385399238023318, Recall = 1.0, Aging Rate = 0.5520144317498497, Precision = 0.995279593318809, f1 = 0.9976342129208371\n",
      "Epoch 43: Train Loss = 0.023361811250086822, Recall = 1.0, Aging Rate = 0.5516135498095811, Precision = 0.9960029069767442, f1 = 0.9979974513016566\n",
      "Epoch 44: Train Loss = 0.023278318768552728, Recall = 1.0, Aging Rate = 0.5514131088394468, Precision = 0.9963649581970193, f1 = 0.9981791697013839\n",
      "Epoch 45: Train Loss = 0.022639755370186098, Recall = 1.0, Aging Rate = 0.5520144317498497, Precision = 0.995279593318809, f1 = 0.9976342129208371\n",
      "Test Loss = 0.022592370929806906, Recall = 0.9992703392922291, Aging Rate = 0.5500100220485067, precision = 0.9981778425655977\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model in epoch 45 is saved.\n",
      "\n",
      "Epoch 46: Train Loss = 0.023040619401956015, Recall = 0.9996351696461145, Aging Rate = 0.5516135498095811, Precision = 0.9956395348837209, f1 = 0.9976333515383214\n",
      "Epoch 47: Train Loss = 0.022187582279319728, Recall = 1.0, Aging Rate = 0.5512126678693124, Precision = 0.9967272727272727, f1 = 0.9983609542888363\n",
      "Epoch 48: Train Loss = 0.021821677858018522, Recall = 0.9996351696461145, Aging Rate = 0.5512126678693124, Precision = 0.9963636363636363, f1 = 0.9979967219085777\n",
      "Epoch 49: Train Loss = 0.022297791547522226, Recall = 1.0, Aging Rate = 0.5510122268991782, Precision = 0.9970898508548564, f1 = 0.9985428051001822\n",
      "Epoch 50: Train Loss = 0.021766995052747484, Recall = 1.0, Aging Rate = 0.5516135498095811, Precision = 0.9960029069767442, f1 = 0.9979974513016566\n",
      "Test Loss = 0.020502859490217393, Recall = 1.0, Aging Rate = 0.5500100220485067, precision = 0.9989067055393586\n",
      "Model in epoch 50 is saved.\n",
      "\n",
      "Epoch 51: Train Loss = 0.02177084563832038, Recall = 1.0, Aging Rate = 0.5514131088394468, Precision = 0.9963649581970193, f1 = 0.9981791697013839\n",
      "Epoch 52: Train Loss = 0.02167459332105463, Recall = 0.9992703392922291, Aging Rate = 0.5520144317498497, Precision = 0.9945533769063181, f1 = 0.9969062784349408\n",
      "Epoch 53: Train Loss = 0.021161429077389843, Recall = 1.0, Aging Rate = 0.5512126678693124, Precision = 0.9967272727272727, f1 = 0.9983609542888363\n",
      "Epoch 54: Train Loss = 0.020924238113234316, Recall = 1.0, Aging Rate = 0.5508117859290439, Precision = 0.99745269286754, f1 = 0.9987247221716159\n",
      "Epoch 55: Train Loss = 0.02189612725848923, Recall = 0.9992703392922291, Aging Rate = 0.5508117859290439, Precision = 0.9967248908296943, f1 = 0.9979959919839678\n",
      "Test Loss = 0.019176969372257248, Recall = 1.0, Aging Rate = 0.5506113449589096, precision = 0.9978157990535129\n",
      "\n",
      "Epoch 56: Train Loss = 0.02110099172942814, Recall = 0.9996351696461145, Aging Rate = 0.5512126678693124, Precision = 0.9963636363636363, f1 = 0.9979967219085777\n",
      "Epoch 57: Train Loss = 0.020848523898210358, Recall = 0.9996351696461145, Aging Rate = 0.5508117859290439, Precision = 0.9970887918486172, f1 = 0.998360357077792\n",
      "Epoch 58: Train Loss = 0.02060539190470575, Recall = 1.0, Aging Rate = 0.5508117859290439, Precision = 0.99745269286754, f1 = 0.9987247221716159\n",
      "Epoch 59: Train Loss = 0.02011228497887744, Recall = 1.0, Aging Rate = 0.5512126678693124, Precision = 0.9967272727272727, f1 = 0.9983609542888363\n",
      "Epoch 60: Train Loss = 0.021106614767467183, Recall = 0.9996351696461145, Aging Rate = 0.5500100220485067, Precision = 0.9985422740524781, f1 = 0.9990884229717412\n",
      "Test Loss = 0.01967451994498308, Recall = 1.0, Aging Rate = 0.5512126678693124, precision = 0.9967272727272727\n",
      "\n",
      "Epoch 61: Train Loss = 0.020546302942704358, Recall = 1.0, Aging Rate = 0.5514131088394468, Precision = 0.9963649581970193, f1 = 0.9981791697013839\n",
      "Epoch 62: Train Loss = 0.020842661225776632, Recall = 0.9996351696461145, Aging Rate = 0.5506113449589096, Precision = 0.9974517655624318, f1 = 0.9985422740524781\n",
      "Epoch 63: Train Loss = 0.02035759567339283, Recall = 0.9996351696461145, Aging Rate = 0.5506113449589096, Precision = 0.9974517655624318, f1 = 0.9985422740524781\n",
      "Epoch 64: Train Loss = 0.020289423602404873, Recall = 1.0, Aging Rate = 0.5516135498095811, Precision = 0.9960029069767442, f1 = 0.9979974513016566\n",
      "Epoch 65: Train Loss = 0.02031242320122521, Recall = 1.0, Aging Rate = 0.5504109039887753, Precision = 0.9981791697013839, f1 = 0.9990887552396573\n",
      "Test Loss = 0.018792331153569836, Recall = 1.0, Aging Rate = 0.5504109039887753, precision = 0.9981791697013839\n",
      "\n",
      "Epoch 66: Train Loss = 0.02016609038326551, Recall = 1.0, Aging Rate = 0.5518139907797154, Precision = 0.9956411187795132, f1 = 0.9978157990535128\n",
      "Epoch 67: Train Loss = 0.019942734848038123, Recall = 1.0, Aging Rate = 0.5508117859290439, Precision = 0.99745269286754, f1 = 0.9987247221716159\n",
      "Epoch 68: Train Loss = 0.02016222095469789, Recall = 0.9996351696461145, Aging Rate = 0.5508117859290439, Precision = 0.9970887918486172, f1 = 0.998360357077792\n",
      "Epoch 69: Train Loss = 0.020015825086815917, Recall = 1.0, Aging Rate = 0.5508117859290439, Precision = 0.99745269286754, f1 = 0.9987247221716159\n",
      "Epoch 70: Train Loss = 0.02008889054334081, Recall = 1.0, Aging Rate = 0.5508117859290439, Precision = 0.99745269286754, f1 = 0.9987247221716159\n",
      "Test Loss = 0.018381529864193346, Recall = 1.0, Aging Rate = 0.5500100220485067, precision = 0.9989067055393586\n",
      "\n",
      "Epoch 71: Train Loss = 0.019964667718493884, Recall = 0.9996351696461145, Aging Rate = 0.5506113449589096, Precision = 0.9974517655624318, f1 = 0.9985422740524781\n",
      "Epoch 72: Train Loss = 0.019902398353929773, Recall = 0.9996351696461145, Aging Rate = 0.5510122268991782, Precision = 0.9967260822117133, f1 = 0.9981785063752276\n",
      "Epoch 73: Train Loss = 0.019701111574890046, Recall = 1.0, Aging Rate = 0.5508117859290439, Precision = 0.99745269286754, f1 = 0.9987247221716159\n",
      "Epoch 74: Train Loss = 0.019886181212096996, Recall = 1.0, Aging Rate = 0.5508117859290439, Precision = 0.99745269286754, f1 = 0.9987247221716159\n",
      "Epoch 75: Train Loss = 0.019905302795290493, Recall = 0.9996351696461145, Aging Rate = 0.5506113449589096, Precision = 0.9974517655624318, f1 = 0.9985422740524781\n",
      "Test Loss = 0.021008862263701692, Recall = 1.0, Aging Rate = 0.5514131088394468, precision = 0.9963649581970193\n",
      "\n",
      "Epoch 76: Train Loss = 0.02003524498706006, Recall = 1.0, Aging Rate = 0.5500100220485067, Precision = 0.9989067055393586, f1 = 0.9994530537830446\n",
      "Epoch 77: Train Loss = 0.019961848120265028, Recall = 1.0, Aging Rate = 0.5510122268991782, Precision = 0.9970898508548564, f1 = 0.9985428051001822\n",
      "Epoch 78: Train Loss = 0.019570255927602642, Recall = 1.0, Aging Rate = 0.5510122268991782, Precision = 0.9970898508548564, f1 = 0.9985428051001822\n",
      "Epoch 79: Train Loss = 0.02007818744941802, Recall = 0.9996351696461145, Aging Rate = 0.5510122268991782, Precision = 0.9967260822117133, f1 = 0.9981785063752276\n",
      "Epoch 80: Train Loss = 0.0197890548908769, Recall = 1.0, Aging Rate = 0.5506113449589096, Precision = 0.9978157990535129, f1 = 0.9989067055393587\n",
      "Test Loss = 0.018073696630046827, Recall = 1.0, Aging Rate = 0.5508117859290439, precision = 0.99745269286754\n",
      "\n",
      "Epoch 81: Train Loss = 0.019332095540464105, Recall = 1.0, Aging Rate = 0.550210463018641, Precision = 0.9985428051001821, f1 = 0.999270871308786\n",
      "Epoch 82: Train Loss = 0.019136478333484017, Recall = 1.0, Aging Rate = 0.5506113449589096, Precision = 0.9978157990535129, f1 = 0.9989067055393587\n",
      "Epoch 83: Train Loss = 0.019685976297607113, Recall = 0.9996351696461145, Aging Rate = 0.5510122268991782, Precision = 0.9967260822117133, f1 = 0.9981785063752276\n",
      "Epoch 84: Train Loss = 0.019965924424156442, Recall = 1.0, Aging Rate = 0.5504109039887753, Precision = 0.9981791697013839, f1 = 0.9990887552396573\n",
      "Epoch 85: Train Loss = 0.01970802297254535, Recall = 1.0, Aging Rate = 0.5504109039887753, Precision = 0.9981791697013839, f1 = 0.9990887552396573\n",
      "Test Loss = 0.018131490217737956, Recall = 1.0, Aging Rate = 0.5506113449589096, precision = 0.9978157990535129\n",
      "\n",
      "Epoch 86: Train Loss = 0.01951861620363013, Recall = 0.9996351696461145, Aging Rate = 0.5508117859290439, Precision = 0.9970887918486172, f1 = 0.998360357077792\n",
      "Epoch 87: Train Loss = 0.01955030628383506, Recall = 1.0, Aging Rate = 0.5508117859290439, Precision = 0.99745269286754, f1 = 0.9987247221716159\n",
      "Epoch 88: Train Loss = 0.01927400375314103, Recall = 1.0, Aging Rate = 0.5504109039887753, Precision = 0.9981791697013839, f1 = 0.9990887552396573\n",
      "Epoch 89: Train Loss = 0.019365313578091636, Recall = 0.9996351696461145, Aging Rate = 0.5512126678693124, Precision = 0.9963636363636363, f1 = 0.9979967219085777\n",
      "Epoch 90: Train Loss = 0.019493985959972926, Recall = 1.0, Aging Rate = 0.5510122268991782, Precision = 0.9970898508548564, f1 = 0.9985428051001822\n",
      "Test Loss = 0.018715872014332304, Recall = 1.0, Aging Rate = 0.5510122268991782, precision = 0.9970898508548564\n",
      "\n",
      "Epoch 91: Train Loss = 0.019523688737063328, Recall = 1.0, Aging Rate = 0.5504109039887753, Precision = 0.9981791697013839, f1 = 0.9990887552396573\n",
      "Epoch 92: Train Loss = 0.0196225609623626, Recall = 0.9996351696461145, Aging Rate = 0.5512126678693124, Precision = 0.9963636363636363, f1 = 0.9979967219085777\n",
      "Epoch 93: Train Loss = 0.020101659440100013, Recall = 1.0, Aging Rate = 0.5510122268991782, Precision = 0.9970898508548564, f1 = 0.9985428051001822\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 94: Train Loss = 0.019650723795242433, Recall = 1.0, Aging Rate = 0.5508117859290439, Precision = 0.99745269286754, f1 = 0.9987247221716159\n",
      "Epoch 95: Train Loss = 0.01945113149350429, Recall = 1.0, Aging Rate = 0.5512126678693124, Precision = 0.9967272727272727, f1 = 0.9983609542888363\n",
      "Test Loss = 0.017853988636203678, Recall = 1.0, Aging Rate = 0.5500100220485067, precision = 0.9989067055393586\n",
      "\n",
      "Epoch 96: Train Loss = 0.020062616528406678, Recall = 1.0, Aging Rate = 0.5504109039887753, Precision = 0.9981791697013839, f1 = 0.9990887552396573\n",
      "Epoch 97: Train Loss = 0.019157593939539235, Recall = 1.0, Aging Rate = 0.5514131088394468, Precision = 0.9963649581970193, f1 = 0.9981791697013839\n",
      "Epoch 98: Train Loss = 0.019596399904405527, Recall = 1.0, Aging Rate = 0.5504109039887753, Precision = 0.9981791697013839, f1 = 0.9990887552396573\n",
      "Epoch 99: Train Loss = 0.02024569841709207, Recall = 0.9996351696461145, Aging Rate = 0.5512126678693124, Precision = 0.9963636363636363, f1 = 0.9979967219085777\n",
      "Epoch 100: Train Loss = 0.019457569311110284, Recall = 0.9996351696461145, Aging Rate = 0.5506113449589096, Precision = 0.9974517655624318, f1 = 0.9985422740524781\n",
      "Test Loss = 0.01741932784288369, Recall = 1.0, Aging Rate = 0.5504109039887753, precision = 0.9981791697013839\n",
      "\n",
      "Training Finished at epoch 100.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee397fc17713438494cefa882c6a9148",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss = 0.5299650883180007, Recall = 0.983582634075155, Aging Rate = 0.9775506113449589, Precision = 0.5527988517531269, f1 = 0.707797322131793\n",
      "Epoch 2: Train Loss = 0.3822768945198399, Recall = 0.9813936519518424, Aging Rate = 0.7989577069553017, Precision = 0.6748620170597089, f1 = 0.7997621525196967\n",
      "Epoch 3: Train Loss = 0.3062312095180545, Recall = 0.961327982488143, Aging Rate = 0.683904590098216, Precision = 0.772274325908558, f1 = 0.8564927677555665\n",
      "Epoch 4: Train Loss = 0.26630131256654427, Recall = 0.9668004377964247, Aging Rate = 0.6630587292042494, Precision = 0.8010882708585247, f1 = 0.8761778806414282\n",
      "Epoch 5: Train Loss = 0.23636995265206204, Recall = 0.9686245895658518, Aging Rate = 0.6396071356985368, Precision = 0.8320275775618928, f1 = 0.8951449763991908\n",
      "Test Loss = 0.2083576513802654, Recall = 0.974461875228019, Aging Rate = 0.6357987572659851, precision = 0.8420554854981085\n",
      "Model in epoch 5 is saved.\n",
      "\n",
      "Epoch 6: Train Loss = 0.19905553512629154, Recall = 0.9722728931047063, Aging Rate = 0.6249749448787332, Precision = 0.8547145606157793, f1 = 0.9097115548728453\n",
      "Epoch 7: Train Loss = 0.17195003979859358, Recall = 0.9740970448741335, Aging Rate = 0.6055321707757065, Precision = 0.8838133068520357, f1 = 0.9267615411315515\n",
      "Epoch 8: Train Loss = 0.15131263065419376, Recall = 0.9788398394746443, Aging Rate = 0.5993185007015434, Precision = 0.8973244147157191, f1 = 0.9363112894782761\n",
      "Epoch 9: Train Loss = 0.13302728975493006, Recall = 0.983582634075155, Aging Rate = 0.5927039486871116, Precision = 0.9117348664186675, f1 = 0.9462969462969463\n",
      "Epoch 10: Train Loss = 0.11849535695385613, Recall = 0.986866107260124, Aging Rate = 0.5858889557025456, Precision = 0.925419089976052, f1 = 0.9551553672316384\n",
      "Test Loss = 0.10793782237937345, Recall = 0.986866107260124, Aging Rate = 0.5802766085387854, precision = 0.9343696027633851\n",
      "Model in epoch 10 is saved.\n",
      "\n",
      "Epoch 11: Train Loss = 0.10655547435344831, Recall = 0.9894199197373221, Aging Rate = 0.5830827821206654, Precision = 0.9322791337229288, f1 = 0.96\n",
      "Epoch 12: Train Loss = 0.09755916217269962, Recall = 0.9886902590295512, Aging Rate = 0.5768691120465023, Precision = 0.9416261292564281, f1 = 0.9645844456308952\n",
      "Epoch 13: Train Loss = 0.08794638602629433, Recall = 0.9923385625684057, Aging Rate = 0.5760673481659652, Precision = 0.9464161447459986, f1 = 0.968833481745325\n",
      "Epoch 14: Train Loss = 0.08033992518258491, Recall = 0.9912440715067493, Aging Rate = 0.5708558829424735, Precision = 0.954002808988764, f1 = 0.9722669529432814\n",
      "Epoch 15: Train Loss = 0.0751241479127984, Recall = 0.9956220357533747, Aging Rate = 0.5704550010022048, Precision = 0.9588896697118763, f1 = 0.976910685519957\n",
      "Test Loss = 0.06786601883533795, Recall = 0.996716526815031, Aging Rate = 0.571256764882742, precision = 0.9585964912280702\n",
      "Model in epoch 15 is saved.\n",
      "\n",
      "Epoch 16: Train Loss = 0.06883289260869276, Recall = 0.9941627143378329, Aging Rate = 0.5662457406293846, Precision = 0.9646017699115044, f1 = 0.9791591807402084\n",
      "Epoch 17: Train Loss = 0.06330955304738561, Recall = 0.9941627143378329, Aging Rate = 0.5638404489877731, Precision = 0.9687166725915393, f1 = 0.981274756931941\n",
      "Epoch 18: Train Loss = 0.059314812306747046, Recall = 0.9948923750456038, Aging Rate = 0.5620364802565645, Precision = 0.9725392296718973, f1 = 0.9835888187556358\n",
      "Epoch 19: Train Loss = 0.055049915206434735, Recall = 0.9959868661072602, Aging Rate = 0.5606333934656244, Precision = 0.9760457633178405, f1 = 0.9859154929577465\n",
      "Epoch 20: Train Loss = 0.05292130671673032, Recall = 0.9963516964611455, Aging Rate = 0.5612347163760273, Precision = 0.9753571428571428, f1 = 0.9857426457318174\n",
      "Test Loss = 0.047548314082697794, Recall = 0.9978110178766874, Aging Rate = 0.5574263379434756, precision = 0.9834591873426825\n",
      "Model in epoch 20 is saved.\n",
      "\n",
      "Epoch 21: Train Loss = 0.04880452500221294, Recall = 0.996716526815031, Aging Rate = 0.55902986570455, Precision = 0.9795625672283973, f1 = 0.9880650994575045\n",
      "Epoch 22: Train Loss = 0.046527840129883265, Recall = 0.9970813571689164, Aging Rate = 0.5582281018240128, Precision = 0.9813285457809695, f1 = 0.98914223669924\n",
      "Epoch 23: Train Loss = 0.043885452764683364, Recall = 0.9978110178766874, Aging Rate = 0.5566245740629384, Precision = 0.98487576521426, f1 = 0.9913011960855382\n",
      "Epoch 24: Train Loss = 0.041882650525357494, Recall = 0.9978110178766874, Aging Rate = 0.5570254560032071, Precision = 0.9841669665347247, f1 = 0.9909420289855072\n",
      "Epoch 25: Train Loss = 0.043053376643888024, Recall = 0.9974461875228019, Aging Rate = 0.5570254560032071, Precision = 0.9838071248650594, f1 = 0.9905797101449275\n",
      "Test Loss = 0.037449745281016474, Recall = 0.9992703392922291, Aging Rate = 0.5576267789136099, precision = 0.9845434938892883\n",
      "Model in epoch 25 is saved.\n",
      "\n",
      "Epoch 26: Train Loss = 0.03779655633209392, Recall = 0.9978110178766874, Aging Rate = 0.5550210463018641, Precision = 0.9877211989888046, f1 = 0.9927404718693285\n",
      "Epoch 27: Train Loss = 0.03658601245007503, Recall = 0.9989055089383436, Aging Rate = 0.5542192824213269, Precision = 0.9902350813743219, f1 = 0.9945513984743916\n",
      "Epoch 28: Train Loss = 0.0356976178658226, Recall = 0.9985406785844583, Aging Rate = 0.5550210463018641, Precision = 0.9884434814012278, f1 = 0.9934664246823957\n",
      "Epoch 29: Train Loss = 0.034177524468692204, Recall = 0.9992703392922291, Aging Rate = 0.5538184004810583, Precision = 0.991313789359392, f1 = 0.9952761627906976\n",
      "Epoch 30: Train Loss = 0.03263004308300999, Recall = 0.9996351696461145, Aging Rate = 0.5542192824213269, Precision = 0.9909584086799277, f1 = 0.995277878677806\n",
      "Test Loss = 0.03062688191618272, Recall = 0.9992703392922291, Aging Rate = 0.5518139907797154, precision = 0.9949146385760989\n",
      "Model in epoch 30 is saved.\n",
      "\n",
      "Epoch 31: Train Loss = 0.03197565776258438, Recall = 0.9989055089383436, Aging Rate = 0.5538184004810583, Precision = 0.9909518639160333, f1 = 0.9949127906976744\n",
      "Epoch 32: Train Loss = 0.03144285647360218, Recall = 0.9996351696461145, Aging Rate = 0.5534175185407897, Precision = 0.9923940601231438, f1 = 0.9960014540167212\n",
      "Epoch 33: Train Loss = 0.03056952453168558, Recall = 0.9996351696461145, Aging Rate = 0.5530166366005211, Precision = 0.9931134469010511, f1 = 0.9963636363636365\n",
      "Epoch 34: Train Loss = 0.02994348424548232, Recall = 0.9996351696461145, Aging Rate = 0.5530166366005211, Precision = 0.9931134469010511, f1 = 0.9963636363636365\n",
      "Epoch 35: Train Loss = 0.02923845202455028, Recall = 0.9992703392922291, Aging Rate = 0.5532170775706554, Precision = 0.9923913043478261, f1 = 0.9958189420105436\n",
      "Test Loss = 0.02645398230503033, Recall = 1.0, Aging Rate = 0.5522148727199839, precision = 0.9949183303085299\n",
      "Model in epoch 35 is saved.\n",
      "\n",
      "Epoch 36: Train Loss = 0.028440163926105506, Recall = 0.9996351696461145, Aging Rate = 0.5522148727199839, Precision = 0.9945553539019963, f1 = 0.9970887918486172\n",
      "Epoch 37: Train Loss = 0.027549644710380704, Recall = 1.0, Aging Rate = 0.5528161956303869, Precision = 0.9938361131254533, f1 = 0.9969085288234224\n",
      "Epoch 38: Train Loss = 0.027023377215445316, Recall = 1.0, Aging Rate = 0.5522148727199839, Precision = 0.9949183303085299, f1 = 0.99745269286754\n",
      "Epoch 39: Train Loss = 0.02637899904400797, Recall = 1.0, Aging Rate = 0.5522148727199839, Precision = 0.9949183303085299, f1 = 0.99745269286754\n",
      "Epoch 40: Train Loss = 0.02669909397820763, Recall = 0.9996351696461145, Aging Rate = 0.5522148727199839, Precision = 0.9945553539019963, f1 = 0.9970887918486172\n",
      "Test Loss = 0.025772050476699657, Recall = 1.0, Aging Rate = 0.5532170775706554, precision = 0.9931159420289855\n",
      "\n",
      "Epoch 41: Train Loss = 0.025471270405275772, Recall = 1.0, Aging Rate = 0.5528161956303869, Precision = 0.9938361131254533, f1 = 0.9969085288234224\n",
      "Epoch 42: Train Loss = 0.026153703994330674, Recall = 1.0, Aging Rate = 0.5528161956303869, Precision = 0.9938361131254533, f1 = 0.9969085288234224\n",
      "Epoch 43: Train Loss = 0.025402273048267237, Recall = 0.9992703392922291, Aging Rate = 0.5522148727199839, Precision = 0.9941923774954627, f1 = 0.9967248908296942\n",
      "Epoch 44: Train Loss = 0.025220567270542917, Recall = 1.0, Aging Rate = 0.5524153136901183, Precision = 0.9945573294629898, f1 = 0.9972712388575588\n",
      "Epoch 45: Train Loss = 0.024544017047614403, Recall = 0.9996351696461145, Aging Rate = 0.5518139907797154, Precision = 0.995277878677806, f1 = 0.9974517655624318\n",
      "Test Loss = 0.022979233803712525, Recall = 1.0, Aging Rate = 0.5506113449589096, precision = 0.9978157990535129\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model in epoch 45 is saved.\n",
      "\n",
      "Epoch 46: Train Loss = 0.02456483740481257, Recall = 1.0, Aging Rate = 0.5520144317498497, Precision = 0.995279593318809, f1 = 0.9976342129208371\n",
      "Epoch 47: Train Loss = 0.024233047419396973, Recall = 1.0, Aging Rate = 0.5518139907797154, Precision = 0.9956411187795132, f1 = 0.9978157990535128\n",
      "Epoch 48: Train Loss = 0.024108207633012843, Recall = 0.9996351696461145, Aging Rate = 0.5512126678693124, Precision = 0.9963636363636363, f1 = 0.9979967219085777\n",
      "Epoch 49: Train Loss = 0.023499415581831235, Recall = 1.0, Aging Rate = 0.5518139907797154, Precision = 0.9956411187795132, f1 = 0.9978157990535128\n",
      "Epoch 50: Train Loss = 0.02419511766648407, Recall = 0.9996351696461145, Aging Rate = 0.5518139907797154, Precision = 0.995277878677806, f1 = 0.9974517655624318\n",
      "Test Loss = 0.02216249550577932, Recall = 1.0, Aging Rate = 0.5514131088394468, precision = 0.9963649581970193\n",
      "\n",
      "Epoch 51: Train Loss = 0.023154272132800132, Recall = 0.9996351696461145, Aging Rate = 0.5510122268991782, Precision = 0.9967260822117133, f1 = 0.9981785063752276\n",
      "Epoch 52: Train Loss = 0.023371883773850306, Recall = 1.0, Aging Rate = 0.5518139907797154, Precision = 0.9956411187795132, f1 = 0.9978157990535128\n",
      "Epoch 53: Train Loss = 0.023326015599052567, Recall = 0.9996351696461145, Aging Rate = 0.5518139907797154, Precision = 0.995277878677806, f1 = 0.9974517655624318\n",
      "Epoch 54: Train Loss = 0.02297901773276836, Recall = 1.0, Aging Rate = 0.5522148727199839, Precision = 0.9949183303085299, f1 = 0.99745269286754\n",
      "Epoch 55: Train Loss = 0.022880294393261943, Recall = 0.9996351696461145, Aging Rate = 0.5510122268991782, Precision = 0.9967260822117133, f1 = 0.9981785063752276\n",
      "Test Loss = 0.021124559737432814, Recall = 1.0, Aging Rate = 0.5506113449589096, precision = 0.9978157990535129\n",
      "\n",
      "Epoch 56: Train Loss = 0.022266517873979638, Recall = 1.0, Aging Rate = 0.5518139907797154, Precision = 0.9956411187795132, f1 = 0.9978157990535128\n",
      "Epoch 57: Train Loss = 0.02239546791655395, Recall = 1.0, Aging Rate = 0.5516135498095811, Precision = 0.9960029069767442, f1 = 0.9979974513016566\n",
      "Epoch 58: Train Loss = 0.02258764098494152, Recall = 0.9996351696461145, Aging Rate = 0.5512126678693124, Precision = 0.9963636363636363, f1 = 0.9979967219085777\n",
      "Epoch 59: Train Loss = 0.022120233983589952, Recall = 1.0, Aging Rate = 0.5516135498095811, Precision = 0.9960029069767442, f1 = 0.9979974513016566\n",
      "Epoch 60: Train Loss = 0.021874581624735667, Recall = 0.9996351696461145, Aging Rate = 0.5510122268991782, Precision = 0.9967260822117133, f1 = 0.9981785063752276\n",
      "Test Loss = 0.0201977714347377, Recall = 1.0, Aging Rate = 0.5512126678693124, precision = 0.9967272727272727\n",
      "\n",
      "Epoch 61: Train Loss = 0.021864148081961843, Recall = 1.0, Aging Rate = 0.5514131088394468, Precision = 0.9963649581970193, f1 = 0.9981791697013839\n",
      "Epoch 62: Train Loss = 0.022609623232294502, Recall = 0.9996351696461145, Aging Rate = 0.5508117859290439, Precision = 0.9970887918486172, f1 = 0.998360357077792\n",
      "Epoch 63: Train Loss = 0.02220478895465485, Recall = 1.0, Aging Rate = 0.5522148727199839, Precision = 0.9949183303085299, f1 = 0.99745269286754\n",
      "Epoch 64: Train Loss = 0.022330389288473425, Recall = 0.9996351696461145, Aging Rate = 0.5510122268991782, Precision = 0.9967260822117133, f1 = 0.9981785063752276\n",
      "Epoch 65: Train Loss = 0.021631085288095424, Recall = 1.0, Aging Rate = 0.5518139907797154, Precision = 0.9956411187795132, f1 = 0.9978157990535128\n",
      "Test Loss = 0.01953417202280444, Recall = 1.0, Aging Rate = 0.5510122268991782, precision = 0.9970898508548564\n",
      "\n",
      "Epoch 66: Train Loss = 0.021932382500226617, Recall = 1.0, Aging Rate = 0.5514131088394468, Precision = 0.9963649581970193, f1 = 0.9981791697013839\n",
      "Epoch 67: Train Loss = 0.021681761881345903, Recall = 1.0, Aging Rate = 0.5518139907797154, Precision = 0.9956411187795132, f1 = 0.9978157990535128\n",
      "Epoch 68: Train Loss = 0.02154211397287446, Recall = 1.0, Aging Rate = 0.5514131088394468, Precision = 0.9963649581970193, f1 = 0.9981791697013839\n",
      "Epoch 69: Train Loss = 0.0212557402458643, Recall = 1.0, Aging Rate = 0.5516135498095811, Precision = 0.9960029069767442, f1 = 0.9979974513016566\n",
      "Epoch 70: Train Loss = 0.021621743243991864, Recall = 0.9996351696461145, Aging Rate = 0.5520144317498497, Precision = 0.9949164851125636, f1 = 0.997270245677889\n",
      "Test Loss = 0.0206635145346921, Recall = 1.0, Aging Rate = 0.5500100220485067, precision = 0.9989067055393586\n",
      "Model in epoch 70 is saved.\n",
      "\n",
      "Epoch 71: Train Loss = 0.0219391252909742, Recall = 1.0, Aging Rate = 0.5518139907797154, Precision = 0.9956411187795132, f1 = 0.9978157990535128\n",
      "Epoch 72: Train Loss = 0.021367188862295876, Recall = 1.0, Aging Rate = 0.5512126678693124, Precision = 0.9967272727272727, f1 = 0.9983609542888363\n",
      "Epoch 73: Train Loss = 0.021647836558452097, Recall = 0.9996351696461145, Aging Rate = 0.5516135498095811, Precision = 0.9956395348837209, f1 = 0.9976333515383214\n",
      "Epoch 74: Train Loss = 0.021049709012255887, Recall = 1.0, Aging Rate = 0.5512126678693124, Precision = 0.9967272727272727, f1 = 0.9983609542888363\n",
      "Epoch 75: Train Loss = 0.020926699848010415, Recall = 1.0, Aging Rate = 0.5510122268991782, Precision = 0.9970898508548564, f1 = 0.9985428051001822\n",
      "Test Loss = 0.01964192435826369, Recall = 1.0, Aging Rate = 0.5508117859290439, precision = 0.99745269286754\n",
      "\n",
      "Epoch 76: Train Loss = 0.021083687801913883, Recall = 1.0, Aging Rate = 0.5516135498095811, Precision = 0.9960029069767442, f1 = 0.9979974513016566\n",
      "Epoch 77: Train Loss = 0.020360478082599706, Recall = 1.0, Aging Rate = 0.5508117859290439, Precision = 0.99745269286754, f1 = 0.9987247221716159\n",
      "Epoch 78: Train Loss = 0.020995962378821145, Recall = 1.0, Aging Rate = 0.5512126678693124, Precision = 0.9967272727272727, f1 = 0.9983609542888363\n",
      "Epoch 79: Train Loss = 0.021650518303205767, Recall = 1.0, Aging Rate = 0.5514131088394468, Precision = 0.9963649581970193, f1 = 0.9981791697013839\n",
      "Epoch 80: Train Loss = 0.022178994227364274, Recall = 0.9996351696461145, Aging Rate = 0.5516135498095811, Precision = 0.9956395348837209, f1 = 0.9976333515383214\n",
      "Test Loss = 0.019644637606884202, Recall = 1.0, Aging Rate = 0.5504109039887753, precision = 0.9981791697013839\n",
      "\n",
      "Epoch 81: Train Loss = 0.02125119440064154, Recall = 0.9996351696461145, Aging Rate = 0.5516135498095811, Precision = 0.9956395348837209, f1 = 0.9976333515383214\n",
      "Epoch 82: Train Loss = 0.022103121569150553, Recall = 0.9992703392922291, Aging Rate = 0.5504109039887753, Precision = 0.9974508375819373, f1 = 0.9983597594313832\n",
      "Epoch 83: Train Loss = 0.020738743962434424, Recall = 0.9996351696461145, Aging Rate = 0.5512126678693124, Precision = 0.9963636363636363, f1 = 0.9979967219085777\n",
      "Epoch 84: Train Loss = 0.020824374816602396, Recall = 1.0, Aging Rate = 0.5518139907797154, Precision = 0.9956411187795132, f1 = 0.9978157990535128\n",
      "Epoch 85: Train Loss = 0.021199705622422717, Recall = 1.0, Aging Rate = 0.5516135498095811, Precision = 0.9960029069767442, f1 = 0.9979974513016566\n",
      "Test Loss = 0.021276154956172, Recall = 0.9996351696461145, Aging Rate = 0.5498095810783724, precision = 0.998906306963179\n",
      "\n",
      "Epoch 86: Train Loss = 0.02083366993709422, Recall = 0.9996351696461145, Aging Rate = 0.5510122268991782, Precision = 0.9967260822117133, f1 = 0.9981785063752276\n",
      "Epoch 87: Train Loss = 0.020860179344415784, Recall = 0.9996351696461145, Aging Rate = 0.5510122268991782, Precision = 0.9967260822117133, f1 = 0.9981785063752276\n",
      "Epoch 88: Train Loss = 0.02108528840921761, Recall = 0.9996351696461145, Aging Rate = 0.5510122268991782, Precision = 0.9967260822117133, f1 = 0.9981785063752276\n",
      "Epoch 89: Train Loss = 0.02096971219204296, Recall = 1.0, Aging Rate = 0.5510122268991782, Precision = 0.9970898508548564, f1 = 0.9985428051001822\n",
      "Epoch 90: Train Loss = 0.020528884637054736, Recall = 1.0, Aging Rate = 0.5510122268991782, Precision = 0.9970898508548564, f1 = 0.9985428051001822\n",
      "Test Loss = 0.02005544651167549, Recall = 0.9996351696461145, Aging Rate = 0.550210463018641, precision = 0.9981785063752276\n",
      "\n",
      "Epoch 91: Train Loss = 0.02125236875005925, Recall = 1.0, Aging Rate = 0.5514131088394468, Precision = 0.9963649581970193, f1 = 0.9981791697013839\n",
      "Epoch 92: Train Loss = 0.02066258898336798, Recall = 0.9996351696461145, Aging Rate = 0.5510122268991782, Precision = 0.9967260822117133, f1 = 0.9981785063752276\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 93: Train Loss = 0.020177365887195535, Recall = 1.0, Aging Rate = 0.5516135498095811, Precision = 0.9960029069767442, f1 = 0.9979974513016566\n",
      "Epoch 94: Train Loss = 0.02040402556730908, Recall = 1.0, Aging Rate = 0.5514131088394468, Precision = 0.9963649581970193, f1 = 0.9981791697013839\n",
      "Epoch 95: Train Loss = 0.020341830545770163, Recall = 1.0, Aging Rate = 0.5512126678693124, Precision = 0.9967272727272727, f1 = 0.9983609542888363\n",
      "Test Loss = 0.01889776296862848, Recall = 1.0, Aging Rate = 0.5504109039887753, precision = 0.9981791697013839\n",
      "\n",
      "Epoch 96: Train Loss = 0.020795765290129015, Recall = 1.0, Aging Rate = 0.5520144317498497, Precision = 0.995279593318809, f1 = 0.9976342129208371\n",
      "Epoch 97: Train Loss = 0.021185495515646496, Recall = 1.0, Aging Rate = 0.5520144317498497, Precision = 0.995279593318809, f1 = 0.9976342129208371\n",
      "Epoch 98: Train Loss = 0.023357196476353054, Recall = 1.0, Aging Rate = 0.5514131088394468, Precision = 0.9963649581970193, f1 = 0.9981791697013839\n",
      "Epoch 99: Train Loss = 0.020496918323102013, Recall = 1.0, Aging Rate = 0.5514131088394468, Precision = 0.9963649581970193, f1 = 0.9981791697013839\n",
      "Epoch 100: Train Loss = 0.020123609512115462, Recall = 1.0, Aging Rate = 0.5514131088394468, Precision = 0.9963649581970193, f1 = 0.9981791697013839\n",
      "Test Loss = 0.018445824729724836, Recall = 1.0, Aging Rate = 0.5504109039887753, precision = 0.9981791697013839\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "89e5b796355a4eed877c858216034b82",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss = 0.5462270021247443, Recall = 0.9751915359357899, Aging Rate = 0.97013429544999, Precision = 0.5522727272727272, f1 = 0.705184012663237\n",
      "Epoch 2: Train Loss = 0.39173377654575875, Recall = 0.9722728931047063, Aging Rate = 0.7981559430747645, Precision = 0.6692616775489704, f1 = 0.7928008329614754\n",
      "Epoch 3: Train Loss = 0.3093570706110293, Recall = 0.961327982488143, Aging Rate = 0.6893164962918421, Precision = 0.7662111078801978, f1 = 0.8527508090614886\n",
      "Epoch 4: Train Loss = 0.2770129323101254, Recall = 0.9657059467347683, Aging Rate = 0.6654640208458609, Precision = 0.797289156626506, f1 = 0.8734532255403398\n",
      "Epoch 5: Train Loss = 0.24700313836401847, Recall = 0.9642466253192266, Aging Rate = 0.6462216877129685, Precision = 0.8197890818858561, f1 = 0.8861693210393965\n",
      "Test Loss = 0.22179009403834055, Recall = 0.9751915359357899, Aging Rate = 0.6496291842052515, precision = 0.8247454489355137\n",
      "Model in epoch 5 is saved.\n",
      "\n",
      "Epoch 6: Train Loss = 0.211255107002546, Recall = 0.9715432323969354, Aging Rate = 0.6335939065945079, Precision = 0.8424549193293261, f1 = 0.9024059640799729\n",
      "Epoch 7: Train Loss = 0.18397324392338701, Recall = 0.977745348412988, Aging Rate = 0.6231709761475246, Precision = 0.8620135091669348, f1 = 0.9162393162393162\n",
      "Epoch 8: Train Loss = 0.16011803107824132, Recall = 0.9792046698285297, Aging Rate = 0.6047304068951693, Precision = 0.8896254557507458, f1 = 0.9322681486627302\n",
      "Epoch 9: Train Loss = 0.13913380556700106, Recall = 0.9810288215979569, Aging Rate = 0.5945079174183203, Precision = 0.9066082265677681, f1 = 0.9423514981601542\n",
      "Epoch 10: Train Loss = 0.12373442830781847, Recall = 0.9854067858445823, Aging Rate = 0.5870916015233514, Precision = 0.9221577330146807, f1 = 0.9527336860670194\n",
      "Test Loss = 0.11019251923907326, Recall = 0.9919737322145202, Aging Rate = 0.5921026257767088, precision = 0.9204468517264726\n",
      "Model in epoch 10 is saved.\n",
      "\n",
      "Epoch 11: Train Loss = 0.10919901137840392, Recall = 0.9865012769062386, Aging Rate = 0.5818801362998597, Precision = 0.9314502239063038, f1 = 0.958185683912119\n",
      "Epoch 12: Train Loss = 0.09571725908143412, Recall = 0.9890550893834367, Aging Rate = 0.5758669071958308, Precision = 0.943612948137835, f1 = 0.965799786248664\n",
      "Epoch 13: Train Loss = 0.08627041710787436, Recall = 0.990879241152864, Aging Rate = 0.5720585287632792, Precision = 0.9516468114926419, f1 = 0.9708668453976765\n",
      "Epoch 14: Train Loss = 0.07752377905607176, Recall = 0.9916089018606348, Aging Rate = 0.5666466225696533, Precision = 0.9614432260346657, f1 = 0.9762931034482757\n",
      "Epoch 15: Train Loss = 0.07019382708654252, Recall = 0.9930682232761766, Aging Rate = 0.5660452996592503, Precision = 0.9638810198300283, f1 = 0.9782569631626236\n",
      "Test Loss = 0.06542261816915158, Recall = 0.9930682232761766, Aging Rate = 0.5580276608538786, precision = 0.9777298850574713\n",
      "Model in epoch 15 is saved.\n",
      "\n",
      "Epoch 16: Train Loss = 0.06527197519890363, Recall = 0.9919737322145202, Aging Rate = 0.5636400080176388, Precision = 0.966927453769559, f1 = 0.9792904736178641\n",
      "Epoch 17: Train Loss = 0.05956744345151057, Recall = 0.9945275446917183, Aging Rate = 0.5608338344357586, Precision = 0.9742673338098642, f1 = 0.9842931937172775\n",
      "Epoch 18: Train Loss = 0.056026276820024715, Recall = 0.9948923750456038, Aging Rate = 0.5606333934656244, Precision = 0.9749731855559528, f1 = 0.9848320693391116\n",
      "Epoch 19: Train Loss = 0.05239013818350816, Recall = 0.996716526815031, Aging Rate = 0.5592303066746843, Precision = 0.9792114695340501, f1 = 0.9878864581450009\n",
      "Epoch 20: Train Loss = 0.049299037448746766, Recall = 0.9959868661072602, Aging Rate = 0.5576267789136099, Precision = 0.9813084112149533, f1 = 0.9885931558935362\n",
      "Test Loss = 0.04507564394354916, Recall = 0.9978110178766874, Aging Rate = 0.5594307476448186, precision = 0.9799355069867431\n",
      "Model in epoch 20 is saved.\n",
      "\n",
      "Epoch 21: Train Loss = 0.04588658280788622, Recall = 0.9970813571689164, Aging Rate = 0.5560232511525356, Precision = 0.9852198990627253, f1 = 0.9911151405258386\n",
      "Epoch 22: Train Loss = 0.04370668969374904, Recall = 0.9970813571689164, Aging Rate = 0.5554219282421327, Precision = 0.9862865391555395, f1 = 0.9916545718432512\n",
      "Epoch 23: Train Loss = 0.04142208285906029, Recall = 0.9978110178766874, Aging Rate = 0.5564241330928041, Precision = 0.9852305475504323, f1 = 0.9914808772883814\n",
      "Epoch 24: Train Loss = 0.03926750421815261, Recall = 0.9981758482305728, Aging Rate = 0.5550210463018641, Precision = 0.9880823401950163, f1 = 0.993103448275862\n",
      "Epoch 25: Train Loss = 0.03774220303169924, Recall = 0.9985406785844583, Aging Rate = 0.555622369212267, Precision = 0.9873737373737373, f1 = 0.9929258117177581\n",
      "Test Loss = 0.0351218744686053, Recall = 0.9981758482305728, Aging Rate = 0.5532170775706554, precision = 0.991304347826087\n",
      "Model in epoch 25 is saved.\n",
      "\n",
      "Epoch 26: Train Loss = 0.036615817823482194, Recall = 0.9981758482305728, Aging Rate = 0.5540188414511926, Precision = 0.9898697539797395, f1 = 0.9940054495912807\n",
      "Epoch 27: Train Loss = 0.03491500462671396, Recall = 0.9989055089383436, Aging Rate = 0.5552214872719984, Precision = 0.9884476534296028, f1 = 0.993649065505353\n",
      "Epoch 28: Train Loss = 0.03361584099431893, Recall = 0.9989055089383436, Aging Rate = 0.5546201643615956, Precision = 0.9895193350198771, f1 = 0.9941902687000725\n",
      "Epoch 29: Train Loss = 0.03272676732750282, Recall = 0.9992703392922291, Aging Rate = 0.5552214872719984, Precision = 0.9888086642599277, f1 = 0.9940119760479043\n",
      "Epoch 30: Train Loss = 0.031602123564441115, Recall = 0.9989055089383436, Aging Rate = 0.5540188414511926, Precision = 0.9905933429811867, f1 = 0.9947320617620345\n",
      "Test Loss = 0.02917311474901924, Recall = 0.9992703392922291, Aging Rate = 0.5528161956303869, precision = 0.9931109499637418\n",
      "Model in epoch 30 is saved.\n",
      "\n",
      "Epoch 31: Train Loss = 0.030862096738907302, Recall = 0.9992703392922291, Aging Rate = 0.5544197233914612, Precision = 0.9902386117136659, f1 = 0.9947339749409841\n",
      "Epoch 32: Train Loss = 0.030045449054983103, Recall = 0.9992703392922291, Aging Rate = 0.5542192824213269, Precision = 0.9905967450271248, f1 = 0.9949146385760987\n",
      "Epoch 33: Train Loss = 0.029158544344172303, Recall = 0.9996351696461145, Aging Rate = 0.5534175185407897, Precision = 0.9923940601231438, f1 = 0.9960014540167212\n",
      "Epoch 34: Train Loss = 0.028981531110190275, Recall = 0.9996351696461145, Aging Rate = 0.5538184004810583, Precision = 0.9916757148027506, f1 = 0.9956395348837209\n",
      "Epoch 35: Train Loss = 0.027618036281909605, Recall = 0.9996351696461145, Aging Rate = 0.5540188414511926, Precision = 0.9913169319826338, f1 = 0.9954586739327883\n",
      "Test Loss = 0.025040545943048463, Recall = 1.0, Aging Rate = 0.5524153136901183, precision = 0.9945573294629898\n",
      "Model in epoch 35 is saved.\n",
      "\n",
      "Epoch 36: Train Loss = 0.027019937635274514, Recall = 1.0, Aging Rate = 0.5542192824213269, Precision = 0.9913200723327306, f1 = 0.9956411187795133\n",
      "Epoch 37: Train Loss = 0.02675310848178116, Recall = 0.9996351696461145, Aging Rate = 0.5532170775706554, Precision = 0.9927536231884058, f1 = 0.9961825122704963\n",
      "Epoch 38: Train Loss = 0.02656468370095669, Recall = 0.9996351696461145, Aging Rate = 0.5534175185407897, Precision = 0.9923940601231438, f1 = 0.9960014540167212\n",
      "Epoch 39: Train Loss = 0.025775350006041486, Recall = 1.0, Aging Rate = 0.5528161956303869, Precision = 0.9938361131254533, f1 = 0.9969085288234224\n",
      "Epoch 40: Train Loss = 0.02566693849170177, Recall = 1.0, Aging Rate = 0.5530166366005211, Precision = 0.9934758970641536, f1 = 0.9967272727272727\n",
      "Test Loss = 0.023434336188942414, Recall = 1.0, Aging Rate = 0.5516135498095811, precision = 0.9960029069767442\n",
      "Model in epoch 40 is saved.\n",
      "\n",
      "Epoch 41: Train Loss = 0.02554531605892954, Recall = 1.0, Aging Rate = 0.5530166366005211, Precision = 0.9934758970641536, f1 = 0.9967272727272727\n",
      "Epoch 42: Train Loss = 0.025166100719904442, Recall = 0.9996351696461145, Aging Rate = 0.5532170775706554, Precision = 0.9927536231884058, f1 = 0.9961825122704963\n",
      "Epoch 43: Train Loss = 0.024675789726929808, Recall = 0.9996351696461145, Aging Rate = 0.5528161956303869, Precision = 0.9934735315445975, f1 = 0.9965448263320604\n",
      "Epoch 44: Train Loss = 0.02440786447564928, Recall = 1.0, Aging Rate = 0.5526157546602526, Precision = 0.9941965904969169, f1 = 0.9970898508548564\n",
      "Epoch 45: Train Loss = 0.02448123627177823, Recall = 1.0, Aging Rate = 0.5524153136901183, Precision = 0.9945573294629898, f1 = 0.9972712388575588\n",
      "Test Loss = 0.024335736359174086, Recall = 1.0, Aging Rate = 0.5534175185407897, precision = 0.9927562477363274\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 46: Train Loss = 0.023071704906149938, Recall = 0.9996351696461145, Aging Rate = 0.5526157546602526, Precision = 0.9938338774029742, f1 = 0.9967260822117134\n",
      "Epoch 47: Train Loss = 0.022828427881695364, Recall = 1.0, Aging Rate = 0.5520144317498497, Precision = 0.995279593318809, f1 = 0.9976342129208371\n",
      "Epoch 48: Train Loss = 0.02322839471138379, Recall = 0.9996351696461145, Aging Rate = 0.5518139907797154, Precision = 0.995277878677806, f1 = 0.9974517655624318\n",
      "Epoch 49: Train Loss = 0.022959371423507458, Recall = 1.0, Aging Rate = 0.5524153136901183, Precision = 0.9945573294629898, f1 = 0.9972712388575588\n",
      "Epoch 50: Train Loss = 0.02233117413971223, Recall = 1.0, Aging Rate = 0.5522148727199839, Precision = 0.9949183303085299, f1 = 0.99745269286754\n",
      "Test Loss = 0.021797946925125874, Recall = 1.0, Aging Rate = 0.5500100220485067, precision = 0.9989067055393586\n",
      "Model in epoch 50 is saved.\n",
      "\n",
      "Epoch 51: Train Loss = 0.022545852349863116, Recall = 0.9996351696461145, Aging Rate = 0.5518139907797154, Precision = 0.995277878677806, f1 = 0.9974517655624318\n",
      "Epoch 52: Train Loss = 0.022543929554604176, Recall = 0.9992703392922291, Aging Rate = 0.5518139907797154, Precision = 0.9949146385760989, f1 = 0.9970877320713507\n",
      "Epoch 53: Train Loss = 0.022952232070418035, Recall = 0.9996351696461145, Aging Rate = 0.5528161956303869, Precision = 0.9934735315445975, f1 = 0.9965448263320604\n",
      "Epoch 54: Train Loss = 0.022367515493506157, Recall = 0.9996351696461145, Aging Rate = 0.5518139907797154, Precision = 0.995277878677806, f1 = 0.9974517655624318\n",
      "Epoch 55: Train Loss = 0.02186761837692341, Recall = 1.0, Aging Rate = 0.5516135498095811, Precision = 0.9960029069767442, f1 = 0.9979974513016566\n",
      "Test Loss = 0.020196855701409066, Recall = 0.9996351696461145, Aging Rate = 0.5510122268991782, precision = 0.9967260822117133\n",
      "\n",
      "Epoch 56: Train Loss = 0.022715167992009646, Recall = 1.0, Aging Rate = 0.5520144317498497, Precision = 0.995279593318809, f1 = 0.9976342129208371\n",
      "Epoch 57: Train Loss = 0.022314214549352385, Recall = 0.9996351696461145, Aging Rate = 0.5514131088394468, Precision = 0.9960014540167212, f1 = 0.9978150036416606\n",
      "Epoch 58: Train Loss = 0.021533821412453816, Recall = 1.0, Aging Rate = 0.5520144317498497, Precision = 0.995279593318809, f1 = 0.9976342129208371\n",
      "Epoch 59: Train Loss = 0.022139028249367084, Recall = 1.0, Aging Rate = 0.5522148727199839, Precision = 0.9949183303085299, f1 = 0.99745269286754\n",
      "Epoch 60: Train Loss = 0.02161655938605623, Recall = 1.0, Aging Rate = 0.5514131088394468, Precision = 0.9963649581970193, f1 = 0.9981791697013839\n",
      "Test Loss = 0.021023598521810467, Recall = 1.0, Aging Rate = 0.5522148727199839, precision = 0.9949183303085299\n",
      "\n",
      "Epoch 61: Train Loss = 0.021643229503551187, Recall = 0.9996351696461145, Aging Rate = 0.5510122268991782, Precision = 0.9967260822117133, f1 = 0.9981785063752276\n",
      "Epoch 62: Train Loss = 0.021270460203681257, Recall = 1.0, Aging Rate = 0.5512126678693124, Precision = 0.9967272727272727, f1 = 0.9983609542888363\n",
      "Epoch 63: Train Loss = 0.021782727392364608, Recall = 1.0, Aging Rate = 0.5512126678693124, Precision = 0.9967272727272727, f1 = 0.9983609542888363\n",
      "Epoch 64: Train Loss = 0.022088646686003643, Recall = 1.0, Aging Rate = 0.5522148727199839, Precision = 0.9949183303085299, f1 = 0.99745269286754\n",
      "Epoch 65: Train Loss = 0.020850490808552648, Recall = 1.0, Aging Rate = 0.5516135498095811, Precision = 0.9960029069767442, f1 = 0.9979974513016566\n",
      "Test Loss = 0.01944522366844645, Recall = 1.0, Aging Rate = 0.5506113449589096, precision = 0.9978157990535129\n",
      "\n",
      "Epoch 66: Train Loss = 0.021106271245336695, Recall = 1.0, Aging Rate = 0.5514131088394468, Precision = 0.9963649581970193, f1 = 0.9981791697013839\n",
      "Epoch 67: Train Loss = 0.021265825642376248, Recall = 1.0, Aging Rate = 0.5510122268991782, Precision = 0.9970898508548564, f1 = 0.9985428051001822\n",
      "Epoch 68: Train Loss = 0.02140113501235511, Recall = 0.9996351696461145, Aging Rate = 0.5514131088394468, Precision = 0.9960014540167212, f1 = 0.9978150036416606\n",
      "Epoch 69: Train Loss = 0.021139646465349684, Recall = 1.0, Aging Rate = 0.5518139907797154, Precision = 0.9956411187795132, f1 = 0.9978157990535128\n",
      "Epoch 70: Train Loss = 0.021100666410556464, Recall = 0.9996351696461145, Aging Rate = 0.5510122268991782, Precision = 0.9967260822117133, f1 = 0.9981785063752276\n",
      "Test Loss = 0.019217858758547257, Recall = 0.9996351696461145, Aging Rate = 0.5504109039887753, precision = 0.9978150036416606\n",
      "\n",
      "Epoch 71: Train Loss = 0.021066615088809394, Recall = 0.9996351696461145, Aging Rate = 0.5514131088394468, Precision = 0.9960014540167212, f1 = 0.9978150036416606\n",
      "Epoch 72: Train Loss = 0.020881167287968353, Recall = 1.0, Aging Rate = 0.5512126678693124, Precision = 0.9967272727272727, f1 = 0.9983609542888363\n",
      "Epoch 73: Train Loss = 0.020990850014500448, Recall = 1.0, Aging Rate = 0.5514131088394468, Precision = 0.9963649581970193, f1 = 0.9981791697013839\n",
      "Epoch 74: Train Loss = 0.020756040096259063, Recall = 0.9996351696461145, Aging Rate = 0.5510122268991782, Precision = 0.9967260822117133, f1 = 0.9981785063752276\n",
      "Epoch 75: Train Loss = 0.020731854128378215, Recall = 0.9996351696461145, Aging Rate = 0.5518139907797154, Precision = 0.995277878677806, f1 = 0.9974517655624318\n",
      "Test Loss = 0.019286420390436994, Recall = 1.0, Aging Rate = 0.5506113449589096, precision = 0.9978157990535129\n",
      "\n",
      "Epoch 76: Train Loss = 0.020315490030222677, Recall = 1.0, Aging Rate = 0.5512126678693124, Precision = 0.9967272727272727, f1 = 0.9983609542888363\n",
      "Epoch 77: Train Loss = 0.021281047841232723, Recall = 1.0, Aging Rate = 0.5514131088394468, Precision = 0.9963649581970193, f1 = 0.9981791697013839\n",
      "Epoch 78: Train Loss = 0.020605380113926746, Recall = 1.0, Aging Rate = 0.5516135498095811, Precision = 0.9960029069767442, f1 = 0.9979974513016566\n",
      "Epoch 79: Train Loss = 0.020763682648778488, Recall = 1.0, Aging Rate = 0.5510122268991782, Precision = 0.9970898508548564, f1 = 0.9985428051001822\n",
      "Epoch 80: Train Loss = 0.020906090511632218, Recall = 0.9996351696461145, Aging Rate = 0.5510122268991782, Precision = 0.9967260822117133, f1 = 0.9981785063752276\n",
      "Test Loss = 0.020426069781868176, Recall = 0.9996351696461145, Aging Rate = 0.550210463018641, precision = 0.9981785063752276\n",
      "\n",
      "Epoch 81: Train Loss = 0.020339015024714358, Recall = 1.0, Aging Rate = 0.5518139907797154, Precision = 0.9956411187795132, f1 = 0.9978157990535128\n",
      "Epoch 82: Train Loss = 0.02078145320605099, Recall = 1.0, Aging Rate = 0.5518139907797154, Precision = 0.9956411187795132, f1 = 0.9978157990535128\n",
      "Epoch 83: Train Loss = 0.020577830154770577, Recall = 0.9996351696461145, Aging Rate = 0.5506113449589096, Precision = 0.9974517655624318, f1 = 0.9985422740524781\n",
      "Epoch 84: Train Loss = 0.020252974080412798, Recall = 1.0, Aging Rate = 0.5510122268991782, Precision = 0.9970898508548564, f1 = 0.9985428051001822\n",
      "Epoch 85: Train Loss = 0.020556081439026624, Recall = 1.0, Aging Rate = 0.5514131088394468, Precision = 0.9963649581970193, f1 = 0.9981791697013839\n",
      "Test Loss = 0.019585297546204045, Recall = 1.0, Aging Rate = 0.5514131088394468, precision = 0.9963649581970193\n",
      "\n",
      "Epoch 86: Train Loss = 0.02079319424190241, Recall = 0.9996351696461145, Aging Rate = 0.5512126678693124, Precision = 0.9963636363636363, f1 = 0.9979967219085777\n",
      "Epoch 87: Train Loss = 0.020752576722467227, Recall = 0.9996351696461145, Aging Rate = 0.5512126678693124, Precision = 0.9963636363636363, f1 = 0.9979967219085777\n",
      "Epoch 88: Train Loss = 0.020338764431738716, Recall = 1.0, Aging Rate = 0.5510122268991782, Precision = 0.9970898508548564, f1 = 0.9985428051001822\n",
      "Epoch 89: Train Loss = 0.02044151355298697, Recall = 1.0, Aging Rate = 0.5510122268991782, Precision = 0.9970898508548564, f1 = 0.9985428051001822\n",
      "Epoch 90: Train Loss = 0.02049729357049613, Recall = 1.0, Aging Rate = 0.5510122268991782, Precision = 0.9970898508548564, f1 = 0.9985428051001822\n",
      "Test Loss = 0.018266076315213035, Recall = 1.0, Aging Rate = 0.5504109039887753, precision = 0.9981791697013839\n",
      "\n",
      "Epoch 91: Train Loss = 0.020318429016202576, Recall = 0.9996351696461145, Aging Rate = 0.5510122268991782, Precision = 0.9967260822117133, f1 = 0.9981785063752276\n",
      "Epoch 92: Train Loss = 0.020237534748430267, Recall = 0.9996351696461145, Aging Rate = 0.5508117859290439, Precision = 0.9970887918486172, f1 = 0.998360357077792\n",
      "Epoch 93: Train Loss = 0.020292708309922473, Recall = 1.0, Aging Rate = 0.5510122268991782, Precision = 0.9970898508548564, f1 = 0.9985428051001822\n",
      "Epoch 94: Train Loss = 0.02055623268663411, Recall = 0.9996351696461145, Aging Rate = 0.5506113449589096, Precision = 0.9974517655624318, f1 = 0.9985422740524781\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 95: Train Loss = 0.019929830839502404, Recall = 1.0, Aging Rate = 0.5512126678693124, Precision = 0.9967272727272727, f1 = 0.9983609542888363\n",
      "Test Loss = 0.018654646619999066, Recall = 1.0, Aging Rate = 0.5508117859290439, precision = 0.99745269286754\n",
      "\n",
      "Epoch 96: Train Loss = 0.02046266074952632, Recall = 1.0, Aging Rate = 0.5512126678693124, Precision = 0.9967272727272727, f1 = 0.9983609542888363\n",
      "Epoch 97: Train Loss = 0.01963792046530915, Recall = 1.0, Aging Rate = 0.5510122268991782, Precision = 0.9970898508548564, f1 = 0.9985428051001822\n",
      "Epoch 98: Train Loss = 0.02085625746459707, Recall = 1.0, Aging Rate = 0.5520144317498497, Precision = 0.995279593318809, f1 = 0.9976342129208371\n",
      "Epoch 99: Train Loss = 0.020220555438448955, Recall = 1.0, Aging Rate = 0.5504109039887753, Precision = 0.9981791697013839, f1 = 0.9990887552396573\n",
      "Epoch 100: Train Loss = 0.020150834056448904, Recall = 1.0, Aging Rate = 0.5512126678693124, Precision = 0.9967272727272727, f1 = 0.9983609542888363\n",
      "Test Loss = 0.01967138465472263, Recall = 0.9996351696461145, Aging Rate = 0.5500100220485067, precision = 0.9985422740524781\n",
      "\n",
      "Training Finished at epoch 100.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8c5489bfe7a49de880fb8ebc80b8822",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss = 0.5405759065745827, Recall = 0.9821167883211679, Aging Rate = 0.9829591018444266, Precision = 0.5488476442994086, f1 = 0.7041737537616121\n",
      "Epoch 2: Train Loss = 0.3874099300972633, Recall = 0.9777372262773723, Aging Rate = 0.7989174017642342, Precision = 0.6722710163111669, f1 = 0.796728624535316\n",
      "Epoch 3: Train Loss = 0.30279834266175437, Recall = 0.9671532846715328, Aging Rate = 0.6832397754611067, Precision = 0.7775821596244131, f1 = 0.8620689655172414\n",
      "Epoch 4: Train Loss = 0.2615055343391614, Recall = 0.9675182481751825, Aging Rate = 0.6513632718524459, Precision = 0.8159433671899046, f1 = 0.885289697779262\n",
      "Epoch 5: Train Loss = 0.230375824291513, Recall = 0.9708029197080292, Aging Rate = 0.6405372894947875, Precision = 0.8325508607198748, f1 = 0.8963774220724516\n",
      "Test Loss = 0.2036725410051889, Recall = 0.9773722627737226, Aging Rate = 0.6313151563753007, precision = 0.8504287075261988\n",
      "Model in epoch 5 is saved.\n",
      "\n",
      "Epoch 6: Train Loss = 0.1950472947852365, Recall = 0.9744525547445255, Aging Rate = 0.6210906174819567, Precision = 0.8618463524854745, f1 = 0.9146968139773894\n",
      "Epoch 7: Train Loss = 0.17057320307088836, Recall = 0.9799270072992701, Aging Rate = 0.6116680032076984, Precision = 0.880039331366765, f1 = 0.927300984285961\n",
      "Epoch 8: Train Loss = 0.14988426819336156, Recall = 0.9806569343065693, Aging Rate = 0.5992381716118684, Precision = 0.8989628638340582, f1 = 0.938034561005411\n",
      "Epoch 9: Train Loss = 0.13017256812468087, Recall = 0.9854014598540146, Aging Rate = 0.5914194065757818, Precision = 0.9152542372881356, f1 = 0.9490333919156415\n",
      "Epoch 10: Train Loss = 0.11554820527290476, Recall = 0.9875912408759124, Aging Rate = 0.5860064153969526, Precision = 0.9257612042422169, f1 = 0.9556772028959916\n",
      "Test Loss = 0.10718069429290515, Recall = 0.9861313868613139, Aging Rate = 0.5673616680032078, precision = 0.9547703180212014\n",
      "Model in epoch 10 is saved.\n",
      "\n",
      "Epoch 11: Train Loss = 0.10292623857067601, Recall = 0.9908759124087592, Aging Rate = 0.5797914995990376, Precision = 0.9387966804979253, f1 = 0.9641335227272727\n",
      "Epoch 12: Train Loss = 0.0931198689982044, Recall = 0.9912408759124087, Aging Rate = 0.5755813953488372, Precision = 0.9460118425635667, f1 = 0.9680983781857065\n",
      "Epoch 13: Train Loss = 0.08369224324953871, Recall = 0.9916058394160584, Aging Rate = 0.572373696872494, Precision = 0.9516637478108582, f1 = 0.9712243074173369\n",
      "Epoch 14: Train Loss = 0.07657294924152118, Recall = 0.9937956204379562, Aging Rate = 0.5709703287890938, Precision = 0.9561095505617978, f1 = 0.974588403722262\n",
      "Epoch 15: Train Loss = 0.07108120698520634, Recall = 0.9934306569343065, Aging Rate = 0.5673616680032078, Precision = 0.9618374558303887, f1 = 0.97737881508079\n",
      "Test Loss = 0.0665764310266509, Recall = 0.9981751824817519, Aging Rate = 0.5715717722534082, precision = 0.9593125219221326\n",
      "Model in epoch 15 is saved.\n",
      "\n",
      "Epoch 16: Train Loss = 0.0650355680080156, Recall = 0.9948905109489051, Aging Rate = 0.5647554129911788, Precision = 0.9676961306354278, f1 = 0.9811049127226922\n",
      "Epoch 17: Train Loss = 0.061091124476699135, Recall = 0.9956204379562044, Aging Rate = 0.5633520449077787, Precision = 0.9708185053380783, f1 = 0.9830630630630631\n",
      "Epoch 18: Train Loss = 0.057039551469762514, Recall = 0.995985401459854, Aging Rate = 0.56214915797915, Precision = 0.9732524964336662, f1 = 0.9844877344877345\n",
      "Epoch 19: Train Loss = 0.05442536544613391, Recall = 0.995985401459854, Aging Rate = 0.5587409783480353, Precision = 0.97918909221385, f1 = 0.9875158313732585\n",
      "Epoch 20: Train Loss = 0.050021123347181076, Recall = 0.9981751824817519, Aging Rate = 0.5603448275862069, Precision = 0.9785330948121646, f1 = 0.988256549232159\n",
      "Test Loss = 0.04958121522472396, Recall = 1.0, Aging Rate = 0.566158781074579, precision = 0.9702549575070821\n",
      "Model in epoch 20 is saved.\n",
      "\n",
      "Epoch 21: Train Loss = 0.047999656232672876, Recall = 0.9985401459854014, Aging Rate = 0.5595429029671211, Precision = 0.980293801504837, f1 = 0.9893328512023142\n",
      "Epoch 22: Train Loss = 0.044947511154288945, Recall = 0.9981751824817519, Aging Rate = 0.5579390537289495, Precision = 0.9827524254401725, f1 = 0.9904037660691654\n",
      "Epoch 23: Train Loss = 0.04288276695103385, Recall = 0.9981751824817519, Aging Rate = 0.5569366479550922, Precision = 0.984521238300936, f1 = 0.9913011960855382\n",
      "Epoch 24: Train Loss = 0.041399775181972416, Recall = 0.9981751824817519, Aging Rate = 0.5563352044907779, Precision = 0.9855855855855856, f1 = 0.9918404351767905\n",
      "Epoch 25: Train Loss = 0.04070654403905249, Recall = 0.9981751824817519, Aging Rate = 0.5565356856455493, Precision = 0.9852305475504323, f1 = 0.991660623640319\n",
      "Test Loss = 0.0372402410724207, Recall = 1.0, Aging Rate = 0.5569366479550922, precision = 0.986321094312455\n",
      "Model in epoch 25 is saved.\n",
      "\n",
      "Epoch 26: Train Loss = 0.038448669945443256, Recall = 0.9985401459854014, Aging Rate = 0.555934242181235, Precision = 0.9866570501262171, f1 = 0.9925630328314892\n",
      "Epoch 27: Train Loss = 0.037350346191630135, Recall = 0.9989051094890511, Aging Rate = 0.5547313552526063, Precision = 0.9891579327791832, f1 = 0.9940076266569821\n",
      "Epoch 28: Train Loss = 0.03610377995044877, Recall = 0.9989051094890511, Aging Rate = 0.5563352044907779, Precision = 0.9863063063063063, f1 = 0.9925657298277426\n",
      "Epoch 29: Train Loss = 0.03443528562724447, Recall = 0.9992700729927008, Aging Rate = 0.5551323175621492, Precision = 0.9888046226074395, f1 = 0.9940098021419496\n",
      "Epoch 30: Train Loss = 0.033195386427875125, Recall = 0.9992700729927008, Aging Rate = 0.5543303929430633, Precision = 0.9902350813743219, f1 = 0.9947320617620345\n",
      "Test Loss = 0.030499825563278786, Recall = 1.0, Aging Rate = 0.5525260625501203, precision = 0.9941944847605225\n",
      "Model in epoch 30 is saved.\n",
      "\n",
      "Epoch 31: Train Loss = 0.03218575248550011, Recall = 0.9992700729927008, Aging Rate = 0.5535284683239775, Precision = 0.9916696848967765, f1 = 0.9954553717505907\n",
      "Epoch 32: Train Loss = 0.03198363782230051, Recall = 0.9996350364963503, Aging Rate = 0.5547313552526063, Precision = 0.989880737260571, f1 = 0.9947339749409843\n",
      "Epoch 33: Train Loss = 0.03140123401497399, Recall = 0.9992700729927008, Aging Rate = 0.5543303929430633, Precision = 0.9902350813743219, f1 = 0.9947320617620345\n",
      "Epoch 34: Train Loss = 0.03047823737455351, Recall = 1.0, Aging Rate = 0.5541299117882919, Precision = 0.9913169319826338, f1 = 0.9956395348837209\n",
      "Epoch 35: Train Loss = 0.029584063276791916, Recall = 0.9992700729927008, Aging Rate = 0.5543303929430633, Precision = 0.9902350813743219, f1 = 0.9947320617620345\n",
      "Test Loss = 0.02750558131273594, Recall = 1.0, Aging Rate = 0.5523255813953488, precision = 0.9945553539019963\n",
      "Model in epoch 35 is saved.\n",
      "\n",
      "Epoch 36: Train Loss = 0.02893794950399527, Recall = 0.9996350364963503, Aging Rate = 0.5531275060144346, Precision = 0.9927509967379485, f1 = 0.9961811238406982\n",
      "Epoch 37: Train Loss = 0.028291998465441663, Recall = 0.9989051094890511, Aging Rate = 0.5525260625501203, Precision = 0.9931059506531205, f1 = 0.9959970887918487\n",
      "Epoch 38: Train Loss = 0.02800627947212126, Recall = 1.0, Aging Rate = 0.5533279871692061, Precision = 0.9927536231884058, f1 = 0.9963636363636363\n",
      "Epoch 39: Train Loss = 0.02728238416224742, Recall = 0.9996350364963503, Aging Rate = 0.5525260625501203, Precision = 0.9938316400580551, f1 = 0.9967248908296943\n",
      "Epoch 40: Train Loss = 0.026691684296239637, Recall = 0.9996350364963503, Aging Rate = 0.5523255813953488, Precision = 0.9941923774954627, f1 = 0.9969062784349407\n",
      "Test Loss = 0.024584745986756078, Recall = 1.0, Aging Rate = 0.5527265437048917, precision = 0.9938338774029742\n",
      "\n",
      "Epoch 41: Train Loss = 0.026470692767055874, Recall = 1.0, Aging Rate = 0.5533279871692061, Precision = 0.9927536231884058, f1 = 0.9963636363636363\n",
      "Epoch 42: Train Loss = 0.026140232620508363, Recall = 0.9996350364963503, Aging Rate = 0.5521251002405774, Precision = 0.9945533769063181, f1 = 0.9970877320713506\n",
      "Epoch 43: Train Loss = 0.026030000950468955, Recall = 0.9996350364963503, Aging Rate = 0.5521251002405774, Precision = 0.9945533769063181, f1 = 0.9970877320713506\n",
      "Epoch 44: Train Loss = 0.025395835811793565, Recall = 1.0, Aging Rate = 0.5525260625501203, Precision = 0.9941944847605225, f1 = 0.9970887918486171\n",
      "Epoch 45: Train Loss = 0.02520494948274963, Recall = 1.0, Aging Rate = 0.5527265437048917, Precision = 0.9938338774029742, f1 = 0.9969074040385665\n",
      "Test Loss = 0.023328543545823147, Recall = 1.0, Aging Rate = 0.5529270248596632, precision = 0.9934735315445975\n",
      "\n",
      "Epoch 46: Train Loss = 0.0248233113712732, Recall = 1.0, Aging Rate = 0.5527265437048917, Precision = 0.9938338774029742, f1 = 0.9969074040385665\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 47: Train Loss = 0.024625946120108808, Recall = 1.0, Aging Rate = 0.5527265437048917, Precision = 0.9938338774029742, f1 = 0.9969074040385665\n",
      "Epoch 48: Train Loss = 0.02431393432436151, Recall = 1.0, Aging Rate = 0.5525260625501203, Precision = 0.9941944847605225, f1 = 0.9970887918486171\n",
      "Epoch 49: Train Loss = 0.02460437700893273, Recall = 1.0, Aging Rate = 0.5531275060144346, Precision = 0.9931134469010511, f1 = 0.9965448263320604\n",
      "Epoch 50: Train Loss = 0.023696998680949977, Recall = 1.0, Aging Rate = 0.551523656776263, Precision = 0.9960014540167212, f1 = 0.9979967219085777\n",
      "Test Loss = 0.02218403183252408, Recall = 1.0, Aging Rate = 0.5509222133119487, precision = 0.9970887918486172\n",
      "Model in epoch 50 is saved.\n",
      "\n",
      "Epoch 51: Train Loss = 0.023843422349850082, Recall = 1.0, Aging Rate = 0.5525260625501203, Precision = 0.9941944847605225, f1 = 0.9970887918486171\n",
      "Epoch 52: Train Loss = 0.023486547612711343, Recall = 1.0, Aging Rate = 0.5517241379310345, Precision = 0.9956395348837209, f1 = 0.9978150036416605\n",
      "Epoch 53: Train Loss = 0.023311229682592458, Recall = 1.0, Aging Rate = 0.5517241379310345, Precision = 0.9956395348837209, f1 = 0.9978150036416605\n",
      "Epoch 54: Train Loss = 0.023178598522369205, Recall = 1.0, Aging Rate = 0.5523255813953488, Precision = 0.9945553539019963, f1 = 0.997270245677889\n",
      "Epoch 55: Train Loss = 0.02333512789186661, Recall = 1.0, Aging Rate = 0.5517241379310345, Precision = 0.9956395348837209, f1 = 0.9978150036416605\n",
      "Test Loss = 0.020809875391931562, Recall = 1.0, Aging Rate = 0.5509222133119487, precision = 0.9970887918486172\n",
      "\n",
      "Epoch 56: Train Loss = 0.022819797368757517, Recall = 1.0, Aging Rate = 0.551523656776263, Precision = 0.9960014540167212, f1 = 0.9979967219085777\n",
      "Epoch 57: Train Loss = 0.02257692309674518, Recall = 1.0, Aging Rate = 0.5519246190858059, Precision = 0.995277878677806, f1 = 0.9976333515383216\n",
      "Epoch 58: Train Loss = 0.02263546418682422, Recall = 1.0, Aging Rate = 0.551523656776263, Precision = 0.9960014540167212, f1 = 0.9979967219085777\n",
      "Epoch 59: Train Loss = 0.02259531070171305, Recall = 1.0, Aging Rate = 0.5519246190858059, Precision = 0.995277878677806, f1 = 0.9976333515383216\n",
      "Epoch 60: Train Loss = 0.022519714861462953, Recall = 1.0, Aging Rate = 0.551523656776263, Precision = 0.9960014540167212, f1 = 0.9979967219085777\n",
      "Test Loss = 0.02131095084375922, Recall = 1.0, Aging Rate = 0.5501202886928629, precision = 0.9985422740524781\n",
      "Model in epoch 60 is saved.\n",
      "\n",
      "Epoch 61: Train Loss = 0.022235458446390265, Recall = 1.0, Aging Rate = 0.5517241379310345, Precision = 0.9956395348837209, f1 = 0.9978150036416605\n",
      "Epoch 62: Train Loss = 0.02208615619011086, Recall = 1.0, Aging Rate = 0.5519246190858059, Precision = 0.995277878677806, f1 = 0.9976333515383216\n",
      "Epoch 63: Train Loss = 0.02243517135488767, Recall = 1.0, Aging Rate = 0.5521251002405774, Precision = 0.9949164851125636, f1 = 0.9974517655624318\n",
      "Epoch 64: Train Loss = 0.021762579862467508, Recall = 1.0, Aging Rate = 0.5513231756214916, Precision = 0.9963636363636363, f1 = 0.9981785063752276\n",
      "Epoch 65: Train Loss = 0.02230946876485059, Recall = 1.0, Aging Rate = 0.5519246190858059, Precision = 0.995277878677806, f1 = 0.9976333515383216\n",
      "Test Loss = 0.020760681684806333, Recall = 1.0, Aging Rate = 0.5501202886928629, precision = 0.9985422740524781\n",
      "\n",
      "Epoch 66: Train Loss = 0.02184256555179452, Recall = 1.0, Aging Rate = 0.5513231756214916, Precision = 0.9963636363636363, f1 = 0.9981785063752276\n",
      "Epoch 67: Train Loss = 0.022867351267023762, Recall = 0.9996350364963503, Aging Rate = 0.5513231756214916, Precision = 0.996, f1 = 0.9978142076502731\n",
      "Epoch 68: Train Loss = 0.02174436360741006, Recall = 1.0, Aging Rate = 0.551523656776263, Precision = 0.9960014540167212, f1 = 0.9979967219085777\n",
      "Epoch 69: Train Loss = 0.021739558063584897, Recall = 1.0, Aging Rate = 0.551523656776263, Precision = 0.9960014540167212, f1 = 0.9979967219085777\n",
      "Epoch 70: Train Loss = 0.02271384150596409, Recall = 1.0, Aging Rate = 0.5519246190858059, Precision = 0.995277878677806, f1 = 0.9976333515383216\n",
      "Test Loss = 0.01953898585358905, Recall = 1.0, Aging Rate = 0.5507217321571772, precision = 0.9974517655624318\n",
      "\n",
      "Epoch 71: Train Loss = 0.021386228893146383, Recall = 1.0, Aging Rate = 0.551523656776263, Precision = 0.9960014540167212, f1 = 0.9979967219085777\n",
      "Epoch 72: Train Loss = 0.021126099780751594, Recall = 1.0, Aging Rate = 0.5513231756214916, Precision = 0.9963636363636363, f1 = 0.9981785063752276\n",
      "Epoch 73: Train Loss = 0.021039504507062143, Recall = 1.0, Aging Rate = 0.5513231756214916, Precision = 0.9963636363636363, f1 = 0.9981785063752276\n",
      "Epoch 74: Train Loss = 0.02144854170820693, Recall = 1.0, Aging Rate = 0.5511226944667201, Precision = 0.9967260822117133, f1 = 0.998360357077792\n",
      "Epoch 75: Train Loss = 0.02137227293623741, Recall = 1.0, Aging Rate = 0.551523656776263, Precision = 0.9960014540167212, f1 = 0.9979967219085777\n",
      "Test Loss = 0.019573607149667615, Recall = 1.0, Aging Rate = 0.5517241379310345, precision = 0.9956395348837209\n",
      "\n",
      "Epoch 76: Train Loss = 0.020977910392960264, Recall = 1.0, Aging Rate = 0.5513231756214916, Precision = 0.9963636363636363, f1 = 0.9981785063752276\n",
      "Epoch 77: Train Loss = 0.021576028677195, Recall = 1.0, Aging Rate = 0.5513231756214916, Precision = 0.9963636363636363, f1 = 0.9981785063752276\n",
      "Epoch 78: Train Loss = 0.02087468019542497, Recall = 1.0, Aging Rate = 0.5513231756214916, Precision = 0.9963636363636363, f1 = 0.9981785063752276\n",
      "Epoch 79: Train Loss = 0.021564385128515953, Recall = 1.0, Aging Rate = 0.5509222133119487, Precision = 0.9970887918486172, f1 = 0.9985422740524782\n",
      "Epoch 80: Train Loss = 0.021033440835313885, Recall = 1.0, Aging Rate = 0.5521251002405774, Precision = 0.9949164851125636, f1 = 0.9974517655624318\n",
      "Test Loss = 0.019713982524471277, Recall = 1.0, Aging Rate = 0.5509222133119487, precision = 0.9970887918486172\n",
      "\n",
      "Epoch 81: Train Loss = 0.022126416979714594, Recall = 1.0, Aging Rate = 0.5511226944667201, Precision = 0.9967260822117133, f1 = 0.998360357077792\n",
      "Epoch 82: Train Loss = 0.02166918783770529, Recall = 1.0, Aging Rate = 0.5519246190858059, Precision = 0.995277878677806, f1 = 0.9976333515383216\n",
      "Epoch 83: Train Loss = 0.022117526651342916, Recall = 1.0, Aging Rate = 0.551523656776263, Precision = 0.9960014540167212, f1 = 0.9979967219085777\n",
      "Epoch 84: Train Loss = 0.021212296826285462, Recall = 1.0, Aging Rate = 0.551523656776263, Precision = 0.9960014540167212, f1 = 0.9979967219085777\n",
      "Epoch 85: Train Loss = 0.02060803945333889, Recall = 1.0, Aging Rate = 0.5505212510024058, Precision = 0.9978150036416606, f1 = 0.9989063069631791\n",
      "Test Loss = 0.019070970569681243, Recall = 1.0, Aging Rate = 0.5507217321571772, precision = 0.9974517655624318\n",
      "\n",
      "Epoch 86: Train Loss = 0.021040374629719312, Recall = 1.0, Aging Rate = 0.5513231756214916, Precision = 0.9963636363636363, f1 = 0.9981785063752276\n",
      "Epoch 87: Train Loss = 0.021010759102110397, Recall = 1.0, Aging Rate = 0.5513231756214916, Precision = 0.9963636363636363, f1 = 0.9981785063752276\n",
      "Epoch 88: Train Loss = 0.02098441078553892, Recall = 1.0, Aging Rate = 0.5513231756214916, Precision = 0.9963636363636363, f1 = 0.9981785063752276\n",
      "Epoch 89: Train Loss = 0.0206967653510995, Recall = 1.0, Aging Rate = 0.5513231756214916, Precision = 0.9963636363636363, f1 = 0.9981785063752276\n",
      "Epoch 90: Train Loss = 0.021134476481362543, Recall = 1.0, Aging Rate = 0.5521251002405774, Precision = 0.9949164851125636, f1 = 0.9974517655624318\n",
      "Test Loss = 0.020112843427481465, Recall = 1.0, Aging Rate = 0.5519246190858059, precision = 0.995277878677806\n",
      "\n",
      "Epoch 91: Train Loss = 0.020592896482864664, Recall = 1.0, Aging Rate = 0.5511226944667201, Precision = 0.9967260822117133, f1 = 0.998360357077792\n",
      "Epoch 92: Train Loss = 0.020743861189522834, Recall = 1.0, Aging Rate = 0.5509222133119487, Precision = 0.9970887918486172, f1 = 0.9985422740524782\n",
      "Epoch 93: Train Loss = 0.020570944307585572, Recall = 1.0, Aging Rate = 0.5513231756214916, Precision = 0.9963636363636363, f1 = 0.9981785063752276\n",
      "Epoch 94: Train Loss = 0.020436543426099258, Recall = 1.0, Aging Rate = 0.5511226944667201, Precision = 0.9967260822117133, f1 = 0.998360357077792\n",
      "Epoch 95: Train Loss = 0.02074058456368798, Recall = 1.0, Aging Rate = 0.5511226944667201, Precision = 0.9967260822117133, f1 = 0.998360357077792\n",
      "Test Loss = 0.019742084142797548, Recall = 1.0, Aging Rate = 0.5501202886928629, precision = 0.9985422740524781\n",
      "\n",
      "Epoch 96: Train Loss = 0.020104978451656166, Recall = 1.0, Aging Rate = 0.5511226944667201, Precision = 0.9967260822117133, f1 = 0.998360357077792\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 97: Train Loss = 0.020506734745435077, Recall = 1.0, Aging Rate = 0.5509222133119487, Precision = 0.9970887918486172, f1 = 0.9985422740524782\n",
      "Epoch 98: Train Loss = 0.020606382764911738, Recall = 1.0, Aging Rate = 0.551523656776263, Precision = 0.9960014540167212, f1 = 0.9979967219085777\n",
      "Epoch 99: Train Loss = 0.020909961393669116, Recall = 1.0, Aging Rate = 0.5511226944667201, Precision = 0.9967260822117133, f1 = 0.998360357077792\n",
      "Epoch 100: Train Loss = 0.02059482648197947, Recall = 1.0, Aging Rate = 0.551523656776263, Precision = 0.9960014540167212, f1 = 0.9979967219085777\n",
      "Test Loss = 0.019234365894165675, Recall = 1.0, Aging Rate = 0.5501202886928629, precision = 0.9985422740524781\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7be6d21b1c8c4513a72d74b28710d8ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss = 0.5033212376515405, Recall = 0.9682597592119664, Aging Rate = 0.9096011224694327, Precision = 0.5848391361833407, f1 = 0.7292210468470943\n",
      "Epoch 2: Train Loss = 0.32544714800817837, Recall = 0.9657059467347683, Aging Rate = 0.7039486871116456, Precision = 0.7537015945330297, f1 = 0.846633615864385\n",
      "Epoch 3: Train Loss = 0.2539989404913466, Recall = 0.964611455673112, Aging Rate = 0.6534375626378032, Precision = 0.811042944785276, f1 = 0.8811864689218464\n",
      "Epoch 4: Train Loss = 0.20841780624795375, Recall = 0.9704487413352791, Aging Rate = 0.6259771497294047, Precision = 0.8517451168747999, f1 = 0.907230559345157\n",
      "Epoch 5: Train Loss = 0.16921305638213605, Recall = 0.977745348412988, Aging Rate = 0.6089396672679895, Precision = 0.8821593153390388, f1 = 0.9274961065928361\n",
      "Test Loss = 0.13708578216800185, Recall = 0.9883254286756659, Aging Rate = 0.5989176187612748, precision = 0.9066265060240963\n",
      "Model in epoch 5 is saved.\n",
      "\n",
      "Epoch 6: Train Loss = 0.1270656143676353, Recall = 0.9861364465523531, Aging Rate = 0.5947083583884546, Precision = 0.9110212335692619, f1 = 0.9470918009810793\n",
      "Epoch 7: Train Loss = 0.10062673473930425, Recall = 0.9894199197373221, Aging Rate = 0.5764682301062337, Precision = 0.9429763560500696, f1 = 0.9656400213637173\n",
      "Epoch 8: Train Loss = 0.08122799461597334, Recall = 0.9919737322145202, Aging Rate = 0.5710563239126077, Precision = 0.9543699543699544, f1 = 0.9728085867620752\n",
      "Epoch 9: Train Loss = 0.06711316122442908, Recall = 0.9927033929222912, Aging Rate = 0.5652435357787132, Precision = 0.9648936170212766, f1 = 0.9786009710483726\n",
      "Epoch 10: Train Loss = 0.056353497141395356, Recall = 0.9948923750456038, Aging Rate = 0.5614351573461616, Precision = 0.973580863977151, f1 = 0.9841212558643089\n",
      "Test Loss = 0.04748458512042276, Recall = 0.9970813571689164, Aging Rate = 0.5594307476448186, precision = 0.9792189179505554\n",
      "Model in epoch 10 is saved.\n",
      "\n",
      "Epoch 11: Train Loss = 0.047724698700076486, Recall = 0.9956220357533747, Aging Rate = 0.5576267789136099, Precision = 0.9809489575844716, f1 = 0.9882310338584103\n",
      "Epoch 12: Train Loss = 0.04128321759084658, Recall = 0.9956220357533747, Aging Rate = 0.5554219282421327, Precision = 0.9848430169613858, f1 = 0.9902031930333818\n",
      "Epoch 13: Train Loss = 0.035338362459728774, Recall = 0.9974461875228019, Aging Rate = 0.555622369212267, Precision = 0.9862914862914863, f1 = 0.9918374750589516\n",
      "Epoch 14: Train Loss = 0.03164288983059613, Recall = 0.9970813571689164, Aging Rate = 0.5538184004810583, Precision = 0.98914223669924, f1 = 0.9930959302325582\n",
      "Epoch 15: Train Loss = 0.02731841158716945, Recall = 0.9989055089383436, Aging Rate = 0.5536179595109241, Precision = 0.9913106444605359, f1 = 0.9950935853170997\n",
      "Test Loss = 0.023151969354197242, Recall = 0.9996351696461145, Aging Rate = 0.5520144317498497, precision = 0.9949164851125636\n",
      "Model in epoch 15 is saved.\n",
      "\n",
      "Epoch 16: Train Loss = 0.02401738964307939, Recall = 0.9992703392922291, Aging Rate = 0.5532170775706554, Precision = 0.9923913043478261, f1 = 0.9958189420105436\n",
      "Epoch 17: Train Loss = 0.021887694844835315, Recall = 0.9992703392922291, Aging Rate = 0.5526157546602526, Precision = 0.9934711643090316, f1 = 0.9963623135685704\n",
      "Epoch 18: Train Loss = 0.0190290230272032, Recall = 0.9996351696461145, Aging Rate = 0.5522148727199839, Precision = 0.9945553539019963, f1 = 0.9970887918486172\n",
      "Epoch 19: Train Loss = 0.01735570604384086, Recall = 0.9996351696461145, Aging Rate = 0.5516135498095811, Precision = 0.9956395348837209, f1 = 0.9976333515383214\n",
      "Epoch 20: Train Loss = 0.015570870206196075, Recall = 0.9996351696461145, Aging Rate = 0.5514131088394468, Precision = 0.9960014540167212, f1 = 0.9978150036416606\n",
      "Test Loss = 0.013181338520557447, Recall = 1.0, Aging Rate = 0.5512126678693124, precision = 0.9967272727272727\n",
      "Model in epoch 20 is saved.\n",
      "\n",
      "Epoch 21: Train Loss = 0.014285489356589177, Recall = 1.0, Aging Rate = 0.5508117859290439, Precision = 0.99745269286754, f1 = 0.9987247221716159\n",
      "Epoch 22: Train Loss = 0.013306003312381852, Recall = 0.9996351696461145, Aging Rate = 0.5512126678693124, Precision = 0.9963636363636363, f1 = 0.9979967219085777\n",
      "Epoch 23: Train Loss = 0.012031433058465428, Recall = 0.9996351696461145, Aging Rate = 0.5504109039887753, Precision = 0.9978150036416606, f1 = 0.9987242573355203\n",
      "Epoch 24: Train Loss = 0.011030920565025281, Recall = 1.0, Aging Rate = 0.5506113449589096, Precision = 0.9978157990535129, f1 = 0.9989067055393587\n",
      "Epoch 25: Train Loss = 0.009655884251082127, Recall = 1.0, Aging Rate = 0.550210463018641, Precision = 0.9985428051001821, f1 = 0.999270871308786\n",
      "Test Loss = 0.009524255574883034, Recall = 1.0, Aging Rate = 0.5506113449589096, precision = 0.9978157990535129\n",
      "Model in epoch 25 is saved.\n",
      "\n",
      "Epoch 26: Train Loss = 0.009467612746464547, Recall = 1.0, Aging Rate = 0.5504109039887753, Precision = 0.9981791697013839, f1 = 0.9990887552396573\n",
      "Epoch 27: Train Loss = 0.008849942276213602, Recall = 1.0, Aging Rate = 0.5506113449589096, Precision = 0.9978157990535129, f1 = 0.9989067055393587\n",
      "Epoch 28: Train Loss = 0.00839846000455411, Recall = 1.0, Aging Rate = 0.550210463018641, Precision = 0.9985428051001821, f1 = 0.999270871308786\n",
      "Epoch 29: Train Loss = 0.00728029615678286, Recall = 1.0, Aging Rate = 0.5506113449589096, Precision = 0.9978157990535129, f1 = 0.9989067055393587\n",
      "Epoch 30: Train Loss = 0.007458966389193154, Recall = 1.0, Aging Rate = 0.550210463018641, Precision = 0.9985428051001821, f1 = 0.999270871308786\n",
      "Test Loss = 0.007449238448528662, Recall = 0.9996351696461145, Aging Rate = 0.5500100220485067, precision = 0.9985422740524781\n",
      "Model in epoch 30 is saved.\n",
      "\n",
      "Epoch 31: Train Loss = 0.006706593592307146, Recall = 1.0, Aging Rate = 0.550210463018641, Precision = 0.9985428051001821, f1 = 0.999270871308786\n",
      "Epoch 32: Train Loss = 0.006317083908838221, Recall = 1.0, Aging Rate = 0.5504109039887753, Precision = 0.9981791697013839, f1 = 0.9990887552396573\n",
      "Epoch 33: Train Loss = 0.00642330822158522, Recall = 0.9996351696461145, Aging Rate = 0.5498095810783724, Precision = 0.998906306963179, f1 = 0.99927060539752\n",
      "Epoch 34: Train Loss = 0.005857716998052525, Recall = 1.0, Aging Rate = 0.5500100220485067, Precision = 0.9989067055393586, f1 = 0.9994530537830446\n",
      "Epoch 35: Train Loss = 0.005337083404952812, Recall = 1.0, Aging Rate = 0.5500100220485067, Precision = 0.9989067055393586, f1 = 0.9994530537830446\n",
      "Test Loss = 0.004477874013916551, Recall = 1.0, Aging Rate = 0.5494086991381039, precision = 1.0\n",
      "Model in epoch 35 is saved.\n",
      "\n",
      "Epoch 36: Train Loss = 0.004508736453939951, Recall = 1.0, Aging Rate = 0.5496091401082381, Precision = 0.99963530269876, f1 = 0.9998176180922853\n",
      "Epoch 37: Train Loss = 0.005352340950571802, Recall = 0.9996351696461145, Aging Rate = 0.5498095810783724, Precision = 0.998906306963179, f1 = 0.99927060539752\n",
      "Epoch 38: Train Loss = 0.004694808835793181, Recall = 1.0, Aging Rate = 0.5500100220485067, Precision = 0.9989067055393586, f1 = 0.9994530537830446\n",
      "Epoch 39: Train Loss = 0.004272854827773024, Recall = 1.0, Aging Rate = 0.5500100220485067, Precision = 0.9989067055393586, f1 = 0.9994530537830446\n",
      "Epoch 40: Train Loss = 0.003959673681511271, Recall = 1.0, Aging Rate = 0.5496091401082381, Precision = 0.99963530269876, f1 = 0.9998176180922853\n",
      "Test Loss = 0.0032728367292503852, Recall = 1.0, Aging Rate = 0.5498095810783724, precision = 0.999270871308786\n",
      "\n",
      "Epoch 41: Train Loss = 0.00407462680393501, Recall = 1.0, Aging Rate = 0.5506113449589096, Precision = 0.9978157990535129, f1 = 0.9989067055393587\n",
      "Epoch 42: Train Loss = 0.003952354380202335, Recall = 1.0, Aging Rate = 0.5498095810783724, Precision = 0.999270871308786, f1 = 0.99963530269876\n",
      "Epoch 43: Train Loss = 0.003507681949615574, Recall = 1.0, Aging Rate = 0.5498095810783724, Precision = 0.999270871308786, f1 = 0.99963530269876\n",
      "Epoch 44: Train Loss = 0.0037939758880982705, Recall = 1.0, Aging Rate = 0.5498095810783724, Precision = 0.999270871308786, f1 = 0.99963530269876\n",
      "Epoch 45: Train Loss = 0.004571944701890981, Recall = 0.9996351696461145, Aging Rate = 0.550210463018641, Precision = 0.9981785063752276, f1 = 0.998906306963179\n",
      "Test Loss = 0.004503379865628095, Recall = 1.0, Aging Rate = 0.5500100220485067, precision = 0.9989067055393586\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 46: Train Loss = 0.003618155441163483, Recall = 1.0, Aging Rate = 0.5498095810783724, Precision = 0.999270871308786, f1 = 0.99963530269876\n",
      "Epoch 47: Train Loss = 0.003259061467396064, Recall = 1.0, Aging Rate = 0.5498095810783724, Precision = 0.999270871308786, f1 = 0.99963530269876\n",
      "Epoch 48: Train Loss = 0.0031900026051092, Recall = 1.0, Aging Rate = 0.5496091401082381, Precision = 0.99963530269876, f1 = 0.9998176180922853\n",
      "Epoch 49: Train Loss = 0.0032387953107860363, Recall = 1.0, Aging Rate = 0.5496091401082381, Precision = 0.99963530269876, f1 = 0.9998176180922853\n",
      "Epoch 50: Train Loss = 0.003163077447755312, Recall = 1.0, Aging Rate = 0.5496091401082381, Precision = 0.99963530269876, f1 = 0.9998176180922853\n",
      "Test Loss = 0.002395859835671265, Recall = 1.0, Aging Rate = 0.5494086991381039, precision = 1.0\n",
      "\n",
      "Epoch 51: Train Loss = 0.003073782661747158, Recall = 1.0, Aging Rate = 0.5496091401082381, Precision = 0.99963530269876, f1 = 0.9998176180922853\n",
      "Epoch 52: Train Loss = 0.0026861663683196077, Recall = 1.0, Aging Rate = 0.5494086991381039, Precision = 0, f1 = 0.0\n",
      "Epoch 53: Train Loss = 0.0034973915859037256, Recall = 1.0, Aging Rate = 0.5498095810783724, Precision = 0.999270871308786, f1 = 0.99963530269876\n",
      "Epoch 54: Train Loss = 0.004507588398984267, Recall = 1.0, Aging Rate = 0.5500100220485067, Precision = 0.9989067055393586, f1 = 0.9994530537830446\n",
      "Epoch 55: Train Loss = 0.003041833452516366, Recall = 1.0, Aging Rate = 0.5498095810783724, Precision = 0.999270871308786, f1 = 0.99963530269876\n",
      "Test Loss = 0.0022088113471628204, Recall = 1.0, Aging Rate = 0.5496091401082381, precision = 0.99963530269876\n",
      "\n",
      "Epoch 56: Train Loss = 0.0023897743437982055, Recall = 1.0, Aging Rate = 0.5496091401082381, Precision = 0.99963530269876, f1 = 0.9998176180922853\n",
      "Epoch 57: Train Loss = 0.002487361923197654, Recall = 1.0, Aging Rate = 0.5494086991381039, Precision = 0, f1 = 0.0\n",
      "Epoch 58: Train Loss = 0.0025681343995890412, Recall = 1.0, Aging Rate = 0.5496091401082381, Precision = 0.99963530269876, f1 = 0.9998176180922853\n",
      "Epoch 59: Train Loss = 0.0026715157045237013, Recall = 1.0, Aging Rate = 0.5496091401082381, Precision = 0.99963530269876, f1 = 0.9998176180922853\n",
      "Epoch 60: Train Loss = 0.0025010915228279, Recall = 1.0, Aging Rate = 0.5496091401082381, Precision = 0.99963530269876, f1 = 0.9998176180922853\n",
      "Test Loss = 0.002306893102229754, Recall = 1.0, Aging Rate = 0.5494086991381039, precision = 1.0\n",
      "\n",
      "Epoch 61: Train Loss = 0.0026698122676058716, Recall = 1.0, Aging Rate = 0.5498095810783724, Precision = 0.999270871308786, f1 = 0.99963530269876\n",
      "Epoch 62: Train Loss = 0.002688835369270705, Recall = 1.0, Aging Rate = 0.5496091401082381, Precision = 0.99963530269876, f1 = 0.9998176180922853\n",
      "Epoch 63: Train Loss = 0.002627430016077468, Recall = 1.0, Aging Rate = 0.5496091401082381, Precision = 0.99963530269876, f1 = 0.9998176180922853\n",
      "Epoch 64: Train Loss = 0.0031766678824004155, Recall = 0.9996351696461145, Aging Rate = 0.5494086991381039, Precision = 0.9996351696461145, f1 = 0.9996351696461145\n",
      "Epoch 65: Train Loss = 0.0023613589185113256, Recall = 1.0, Aging Rate = 0.5496091401082381, Precision = 0.99963530269876, f1 = 0.9998176180922853\n",
      "Test Loss = 0.0020212822108486386, Recall = 1.0, Aging Rate = 0.5494086991381039, precision = 1.0\n",
      "\n",
      "Epoch 66: Train Loss = 0.002366849626794362, Recall = 1.0, Aging Rate = 0.5494086991381039, Precision = 0, f1 = 0.0\n",
      "Epoch 67: Train Loss = 0.002409154743523281, Recall = 1.0, Aging Rate = 0.5496091401082381, Precision = 0.99963530269876, f1 = 0.9998176180922853\n",
      "Epoch 68: Train Loss = 0.002527003312456549, Recall = 1.0, Aging Rate = 0.5496091401082381, Precision = 0.99963530269876, f1 = 0.9998176180922853\n",
      "Epoch 69: Train Loss = 0.0025535231813130195, Recall = 1.0, Aging Rate = 0.5496091401082381, Precision = 0.99963530269876, f1 = 0.9998176180922853\n",
      "Epoch 70: Train Loss = 0.0029847660302346, Recall = 1.0, Aging Rate = 0.5496091401082381, Precision = 0.99963530269876, f1 = 0.9998176180922853\n",
      "Test Loss = 0.0022270444287858958, Recall = 1.0, Aging Rate = 0.5494086991381039, precision = 1.0\n",
      "\n",
      "Epoch 71: Train Loss = 0.003988132745533058, Recall = 1.0, Aging Rate = 0.5500100220485067, Precision = 0.9989067055393586, f1 = 0.9994530537830446\n",
      "Epoch 72: Train Loss = 0.0033210547843275603, Recall = 1.0, Aging Rate = 0.5496091401082381, Precision = 0.99963530269876, f1 = 0.9998176180922853\n",
      "Epoch 73: Train Loss = 0.002248088243677574, Recall = 1.0, Aging Rate = 0.5496091401082381, Precision = 0.99963530269876, f1 = 0.9998176180922853\n",
      "Epoch 74: Train Loss = 0.0022220684363693224, Recall = 1.0, Aging Rate = 0.5494086991381039, Precision = 0, f1 = 0.0\n",
      "Epoch 75: Train Loss = 0.002088466893628988, Recall = 1.0, Aging Rate = 0.5494086991381039, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0018515179706131639, Recall = 1.0, Aging Rate = 0.5494086991381039, precision = 1.0\n",
      "\n",
      "Epoch 76: Train Loss = 0.002008351849234876, Recall = 1.0, Aging Rate = 0.5494086991381039, Precision = 0, f1 = 0.0\n",
      "Epoch 77: Train Loss = 0.0019983013358775815, Recall = 1.0, Aging Rate = 0.5494086991381039, Precision = 0, f1 = 0.0\n",
      "Epoch 78: Train Loss = 0.0021844773311007416, Recall = 1.0, Aging Rate = 0.5494086991381039, Precision = 0, f1 = 0.0\n",
      "Epoch 79: Train Loss = 0.0022584101568400117, Recall = 1.0, Aging Rate = 0.5494086991381039, Precision = 0, f1 = 0.0\n",
      "Epoch 80: Train Loss = 0.002519974408222866, Recall = 1.0, Aging Rate = 0.5496091401082381, Precision = 0.99963530269876, f1 = 0.9998176180922853\n",
      "Test Loss = 0.0019772675377204767, Recall = 1.0, Aging Rate = 0.5494086991381039, precision = 1.0\n",
      "\n",
      "Epoch 81: Train Loss = 0.0021397354995794887, Recall = 1.0, Aging Rate = 0.5496091401082381, Precision = 0.99963530269876, f1 = 0.9998176180922853\n",
      "Epoch 82: Train Loss = 0.0022113053642180114, Recall = 1.0, Aging Rate = 0.5494086991381039, Precision = 0, f1 = 0.0\n",
      "Epoch 83: Train Loss = 0.0026055429620628345, Recall = 1.0, Aging Rate = 0.5494086991381039, Precision = 0, f1 = 0.0\n",
      "Epoch 84: Train Loss = 0.002507077181970525, Recall = 1.0, Aging Rate = 0.5494086991381039, Precision = 0, f1 = 0.0\n",
      "Epoch 85: Train Loss = 0.0032000685021830815, Recall = 0.9996351696461145, Aging Rate = 0.5498095810783724, Precision = 0.998906306963179, f1 = 0.99927060539752\n",
      "Test Loss = 0.006623184613250293, Recall = 0.9989055089383436, Aging Rate = 0.5490078171978352, precision = 0.9996349032493611\n",
      "\n",
      "Training Finished at epoch 85.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "16ea1e8e74614c1eb61d9b77bc17d2ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss = 0.49501061515378963, Recall = 0.9919737322145202, Aging Rate = 0.936259771497294, Precision = 0.5821023335474202, f1 = 0.7336751214247166\n",
      "Epoch 2: Train Loss = 0.32091966451206005, Recall = 0.9627873039036848, Aging Rate = 0.6961314892764081, Precision = 0.7598617909588252, f1 = 0.8493723849372385\n",
      "Epoch 3: Train Loss = 0.2549190689576463, Recall = 0.9627873039036848, Aging Rate = 0.6522349168169974, Precision = 0.81100184388445, f1 = 0.8804003336113427\n",
      "Epoch 4: Train Loss = 0.20904733104406176, Recall = 0.9715432323969354, Aging Rate = 0.6305872920424935, Precision = 0.8464717101080738, f1 = 0.904705282826567\n",
      "Epoch 5: Train Loss = 0.17348667602604534, Recall = 0.9730025538124772, Aging Rate = 0.6081379033874524, Precision = 0.8790375741595253, f1 = 0.9236363636363637\n",
      "Test Loss = 0.14107373486745092, Recall = 0.9861364465523531, Aging Rate = 0.5989176187612748, precision = 0.9046184738955824\n",
      "Model in epoch 5 is saved.\n",
      "\n",
      "Epoch 6: Train Loss = 0.13133973561826176, Recall = 0.9824881430134987, Aging Rate = 0.5882942473441571, Precision = 0.9175468483816014, f1 = 0.948907681465821\n",
      "Epoch 7: Train Loss = 0.10403851895933042, Recall = 0.9857716161984678, Aging Rate = 0.5790739627179795, Precision = 0.9352717203184493, f1 = 0.9598579040852576\n",
      "Epoch 8: Train Loss = 0.08452371234291899, Recall = 0.9916089018606348, Aging Rate = 0.5722589697334135, Precision = 0.9520140105078809, f1 = 0.9714081486776268\n",
      "Epoch 9: Train Loss = 0.06999730815975443, Recall = 0.9923385625684057, Aging Rate = 0.5654439767488475, Precision = 0.9641970932293513, f1 = 0.9780654440848615\n",
      "Epoch 10: Train Loss = 0.05903819720168395, Recall = 0.9945275446917183, Aging Rate = 0.5606333934656244, Precision = 0.9746156596353236, f1 = 0.9844709281329\n",
      "Test Loss = 0.05095011226595416, Recall = 0.9963516964611455, Aging Rate = 0.561034275405893, precision = 0.9757056091461236\n",
      "Model in epoch 10 is saved.\n",
      "\n",
      "Epoch 11: Train Loss = 0.05042021472352759, Recall = 0.9956220357533747, Aging Rate = 0.5584285427941471, Precision = 0.9795405599425699, f1 = 0.9875158313732585\n",
      "Epoch 12: Train Loss = 0.042648037878012794, Recall = 0.9963516964611455, Aging Rate = 0.5568250150330728, Precision = 0.9830813534917207, f1 = 0.9896720420366009\n",
      "Epoch 13: Train Loss = 0.03798021896060733, Recall = 0.9970813571689164, Aging Rate = 0.5562236921226699, Precision = 0.9848648648648649, f1 = 0.9909354604786077\n",
      "Epoch 14: Train Loss = 0.032702187802377505, Recall = 0.9970813571689164, Aging Rate = 0.5540188414511926, Precision = 0.9887843704775687, f1 = 0.9929155313351498\n",
      "Epoch 15: Train Loss = 0.029362894225799147, Recall = 0.9974461875228019, Aging Rate = 0.5530166366005211, Precision = 0.9909387459224357, f1 = 0.9941818181818183\n",
      "Test Loss = 0.02388513288584811, Recall = 0.9992703392922291, Aging Rate = 0.5526157546602526, precision = 0.9934711643090316\n",
      "Model in epoch 15 is saved.\n",
      "\n",
      "Epoch 16: Train Loss = 0.025044307664132327, Recall = 0.9985406785844583, Aging Rate = 0.5526157546602526, Precision = 0.9927457381211462, f1 = 0.9956347762822846\n",
      "Epoch 17: Train Loss = 0.02224781418973003, Recall = 0.9992703392922291, Aging Rate = 0.5528161956303869, Precision = 0.9931109499637418, f1 = 0.9961811238406982\n",
      "Epoch 18: Train Loss = 0.01976967849752831, Recall = 0.9992703392922291, Aging Rate = 0.5522148727199839, Precision = 0.9941923774954627, f1 = 0.9967248908296942\n",
      "Epoch 19: Train Loss = 0.017791811405184703, Recall = 0.9996351696461145, Aging Rate = 0.5520144317498497, Precision = 0.9949164851125636, f1 = 0.997270245677889\n",
      "Epoch 20: Train Loss = 0.016269576075524362, Recall = 0.9989055089383436, Aging Rate = 0.5510122268991782, Precision = 0.9959985449254274, f1 = 0.9974499089253187\n",
      "Test Loss = 0.013905673976827059, Recall = 1.0, Aging Rate = 0.550210463018641, precision = 0.9985428051001821\n",
      "Model in epoch 20 is saved.\n",
      "\n",
      "Epoch 21: Train Loss = 0.014670021797174363, Recall = 0.9992703392922291, Aging Rate = 0.5510122268991782, Precision = 0.9963623135685704, f1 = 0.9978142076502732\n",
      "Epoch 22: Train Loss = 0.012944672336231781, Recall = 1.0, Aging Rate = 0.5506113449589096, Precision = 0.9978157990535129, f1 = 0.9989067055393587\n",
      "Epoch 23: Train Loss = 0.0113853228035407, Recall = 1.0, Aging Rate = 0.5504109039887753, Precision = 0.9981791697013839, f1 = 0.9990887552396573\n",
      "Epoch 24: Train Loss = 0.010471246431707309, Recall = 1.0, Aging Rate = 0.5500100220485067, Precision = 0.9989067055393586, f1 = 0.9994530537830446\n",
      "Epoch 25: Train Loss = 0.009605458236293295, Recall = 1.0, Aging Rate = 0.5504109039887753, Precision = 0.9981791697013839, f1 = 0.9990887552396573\n",
      "Test Loss = 0.008056984342952772, Recall = 1.0, Aging Rate = 0.5498095810783724, precision = 0.999270871308786\n",
      "Model in epoch 25 is saved.\n",
      "\n",
      "Epoch 26: Train Loss = 0.00878763827728621, Recall = 1.0, Aging Rate = 0.5498095810783724, Precision = 0.999270871308786, f1 = 0.99963530269876\n",
      "Epoch 27: Train Loss = 0.008207436660278532, Recall = 1.0, Aging Rate = 0.5500100220485067, Precision = 0.9989067055393586, f1 = 0.9994530537830446\n",
      "Epoch 28: Train Loss = 0.007698763985041955, Recall = 1.0, Aging Rate = 0.5498095810783724, Precision = 0.999270871308786, f1 = 0.99963530269876\n",
      "Epoch 29: Train Loss = 0.007115592692278088, Recall = 0.9996351696461145, Aging Rate = 0.5496091401082381, Precision = 0.9992706053975201, f1 = 0.9994528542768557\n",
      "Epoch 30: Train Loss = 0.006568784234116791, Recall = 1.0, Aging Rate = 0.5498095810783724, Precision = 0.999270871308786, f1 = 0.99963530269876\n",
      "Test Loss = 0.005777393685760957, Recall = 1.0, Aging Rate = 0.5494086991381039, precision = 1.0\n",
      "Model in epoch 30 is saved.\n",
      "\n",
      "Epoch 31: Train Loss = 0.006105037850933924, Recall = 1.0, Aging Rate = 0.5498095810783724, Precision = 0.999270871308786, f1 = 0.99963530269876\n",
      "Epoch 32: Train Loss = 0.0056730611756627665, Recall = 1.0, Aging Rate = 0.5498095810783724, Precision = 0.999270871308786, f1 = 0.99963530269876\n",
      "Epoch 33: Train Loss = 0.004986011582964538, Recall = 1.0, Aging Rate = 0.5496091401082381, Precision = 0.99963530269876, f1 = 0.9998176180922853\n",
      "Epoch 34: Train Loss = 0.005211946689634828, Recall = 1.0, Aging Rate = 0.5498095810783724, Precision = 0.999270871308786, f1 = 0.99963530269876\n",
      "Epoch 35: Train Loss = 0.004642993645486044, Recall = 1.0, Aging Rate = 0.5494086991381039, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.003914912842814455, Recall = 1.0, Aging Rate = 0.5494086991381039, precision = 1.0\n",
      "\n",
      "Epoch 36: Train Loss = 0.004266428568348734, Recall = 1.0, Aging Rate = 0.5494086991381039, Precision = 0, f1 = 0.0\n",
      "Epoch 37: Train Loss = 0.003951754548004852, Recall = 1.0, Aging Rate = 0.5494086991381039, Precision = 0, f1 = 0.0\n",
      "Epoch 38: Train Loss = 0.00395298183591927, Recall = 1.0, Aging Rate = 0.5494086991381039, Precision = 0, f1 = 0.0\n",
      "Epoch 39: Train Loss = 0.0037926296133411375, Recall = 1.0, Aging Rate = 0.5494086991381039, Precision = 0, f1 = 0.0\n",
      "Epoch 40: Train Loss = 0.0036389422034292197, Recall = 1.0, Aging Rate = 0.5496091401082381, Precision = 0.99963530269876, f1 = 0.9998176180922853\n",
      "Test Loss = 0.003006336191989441, Recall = 1.0, Aging Rate = 0.5494086991381039, precision = 1.0\n",
      "\n",
      "Epoch 41: Train Loss = 0.0032586256463262094, Recall = 1.0, Aging Rate = 0.5494086991381039, Precision = 0, f1 = 0.0\n",
      "Epoch 42: Train Loss = 0.003208972370845827, Recall = 1.0, Aging Rate = 0.5494086991381039, Precision = 0, f1 = 0.0\n",
      "Epoch 43: Train Loss = 0.003211378171781627, Recall = 1.0, Aging Rate = 0.5494086991381039, Precision = 0, f1 = 0.0\n",
      "Epoch 44: Train Loss = 0.003201726317735369, Recall = 1.0, Aging Rate = 0.5494086991381039, Precision = 0, f1 = 0.0\n",
      "Epoch 45: Train Loss = 0.002898548815214973, Recall = 1.0, Aging Rate = 0.5494086991381039, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.002677199708349744, Recall = 1.0, Aging Rate = 0.5494086991381039, precision = 1.0\n",
      "\n",
      "Epoch 46: Train Loss = 0.002877844236682862, Recall = 1.0, Aging Rate = 0.5494086991381039, Precision = 0, f1 = 0.0\n",
      "Epoch 47: Train Loss = 0.002904972466646708, Recall = 1.0, Aging Rate = 0.5494086991381039, Precision = 0, f1 = 0.0\n",
      "Epoch 48: Train Loss = 0.002713353132590966, Recall = 1.0, Aging Rate = 0.5494086991381039, Precision = 0, f1 = 0.0\n",
      "Epoch 49: Train Loss = 0.002792803131101407, Recall = 1.0, Aging Rate = 0.5494086991381039, Precision = 0, f1 = 0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50: Train Loss = 0.0027520906731395224, Recall = 1.0, Aging Rate = 0.5494086991381039, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0029338899109229567, Recall = 1.0, Aging Rate = 0.5494086991381039, precision = 1.0\n",
      "\n",
      "Epoch 51: Train Loss = 0.0027475198469481097, Recall = 1.0, Aging Rate = 0.5494086991381039, Precision = 0, f1 = 0.0\n",
      "Epoch 52: Train Loss = 0.0025273940516521904, Recall = 1.0, Aging Rate = 0.5494086991381039, Precision = 0, f1 = 0.0\n",
      "Epoch 53: Train Loss = 0.002463484618187064, Recall = 1.0, Aging Rate = 0.5494086991381039, Precision = 0, f1 = 0.0\n",
      "Epoch 54: Train Loss = 0.0026162172391449544, Recall = 1.0, Aging Rate = 0.5494086991381039, Precision = 0, f1 = 0.0\n",
      "Epoch 55: Train Loss = 0.0025093511775209545, Recall = 1.0, Aging Rate = 0.5494086991381039, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.002402149197817413, Recall = 1.0, Aging Rate = 0.5494086991381039, precision = 1.0\n",
      "\n",
      "Epoch 56: Train Loss = 0.0024597153936935213, Recall = 1.0, Aging Rate = 0.5494086991381039, Precision = 0, f1 = 0.0\n",
      "Epoch 57: Train Loss = 0.002458785421503971, Recall = 1.0, Aging Rate = 0.5494086991381039, Precision = 0, f1 = 0.0\n",
      "Epoch 58: Train Loss = 0.0023675022752162934, Recall = 1.0, Aging Rate = 0.5494086991381039, Precision = 0, f1 = 0.0\n",
      "Epoch 59: Train Loss = 0.002421710295426271, Recall = 1.0, Aging Rate = 0.5494086991381039, Precision = 0, f1 = 0.0\n",
      "Epoch 60: Train Loss = 0.0023912325040167538, Recall = 1.0, Aging Rate = 0.5494086991381039, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.001968047329928225, Recall = 1.0, Aging Rate = 0.5494086991381039, precision = 1.0\n",
      "\n",
      "Epoch 61: Train Loss = 0.0022134780152780645, Recall = 1.0, Aging Rate = 0.5494086991381039, Precision = 0, f1 = 0.0\n",
      "Epoch 62: Train Loss = 0.0027391878356173333, Recall = 1.0, Aging Rate = 0.5494086991381039, Precision = 0, f1 = 0.0\n",
      "Epoch 63: Train Loss = 0.0021756041324500494, Recall = 1.0, Aging Rate = 0.5494086991381039, Precision = 0, f1 = 0.0\n",
      "Epoch 64: Train Loss = 0.0022310994137860695, Recall = 1.0, Aging Rate = 0.5494086991381039, Precision = 0, f1 = 0.0\n",
      "Epoch 65: Train Loss = 0.0021501863180347215, Recall = 1.0, Aging Rate = 0.5494086991381039, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0018909410932775206, Recall = 1.0, Aging Rate = 0.5494086991381039, precision = 1.0\n",
      "\n",
      "Epoch 66: Train Loss = 0.0020589919973726316, Recall = 1.0, Aging Rate = 0.5494086991381039, Precision = 0, f1 = 0.0\n",
      "Epoch 67: Train Loss = 0.0020747503425719133, Recall = 1.0, Aging Rate = 0.5494086991381039, Precision = 0, f1 = 0.0\n",
      "Epoch 68: Train Loss = 0.0022634308298724545, Recall = 1.0, Aging Rate = 0.5494086991381039, Precision = 0, f1 = 0.0\n",
      "Epoch 69: Train Loss = 0.0022541530456031433, Recall = 1.0, Aging Rate = 0.5494086991381039, Precision = 0, f1 = 0.0\n",
      "Epoch 70: Train Loss = 0.004777782077504007, Recall = 0.9996351696461145, Aging Rate = 0.5498095810783724, Precision = 0.998906306963179, f1 = 0.99927060539752\n",
      "Test Loss = 0.00248931590349386, Recall = 1.0, Aging Rate = 0.5494086991381039, precision = 1.0\n",
      "\n",
      "Epoch 71: Train Loss = 0.0021775708201588304, Recall = 1.0, Aging Rate = 0.5494086991381039, Precision = 0, f1 = 0.0\n",
      "Epoch 72: Train Loss = 0.0018691077445163102, Recall = 1.0, Aging Rate = 0.5494086991381039, Precision = 0, f1 = 0.0\n",
      "Epoch 73: Train Loss = 0.0018993381906319824, Recall = 1.0, Aging Rate = 0.5494086991381039, Precision = 0, f1 = 0.0\n",
      "Epoch 74: Train Loss = 0.0021185244102793375, Recall = 1.0, Aging Rate = 0.5494086991381039, Precision = 0, f1 = 0.0\n",
      "Epoch 75: Train Loss = 0.00223743085814597, Recall = 1.0, Aging Rate = 0.5494086991381039, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.001687820114853937, Recall = 1.0, Aging Rate = 0.5494086991381039, precision = 1.0\n",
      "\n",
      "Epoch 76: Train Loss = 0.001920472928398455, Recall = 1.0, Aging Rate = 0.5494086991381039, Precision = 0, f1 = 0.0\n",
      "Epoch 77: Train Loss = 0.0022273626364058188, Recall = 1.0, Aging Rate = 0.5496091401082381, Precision = 0.99963530269876, f1 = 0.9998176180922853\n",
      "Epoch 78: Train Loss = 0.002299373418930526, Recall = 1.0, Aging Rate = 0.5494086991381039, Precision = 0, f1 = 0.0\n",
      "Epoch 79: Train Loss = 0.0019831189838810034, Recall = 1.0, Aging Rate = 0.5494086991381039, Precision = 0, f1 = 0.0\n",
      "Epoch 80: Train Loss = 0.0021811220768781624, Recall = 1.0, Aging Rate = 0.5494086991381039, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0023189617235397954, Recall = 1.0, Aging Rate = 0.5496091401082381, precision = 0.99963530269876\n",
      "\n",
      "Training Finished at epoch 80.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e260b3ba4a3e46089f19c4db26f7a989",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss = 0.489684537587746, Recall = 0.9759211966435607, Aging Rate = 0.9079975947083584, Precision = 0.5905077262693157, f1 = 0.7357997524412048\n",
      "Epoch 2: Train Loss = 0.3125753915305127, Recall = 0.9657059467347683, Aging Rate = 0.6959310483062738, Precision = 0.7623847926267281, f1 = 0.8520843392885884\n",
      "Epoch 3: Train Loss = 0.24491837868639835, Recall = 0.9642466253192266, Aging Rate = 0.6402084586089397, Precision = 0.8274890419536631, f1 = 0.8906486941870262\n",
      "Epoch 4: Train Loss = 0.1985917781739322, Recall = 0.9686245895658518, Aging Rate = 0.6151533373421527, Precision = 0.8651026392961877, f1 = 0.9139414802065404\n",
      "Epoch 5: Train Loss = 0.16782105472002318, Recall = 0.9751915359357899, Aging Rate = 0.603126879134095, Precision = 0.8883349950149552, f1 = 0.9297391304347826\n",
      "Test Loss = 0.1378242061584501, Recall = 0.9784750091207588, Aging Rate = 0.5772699939867709, precision = 0.93125\n",
      "Model in epoch 5 is saved.\n",
      "\n",
      "Epoch 6: Train Loss = 0.1276010490086256, Recall = 0.9828529733673842, Aging Rate = 0.5884946883142914, Precision = 0.917574931880109, f1 = 0.949092830720451\n",
      "Epoch 7: Train Loss = 0.10617526465835374, Recall = 0.9865012769062386, Aging Rate = 0.5778713168971737, Precision = 0.937911897329171, f1 = 0.9615931721194879\n",
      "Epoch 8: Train Loss = 0.08671916296676109, Recall = 0.9919737322145202, Aging Rate = 0.5740629384646222, Precision = 0.9493715083798883, f1 = 0.9702051739518287\n",
      "Epoch 9: Train Loss = 0.07234403239083352, Recall = 0.9923385625684057, Aging Rate = 0.5674483864501905, Precision = 0.9607912398445779, f1 = 0.9763101220387652\n",
      "Epoch 10: Train Loss = 0.06201769940974741, Recall = 0.9934330536300621, Aging Rate = 0.5654439767488475, Precision = 0.9652605459057072, f1 = 0.9791441927364258\n",
      "Test Loss = 0.0551056232158521, Recall = 0.9974461875228019, Aging Rate = 0.5694527961515333, precision = 0.9623372052094333\n",
      "Model in epoch 10 is saved.\n",
      "\n",
      "Epoch 11: Train Loss = 0.053229511505462145, Recall = 0.9963516964611455, Aging Rate = 0.5628382441371016, Precision = 0.9725783475783476, f1 = 0.9843214993692556\n",
      "Epoch 12: Train Loss = 0.04590843666451659, Recall = 0.9948923750456038, Aging Rate = 0.5582281018240128, Precision = 0.9791741472172352, f1 = 0.9869706840390879\n",
      "Epoch 13: Train Loss = 0.04116602607801673, Recall = 0.9970813571689164, Aging Rate = 0.5578272198837443, Precision = 0.9820337765001796, f1 = 0.9895003620564808\n",
      "Epoch 14: Train Loss = 0.03595849282787185, Recall = 0.9974461875228019, Aging Rate = 0.5546201643615956, Precision = 0.9880737260571015, f1 = 0.9927378358750908\n",
      "Epoch 15: Train Loss = 0.03175340406932676, Recall = 0.996716526815031, Aging Rate = 0.5540188414511926, Precision = 0.9884225759768451, f1 = 0.9925522252497729\n",
      "Test Loss = 0.028593715624523487, Recall = 0.9985406785844583, Aging Rate = 0.5554219282421327, precision = 0.9877300613496932\n",
      "Model in epoch 15 is saved.\n",
      "\n",
      "Epoch 16: Train Loss = 0.029278274397422685, Recall = 0.9985406785844583, Aging Rate = 0.5542192824213269, Precision = 0.9898734177215189, f1 = 0.9941881583726844\n",
      "Epoch 17: Train Loss = 0.02677206755077213, Recall = 0.9978110178766874, Aging Rate = 0.5538184004810583, Precision = 0.9898660875859573, f1 = 0.9938226744186047\n",
      "Epoch 18: Train Loss = 0.023126658540361687, Recall = 0.9989055089383436, Aging Rate = 0.5528161956303869, Precision = 0.9927483683828862, f1 = 0.9958174213493362\n",
      "Epoch 19: Train Loss = 0.022131904642797497, Recall = 0.9978110178766874, Aging Rate = 0.5520144317498497, Precision = 0.9931009440813362, f1 = 0.9954504094631483\n",
      "Epoch 20: Train Loss = 0.019339179250529855, Recall = 0.9989055089383436, Aging Rate = 0.5526157546602526, Precision = 0.9931084512150888, f1 = 0.9959985449254275\n",
      "Test Loss = 0.020722131165501277, Recall = 1.0, Aging Rate = 0.5550210463018641, precision = 0.9898880462260744\n",
      "Model in epoch 20 is saved.\n",
      "\n",
      "Epoch 21: Train Loss = 0.018261934478432506, Recall = 0.9989055089383436, Aging Rate = 0.5524153136901183, Precision = 0.9934687953555879, f1 = 0.9961797344005822\n",
      "Epoch 22: Train Loss = 0.01641324735165395, Recall = 0.9992703392922291, Aging Rate = 0.5514131088394468, Precision = 0.9956379498364231, f1 = 0.9974508375819373\n",
      "Epoch 23: Train Loss = 0.015332387248044813, Recall = 0.9992703392922291, Aging Rate = 0.5506113449589096, Precision = 0.9970877320713506, f1 = 0.9981778425655977\n",
      "Epoch 24: Train Loss = 0.013777913953000103, Recall = 1.0, Aging Rate = 0.5514131088394468, Precision = 0.9963649581970193, f1 = 0.9981791697013839\n",
      "Epoch 25: Train Loss = 0.01356139252442806, Recall = 0.9996351696461145, Aging Rate = 0.5510122268991782, Precision = 0.9967260822117133, f1 = 0.9981785063752276\n",
      "Test Loss = 0.012778961027720949, Recall = 1.0, Aging Rate = 0.5522148727199839, precision = 0.9949183303085299\n",
      "Model in epoch 25 is saved.\n",
      "\n",
      "Epoch 26: Train Loss = 0.012699456185051687, Recall = 0.9996351696461145, Aging Rate = 0.5506113449589096, Precision = 0.9974517655624318, f1 = 0.9985422740524781\n",
      "Epoch 27: Train Loss = 0.01176882793334992, Recall = 0.9996351696461145, Aging Rate = 0.5512126678693124, Precision = 0.9963636363636363, f1 = 0.9979967219085777\n",
      "Epoch 28: Train Loss = 0.010534805671036943, Recall = 0.9996351696461145, Aging Rate = 0.5508117859290439, Precision = 0.9970887918486172, f1 = 0.998360357077792\n",
      "Epoch 29: Train Loss = 0.010391104924773483, Recall = 0.9996351696461145, Aging Rate = 0.5508117859290439, Precision = 0.9970887918486172, f1 = 0.998360357077792\n",
      "Epoch 30: Train Loss = 0.009007115430209997, Recall = 1.0, Aging Rate = 0.5506113449589096, Precision = 0.9978157990535129, f1 = 0.9989067055393587\n",
      "Test Loss = 0.008470776725004507, Recall = 0.9996351696461145, Aging Rate = 0.5500100220485067, precision = 0.9985422740524781\n",
      "Model in epoch 30 is saved.\n",
      "\n",
      "Epoch 31: Train Loss = 0.009434650197556464, Recall = 0.9992703392922291, Aging Rate = 0.550210463018641, Precision = 0.9978142076502732, f1 = 0.998541742617572\n",
      "Epoch 32: Train Loss = 0.0092476634262027, Recall = 0.9996351696461145, Aging Rate = 0.550210463018641, Precision = 0.9981785063752276, f1 = 0.998906306963179\n",
      "Epoch 33: Train Loss = 0.007953448589537632, Recall = 0.9996351696461145, Aging Rate = 0.550210463018641, Precision = 0.9981785063752276, f1 = 0.998906306963179\n",
      "Epoch 34: Train Loss = 0.007864868460319403, Recall = 0.9996351696461145, Aging Rate = 0.5506113449589096, Precision = 0.9974517655624318, f1 = 0.9985422740524781\n",
      "Epoch 35: Train Loss = 0.007241887138067398, Recall = 1.0, Aging Rate = 0.5500100220485067, Precision = 0.9989067055393586, f1 = 0.9994530537830446\n",
      "Test Loss = 0.005983965665155767, Recall = 1.0, Aging Rate = 0.5498095810783724, precision = 0.999270871308786\n",
      "Model in epoch 35 is saved.\n",
      "\n",
      "Epoch 36: Train Loss = 0.006799952709279382, Recall = 1.0, Aging Rate = 0.5506113449589096, Precision = 0.9978157990535129, f1 = 0.9989067055393587\n",
      "Epoch 37: Train Loss = 0.006975644894554132, Recall = 0.9996351696461145, Aging Rate = 0.5496091401082381, Precision = 0.9992706053975201, f1 = 0.9994528542768557\n",
      "Epoch 38: Train Loss = 0.0060865377204029365, Recall = 1.0, Aging Rate = 0.5504109039887753, Precision = 0.9981791697013839, f1 = 0.9990887552396573\n",
      "Epoch 39: Train Loss = 0.005667390508379725, Recall = 1.0, Aging Rate = 0.5500100220485067, Precision = 0.9989067055393586, f1 = 0.9994530537830446\n",
      "Epoch 40: Train Loss = 0.005393450494126116, Recall = 1.0, Aging Rate = 0.550210463018641, Precision = 0.9985428051001821, f1 = 0.999270871308786\n",
      "Test Loss = 0.005296038922092693, Recall = 1.0, Aging Rate = 0.5506113449589096, precision = 0.9978157990535129\n",
      "\n",
      "Epoch 41: Train Loss = 0.00544706224250137, Recall = 1.0, Aging Rate = 0.550210463018641, Precision = 0.9985428051001821, f1 = 0.999270871308786\n",
      "Epoch 42: Train Loss = 0.005533825685608013, Recall = 0.9996351696461145, Aging Rate = 0.5498095810783724, Precision = 0.998906306963179, f1 = 0.99927060539752\n",
      "Epoch 43: Train Loss = 0.004822125107421052, Recall = 1.0, Aging Rate = 0.5500100220485067, Precision = 0.9989067055393586, f1 = 0.9994530537830446\n",
      "Epoch 44: Train Loss = 0.0047074002039001455, Recall = 1.0, Aging Rate = 0.5500100220485067, Precision = 0.9989067055393586, f1 = 0.9994530537830446\n",
      "Epoch 45: Train Loss = 0.004908042961548985, Recall = 1.0, Aging Rate = 0.5500100220485067, Precision = 0.9989067055393586, f1 = 0.9994530537830446\n",
      "Test Loss = 0.004156130103842037, Recall = 1.0, Aging Rate = 0.5494086991381039, precision = 1.0\n",
      "Model in epoch 45 is saved.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 46: Train Loss = 0.004270286034209488, Recall = 1.0, Aging Rate = 0.5498095810783724, Precision = 0.999270871308786, f1 = 0.99963530269876\n",
      "Epoch 47: Train Loss = 0.004052256353648996, Recall = 1.0, Aging Rate = 0.5500100220485067, Precision = 0.9989067055393586, f1 = 0.9994530537830446\n",
      "Epoch 48: Train Loss = 0.004131479115529842, Recall = 1.0, Aging Rate = 0.5500100220485067, Precision = 0.9989067055393586, f1 = 0.9994530537830446\n",
      "Epoch 49: Train Loss = 0.00400978502533519, Recall = 1.0, Aging Rate = 0.5498095810783724, Precision = 0.999270871308786, f1 = 0.99963530269876\n",
      "Epoch 50: Train Loss = 0.003593617685220943, Recall = 1.0, Aging Rate = 0.5494086991381039, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0031502531956855897, Recall = 1.0, Aging Rate = 0.5496091401082381, precision = 0.99963530269876\n",
      "\n",
      "Epoch 51: Train Loss = 0.0036009101549566306, Recall = 1.0, Aging Rate = 0.5496091401082381, Precision = 0.99963530269876, f1 = 0.9998176180922853\n",
      "Epoch 52: Train Loss = 0.004259254736163127, Recall = 0.9996351696461145, Aging Rate = 0.5494086991381039, Precision = 0.9996351696461145, f1 = 0.9996351696461145\n",
      "Epoch 53: Train Loss = 0.003926473409039192, Recall = 1.0, Aging Rate = 0.5498095810783724, Precision = 0.999270871308786, f1 = 0.99963530269876\n",
      "Epoch 54: Train Loss = 0.003131930419568874, Recall = 1.0, Aging Rate = 0.5494086991381039, Precision = 0, f1 = 0.0\n",
      "Epoch 55: Train Loss = 0.003136242005709349, Recall = 1.0, Aging Rate = 0.5496091401082381, Precision = 0.99963530269876, f1 = 0.9998176180922853\n",
      "Test Loss = 0.0036251985016776413, Recall = 1.0, Aging Rate = 0.5494086991381039, precision = 1.0\n",
      "\n",
      "Epoch 56: Train Loss = 0.004049760524094281, Recall = 1.0, Aging Rate = 0.5500100220485067, Precision = 0.9989067055393586, f1 = 0.9994530537830446\n",
      "Epoch 57: Train Loss = 0.0035158176715298145, Recall = 1.0, Aging Rate = 0.5496091401082381, Precision = 0.99963530269876, f1 = 0.9998176180922853\n",
      "Epoch 58: Train Loss = 0.002795393197190731, Recall = 1.0, Aging Rate = 0.5494086991381039, Precision = 0, f1 = 0.0\n",
      "Epoch 59: Train Loss = 0.0029608855164173216, Recall = 1.0, Aging Rate = 0.5496091401082381, Precision = 0.99963530269876, f1 = 0.9998176180922853\n",
      "Epoch 60: Train Loss = 0.003899854318020198, Recall = 1.0, Aging Rate = 0.5498095810783724, Precision = 0.999270871308786, f1 = 0.99963530269876\n",
      "Test Loss = 0.003464131705613393, Recall = 1.0, Aging Rate = 0.550210463018641, precision = 0.9985428051001821\n",
      "\n",
      "Epoch 61: Train Loss = 0.0034134906579345154, Recall = 1.0, Aging Rate = 0.5500100220485067, Precision = 0.9989067055393586, f1 = 0.9994530537830446\n",
      "Epoch 62: Train Loss = 0.0026490083297049656, Recall = 1.0, Aging Rate = 0.5498095810783724, Precision = 0.999270871308786, f1 = 0.99963530269876\n",
      "Epoch 63: Train Loss = 0.002612985314110264, Recall = 1.0, Aging Rate = 0.5494086991381039, Precision = 0, f1 = 0.0\n",
      "Epoch 64: Train Loss = 0.002894520425900599, Recall = 1.0, Aging Rate = 0.5494086991381039, Precision = 0, f1 = 0.0\n",
      "Epoch 65: Train Loss = 0.002683986817003282, Recall = 1.0, Aging Rate = 0.5494086991381039, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0022770131507033092, Recall = 1.0, Aging Rate = 0.5494086991381039, precision = 1.0\n",
      "\n",
      "Epoch 66: Train Loss = 0.0026109245252763967, Recall = 1.0, Aging Rate = 0.5494086991381039, Precision = 0, f1 = 0.0\n",
      "Epoch 67: Train Loss = 0.002881440294120221, Recall = 1.0, Aging Rate = 0.5496091401082381, Precision = 0.99963530269876, f1 = 0.9998176180922853\n",
      "Epoch 68: Train Loss = 0.0025468838728193734, Recall = 1.0, Aging Rate = 0.5494086991381039, Precision = 0, f1 = 0.0\n",
      "Epoch 69: Train Loss = 0.0025790452478891457, Recall = 1.0, Aging Rate = 0.5496091401082381, Precision = 0.99963530269876, f1 = 0.9998176180922853\n",
      "Epoch 70: Train Loss = 0.0032621641689734144, Recall = 1.0, Aging Rate = 0.5494086991381039, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.002449123477173111, Recall = 1.0, Aging Rate = 0.5498095810783724, precision = 0.999270871308786\n",
      "\n",
      "Epoch 71: Train Loss = 0.002842486305251915, Recall = 1.0, Aging Rate = 0.5496091401082381, Precision = 0.99963530269876, f1 = 0.9998176180922853\n",
      "Epoch 72: Train Loss = 0.002709839162527828, Recall = 1.0, Aging Rate = 0.5494086991381039, Precision = 0, f1 = 0.0\n",
      "Epoch 73: Train Loss = 0.002875805975905513, Recall = 1.0, Aging Rate = 0.5494086991381039, Precision = 0, f1 = 0.0\n",
      "Epoch 74: Train Loss = 0.00296026624241774, Recall = 1.0, Aging Rate = 0.5496091401082381, Precision = 0.99963530269876, f1 = 0.9998176180922853\n",
      "Epoch 75: Train Loss = 0.003724992527622908, Recall = 1.0, Aging Rate = 0.5496091401082381, Precision = 0.99963530269876, f1 = 0.9998176180922853\n",
      "Test Loss = 0.0018954867946320395, Recall = 1.0, Aging Rate = 0.5494086991381039, precision = 1.0\n",
      "\n",
      "Epoch 76: Train Loss = 0.002959420052344884, Recall = 1.0, Aging Rate = 0.5496091401082381, Precision = 0.99963530269876, f1 = 0.9998176180922853\n",
      "Epoch 77: Train Loss = 0.0025828168611952244, Recall = 1.0, Aging Rate = 0.5494086991381039, Precision = 0, f1 = 0.0\n",
      "Epoch 78: Train Loss = 0.002340149183848934, Recall = 1.0, Aging Rate = 0.5494086991381039, Precision = 0, f1 = 0.0\n",
      "Epoch 79: Train Loss = 0.0022553086604844234, Recall = 1.0, Aging Rate = 0.5494086991381039, Precision = 0, f1 = 0.0\n",
      "Epoch 80: Train Loss = 0.002493066873999604, Recall = 1.0, Aging Rate = 0.5496091401082381, Precision = 0.99963530269876, f1 = 0.9998176180922853\n",
      "Test Loss = 0.0021652716092409154, Recall = 1.0, Aging Rate = 0.5494086991381039, precision = 1.0\n",
      "\n",
      "Epoch 81: Train Loss = 0.0024122108791352413, Recall = 1.0, Aging Rate = 0.5494086991381039, Precision = 0, f1 = 0.0\n",
      "Epoch 82: Train Loss = 0.003024710491254827, Recall = 1.0, Aging Rate = 0.5498095810783724, Precision = 0.999270871308786, f1 = 0.99963530269876\n",
      "Epoch 83: Train Loss = 0.0033164561458647337, Recall = 0.9996351696461145, Aging Rate = 0.5494086991381039, Precision = 0.9996351696461145, f1 = 0.9996351696461145\n",
      "Epoch 84: Train Loss = 0.0024622617423410067, Recall = 1.0, Aging Rate = 0.5496091401082381, Precision = 0.99963530269876, f1 = 0.9998176180922853\n",
      "Epoch 85: Train Loss = 0.0029128336616545186, Recall = 0.9996351696461145, Aging Rate = 0.5492082581679696, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.002780761442005882, Recall = 1.0, Aging Rate = 0.5494086991381039, precision = 1.0\n",
      "\n",
      "Epoch 86: Train Loss = 0.0027945543788282, Recall = 1.0, Aging Rate = 0.5494086991381039, Precision = 0, f1 = 0.0\n",
      "Epoch 87: Train Loss = 0.0021271354524057683, Recall = 1.0, Aging Rate = 0.5494086991381039, Precision = 0, f1 = 0.0\n",
      "Epoch 88: Train Loss = 0.002227969355821478, Recall = 1.0, Aging Rate = 0.5494086991381039, Precision = 0, f1 = 0.0\n",
      "Epoch 89: Train Loss = 0.0022488027831538016, Recall = 1.0, Aging Rate = 0.5494086991381039, Precision = 0, f1 = 0.0\n",
      "Epoch 90: Train Loss = 0.002146901013238154, Recall = 1.0, Aging Rate = 0.5494086991381039, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.002339303715853254, Recall = 1.0, Aging Rate = 0.5494086991381039, precision = 1.0\n",
      "\n",
      "Epoch 91: Train Loss = 0.002324581468908318, Recall = 1.0, Aging Rate = 0.5494086991381039, Precision = 0, f1 = 0.0\n",
      "Epoch 92: Train Loss = 0.0028208905077418234, Recall = 0.9996351696461145, Aging Rate = 0.5494086991381039, Precision = 0.9996351696461145, f1 = 0.9996351696461145\n",
      "Epoch 93: Train Loss = 0.0037672370541319967, Recall = 1.0, Aging Rate = 0.550210463018641, Precision = 0.9985428051001821, f1 = 0.999270871308786\n",
      "Epoch 94: Train Loss = 0.002473235899633561, Recall = 1.0, Aging Rate = 0.5494086991381039, Precision = 0, f1 = 0.0\n",
      "Epoch 95: Train Loss = 0.002593965746486986, Recall = 1.0, Aging Rate = 0.5498095810783724, Precision = 0.999270871308786, f1 = 0.99963530269876\n",
      "Test Loss = 0.0032534165710211174, Recall = 0.9992703392922291, Aging Rate = 0.5490078171978352, precision = 1.0\n",
      "\n",
      "Training Finished at epoch 95.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9955c848b758433e833ee1ed90df0e42",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss = 0.502148015032218, Recall = 0.9719080627508209, Aging Rate = 0.9238324313489678, Precision = 0.5779995660663918, f1 = 0.7248979591836734\n",
      "Epoch 2: Train Loss = 0.3246056528470396, Recall = 0.9668004377964247, Aging Rate = 0.7019442774103026, Precision = 0.7567104511707595, f1 = 0.8489508249239148\n",
      "Epoch 3: Train Loss = 0.2476332792539973, Recall = 0.9653411163808829, Aging Rate = 0.6434155141310884, Precision = 0.8242990654205608, f1 = 0.8892623088556546\n",
      "Epoch 4: Train Loss = 0.19524460053827414, Recall = 0.9722728931047063, Aging Rate = 0.6223692122669874, Precision = 0.8582930756843801, f1 = 0.9117345193294562\n",
      "Epoch 5: Train Loss = 0.1567117895406075, Recall = 0.9773805180591025, Aging Rate = 0.5993185007015434, Precision = 0.8959866220735786, f1 = 0.9349153725353343\n",
      "Test Loss = 0.12326747839264221, Recall = 0.9861364465523531, Aging Rate = 0.5824814592102626, precision = 0.9301445285615967\n",
      "Model in epoch 5 is saved.\n",
      "\n",
      "Epoch 6: Train Loss = 0.11413109705291165, Recall = 0.9850419554906968, Aging Rate = 0.5814792543595911, Precision = 0.9307135470527405, f1 = 0.957107408720312\n",
      "Epoch 7: Train Loss = 0.09165439895552274, Recall = 0.9872309376140095, Aging Rate = 0.5708558829424735, Precision = 0.9501404494382022, f1 = 0.9683306494900698\n",
      "Epoch 8: Train Loss = 0.07575274852703152, Recall = 0.990149580445093, Aging Rate = 0.5666466225696533, Precision = 0.9600282985496993, f1 = 0.9748563218390804\n",
      "Epoch 9: Train Loss = 0.06223195122424599, Recall = 0.9948923750456038, Aging Rate = 0.5638404489877731, Precision = 0.969427657305368, f1 = 0.9819949585884048\n",
      "Epoch 10: Train Loss = 0.053111307304311454, Recall = 0.9945275446917183, Aging Rate = 0.5596311886149529, Precision = 0.9763610315186246, f1 = 0.9853605638893909\n",
      "Test Loss = 0.04635528622370226, Recall = 0.9934330536300621, Aging Rate = 0.5528161956303869, precision = 0.9873096446700508\n",
      "Model in epoch 10 is saved.\n",
      "\n",
      "Epoch 11: Train Loss = 0.04536921361834259, Recall = 0.9948923750456038, Aging Rate = 0.5578272198837443, Precision = 0.9798778296802012, f1 = 0.9873280231716147\n",
      "Epoch 12: Train Loss = 0.039796917765920446, Recall = 0.996716526815031, Aging Rate = 0.5558228101824013, Precision = 0.9852145690587811, f1 = 0.9909321726514327\n",
      "Epoch 13: Train Loss = 0.03408876653125229, Recall = 0.9974461875228019, Aging Rate = 0.5544197233914612, Precision = 0.9884309472161966, f1 = 0.9929181042309788\n",
      "Epoch 14: Train Loss = 0.030254539460172262, Recall = 0.9985406785844583, Aging Rate = 0.5540188414511926, Precision = 0.9902315484804631, f1 = 0.9943687556766576\n",
      "Epoch 15: Train Loss = 0.02663815208974129, Recall = 0.9992703392922291, Aging Rate = 0.5532170775706554, Precision = 0.9923913043478261, f1 = 0.9958189420105436\n",
      "Test Loss = 0.02239728371836178, Recall = 0.9989055089383436, Aging Rate = 0.5516135498095811, precision = 0.9949127906976745\n",
      "Model in epoch 15 is saved.\n",
      "\n",
      "Epoch 16: Train Loss = 0.023512443700067193, Recall = 0.9996351696461145, Aging Rate = 0.5534175185407897, Precision = 0.9923940601231438, f1 = 0.9960014540167212\n",
      "Epoch 17: Train Loss = 0.020594348947673074, Recall = 0.9996351696461145, Aging Rate = 0.5526157546602526, Precision = 0.9938338774029742, f1 = 0.9967260822117134\n",
      "Epoch 18: Train Loss = 0.01869626043832587, Recall = 0.9996351696461145, Aging Rate = 0.5528161956303869, Precision = 0.9934735315445975, f1 = 0.9965448263320604\n",
      "Epoch 19: Train Loss = 0.01712329960025893, Recall = 0.9996351696461145, Aging Rate = 0.5522148727199839, Precision = 0.9945553539019963, f1 = 0.9970887918486172\n",
      "Epoch 20: Train Loss = 0.015150570133497491, Recall = 0.9996351696461145, Aging Rate = 0.5518139907797154, Precision = 0.995277878677806, f1 = 0.9974517655624318\n",
      "Test Loss = 0.01456646456841083, Recall = 0.9996351696461145, Aging Rate = 0.5498095810783724, precision = 0.998906306963179\n",
      "Model in epoch 20 is saved.\n",
      "\n",
      "Epoch 21: Train Loss = 0.014290610158535593, Recall = 0.9996351696461145, Aging Rate = 0.5518139907797154, Precision = 0.995277878677806, f1 = 0.9974517655624318\n",
      "Epoch 22: Train Loss = 0.012729473670768723, Recall = 1.0, Aging Rate = 0.5510122268991782, Precision = 0.9970898508548564, f1 = 0.9985428051001822\n",
      "Epoch 23: Train Loss = 0.011373044079549328, Recall = 1.0, Aging Rate = 0.5508117859290439, Precision = 0.99745269286754, f1 = 0.9987247221716159\n",
      "Epoch 24: Train Loss = 0.011356278367625804, Recall = 0.9989055089383436, Aging Rate = 0.550210463018641, Precision = 0.9974499089253187, f1 = 0.998177178271965\n",
      "Epoch 25: Train Loss = 0.010127942529942868, Recall = 1.0, Aging Rate = 0.5506113449589096, Precision = 0.9978157990535129, f1 = 0.9989067055393587\n",
      "Test Loss = 0.008474275122284082, Recall = 1.0, Aging Rate = 0.5504109039887753, precision = 0.9981791697013839\n",
      "\n",
      "Epoch 26: Train Loss = 0.009548173637903508, Recall = 1.0, Aging Rate = 0.5510122268991782, Precision = 0.9970898508548564, f1 = 0.9985428051001822\n",
      "Epoch 27: Train Loss = 0.009128820559722636, Recall = 0.9996351696461145, Aging Rate = 0.550210463018641, Precision = 0.9981785063752276, f1 = 0.998906306963179\n",
      "Epoch 28: Train Loss = 0.008059259850875673, Recall = 0.9996351696461145, Aging Rate = 0.5500100220485067, Precision = 0.9985422740524781, f1 = 0.9990884229717412\n",
      "Epoch 29: Train Loss = 0.008275238606753228, Recall = 1.0, Aging Rate = 0.5506113449589096, Precision = 0.9978157990535129, f1 = 0.9989067055393587\n",
      "Epoch 30: Train Loss = 0.007076950027148347, Recall = 1.0, Aging Rate = 0.5506113449589096, Precision = 0.9978157990535129, f1 = 0.9989067055393587\n",
      "Test Loss = 0.006048856525752663, Recall = 1.0, Aging Rate = 0.5500100220485067, precision = 0.9989067055393586\n",
      "Model in epoch 30 is saved.\n",
      "\n",
      "Epoch 31: Train Loss = 0.007036661673960717, Recall = 1.0, Aging Rate = 0.550210463018641, Precision = 0.9985428051001821, f1 = 0.999270871308786\n",
      "Epoch 32: Train Loss = 0.006309378700841224, Recall = 1.0, Aging Rate = 0.5500100220485067, Precision = 0.9989067055393586, f1 = 0.9994530537830446\n",
      "Epoch 33: Train Loss = 0.0064779618632897365, Recall = 0.9996351696461145, Aging Rate = 0.5504109039887753, Precision = 0.9978150036416606, f1 = 0.9987242573355203\n",
      "Epoch 34: Train Loss = 0.005750068564096376, Recall = 1.0, Aging Rate = 0.550210463018641, Precision = 0.9985428051001821, f1 = 0.999270871308786\n",
      "Epoch 35: Train Loss = 0.005626557957967917, Recall = 0.9996351696461145, Aging Rate = 0.5496091401082381, Precision = 0.9992706053975201, f1 = 0.9994528542768557\n",
      "Test Loss = 0.004466706795696715, Recall = 1.0, Aging Rate = 0.5500100220485067, precision = 0.9989067055393586\n",
      "\n",
      "Epoch 36: Train Loss = 0.0054237814363925505, Recall = 1.0, Aging Rate = 0.5500100220485067, Precision = 0.9989067055393586, f1 = 0.9994530537830446\n",
      "Epoch 37: Train Loss = 0.004808281266605035, Recall = 1.0, Aging Rate = 0.5500100220485067, Precision = 0.9989067055393586, f1 = 0.9994530537830446\n",
      "Epoch 38: Train Loss = 0.004904544118255688, Recall = 1.0, Aging Rate = 0.550210463018641, Precision = 0.9985428051001821, f1 = 0.999270871308786\n",
      "Epoch 39: Train Loss = 0.004550604150072562, Recall = 1.0, Aging Rate = 0.5500100220485067, Precision = 0.9989067055393586, f1 = 0.9994530537830446\n",
      "Epoch 40: Train Loss = 0.004411778187162325, Recall = 1.0, Aging Rate = 0.550210463018641, Precision = 0.9985428051001821, f1 = 0.999270871308786\n",
      "Test Loss = 0.0043171654486818525, Recall = 1.0, Aging Rate = 0.5498095810783724, precision = 0.999270871308786\n",
      "Model in epoch 40 is saved.\n",
      "\n",
      "Epoch 41: Train Loss = 0.004016785945136255, Recall = 1.0, Aging Rate = 0.5498095810783724, Precision = 0.999270871308786, f1 = 0.99963530269876\n",
      "Epoch 42: Train Loss = 0.004303903770275559, Recall = 1.0, Aging Rate = 0.5500100220485067, Precision = 0.9989067055393586, f1 = 0.9994530537830446\n",
      "Epoch 43: Train Loss = 0.0039038298453513655, Recall = 0.9996351696461145, Aging Rate = 0.5494086991381039, Precision = 0.9996351696461145, f1 = 0.9996351696461145\n",
      "Epoch 44: Train Loss = 0.003829862747188694, Recall = 1.0, Aging Rate = 0.5498095810783724, Precision = 0.999270871308786, f1 = 0.99963530269876\n",
      "Epoch 45: Train Loss = 0.004010326284478389, Recall = 1.0, Aging Rate = 0.5500100220485067, Precision = 0.9989067055393586, f1 = 0.9994530537830446\n",
      "Test Loss = 0.002889064986023161, Recall = 1.0, Aging Rate = 0.5496091401082381, precision = 0.99963530269876\n",
      "Model in epoch 45 is saved.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 46: Train Loss = 0.003916762094111397, Recall = 1.0, Aging Rate = 0.5500100220485067, Precision = 0.9989067055393586, f1 = 0.9994530537830446\n",
      "Epoch 47: Train Loss = 0.004046364054005888, Recall = 0.9996351696461145, Aging Rate = 0.5494086991381039, Precision = 0.9996351696461145, f1 = 0.9996351696461145\n",
      "Epoch 48: Train Loss = 0.003155973022155901, Recall = 1.0, Aging Rate = 0.5498095810783724, Precision = 0.999270871308786, f1 = 0.99963530269876\n",
      "Epoch 49: Train Loss = 0.002998149097410077, Recall = 1.0, Aging Rate = 0.5496091401082381, Precision = 0.99963530269876, f1 = 0.9998176180922853\n",
      "Epoch 50: Train Loss = 0.0031067834632039237, Recall = 1.0, Aging Rate = 0.5498095810783724, Precision = 0.999270871308786, f1 = 0.99963530269876\n",
      "Test Loss = 0.003120323859164885, Recall = 1.0, Aging Rate = 0.5498095810783724, precision = 0.999270871308786\n",
      "\n",
      "Epoch 51: Train Loss = 0.004225900889877219, Recall = 0.9996351696461145, Aging Rate = 0.5496091401082381, Precision = 0.9992706053975201, f1 = 0.9994528542768557\n",
      "Epoch 52: Train Loss = 0.0031245885459497296, Recall = 1.0, Aging Rate = 0.5496091401082381, Precision = 0.99963530269876, f1 = 0.9998176180922853\n",
      "Epoch 53: Train Loss = 0.0032994764705600566, Recall = 1.0, Aging Rate = 0.5496091401082381, Precision = 0.99963530269876, f1 = 0.9998176180922853\n",
      "Epoch 54: Train Loss = 0.003518864446733872, Recall = 1.0, Aging Rate = 0.550210463018641, Precision = 0.9985428051001821, f1 = 0.999270871308786\n",
      "Epoch 55: Train Loss = 0.002830496672426098, Recall = 1.0, Aging Rate = 0.5494086991381039, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0023284155855283492, Recall = 1.0, Aging Rate = 0.5496091401082381, precision = 0.99963530269876\n",
      "\n",
      "Epoch 56: Train Loss = 0.0028747813792002835, Recall = 1.0, Aging Rate = 0.5496091401082381, Precision = 0.99963530269876, f1 = 0.9998176180922853\n",
      "Epoch 57: Train Loss = 0.0028717211575482, Recall = 1.0, Aging Rate = 0.5496091401082381, Precision = 0.99963530269876, f1 = 0.9998176180922853\n",
      "Epoch 58: Train Loss = 0.002665335040966616, Recall = 1.0, Aging Rate = 0.5498095810783724, Precision = 0.999270871308786, f1 = 0.99963530269876\n",
      "Epoch 59: Train Loss = 0.0027745052903112547, Recall = 1.0, Aging Rate = 0.5496091401082381, Precision = 0.99963530269876, f1 = 0.9998176180922853\n",
      "Epoch 60: Train Loss = 0.0026536726936590435, Recall = 1.0, Aging Rate = 0.5496091401082381, Precision = 0.99963530269876, f1 = 0.9998176180922853\n",
      "Test Loss = 0.0020374518366092598, Recall = 1.0, Aging Rate = 0.5494086991381039, precision = 1.0\n",
      "Model in epoch 60 is saved.\n",
      "\n",
      "Epoch 61: Train Loss = 0.0030699063408977973, Recall = 1.0, Aging Rate = 0.5498095810783724, Precision = 0.999270871308786, f1 = 0.99963530269876\n",
      "Epoch 62: Train Loss = 0.0028125547515898556, Recall = 1.0, Aging Rate = 0.5496091401082381, Precision = 0.99963530269876, f1 = 0.9998176180922853\n",
      "Epoch 63: Train Loss = 0.0026157214570907013, Recall = 1.0, Aging Rate = 0.5496091401082381, Precision = 0.99963530269876, f1 = 0.9998176180922853\n",
      "Epoch 64: Train Loss = 0.003120307685765532, Recall = 1.0, Aging Rate = 0.5498095810783724, Precision = 0.999270871308786, f1 = 0.99963530269876\n",
      "Epoch 65: Train Loss = 0.0033482977702107082, Recall = 1.0, Aging Rate = 0.5496091401082381, Precision = 0.99963530269876, f1 = 0.9998176180922853\n",
      "Test Loss = 0.0031775460542286236, Recall = 1.0, Aging Rate = 0.5500100220485067, precision = 0.9989067055393586\n",
      "\n",
      "Epoch 66: Train Loss = 0.00261823824355011, Recall = 1.0, Aging Rate = 0.5496091401082381, Precision = 0.99963530269876, f1 = 0.9998176180922853\n",
      "Epoch 67: Train Loss = 0.002350426120334468, Recall = 1.0, Aging Rate = 0.5494086991381039, Precision = 0, f1 = 0.0\n",
      "Epoch 68: Train Loss = 0.002873300959177481, Recall = 1.0, Aging Rate = 0.5496091401082381, Precision = 0.99963530269876, f1 = 0.9998176180922853\n",
      "Epoch 69: Train Loss = 0.002603138243399843, Recall = 1.0, Aging Rate = 0.5496091401082381, Precision = 0.99963530269876, f1 = 0.9998176180922853\n",
      "Epoch 70: Train Loss = 0.002667946271870138, Recall = 1.0, Aging Rate = 0.5494086991381039, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0019504013455904667, Recall = 1.0, Aging Rate = 0.5494086991381039, precision = 1.0\n",
      "\n",
      "Epoch 71: Train Loss = 0.002762069001646948, Recall = 1.0, Aging Rate = 0.5496091401082381, Precision = 0.99963530269876, f1 = 0.9998176180922853\n",
      "Epoch 72: Train Loss = 0.0025439356768451145, Recall = 1.0, Aging Rate = 0.5494086991381039, Precision = 0, f1 = 0.0\n",
      "Epoch 73: Train Loss = 0.0029441819026992306, Recall = 1.0, Aging Rate = 0.5498095810783724, Precision = 0.999270871308786, f1 = 0.99963530269876\n",
      "Epoch 74: Train Loss = 0.002535081640917096, Recall = 1.0, Aging Rate = 0.5494086991381039, Precision = 0, f1 = 0.0\n",
      "Epoch 75: Train Loss = 0.0030451047773355174, Recall = 1.0, Aging Rate = 0.5496091401082381, Precision = 0.99963530269876, f1 = 0.9998176180922853\n",
      "Test Loss = 0.002541966191120091, Recall = 1.0, Aging Rate = 0.5498095810783724, precision = 0.999270871308786\n",
      "\n",
      "Epoch 76: Train Loss = 0.0025689129083512376, Recall = 1.0, Aging Rate = 0.5496091401082381, Precision = 0.99963530269876, f1 = 0.9998176180922853\n",
      "Epoch 77: Train Loss = 0.0030238999661790326, Recall = 1.0, Aging Rate = 0.5496091401082381, Precision = 0.99963530269876, f1 = 0.9998176180922853\n",
      "Epoch 78: Train Loss = 0.002148050878219916, Recall = 1.0, Aging Rate = 0.5496091401082381, Precision = 0.99963530269876, f1 = 0.9998176180922853\n",
      "Epoch 79: Train Loss = 0.002110526573621737, Recall = 1.0, Aging Rate = 0.5494086991381039, Precision = 0, f1 = 0.0\n",
      "Epoch 80: Train Loss = 0.002738177972613976, Recall = 0.9996351696461145, Aging Rate = 0.5494086991381039, Precision = 0.9996351696461145, f1 = 0.9996351696461145\n",
      "Test Loss = 0.00243258701499621, Recall = 1.0, Aging Rate = 0.5496091401082381, precision = 0.99963530269876\n",
      "\n",
      "Epoch 81: Train Loss = 0.002861842590181269, Recall = 1.0, Aging Rate = 0.5498095810783724, Precision = 0.999270871308786, f1 = 0.99963530269876\n",
      "Epoch 82: Train Loss = 0.00332944464900972, Recall = 0.9996351696461145, Aging Rate = 0.5496091401082381, Precision = 0.9992706053975201, f1 = 0.9994528542768557\n",
      "Epoch 83: Train Loss = 0.002317281346142779, Recall = 1.0, Aging Rate = 0.5494086991381039, Precision = 0, f1 = 0.0\n",
      "Epoch 84: Train Loss = 0.0021011735989151592, Recall = 1.0, Aging Rate = 0.5496091401082381, Precision = 0.99963530269876, f1 = 0.9998176180922853\n",
      "Epoch 85: Train Loss = 0.0021197618287185304, Recall = 1.0, Aging Rate = 0.5494086991381039, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0019432754206548989, Recall = 1.0, Aging Rate = 0.5494086991381039, precision = 1.0\n",
      "\n",
      "Epoch 86: Train Loss = 0.0021876561994733255, Recall = 1.0, Aging Rate = 0.5494086991381039, Precision = 0, f1 = 0.0\n",
      "Epoch 87: Train Loss = 0.002277394078343757, Recall = 1.0, Aging Rate = 0.5494086991381039, Precision = 0, f1 = 0.0\n",
      "Epoch 88: Train Loss = 0.0023052542405805946, Recall = 1.0, Aging Rate = 0.5494086991381039, Precision = 0, f1 = 0.0\n",
      "Epoch 89: Train Loss = 0.002486700264990515, Recall = 1.0, Aging Rate = 0.5496091401082381, Precision = 0.99963530269876, f1 = 0.9998176180922853\n",
      "Epoch 90: Train Loss = 0.00279095043868049, Recall = 1.0, Aging Rate = 0.5496091401082381, Precision = 0.99963530269876, f1 = 0.9998176180922853\n",
      "Test Loss = 0.0020927172236325244, Recall = 1.0, Aging Rate = 0.5496091401082381, precision = 0.99963530269876\n",
      "\n",
      "Epoch 91: Train Loss = 0.002495361085412518, Recall = 1.0, Aging Rate = 0.5496091401082381, Precision = 0.99963530269876, f1 = 0.9998176180922853\n",
      "Epoch 92: Train Loss = 0.0022699857601254886, Recall = 1.0, Aging Rate = 0.5494086991381039, Precision = 0, f1 = 0.0\n",
      "Epoch 93: Train Loss = 0.0021313449242481757, Recall = 1.0, Aging Rate = 0.5494086991381039, Precision = 0, f1 = 0.0\n",
      "Epoch 94: Train Loss = 0.002494744666026766, Recall = 1.0, Aging Rate = 0.5496091401082381, Precision = 0.99963530269876, f1 = 0.9998176180922853\n",
      "Epoch 95: Train Loss = 0.0023588360054651787, Recall = 1.0, Aging Rate = 0.5496091401082381, Precision = 0.99963530269876, f1 = 0.9998176180922853\n",
      "Test Loss = 0.002408854181213332, Recall = 1.0, Aging Rate = 0.5494086991381039, precision = 1.0\n",
      "\n",
      "Epoch 96: Train Loss = 0.0023582606577269823, Recall = 1.0, Aging Rate = 0.5494086991381039, Precision = 0, f1 = 0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 97: Train Loss = 0.0024263774560781977, Recall = 1.0, Aging Rate = 0.5494086991381039, Precision = 0, f1 = 0.0\n",
      "Epoch 98: Train Loss = 0.0023089130956486935, Recall = 1.0, Aging Rate = 0.5494086991381039, Precision = 0, f1 = 0.0\n",
      "Epoch 99: Train Loss = 0.0021865491545857148, Recall = 1.0, Aging Rate = 0.5494086991381039, Precision = 0, f1 = 0.0\n",
      "Epoch 100: Train Loss = 0.002385514116765568, Recall = 1.0, Aging Rate = 0.5494086991381039, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.002520193340571171, Recall = 1.0, Aging Rate = 0.5496091401082381, precision = 0.99963530269876\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "084b0b2ec55b434fa5da729cae395c64",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss = 0.48517542362882315, Recall = 0.9755474452554744, Aging Rate = 0.898757016840417, Precision = 0.5962525094802588, f1 = 0.7401356776962481\n",
      "Epoch 2: Train Loss = 0.3133802716743497, Recall = 0.964963503649635, Aging Rate = 0.6886527666399358, Precision = 0.7697234352256186, f1 = 0.8563562753036438\n",
      "Epoch 3: Train Loss = 0.24780292800644826, Recall = 0.9642335766423358, Aging Rate = 0.6467522052927025, Precision = 0.8189708617482951, f1 = 0.8856855514582636\n",
      "Epoch 4: Train Loss = 0.19840199169915682, Recall = 0.9748175182481752, Aging Rate = 0.6240978348035284, Precision = 0.8580147767426919, f1 = 0.9126943447804544\n",
      "Epoch 5: Train Loss = 0.16494839983217793, Recall = 0.9762773722627737, Aging Rate = 0.6094627105052125, Precision = 0.8799342105263158, f1 = 0.9256055363321799\n",
      "Test Loss = 0.13096296672545726, Recall = 0.9846715328467154, Aging Rate = 0.5900160384923817, precision = 0.9167516139993204\n",
      "Model in epoch 5 is saved.\n",
      "\n",
      "Epoch 6: Train Loss = 0.1243876316663066, Recall = 0.9854014598540146, Aging Rate = 0.5858059342421812, Precision = 0.9240246406570842, f1 = 0.9537265983751324\n",
      "Epoch 7: Train Loss = 0.09882974559508426, Recall = 0.9901459854014598, Aging Rate = 0.576383319967923, Precision = 0.9436521739130435, f1 = 0.966340160284951\n",
      "Epoch 8: Train Loss = 0.08146821546167399, Recall = 0.9901459854014598, Aging Rate = 0.5679631114675221, Precision = 0.9576420755382986, f1 = 0.9736228243315987\n",
      "Epoch 9: Train Loss = 0.06765267997980118, Recall = 0.9952554744525547, Aging Rate = 0.5671611868484362, Precision = 0.9639448568398727, f1 = 0.9793499730651822\n",
      "Epoch 10: Train Loss = 0.05702909226764558, Recall = 0.9956204379562044, Aging Rate = 0.5641539695268645, Precision = 0.9694385216773277, f1 = 0.9823550594166366\n",
      "Test Loss = 0.04789008004045668, Recall = 0.9956204379562044, Aging Rate = 0.5581395348837209, precision = 0.9798850574712644\n",
      "Model in epoch 10 is saved.\n",
      "\n",
      "Epoch 11: Train Loss = 0.048524850287863804, Recall = 0.9967153284671533, Aging Rate = 0.5595429029671211, Precision = 0.9785023289143676, f1 = 0.9875248598806725\n",
      "Epoch 12: Train Loss = 0.041198232117816265, Recall = 0.9978102189781022, Aging Rate = 0.5579390537289495, Precision = 0.9823931009701761, f1 = 0.9900416440340394\n",
      "Epoch 13: Train Loss = 0.035535470006723066, Recall = 0.9978102189781022, Aging Rate = 0.5557337610264635, Precision = 0.9862914862914863, f1 = 0.9920174165457185\n",
      "Epoch 14: Train Loss = 0.0322112694140688, Recall = 0.9981751824817519, Aging Rate = 0.5547313552526063, Precision = 0.9884351282977955, f1 = 0.99328127837298\n",
      "Epoch 15: Train Loss = 0.028130356724274667, Recall = 0.9992700729927008, Aging Rate = 0.5539294306335204, Precision = 0.9909518639160333, f1 = 0.9950935853170998\n",
      "Test Loss = 0.023437845150984186, Recall = 1.0, Aging Rate = 0.5535284683239775, precision = 0.9923940601231438\n",
      "Model in epoch 15 is saved.\n",
      "\n",
      "Epoch 16: Train Loss = 0.024452276474855237, Recall = 0.9992700729927008, Aging Rate = 0.5531275060144346, Precision = 0.992388546574846, f1 = 0.9958174213493363\n",
      "Epoch 17: Train Loss = 0.02230645214904282, Recall = 0.9992700729927008, Aging Rate = 0.5527265437048917, Precision = 0.9931084512150888, f1 = 0.9961797344005822\n",
      "Epoch 18: Train Loss = 0.019983327403849806, Recall = 0.9996350364963503, Aging Rate = 0.5525260625501203, Precision = 0.9938316400580551, f1 = 0.9967248908296943\n",
      "Epoch 19: Train Loss = 0.018231328051020453, Recall = 1.0, Aging Rate = 0.5525260625501203, Precision = 0.9941944847605225, f1 = 0.9970887918486171\n",
      "Epoch 20: Train Loss = 0.016004900841614485, Recall = 1.0, Aging Rate = 0.551523656776263, Precision = 0.9960014540167212, f1 = 0.9979967219085777\n",
      "Test Loss = 0.013730177052921011, Recall = 1.0, Aging Rate = 0.5509222133119487, precision = 0.9970887918486172\n",
      "Model in epoch 20 is saved.\n",
      "\n",
      "Epoch 21: Train Loss = 0.014804913067881021, Recall = 0.9996350364963503, Aging Rate = 0.551523656776263, Precision = 0.9956379498364231, f1 = 0.997632489528319\n",
      "Epoch 22: Train Loss = 0.013283351778314892, Recall = 0.9996350364963503, Aging Rate = 0.5513231756214916, Precision = 0.996, f1 = 0.9978142076502731\n",
      "Epoch 23: Train Loss = 0.013449276287747964, Recall = 1.0, Aging Rate = 0.5513231756214916, Precision = 0.9963636363636363, f1 = 0.9981785063752276\n",
      "Epoch 24: Train Loss = 0.011357529626213725, Recall = 1.0, Aging Rate = 0.5509222133119487, Precision = 0.9970887918486172, f1 = 0.9985422740524782\n",
      "Epoch 25: Train Loss = 0.010617798547549495, Recall = 1.0, Aging Rate = 0.5509222133119487, Precision = 0.9970887918486172, f1 = 0.9985422740524782\n",
      "Test Loss = 0.008663191446442972, Recall = 1.0, Aging Rate = 0.5503207698476343, precision = 0.9981785063752276\n",
      "Model in epoch 25 is saved.\n",
      "\n",
      "Epoch 26: Train Loss = 0.010170097973211889, Recall = 0.9996350364963503, Aging Rate = 0.5509222133119487, Precision = 0.9967248908296943, f1 = 0.9981778425655976\n",
      "Epoch 27: Train Loss = 0.009325338249731847, Recall = 1.0, Aging Rate = 0.5505212510024058, Precision = 0.9978150036416606, f1 = 0.9989063069631791\n",
      "Epoch 28: Train Loss = 0.008147284987516277, Recall = 0.9996350364963503, Aging Rate = 0.5501202886928629, Precision = 0.9981778425655977, f1 = 0.99890590809628\n",
      "Epoch 29: Train Loss = 0.007664507955130497, Recall = 1.0, Aging Rate = 0.5503207698476343, Precision = 0.9981785063752276, f1 = 0.999088422971741\n",
      "Epoch 30: Train Loss = 0.007106958327586401, Recall = 1.0, Aging Rate = 0.5503207698476343, Precision = 0.9981785063752276, f1 = 0.999088422971741\n",
      "Test Loss = 0.005954702741391031, Recall = 1.0, Aging Rate = 0.54971932638332, precision = 0.9992706053975201\n",
      "Model in epoch 30 is saved.\n",
      "\n",
      "Epoch 31: Train Loss = 0.006729653362803155, Recall = 1.0, Aging Rate = 0.5503207698476343, Precision = 0.9981785063752276, f1 = 0.999088422971741\n",
      "Epoch 32: Train Loss = 0.006153148040324808, Recall = 1.0, Aging Rate = 0.5501202886928629, Precision = 0.9985422740524781, f1 = 0.99927060539752\n",
      "Epoch 33: Train Loss = 0.0059982587532203795, Recall = 1.0, Aging Rate = 0.5501202886928629, Precision = 0.9985422740524781, f1 = 0.99927060539752\n",
      "Epoch 34: Train Loss = 0.006253223925972329, Recall = 1.0, Aging Rate = 0.5499198075380914, Precision = 0.998906306963179, f1 = 0.9994528542768557\n",
      "Epoch 35: Train Loss = 0.005524699168792106, Recall = 1.0, Aging Rate = 0.5501202886928629, Precision = 0.9985422740524781, f1 = 0.99927060539752\n",
      "Test Loss = 0.004704568804515811, Recall = 1.0, Aging Rate = 0.54971932638332, precision = 0.9992706053975201\n",
      "\n",
      "Epoch 36: Train Loss = 0.00527091024067468, Recall = 1.0, Aging Rate = 0.5501202886928629, Precision = 0.9985422740524781, f1 = 0.99927060539752\n",
      "Epoch 37: Train Loss = 0.005241706781761471, Recall = 1.0, Aging Rate = 0.5505212510024058, Precision = 0.9978150036416606, f1 = 0.9989063069631791\n",
      "Epoch 38: Train Loss = 0.00475071699253217, Recall = 1.0, Aging Rate = 0.5499198075380914, Precision = 0.998906306963179, f1 = 0.9994528542768557\n",
      "Epoch 39: Train Loss = 0.004455071053921029, Recall = 1.0, Aging Rate = 0.5501202886928629, Precision = 0.9985422740524781, f1 = 0.99927060539752\n",
      "Epoch 40: Train Loss = 0.004136788436609717, Recall = 1.0, Aging Rate = 0.54971932638332, Precision = 0.9992706053975201, f1 = 0.9996351696461145\n",
      "Test Loss = 0.004356063479473986, Recall = 1.0, Aging Rate = 0.5495188452285485, precision = 0.9996351696461145\n",
      "Model in epoch 40 is saved.\n",
      "\n",
      "Epoch 41: Train Loss = 0.003840452426433587, Recall = 1.0, Aging Rate = 0.54971932638332, Precision = 0.9992706053975201, f1 = 0.9996351696461145\n",
      "Epoch 42: Train Loss = 0.003929984623994962, Recall = 1.0, Aging Rate = 0.54971932638332, Precision = 0.9992706053975201, f1 = 0.9996351696461145\n",
      "Epoch 43: Train Loss = 0.00404347366765037, Recall = 1.0, Aging Rate = 0.54971932638332, Precision = 0.9992706053975201, f1 = 0.9996351696461145\n",
      "Epoch 44: Train Loss = 0.004311183973171829, Recall = 1.0, Aging Rate = 0.5499198075380914, Precision = 0.998906306963179, f1 = 0.9994528542768557\n",
      "Epoch 45: Train Loss = 0.003735443784421386, Recall = 1.0, Aging Rate = 0.5499198075380914, Precision = 0.998906306963179, f1 = 0.9994528542768557\n",
      "Test Loss = 0.003108949015483129, Recall = 1.0, Aging Rate = 0.5499198075380914, precision = 0.998906306963179\n",
      "\n",
      "Epoch 46: Train Loss = 0.0035564270796240834, Recall = 1.0, Aging Rate = 0.5499198075380914, Precision = 0.998906306963179, f1 = 0.9994528542768557\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 47: Train Loss = 0.0036359281251513204, Recall = 0.9996350364963503, Aging Rate = 0.5493183640737771, Precision = 0.9996350364963503, f1 = 0.9996350364963503\n",
      "Epoch 48: Train Loss = 0.003365198678300442, Recall = 1.0, Aging Rate = 0.54971932638332, Precision = 0.9992706053975201, f1 = 0.9996351696461145\n",
      "Epoch 49: Train Loss = 0.003052254739283183, Recall = 1.0, Aging Rate = 0.54971932638332, Precision = 0.9992706053975201, f1 = 0.9996351696461145\n",
      "Epoch 50: Train Loss = 0.0030969080848301184, Recall = 1.0, Aging Rate = 0.5493183640737771, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.002612972284951744, Recall = 1.0, Aging Rate = 0.5495188452285485, precision = 0.9996351696461145\n",
      "\n",
      "Epoch 51: Train Loss = 0.003100165687822576, Recall = 1.0, Aging Rate = 0.5495188452285485, Precision = 0.9996351696461145, f1 = 0.9998175515416895\n",
      "Epoch 52: Train Loss = 0.0029582828656735186, Recall = 1.0, Aging Rate = 0.5495188452285485, Precision = 0.9996351696461145, f1 = 0.9998175515416895\n",
      "Epoch 53: Train Loss = 0.0031990823266861935, Recall = 1.0, Aging Rate = 0.5493183640737771, Precision = 0, f1 = 0.0\n",
      "Epoch 54: Train Loss = 0.0028096949246599256, Recall = 1.0, Aging Rate = 0.5495188452285485, Precision = 0.9996351696461145, f1 = 0.9998175515416895\n",
      "Epoch 55: Train Loss = 0.002774108388164673, Recall = 1.0, Aging Rate = 0.5495188452285485, Precision = 0.9996351696461145, f1 = 0.9998175515416895\n",
      "Test Loss = 0.002496043024954342, Recall = 1.0, Aging Rate = 0.5493183640737771, precision = 1.0\n",
      "Model in epoch 55 is saved.\n",
      "\n",
      "Epoch 56: Train Loss = 0.0029246288339765, Recall = 1.0, Aging Rate = 0.5493183640737771, Precision = 0, f1 = 0.0\n",
      "Epoch 57: Train Loss = 0.0028579460786328425, Recall = 1.0, Aging Rate = 0.5495188452285485, Precision = 0.9996351696461145, f1 = 0.9998175515416895\n",
      "Epoch 58: Train Loss = 0.0025827384649259847, Recall = 1.0, Aging Rate = 0.5495188452285485, Precision = 0.9996351696461145, f1 = 0.9998175515416895\n",
      "Epoch 59: Train Loss = 0.0026584820135338973, Recall = 1.0, Aging Rate = 0.5493183640737771, Precision = 0, f1 = 0.0\n",
      "Epoch 60: Train Loss = 0.0026014273616155937, Recall = 1.0, Aging Rate = 0.5495188452285485, Precision = 0.9996351696461145, f1 = 0.9998175515416895\n",
      "Test Loss = 0.00225129386345888, Recall = 1.0, Aging Rate = 0.5493183640737771, precision = 1.0\n",
      "\n",
      "Epoch 61: Train Loss = 0.0026644089809262643, Recall = 1.0, Aging Rate = 0.5493183640737771, Precision = 0, f1 = 0.0\n",
      "Epoch 62: Train Loss = 0.003007302617687066, Recall = 1.0, Aging Rate = 0.54971932638332, Precision = 0.9992706053975201, f1 = 0.9996351696461145\n",
      "Epoch 63: Train Loss = 0.0022750186365890915, Recall = 1.0, Aging Rate = 0.5495188452285485, Precision = 0.9996351696461145, f1 = 0.9998175515416895\n",
      "Epoch 64: Train Loss = 0.003976912886903598, Recall = 0.9996350364963503, Aging Rate = 0.5493183640737771, Precision = 0.9996350364963503, f1 = 0.9996350364963503\n",
      "Epoch 65: Train Loss = 0.0032368302853134218, Recall = 1.0, Aging Rate = 0.54971932638332, Precision = 0.9992706053975201, f1 = 0.9996351696461145\n",
      "Test Loss = 0.00268547696437845, Recall = 1.0, Aging Rate = 0.5493183640737771, precision = 1.0\n",
      "\n",
      "Epoch 66: Train Loss = 0.0023722928128471865, Recall = 1.0, Aging Rate = 0.5495188452285485, Precision = 0.9996351696461145, f1 = 0.9998175515416895\n",
      "Epoch 67: Train Loss = 0.002197085728785942, Recall = 1.0, Aging Rate = 0.5493183640737771, Precision = 0, f1 = 0.0\n",
      "Epoch 68: Train Loss = 0.002318759622375698, Recall = 1.0, Aging Rate = 0.5493183640737771, Precision = 0, f1 = 0.0\n",
      "Epoch 69: Train Loss = 0.0021322081556339073, Recall = 1.0, Aging Rate = 0.5493183640737771, Precision = 0, f1 = 0.0\n",
      "Epoch 70: Train Loss = 0.0038766384442354036, Recall = 0.9996350364963503, Aging Rate = 0.54971932638332, Precision = 0.9989059080962801, f1 = 0.9992703392922291\n",
      "Test Loss = 0.002778495897639038, Recall = 1.0, Aging Rate = 0.5495188452285485, precision = 0.9996351696461145\n",
      "\n",
      "Epoch 71: Train Loss = 0.0027825682162237746, Recall = 1.0, Aging Rate = 0.5495188452285485, Precision = 0.9996351696461145, f1 = 0.9998175515416895\n",
      "Epoch 72: Train Loss = 0.002357709438128527, Recall = 1.0, Aging Rate = 0.5495188452285485, Precision = 0.9996351696461145, f1 = 0.9998175515416895\n",
      "Epoch 73: Train Loss = 0.002034996518209493, Recall = 1.0, Aging Rate = 0.5493183640737771, Precision = 0, f1 = 0.0\n",
      "Epoch 74: Train Loss = 0.0021770716198206952, Recall = 1.0, Aging Rate = 0.5493183640737771, Precision = 0, f1 = 0.0\n",
      "Epoch 75: Train Loss = 0.0021446769234239635, Recall = 1.0, Aging Rate = 0.5493183640737771, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0018522470066235747, Recall = 1.0, Aging Rate = 0.5493183640737771, precision = 1.0\n",
      "\n",
      "Epoch 76: Train Loss = 0.0022122443729448455, Recall = 1.0, Aging Rate = 0.5493183640737771, Precision = 0, f1 = 0.0\n",
      "Epoch 77: Train Loss = 0.0024440291697277413, Recall = 1.0, Aging Rate = 0.5493183640737771, Precision = 0, f1 = 0.0\n",
      "Epoch 78: Train Loss = 0.0025042348913624345, Recall = 1.0, Aging Rate = 0.5495188452285485, Precision = 0.9996351696461145, f1 = 0.9998175515416895\n",
      "Epoch 79: Train Loss = 0.0023886617868705546, Recall = 1.0, Aging Rate = 0.5495188452285485, Precision = 0.9996351696461145, f1 = 0.9998175515416895\n",
      "Epoch 80: Train Loss = 0.0027888845127679368, Recall = 1.0, Aging Rate = 0.5495188452285485, Precision = 0.9996351696461145, f1 = 0.9998175515416895\n",
      "Test Loss = 0.002411529661732059, Recall = 1.0, Aging Rate = 0.5495188452285485, precision = 0.9996351696461145\n",
      "\n",
      "Epoch 81: Train Loss = 0.0025001499918009414, Recall = 1.0, Aging Rate = 0.5493183640737771, Precision = 0, f1 = 0.0\n",
      "Epoch 82: Train Loss = 0.0020499821209349484, Recall = 1.0, Aging Rate = 0.5493183640737771, Precision = 0, f1 = 0.0\n",
      "Epoch 83: Train Loss = 0.0023371580071969863, Recall = 1.0, Aging Rate = 0.5493183640737771, Precision = 0, f1 = 0.0\n",
      "Epoch 84: Train Loss = 0.0022661120364921945, Recall = 1.0, Aging Rate = 0.5495188452285485, Precision = 0.9996351696461145, f1 = 0.9998175515416895\n",
      "Epoch 85: Train Loss = 0.0022243999505644095, Recall = 1.0, Aging Rate = 0.5493183640737771, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.002549571568241945, Recall = 1.0, Aging Rate = 0.5493183640737771, precision = 1.0\n",
      "\n",
      "Epoch 86: Train Loss = 0.002116271712422915, Recall = 1.0, Aging Rate = 0.5493183640737771, Precision = 0, f1 = 0.0\n",
      "Epoch 87: Train Loss = 0.0024514919141854167, Recall = 1.0, Aging Rate = 0.5493183640737771, Precision = 0, f1 = 0.0\n",
      "Epoch 88: Train Loss = 0.002530559089143836, Recall = 1.0, Aging Rate = 0.54971932638332, Precision = 0.9992706053975201, f1 = 0.9996351696461145\n",
      "Epoch 89: Train Loss = 0.003623657734764392, Recall = 1.0, Aging Rate = 0.5495188452285485, Precision = 0.9996351696461145, f1 = 0.9998175515416895\n",
      "Epoch 90: Train Loss = 0.0023425724887630416, Recall = 1.0, Aging Rate = 0.5495188452285485, Precision = 0.9996351696461145, f1 = 0.9998175515416895\n",
      "Test Loss = 0.0016744044422561865, Recall = 1.0, Aging Rate = 0.5493183640737771, precision = 1.0\n",
      "\n",
      "Epoch 91: Train Loss = 0.0020805754679768273, Recall = 1.0, Aging Rate = 0.5493183640737771, Precision = 0, f1 = 0.0\n",
      "Epoch 92: Train Loss = 0.0022327461142788263, Recall = 1.0, Aging Rate = 0.5493183640737771, Precision = 0, f1 = 0.0\n",
      "Epoch 93: Train Loss = 0.002037117684819402, Recall = 1.0, Aging Rate = 0.5493183640737771, Precision = 0, f1 = 0.0\n",
      "Epoch 94: Train Loss = 0.002387111487764038, Recall = 1.0, Aging Rate = 0.5495188452285485, Precision = 0.9996351696461145, f1 = 0.9998175515416895\n",
      "Epoch 95: Train Loss = 0.002254112493306542, Recall = 1.0, Aging Rate = 0.5493183640737771, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.001875600841795576, Recall = 1.0, Aging Rate = 0.5493183640737771, precision = 1.0\n",
      "\n",
      "Epoch 96: Train Loss = 0.0020798451602145277, Recall = 1.0, Aging Rate = 0.5493183640737771, Precision = 0, f1 = 0.0\n",
      "Epoch 97: Train Loss = 0.002132545033194955, Recall = 1.0, Aging Rate = 0.5493183640737771, Precision = 0, f1 = 0.0\n",
      "Epoch 98: Train Loss = 0.002298255868886434, Recall = 1.0, Aging Rate = 0.5495188452285485, Precision = 0.9996351696461145, f1 = 0.9998175515416895\n",
      "Epoch 99: Train Loss = 0.0023298095459896705, Recall = 1.0, Aging Rate = 0.5493183640737771, Precision = 0, f1 = 0.0\n",
      "Epoch 100: Train Loss = 0.0026318443449529273, Recall = 1.0, Aging Rate = 0.5495188452285485, Precision = 0.9996351696461145, f1 = 0.9998175515416895\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss = 0.001782405485735897, Recall = 1.0, Aging Rate = 0.5493183640737771, precision = 1.0\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f263fa6c0c0e49d8a00b93d5a484176a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f7ed20c8ba84531aa93a72018856257",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss = 0.32823289750521717, Recall = 0.923932384341637, Aging Rate = 0.6212188612099644, Precision = 0.7436448263515932, f1 = 0.8240428486411426\n",
      "Epoch 2: Train Loss = 0.13303789863647938, Recall = 0.9661921708185054, Aging Rate = 0.5233540925266904, Precision = 0.9230769230769231, f1 = 0.9441425777005\n",
      "Epoch 3: Train Loss = 0.07976726245042268, Recall = 0.9777580071174378, Aging Rate = 0.5082295373665481, Precision = 0.9619256017505471, f1 = 0.9697771894992279\n",
      "Epoch 4: Train Loss = 0.06345690476618628, Recall = 0.9848754448398577, Aging Rate = 0.5129003558718861, Precision = 0.9601040763226366, f1 = 0.9723320158102767\n",
      "Epoch 5: Train Loss = 0.05646833398104297, Recall = 0.9857651245551602, Aging Rate = 0.5031138790035588, Precision = 0.9796640141467727, f1 = 0.9827050997782706\n",
      "Test Loss = 0.021490277666134556, Recall = 1.0, Aging Rate = 0.5031138790035588, precision = 0.9938107869142352\n",
      "Model in epoch 5 is saved.\n",
      "\n",
      "Epoch 6: Train Loss = 0.012099768577832928, Recall = 0.9991103202846975, Aging Rate = 0.5011120996441281, Precision = 0.9968930315135375, f1 = 0.998000444345701\n",
      "Epoch 7: Train Loss = 0.00534801233644362, Recall = 0.9995551601423488, Aging Rate = 0.5004448398576512, Precision = 0.9986666666666667, f1 = 0.9991107158737217\n",
      "Epoch 8: Train Loss = 0.005544093309684567, Recall = 0.9991103202846975, Aging Rate = 0.5, Precision = 0.9991103202846975, f1 = 0.9991103202846975\n",
      "Epoch 9: Train Loss = 0.003863495667266172, Recall = 0.9995551601423488, Aging Rate = 0.5004448398576512, Precision = 0.9986666666666667, f1 = 0.9991107158737217\n",
      "Epoch 10: Train Loss = 0.002381883196725785, Recall = 1.0, Aging Rate = 0.5004448398576512, Precision = 0.9991111111111111, f1 = 0.9995553579368608\n",
      "Test Loss = 0.0029513439520061665, Recall = 0.9991103202846975, Aging Rate = 0.49955516014234874, precision = 1.0\n",
      "Model in epoch 10 is saved.\n",
      "\n",
      "Epoch 11: Train Loss = 0.002251968699800732, Recall = 1.0, Aging Rate = 0.5002224199288257, Precision = 0.9995553579368608, f1 = 0.9997776295307983\n",
      "Epoch 12: Train Loss = 0.0024664058764108866, Recall = 0.9995551601423488, Aging Rate = 0.5, Precision = 0.9995551601423488, f1 = 0.9995551601423488\n",
      "Epoch 13: Train Loss = 0.0033364487181995993, Recall = 0.9995551601423488, Aging Rate = 0.5, Precision = 0.9995551601423488, f1 = 0.9995551601423488\n",
      "Epoch 14: Train Loss = 0.002919192698094795, Recall = 1.0, Aging Rate = 0.5004448398576512, Precision = 0.9991111111111111, f1 = 0.9995553579368608\n",
      "Epoch 15: Train Loss = 0.028628565806040403, Recall = 0.9928825622775801, Aging Rate = 0.5046708185053381, Precision = 0.9836932569413839, f1 = 0.9882665485941997\n",
      "Test Loss = 0.038661680652451735, Recall = 0.9879893238434164, Aging Rate = 0.5040035587188612, precision = 0.9801412180052956\n",
      "\n",
      "Epoch 16: Train Loss = 0.07054510446152654, Recall = 0.9777580071174378, Aging Rate = 0.5095640569395018, Precision = 0.9594063727629856, f1 = 0.9684952632738489\n",
      "Epoch 17: Train Loss = 0.021765279750177287, Recall = 0.9933274021352313, Aging Rate = 0.5028914590747331, Precision = 0.9876160990712074, f1 = 0.9904635174096251\n",
      "Epoch 18: Train Loss = 0.005083606537912883, Recall = 0.9995551601423488, Aging Rate = 0.5008896797153025, Precision = 0.9977797513321492, f1 = 0.9986666666666667\n",
      "Epoch 19: Train Loss = 0.001792695188005803, Recall = 0.9995551601423488, Aging Rate = 0.5, Precision = 0.9995551601423488, f1 = 0.9995551601423488\n",
      "Epoch 20: Train Loss = 0.0013222624866782399, Recall = 1.0, Aging Rate = 0.5002224199288257, Precision = 0.9995553579368608, f1 = 0.9997776295307983\n",
      "Test Loss = 0.0010016664198319696, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "Model in epoch 20 is saved.\n",
      "\n",
      "Epoch 21: Train Loss = 0.001053163866277161, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 22: Train Loss = 0.0010254720622198026, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 23: Train Loss = 0.001329828033101947, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 24: Train Loss = 0.0016133856338828312, Recall = 1.0, Aging Rate = 0.5002224199288257, Precision = 0.9995553579368608, f1 = 0.9997776295307983\n",
      "Epoch 25: Train Loss = 0.0015532055838005385, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0015463744461274576, Recall = 1.0, Aging Rate = 0.5002224199288257, precision = 0.9995553579368608\n",
      "\n",
      "Epoch 26: Train Loss = 0.0138095845450735, Recall = 0.9968861209964412, Aging Rate = 0.5015569395017794, Precision = 0.9937915742793791, f1 = 0.9953364423717522\n",
      "Epoch 27: Train Loss = 0.06573185785524414, Recall = 0.9822064056939501, Aging Rate = 0.5113434163701067, Precision = 0.9604175728577642, f1 = 0.9711897954695403\n",
      "Epoch 28: Train Loss = 0.013209906291217441, Recall = 0.99644128113879, Aging Rate = 0.5004448398576512, Precision = 0.9955555555555555, f1 = 0.9959982214317474\n",
      "Epoch 29: Train Loss = 0.007946624824515415, Recall = 0.9977758007117438, Aging Rate = 0.5011120996441281, Precision = 0.9955614735907679, f1 = 0.9966674072428349\n",
      "Epoch 30: Train Loss = 0.002827527929508389, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0010957537125506078, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 31: Train Loss = 0.00108709493236661, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 32: Train Loss = 0.0010951406622158025, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 33: Train Loss = 0.0011240940415085, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 34: Train Loss = 0.001522911883628798, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 35: Train Loss = 0.0016744837732041037, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0018092680347439572, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 36: Train Loss = 0.0016127619336175258, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 37: Train Loss = 0.002530300511864223, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 38: Train Loss = 0.060220457087527775, Recall = 0.9839857651245552, Aging Rate = 0.5106761565836299, Precision = 0.9634146341463414, f1 = 0.9735915492957746\n",
      "Epoch 39: Train Loss = 0.0378247168746999, Recall = 0.9875444839857651, Aging Rate = 0.5040035587188612, Precision = 0.9796999117387467, f1 = 0.9836065573770492\n",
      "Epoch 40: Train Loss = 0.015181237046426209, Recall = 0.9959964412811388, Aging Rate = 0.5013345195729537, Precision = 0.9933451641526175, f1 = 0.994669035984007\n",
      "Test Loss = 0.007796468753641093, Recall = 1.0, Aging Rate = 0.5026690391459074, precision = 0.9946902654867257\n",
      "\n",
      "Epoch 41: Train Loss = 0.005655539944996639, Recall = 0.9995551601423488, Aging Rate = 0.5008896797153025, Precision = 0.9977797513321492, f1 = 0.9986666666666667\n",
      "Epoch 42: Train Loss = 0.003591196749999861, Recall = 0.9995551601423488, Aging Rate = 0.5002224199288257, Precision = 0.9991107158737217, f1 = 0.9993328885923949\n",
      "Epoch 43: Train Loss = 0.001892831279056021, Recall = 0.9995551601423488, Aging Rate = 0.5, Precision = 0.9995551601423488, f1 = 0.9995551601423488\n",
      "Epoch 44: Train Loss = 0.001522419812479653, Recall = 1.0, Aging Rate = 0.5002224199288257, Precision = 0.9995553579368608, f1 = 0.9997776295307983\n",
      "Epoch 45: Train Loss = 0.0011461472177705678, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.000924515712644169, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 46: Train Loss = 0.0011204609898452604, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 47: Train Loss = 0.00123695011090759, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 48: Train Loss = 0.001481704283596822, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 49: Train Loss = 0.0019146451857885564, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 50: Train Loss = 0.024683840463254468, Recall = 0.9937722419928826, Aging Rate = 0.5026690391459074, Precision = 0.988495575221239, f1 = 0.9911268855368235\n",
      "Test Loss = 0.03774207165577446, Recall = 0.9977758007117438, Aging Rate = 0.5144572953736655, precision = 0.9697362732382188\n",
      "\n",
      "Epoch 51: Train Loss = 0.060659101925992484, Recall = 0.9822064056939501, Aging Rate = 0.5080071174377224, Precision = 0.9667250437828371, f1 = 0.9744042365401587\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 52: Train Loss = 0.018218794819572445, Recall = 0.9955516014234875, Aging Rate = 0.501779359430605, Precision = 0.9920212765957447, f1 = 0.9937833037300178\n",
      "Epoch 53: Train Loss = 0.004162274803170848, Recall = 1.0, Aging Rate = 0.5004448398576512, Precision = 0.9991111111111111, f1 = 0.9995553579368608\n",
      "Epoch 54: Train Loss = 0.0019177689518012253, Recall = 1.0, Aging Rate = 0.5004448398576512, Precision = 0.9991111111111111, f1 = 0.9995553579368608\n",
      "Epoch 55: Train Loss = 0.0012632049453400035, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0012732118989997195, Recall = 1.0, Aging Rate = 0.5002224199288257, precision = 0.9995553579368608\n",
      "\n",
      "Epoch 56: Train Loss = 0.0015826641027426207, Recall = 0.9995551601423488, Aging Rate = 0.4997775800711744, Precision = 0, f1 = 0.0\n",
      "Epoch 57: Train Loss = 0.0017318814260441002, Recall = 1.0, Aging Rate = 0.5002224199288257, Precision = 0.9995553579368608, f1 = 0.9997776295307983\n",
      "Epoch 58: Train Loss = 0.0013862854186002184, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 59: Train Loss = 0.002286072997274822, Recall = 1.0, Aging Rate = 0.5002224199288257, Precision = 0.9995553579368608, f1 = 0.9997776295307983\n",
      "Epoch 60: Train Loss = 0.006683517905537145, Recall = 0.9991103202846975, Aging Rate = 0.5013345195729537, Precision = 0.9964507542147294, f1 = 0.9977787649933363\n",
      "Test Loss = 0.02090733676417184, Recall = 0.9888790035587188, Aging Rate = 0.4944395017793594, precision = 1.0\n",
      "\n",
      "Epoch 61: Train Loss = 0.0285947742841697, Recall = 0.9928825622775801, Aging Rate = 0.5048932384341637, Precision = 0.9832599118942731, f1 = 0.9880478087649402\n",
      "Epoch 62: Train Loss = 0.022907294091450387, Recall = 0.9955516014234875, Aging Rate = 0.5042259786476868, Precision = 0.9872077635641817, f1 = 0.9913621262458472\n",
      "Epoch 63: Train Loss = 0.006820894593416027, Recall = 0.9986654804270463, Aging Rate = 0.5, Precision = 0.9986654804270463, f1 = 0.9986654804270463\n",
      "Epoch 64: Train Loss = 0.0035160232077019616, Recall = 1.0, Aging Rate = 0.5008896797153025, Precision = 0.9982238010657194, f1 = 0.9991111111111112\n",
      "Epoch 65: Train Loss = 0.001040575606919356, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0007790769070773833, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 66: Train Loss = 0.0009218245340565889, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 67: Train Loss = 0.0010430143431021277, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 68: Train Loss = 0.0012475247024140053, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 69: Train Loss = 0.0018770054776720319, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 70: Train Loss = 0.04601203433562773, Recall = 0.9870996441281139, Aging Rate = 0.5075622775800712, Precision = 0.9723926380368099, f1 = 0.9796909492273731\n",
      "Test Loss = 0.033444927610105625, Recall = 0.9986654804270463, Aging Rate = 0.513567615658363, precision = 0.9722823733217844\n",
      "\n",
      "Training Finished at epoch 70.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8681ef2d785b45259b30862ebe1ba94f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss = 0.319554906272167, Recall = 0.9337188612099644, Aging Rate = 0.6305604982206405, Precision = 0.7403880070546737, f1 = 0.8258902223096596\n",
      "Epoch 2: Train Loss = 0.13007426281787746, Recall = 0.9661921708185054, Aging Rate = 0.527135231316726, Precision = 0.9164556962025316, f1 = 0.9406669553919446\n",
      "Epoch 3: Train Loss = 0.07746160654781976, Recall = 0.9777580071174378, Aging Rate = 0.5097864768683275, Precision = 0.9589877835951134, f1 = 0.9682819383259912\n",
      "Epoch 4: Train Loss = 0.057474756905033494, Recall = 0.9857651245551602, Aging Rate = 0.5073398576512456, Precision = 0.9715037264357738, f1 = 0.9785824685361008\n",
      "Epoch 5: Train Loss = 0.04715157897970589, Recall = 0.9879893238434164, Aging Rate = 0.5060053380782918, Precision = 0.9762637362637363, f1 = 0.9820915321689144\n",
      "Test Loss = 0.020184679556757318, Recall = 1.0, Aging Rate = 0.5055604982206405, precision = 0.989001319841619\n",
      "Model in epoch 5 is saved.\n",
      "\n",
      "Epoch 6: Train Loss = 0.010164946404259214, Recall = 1.0, Aging Rate = 0.5015569395017794, Precision = 0.9968957871396896, f1 = 0.998445480790584\n",
      "Epoch 7: Train Loss = 0.005304729050187746, Recall = 0.9995551601423488, Aging Rate = 0.5, Precision = 0.9995551601423488, f1 = 0.9995551601423488\n",
      "Epoch 8: Train Loss = 0.004121123910036428, Recall = 0.9995551601423488, Aging Rate = 0.5, Precision = 0.9995551601423488, f1 = 0.9995551601423488\n",
      "Epoch 9: Train Loss = 0.0020967925821258637, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 10: Train Loss = 0.0019507610891180054, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0015596759258446307, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "Model in epoch 10 is saved.\n",
      "\n",
      "Epoch 11: Train Loss = 0.0018792818031137895, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 12: Train Loss = 0.001966365519828193, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 13: Train Loss = 0.006382791929691036, Recall = 0.9995551601423488, Aging Rate = 0.5006672597864769, Precision = 0.998223011994669, f1 = 0.9988886419204268\n",
      "Epoch 14: Train Loss = 0.0491367249908688, Recall = 0.9879893238434164, Aging Rate = 0.5115658362989324, Precision = 0.9656521739130435, f1 = 0.9766930518909411\n",
      "Epoch 15: Train Loss = 0.03669408812797446, Recall = 0.9902135231316725, Aging Rate = 0.5055604982206405, Precision = 0.9793224813022438, f1 = 0.9847378898473789\n",
      "Test Loss = 0.011280286684508015, Recall = 0.998220640569395, Aging Rate = 0.5015569395017794, precision = 0.9951219512195122\n",
      "\n",
      "Epoch 16: Train Loss = 0.009393282793545135, Recall = 0.9973309608540926, Aging Rate = 0.5011120996441281, Precision = 0.9951176209498447, f1 = 0.9962230615418796\n",
      "Epoch 17: Train Loss = 0.0041931281717112155, Recall = 0.9991103202846975, Aging Rate = 0.4997775800711744, Precision = 0.9995549621717846, f1 = 0.9993325917686319\n",
      "Epoch 18: Train Loss = 0.0011523922050750426, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 19: Train Loss = 0.0009428131924585847, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 20: Train Loss = 0.001110720423545715, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0009647017572484446, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 21: Train Loss = 0.00128396125450263, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 22: Train Loss = 0.0013408445796864671, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 23: Train Loss = 0.0016496281582427962, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 24: Train Loss = 0.001627242483664304, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 25: Train Loss = 0.0017148351979945717, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.003945970002792153, Recall = 1.0, Aging Rate = 0.5004448398576512, precision = 0.9991111111111111\n",
      "\n",
      "Epoch 26: Train Loss = 0.03951368347623177, Recall = 0.9906583629893239, Aging Rate = 0.5075622775800712, Precision = 0.9758983347940403, f1 = 0.9832229580573951\n",
      "Epoch 27: Train Loss = 0.06348855277602942, Recall = 0.9817615658362989, Aging Rate = 0.5075622775800712, Precision = 0.9671340929009641, f1 = 0.9743929359823399\n",
      "Epoch 28: Train Loss = 0.015222514699274521, Recall = 0.99644128113879, Aging Rate = 0.5024466192170819, Precision = 0.9915891987605135, f1 = 0.9940093188373641\n",
      "Epoch 29: Train Loss = 0.0046438589501335515, Recall = 0.9991103202846975, Aging Rate = 0.5006672597864769, Precision = 0.9977787649933363, f1 = 0.9984440986885974\n",
      "Epoch 30: Train Loss = 0.004537688604070477, Recall = 0.9991103202846975, Aging Rate = 0.5006672597864769, Precision = 0.9977787649933363, f1 = 0.9984440986885974\n",
      "Test Loss = 0.001231898471018717, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 31: Train Loss = 0.0012371569298215218, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 32: Train Loss = 0.001052487326091573, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 33: Train Loss = 0.0010389687460921771, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 34: Train Loss = 0.0012414387226961487, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 35: Train Loss = 0.0017864519061495424, Recall = 0.9995551601423488, Aging Rate = 0.4997775800711744, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0028341821535926284, Recall = 1.0, Aging Rate = 0.5002224199288257, precision = 0.9995553579368608\n",
      "\n",
      "Epoch 36: Train Loss = 0.002336486657415235, Recall = 1.0, Aging Rate = 0.5002224199288257, Precision = 0.9995553579368608, f1 = 0.9997776295307983\n",
      "Epoch 37: Train Loss = 0.011100170407937242, Recall = 0.9977758007117438, Aging Rate = 0.5028914590747331, Precision = 0.9920389208314905, f1 = 0.9948990907074738\n",
      "Epoch 38: Train Loss = 0.0494110796603066, Recall = 0.9866548042704626, Aging Rate = 0.5088967971530249, Precision = 0.9694055944055944, f1 = 0.9779541446208113\n",
      "Epoch 39: Train Loss = 0.025909629473926703, Recall = 0.9911032028469751, Aging Rate = 0.5015569395017794, Precision = 0.9880266075388027, f1 = 0.9895625138796358\n",
      "Epoch 40: Train Loss = 0.009639660392604516, Recall = 0.9977758007117438, Aging Rate = 0.5028914590747331, Precision = 0.9920389208314905, f1 = 0.9948990907074738\n",
      "Test Loss = 0.004885889869846165, Recall = 0.9991103202846975, Aging Rate = 0.5004448398576512, precision = 0.9982222222222222\n",
      "\n",
      "Epoch 41: Train Loss = 0.0032470835730078417, Recall = 0.9995551601423488, Aging Rate = 0.5004448398576512, Precision = 0.9986666666666667, f1 = 0.9991107158737217\n",
      "Epoch 42: Train Loss = 0.001278850319546737, Recall = 1.0, Aging Rate = 0.5004448398576512, Precision = 0.9991111111111111, f1 = 0.9995553579368608\n",
      "Epoch 43: Train Loss = 0.0012154209246180347, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 44: Train Loss = 0.000846423270028363, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 45: Train Loss = 0.0009665561680851034, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0009207580979330154, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 46: Train Loss = 0.0012155807663245769, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 47: Train Loss = 0.0015442272155418051, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 48: Train Loss = 0.0018452199634157943, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 49: Train Loss = 0.001422449842831153, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 50: Train Loss = 0.0018282357699219536, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0016218080329112178, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 51: Train Loss = 0.03522377213284214, Recall = 0.9893238434163701, Aging Rate = 0.5068950177935944, Precision = 0.9758666081614743, f1 = 0.9825491495471615\n",
      "Epoch 52: Train Loss = 0.03726603281833364, Recall = 0.9879893238434164, Aging Rate = 0.5057829181494662, Precision = 0.976693051890941, f1 = 0.9823087129588678\n",
      "Epoch 53: Train Loss = 0.029056842074301956, Recall = 0.9911032028469751, Aging Rate = 0.5028914590747331, Precision = 0.9854046881910659, f1 = 0.9882457307607008\n",
      "Epoch 54: Train Loss = 0.00936101176577133, Recall = 0.9973309608540926, Aging Rate = 0.4997775800711744, Precision = 0.9977748108589231, f1 = 0.9975528364849834\n",
      "Epoch 55: Train Loss = 0.0025470347317296917, Recall = 1.0, Aging Rate = 0.5002224199288257, Precision = 0.9995553579368608, f1 = 0.9997776295307983\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss = 0.001544179023845035, Recall = 1.0, Aging Rate = 0.5002224199288257, precision = 0.9995553579368608\n",
      "\n",
      "Epoch 56: Train Loss = 0.001203737941175348, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 57: Train Loss = 0.001030335665885127, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 58: Train Loss = 0.0010664456510904752, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 59: Train Loss = 0.0011360216230192153, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 60: Train Loss = 0.0014003464929118181, Recall = 1.0, Aging Rate = 0.5002224199288257, Precision = 0.9995553579368608, f1 = 0.9997776295307983\n",
      "Test Loss = 0.0014252600618335667, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Training Finished at epoch 60.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "566f1a8153cd46a2b819b09d3ea97a59",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss = 0.2963478073106542, Recall = 0.9372775800711743, Aging Rate = 0.6152135231316725, Precision = 0.7617498192335502, f1 = 0.840446749102513\n",
      "Epoch 2: Train Loss = 0.12032295213316259, Recall = 0.9706405693950177, Aging Rate = 0.5193505338078291, Precision = 0.934475374732334, f1 = 0.9522147065241108\n",
      "Epoch 3: Train Loss = 0.07772926646831621, Recall = 0.9804270462633452, Aging Rate = 0.5104537366548043, Precision = 0.9603485838779956, f1 = 0.9702839533348008\n",
      "Epoch 4: Train Loss = 0.05915060169411512, Recall = 0.9839857651245552, Aging Rate = 0.5028914590747331, Precision = 0.978328173374613, f1 = 0.9811488134841428\n",
      "Epoch 5: Train Loss = 0.049196139133777274, Recall = 0.9875444839857651, Aging Rate = 0.5048932384341637, Precision = 0.9779735682819384, f1 = 0.9827357237715804\n",
      "Test Loss = 0.024670766736132183, Recall = 0.9995551601423488, Aging Rate = 0.5057829181494662, precision = 0.9881266490765171\n",
      "Model in epoch 5 is saved.\n",
      "\n",
      "Epoch 6: Train Loss = 0.015186454824029446, Recall = 0.998220640569395, Aging Rate = 0.501779359430605, Precision = 0.9946808510638298, f1 = 0.9964476021314387\n",
      "Epoch 7: Train Loss = 0.005707422549359076, Recall = 0.9995551601423488, Aging Rate = 0.5002224199288257, Precision = 0.9991107158737217, f1 = 0.9993328885923949\n",
      "Epoch 8: Train Loss = 0.002900044651378072, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 9: Train Loss = 0.002551681149562032, Recall = 1.0, Aging Rate = 0.5002224199288257, Precision = 0.9995553579368608, f1 = 0.9997776295307983\n",
      "Epoch 10: Train Loss = 0.0018906715311303908, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.001503196765761491, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "Model in epoch 10 is saved.\n",
      "\n",
      "Epoch 11: Train Loss = 0.0019122879782126508, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 12: Train Loss = 0.001809772407284729, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 13: Train Loss = 0.0021511420926155385, Recall = 1.0, Aging Rate = 0.5002224199288257, Precision = 0.9995553579368608, f1 = 0.9997776295307983\n",
      "Epoch 14: Train Loss = 0.002208088410710021, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 15: Train Loss = 0.06037318053592355, Recall = 0.9839857651245552, Aging Rate = 0.5104537366548043, Precision = 0.963834422657952, f1 = 0.9738058551617873\n",
      "Test Loss = 0.03795767384929271, Recall = 0.9968861209964412, Aging Rate = 0.515346975088968, precision = 0.9671989641778161\n",
      "\n",
      "Epoch 16: Train Loss = 0.047279158050320326, Recall = 0.9884341637010676, Aging Rate = 0.5091192170818505, Precision = 0.9707295762341633, f1 = 0.9795018734846814\n",
      "Epoch 17: Train Loss = 0.023354429193172484, Recall = 0.9937722419928826, Aging Rate = 0.5033362989323843, Precision = 0.9871851524524967, f1 = 0.9904677455109733\n",
      "Epoch 18: Train Loss = 0.004861110329086929, Recall = 0.9991103202846975, Aging Rate = 0.5004448398576512, Precision = 0.9982222222222222, f1 = 0.9986660738105825\n",
      "Epoch 19: Train Loss = 0.003224032133936988, Recall = 0.9995551601423488, Aging Rate = 0.5004448398576512, Precision = 0.9986666666666667, f1 = 0.9991107158737217\n",
      "Epoch 20: Train Loss = 0.001849971183830892, Recall = 0.9995551601423488, Aging Rate = 0.5, Precision = 0.9995551601423488, f1 = 0.9995551601423488\n",
      "Test Loss = 0.0010587839197696376, Recall = 1.0, Aging Rate = 0.5002224199288257, precision = 0.9995553579368608\n",
      "\n",
      "Epoch 21: Train Loss = 0.0013466265017963827, Recall = 1.0, Aging Rate = 0.5002224199288257, Precision = 0.9995553579368608, f1 = 0.9997776295307983\n",
      "Epoch 22: Train Loss = 0.0013442310963233675, Recall = 1.0, Aging Rate = 0.5002224199288257, Precision = 0.9995553579368608, f1 = 0.9997776295307983\n",
      "Epoch 23: Train Loss = 0.001383680635561928, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 24: Train Loss = 0.001389604804766434, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 25: Train Loss = 0.00210078186011671, Recall = 1.0, Aging Rate = 0.5002224199288257, Precision = 0.9995553579368608, f1 = 0.9997776295307983\n",
      "Test Loss = 0.0037422971934613727, Recall = 0.9991103202846975, Aging Rate = 0.49955516014234874, precision = 1.0\n",
      "\n",
      "Epoch 26: Train Loss = 0.010803628539305273, Recall = 0.9973309608540926, Aging Rate = 0.5011120996441281, Precision = 0.9951176209498447, f1 = 0.9962230615418796\n",
      "Epoch 27: Train Loss = 0.06334709408577015, Recall = 0.9822064056939501, Aging Rate = 0.511788256227758, Precision = 0.9595827900912647, f1 = 0.9707628050120906\n",
      "Epoch 28: Train Loss = 0.022065765857431387, Recall = 0.9951067615658363, Aging Rate = 0.5024466192170819, Precision = 0.9902611775121736, f1 = 0.9926780563567784\n",
      "Epoch 29: Train Loss = 0.0054051109053752985, Recall = 0.9991103202846975, Aging Rate = 0.5004448398576512, Precision = 0.9982222222222222, f1 = 0.9986660738105825\n",
      "Epoch 30: Train Loss = 0.0031319473976985255, Recall = 1.0, Aging Rate = 0.5004448398576512, Precision = 0.9991111111111111, f1 = 0.9995553579368608\n",
      "Test Loss = 0.0014625179306463109, Recall = 1.0, Aging Rate = 0.5002224199288257, precision = 0.9995553579368608\n",
      "\n",
      "Epoch 31: Train Loss = 0.0013436082261904503, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 32: Train Loss = 0.003493963125442715, Recall = 0.9995551601423488, Aging Rate = 0.5006672597864769, Precision = 0.998223011994669, f1 = 0.9988886419204268\n",
      "Epoch 33: Train Loss = 0.0029444288871718367, Recall = 0.9995551601423488, Aging Rate = 0.5, Precision = 0.9995551601423488, f1 = 0.9995551601423488\n",
      "Epoch 34: Train Loss = 0.0020133014972917437, Recall = 0.9995551601423488, Aging Rate = 0.5, Precision = 0.9995551601423488, f1 = 0.9995551601423488\n",
      "Epoch 35: Train Loss = 0.0011433072581231011, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0009595904490178007, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 36: Train Loss = 0.0012248898173800049, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 37: Train Loss = 0.0013669846571975279, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 38: Train Loss = 0.0017578518647846377, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 39: Train Loss = 0.0020862161650014146, Recall = 1.0, Aging Rate = 0.5002224199288257, Precision = 0.9995553579368608, f1 = 0.9997776295307983\n",
      "Epoch 40: Train Loss = 0.022127865916002024, Recall = 0.9951067615658363, Aging Rate = 0.5028914590747331, Precision = 0.9893852277753207, f1 = 0.9922377467287646\n",
      "Test Loss = 0.14460103865050017, Recall = 0.9764234875444839, Aging Rate = 0.5480427046263345, precision = 0.890827922077922\n",
      "\n",
      "Epoch 41: Train Loss = 0.08386362800242055, Recall = 0.9777580071174378, Aging Rate = 0.513567615658363, Precision = 0.9519272412299696, f1 = 0.9646697388632873\n",
      "Epoch 42: Train Loss = 0.019096152156796904, Recall = 0.9951067615658363, Aging Rate = 0.5024466192170819, Precision = 0.9902611775121736, f1 = 0.9926780563567784\n",
      "Epoch 43: Train Loss = 0.0047156594082998155, Recall = 0.9991103202846975, Aging Rate = 0.5006672597864769, Precision = 0.9977787649933363, f1 = 0.9984440986885974\n",
      "Epoch 44: Train Loss = 0.0020119070789687255, Recall = 0.9995551601423488, Aging Rate = 0.5, Precision = 0.9995551601423488, f1 = 0.9995551601423488\n",
      "Epoch 45: Train Loss = 0.0015042756147205405, Recall = 1.0, Aging Rate = 0.5002224199288257, Precision = 0.9995553579368608, f1 = 0.9997776295307983\n",
      "Test Loss = 0.0009227145150025438, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 46: Train Loss = 0.0010905628065865328, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 47: Train Loss = 0.0011382294451905699, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 48: Train Loss = 0.0013482049229766948, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 49: Train Loss = 0.004411737330890098, Recall = 0.9995551601423488, Aging Rate = 0.5004448398576512, Precision = 0.9986666666666667, f1 = 0.9991107158737217\n",
      "Epoch 50: Train Loss = 0.003465993249821195, Recall = 0.9995551601423488, Aging Rate = 0.5, Precision = 0.9995551601423488, f1 = 0.9995551601423488\n",
      "Test Loss = 0.0016390289964748454, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 51: Train Loss = 0.001373596051111287, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 52: Train Loss = 0.001329510377842628, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 53: Train Loss = 0.0014214211761258756, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 54: Train Loss = 0.010460032460866396, Recall = 0.9973309608540926, Aging Rate = 0.5011120996441281, Precision = 0.9951176209498447, f1 = 0.9962230615418796\n",
      "Epoch 55: Train Loss = 0.09566171280832571, Recall = 0.9724199288256228, Aging Rate = 0.513567615658363, Precision = 0.9467301862278042, f1 = 0.9594031160851437\n",
      "Test Loss = 0.033143698251093624, Recall = 0.9973309608540926, Aging Rate = 0.5142348754448398, precision = 0.9697231833910035\n",
      "\n",
      "Epoch 56: Train Loss = 0.017266274193298483, Recall = 0.9968861209964412, Aging Rate = 0.5026690391459074, Precision = 0.9915929203539823, f1 = 0.9942324755989352\n",
      "Epoch 57: Train Loss = 0.005375857124216126, Recall = 0.9991103202846975, Aging Rate = 0.5, Precision = 0.9991103202846975, f1 = 0.9991103202846975\n",
      "Epoch 58: Train Loss = 0.0036477069083553177, Recall = 0.9995551601423488, Aging Rate = 0.5002224199288257, Precision = 0.9991107158737217, f1 = 0.9993328885923949\n",
      "Epoch 59: Train Loss = 0.0014970363202683786, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 60: Train Loss = 0.0013436899309997774, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0011710603020255027, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Training Finished at epoch 60.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd0790e8bbec43ce883f398c2a07e9e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss = 0.32406192227826847, Recall = 0.925711743772242, Aging Rate = 0.62144128113879, Precision = 0.7448103078024337, f1 = 0.8254660848869496\n",
      "Epoch 2: Train Loss = 0.13431005895774134, Recall = 0.9661921708185054, Aging Rate = 0.5246886120996441, Precision = 0.920729122509538, f1 = 0.9429129585413503\n",
      "Epoch 3: Train Loss = 0.07444297173640482, Recall = 0.9826512455516014, Aging Rate = 0.5097864768683275, Precision = 0.9637870855148342, f1 = 0.9731277533039647\n",
      "Epoch 4: Train Loss = 0.06839988701827691, Recall = 0.9848754448398577, Aging Rate = 0.5082295373665481, Precision = 0.9689277899343545, f1 = 0.9768365320979483\n",
      "Epoch 5: Train Loss = 0.05514280459913177, Recall = 0.9848754448398577, Aging Rate = 0.5028914590747331, Precision = 0.9792127377266696, f1 = 0.9820359281437125\n",
      "Test Loss = 0.018051460802926286, Recall = 1.0, Aging Rate = 0.5026690391459074, precision = 0.9946902654867257\n",
      "Model in epoch 5 is saved.\n",
      "\n",
      "Epoch 6: Train Loss = 0.013763622321964, Recall = 0.9986654804270463, Aging Rate = 0.5013345195729537, Precision = 0.9960070984915705, f1 = 0.9973345179920036\n",
      "Epoch 7: Train Loss = 0.005558524585703514, Recall = 1.0, Aging Rate = 0.5004448398576512, Precision = 0.9991111111111111, f1 = 0.9995553579368608\n",
      "Epoch 8: Train Loss = 0.0028444793771536443, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 9: Train Loss = 0.0021845275120647273, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 10: Train Loss = 0.001964510670569775, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0019471163056074936, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "Model in epoch 10 is saved.\n",
      "\n",
      "Epoch 11: Train Loss = 0.0020112389610795257, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 12: Train Loss = 0.001952493534708442, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 13: Train Loss = 0.0019223783832222382, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 14: Train Loss = 0.001998201656624264, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 15: Train Loss = 0.0022686897995351446, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0025716899733433628, Recall = 0.9995551601423488, Aging Rate = 0.4997775800711744, precision = 1.0\n",
      "\n",
      "Epoch 16: Train Loss = 0.06314368935772532, Recall = 0.9826512455516014, Aging Rate = 0.5104537366548043, Precision = 0.9625272331154684, f1 = 0.9724851419766675\n",
      "Epoch 17: Train Loss = 0.05697995589862104, Recall = 0.983540925266904, Aging Rate = 0.5088967971530249, Precision = 0.9663461538461539, f1 = 0.9748677248677249\n",
      "Epoch 18: Train Loss = 0.018385695583962594, Recall = 0.9955516014234875, Aging Rate = 0.5033362989323843, Precision = 0.9889527176314626, f1 = 0.992241188206606\n",
      "Epoch 19: Train Loss = 0.004750645684357567, Recall = 1.0, Aging Rate = 0.5008896797153025, Precision = 0.9982238010657194, f1 = 0.9991111111111112\n",
      "Epoch 20: Train Loss = 0.0016723514460582367, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0011072207079227563, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 21: Train Loss = 0.0011731243070490075, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 22: Train Loss = 0.0010668272118364193, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 23: Train Loss = 0.0011257583813392143, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 24: Train Loss = 0.0013383760186802146, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 25: Train Loss = 0.004219433550020262, Recall = 0.9995551601423488, Aging Rate = 0.5008896797153025, Precision = 0.9977797513321492, f1 = 0.9986666666666667\n",
      "Test Loss = 0.0042711876699820265, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 26: Train Loss = 0.014797041710926837, Recall = 0.9977758007117438, Aging Rate = 0.5037811387900356, Precision = 0.9902869757174393, f1 = 0.994017283403501\n",
      "Epoch 27: Train Loss = 0.01817908964067651, Recall = 0.994661921708185, Aging Rate = 0.5020017793594306, Precision = 0.9906956136464333, f1 = 0.9926748057713651\n",
      "Epoch 28: Train Loss = 0.02339690518909336, Recall = 0.9942170818505338, Aging Rate = 0.5040035587188612, Precision = 0.9863195057369815, f1 = 0.9902525476295967\n",
      "Epoch 29: Train Loss = 0.013578636524121664, Recall = 0.9968861209964412, Aging Rate = 0.5015569395017794, Precision = 0.9937915742793791, f1 = 0.9953364423717522\n",
      "Epoch 30: Train Loss = 0.010934917181094336, Recall = 0.9968861209964412, Aging Rate = 0.5015569395017794, Precision = 0.9937915742793791, f1 = 0.9953364423717522\n",
      "Test Loss = 0.006539365463383459, Recall = 0.9977758007117438, Aging Rate = 0.4988879003558719, precision = 1.0\n",
      "\n",
      "Epoch 31: Train Loss = 0.002491209804937177, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 32: Train Loss = 0.0009962838247511204, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 33: Train Loss = 0.0007789018278066533, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 34: Train Loss = 0.0008955364671926879, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 35: Train Loss = 0.0010313716542234253, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0009040359484928319, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 36: Train Loss = 0.0011680568390264046, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 37: Train Loss = 0.0013998410324988643, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 38: Train Loss = 0.0017844280998597047, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 39: Train Loss = 0.022884489183133513, Recall = 0.994661921708185, Aging Rate = 0.5046708185053381, Precision = 0.9854561480828559, f1 = 0.9900376355988487\n",
      "Epoch 40: Train Loss = 0.05423644703756554, Recall = 0.983540925266904, Aging Rate = 0.5077846975088968, Precision = 0.9684625492772667, f1 = 0.9759435003310528\n",
      "Test Loss = 0.013408997614397353, Recall = 0.9955516014234875, Aging Rate = 0.498220640569395, precision = 0.9991071428571429\n",
      "\n",
      "Epoch 41: Train Loss = 0.0146820548800851, Recall = 0.99644128113879, Aging Rate = 0.5020017793594306, Precision = 0.9924678777137793, f1 = 0.9944506104328523\n",
      "Epoch 42: Train Loss = 0.0031954637968712204, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 43: Train Loss = 0.0037842176952382744, Recall = 0.9995551601423488, Aging Rate = 0.5004448398576512, Precision = 0.9986666666666667, f1 = 0.9991107158737217\n",
      "Epoch 44: Train Loss = 0.002653804329131544, Recall = 0.9995551601423488, Aging Rate = 0.5002224199288257, Precision = 0.9991107158737217, f1 = 0.9993328885923949\n",
      "Epoch 45: Train Loss = 0.0009726865725215604, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0007681959147939584, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 46: Train Loss = 0.0009306810055304239, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 47: Train Loss = 0.001051985901789541, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 48: Train Loss = 0.0012583733286486533, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 49: Train Loss = 0.001449193405045455, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 50: Train Loss = 0.0015229167973082446, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0012554239317628944, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 51: Train Loss = 0.003732541392083376, Recall = 1.0, Aging Rate = 0.5002224199288257, Precision = 0.9995553579368608, f1 = 0.9997776295307983\n",
      "Epoch 52: Train Loss = 0.0734388168521716, Recall = 0.9817615658362989, Aging Rate = 0.5126779359430605, Precision = 0.9574837310195228, f1 = 0.9694706786734021\n",
      "Epoch 53: Train Loss = 0.023105810156913997, Recall = 0.9919928825622776, Aging Rate = 0.5026690391459074, Precision = 0.9867256637168141, f1 = 0.9893522626441881\n",
      "Epoch 54: Train Loss = 0.007988022300008737, Recall = 0.9986654804270463, Aging Rate = 0.5013345195729537, Precision = 0.9960070984915705, f1 = 0.9973345179920036\n",
      "Epoch 55: Train Loss = 0.0019214555322444498, Recall = 0.9995551601423488, Aging Rate = 0.5, Precision = 0.9995551601423488, f1 = 0.9995551601423488\n",
      "Test Loss = 0.001064291773749237, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 56: Train Loss = 0.0010284165322724265, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57: Train Loss = 0.0009530276570508913, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 58: Train Loss = 0.0010587020976646237, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 59: Train Loss = 0.0011805074838996, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 60: Train Loss = 0.0012667217402506845, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0011314921465526695, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Training Finished at epoch 60.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a7c3745db2c843899ed41c4ff96138ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss = 0.32247314944173944, Recall = 0.9190391459074733, Aging Rate = 0.6192170818505338, Precision = 0.7420977011494253, f1 = 0.8211446740858506\n",
      "Epoch 2: Train Loss = 0.13690902447838377, Recall = 0.9661921708185054, Aging Rate = 0.5240213523131673, Precision = 0.9219015280135824, f1 = 0.9435273675065161\n",
      "Epoch 3: Train Loss = 0.08924488348097563, Recall = 0.9741992882562278, Aging Rate = 0.5144572953736655, Precision = 0.9468223086900129, f1 = 0.9603157202367901\n",
      "Epoch 4: Train Loss = 0.06218933659436652, Recall = 0.983540925266904, Aging Rate = 0.5104537366548043, Precision = 0.9633986928104575, f1 = 0.9733656174334141\n",
      "Epoch 5: Train Loss = 0.05190886613776993, Recall = 0.983540925266904, Aging Rate = 0.5042259786476868, Precision = 0.9752977503308337, f1 = 0.9794019933554817\n",
      "Test Loss = 0.017781112555189063, Recall = 0.9977758007117438, Aging Rate = 0.5002224199288257, precision = 0.997332147621165\n",
      "Model in epoch 5 is saved.\n",
      "\n",
      "Epoch 6: Train Loss = 0.01505188856794237, Recall = 0.9973309608540926, Aging Rate = 0.5020017793594306, Precision = 0.9933540097474524, f1 = 0.9953385127635961\n",
      "Epoch 7: Train Loss = 0.007987089251504475, Recall = 0.9991103202846975, Aging Rate = 0.5004448398576512, Precision = 0.9982222222222222, f1 = 0.9986660738105825\n",
      "Epoch 8: Train Loss = 0.0036367667178968067, Recall = 1.0, Aging Rate = 0.5002224199288257, Precision = 0.9995553579368608, f1 = 0.9997776295307983\n",
      "Epoch 9: Train Loss = 0.0025339800061979514, Recall = 0.9995551601423488, Aging Rate = 0.5, Precision = 0.9995551601423488, f1 = 0.9995551601423488\n",
      "Epoch 10: Train Loss = 0.002928563194689954, Recall = 1.0, Aging Rate = 0.5002224199288257, Precision = 0.9995553579368608, f1 = 0.9997776295307983\n",
      "Test Loss = 0.0021211243003815597, Recall = 1.0, Aging Rate = 0.5002224199288257, precision = 0.9995553579368608\n",
      "Model in epoch 10 is saved.\n",
      "\n",
      "Epoch 11: Train Loss = 0.0021279437283718513, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 12: Train Loss = 0.0026125011968118174, Recall = 1.0, Aging Rate = 0.5002224199288257, Precision = 0.9995553579368608, f1 = 0.9997776295307983\n",
      "Epoch 13: Train Loss = 0.0021759416937854577, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 14: Train Loss = 0.002069151949127506, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 15: Train Loss = 0.0025706459385727355, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0028244719668241796, Recall = 1.0, Aging Rate = 0.5002224199288257, precision = 0.9995553579368608\n",
      "\n",
      "Epoch 16: Train Loss = 0.005221483406604158, Recall = 0.9995551601423488, Aging Rate = 0.5008896797153025, Precision = 0.9977797513321492, f1 = 0.9986666666666667\n",
      "Epoch 17: Train Loss = 0.09740048344495617, Recall = 0.974644128113879, Aging Rate = 0.5146797153024911, Precision = 0.9468452895419187, f1 = 0.9605436212187637\n",
      "Epoch 18: Train Loss = 0.03345699583406451, Recall = 0.9893238434163701, Aging Rate = 0.5028914590747331, Precision = 0.9836355594869527, f1 = 0.9864715014415614\n",
      "Epoch 19: Train Loss = 0.015171693563187873, Recall = 0.9973309608540926, Aging Rate = 0.5040035587188612, Precision = 0.9894086496028244, f1 = 0.9933540097474524\n",
      "Epoch 20: Train Loss = 0.003109490196676295, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.001428107831146969, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "Model in epoch 20 is saved.\n",
      "\n",
      "Epoch 21: Train Loss = 0.0013730284864384534, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 22: Train Loss = 0.0011273846521168232, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 23: Train Loss = 0.0011271647584883105, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 24: Train Loss = 0.0012172678863758956, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 25: Train Loss = 0.0026290455028941703, Recall = 1.0, Aging Rate = 0.5002224199288257, Precision = 0.9995553579368608, f1 = 0.9997776295307983\n",
      "Test Loss = 0.003703097123246693, Recall = 0.9995551601423488, Aging Rate = 0.5004448398576512, precision = 0.9986666666666667\n",
      "\n",
      "Epoch 26: Train Loss = 0.01040798125293908, Recall = 0.998220640569395, Aging Rate = 0.5024466192170819, Precision = 0.9933598937583001, f1 = 0.995784335478145\n",
      "Epoch 27: Train Loss = 0.03872489638616632, Recall = 0.9902135231316725, Aging Rate = 0.5042259786476868, Precision = 0.9819144243493604, f1 = 0.986046511627907\n",
      "Epoch 28: Train Loss = 0.02293484861833239, Recall = 0.9928825622775801, Aging Rate = 0.5022241992882562, Precision = 0.9884853852967228, f1 = 0.9906790945406125\n",
      "Epoch 29: Train Loss = 0.008744153445033485, Recall = 0.9973309608540926, Aging Rate = 0.5011120996441281, Precision = 0.9951176209498447, f1 = 0.9962230615418796\n",
      "Epoch 30: Train Loss = 0.006180579001846262, Recall = 1.0, Aging Rate = 0.5020017793594306, Precision = 0.9960124058484714, f1 = 0.9980022197558268\n",
      "Test Loss = 0.0025522127638577595, Recall = 1.0, Aging Rate = 0.5006672597864769, precision = 0.9986672589960017\n",
      "\n",
      "Epoch 31: Train Loss = 0.0020058221196715582, Recall = 1.0, Aging Rate = 0.5002224199288257, Precision = 0.9995553579368608, f1 = 0.9997776295307983\n",
      "Epoch 32: Train Loss = 0.0008666343261774471, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 33: Train Loss = 0.0008642063606646429, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 34: Train Loss = 0.0009881133658793222, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 35: Train Loss = 0.0017859709522234494, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0012100659799886358, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 36: Train Loss = 0.00143774771761295, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 37: Train Loss = 0.0028110163517708945, Recall = 1.0, Aging Rate = 0.5004448398576512, Precision = 0.9991111111111111, f1 = 0.9995553579368608\n",
      "Epoch 38: Train Loss = 0.051157981370661895, Recall = 0.9862099644128114, Aging Rate = 0.5093416370106761, Precision = 0.9681222707423581, f1 = 0.9770824151608638\n",
      "Epoch 39: Train Loss = 0.030239189812147932, Recall = 0.9919928825622776, Aging Rate = 0.5048932384341637, Precision = 0.9823788546255506, f1 = 0.9871624612660469\n",
      "Epoch 40: Train Loss = 0.022861441507027402, Recall = 0.9928825622775801, Aging Rate = 0.5022241992882562, Precision = 0.9884853852967228, f1 = 0.9906790945406125\n",
      "Test Loss = 0.006715191978119393, Recall = 0.9995551601423488, Aging Rate = 0.5006672597864769, precision = 0.998223011994669\n",
      "\n",
      "Epoch 41: Train Loss = 0.005244448920525445, Recall = 0.9991103202846975, Aging Rate = 0.5004448398576512, Precision = 0.9982222222222222, f1 = 0.9986660738105825\n",
      "Epoch 42: Train Loss = 0.004016924594790804, Recall = 0.9991103202846975, Aging Rate = 0.5002224199288257, Precision = 0.9986660738105825, f1 = 0.9988881476539915\n",
      "Epoch 43: Train Loss = 0.001138230005957168, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 44: Train Loss = 0.0007848508300616413, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 45: Train Loss = 0.0008608543546456062, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0008515098639283316, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 46: Train Loss = 0.0009536015534640068, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 47: Train Loss = 0.0012104148453257288, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 48: Train Loss = 0.0014111891882311804, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 49: Train Loss = 0.002000878568120579, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 50: Train Loss = 0.002146115782950322, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0013332382441925885, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 51: Train Loss = 0.001738209176719109, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 52: Train Loss = 0.0015153284646567367, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 53: Train Loss = 0.005748797401647478, Recall = 0.9991103202846975, Aging Rate = 0.5002224199288257, Precision = 0.9986660738105825, f1 = 0.9988881476539915\n",
      "Epoch 54: Train Loss = 0.0896481342855642, Recall = 0.9724199288256228, Aging Rate = 0.515346975088968, Precision = 0.9434613724643937, f1 = 0.9577217962760132\n",
      "Epoch 55: Train Loss = 0.023352749139448344, Recall = 0.9951067615658363, Aging Rate = 0.50355871886121, Precision = 0.9880742049469965, f1 = 0.9915780141843972\n",
      "Test Loss = 0.006160785097320601, Recall = 0.9986654804270463, Aging Rate = 0.49955516014234874, precision = 0.9995547640249333\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 56: Train Loss = 0.0065726574420849415, Recall = 0.9991103202846975, Aging Rate = 0.5006672597864769, Precision = 0.9977787649933363, f1 = 0.9984440986885974\n",
      "Epoch 57: Train Loss = 0.0029104338686257018, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 58: Train Loss = 0.0012386875887678147, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 59: Train Loss = 0.001214933147371392, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 60: Train Loss = 0.0011626315731729224, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0010370446875106437, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 61: Train Loss = 0.0012678407465921404, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 62: Train Loss = 0.0014249186776827, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 63: Train Loss = 0.0014836989242494026, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 64: Train Loss = 0.0015674016539511202, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 65: Train Loss = 0.0024864898478360415, Recall = 1.0, Aging Rate = 0.5004448398576512, Precision = 0.9991111111111111, f1 = 0.9995553579368608\n",
      "Test Loss = 0.002098937418843782, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 66: Train Loss = 0.004965513956847392, Recall = 1.0, Aging Rate = 0.5002224199288257, Precision = 0.9995553579368608, f1 = 0.9997776295307983\n",
      "Epoch 67: Train Loss = 0.051498011661879055, Recall = 0.9862099644128114, Aging Rate = 0.5095640569395018, Precision = 0.9676996944565692, f1 = 0.976867151354924\n",
      "Epoch 68: Train Loss = 0.032675729812623344, Recall = 0.9888790035587188, Aging Rate = 0.5033362989323843, Precision = 0.9823243482103402, f1 = 0.9855907780979827\n",
      "Epoch 69: Train Loss = 0.009438072479979609, Recall = 0.9977758007117438, Aging Rate = 0.5013345195729537, Precision = 0.9951197870452528, f1 = 0.9964460239893379\n",
      "Epoch 70: Train Loss = 0.001835043858914898, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0010191563478429899, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Training Finished at epoch 70.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4cb90e44d9047539e030e018ac87b91",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss = 0.3591331416389696, Recall = 0.8941281138790036, Aging Rate = 0.5798487544483986, Precision = 0.7710011507479861, f1 = 0.8280123583934088\n",
      "Epoch 2: Train Loss = 0.15548349781710907, Recall = 0.9488434163701067, Aging Rate = 0.5066725978647687, Precision = 0.9363476733977173, f1 = 0.9425541316836058\n",
      "Epoch 3: Train Loss = 0.08975339497959911, Recall = 0.9733096085409253, Aging Rate = 0.5015569395017794, Precision = 0.9702882483370289, f1 = 0.9717965800577393\n",
      "Epoch 4: Train Loss = 0.06350651234918642, Recall = 0.9813167259786477, Aging Rate = 0.5008896797153025, Precision = 0.9795737122557726, f1 = 0.9804444444444445\n",
      "Epoch 5: Train Loss = 0.049123469203233294, Recall = 0.9862099644128114, Aging Rate = 0.5020017793594306, Precision = 0.9822773593265397, f1 = 0.9842397336293008\n",
      "Test Loss = 0.019625110220283376, Recall = 1.0, Aging Rate = 0.5024466192170819, precision = 0.9951305887560867\n",
      "Model in epoch 5 is saved.\n",
      "\n",
      "Epoch 6: Train Loss = 0.014305387384977417, Recall = 0.998220640569395, Aging Rate = 0.5, Precision = 0.998220640569395, f1 = 0.998220640569395\n",
      "Epoch 7: Train Loss = 0.00655090332767028, Recall = 0.9995551601423488, Aging Rate = 0.4997775800711744, Precision = 0, f1 = 0.0\n",
      "Epoch 8: Train Loss = 0.004627468037912854, Recall = 1.0, Aging Rate = 0.5002224199288257, Precision = 0.9995553579368608, f1 = 0.9997776295307983\n",
      "Epoch 9: Train Loss = 0.004997411081393405, Recall = 0.9995551601423488, Aging Rate = 0.5006672597864769, Precision = 0.998223011994669, f1 = 0.9988886419204268\n",
      "Epoch 10: Train Loss = 0.0028803525774265737, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.002196959390560185, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "Model in epoch 10 is saved.\n",
      "\n",
      "Epoch 11: Train Loss = 0.002381836287876147, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 12: Train Loss = 0.002594294908101873, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 13: Train Loss = 0.0021224001253080087, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 14: Train Loss = 0.0023066535852252906, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 15: Train Loss = 0.0020126674462646725, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0018231568342651442, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 16: Train Loss = 0.002103180059453877, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 17: Train Loss = 0.002273342116434273, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 18: Train Loss = 0.0022860581160513054, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 19: Train Loss = 0.0021760506726125274, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 20: Train Loss = 0.002447946048905125, Recall = 1.0, Aging Rate = 0.5002224199288257, Precision = 0.9995553579368608, f1 = 0.9997776295307983\n",
      "Test Loss = 0.0034777694108342467, Recall = 0.9991103202846975, Aging Rate = 0.49955516014234874, precision = 1.0\n",
      "\n",
      "Epoch 21: Train Loss = 0.004824194049601878, Recall = 0.9995551601423488, Aging Rate = 0.4997775800711744, Precision = 0, f1 = 0.0\n",
      "Epoch 22: Train Loss = 0.03174778342982787, Recall = 0.9911032028469751, Aging Rate = 0.5022241992882562, Precision = 0.9867139061116031, f1 = 0.9889036839769196\n",
      "Epoch 23: Train Loss = 0.0554871005221565, Recall = 0.9795373665480427, Aging Rate = 0.5028914590747331, Precision = 0.9739053516143299, f1 = 0.9767132401862941\n",
      "Epoch 24: Train Loss = 0.025242551267594497, Recall = 0.9911032028469751, Aging Rate = 0.5008896797153025, Precision = 0.9893428063943162, f1 = 0.9902222222222222\n",
      "Epoch 25: Train Loss = 0.0037955482838570977, Recall = 1.0, Aging Rate = 0.5002224199288257, Precision = 0.9995553579368608, f1 = 0.9997776295307983\n",
      "Test Loss = 0.0027853348462269028, Recall = 1.0, Aging Rate = 0.5004448398576512, precision = 0.9991111111111111\n",
      "\n",
      "Epoch 26: Train Loss = 0.0016443268228173123, Recall = 1.0, Aging Rate = 0.5002224199288257, Precision = 0.9995553579368608, f1 = 0.9997776295307983\n",
      "Epoch 27: Train Loss = 0.0008250240496383794, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 28: Train Loss = 0.0008014923716013674, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 29: Train Loss = 0.0008891006422915175, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 30: Train Loss = 0.0009271182327819623, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0008694456255948337, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 31: Train Loss = 0.001056404511512214, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 32: Train Loss = 0.0010932562806481145, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 33: Train Loss = 0.0012120554064983813, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 34: Train Loss = 0.0012697363175987017, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 35: Train Loss = 0.0014135397364156738, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0013298392734984168, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 36: Train Loss = 0.0014575587931914369, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 37: Train Loss = 0.001992474934434207, Recall = 1.0, Aging Rate = 0.5002224199288257, Precision = 0.9995553579368608, f1 = 0.9997776295307983\n",
      "Epoch 38: Train Loss = 0.0017913962686202387, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 39: Train Loss = 0.0016861997977283608, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 40: Train Loss = 0.005831650041501134, Recall = 0.9991103202846975, Aging Rate = 0.5002224199288257, Precision = 0.9986660738105825, f1 = 0.9988881476539915\n",
      "Test Loss = 0.020401882581094617, Recall = 0.9902135231316725, Aging Rate = 0.49532918149466193, precision = 0.9995509654243376\n",
      "\n",
      "Epoch 41: Train Loss = 0.0757685477059878, Recall = 0.9777580071174378, Aging Rate = 0.5071174377224199, Precision = 0.9640350877192982, f1 = 0.9708480565371025\n",
      "Epoch 42: Train Loss = 0.02665619327207394, Recall = 0.9906583629893239, Aging Rate = 0.5011120996441281, Precision = 0.9884598313359965, f1 = 0.9895578760275494\n",
      "Epoch 43: Train Loss = 0.00910190924475122, Recall = 0.9977758007117438, Aging Rate = 0.5, Precision = 0.9977758007117438, f1 = 0.9977758007117438\n",
      "Epoch 44: Train Loss = 0.0029131360497040627, Recall = 0.9995551601423488, Aging Rate = 0.5002224199288257, Precision = 0.9991107158737217, f1 = 0.9993328885923949\n",
      "Epoch 45: Train Loss = 0.0016744372671473361, Recall = 1.0, Aging Rate = 0.5002224199288257, Precision = 0.9995553579368608, f1 = 0.9997776295307983\n",
      "Test Loss = 0.0011746661382929498, Recall = 0.9991103202846975, Aging Rate = 0.49955516014234874, precision = 1.0\n",
      "\n",
      "Epoch 46: Train Loss = 0.001485406303466745, Recall = 0.9995551601423488, Aging Rate = 0.5, Precision = 0.9995551601423488, f1 = 0.9995551601423488\n",
      "Epoch 47: Train Loss = 0.0008634356338550665, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 48: Train Loss = 0.000861500889610572, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 49: Train Loss = 0.0009869117554098209, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 50: Train Loss = 0.0010440765628988897, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0009614428463043957, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 51: Train Loss = 0.0011552721663838869, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 52: Train Loss = 0.001286066277284056, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 53: Train Loss = 0.0014472271589598754, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 54: Train Loss = 0.0013480410170393375, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 55: Train Loss = 0.0015789878296125614, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0013068171352267372, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 56: Train Loss = 0.0014937749808634304, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 57: Train Loss = 0.001550659367456714, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 58: Train Loss = 0.0015465559088210725, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59: Train Loss = 0.0018110157817509357, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 60: Train Loss = 0.0022007725209832935, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0024493182996897776, Recall = 1.0, Aging Rate = 0.5002224199288257, precision = 0.9995553579368608\n",
      "\n",
      "Training Finished at epoch 60.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa7ed8247d24475ba5c81a2a92a9644e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss = 0.3775796171715251, Recall = 0.8763345195729537, Aging Rate = 0.5647241992882562, Precision = 0.7758960220559276, f1 = 0.8230624608314184\n",
      "Epoch 2: Train Loss = 0.1657805600836608, Recall = 0.9466192170818505, Aging Rate = 0.5048932384341637, Precision = 0.9374449339207048, f1 = 0.9420097388224878\n",
      "Epoch 3: Train Loss = 0.0927854597011707, Recall = 0.9710854092526691, Aging Rate = 0.5020017793594306, Precision = 0.9672131147540983, f1 = 0.9691453940066593\n",
      "Epoch 4: Train Loss = 0.06904940158659029, Recall = 0.9795373665480427, Aging Rate = 0.5008896797153025, Precision = 0.977797513321492, f1 = 0.9786666666666667\n",
      "Epoch 5: Train Loss = 0.052598089417210676, Recall = 0.9839857651245552, Aging Rate = 0.5008896797153025, Precision = 0.9822380106571936, f1 = 0.983111111111111\n",
      "Test Loss = 0.023196249577180347, Recall = 0.9995551601423488, Aging Rate = 0.5020017793594306, precision = 0.9955693398316349\n",
      "Model in epoch 5 is saved.\n",
      "\n",
      "Epoch 6: Train Loss = 0.01775872123384603, Recall = 0.99644128113879, Aging Rate = 0.49933274021352314, Precision = 0.9977728285077951, f1 = 0.997106610282662\n",
      "Epoch 7: Train Loss = 0.007357480331304155, Recall = 0.9995551601423488, Aging Rate = 0.5, Precision = 0.9995551601423488, f1 = 0.9995551601423488\n",
      "Epoch 8: Train Loss = 0.00417259054712527, Recall = 0.9995551601423488, Aging Rate = 0.4997775800711744, Precision = 0, f1 = 0.0\n",
      "Epoch 9: Train Loss = 0.003292118470529194, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 10: Train Loss = 0.0026795085953727526, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.002483641846417002, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "Model in epoch 10 is saved.\n",
      "\n",
      "Epoch 11: Train Loss = 0.003427092685261443, Recall = 0.9995551601423488, Aging Rate = 0.4997775800711744, Precision = 0, f1 = 0.0\n",
      "Epoch 12: Train Loss = 0.002795695685789824, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 13: Train Loss = 0.0022174998024334382, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 14: Train Loss = 0.0020844414026486386, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 15: Train Loss = 0.002100880709360768, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.001972583881529625, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 16: Train Loss = 0.0022185808082866845, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 17: Train Loss = 0.0022504061681725535, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 18: Train Loss = 0.0020777609164485196, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 19: Train Loss = 0.0020949517300491655, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 20: Train Loss = 0.0027619940255689053, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0023764685323309433, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 21: Train Loss = 0.0023267825127469897, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 22: Train Loss = 0.002066945749934882, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 23: Train Loss = 0.0019602646771155535, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 24: Train Loss = 0.0022384822782911228, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 25: Train Loss = 0.0023761833512499345, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0023105752337856545, Recall = 1.0, Aging Rate = 0.5002224199288257, precision = 0.9995553579368608\n",
      "\n",
      "Epoch 26: Train Loss = 0.014267460143962523, Recall = 0.9951067615658363, Aging Rate = 0.5006672597864769, Precision = 0.9937805419813416, f1 = 0.9944432096021338\n",
      "Epoch 27: Train Loss = 0.07691095216577587, Recall = 0.9759786476868327, Aging Rate = 0.5033362989323843, Precision = 0.9695095006628369, f1 = 0.9727333185546442\n",
      "Epoch 28: Train Loss = 0.05806635506782561, Recall = 0.9808718861209964, Aging Rate = 0.5028914590747331, Precision = 0.9752321981424149, f1 = 0.9780439121756488\n",
      "Epoch 29: Train Loss = 0.02690664645668875, Recall = 0.9937722419928826, Aging Rate = 0.5037811387900356, Precision = 0.9863134657836644, f1 = 0.9900288056725016\n",
      "Epoch 30: Train Loss = 0.005321588370848772, Recall = 0.9991103202846975, Aging Rate = 0.4997775800711744, Precision = 0.9995549621717846, f1 = 0.9993325917686319\n",
      "Test Loss = 0.0014146670723562643, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 31: Train Loss = 0.001265962231155233, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 32: Train Loss = 0.0010341887699532922, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 33: Train Loss = 0.0009920387982483621, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 34: Train Loss = 0.0009916736371483772, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 35: Train Loss = 0.0011398510759268819, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0010291738319624997, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 36: Train Loss = 0.0010908569202649, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 37: Train Loss = 0.0012659130102600172, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 38: Train Loss = 0.0013106981515254679, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 39: Train Loss = 0.0012687361907724331, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 40: Train Loss = 0.0013501925710456121, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0012033338692897658, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 41: Train Loss = 0.001402583266765847, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 42: Train Loss = 0.0017550710598636565, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 43: Train Loss = 0.0016570588651699846, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 44: Train Loss = 0.001606396145478978, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 45: Train Loss = 0.0016217285848398333, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0014026328793716918, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 46: Train Loss = 0.0026781999206110783, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 47: Train Loss = 0.0053176735768101285, Recall = 0.9995551601423488, Aging Rate = 0.5006672597864769, Precision = 0.998223011994669, f1 = 0.9988886419204268\n",
      "Epoch 48: Train Loss = 0.00218490657992777, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 49: Train Loss = 0.001456455975726207, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 50: Train Loss = 0.0021402081980094897, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0019486992374672372, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 51: Train Loss = 0.0015589945694411778, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 52: Train Loss = 0.0014861938767334003, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 53: Train Loss = 0.0017043886982978345, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 54: Train Loss = 0.0055598627006986385, Recall = 0.9995551601423488, Aging Rate = 0.5006672597864769, Precision = 0.998223011994669, f1 = 0.9988886419204268\n",
      "Epoch 55: Train Loss = 0.07894365718833492, Recall = 0.9733096085409253, Aging Rate = 0.5031138790035588, Precision = 0.9672855879752431, f1 = 0.9702882483370289\n",
      "Test Loss = 0.027750130825646195, Recall = 0.9911032028469751, Aging Rate = 0.49955516014234874, precision = 0.9919857524487978\n",
      "\n",
      "Epoch 56: Train Loss = 0.03294916336964882, Recall = 0.9879893238434164, Aging Rate = 0.4997775800711744, Precision = 0.9884290164663997, f1 = 0.9882091212458287\n",
      "Epoch 57: Train Loss = 0.012092757622091584, Recall = 0.9968861209964412, Aging Rate = 0.5013345195729537, Precision = 0.9942324755989352, f1 = 0.9955575299866726\n",
      "Epoch 58: Train Loss = 0.005516960937281229, Recall = 0.998220640569395, Aging Rate = 0.4997775800711744, Precision = 0.9986648865153538, f1 = 0.9984427141268075\n",
      "Epoch 59: Train Loss = 0.0012289657086810078, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 60: Train Loss = 0.0009588145906125524, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.000883925947996059, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Training Finished at epoch 60.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f3637e7c0b51471f86c14a872c5cbe1a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss = 0.37123344430295596, Recall = 0.8776690391459074, Aging Rate = 0.5573843416370107, Precision = 0.7873104549082203, f1 = 0.8300378628523348\n",
      "Epoch 2: Train Loss = 0.1599102573886885, Recall = 0.9457295373665481, Aging Rate = 0.5066725978647687, Precision = 0.9332748024582967, f1 = 0.9394608926204153\n",
      "Epoch 3: Train Loss = 0.09019669036636149, Recall = 0.9755338078291815, Aging Rate = 0.5040035587188612, Precision = 0.9677846425419241, f1 = 0.9716437749224635\n",
      "Epoch 4: Train Loss = 0.05985428976869456, Recall = 0.9826512455516014, Aging Rate = 0.5013345195729537, Precision = 0.9800354924578527, f1 = 0.9813416259440249\n",
      "Epoch 5: Train Loss = 0.052905790414992604, Recall = 0.9822064056939501, Aging Rate = 0.5006672597864769, Precision = 0.9808973789426921, f1 = 0.9815514558790843\n",
      "Test Loss = 0.01927693017834658, Recall = 0.9986654804270463, Aging Rate = 0.5008896797153025, precision = 0.9968916518650088\n",
      "Model in epoch 5 is saved.\n",
      "\n",
      "Epoch 6: Train Loss = 0.01626991583001253, Recall = 0.9977758007117438, Aging Rate = 0.5002224199288257, Precision = 0.997332147621165, f1 = 0.9975539248387815\n",
      "Epoch 7: Train Loss = 0.0071292719082886955, Recall = 0.9991103202846975, Aging Rate = 0.5, Precision = 0.9991103202846975, f1 = 0.9991103202846975\n",
      "Epoch 8: Train Loss = 0.004070214907310611, Recall = 0.9995551601423488, Aging Rate = 0.4997775800711744, Precision = 0, f1 = 0.0\n",
      "Epoch 9: Train Loss = 0.0031987605285018787, Recall = 0.9995551601423488, Aging Rate = 0.4997775800711744, Precision = 0, f1 = 0.0\n",
      "Epoch 10: Train Loss = 0.002778856512954545, Recall = 1.0, Aging Rate = 0.5002224199288257, Precision = 0.9995553579368608, f1 = 0.9997776295307983\n",
      "Test Loss = 0.0023470676348302712, Recall = 0.9995551601423488, Aging Rate = 0.4997775800711744, precision = 1.0\n",
      "Model in epoch 10 is saved.\n",
      "\n",
      "Epoch 11: Train Loss = 0.0025758508400613726, Recall = 0.9995551601423488, Aging Rate = 0.4997775800711744, Precision = 0, f1 = 0.0\n",
      "Epoch 12: Train Loss = 0.0026493312590473803, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 13: Train Loss = 0.0026940769926906694, Recall = 1.0, Aging Rate = 0.5002224199288257, Precision = 0.9995553579368608, f1 = 0.9997776295307983\n",
      "Epoch 14: Train Loss = 0.002955954786211093, Recall = 0.9995551601423488, Aging Rate = 0.4997775800711744, Precision = 0, f1 = 0.0\n",
      "Epoch 15: Train Loss = 0.002512240126145692, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0020304507256097746, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "Model in epoch 15 is saved.\n",
      "\n",
      "Epoch 16: Train Loss = 0.002187503887683458, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 17: Train Loss = 0.00197308086806716, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 18: Train Loss = 0.002095376438829133, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 19: Train Loss = 0.002068095096812444, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 20: Train Loss = 0.0020812048056424726, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0021808990157206024, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 21: Train Loss = 0.0021331230819795375, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 22: Train Loss = 0.0020356205510790874, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 23: Train Loss = 0.002072351226530094, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 24: Train Loss = 0.0022650965235902, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 25: Train Loss = 0.002497306750636561, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0025466099585277225, Recall = 1.0, Aging Rate = 0.5002224199288257, precision = 0.9995553579368608\n",
      "\n",
      "Epoch 26: Train Loss = 0.006508207624758265, Recall = 1.0, Aging Rate = 0.5002224199288257, Precision = 0.9995553579368608, f1 = 0.9997776295307983\n",
      "Epoch 27: Train Loss = 0.12551182248129167, Recall = 0.9630782918149466, Aging Rate = 0.5060053380782918, Precision = 0.9516483516483516, f1 = 0.9573292062790184\n",
      "Epoch 28: Train Loss = 0.026544735778961662, Recall = 0.9915480427046264, Aging Rate = 0.5004448398576512, Precision = 0.9906666666666667, f1 = 0.9911071587372166\n",
      "Epoch 29: Train Loss = 0.008814362616831722, Recall = 0.9973309608540926, Aging Rate = 0.4997775800711744, Precision = 0.9977748108589231, f1 = 0.9975528364849834\n",
      "Epoch 30: Train Loss = 0.0059612825625987055, Recall = 0.9991103202846975, Aging Rate = 0.5006672597864769, Precision = 0.9977787649933363, f1 = 0.9984440986885974\n",
      "Test Loss = 0.0021508366009966202, Recall = 1.0, Aging Rate = 0.5002224199288257, precision = 0.9995553579368608\n",
      "\n",
      "Epoch 31: Train Loss = 0.0018819934291619265, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 32: Train Loss = 0.0013932682314035864, Recall = 1.0, Aging Rate = 0.5002224199288257, Precision = 0.9995553579368608, f1 = 0.9997776295307983\n",
      "Epoch 33: Train Loss = 0.0012563901259050145, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 34: Train Loss = 0.0012744397423776973, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 35: Train Loss = 0.001305781082777154, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0011412015854251768, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 36: Train Loss = 0.001340481795468351, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 37: Train Loss = 0.0012775755423581844, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 38: Train Loss = 0.0013650051497082058, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 39: Train Loss = 0.0014426705176408445, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 40: Train Loss = 0.0015418341464538698, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.001348811726655904, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 41: Train Loss = 0.0022496414433806817, Recall = 1.0, Aging Rate = 0.5002224199288257, Precision = 0.9995553579368608, f1 = 0.9997776295307983\n",
      "Epoch 42: Train Loss = 0.0014831803985987375, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 43: Train Loss = 0.001582898410017274, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 44: Train Loss = 0.0015876068214942234, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 45: Train Loss = 0.0016328863338882177, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0015827738462961395, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 46: Train Loss = 0.001664912821957013, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 47: Train Loss = 0.001758355975235577, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 48: Train Loss = 0.00212156257858944, Recall = 1.0, Aging Rate = 0.5002224199288257, Precision = 0.9995553579368608, f1 = 0.9997776295307983\n",
      "Epoch 49: Train Loss = 0.0017438621319883446, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 50: Train Loss = 0.0018541004845965322, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0014311006972963964, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 51: Train Loss = 0.0017470388295828263, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 52: Train Loss = 0.0023189671834751803, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 53: Train Loss = 0.00296653700898007, Recall = 1.0, Aging Rate = 0.5002224199288257, Precision = 0.9995553579368608, f1 = 0.9997776295307983\n",
      "Epoch 54: Train Loss = 0.06341731585761089, Recall = 0.9804270462633452, Aging Rate = 0.50355871886121, Precision = 0.9734982332155477, f1 = 0.9769503546099292\n",
      "Epoch 55: Train Loss = 0.09120822643523115, Recall = 0.9741992882562278, Aging Rate = 0.5093416370106761, Precision = 0.9563318777292577, f1 = 0.9651828999559278\n",
      "Test Loss = 0.024039835468584216, Recall = 0.9897686832740213, Aging Rate = 0.4971085409252669, precision = 0.9955257270693513\n",
      "\n",
      "Epoch 56: Train Loss = 0.017236300498028403, Recall = 0.9937722419928826, Aging Rate = 0.49955516014234874, Precision = 0.9946571682991986, f1 = 0.9942145082331998\n",
      "Epoch 57: Train Loss = 0.005073818908855186, Recall = 0.9991103202846975, Aging Rate = 0.5, Precision = 0.9991103202846975, f1 = 0.9991103202846975\n",
      "Epoch 58: Train Loss = 0.002751152020766403, Recall = 0.9995551601423488, Aging Rate = 0.4997775800711744, Precision = 0, f1 = 0.0\n",
      "Epoch 59: Train Loss = 0.0012992166138703196, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 60: Train Loss = 0.0011363573016282304, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0009801444219296063, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 61: Train Loss = 0.0011014382150256177, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 62: Train Loss = 0.0011363312574285763, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 63: Train Loss = 0.0011695252252523903, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 64: Train Loss = 0.001234237255041365, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 65: Train Loss = 0.001237967107080427, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0011711273055682722, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Training Finished at epoch 65.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "75633273352d45a19e377667d8bfca5e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss = 0.3626084589130938, Recall = 0.8852313167259787, Aging Rate = 0.5631672597864769, Precision = 0.7859399684044234, f1 = 0.8326359832635983\n",
      "Epoch 2: Train Loss = 0.15080526664694008, Recall = 0.9519572953736655, Aging Rate = 0.5037811387900356, Precision = 0.9448123620309051, f1 = 0.9483713715931752\n",
      "Epoch 3: Train Loss = 0.08984994002720639, Recall = 0.9741992882562278, Aging Rate = 0.5002224199288257, Precision = 0.9737661182747888, f1 = 0.9739826551034023\n",
      "Epoch 4: Train Loss = 0.06266904428760352, Recall = 0.983540925266904, Aging Rate = 0.5013345195729537, Precision = 0.9809228039041704, f1 = 0.9822301199466903\n",
      "Epoch 5: Train Loss = 0.05260878145111413, Recall = 0.9848754448398577, Aging Rate = 0.5008896797153025, Precision = 0.9831261101243339, f1 = 0.984\n",
      "Test Loss = 0.01863481293289899, Recall = 0.9995551601423488, Aging Rate = 0.5008896797153025, precision = 0.9977797513321492\n",
      "Model in epoch 5 is saved.\n",
      "\n",
      "Epoch 6: Train Loss = 0.013645452599694083, Recall = 0.9977758007117438, Aging Rate = 0.4997775800711744, Precision = 0.9982198486871384, f1 = 0.9979977753058954\n",
      "Epoch 7: Train Loss = 0.0064849453834067775, Recall = 0.9991103202846975, Aging Rate = 0.4997775800711744, Precision = 0.9995549621717846, f1 = 0.9993325917686319\n",
      "Epoch 8: Train Loss = 0.003993372529002695, Recall = 1.0, Aging Rate = 0.5002224199288257, Precision = 0.9995553579368608, f1 = 0.9997776295307983\n",
      "Epoch 9: Train Loss = 0.002752149862061616, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 10: Train Loss = 0.0022852677479883476, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.002135790342189955, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "Model in epoch 10 is saved.\n",
      "\n",
      "Epoch 11: Train Loss = 0.0021785149260447278, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 12: Train Loss = 0.0020746259943472743, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 13: Train Loss = 0.0020535838899196014, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 14: Train Loss = 0.0020224491848520854, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 15: Train Loss = 0.002040603956260662, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0018204550500760298, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 16: Train Loss = 0.002031336270241246, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 17: Train Loss = 0.0019957108946775624, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 18: Train Loss = 0.002023219967797876, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 19: Train Loss = 0.0020585249516171704, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 20: Train Loss = 0.002065880599869183, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0018081556273594473, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 21: Train Loss = 0.0021510531577311484, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 22: Train Loss = 0.002743140443433673, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 23: Train Loss = 0.0023362723703651933, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 24: Train Loss = 0.002474796258947179, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 25: Train Loss = 0.002359777890324752, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0025899142877851677, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 26: Train Loss = 0.01067746587982567, Recall = 0.998220640569395, Aging Rate = 0.5013345195729537, Precision = 0.9955634427684117, f1 = 0.9968902709906707\n",
      "Epoch 27: Train Loss = 0.1154294201832437, Recall = 0.9639679715302492, Aging Rate = 0.5088967971530249, Precision = 0.9471153846153846, f1 = 0.9554673721340388\n",
      "Epoch 28: Train Loss = 0.03628078393399503, Recall = 0.9897686832740213, Aging Rate = 0.501779359430605, Precision = 0.9862588652482269, f1 = 0.9880106571936057\n",
      "Epoch 29: Train Loss = 0.008683860247803096, Recall = 0.9991103202846975, Aging Rate = 0.5015569395017794, Precision = 0.9960088691796009, f1 = 0.9975571840994892\n",
      "Epoch 30: Train Loss = 0.0027584653371345133, Recall = 0.9995551601423488, Aging Rate = 0.4997775800711744, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0018765600929509026, Recall = 1.0, Aging Rate = 0.5002224199288257, precision = 0.9995553579368608\n",
      "\n",
      "Epoch 31: Train Loss = 0.0015244936799212918, Recall = 1.0, Aging Rate = 0.5002224199288257, Precision = 0.9995553579368608, f1 = 0.9997776295307983\n",
      "Epoch 32: Train Loss = 0.0009585552326042298, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 33: Train Loss = 0.0009482224311122796, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 34: Train Loss = 0.0009855069176047822, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 35: Train Loss = 0.0010505631239587621, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0009757037223996163, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 36: Train Loss = 0.0011381291263584325, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 37: Train Loss = 0.0011904638528233904, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 38: Train Loss = 0.0012597147844735123, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 39: Train Loss = 0.0013574651720870644, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 40: Train Loss = 0.0013669585789225704, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0012838318502759144, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 41: Train Loss = 0.001467002569399509, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 42: Train Loss = 0.0016216225764677725, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 43: Train Loss = 0.0015977062446519308, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 44: Train Loss = 0.0016443844999806472, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 45: Train Loss = 0.0016297638454404908, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0015566457018216415, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 46: Train Loss = 0.006701149765627452, Recall = 0.9995551601423488, Aging Rate = 0.5, Precision = 0.9995551601423488, f1 = 0.9995551601423488\n",
      "Epoch 47: Train Loss = 0.03140760258045644, Recall = 0.9911032028469751, Aging Rate = 0.5011120996441281, Precision = 0.9889036839769196, f1 = 0.9900022217285047\n",
      "Epoch 48: Train Loss = 0.051749215398341736, Recall = 0.983540925266904, Aging Rate = 0.5015569395017794, Precision = 0.9804878048780488, f1 = 0.9820119920053297\n",
      "Epoch 49: Train Loss = 0.018968675791010844, Recall = 0.9942170818505338, Aging Rate = 0.4997775800711744, Precision = 0.9946595460614153, f1 = 0.9944382647385985\n",
      "Epoch 50: Train Loss = 0.005415638707813498, Recall = 0.998220640569395, Aging Rate = 0.5, Precision = 0.998220640569395, f1 = 0.998220640569395\n",
      "Test Loss = 0.0014134377956405296, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 51: Train Loss = 0.0013300542246543693, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 52: Train Loss = 0.0007774232376327082, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 53: Train Loss = 0.0006794556266411947, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 54: Train Loss = 0.0007156677611646146, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 55: Train Loss = 0.0008199332581064083, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.000789476278506458, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 56: Train Loss = 0.000902033525879919, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 57: Train Loss = 0.0010328771819085466, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 58: Train Loss = 0.001115497330861751, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 59: Train Loss = 0.0011816331437288442, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 60: Train Loss = 0.0012832942954844587, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0011626222329147928, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Training Finished at epoch 60.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb417405b3a941fdb3feee650742fae6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss = 0.35616084556774735, Recall = 0.9039145907473309, Aging Rate = 0.5829626334519573, Precision = 0.7752766119801603, f1 = 0.8346683097145204\n",
      "Epoch 2: Train Loss = 0.1411778447665672, Recall = 0.9537366548042705, Aging Rate = 0.5015569395017794, Precision = 0.9507760532150776, f1 = 0.9522540528536532\n",
      "Epoch 3: Train Loss = 0.08097255501723799, Recall = 0.9759786476868327, Aging Rate = 0.5004448398576512, Precision = 0.9751111111111112, f1 = 0.9755446865273455\n",
      "Epoch 4: Train Loss = 0.05304167090891943, Recall = 0.9830960854092526, Aging Rate = 0.49933274021352314, Precision = 0.9844097995545658, f1 = 0.9837525038949477\n",
      "Epoch 5: Train Loss = 0.04400393382722373, Recall = 0.9866548042704626, Aging Rate = 0.4988879003558719, Precision = 0.9888542131074454, f1 = 0.9877532843464707\n",
      "Test Loss = 0.018819505872463418, Recall = 0.9986654804270463, Aging Rate = 0.4997775800711744, precision = 0.9991099243435692\n",
      "Model in epoch 5 is saved.\n",
      "\n",
      "Epoch 6: Train Loss = 0.011831287712229953, Recall = 0.9991103202846975, Aging Rate = 0.5002224199288257, Precision = 0.9986660738105825, f1 = 0.9988881476539915\n",
      "Epoch 7: Train Loss = 0.004513472089961543, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 8: Train Loss = 0.0030608156106013843, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 9: Train Loss = 0.0028536400129667273, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 10: Train Loss = 0.002713794457507436, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.002215762306965914, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "Model in epoch 10 is saved.\n",
      "\n",
      "Epoch 11: Train Loss = 0.0023707279942107797, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 12: Train Loss = 0.0024734291306438318, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 13: Train Loss = 0.005344536094561723, Recall = 0.9995551601423488, Aging Rate = 0.5002224199288257, Precision = 0.9991107158737217, f1 = 0.9993328885923949\n",
      "Epoch 14: Train Loss = 0.0032597874640072845, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 15: Train Loss = 0.0019040714329592485, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0016007292048352707, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 16: Train Loss = 0.0018153560668515089, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 17: Train Loss = 0.0018566247673201444, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 18: Train Loss = 0.0019346469469713147, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 19: Train Loss = 0.0019257103256198488, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 20: Train Loss = 0.0054767593646958945, Recall = 0.9995551601423488, Aging Rate = 0.5004448398576512, Precision = 0.9986666666666667, f1 = 0.9991107158737217\n",
      "Test Loss = 0.017800972457259256, Recall = 0.9959964412811388, Aging Rate = 0.4988879003558719, precision = 0.9982166740971913\n",
      "\n",
      "Epoch 21: Train Loss = 0.02923274197983572, Recall = 0.9911032028469751, Aging Rate = 0.5006672597864769, Precision = 0.989782318969347, f1 = 0.9904423205156702\n",
      "Epoch 22: Train Loss = 0.04704563019903264, Recall = 0.9839857651245552, Aging Rate = 0.5033362989323843, Precision = 0.9774635439681838, f1 = 0.9807138106849922\n",
      "Epoch 23: Train Loss = 0.0355002185183965, Recall = 0.9866548042704626, Aging Rate = 0.5008896797153025, Precision = 0.9849023090586145, f1 = 0.9857777777777779\n",
      "Epoch 24: Train Loss = 0.008036133848972539, Recall = 0.998220640569395, Aging Rate = 0.5008896797153025, Precision = 0.9964476021314387, f1 = 0.9973333333333333\n",
      "Epoch 25: Train Loss = 0.0018792169968584334, Recall = 0.9995551601423488, Aging Rate = 0.5, Precision = 0.9995551601423488, f1 = 0.9995551601423488\n",
      "Test Loss = 0.002396313952500816, Recall = 1.0, Aging Rate = 0.5002224199288257, precision = 0.9995553579368608\n",
      "\n",
      "Epoch 26: Train Loss = 0.0012138533147857309, Recall = 1.0, Aging Rate = 0.5002224199288257, Precision = 0.9995553579368608, f1 = 0.9997776295307983\n",
      "Epoch 27: Train Loss = 0.0008522551556472464, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 28: Train Loss = 0.0007518751279938157, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 29: Train Loss = 0.0007783704084340894, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 30: Train Loss = 0.0008900910396347638, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0008169062544585097, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 31: Train Loss = 0.0009460277529971945, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 32: Train Loss = 0.0010759853706131706, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 33: Train Loss = 0.00111602833105112, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 34: Train Loss = 0.001274541300453007, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 35: Train Loss = 0.0013289793715165975, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0012769713737667138, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 36: Train Loss = 0.0016637209753565542, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 37: Train Loss = 0.0014422455708516157, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 38: Train Loss = 0.001420252803162907, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 39: Train Loss = 0.0015810722239925344, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 40: Train Loss = 0.001598606889717798, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0014347253763779759, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 41: Train Loss = 0.0017313885550574793, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 42: Train Loss = 0.0018877480241214837, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 43: Train Loss = 0.0017452651255323263, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 44: Train Loss = 0.0020336272423669326, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 45: Train Loss = 0.0019630039279809838, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.002870834937146815, Recall = 0.9991103202846975, Aging Rate = 0.49955516014234874, precision = 1.0\n",
      "\n",
      "Epoch 46: Train Loss = 0.012300588623902287, Recall = 0.99644128113879, Aging Rate = 0.5, Precision = 0.99644128113879, f1 = 0.99644128113879\n",
      "Epoch 47: Train Loss = 0.10086534935583318, Recall = 0.9670818505338078, Aging Rate = 0.5060053380782918, Precision = 0.9556043956043956, f1 = 0.9613088657970374\n",
      "Epoch 48: Train Loss = 0.028610482982615027, Recall = 0.9911032028469751, Aging Rate = 0.5013345195729537, Precision = 0.9884649511978705, f1 = 0.989782318969347\n",
      "Epoch 49: Train Loss = 0.006874827501526454, Recall = 0.9986654804270463, Aging Rate = 0.5, Precision = 0.9986654804270463, f1 = 0.9986654804270463\n",
      "Epoch 50: Train Loss = 0.008976130095974201, Recall = 0.9973309608540926, Aging Rate = 0.5, Precision = 0.9973309608540926, f1 = 0.9973309608540926\n",
      "Test Loss = 0.002094865201771909, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 51: Train Loss = 0.0016272172099393643, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 52: Train Loss = 0.000950332064831172, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 53: Train Loss = 0.0007894424700055576, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 54: Train Loss = 0.0008507706684779601, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 55: Train Loss = 0.0008783562507006436, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.000832256949274698, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 56: Train Loss = 0.0009836076690029896, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 57: Train Loss = 0.0010829535880527092, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 58: Train Loss = 0.0012897081553829948, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 59: Train Loss = 0.0014577457363123996, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 60: Train Loss = 0.0013840198769562238, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.001319653700516821, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Training Finished at epoch 60.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c01a4b9334c541458cf7e3a0713b72b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss = 0.35918270597678487, Recall = 0.9426156583629893, Aging Rate = 0.6875, Precision = 0.6855386606276286, f1 = 0.7937816070425174\n",
      "Epoch 2: Train Loss = 0.1645303952418188, Recall = 0.9608540925266904, Aging Rate = 0.5389234875444839, Precision = 0.8914568716467189, f1 = 0.9248554913294799\n",
      "Epoch 3: Train Loss = 0.09949278147407274, Recall = 0.9808718861209964, Aging Rate = 0.5197953736654805, Precision = 0.9435173299101413, f1 = 0.9618320610687023\n",
      "Epoch 4: Train Loss = 0.06665264767365947, Recall = 0.9862099644128114, Aging Rate = 0.5113434163701067, Precision = 0.964332318399304, f1 = 0.9751484495271607\n",
      "Epoch 5: Train Loss = 0.055922413118899506, Recall = 0.9902135231316725, Aging Rate = 0.5077846975088968, Precision = 0.9750328515111695, f1 = 0.9825645552858088\n",
      "Test Loss = 0.022315605069606753, Recall = 0.9973309608540926, Aging Rate = 0.5, precision = 0.9973309608540926\n",
      "Model in epoch 5 is saved.\n",
      "\n",
      "Epoch 6: Train Loss = 0.016596918401152586, Recall = 0.9986654804270463, Aging Rate = 0.5008896797153025, Precision = 0.9968916518650088, f1 = 0.9977777777777778\n",
      "Epoch 7: Train Loss = 0.007440674682959808, Recall = 0.9995551601423488, Aging Rate = 0.5002224199288257, Precision = 0.9991107158737217, f1 = 0.9993328885923949\n",
      "Epoch 8: Train Loss = 0.005185377959732059, Recall = 0.9995551601423488, Aging Rate = 0.5, Precision = 0.9995551601423488, f1 = 0.9995551601423488\n",
      "Epoch 9: Train Loss = 0.004471229675065998, Recall = 0.9995551601423488, Aging Rate = 0.5, Precision = 0.9995551601423488, f1 = 0.9995551601423488\n",
      "Epoch 10: Train Loss = 0.0031057600134128567, Recall = 1.0, Aging Rate = 0.5002224199288257, Precision = 0.9995553579368608, f1 = 0.9997776295307983\n",
      "Test Loss = 0.002744536222956306, Recall = 1.0, Aging Rate = 0.5002224199288257, precision = 0.9995553579368608\n",
      "Model in epoch 10 is saved.\n",
      "\n",
      "Epoch 11: Train Loss = 0.002802760984907689, Recall = 1.0, Aging Rate = 0.5002224199288257, Precision = 0.9995553579368608, f1 = 0.9997776295307983\n",
      "Epoch 12: Train Loss = 0.003062867635721838, Recall = 0.9995551601423488, Aging Rate = 0.4997775800711744, Precision = 0, f1 = 0.0\n",
      "Epoch 13: Train Loss = 0.002738252265571063, Recall = 1.0, Aging Rate = 0.5002224199288257, Precision = 0.9995553579368608, f1 = 0.9997776295307983\n",
      "Epoch 14: Train Loss = 0.00252715763768506, Recall = 1.0, Aging Rate = 0.5002224199288257, Precision = 0.9995553579368608, f1 = 0.9997776295307983\n",
      "Epoch 15: Train Loss = 0.002944201110030302, Recall = 1.0, Aging Rate = 0.5002224199288257, Precision = 0.9995553579368608, f1 = 0.9997776295307983\n",
      "Test Loss = 0.0035309763695693364, Recall = 1.0, Aging Rate = 0.5002224199288257, precision = 0.9995553579368608\n",
      "\n",
      "Epoch 16: Train Loss = 0.0024060614769980046, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 17: Train Loss = 0.00212529066699852, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 18: Train Loss = 0.0022393057538773135, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 19: Train Loss = 0.002444702138448154, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 20: Train Loss = 0.0019192206938469325, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0017871387997638844, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "Model in epoch 20 is saved.\n",
      "\n",
      "Epoch 21: Train Loss = 0.002658166578768676, Recall = 1.0, Aging Rate = 0.5002224199288257, Precision = 0.9995553579368608, f1 = 0.9997776295307983\n",
      "Epoch 22: Train Loss = 0.005297431588053597, Recall = 0.9995551601423488, Aging Rate = 0.5004448398576512, Precision = 0.9986666666666667, f1 = 0.9991107158737217\n",
      "Epoch 23: Train Loss = 0.041274129182723385, Recall = 0.9897686832740213, Aging Rate = 0.5077846975088968, Precision = 0.9745948313622427, f1 = 0.9821231516221585\n",
      "Epoch 24: Train Loss = 0.04750395108973839, Recall = 0.9875444839857651, Aging Rate = 0.5075622775800712, Precision = 0.9728308501314636, f1 = 0.9801324503311258\n",
      "Epoch 25: Train Loss = 0.01543710251865756, Recall = 0.9955516014234875, Aging Rate = 0.5008896797153025, Precision = 0.9937833037300178, f1 = 0.9946666666666666\n",
      "Test Loss = 0.01724900911459401, Recall = 0.9986654804270463, Aging Rate = 0.5091192170818505, precision = 0.9807776321537789\n",
      "\n",
      "Epoch 26: Train Loss = 0.005946516471971291, Recall = 0.9991103202846975, Aging Rate = 0.5004448398576512, Precision = 0.9982222222222222, f1 = 0.9986660738105825\n",
      "Epoch 27: Train Loss = 0.0016283514730058928, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 28: Train Loss = 0.0008558429017608316, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 29: Train Loss = 0.0007994765127027984, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 30: Train Loss = 0.0008498708111833901, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0008181637856078556, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 31: Train Loss = 0.0009573348727428563, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 32: Train Loss = 0.0011078946827247978, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 33: Train Loss = 0.0013738892662995147, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 34: Train Loss = 0.0012834319203521964, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 35: Train Loss = 0.0013757500804967356, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0012966282226582757, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 36: Train Loss = 0.0016116986102573706, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 37: Train Loss = 0.003752721747834222, Recall = 1.0, Aging Rate = 0.5002224199288257, Precision = 0.9995553579368608, f1 = 0.9997776295307983\n",
      "Epoch 38: Train Loss = 0.002146247564732127, Recall = 1.0, Aging Rate = 0.5002224199288257, Precision = 0.9995553579368608, f1 = 0.9997776295307983\n",
      "Epoch 39: Train Loss = 0.0015948055278065738, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 40: Train Loss = 0.0013220027491808255, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.001672543513628379, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 41: Train Loss = 0.0016427063615164087, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 42: Train Loss = 0.0014772971133366758, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 43: Train Loss = 0.0015192122680874165, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 44: Train Loss = 0.0016765791883035911, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 45: Train Loss = 0.002320553417221454, Recall = 1.0, Aging Rate = 0.5002224199288257, Precision = 0.9995553579368608, f1 = 0.9997776295307983\n",
      "Test Loss = 0.0028828229619276267, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 46: Train Loss = 0.029687093166481982, Recall = 0.9928825622775801, Aging Rate = 0.50355871886121, Precision = 0.9858657243816255, f1 = 0.9893617021276595\n",
      "Epoch 47: Train Loss = 0.0666953717553955, Recall = 0.9826512455516014, Aging Rate = 0.5113434163701067, Precision = 0.960852544584602, f1 = 0.9716296459203871\n",
      "Epoch 48: Train Loss = 0.018838899347639486, Recall = 0.9968861209964412, Aging Rate = 0.5033362989323843, Precision = 0.9902783915156872, f1 = 0.9935712702283308\n",
      "Epoch 49: Train Loss = 0.01267434916317337, Recall = 0.9968861209964412, Aging Rate = 0.5013345195729537, Precision = 0.9942324755989352, f1 = 0.9955575299866726\n",
      "Epoch 50: Train Loss = 0.0049785554510113714, Recall = 0.9986654804270463, Aging Rate = 0.5002224199288257, Precision = 0.9982214317474433, f1 = 0.9984434067155882\n",
      "Test Loss = 0.0020658474824030047, Recall = 1.0, Aging Rate = 0.5002224199288257, precision = 0.9995553579368608\n",
      "\n",
      "Epoch 51: Train Loss = 0.002451280931514618, Recall = 1.0, Aging Rate = 0.5004448398576512, Precision = 0.9991111111111111, f1 = 0.9995553579368608\n",
      "Epoch 52: Train Loss = 0.001112859187402441, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 53: Train Loss = 0.0008788728680307529, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 54: Train Loss = 0.000888333801723672, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 55: Train Loss = 0.0009670791657827132, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0009234543244298083, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 56: Train Loss = 0.0011033758928533643, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57: Train Loss = 0.0012934234057921002, Recall = 1.0, Aging Rate = 0.5002224199288257, Precision = 0.9995553579368608, f1 = 0.9997776295307983\n",
      "Epoch 58: Train Loss = 0.0011782501335338659, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 59: Train Loss = 0.001229117690747955, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 60: Train Loss = 0.001420048682101558, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0012698142474030021, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 61: Train Loss = 0.0015382564760656743, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 62: Train Loss = 0.001885291163269364, Recall = 1.0, Aging Rate = 0.5002224199288257, Precision = 0.9995553579368608, f1 = 0.9997776295307983\n",
      "Epoch 63: Train Loss = 0.0015395725114035728, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 64: Train Loss = 0.0014907875002172918, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 65: Train Loss = 0.0015925922281078968, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0013949353052336339, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 66: Train Loss = 0.00164914781018906, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 67: Train Loss = 0.0016208923483114967, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 68: Train Loss = 0.0017669264590069386, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 69: Train Loss = 0.005224293599972415, Recall = 1.0, Aging Rate = 0.5006672597864769, Precision = 0.9986672589960017, f1 = 0.999333185152256\n",
      "Epoch 70: Train Loss = 0.05755403342746278, Recall = 0.9822064056939501, Aging Rate = 0.5075622775800712, Precision = 0.9675723049956179, f1 = 0.9748344370860926\n",
      "Test Loss = 0.07275618541177058, Recall = 0.9928825622775801, Aging Rate = 0.531806049822064, precision = 0.9335006273525721\n",
      "\n",
      "Training Finished at epoch 70.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f7e2fe5bc7a2440dbc8ae964fd1d127d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss = 0.3673906495986884, Recall = 0.9399466192170819, Aging Rate = 0.6972864768683275, Precision = 0.6740031897926635, f1 = 0.7850640906557683\n",
      "Epoch 2: Train Loss = 0.16124574869234792, Recall = 0.9653024911032029, Aging Rate = 0.537144128113879, Precision = 0.8985507246376812, f1 = 0.9307312888698264\n",
      "Epoch 3: Train Loss = 0.1041855923433745, Recall = 0.974644128113879, Aging Rate = 0.5175711743772242, Precision = 0.9415556510528578, f1 = 0.9578142076502733\n",
      "Epoch 4: Train Loss = 0.06820860916079151, Recall = 0.9826512455516014, Aging Rate = 0.5075622775800712, Precision = 0.9680105170902716, f1 = 0.9752759381898455\n",
      "Epoch 5: Train Loss = 0.06033974273786532, Recall = 0.9879893238434164, Aging Rate = 0.5095640569395018, Precision = 0.9694456569183763, f1 = 0.9786296541088345\n",
      "Test Loss = 0.021998381474158092, Recall = 0.998220640569395, Aging Rate = 0.5002224199288257, precision = 0.9977767896843042\n",
      "Model in epoch 5 is saved.\n",
      "\n",
      "Epoch 6: Train Loss = 0.015857009422630602, Recall = 0.9986654804270463, Aging Rate = 0.5015569395017794, Precision = 0.9955654101995566, f1 = 0.997113035753942\n",
      "Epoch 7: Train Loss = 0.007056854206246732, Recall = 0.9995551601423488, Aging Rate = 0.5004448398576512, Precision = 0.9986666666666667, f1 = 0.9991107158737217\n",
      "Epoch 8: Train Loss = 0.004472122171370054, Recall = 0.9995551601423488, Aging Rate = 0.5, Precision = 0.9995551601423488, f1 = 0.9995551601423488\n",
      "Epoch 9: Train Loss = 0.0037677612344591857, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 10: Train Loss = 0.0031907699531560692, Recall = 0.9995551601423488, Aging Rate = 0.4997775800711744, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.002731045072954612, Recall = 1.0, Aging Rate = 0.5002224199288257, precision = 0.9995553579368608\n",
      "Model in epoch 10 is saved.\n",
      "\n",
      "Epoch 11: Train Loss = 0.0028289683474711676, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 12: Train Loss = 0.0028066402848054292, Recall = 1.0, Aging Rate = 0.5002224199288257, Precision = 0.9995553579368608, f1 = 0.9997776295307983\n",
      "Epoch 13: Train Loss = 0.002473944041205179, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 14: Train Loss = 0.0022422638390332565, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 15: Train Loss = 0.0022404062424146724, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0018586267912312944, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "Model in epoch 15 is saved.\n",
      "\n",
      "Epoch 16: Train Loss = 0.002262723580784963, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 17: Train Loss = 0.0021765709612717407, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 18: Train Loss = 0.0021543553868785927, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 19: Train Loss = 0.0022743770362166323, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 20: Train Loss = 0.0020658852771965265, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0017473060572254753, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 21: Train Loss = 0.002108881929044171, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 22: Train Loss = 0.0019956255663895577, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 23: Train Loss = 0.002195157307064247, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 24: Train Loss = 0.0022568072898112887, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 25: Train Loss = 0.0046842863801469055, Recall = 0.9995551601423488, Aging Rate = 0.5, Precision = 0.9995551601423488, f1 = 0.9995551601423488\n",
      "Test Loss = 0.008674136912317621, Recall = 0.9986654804270463, Aging Rate = 0.5008896797153025, precision = 0.9968916518650088\n",
      "\n",
      "Epoch 26: Train Loss = 0.055045139914530986, Recall = 0.9875444839857651, Aging Rate = 0.510008896797153, Precision = 0.9681639773222852, f1 = 0.9777582030389781\n",
      "Epoch 27: Train Loss = 0.05612481357463473, Recall = 0.9839857651245552, Aging Rate = 0.5093416370106761, Precision = 0.965938864628821, f1 = 0.9748788012340237\n",
      "Epoch 28: Train Loss = 0.016305357466362337, Recall = 0.9955516014234875, Aging Rate = 0.5020017793594306, Precision = 0.9915817456801064, f1 = 0.9935627081021088\n",
      "Epoch 29: Train Loss = 0.007097012526189968, Recall = 0.9995551601423488, Aging Rate = 0.5020017793594306, Precision = 0.9955693398316349, f1 = 0.997558268590455\n",
      "Epoch 30: Train Loss = 0.0020009936019426107, Recall = 1.0, Aging Rate = 0.5002224199288257, Precision = 0.9995553579368608, f1 = 0.9997776295307983\n",
      "Test Loss = 0.0009342583246012069, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 31: Train Loss = 0.0009979233979471227, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 32: Train Loss = 0.0009282157303569872, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 33: Train Loss = 0.0009318312073459524, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 34: Train Loss = 0.0010190403837341073, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 35: Train Loss = 0.0010603318132586062, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0010183988743067264, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 36: Train Loss = 0.0011476837842247956, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 37: Train Loss = 0.0012173668035634154, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 38: Train Loss = 0.0012684005587709757, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 39: Train Loss = 0.001383722831041045, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 40: Train Loss = 0.0014210154494648515, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0020043310676983086, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 41: Train Loss = 0.0015371559636031022, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 42: Train Loss = 0.0015488577032216502, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 43: Train Loss = 0.0015308638650168304, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 44: Train Loss = 0.0016054537300984923, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 45: Train Loss = 0.0019534832700172245, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0015538139765903195, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 46: Train Loss = 0.0016837227141676848, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 47: Train Loss = 0.0016770993253328835, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 48: Train Loss = 0.001686637893856049, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 49: Train Loss = 0.002477256360785287, Recall = 1.0, Aging Rate = 0.5002224199288257, Precision = 0.9995553579368608, f1 = 0.9997776295307983\n",
      "Epoch 50: Train Loss = 0.004889735436643676, Recall = 0.9995551601423488, Aging Rate = 0.5004448398576512, Precision = 0.9986666666666667, f1 = 0.9991107158737217\n",
      "Test Loss = 0.010900761505804941, Recall = 0.9977758007117438, Aging Rate = 0.49933274021352314, precision = 0.9991091314031181\n",
      "\n",
      "Epoch 51: Train Loss = 0.10483022505132435, Recall = 0.972864768683274, Aging Rate = 0.5193505338078291, Precision = 0.9366167023554604, f1 = 0.954396683395156\n",
      "Epoch 52: Train Loss = 0.0362576192304545, Recall = 0.9902135231316725, Aging Rate = 0.5044483985765125, Precision = 0.9814814814814815, f1 = 0.9858281665190434\n",
      "Epoch 53: Train Loss = 0.008851877797736366, Recall = 0.9986654804270463, Aging Rate = 0.5011120996441281, Precision = 0.9964491788726143, f1 = 0.9975560986447456\n",
      "Epoch 54: Train Loss = 0.0035701288043743402, Recall = 0.9995551601423488, Aging Rate = 0.5, Precision = 0.9995551601423488, f1 = 0.9995551601423488\n",
      "Epoch 55: Train Loss = 0.0015032089066159748, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0010424606587814027, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 56: Train Loss = 0.0011103972504694292, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 57: Train Loss = 0.001064638572196506, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 58: Train Loss = 0.001076769263747072, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 59: Train Loss = 0.001110150812283238, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 60: Train Loss = 0.001162761166833467, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0010647536089703493, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 61: Train Loss = 0.0012131782424274924, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 62: Train Loss = 0.0013176632495729577, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 63: Train Loss = 0.0013994951394810822, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 64: Train Loss = 0.0013894820672847674, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 65: Train Loss = 0.0013938827448531992, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0013330083181319287, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Training Finished at epoch 65.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a21ef767476c4333813b53e1b6c944c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss = 0.3685253197294113, Recall = 0.9448398576512456, Aging Rate = 0.7177491103202847, Precision = 0.6581964673070964, f1 = 0.7758904109589041\n",
      "Epoch 2: Train Loss = 0.16506397500103903, Recall = 0.9639679715302492, Aging Rate = 0.5378113879003559, Precision = 0.8961952026468155, f1 = 0.9288469781397342\n",
      "Epoch 3: Train Loss = 0.08973846454637331, Recall = 0.9822064056939501, Aging Rate = 0.5155693950177936, Precision = 0.9525452976704055, f1 = 0.9671484888304862\n",
      "Epoch 4: Train Loss = 0.06597061036320344, Recall = 0.9866548042704626, Aging Rate = 0.5091192170818505, Precision = 0.9689820882481432, f1 = 0.9777385937844391\n",
      "Epoch 5: Train Loss = 0.049230155515156394, Recall = 0.9906583629893239, Aging Rate = 0.5048932384341637, Precision = 0.981057268722467, f1 = 0.9858344400177069\n",
      "Test Loss = 0.020890695947716243, Recall = 1.0, Aging Rate = 0.5008896797153025, precision = 0.9982238010657194\n",
      "Model in epoch 5 is saved.\n",
      "\n",
      "Epoch 6: Train Loss = 0.014114723772844598, Recall = 0.9991103202846975, Aging Rate = 0.5004448398576512, Precision = 0.9982222222222222, f1 = 0.9986660738105825\n",
      "Epoch 7: Train Loss = 0.006645560990422434, Recall = 1.0, Aging Rate = 0.5004448398576512, Precision = 0.9991111111111111, f1 = 0.9995553579368608\n",
      "Epoch 8: Train Loss = 0.003687243329467139, Recall = 1.0, Aging Rate = 0.5002224199288257, Precision = 0.9995553579368608, f1 = 0.9997776295307983\n",
      "Epoch 9: Train Loss = 0.0032210071882716913, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 10: Train Loss = 0.0028227788613267323, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.002492028458401879, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "Model in epoch 10 is saved.\n",
      "\n",
      "Epoch 11: Train Loss = 0.0025619503452021667, Recall = 1.0, Aging Rate = 0.5002224199288257, Precision = 0.9995553579368608, f1 = 0.9997776295307983\n",
      "Epoch 12: Train Loss = 0.002618326730959886, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 13: Train Loss = 0.002363741714789058, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 14: Train Loss = 0.0022710254888159633, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 15: Train Loss = 0.0021398249206554107, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0019268000125967867, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 16: Train Loss = 0.0022372457636288265, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 17: Train Loss = 0.004291089657641072, Recall = 1.0, Aging Rate = 0.5002224199288257, Precision = 0.9995553579368608, f1 = 0.9997776295307983\n",
      "Epoch 18: Train Loss = 0.0032740321318582497, Recall = 1.0, Aging Rate = 0.5004448398576512, Precision = 0.9991111111111111, f1 = 0.9995553579368608\n",
      "Epoch 19: Train Loss = 0.004527207643988466, Recall = 1.0, Aging Rate = 0.5002224199288257, Precision = 0.9995553579368608, f1 = 0.9997776295307983\n",
      "Epoch 20: Train Loss = 0.004842780542156404, Recall = 0.9995551601423488, Aging Rate = 0.5, Precision = 0.9995551601423488, f1 = 0.9995551601423488\n",
      "Test Loss = 0.004671016500975267, Recall = 1.0, Aging Rate = 0.5013345195729537, precision = 0.997338065661047\n",
      "\n",
      "Epoch 21: Train Loss = 0.0051900566828162065, Recall = 0.9995551601423488, Aging Rate = 0.5004448398576512, Precision = 0.9986666666666667, f1 = 0.9991107158737217\n",
      "Epoch 22: Train Loss = 0.03488819496010122, Recall = 0.9906583629893239, Aging Rate = 0.5046708185053381, Precision = 0.9814896430145439, f1 = 0.9860526898383883\n",
      "Epoch 23: Train Loss = 0.03336808532045564, Recall = 0.9924377224199288, Aging Rate = 0.5040035587188612, Precision = 0.9845542806707855, f1 = 0.9884802835622507\n",
      "Epoch 24: Train Loss = 0.011556401360760115, Recall = 0.9977758007117438, Aging Rate = 0.5020017793594306, Precision = 0.9937970757642889, f1 = 0.9957824639289677\n",
      "Epoch 25: Train Loss = 0.003355937779987118, Recall = 1.0, Aging Rate = 0.5002224199288257, Precision = 0.9995553579368608, f1 = 0.9997776295307983\n",
      "Test Loss = 0.0017326725601281613, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 26: Train Loss = 0.001445389197794621, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 27: Train Loss = 0.0011162915634939255, Recall = 1.0, Aging Rate = 0.5002224199288257, Precision = 0.9995553579368608, f1 = 0.9997776295307983\n",
      "Epoch 28: Train Loss = 0.0010171094852345548, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 29: Train Loss = 0.001021166904562226, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 30: Train Loss = 0.0009373443887247522, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0008920956062471156, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 31: Train Loss = 0.0009949650077706077, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 32: Train Loss = 0.0011069279961997238, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 33: Train Loss = 0.0012515725676066432, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 34: Train Loss = 0.0013412613105990019, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 35: Train Loss = 0.0016254962944372614, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0015254244050905905, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 36: Train Loss = 0.0015886466845777217, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 37: Train Loss = 0.001602162559370898, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 38: Train Loss = 0.0018641833933501163, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 39: Train Loss = 0.0028493985015023964, Recall = 1.0, Aging Rate = 0.5002224199288257, Precision = 0.9995553579368608, f1 = 0.9997776295307983\n",
      "Epoch 40: Train Loss = 0.0029620038365342017, Recall = 1.0, Aging Rate = 0.5004448398576512, Precision = 0.9991111111111111, f1 = 0.9995553579368608\n",
      "Test Loss = 0.0021704479470332004, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 41: Train Loss = 0.0021909873384080856, Recall = 1.0, Aging Rate = 0.5002224199288257, Precision = 0.9995553579368608, f1 = 0.9997776295307983\n",
      "Epoch 42: Train Loss = 0.001764880401725314, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 43: Train Loss = 0.0017382003523548567, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 44: Train Loss = 0.001599316882115401, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 45: Train Loss = 0.0015910166032774725, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0014023961718078186, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 46: Train Loss = 0.0018418026546155536, Recall = 1.0, Aging Rate = 0.5002224199288257, Precision = 0.9995553579368608, f1 = 0.9997776295307983\n",
      "Epoch 47: Train Loss = 0.03770463066457297, Recall = 0.9911032028469751, Aging Rate = 0.505338078291815, Precision = 0.9806338028169014, f1 = 0.9858407079646017\n",
      "Epoch 48: Train Loss = 0.061152890530080134, Recall = 0.983540925266904, Aging Rate = 0.5097864768683275, Precision = 0.9646596858638743, f1 = 0.9740088105726872\n",
      "Epoch 49: Train Loss = 0.02206225785736684, Recall = 0.994661921708185, Aging Rate = 0.5037811387900356, Precision = 0.98719646799117, f1 = 0.9909151340571682\n",
      "Epoch 50: Train Loss = 0.005062075533151786, Recall = 0.9991103202846975, Aging Rate = 0.5, Precision = 0.9991103202846975, f1 = 0.9991103202846975\n",
      "Test Loss = 0.009422083552868778, Recall = 1.0, Aging Rate = 0.5037811387900356, precision = 0.9924944812362031\n",
      "\n",
      "Epoch 51: Train Loss = 0.0027156509036443516, Recall = 1.0, Aging Rate = 0.5004448398576512, Precision = 0.9991111111111111, f1 = 0.9995553579368608\n",
      "Epoch 52: Train Loss = 0.0008574754948018523, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 53: Train Loss = 0.0007563192343291266, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 54: Train Loss = 0.0008029989311778156, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 55: Train Loss = 0.0009215506368724371, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0008589063779976272, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 56: Train Loss = 0.0009747618155593709, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 57: Train Loss = 0.0010012782154376104, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58: Train Loss = 0.0010811640268682213, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 59: Train Loss = 0.001195811324759496, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 60: Train Loss = 0.0012365938947300735, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0011380713928517393, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Training Finished at epoch 60.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b4abafb09de3437ebda0fc3688e0b9d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss = 0.3700273791029784, Recall = 0.9506227758007118, Aging Rate = 0.729982206405694, Precision = 0.6511273613650214, f1 = 0.7728752260397831\n",
      "Epoch 2: Train Loss = 0.16777888592664034, Recall = 0.9675266903914591, Aging Rate = 0.5387010676156584, Precision = 0.898018166804294, f1 = 0.9314775160599572\n",
      "Epoch 3: Train Loss = 0.1008710373869146, Recall = 0.983540925266904, Aging Rate = 0.5195729537366548, Precision = 0.9464897260273972, f1 = 0.9646596858638744\n",
      "Epoch 4: Train Loss = 0.06795451742368236, Recall = 0.9893238434163701, Aging Rate = 0.5071174377224199, Precision = 0.9754385964912281, f1 = 0.9823321554770319\n",
      "Epoch 5: Train Loss = 0.05030833892656815, Recall = 0.9911032028469751, Aging Rate = 0.5055604982206405, Precision = 0.9802023757149142, f1 = 0.9856226498562265\n",
      "Test Loss = 0.021196159683300506, Recall = 0.9995551601423488, Aging Rate = 0.5, precision = 0.9995551601423488\n",
      "Model in epoch 5 is saved.\n",
      "\n",
      "Epoch 6: Train Loss = 0.01452889664304108, Recall = 1.0, Aging Rate = 0.5002224199288257, Precision = 0.9995553579368608, f1 = 0.9997776295307983\n",
      "Epoch 7: Train Loss = 0.006297246678119187, Recall = 1.0, Aging Rate = 0.5002224199288257, Precision = 0.9995553579368608, f1 = 0.9997776295307983\n",
      "Epoch 8: Train Loss = 0.004242251050456351, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 9: Train Loss = 0.0034604325345336225, Recall = 1.0, Aging Rate = 0.5002224199288257, Precision = 0.9995553579368608, f1 = 0.9997776295307983\n",
      "Epoch 10: Train Loss = 0.0027465759196527487, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.002389707363101246, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "Model in epoch 10 is saved.\n",
      "\n",
      "Epoch 11: Train Loss = 0.0027560723822868806, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 12: Train Loss = 0.002693475811540073, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 13: Train Loss = 0.0025989096810597116, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 14: Train Loss = 0.002315232342148856, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 15: Train Loss = 0.0021809999933764604, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.001799032388725633, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 16: Train Loss = 0.002226922010631695, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 17: Train Loss = 0.0022431866384320146, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 18: Train Loss = 0.002074642778039509, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 19: Train Loss = 0.002465397395438836, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 20: Train Loss = 0.002218360353088888, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0016185346919565969, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 21: Train Loss = 0.0021852511710411075, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 22: Train Loss = 0.0020676637250678183, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 23: Train Loss = 0.0020774187204457848, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 24: Train Loss = 0.0025531571661702147, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 25: Train Loss = 0.047017489980866474, Recall = 0.9884341637010676, Aging Rate = 0.5091192170818505, Precision = 0.9707295762341633, f1 = 0.9795018734846814\n",
      "Test Loss = 0.08880754723959335, Recall = 0.9911032028469751, Aging Rate = 0.5422597864768683, precision = 0.9138638228055783\n",
      "\n",
      "Epoch 26: Train Loss = 0.04814041637255416, Recall = 0.9862099644128114, Aging Rate = 0.5082295373665481, Precision = 0.9702407002188184, f1 = 0.9781601588352085\n",
      "Epoch 27: Train Loss = 0.019837133129859786, Recall = 0.9951067615658363, Aging Rate = 0.5046708185053381, Precision = 0.9858968708682239, f1 = 0.9904804073500111\n",
      "Epoch 28: Train Loss = 0.010337106165562316, Recall = 0.998220640569395, Aging Rate = 0.5028914590747331, Precision = 0.9924812030075187, f1 = 0.9953426480372588\n",
      "Epoch 29: Train Loss = 0.003052335662425088, Recall = 0.9995551601423488, Aging Rate = 0.5002224199288257, Precision = 0.9991107158737217, f1 = 0.9993328885923949\n",
      "Epoch 30: Train Loss = 0.0010528028509194309, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0007554276386902293, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 31: Train Loss = 0.0008321288886920837, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 32: Train Loss = 0.0008780924322454796, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 33: Train Loss = 0.0009260729313214903, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 34: Train Loss = 0.0010113741935717996, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 35: Train Loss = 0.00109582638357239, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0010281025125061783, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 36: Train Loss = 0.0012183518441447, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 37: Train Loss = 0.001270817751827189, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 38: Train Loss = 0.0013682253785544073, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 39: Train Loss = 0.001614491657430167, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 40: Train Loss = 0.0019826270694582593, Recall = 0.9995551601423488, Aging Rate = 0.4997775800711744, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.006248932846347898, Recall = 1.0, Aging Rate = 0.501779359430605, precision = 0.9964539007092199\n",
      "\n",
      "Epoch 41: Train Loss = 0.004084406453731646, Recall = 0.9995551601423488, Aging Rate = 0.5002224199288257, Precision = 0.9991107158737217, f1 = 0.9993328885923949\n",
      "Epoch 42: Train Loss = 0.0016729866686439492, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 43: Train Loss = 0.0034538498608183343, Recall = 0.9995551601423488, Aging Rate = 0.5, Precision = 0.9995551601423488, f1 = 0.9995551601423488\n",
      "Epoch 44: Train Loss = 0.0015002974753145434, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 45: Train Loss = 0.0015115309775942851, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0011518577406235914, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 46: Train Loss = 0.0013692225408292909, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 47: Train Loss = 0.0014888016168140804, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 48: Train Loss = 0.0017624248417419152, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 49: Train Loss = 0.0016269361504164667, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 50: Train Loss = 0.0019223656334659066, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0014712080343715927, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 51: Train Loss = 0.0018779714500657498, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 52: Train Loss = 0.001987096097476091, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 53: Train Loss = 0.001882907317609947, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 54: Train Loss = 0.002175656496754307, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 55: Train Loss = 0.005501783747073542, Recall = 0.9991103202846975, Aging Rate = 0.5004448398576512, Precision = 0.9982222222222222, f1 = 0.9986660738105825\n",
      "Test Loss = 0.07127478716603325, Recall = 0.9848754448398577, Aging Rate = 0.5175711743772242, precision = 0.9514396218306833\n",
      "\n",
      "Epoch 56: Train Loss = 0.12027547613873388, Recall = 0.9626334519572953, Aging Rate = 0.515346975088968, Precision = 0.9339663357790245, f1 = 0.9480832420591456\n",
      "Epoch 57: Train Loss = 0.036238078813456344, Recall = 0.9902135231316725, Aging Rate = 0.5048932384341637, Precision = 0.9806167400881057, f1 = 0.9853917662682603\n",
      "Epoch 58: Train Loss = 0.009756174264144272, Recall = 0.9968861209964412, Aging Rate = 0.5, Precision = 0.9968861209964412, f1 = 0.9968861209964412\n",
      "Epoch 59: Train Loss = 0.004188217507514546, Recall = 0.9995551601423488, Aging Rate = 0.5002224199288257, Precision = 0.9991107158737217, f1 = 0.9993328885923949\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 60: Train Loss = 0.0017243495125661595, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0014667343617552806, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Training Finished at epoch 60.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "63e1da5659fc46d1bd047be10b298822",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss = 0.3453660413251653, Recall = 0.9306049822064056, Aging Rate = 0.645017793594306, Precision = 0.7213793103448276, f1 = 0.8127428127428128\n",
      "Epoch 2: Train Loss = 0.14330639350774874, Recall = 0.9666370106761566, Aging Rate = 0.5293594306049823, Precision = 0.9130252100840336, f1 = 0.9390665514261018\n",
      "Epoch 3: Train Loss = 0.08912175325709942, Recall = 0.9786476868327402, Aging Rate = 0.5129003558718861, Precision = 0.9540329575021682, f1 = 0.9661835748792269\n",
      "Epoch 4: Train Loss = 0.06214262798322477, Recall = 0.9839857651245552, Aging Rate = 0.5084519572953736, Precision = 0.9676290463692039, f1 = 0.9757388619320688\n",
      "Epoch 5: Train Loss = 0.05109121951397203, Recall = 0.9853202846975089, Aging Rate = 0.5033362989323843, Precision = 0.9787892178524084, f1 = 0.9820438927067169\n",
      "Test Loss = 0.020129753468936026, Recall = 1.0, Aging Rate = 0.50355871886121, precision = 0.9929328621908127\n",
      "Model in epoch 5 is saved.\n",
      "\n",
      "Epoch 6: Train Loss = 0.013680120720445207, Recall = 0.9991103202846975, Aging Rate = 0.5008896797153025, Precision = 0.9973357015985791, f1 = 0.9982222222222222\n",
      "Epoch 7: Train Loss = 0.006991144393163061, Recall = 0.9991103202846975, Aging Rate = 0.5, Precision = 0.9991103202846975, f1 = 0.9991103202846975\n",
      "Epoch 8: Train Loss = 0.004668230768392572, Recall = 0.9995551601423488, Aging Rate = 0.5, Precision = 0.9995551601423488, f1 = 0.9995551601423488\n",
      "Epoch 9: Train Loss = 0.0031560233564636407, Recall = 1.0, Aging Rate = 0.5002224199288257, Precision = 0.9995553579368608, f1 = 0.9997776295307983\n",
      "Epoch 10: Train Loss = 0.0026311990529467814, Recall = 1.0, Aging Rate = 0.5002224199288257, Precision = 0.9995553579368608, f1 = 0.9997776295307983\n",
      "Test Loss = 0.0022200031530814662, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "Model in epoch 10 is saved.\n",
      "\n",
      "Epoch 11: Train Loss = 0.0024231936450079465, Recall = 1.0, Aging Rate = 0.5002224199288257, Precision = 0.9995553579368608, f1 = 0.9997776295307983\n",
      "Epoch 12: Train Loss = 0.0022311688026287377, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 13: Train Loss = 0.0021476263994039484, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 14: Train Loss = 0.0020905307774163545, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 15: Train Loss = 0.002056479695156959, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0017556420302025152, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 16: Train Loss = 0.0020835723193922476, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 17: Train Loss = 0.00213096565293526, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 18: Train Loss = 0.002061381335353671, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 19: Train Loss = 0.0024122748303548615, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 20: Train Loss = 0.002314022397523037, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0017009873470967616, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 21: Train Loss = 0.002198768748149435, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 22: Train Loss = 0.006344533727580542, Recall = 0.9991103202846975, Aging Rate = 0.5013345195729537, Precision = 0.9964507542147294, f1 = 0.9977787649933363\n",
      "Epoch 23: Train Loss = 0.07117498056214051, Recall = 0.979982206405694, Aging Rate = 0.5097864768683275, Precision = 0.9611692844677138, f1 = 0.9704845814977974\n",
      "Epoch 24: Train Loss = 0.04881888490876189, Recall = 0.9857651245551602, Aging Rate = 0.5077846975088968, Precision = 0.970652650021901, f1 = 0.9781505186493048\n",
      "Epoch 25: Train Loss = 0.015708842918192273, Recall = 0.99644128113879, Aging Rate = 0.5026690391459074, Precision = 0.9911504424778761, f1 = 0.9937888198757764\n",
      "Test Loss = 0.006114585333407667, Recall = 0.9991103202846975, Aging Rate = 0.5004448398576512, precision = 0.9982222222222222\n",
      "\n",
      "Epoch 26: Train Loss = 0.004438143530098251, Recall = 0.9995551601423488, Aging Rate = 0.5004448398576512, Precision = 0.9986666666666667, f1 = 0.9991107158737217\n",
      "Epoch 27: Train Loss = 0.0015520390085428555, Recall = 1.0, Aging Rate = 0.5002224199288257, Precision = 0.9995553579368608, f1 = 0.9997776295307983\n",
      "Epoch 28: Train Loss = 0.0009734212786284047, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 29: Train Loss = 0.0008858268536971982, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 30: Train Loss = 0.000951733472889614, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0009402378803629468, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 31: Train Loss = 0.0010731283913356553, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 32: Train Loss = 0.0011292130746828968, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 33: Train Loss = 0.0012034308645887518, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 34: Train Loss = 0.001217770419212794, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 35: Train Loss = 0.0014450940248818267, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.001438511451010284, Recall = 1.0, Aging Rate = 0.5004448398576512, precision = 0.9991111111111111\n",
      "\n",
      "Epoch 36: Train Loss = 0.0014249998355264448, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 37: Train Loss = 0.0013987599910167295, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 38: Train Loss = 0.001526310114816388, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 39: Train Loss = 0.002893879916850358, Recall = 1.0, Aging Rate = 0.5004448398576512, Precision = 0.9991111111111111, f1 = 0.9995553579368608\n",
      "Epoch 40: Train Loss = 0.005435310985256662, Recall = 0.9995551601423488, Aging Rate = 0.5, Precision = 0.9995551601423488, f1 = 0.9995551601423488\n",
      "Test Loss = 0.02519446153034625, Recall = 1.0, Aging Rate = 0.5129003558718861, precision = 0.9748482220294883\n",
      "\n",
      "Epoch 41: Train Loss = 0.047909214908714505, Recall = 0.9866548042704626, Aging Rate = 0.5084519572953736, Precision = 0.9702537182852143, f1 = 0.9783855315394795\n",
      "Epoch 42: Train Loss = 0.03659461538251026, Recall = 0.9853202846975089, Aging Rate = 0.5022241992882562, Precision = 0.9809565987599645, f1 = 0.9831335996449179\n",
      "Epoch 43: Train Loss = 0.015078056688185158, Recall = 0.9973309608540926, Aging Rate = 0.5026690391459074, Precision = 0.9920353982300885, f1 = 0.9946761313220941\n",
      "Epoch 44: Train Loss = 0.004730044685559367, Recall = 0.9995551601423488, Aging Rate = 0.5011120996441281, Precision = 0.9973368841544608, f1 = 0.9984447900466562\n",
      "Epoch 45: Train Loss = 0.0016811947372254792, Recall = 1.0, Aging Rate = 0.5002224199288257, Precision = 0.9995553579368608, f1 = 0.9997776295307983\n",
      "Test Loss = 0.0009668751497955137, Recall = 0.9995551601423488, Aging Rate = 0.4997775800711744, precision = 1.0\n",
      "\n",
      "Epoch 46: Train Loss = 0.0013370142520067292, Recall = 1.0, Aging Rate = 0.5002224199288257, Precision = 0.9995553579368608, f1 = 0.9997776295307983\n",
      "Epoch 47: Train Loss = 0.0007650361273535511, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 48: Train Loss = 0.0007396509501754946, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 49: Train Loss = 0.0008185979084930386, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 50: Train Loss = 0.0009104387330892247, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0008852567877521029, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 51: Train Loss = 0.0010376876353508267, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 52: Train Loss = 0.0011054480140133896, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 53: Train Loss = 0.001190036021958493, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 54: Train Loss = 0.001277814905102832, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 55: Train Loss = 0.0014246398590511751, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0012463980708171836, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 56: Train Loss = 0.0014597985046680393, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 57: Train Loss = 0.0015222531208085738, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 58: Train Loss = 0.001540069741750421, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59: Train Loss = 0.001584987320566013, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 60: Train Loss = 0.001637470262171535, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0015572132018653285, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Training Finished at epoch 60.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c13ec9ee3f84b23a42b8d1e8b4a32a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "736410669684443dabb2450912485594",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss = 0.6403967161195558, Recall = 0.574288256227758, Aging Rate = 0.3765569395017794, Precision = 0.7625516834022446, f1 = 0.6551636640446586\n",
      "Epoch 2: Train Loss = 0.47658002875029404, Recall = 0.7798042704626335, Aging Rate = 0.46352313167259784, Precision = 0.8411708253358925, f1 = 0.8093259464450601\n",
      "Epoch 3: Train Loss = 0.3585641695935531, Recall = 0.8656583629893239, Aging Rate = 0.5024466192170819, Precision = 0.8614431164231962, f1 = 0.8635455957399601\n",
      "Epoch 4: Train Loss = 0.3022539833050181, Recall = 0.8994661921708185, Aging Rate = 0.506450177935943, Precision = 0.8880105401844532, f1 = 0.8937016574585634\n",
      "Epoch 5: Train Loss = 0.265559693884595, Recall = 0.9079181494661922, Aging Rate = 0.5015569395017794, Precision = 0.90509977827051, f1 = 0.9065067732622697\n",
      "Test Loss = 0.24427815927093138, Recall = 0.931049822064057, Aging Rate = 0.5120106761565836, precision = 0.9092093831450913\n",
      "Model in epoch 5 is saved.\n",
      "\n",
      "Epoch 6: Train Loss = 0.24196005530416753, Recall = 0.925711743772242, Aging Rate = 0.5055604982206405, Precision = 0.915530136383634, f1 = 0.920592789205928\n",
      "Epoch 7: Train Loss = 0.22380488792772396, Recall = 0.9283807829181495, Aging Rate = 0.4973309608540925, Precision = 0.9333631484794276, f1 = 0.9308652988403212\n",
      "Epoch 8: Train Loss = 0.20838735080274398, Recall = 0.9341637010676157, Aging Rate = 0.49666370106761565, Precision = 0.9404388714733543, f1 = 0.9372907833072975\n",
      "Epoch 9: Train Loss = 0.19727216464768949, Recall = 0.9386120996441281, Aging Rate = 0.49488434163701067, Precision = 0.9483146067415731, f1 = 0.9434384082271406\n",
      "Epoch 10: Train Loss = 0.1870897560251141, Recall = 0.9408362989323843, Aging Rate = 0.49243772241992884, Precision = 0.9552845528455285, f1 = 0.948005378753922\n",
      "Test Loss = 0.17783756172317627, Recall = 0.9350533807829181, Aging Rate = 0.4830960854092527, precision = 0.9677716390423573\n",
      "Model in epoch 10 is saved.\n",
      "\n",
      "Epoch 11: Train Loss = 0.1774724456233062, Recall = 0.943950177935943, Aging Rate = 0.489991103202847, Precision = 0.9632319564230595, f1 = 0.9534935969445069\n",
      "Epoch 12: Train Loss = 0.17008592092906027, Recall = 0.9452846975088968, Aging Rate = 0.489991103202847, Precision = 0.964593735814798, f1 = 0.9548416086272747\n",
      "Epoch 13: Train Loss = 0.1639184071234961, Recall = 0.9430604982206405, Aging Rate = 0.4862099644128114, Precision = 0.969807868252516, f1 = 0.9562471808750563\n",
      "Epoch 14: Train Loss = 0.158332484074971, Recall = 0.9470640569395018, Aging Rate = 0.48687722419928825, Precision = 0.9725902238465053, f1 = 0.9596574261888664\n",
      "Epoch 15: Train Loss = 0.1536356801982452, Recall = 0.9435053380782918, Aging Rate = 0.4853202846975089, Precision = 0.9720439963336389, f1 = 0.9575620767494357\n",
      "Test Loss = 0.1471180421601835, Recall = 0.9506227758007118, Aging Rate = 0.486432384341637, precision = 0.9771376314586191\n",
      "Model in epoch 15 is saved.\n",
      "\n",
      "Epoch 16: Train Loss = 0.15001060015578288, Recall = 0.951067615658363, Aging Rate = 0.4888790035587189, Precision = 0.9727024567788899, f1 = 0.9617633828160144\n",
      "Epoch 17: Train Loss = 0.14691523687907385, Recall = 0.9479537366548043, Aging Rate = 0.48576512455516013, Precision = 0.9757326007326007, f1 = 0.9616425992779782\n",
      "Epoch 18: Train Loss = 0.14400721105392292, Recall = 0.9519572953736655, Aging Rate = 0.4870996441281139, Precision = 0.9771689497716894, f1 = 0.964398377647589\n",
      "Epoch 19: Train Loss = 0.13981652556789304, Recall = 0.9546263345195729, Aging Rate = 0.48821174377224197, Precision = 0.9776765375854214, f1 = 0.9660139545352239\n",
      "Epoch 20: Train Loss = 0.13761514801783917, Recall = 0.9590747330960854, Aging Rate = 0.491770462633452, Precision = 0.9751243781094527, f1 = 0.967032967032967\n",
      "Test Loss = 0.13297989691385595, Recall = 0.9586298932384342, Aging Rate = 0.48954626334519574, precision = 0.9791004089050431\n",
      "Model in epoch 20 is saved.\n",
      "\n",
      "Epoch 21: Train Loss = 0.13554614342192314, Recall = 0.9572953736654805, Aging Rate = 0.4886565836298932, Precision = 0.9795175238962222, f1 = 0.9682789651293588\n",
      "Epoch 22: Train Loss = 0.13602302931381716, Recall = 0.9568505338078291, Aging Rate = 0.4891014234875445, Precision = 0.9781718963165075, f1 = 0.9673937485945582\n",
      "Epoch 23: Train Loss = 0.13218723624626513, Recall = 0.9577402135231317, Aging Rate = 0.4886565836298932, Precision = 0.9799726900318616, f1 = 0.9687289088863892\n",
      "Epoch 24: Train Loss = 0.13177948850753893, Recall = 0.9626334519572953, Aging Rate = 0.49088078291814946, Precision = 0.9805165382872678, f1 = 0.9714927048260381\n",
      "Epoch 25: Train Loss = 0.13015996274999028, Recall = 0.9661921708185054, Aging Rate = 0.4928825622775801, Precision = 0.98014440433213, f1 = 0.9731182795698925\n",
      "Test Loss = 0.1253127298215106, Recall = 0.9710854092526691, Aging Rate = 0.49377224199288255, precision = 0.9833333333333333\n",
      "Model in epoch 25 is saved.\n",
      "\n",
      "Epoch 26: Train Loss = 0.12948272130667526, Recall = 0.9648576512455516, Aging Rate = 0.4922153024911032, Precision = 0.9801174875734298, f1 = 0.972427706792199\n",
      "Epoch 27: Train Loss = 0.13033687339240546, Recall = 0.9595195729537367, Aging Rate = 0.4893238434163701, Precision = 0.9804545454545455, f1 = 0.9698741007194245\n",
      "Epoch 28: Train Loss = 0.12833151067491103, Recall = 0.9639679715302492, Aging Rate = 0.49065836298932386, Precision = 0.9823209428830463, f1 = 0.9730579254602605\n",
      "Epoch 29: Train Loss = 0.12641073580420314, Recall = 0.9688612099644128, Aging Rate = 0.4915480427046263, Precision = 0.9855203619909503, f1 = 0.9771197846567968\n",
      "Epoch 30: Train Loss = 0.12666117206374947, Recall = 0.9661921708185054, Aging Rate = 0.49065836298932386, Precision = 0.9845874886672711, f1 = 0.9753030983385721\n",
      "Test Loss = 0.12184592458383044, Recall = 0.969306049822064, Aging Rate = 0.49243772241992884, precision = 0.9841915085817525\n",
      "\n",
      "Epoch 31: Train Loss = 0.1254657261418278, Recall = 0.969306049822064, Aging Rate = 0.4933274021352313, Precision = 0.9824165915238954, f1 = 0.9758172861621137\n",
      "Epoch 32: Train Loss = 0.12611052632543965, Recall = 0.9657473309608541, Aging Rate = 0.4919928825622776, Precision = 0.9814647377938517, f1 = 0.973542600896861\n",
      "Epoch 33: Train Loss = 0.12503507319718493, Recall = 0.9639679715302492, Aging Rate = 0.489991103202847, Precision = 0.9836586472991375, f1 = 0.9737137721860256\n",
      "Epoch 34: Train Loss = 0.12401824953611211, Recall = 0.9661921708185054, Aging Rate = 0.4915480427046263, Precision = 0.9828054298642533, f1 = 0.9744279946164199\n",
      "Epoch 35: Train Loss = 0.12476803882054163, Recall = 0.9670818505338078, Aging Rate = 0.49266014234875444, Precision = 0.981489841986456, f1 = 0.9742325789827471\n",
      "Test Loss = 0.12086419151346879, Recall = 0.972864768683274, Aging Rate = 0.49644128113879005, precision = 0.9798387096774194\n",
      "\n",
      "Epoch 36: Train Loss = 0.12303588202627529, Recall = 0.9701957295373665, Aging Rate = 0.4939946619217082, Precision = 0.9819900945520036, f1 = 0.9760572835086149\n",
      "Epoch 37: Train Loss = 0.12405326925350678, Recall = 0.9697508896797153, Aging Rate = 0.4939946619217082, Precision = 0.9815398469158036, f1 = 0.975609756097561\n",
      "Epoch 38: Train Loss = 0.12263415165219019, Recall = 0.9644128113879004, Aging Rate = 0.489991103202847, Precision = 0.9841125737630504, f1 = 0.9741631094136148\n",
      "Epoch 39: Train Loss = 0.12256637268643363, Recall = 0.9675266903914591, Aging Rate = 0.49266014234875444, Precision = 0.981941309255079, f1 = 0.9746807080439166\n",
      "Epoch 40: Train Loss = 0.1232383750193484, Recall = 0.9701957295373665, Aging Rate = 0.4942170818505338, Precision = 0.9815481548154815, f1 = 0.9758389261744965\n",
      "Test Loss = 0.12324404984288369, Recall = 0.9621886120996441, Aging Rate = 0.48376334519572955, precision = 0.9944827586206897\n",
      "Model in epoch 40 is saved.\n",
      "\n",
      "Epoch 41: Train Loss = 0.12250807849537859, Recall = 0.9684163701067615, Aging Rate = 0.4913256227758007, Precision = 0.9855138071525578, f1 = 0.9768902849450302\n",
      "Epoch 42: Train Loss = 0.12350009631007591, Recall = 0.9653024911032029, Aging Rate = 0.491770462633452, Precision = 0.9814563545906829, f1 = 0.9733124018838304\n",
      "Epoch 43: Train Loss = 0.12105688028488296, Recall = 0.9706405693950177, Aging Rate = 0.4928825622775801, Precision = 0.9846570397111913, f1 = 0.9775985663082437\n",
      "Epoch 44: Train Loss = 0.12070492933441311, Recall = 0.969306049822064, Aging Rate = 0.49243772241992884, Precision = 0.9841915085817525, f1 = 0.976692066337965\n",
      "Epoch 45: Train Loss = 0.12032300684587811, Recall = 0.9710854092526691, Aging Rate = 0.49377224199288255, Precision = 0.9833333333333333, f1 = 0.9771709937332139\n",
      "Test Loss = 0.1190018179789981, Recall = 0.9675266903914591, Aging Rate = 0.48821174377224197, precision = 0.9908883826879271\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 46: Train Loss = 0.12186541935939381, Recall = 0.9666370106761566, Aging Rate = 0.49088078291814946, Precision = 0.9845944721341187, f1 = 0.9755331088664422\n",
      "Epoch 47: Train Loss = 0.12102949317027666, Recall = 0.972864768683274, Aging Rate = 0.4939946619217082, Precision = 0.984691580369203, f1 = 0.9787424479749385\n",
      "Epoch 48: Train Loss = 0.12115417479196053, Recall = 0.9719750889679716, Aging Rate = 0.49466192170818507, Precision = 0.9824640287769785, f1 = 0.9771914132379249\n",
      "Epoch 49: Train Loss = 0.12029672848902563, Recall = 0.9670818505338078, Aging Rate = 0.4922153024911032, Precision = 0.98237686398554, f1 = 0.9746693566464919\n",
      "Epoch 50: Train Loss = 0.12057016397498256, Recall = 0.9724199288256228, Aging Rate = 0.4939946619217082, Precision = 0.9842413327330032, f1 = 0.9782949205638846\n",
      "Test Loss = 0.12146833284469687, Recall = 0.978202846975089, Aging Rate = 0.5006672597864769, precision = 0.9768991559306974\n",
      "\n",
      "Epoch 51: Train Loss = 0.12120841337480578, Recall = 0.9675266903914591, Aging Rate = 0.4922153024911032, Precision = 0.982828739267962, f1 = 0.9751176866173504\n",
      "Epoch 52: Train Loss = 0.12134872414039123, Recall = 0.9701957295373665, Aging Rate = 0.49266014234875444, Precision = 0.9846501128668171, f1 = 0.9773694824109344\n",
      "Epoch 53: Train Loss = 0.11949304364011805, Recall = 0.9701957295373665, Aging Rate = 0.4919928825622776, Precision = 0.9859855334538878, f1 = 0.9780269058295963\n",
      "Epoch 54: Train Loss = 0.11994686916311441, Recall = 0.9666370106761566, Aging Rate = 0.49088078291814946, Precision = 0.9845944721341187, f1 = 0.9755331088664422\n",
      "Epoch 55: Train Loss = 0.12045243170337745, Recall = 0.9684163701067615, Aging Rate = 0.49110320284697506, Precision = 0.9859601449275363, f1 = 0.9771095152603232\n",
      "Test Loss = 0.11618774217218691, Recall = 0.9697508896797153, Aging Rate = 0.49266014234875444, precision = 0.9841986455981941\n",
      "\n",
      "Epoch 56: Train Loss = 0.12009391509447234, Recall = 0.9697508896797153, Aging Rate = 0.4928825622775801, Precision = 0.983754512635379, f1 = 0.9767025089605734\n",
      "Epoch 57: Train Loss = 0.11937482602019327, Recall = 0.9684163701067615, Aging Rate = 0.49065836298932386, Precision = 0.9868540344514959, f1 = 0.9775482712168837\n",
      "Epoch 58: Train Loss = 0.11946053004879968, Recall = 0.9701957295373665, Aging Rate = 0.4931049822064057, Precision = 0.9837618403247632, f1 = 0.9769316909294512\n",
      "Epoch 59: Train Loss = 0.11906995011818367, Recall = 0.9701957295373665, Aging Rate = 0.49266014234875444, Precision = 0.9846501128668171, f1 = 0.9773694824109344\n",
      "Epoch 60: Train Loss = 0.12006182451583312, Recall = 0.9679715302491103, Aging Rate = 0.4922153024911032, Precision = 0.9832806145503841, f1 = 0.9755660165882089\n",
      "Test Loss = 0.11711998771730267, Recall = 0.9759786476868327, Aging Rate = 0.4962188612099644, precision = 0.9834155087404751\n",
      "\n",
      "Epoch 61: Train Loss = 0.11936366080813561, Recall = 0.9706405693950177, Aging Rate = 0.4922153024911032, Precision = 0.9859918662449164, f1 = 0.9782559964133601\n",
      "Epoch 62: Train Loss = 0.11922310663924099, Recall = 0.9661921708185054, Aging Rate = 0.49065836298932386, Precision = 0.9845874886672711, f1 = 0.9753030983385721\n",
      "Epoch 63: Train Loss = 0.1195170118397241, Recall = 0.9719750889679716, Aging Rate = 0.4944395017793594, Precision = 0.9829059829059829, f1 = 0.9774099753970029\n",
      "Epoch 64: Train Loss = 0.12005029183901926, Recall = 0.969306049822064, Aging Rate = 0.4922153024911032, Precision = 0.9846362403976503, f1 = 0.9769110065007846\n",
      "Epoch 65: Train Loss = 0.11862807588326973, Recall = 0.9684163701067615, Aging Rate = 0.49243772241992884, Precision = 0.9832881662149955, f1 = 0.9757956073509637\n",
      "Test Loss = 0.11760372411313855, Recall = 0.9773131672597865, Aging Rate = 0.498220640569395, precision = 0.9808035714285714\n",
      "\n",
      "Epoch 66: Train Loss = 0.11927871289414443, Recall = 0.9697508896797153, Aging Rate = 0.4928825622775801, Precision = 0.983754512635379, f1 = 0.9767025089605734\n",
      "Epoch 67: Train Loss = 0.11915837583592778, Recall = 0.9697508896797153, Aging Rate = 0.4922153024911032, Precision = 0.9850881156800723, f1 = 0.9773593364716432\n",
      "Epoch 68: Train Loss = 0.11836278401447785, Recall = 0.9684163701067615, Aging Rate = 0.49110320284697506, Precision = 0.9859601449275363, f1 = 0.9771095152603232\n",
      "Epoch 69: Train Loss = 0.11915247423368841, Recall = 0.9706405693950177, Aging Rate = 0.4933274021352313, Precision = 0.9837691614066727, f1 = 0.9771607702642185\n",
      "Epoch 70: Train Loss = 0.11837186184430037, Recall = 0.9670818505338078, Aging Rate = 0.491770462633452, Precision = 0.9832654907281773, f1 = 0.9751065261269343\n",
      "Test Loss = 0.11624720525593096, Recall = 0.9675266903914591, Aging Rate = 0.4888790035587189, precision = 0.9895359417652412\n",
      "\n",
      "Epoch 71: Train Loss = 0.11895659054195329, Recall = 0.969306049822064, Aging Rate = 0.4922153024911032, Precision = 0.9846362403976503, f1 = 0.9769110065007846\n",
      "Epoch 72: Train Loss = 0.11796080191152376, Recall = 0.9715302491103203, Aging Rate = 0.49266014234875444, Precision = 0.9860045146726862, f1 = 0.9787138695944432\n",
      "Epoch 73: Train Loss = 0.11819343465078767, Recall = 0.9684163701067615, Aging Rate = 0.4913256227758007, Precision = 0.9855138071525578, f1 = 0.9768902849450302\n",
      "Epoch 74: Train Loss = 0.11822368424664188, Recall = 0.9706405693950177, Aging Rate = 0.49243772241992884, Precision = 0.985546522131888, f1 = 0.978036754818467\n",
      "Epoch 75: Train Loss = 0.11815507712631464, Recall = 0.969306049822064, Aging Rate = 0.4915480427046263, Precision = 0.9859728506787331, f1 = 0.9775684163301929\n",
      "Test Loss = 0.11539556518250088, Recall = 0.9710854092526691, Aging Rate = 0.4913256227758007, precision = 0.9882299683114532\n",
      "\n",
      "Epoch 76: Train Loss = 0.11854054243220978, Recall = 0.9701957295373665, Aging Rate = 0.49266014234875444, Precision = 0.9846501128668171, f1 = 0.9773694824109344\n",
      "Epoch 77: Train Loss = 0.11936932478723153, Recall = 0.969306049822064, Aging Rate = 0.49266014234875444, Precision = 0.9837471783295711, f1 = 0.9764732242885952\n",
      "Epoch 78: Train Loss = 0.11869731815896424, Recall = 0.9684163701067615, Aging Rate = 0.4919928825622776, Precision = 0.9841772151898734, f1 = 0.9762331838565023\n",
      "Epoch 79: Train Loss = 0.11754048591830976, Recall = 0.9719750889679716, Aging Rate = 0.4933274021352313, Precision = 0.9851217312894499, f1 = 0.9785042543663234\n",
      "Epoch 80: Train Loss = 0.11876307841509687, Recall = 0.969306049822064, Aging Rate = 0.4922153024911032, Precision = 0.9846362403976503, f1 = 0.9769110065007846\n",
      "Test Loss = 0.11517818176661522, Recall = 0.9697508896797153, Aging Rate = 0.489991103202847, precision = 0.9895596913300045\n",
      "\n",
      "Epoch 81: Train Loss = 0.11779129839240444, Recall = 0.9701957295373665, Aging Rate = 0.4919928825622776, Precision = 0.9859855334538878, f1 = 0.9780269058295963\n",
      "Epoch 82: Train Loss = 0.11801051711696747, Recall = 0.9710854092526691, Aging Rate = 0.49377224199288255, Precision = 0.9833333333333333, f1 = 0.9771709937332139\n",
      "Epoch 83: Train Loss = 0.11783119283112767, Recall = 0.9697508896797153, Aging Rate = 0.4919928825622776, Precision = 0.9855334538878843, f1 = 0.9775784753363229\n",
      "Epoch 84: Train Loss = 0.11797847028728906, Recall = 0.969306049822064, Aging Rate = 0.49110320284697506, Precision = 0.9868659420289855, f1 = 0.9780071813285457\n",
      "Epoch 85: Train Loss = 0.11802507989983542, Recall = 0.9701957295373665, Aging Rate = 0.4915480427046263, Precision = 0.9868778280542987, f1 = 0.9784656796769853\n",
      "Test Loss = 0.11407221721160454, Recall = 0.9710854092526691, Aging Rate = 0.4919928825622776, precision = 0.9868896925858951\n",
      "\n",
      "Epoch 86: Train Loss = 0.1174524796602989, Recall = 0.9697508896797153, Aging Rate = 0.49266014234875444, Precision = 0.9841986455981941, f1 = 0.9769213533497648\n",
      "Epoch 87: Train Loss = 0.11834573703304305, Recall = 0.9701957295373665, Aging Rate = 0.4933274021352313, Precision = 0.9833183047790802, f1 = 0.9767129422301837\n",
      "Epoch 88: Train Loss = 0.11724401570299767, Recall = 0.9684163701067615, Aging Rate = 0.489991103202847, Precision = 0.988197911938266, f1 = 0.9782071444619187\n",
      "Epoch 89: Train Loss = 0.11803562111913946, Recall = 0.9688612099644128, Aging Rate = 0.4931049822064057, Precision = 0.9824086603518268, f1 = 0.9755879059350504\n",
      "Epoch 90: Train Loss = 0.1173673276375197, Recall = 0.9697508896797153, Aging Rate = 0.49266014234875444, Precision = 0.9841986455981941, f1 = 0.9769213533497648\n",
      "Test Loss = 0.11550871341147881, Recall = 0.9688612099644128, Aging Rate = 0.48976868327402134, precision = 0.989100817438692\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Finished at epoch 90.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cdb034cde4734a6aacfdf2103cd17d61",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss = 0.6384874783801014, Recall = 0.5822953736654805, Aging Rate = 0.3994661921708185, Precision = 0.7288418708240535, f1 = 0.6473788328387735\n",
      "Epoch 2: Train Loss = 0.4749886410516352, Recall = 0.797153024911032, Aging Rate = 0.47731316725978645, Precision = 0.8350419384902144, f1 = 0.8156577150659989\n",
      "Epoch 3: Train Loss = 0.36141777017362603, Recall = 0.869661921708185, Aging Rate = 0.5033362989323843, Precision = 0.86389748121962, f1 = 0.8667701174905785\n",
      "Epoch 4: Train Loss = 0.3029729267880586, Recall = 0.8936832740213523, Aging Rate = 0.5006672597864769, Precision = 0.8924922256774767, f1 = 0.8930873527450544\n",
      "Epoch 5: Train Loss = 0.2678547196116736, Recall = 0.9172597864768683, Aging Rate = 0.5042259786476868, Precision = 0.9095721217468019, f1 = 0.9133997785160576\n",
      "Test Loss = 0.2461534461729043, Recall = 0.931049822064057, Aging Rate = 0.5008896797153025, precision = 0.9293960923623446\n",
      "Model in epoch 5 is saved.\n",
      "\n",
      "Epoch 6: Train Loss = 0.23811043894375772, Recall = 0.9319395017793595, Aging Rate = 0.5011120996441281, Precision = 0.9298712827341322, f1 = 0.9309042435014442\n",
      "Epoch 7: Train Loss = 0.22136491839359665, Recall = 0.9306049822064056, Aging Rate = 0.4973309608540925, Precision = 0.9355992844364938, f1 = 0.9330954504906332\n",
      "Epoch 8: Train Loss = 0.20599907657854075, Recall = 0.9377224199288257, Aging Rate = 0.49555160142348753, Precision = 0.9461400359066428, f1 = 0.9419124218051833\n",
      "Epoch 9: Train Loss = 0.19263793252328962, Recall = 0.9337188612099644, Aging Rate = 0.4884341637010676, Precision = 0.9558287795992714, f1 = 0.9446444644464446\n",
      "Epoch 10: Train Loss = 0.18534805776809882, Recall = 0.9341637010676157, Aging Rate = 0.484653024911032, Precision = 0.9637448370812299, f1 = 0.9487237406821776\n",
      "Test Loss = 0.1754248034063183, Recall = 0.9443950177935944, Aging Rate = 0.49266014234875444, precision = 0.9584650112866817\n",
      "Model in epoch 10 is saved.\n",
      "\n",
      "Epoch 11: Train Loss = 0.17461654968108994, Recall = 0.9417259786476868, Aging Rate = 0.4888790035587189, Precision = 0.9631483166515014, f1 = 0.9523166891587944\n",
      "Epoch 12: Train Loss = 0.16745830059475747, Recall = 0.9421708185053381, Aging Rate = 0.4862099644128114, Precision = 0.9688929551692589, f1 = 0.9553450608930988\n",
      "Epoch 13: Train Loss = 0.160134532220423, Recall = 0.9408362989323843, Aging Rate = 0.48487544483985767, Precision = 0.9701834862385321, f1 = 0.9552845528455285\n",
      "Epoch 14: Train Loss = 0.1565206794339991, Recall = 0.9466192170818505, Aging Rate = 0.4870996441281139, Precision = 0.971689497716895, f1 = 0.9589905362776024\n",
      "Epoch 15: Train Loss = 0.15194696665234414, Recall = 0.9470640569395018, Aging Rate = 0.4870996441281139, Precision = 0.9721461187214612, f1 = 0.9594411897251014\n",
      "Test Loss = 0.14595806312306495, Recall = 0.9430604982206405, Aging Rate = 0.4806494661921708, precision = 0.9810273021749191\n",
      "Model in epoch 15 is saved.\n",
      "\n",
      "Epoch 16: Train Loss = 0.14600082993295269, Recall = 0.9515124555160143, Aging Rate = 0.4891014234875445, Precision = 0.9727148703956344, f1 = 0.9619968518102092\n",
      "Epoch 17: Train Loss = 0.14517951769973036, Recall = 0.9506227758007118, Aging Rate = 0.48821174377224197, Precision = 0.9735763097949887, f1 = 0.9619626378573036\n",
      "Epoch 18: Train Loss = 0.14191390054293798, Recall = 0.9541814946619217, Aging Rate = 0.4875444839857651, Precision = 0.978558394160584, f1 = 0.9662162162162163\n",
      "Epoch 19: Train Loss = 0.1381314453864437, Recall = 0.9559608540925267, Aging Rate = 0.4891014234875445, Precision = 0.977262391996362, f1 = 0.9664942657971667\n",
      "Epoch 20: Train Loss = 0.1361613175516875, Recall = 0.9612989323843416, Aging Rate = 0.49088078291814946, Precision = 0.9791572270049841, f1 = 0.9701459034792368\n",
      "Test Loss = 0.1309687992113765, Recall = 0.969306049822064, Aging Rate = 0.49532918149466193, precision = 0.9784463403682083\n",
      "Model in epoch 20 is saved.\n",
      "\n",
      "Epoch 21: Train Loss = 0.13768533010075526, Recall = 0.9555160142348754, Aging Rate = 0.4870996441281139, Precision = 0.9808219178082191, f1 = 0.9680036052275799\n",
      "Epoch 22: Train Loss = 0.13344472020970544, Recall = 0.9657473309608541, Aging Rate = 0.4933274021352313, Precision = 0.978809738503156, f1 = 0.9722346618898342\n",
      "Epoch 23: Train Loss = 0.13125650112739237, Recall = 0.9626334519572953, Aging Rate = 0.4904359430604982, Precision = 0.98140589569161, f1 = 0.9719290366045363\n",
      "Epoch 24: Train Loss = 0.1303239156130794, Recall = 0.9626334519572953, Aging Rate = 0.4922153024911032, Precision = 0.9778581111613195, f1 = 0.9701860569379063\n",
      "Epoch 25: Train Loss = 0.1299467995709796, Recall = 0.9635231316725978, Aging Rate = 0.49065836298932386, Precision = 0.9818676337262012, f1 = 0.972608890884598\n",
      "Test Loss = 0.12526679993524245, Recall = 0.969306049822064, Aging Rate = 0.4922153024911032, precision = 0.9846362403976503\n",
      "Model in epoch 25 is saved.\n",
      "\n",
      "Epoch 26: Train Loss = 0.13038570436506508, Recall = 0.9604092526690391, Aging Rate = 0.4886565836298932, Precision = 0.9827036868456986, f1 = 0.9714285714285714\n",
      "Epoch 27: Train Loss = 0.12718729727845174, Recall = 0.9653024911032029, Aging Rate = 0.4913256227758007, Precision = 0.9823449524671797, f1 = 0.973749158626879\n",
      "Epoch 28: Train Loss = 0.12617856942886135, Recall = 0.9657473309608541, Aging Rate = 0.4913256227758007, Precision = 0.9827976459936623, f1 = 0.9741978909580434\n",
      "Epoch 29: Train Loss = 0.12727689467290967, Recall = 0.9653024911032029, Aging Rate = 0.4919928825622776, Precision = 0.9810126582278481, f1 = 0.9730941704035876\n",
      "Epoch 30: Train Loss = 0.12528449524976182, Recall = 0.9675266903914591, Aging Rate = 0.4922153024911032, Precision = 0.982828739267962, f1 = 0.9751176866173504\n",
      "Test Loss = 0.12515727250283298, Recall = 0.9604092526690391, Aging Rate = 0.4833185053380783, precision = 0.9935572940635067\n",
      "Model in epoch 30 is saved.\n",
      "\n",
      "Epoch 31: Train Loss = 0.12470191083450759, Recall = 0.9675266903914591, Aging Rate = 0.49243772241992884, Precision = 0.9823848238482384, f1 = 0.9748991483639623\n",
      "Epoch 32: Train Loss = 0.12507887611503704, Recall = 0.9653024911032029, Aging Rate = 0.491770462633452, Precision = 0.9814563545906829, f1 = 0.9733124018838304\n",
      "Epoch 33: Train Loss = 0.12343460923306034, Recall = 0.9648576512455516, Aging Rate = 0.48976868327402134, Precision = 0.9850136239782016, f1 = 0.9748314606741573\n",
      "Epoch 34: Train Loss = 0.12339254731173192, Recall = 0.9670818505338078, Aging Rate = 0.49110320284697506, Precision = 0.9846014492753623, f1 = 0.9757630161579893\n",
      "Epoch 35: Train Loss = 0.12300705496102465, Recall = 0.9675266903914591, Aging Rate = 0.49110320284697506, Precision = 0.9850543478260869, f1 = 0.9762118491921006\n",
      "Test Loss = 0.12064310091670298, Recall = 0.9635231316725978, Aging Rate = 0.48665480427046265, precision = 0.9899451553930531\n",
      "\n",
      "Epoch 36: Train Loss = 0.12260841283933972, Recall = 0.9666370106761566, Aging Rate = 0.49110320284697506, Precision = 0.9841485507246377, f1 = 0.975314183123878\n",
      "Epoch 37: Train Loss = 0.12384516117411576, Recall = 0.9657473309608541, Aging Rate = 0.49065836298932386, Precision = 0.9841341795104261, f1 = 0.9748540637629097\n",
      "Epoch 38: Train Loss = 0.12363590289477351, Recall = 0.9675266903914591, Aging Rate = 0.49110320284697506, Precision = 0.9850543478260869, f1 = 0.9762118491921006\n",
      "Epoch 39: Train Loss = 0.12181340794334208, Recall = 0.9670818505338078, Aging Rate = 0.4904359430604982, Precision = 0.9859410430839002, f1 = 0.9764203907478104\n",
      "Epoch 40: Train Loss = 0.12339493754283389, Recall = 0.9626334519572953, Aging Rate = 0.4902135231316726, Precision = 0.9818511796733213, f1 = 0.97214734950584\n",
      "Test Loss = 0.12635294875640463, Recall = 0.9577402135231317, Aging Rate = 0.48087188612099646, precision = 0.9958371877890841\n",
      "Model in epoch 40 is saved.\n",
      "\n",
      "Epoch 41: Train Loss = 0.12147702997901685, Recall = 0.9701957295373665, Aging Rate = 0.49243772241992884, Precision = 0.9850948509485095, f1 = 0.9775885253249664\n",
      "Epoch 42: Train Loss = 0.12323709553458936, Recall = 0.9661921708185054, Aging Rate = 0.49088078291814946, Precision = 0.9841413683733575, f1 = 0.9750841750841752\n",
      "Epoch 43: Train Loss = 0.12142531250295266, Recall = 0.9679715302491103, Aging Rate = 0.4913256227758007, Precision = 0.9850611136260752, f1 = 0.9764415526138659\n",
      "Epoch 44: Train Loss = 0.1207465954204471, Recall = 0.9675266903914591, Aging Rate = 0.4904359430604982, Precision = 0.9863945578231292, f1 = 0.976869526162138\n",
      "Epoch 45: Train Loss = 0.12051929713780346, Recall = 0.9670818505338078, Aging Rate = 0.4902135231316726, Precision = 0.9863883847549909, f1 = 0.9766397124887691\n",
      "Test Loss = 0.11668027810142557, Recall = 0.9675266903914591, Aging Rate = 0.4891014234875445, precision = 0.9890859481582538\n",
      "\n",
      "Epoch 46: Train Loss = 0.12054021423185424, Recall = 0.9679715302491103, Aging Rate = 0.4902135231316726, Precision = 0.9872958257713249, f1 = 0.977538185085355\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 47: Train Loss = 0.1199340045558176, Recall = 0.9688612099644128, Aging Rate = 0.49065836298932386, Precision = 0.9873073436083409, f1 = 0.9779973057925461\n",
      "Epoch 48: Train Loss = 0.12132717780371154, Recall = 0.9675266903914591, Aging Rate = 0.4913256227758007, Precision = 0.9846084200995926, f1 = 0.9759928202827015\n",
      "Epoch 49: Train Loss = 0.12058118105040751, Recall = 0.9679715302491103, Aging Rate = 0.49110320284697506, Precision = 0.9855072463768116, f1 = 0.9766606822262119\n",
      "Epoch 50: Train Loss = 0.11961162970583634, Recall = 0.9661921708185054, Aging Rate = 0.48954626334519574, Precision = 0.9868241708314403, f1 = 0.9763991908294\n",
      "Test Loss = 0.11689807808696163, Recall = 0.9750889679715302, Aging Rate = 0.49488434163701067, precision = 0.9851685393258427\n",
      "\n",
      "Epoch 51: Train Loss = 0.11970358169587905, Recall = 0.9688612099644128, Aging Rate = 0.49110320284697506, Precision = 0.9864130434782609, f1 = 0.9775583482944344\n",
      "Epoch 52: Train Loss = 0.120289581950449, Recall = 0.9675266903914591, Aging Rate = 0.4893238434163701, Precision = 0.9886363636363636, f1 = 0.9779676258992805\n",
      "Epoch 53: Train Loss = 0.11957691387137484, Recall = 0.9679715302491103, Aging Rate = 0.4902135231316726, Precision = 0.9872958257713249, f1 = 0.977538185085355\n",
      "Epoch 54: Train Loss = 0.12086420964940163, Recall = 0.9684163701067615, Aging Rate = 0.4915480427046263, Precision = 0.9850678733031675, f1 = 0.9766711529834006\n",
      "Epoch 55: Train Loss = 0.11935830243541677, Recall = 0.9706405693950177, Aging Rate = 0.4928825622775801, Precision = 0.9846570397111913, f1 = 0.9775985663082437\n",
      "Test Loss = 0.11590130473371078, Recall = 0.9706405693950177, Aging Rate = 0.4922153024911032, precision = 0.9859918662449164\n",
      "\n",
      "Epoch 56: Train Loss = 0.11908917070707817, Recall = 0.9684163701067615, Aging Rate = 0.4913256227758007, Precision = 0.9855138071525578, f1 = 0.9768902849450302\n",
      "Epoch 57: Train Loss = 0.1193528289101302, Recall = 0.9701957295373665, Aging Rate = 0.4919928825622776, Precision = 0.9859855334538878, f1 = 0.9780269058295963\n",
      "Epoch 58: Train Loss = 0.12011009698660773, Recall = 0.9657473309608541, Aging Rate = 0.489991103202847, Precision = 0.9854743531547889, f1 = 0.9755111210963828\n",
      "Epoch 59: Train Loss = 0.11955202606861277, Recall = 0.9644128113879004, Aging Rate = 0.4886565836298932, Precision = 0.9868001820664543, f1 = 0.9754780652418447\n",
      "Epoch 60: Train Loss = 0.11923476868040621, Recall = 0.9670818505338078, Aging Rate = 0.48954626334519574, Precision = 0.987732848705134, f1 = 0.9772982692739942\n",
      "Test Loss = 0.11563779026588086, Recall = 0.9706405693950177, Aging Rate = 0.4919928825622776, precision = 0.9864376130198915\n",
      "\n",
      "Epoch 61: Train Loss = 0.12045981952410152, Recall = 0.9684163701067615, Aging Rate = 0.4902135231316726, Precision = 0.9877495462794919, f1 = 0.9779874213836478\n",
      "Epoch 62: Train Loss = 0.119876266904573, Recall = 0.9666370106761566, Aging Rate = 0.48954626334519574, Precision = 0.9872785097682871, f1 = 0.9768487300516969\n",
      "Epoch 63: Train Loss = 0.11857055938965061, Recall = 0.969306049822064, Aging Rate = 0.49243772241992884, Precision = 0.9841915085817525, f1 = 0.976692066337965\n",
      "Epoch 64: Train Loss = 0.11848480988863948, Recall = 0.9670818505338078, Aging Rate = 0.489991103202847, Precision = 0.9868361325465275, f1 = 0.9768591327791508\n",
      "Epoch 65: Train Loss = 0.11860197925694897, Recall = 0.9706405693950177, Aging Rate = 0.4913256227758007, Precision = 0.9877772747849706, f1 = 0.9791339466008525\n",
      "Test Loss = 0.11545016605977061, Recall = 0.9737544483985765, Aging Rate = 0.4922153024911032, precision = 0.9891549932218707\n",
      "Model in epoch 65 is saved.\n",
      "\n",
      "Epoch 66: Train Loss = 0.12045311312658506, Recall = 0.9675266903914591, Aging Rate = 0.489991103202847, Precision = 0.9872900590104403, f1 = 0.97730847000674\n",
      "Epoch 67: Train Loss = 0.11835605606065526, Recall = 0.9675266903914591, Aging Rate = 0.4904359430604982, Precision = 0.9863945578231292, f1 = 0.976869526162138\n",
      "Epoch 68: Train Loss = 0.11889314206045293, Recall = 0.9719750889679716, Aging Rate = 0.49243772241992884, Precision = 0.9869015356820234, f1 = 0.9793814432989691\n",
      "Epoch 69: Train Loss = 0.11820390576569635, Recall = 0.969306049822064, Aging Rate = 0.4915480427046263, Precision = 0.9859728506787331, f1 = 0.9775684163301929\n",
      "Epoch 70: Train Loss = 0.11908543109893799, Recall = 0.9684163701067615, Aging Rate = 0.491770462633452, Precision = 0.984622342831298, f1 = 0.9764521193092621\n",
      "Test Loss = 0.11472490260185296, Recall = 0.9684163701067615, Aging Rate = 0.48976868327402134, precision = 0.9886466848319709\n",
      "\n",
      "Epoch 71: Train Loss = 0.11792343271584697, Recall = 0.969306049822064, Aging Rate = 0.4913256227758007, Precision = 0.9864191942055228, f1 = 0.9777877496073591\n",
      "Epoch 72: Train Loss = 0.118517692721187, Recall = 0.9697508896797153, Aging Rate = 0.49110320284697506, Precision = 0.9873188405797102, f1 = 0.9784560143626572\n",
      "Epoch 73: Train Loss = 0.11773962479787364, Recall = 0.9670818505338078, Aging Rate = 0.4902135231316726, Precision = 0.9863883847549909, f1 = 0.9766397124887691\n",
      "Epoch 74: Train Loss = 0.1173481112114051, Recall = 0.9697508896797153, Aging Rate = 0.4915480427046263, Precision = 0.9864253393665159, f1 = 0.9780170480035891\n",
      "Epoch 75: Train Loss = 0.11869887095541293, Recall = 0.9684163701067615, Aging Rate = 0.4902135231316726, Precision = 0.9877495462794919, f1 = 0.9779874213836478\n",
      "Test Loss = 0.11637484003852695, Recall = 0.9724199288256228, Aging Rate = 0.4922153024911032, precision = 0.9877993673746046\n",
      "\n",
      "Epoch 76: Train Loss = 0.11809174790713287, Recall = 0.9706405693950177, Aging Rate = 0.4919928825622776, Precision = 0.9864376130198915, f1 = 0.97847533632287\n",
      "Epoch 77: Train Loss = 0.12064720106930919, Recall = 0.9661921708185054, Aging Rate = 0.49110320284697506, Precision = 0.9836956521739131, f1 = 0.9748653500897666\n",
      "Epoch 78: Train Loss = 0.11816955689221514, Recall = 0.9697508896797153, Aging Rate = 0.4915480427046263, Precision = 0.9864253393665159, f1 = 0.9780170480035891\n",
      "Epoch 79: Train Loss = 0.118734095868691, Recall = 0.969306049822064, Aging Rate = 0.49243772241992884, Precision = 0.9841915085817525, f1 = 0.976692066337965\n",
      "Epoch 80: Train Loss = 0.11737829929356898, Recall = 0.9688612099644128, Aging Rate = 0.4904359430604982, Precision = 0.9877551020408163, f1 = 0.9782169324051201\n",
      "Test Loss = 0.11387994050237207, Recall = 0.9701957295373665, Aging Rate = 0.4902135231316726, precision = 0.9895644283121597\n",
      "\n",
      "Epoch 81: Train Loss = 0.1175964916409971, Recall = 0.9697508896797153, Aging Rate = 0.4915480427046263, Precision = 0.9864253393665159, f1 = 0.9780170480035891\n",
      "Epoch 82: Train Loss = 0.11975568304918839, Recall = 0.9670818505338078, Aging Rate = 0.4904359430604982, Precision = 0.9859410430839002, f1 = 0.9764203907478104\n",
      "Epoch 83: Train Loss = 0.11762197787651388, Recall = 0.9675266903914591, Aging Rate = 0.4893238434163701, Precision = 0.9886363636363636, f1 = 0.9779676258992805\n",
      "Epoch 84: Train Loss = 0.11716111189954222, Recall = 0.9715302491103203, Aging Rate = 0.491770462633452, Precision = 0.9877883310719131, f1 = 0.9795918367346939\n",
      "Epoch 85: Train Loss = 0.11746377564197757, Recall = 0.969306049822064, Aging Rate = 0.491770462633452, Precision = 0.9855269109000452, f1 = 0.9773491814308141\n",
      "Test Loss = 0.11492074668089267, Recall = 0.9688612099644128, Aging Rate = 0.48798932384341637, precision = 0.9927073837739289\n",
      "Model in epoch 85 is saved.\n",
      "\n",
      "Epoch 86: Train Loss = 0.11745548794490163, Recall = 0.9684163701067615, Aging Rate = 0.4904359430604982, Precision = 0.9873015873015873, f1 = 0.9777677969907926\n",
      "Epoch 87: Train Loss = 0.11979469715276223, Recall = 0.9697508896797153, Aging Rate = 0.49088078291814946, Precision = 0.9877661984594472, f1 = 0.9786756453423121\n",
      "Epoch 88: Train Loss = 0.11759012258774021, Recall = 0.9688612099644128, Aging Rate = 0.4904359430604982, Precision = 0.9877551020408163, f1 = 0.9782169324051201\n",
      "Epoch 89: Train Loss = 0.11777509563334047, Recall = 0.9710854092526691, Aging Rate = 0.4915480427046263, Precision = 0.9877828054298643, f1 = 0.9793629430237775\n",
      "Epoch 90: Train Loss = 0.11637548855721314, Recall = 0.9710854092526691, Aging Rate = 0.4922153024911032, Precision = 0.9864437415273385, f1 = 0.9787043263842188\n",
      "Test Loss = 0.1139225217901515, Recall = 0.9679715302491103, Aging Rate = 0.48798932384341637, precision = 0.99179580674567\n",
      "\n",
      "Epoch 91: Train Loss = 0.1162293709788034, Recall = 0.9688612099644128, Aging Rate = 0.489991103202847, Precision = 0.9886518384021789, f1 = 0.978656481689508\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 92: Train Loss = 0.11791173172484938, Recall = 0.9688612099644128, Aging Rate = 0.49065836298932386, Precision = 0.9873073436083409, f1 = 0.9779973057925461\n",
      "Epoch 93: Train Loss = 0.11959165835825998, Recall = 0.9666370106761566, Aging Rate = 0.489991103202847, Precision = 0.9863822060826146, f1 = 0.9764097955515615\n",
      "Epoch 94: Train Loss = 0.1162145031198488, Recall = 0.969306049822064, Aging Rate = 0.49110320284697506, Precision = 0.9868659420289855, f1 = 0.9780071813285457\n",
      "Epoch 95: Train Loss = 0.1164988470777498, Recall = 0.9684163701067615, Aging Rate = 0.4902135231316726, Precision = 0.9877495462794919, f1 = 0.9779874213836478\n",
      "Test Loss = 0.11413323155395501, Recall = 0.9697508896797153, Aging Rate = 0.4922153024911032, precision = 0.9850881156800723\n",
      "\n",
      "Epoch 96: Train Loss = 0.11687580700234586, Recall = 0.9688612099644128, Aging Rate = 0.4904359430604982, Precision = 0.9877551020408163, f1 = 0.9782169324051201\n",
      "Epoch 97: Train Loss = 0.11749606465529716, Recall = 0.9706405693950177, Aging Rate = 0.4928825622775801, Precision = 0.9846570397111913, f1 = 0.9775985663082437\n",
      "Epoch 98: Train Loss = 0.1160193845576663, Recall = 0.9684163701067615, Aging Rate = 0.489991103202847, Precision = 0.988197911938266, f1 = 0.9782071444619187\n",
      "Epoch 99: Train Loss = 0.11629704961360986, Recall = 0.9697508896797153, Aging Rate = 0.4913256227758007, Precision = 0.9868718877320054, f1 = 0.9782364819385237\n",
      "Epoch 100: Train Loss = 0.11739209617796317, Recall = 0.9688612099644128, Aging Rate = 0.49088078291814946, Precision = 0.9868599909379248, f1 = 0.9777777777777777\n",
      "Test Loss = 0.113910120099889, Recall = 0.9724199288256228, Aging Rate = 0.4928825622775801, precision = 0.9864620938628159\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "08c8dc3cbb1d47f9b369aec45183a9d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss = 0.6385515684334833, Recall = 0.5044483985765125, Aging Rate = 0.326067615658363, Precision = 0.7735334242837654, f1 = 0.6106623586429726\n",
      "Epoch 2: Train Loss = 0.4725298164578095, Recall = 0.7887010676156584, Aging Rate = 0.4777580071174377, Precision = 0.8254189944134078, f1 = 0.8066424021838036\n",
      "Epoch 3: Train Loss = 0.357163279082003, Recall = 0.8754448398576512, Aging Rate = 0.5084519572953736, Precision = 0.8608923884514436, f1 = 0.8681076312307013\n",
      "Epoch 4: Train Loss = 0.3047342467986816, Recall = 0.9030249110320284, Aging Rate = 0.5048932384341637, Precision = 0.8942731277533039, f1 = 0.8986277113767153\n",
      "Epoch 5: Train Loss = 0.27082982563887625, Recall = 0.9194839857651246, Aging Rate = 0.5062277580071174, Precision = 0.9081722319859402, f1 = 0.9137931034482758\n",
      "Test Loss = 0.24877813500865922, Recall = 0.925711743772242, Aging Rate = 0.4986654804270463, precision = 0.9281891168599464\n",
      "Model in epoch 5 is saved.\n",
      "\n",
      "Epoch 6: Train Loss = 0.24225466918478658, Recall = 0.9261565836298933, Aging Rate = 0.49955516014234874, Precision = 0.9269813000890472, f1 = 0.9265687583444593\n",
      "Epoch 7: Train Loss = 0.22475171948242867, Recall = 0.9408362989323843, Aging Rate = 0.5026690391459074, Precision = 0.9358407079646017, f1 = 0.9383318544809228\n",
      "Epoch 8: Train Loss = 0.21057331615071279, Recall = 0.9377224199288257, Aging Rate = 0.4957740213523132, Precision = 0.9457155675190668, f1 = 0.9417020326111235\n",
      "Epoch 9: Train Loss = 0.1978912124960448, Recall = 0.9430604982206405, Aging Rate = 0.49377224199288255, Precision = 0.954954954954955, f1 = 0.9489704565801254\n",
      "Epoch 10: Train Loss = 0.18855582543539406, Recall = 0.9417259786476868, Aging Rate = 0.49243772241992884, Precision = 0.9561878952122854, f1 = 0.9489018377409232\n",
      "Test Loss = 0.1790650818377627, Recall = 0.9466192170818505, Aging Rate = 0.49354982206405695, precision = 0.9589905362776026\n",
      "Model in epoch 10 is saved.\n",
      "\n",
      "Epoch 11: Train Loss = 0.17865011742955, Recall = 0.9452846975088968, Aging Rate = 0.4919928825622776, Precision = 0.9606690777576854, f1 = 0.952914798206278\n",
      "Epoch 12: Train Loss = 0.17141957114387663, Recall = 0.9457295373665481, Aging Rate = 0.489991103202847, Precision = 0.9650476622787109, f1 = 0.9552909458548641\n",
      "Epoch 13: Train Loss = 0.165443337605305, Recall = 0.947508896797153, Aging Rate = 0.49110320284697506, Precision = 0.9646739130434783, f1 = 0.9560143626570916\n",
      "Epoch 14: Train Loss = 0.16019374879865883, Recall = 0.9443950177935944, Aging Rate = 0.4859875444839858, Precision = 0.9716247139588101, f1 = 0.9578163771712159\n",
      "Epoch 15: Train Loss = 0.1545958579435043, Recall = 0.9479537366548043, Aging Rate = 0.4873220640569395, Precision = 0.9726152441807394, f1 = 0.9601261545393106\n",
      "Test Loss = 0.1484120085941515, Recall = 0.9577402135231317, Aging Rate = 0.4944395017793594, precision = 0.9685110211426001\n",
      "Model in epoch 15 is saved.\n",
      "\n",
      "Epoch 16: Train Loss = 0.1503542108043657, Recall = 0.9501779359430605, Aging Rate = 0.48776690391459077, Precision = 0.9740082079343365, f1 = 0.9619455077685206\n",
      "Epoch 17: Train Loss = 0.14688948666497906, Recall = 0.9501779359430605, Aging Rate = 0.48687722419928825, Precision = 0.9757880310644129, f1 = 0.9628127112914132\n",
      "Epoch 18: Train Loss = 0.14332490432941192, Recall = 0.951067615658363, Aging Rate = 0.4875444839857651, Precision = 0.9753649635036497, f1 = 0.963063063063063\n",
      "Epoch 19: Train Loss = 0.14114373901136404, Recall = 0.9532918149466192, Aging Rate = 0.48687722419928825, Precision = 0.9789858382823207, f1 = 0.9659679963939598\n",
      "Epoch 20: Train Loss = 0.13817107751700378, Recall = 0.9572953736654805, Aging Rate = 0.4888790035587189, Precision = 0.9790718835304822, f1 = 0.9680611785874944\n",
      "Test Loss = 0.13326050113104415, Recall = 0.952846975088968, Aging Rate = 0.48398576512455516, precision = 0.984375\n",
      "Model in epoch 20 is saved.\n",
      "\n",
      "Epoch 21: Train Loss = 0.13643652940454007, Recall = 0.9586298932384342, Aging Rate = 0.4891014234875445, Precision = 0.9799909049567985, f1 = 0.969192714189341\n",
      "Epoch 22: Train Loss = 0.13548859614494432, Recall = 0.9599644128113879, Aging Rate = 0.4902135231316726, Precision = 0.9791288566243194, f1 = 0.9694519317160826\n",
      "Epoch 23: Train Loss = 0.13282962782421145, Recall = 0.9617437722419929, Aging Rate = 0.4902135231316726, Precision = 0.9809437386569873, f1 = 0.9712488769092542\n",
      "Epoch 24: Train Loss = 0.13192707188825167, Recall = 0.9621886120996441, Aging Rate = 0.489991103202847, Precision = 0.9818429414434862, f1 = 0.9719164232756684\n",
      "Epoch 25: Train Loss = 0.13133999243961958, Recall = 0.9635231316725978, Aging Rate = 0.49110320284697506, Precision = 0.9809782608695652, f1 = 0.9721723518850988\n",
      "Test Loss = 0.12919694985995514, Recall = 0.9617437722419929, Aging Rate = 0.48554270462633453, precision = 0.9903802107191938\n",
      "Model in epoch 25 is saved.\n",
      "\n",
      "Epoch 26: Train Loss = 0.1316547987458969, Recall = 0.9639679715302492, Aging Rate = 0.4913256227758007, Precision = 0.980986871887732, f1 = 0.9724029616333857\n",
      "Epoch 27: Train Loss = 0.1290048723808387, Recall = 0.9648576512455516, Aging Rate = 0.4915480427046263, Precision = 0.9814479638009049, f1 = 0.9730820995962314\n",
      "Epoch 28: Train Loss = 0.1267151823565629, Recall = 0.9639679715302492, Aging Rate = 0.4904359430604982, Precision = 0.982766439909297, f1 = 0.9732764428475186\n",
      "Epoch 29: Train Loss = 0.12885288480549945, Recall = 0.9639679715302492, Aging Rate = 0.49088078291814946, Precision = 0.9818758495695514, f1 = 0.9728395061728395\n",
      "Epoch 30: Train Loss = 0.1256137525536836, Recall = 0.9679715302491103, Aging Rate = 0.4928825622775801, Precision = 0.9819494584837545, f1 = 0.974910394265233\n",
      "Test Loss = 0.12266951560762004, Recall = 0.9653024911032029, Aging Rate = 0.48798932384341637, precision = 0.9890610756608933\n",
      "Model in epoch 30 is saved.\n",
      "\n",
      "Epoch 31: Train Loss = 0.12473165967710502, Recall = 0.9670818505338078, Aging Rate = 0.491770462633452, Precision = 0.9832654907281773, f1 = 0.9751065261269343\n",
      "Epoch 32: Train Loss = 0.12388478261932359, Recall = 0.9701957295373665, Aging Rate = 0.4931049822064057, Precision = 0.9837618403247632, f1 = 0.9769316909294512\n",
      "Epoch 33: Train Loss = 0.12500375572896938, Recall = 0.9661921708185054, Aging Rate = 0.49110320284697506, Precision = 0.9836956521739131, f1 = 0.9748653500897666\n",
      "Epoch 34: Train Loss = 0.12393061270493205, Recall = 0.9653024911032029, Aging Rate = 0.49088078291814946, Precision = 0.983235160851835, f1 = 0.9741863075196409\n",
      "Epoch 35: Train Loss = 0.12380631283933158, Recall = 0.9679715302491103, Aging Rate = 0.4928825622775801, Precision = 0.9819494584837545, f1 = 0.974910394265233\n",
      "Test Loss = 0.11987108787607892, Recall = 0.9737544483985765, Aging Rate = 0.4959964412811388, precision = 0.9816143497757848\n",
      "\n",
      "Epoch 36: Train Loss = 0.12331552583445858, Recall = 0.9661921708185054, Aging Rate = 0.49088078291814946, Precision = 0.9841413683733575, f1 = 0.9750841750841752\n",
      "Epoch 37: Train Loss = 0.12292864457356124, Recall = 0.969306049822064, Aging Rate = 0.4933274021352313, Precision = 0.9824165915238954, f1 = 0.9758172861621137\n",
      "Epoch 38: Train Loss = 0.12265211783906318, Recall = 0.9710854092526691, Aging Rate = 0.4931049822064057, Precision = 0.9846639603067208, f1 = 0.9778275475923853\n",
      "Epoch 39: Train Loss = 0.12138028835274571, Recall = 0.9701957295373665, Aging Rate = 0.49354982206405695, Precision = 0.9828751689950428, f1 = 0.9764942914707858\n",
      "Epoch 40: Train Loss = 0.1211585129389135, Recall = 0.9710854092526691, Aging Rate = 0.4919928825622776, Precision = 0.9868896925858951, f1 = 0.9789237668161436\n",
      "Test Loss = 0.11863776749775504, Recall = 0.9670818505338078, Aging Rate = 0.48798932384341637, precision = 0.9908842297174111\n",
      "Model in epoch 40 is saved.\n",
      "\n",
      "Epoch 41: Train Loss = 0.12112227010663294, Recall = 0.9701957295373665, Aging Rate = 0.49354982206405695, Precision = 0.9828751689950428, f1 = 0.9764942914707858\n",
      "Epoch 42: Train Loss = 0.12146163673481483, Recall = 0.9701957295373665, Aging Rate = 0.4942170818505338, Precision = 0.9815481548154815, f1 = 0.9758389261744965\n",
      "Epoch 43: Train Loss = 0.12105746137714046, Recall = 0.9724199288256228, Aging Rate = 0.4922153024911032, Precision = 0.9877993673746046, f1 = 0.9800493162967945\n",
      "Epoch 44: Train Loss = 0.12105073443086971, Recall = 0.9684163701067615, Aging Rate = 0.491770462633452, Precision = 0.984622342831298, f1 = 0.9764521193092621\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45: Train Loss = 0.12233763143049016, Recall = 0.9684163701067615, Aging Rate = 0.491770462633452, Precision = 0.984622342831298, f1 = 0.9764521193092621\n",
      "Test Loss = 0.11597255985931994, Recall = 0.9737544483985765, Aging Rate = 0.49354982206405695, precision = 0.9864803965750338\n",
      "\n",
      "Epoch 46: Train Loss = 0.11975818029289992, Recall = 0.9697508896797153, Aging Rate = 0.49266014234875444, Precision = 0.9841986455981941, f1 = 0.9769213533497648\n",
      "Epoch 47: Train Loss = 0.11981728134736472, Recall = 0.9697508896797153, Aging Rate = 0.4922153024911032, Precision = 0.9850881156800723, f1 = 0.9773593364716432\n",
      "Epoch 48: Train Loss = 0.11900516652445776, Recall = 0.9719750889679716, Aging Rate = 0.4931049822064057, Precision = 0.9855660802886784, f1 = 0.9787234042553191\n",
      "Epoch 49: Train Loss = 0.1191528056386951, Recall = 0.9710854092526691, Aging Rate = 0.4919928825622776, Precision = 0.9868896925858951, f1 = 0.9789237668161436\n",
      "Epoch 50: Train Loss = 0.11872891389708502, Recall = 0.972864768683274, Aging Rate = 0.49266014234875444, Precision = 0.9873589164785553, f1 = 0.9800582567779521\n",
      "Test Loss = 0.11661842290404853, Recall = 0.9657473309608541, Aging Rate = 0.48798932384341637, precision = 0.9895168641750228\n",
      "\n",
      "Epoch 51: Train Loss = 0.11959012560678971, Recall = 0.9706405693950177, Aging Rate = 0.4913256227758007, Precision = 0.9877772747849706, f1 = 0.9791339466008525\n",
      "Epoch 52: Train Loss = 0.11970969488400157, Recall = 0.9701957295373665, Aging Rate = 0.49243772241992884, Precision = 0.9850948509485095, f1 = 0.9775885253249664\n",
      "Epoch 53: Train Loss = 0.11949488976672026, Recall = 0.9688612099644128, Aging Rate = 0.4915480427046263, Precision = 0.9855203619909503, f1 = 0.9771197846567968\n",
      "Epoch 54: Train Loss = 0.11868536949581947, Recall = 0.9661921708185054, Aging Rate = 0.48954626334519574, Precision = 0.9868241708314403, f1 = 0.9763991908294\n",
      "Epoch 55: Train Loss = 0.11947764591496186, Recall = 0.969306049822064, Aging Rate = 0.4922153024911032, Precision = 0.9846362403976503, f1 = 0.9769110065007846\n",
      "Test Loss = 0.1164854704485245, Recall = 0.9666370106761566, Aging Rate = 0.4884341637010676, precision = 0.9895264116575592\n",
      "\n",
      "Epoch 56: Train Loss = 0.11893806622439856, Recall = 0.9706405693950177, Aging Rate = 0.4922153024911032, Precision = 0.9859918662449164, f1 = 0.9782559964133601\n",
      "Epoch 57: Train Loss = 0.11925061630396656, Recall = 0.9719750889679716, Aging Rate = 0.49243772241992884, Precision = 0.9869015356820234, f1 = 0.9793814432989691\n",
      "Epoch 58: Train Loss = 0.1186434192006274, Recall = 0.9688612099644128, Aging Rate = 0.4913256227758007, Precision = 0.9859665006790402, f1 = 0.9773390172761948\n",
      "Epoch 59: Train Loss = 0.11847417223602003, Recall = 0.9710854092526691, Aging Rate = 0.4922153024911032, Precision = 0.9864437415273385, f1 = 0.9787043263842188\n",
      "Epoch 60: Train Loss = 0.1177729023786202, Recall = 0.9697508896797153, Aging Rate = 0.49110320284697506, Precision = 0.9873188405797102, f1 = 0.9784560143626572\n",
      "Test Loss = 0.11571088937041599, Recall = 0.974644128113879, Aging Rate = 0.49488434163701067, precision = 0.9847191011235955\n",
      "\n",
      "Epoch 61: Train Loss = 0.11891969831600732, Recall = 0.9715302491103203, Aging Rate = 0.4922153024911032, Precision = 0.9868956168097605, f1 = 0.9791526563550773\n",
      "Epoch 62: Train Loss = 0.11843252357002679, Recall = 0.9719750889679716, Aging Rate = 0.49266014234875444, Precision = 0.9864559819413092, f1 = 0.9791619986556129\n",
      "Epoch 63: Train Loss = 0.11838794839021574, Recall = 0.9670818505338078, Aging Rate = 0.4915480427046263, Precision = 0.983710407239819, f1 = 0.9753252579632122\n",
      "Epoch 64: Train Loss = 0.1179287771419274, Recall = 0.972864768683274, Aging Rate = 0.4933274021352313, Precision = 0.9860234445446348, f1 = 0.9793999104343932\n",
      "Epoch 65: Train Loss = 0.11742037744178467, Recall = 0.972864768683274, Aging Rate = 0.4939946619217082, Precision = 0.984691580369203, f1 = 0.9787424479749385\n",
      "Test Loss = 0.11399985022604253, Recall = 0.9733096085409253, Aging Rate = 0.49266014234875444, precision = 0.9878103837471783\n",
      "Model in epoch 65 is saved.\n",
      "\n",
      "Epoch 66: Train Loss = 0.11702553917292598, Recall = 0.9719750889679716, Aging Rate = 0.49243772241992884, Precision = 0.9869015356820234, f1 = 0.9793814432989691\n",
      "Epoch 67: Train Loss = 0.11842079603799298, Recall = 0.9697508896797153, Aging Rate = 0.49266014234875444, Precision = 0.9841986455981941, f1 = 0.9769213533497648\n",
      "Epoch 68: Train Loss = 0.11814381617031912, Recall = 0.9715302491103203, Aging Rate = 0.4933274021352313, Precision = 0.9846708746618575, f1 = 0.9780564263322883\n",
      "Epoch 69: Train Loss = 0.1172759728605637, Recall = 0.9688612099644128, Aging Rate = 0.491770462633452, Precision = 0.9850746268656716, f1 = 0.9769006503700381\n",
      "Epoch 70: Train Loss = 0.11756695271386795, Recall = 0.9719750889679716, Aging Rate = 0.4931049822064057, Precision = 0.9855660802886784, f1 = 0.9787234042553191\n",
      "Test Loss = 0.11380424406180602, Recall = 0.9675266903914591, Aging Rate = 0.4884341637010676, precision = 0.9904371584699454\n",
      "\n",
      "Epoch 71: Train Loss = 0.11746948193825013, Recall = 0.9701957295373665, Aging Rate = 0.4915480427046263, Precision = 0.9868778280542987, f1 = 0.9784656796769853\n",
      "Epoch 72: Train Loss = 0.11763664300543558, Recall = 0.9733096085409253, Aging Rate = 0.4944395017793594, Precision = 0.9842555105713, f1 = 0.9787519570565869\n",
      "Epoch 73: Train Loss = 0.11724838216745981, Recall = 0.9688612099644128, Aging Rate = 0.4904359430604982, Precision = 0.9877551020408163, f1 = 0.9782169324051201\n",
      "Epoch 74: Train Loss = 0.11656119841485685, Recall = 0.9706405693950177, Aging Rate = 0.49243772241992884, Precision = 0.985546522131888, f1 = 0.978036754818467\n",
      "Epoch 75: Train Loss = 0.11753730284998001, Recall = 0.9701957295373665, Aging Rate = 0.4915480427046263, Precision = 0.9868778280542987, f1 = 0.9784656796769853\n",
      "Test Loss = 0.11377390293782291, Recall = 0.9737544483985765, Aging Rate = 0.4931049822064057, precision = 0.9873703202525936\n",
      "\n",
      "Epoch 76: Train Loss = 0.11610673696757211, Recall = 0.9706405693950177, Aging Rate = 0.49088078291814946, Precision = 0.9886724059809696, f1 = 0.9795735129068462\n",
      "Epoch 77: Train Loss = 0.11705519325262287, Recall = 0.9701957295373665, Aging Rate = 0.4919928825622776, Precision = 0.9859855334538878, f1 = 0.9780269058295963\n",
      "Epoch 78: Train Loss = 0.11763595787019492, Recall = 0.9706405693950177, Aging Rate = 0.4922153024911032, Precision = 0.9859918662449164, f1 = 0.9782559964133601\n",
      "Epoch 79: Train Loss = 0.11738677131959976, Recall = 0.969306049822064, Aging Rate = 0.4915480427046263, Precision = 0.9859728506787331, f1 = 0.9775684163301929\n",
      "Epoch 80: Train Loss = 0.11803763927195844, Recall = 0.9688612099644128, Aging Rate = 0.491770462633452, Precision = 0.9850746268656716, f1 = 0.9769006503700381\n",
      "Test Loss = 0.1160863325848274, Recall = 0.9750889679715302, Aging Rate = 0.498220640569395, precision = 0.9785714285714285\n",
      "\n",
      "Epoch 81: Train Loss = 0.11688869003723525, Recall = 0.9724199288256228, Aging Rate = 0.49354982206405695, Precision = 0.9851284362325372, f1 = 0.97873293037833\n",
      "Epoch 82: Train Loss = 0.11716678149971674, Recall = 0.9715302491103203, Aging Rate = 0.4922153024911032, Precision = 0.9868956168097605, f1 = 0.9791526563550773\n",
      "Epoch 83: Train Loss = 0.1164867398842798, Recall = 0.9724199288256228, Aging Rate = 0.4928825622775801, Precision = 0.9864620938628159, f1 = 0.9793906810035843\n",
      "Epoch 84: Train Loss = 0.11664103088217698, Recall = 0.9684163701067615, Aging Rate = 0.4904359430604982, Precision = 0.9873015873015873, f1 = 0.9777677969907926\n",
      "Epoch 85: Train Loss = 0.11710449199447429, Recall = 0.9697508896797153, Aging Rate = 0.4915480427046263, Precision = 0.9864253393665159, f1 = 0.9780170480035891\n",
      "Test Loss = 0.1135687071869806, Recall = 0.972864768683274, Aging Rate = 0.49088078291814946, precision = 0.9909379247847757\n",
      "Model in epoch 85 is saved.\n",
      "\n",
      "Epoch 86: Train Loss = 0.1183210987849592, Recall = 0.9697508896797153, Aging Rate = 0.4915480427046263, Precision = 0.9864253393665159, f1 = 0.9780170480035891\n",
      "Epoch 87: Train Loss = 0.1165463900014599, Recall = 0.972864768683274, Aging Rate = 0.49266014234875444, Precision = 0.9873589164785553, f1 = 0.9800582567779521\n",
      "Epoch 88: Train Loss = 0.11686248440971578, Recall = 0.9688612099644128, Aging Rate = 0.4904359430604982, Precision = 0.9877551020408163, f1 = 0.9782169324051201\n",
      "Epoch 89: Train Loss = 0.11621863646863619, Recall = 0.9741992882562278, Aging Rate = 0.4933274021352313, Precision = 0.9873760144274121, f1 = 0.9807433945364982\n",
      "Epoch 90: Train Loss = 0.11490514397196923, Recall = 0.9737544483985765, Aging Rate = 0.49354982206405695, Precision = 0.9864803965750338, f1 = 0.9800761137228565\n",
      "Test Loss = 0.11244723373142426, Recall = 0.9733096085409253, Aging Rate = 0.4922153024911032, precision = 0.9887031179394488\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 91: Train Loss = 0.11690000099961868, Recall = 0.9697508896797153, Aging Rate = 0.491770462633452, Precision = 0.9859791949344188, f1 = 0.97779771249159\n",
      "Epoch 92: Train Loss = 0.1157854751972117, Recall = 0.9719750889679716, Aging Rate = 0.49266014234875444, Precision = 0.9864559819413092, f1 = 0.9791619986556129\n",
      "Epoch 93: Train Loss = 0.1167668358446016, Recall = 0.9710854092526691, Aging Rate = 0.491770462633452, Precision = 0.9873360470375395, f1 = 0.9791433056739178\n",
      "Epoch 94: Train Loss = 0.11607914762670883, Recall = 0.9733096085409253, Aging Rate = 0.4928825622775801, Precision = 0.9873646209386282, f1 = 0.9802867383512545\n",
      "Epoch 95: Train Loss = 0.11601766684089267, Recall = 0.9724199288256228, Aging Rate = 0.4933274021352313, Precision = 0.9855725879170424, f1 = 0.9789520824003582\n",
      "Test Loss = 0.11249669755268776, Recall = 0.972864768683274, Aging Rate = 0.49110320284697506, precision = 0.9904891304347826\n",
      "\n",
      "Epoch 96: Train Loss = 0.11582772216338703, Recall = 0.9719750889679716, Aging Rate = 0.49266014234875444, Precision = 0.9864559819413092, f1 = 0.9791619986556129\n",
      "Epoch 97: Train Loss = 0.11721682243605949, Recall = 0.9719750889679716, Aging Rate = 0.4931049822064057, Precision = 0.9855660802886784, f1 = 0.9787234042553191\n",
      "Epoch 98: Train Loss = 0.11637687242964409, Recall = 0.9701957295373665, Aging Rate = 0.4902135231316726, Precision = 0.9895644283121597, f1 = 0.9797843665768194\n",
      "Epoch 99: Train Loss = 0.1152699715408142, Recall = 0.972864768683274, Aging Rate = 0.49243772241992884, Precision = 0.9878048780487805, f1 = 0.9802779022859704\n",
      "Epoch 100: Train Loss = 0.1161110645087164, Recall = 0.9724199288256228, Aging Rate = 0.4919928825622776, Precision = 0.9882459312839059, f1 = 0.9802690582959642\n",
      "Test Loss = 0.11225116404031944, Recall = 0.9737544483985765, Aging Rate = 0.4931049822064057, precision = 0.9873703202525936\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "823040c8a8784acb911af0b7f8ae96bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss = 0.6224953061321028, Recall = 0.6748220640569395, Aging Rate = 0.4717526690391459, Precision = 0.7152286657237152, f1 = 0.6944380865186542\n",
      "Epoch 2: Train Loss = 0.46466843693706067, Recall = 0.7967081850533808, Aging Rate = 0.4822064056939502, Precision = 0.8261070110701108, f1 = 0.811141304347826\n",
      "Epoch 3: Train Loss = 0.35021314077954274, Recall = 0.8741103202846975, Aging Rate = 0.501779359430605, Precision = 0.8710106382978723, f1 = 0.872557726465364\n",
      "Epoch 4: Train Loss = 0.29559442125181284, Recall = 0.9083629893238434, Aging Rate = 0.5102313167259787, Precision = 0.8901482127288579, f1 = 0.8991633641567591\n",
      "Epoch 5: Train Loss = 0.26055322189772256, Recall = 0.916814946619217, Aging Rate = 0.5013345195729537, Precision = 0.9143744454303461, f1 = 0.9155930697467791\n",
      "Test Loss = 0.23896352538434637, Recall = 0.9314946619217082, Aging Rate = 0.5111209964412812, precision = 0.9112271540469974\n",
      "Model in epoch 5 is saved.\n",
      "\n",
      "Epoch 6: Train Loss = 0.23143253048543827, Recall = 0.9301601423487544, Aging Rate = 0.5011120996441281, Precision = 0.9280958721704394, f1 = 0.9291268606976227\n",
      "Epoch 7: Train Loss = 0.21494915243569643, Recall = 0.9368327402135231, Aging Rate = 0.49666370106761565, Precision = 0.9431258396775638, f1 = 0.9399687569738897\n",
      "Epoch 8: Train Loss = 0.19988764652790125, Recall = 0.9408362989323843, Aging Rate = 0.49377224199288255, Precision = 0.9527027027027027, f1 = 0.9467323187108325\n",
      "Epoch 9: Train Loss = 0.18755107741551044, Recall = 0.9408362989323843, Aging Rate = 0.4902135231316726, Precision = 0.9596188747731398, f1 = 0.9501347708894878\n",
      "Epoch 10: Train Loss = 0.1780669479183455, Recall = 0.9403914590747331, Aging Rate = 0.48798932384341637, Precision = 0.9635369188696444, f1 = 0.9518235029266096\n",
      "Test Loss = 0.1703748022640303, Recall = 0.9417259786476868, Aging Rate = 0.4835409252669039, precision = 0.9737810487580497\n",
      "Model in epoch 10 is saved.\n",
      "\n",
      "Epoch 11: Train Loss = 0.17100309477157866, Recall = 0.9417259786476868, Aging Rate = 0.48687722419928825, Precision = 0.9671082686158063, f1 = 0.954248366013072\n",
      "Epoch 12: Train Loss = 0.16399465252071938, Recall = 0.9457295373665481, Aging Rate = 0.4891014234875445, Precision = 0.9668030923146885, f1 = 0.9561502136271645\n",
      "Epoch 13: Train Loss = 0.15726652958851267, Recall = 0.9483985765124555, Aging Rate = 0.48798932384341637, Precision = 0.9717411121239745, f1 = 0.9599279603782082\n",
      "Epoch 14: Train Loss = 0.152200178823225, Recall = 0.9501779359430605, Aging Rate = 0.4886565836298932, Precision = 0.9722348657259899, f1 = 0.9610798650168728\n",
      "Epoch 15: Train Loss = 0.14790354239558834, Recall = 0.9541814946619217, Aging Rate = 0.489991103202847, Precision = 0.9736722650930549, f1 = 0.9638283531790609\n",
      "Test Loss = 0.14376635112372158, Recall = 0.9452846975088968, Aging Rate = 0.4833185053380783, precision = 0.9779107225034515\n",
      "Model in epoch 15 is saved.\n",
      "\n",
      "Epoch 16: Train Loss = 0.14544333909966342, Recall = 0.9532918149466192, Aging Rate = 0.48954626334519574, Precision = 0.9736483416628805, f1 = 0.9633625533827826\n",
      "Epoch 17: Train Loss = 0.14143196957391352, Recall = 0.9541814946619217, Aging Rate = 0.48798932384341637, Precision = 0.9776663628076573, f1 = 0.9657811796488068\n",
      "Epoch 18: Train Loss = 0.13921351741429325, Recall = 0.958185053380783, Aging Rate = 0.49065836298932386, Precision = 0.9764279238440616, f1 = 0.9672204759766503\n",
      "Epoch 19: Train Loss = 0.13654765815497294, Recall = 0.9568505338078291, Aging Rate = 0.4886565836298932, Precision = 0.9790623577605826, f1 = 0.9678290213723285\n",
      "Epoch 20: Train Loss = 0.13694627180006155, Recall = 0.9568505338078291, Aging Rate = 0.4884341637010676, Precision = 0.9795081967213115, f1 = 0.9680468046804681\n",
      "Test Loss = 0.133440604493075, Recall = 0.9670818505338078, Aging Rate = 0.4997775800711744, precision = 0.9675122385402759\n",
      "Model in epoch 20 is saved.\n",
      "\n",
      "Epoch 21: Train Loss = 0.13351508927302852, Recall = 0.9599644128113879, Aging Rate = 0.49110320284697506, Precision = 0.9773550724637681, f1 = 0.9685816876122082\n",
      "Epoch 22: Train Loss = 0.13066046263399497, Recall = 0.9599644128113879, Aging Rate = 0.48954626334519574, Precision = 0.9804634257155839, f1 = 0.9701056417172399\n",
      "Epoch 23: Train Loss = 0.1302183059398814, Recall = 0.9599644128113879, Aging Rate = 0.489991103202847, Precision = 0.9795733091239219, f1 = 0.9696697371377219\n",
      "Epoch 24: Train Loss = 0.12879926867756555, Recall = 0.9612989323843416, Aging Rate = 0.4891014234875445, Precision = 0.9827194179172352, f1 = 0.9718911625815156\n",
      "Epoch 25: Train Loss = 0.12870857522580972, Recall = 0.9604092526690391, Aging Rate = 0.4891014234875445, Precision = 0.9818099135970896, f1 = 0.9709916797841242\n",
      "Test Loss = 0.1230002252444678, Recall = 0.9599644128113879, Aging Rate = 0.486432384341637, precision = 0.9867398262459991\n",
      "Model in epoch 25 is saved.\n",
      "\n",
      "Epoch 26: Train Loss = 0.12638079711763037, Recall = 0.9608540925266904, Aging Rate = 0.48976868327402134, Precision = 0.9809264305177112, f1 = 0.9707865168539327\n",
      "Epoch 27: Train Loss = 0.12601005140148447, Recall = 0.9666370106761566, Aging Rate = 0.4922153024911032, Precision = 0.981924988703118, f1 = 0.9742210266756333\n",
      "Epoch 28: Train Loss = 0.12784924530473893, Recall = 0.9608540925266904, Aging Rate = 0.4904359430604982, Precision = 0.9795918367346939, f1 = 0.9701324949472266\n",
      "Epoch 29: Train Loss = 0.12432933601408243, Recall = 0.9635231316725978, Aging Rate = 0.4904359430604982, Precision = 0.9823129251700681, f1 = 0.9728273074331911\n",
      "Epoch 30: Train Loss = 0.12350596010260735, Recall = 0.9617437722419929, Aging Rate = 0.4888790035587189, Precision = 0.9836214740673339, f1 = 0.9725596041385515\n",
      "Test Loss = 0.12162784529432283, Recall = 0.9586298932384342, Aging Rate = 0.4844306049822064, precision = 0.9894398530762167\n",
      "Model in epoch 30 is saved.\n",
      "\n",
      "Epoch 31: Train Loss = 0.12377116232580138, Recall = 0.9635231316725978, Aging Rate = 0.4904359430604982, Precision = 0.9823129251700681, f1 = 0.9728273074331911\n",
      "Epoch 32: Train Loss = 0.12290979895303258, Recall = 0.9626334519572953, Aging Rate = 0.48954626334519574, Precision = 0.9831894593366651, f1 = 0.9728028770510228\n",
      "Epoch 33: Train Loss = 0.12412255058509175, Recall = 0.9626334519572953, Aging Rate = 0.48976868327402134, Precision = 0.9827429609445958, f1 = 0.9725842696629213\n",
      "Epoch 34: Train Loss = 0.12255897980143592, Recall = 0.9657473309608541, Aging Rate = 0.4915480427046263, Precision = 0.9823529411764705, f1 = 0.9739793629430238\n",
      "Epoch 35: Train Loss = 0.1224652321684403, Recall = 0.9661921708185054, Aging Rate = 0.49088078291814946, Precision = 0.9841413683733575, f1 = 0.9750841750841752\n",
      "Test Loss = 0.11844792068534898, Recall = 0.9626334519572953, Aging Rate = 0.4884341637010676, precision = 0.9854280510018215\n",
      "\n",
      "Epoch 36: Train Loss = 0.12231156039068283, Recall = 0.9621886120996441, Aging Rate = 0.4893238434163701, Precision = 0.9831818181818182, f1 = 0.9725719424460432\n",
      "Epoch 37: Train Loss = 0.12170545825754621, Recall = 0.9621886120996441, Aging Rate = 0.48798932384341637, Precision = 0.9858705560619873, f1 = 0.9738856371004051\n",
      "Epoch 38: Train Loss = 0.12112488820353437, Recall = 0.9657473309608541, Aging Rate = 0.4904359430604982, Precision = 0.9845804988662131, f1 = 0.9750729845048282\n",
      "Epoch 39: Train Loss = 0.1220875932334581, Recall = 0.9648576512455516, Aging Rate = 0.49065836298932386, Precision = 0.9832275611967362, f1 = 0.9739559946115851\n",
      "Epoch 40: Train Loss = 0.12135205940207552, Recall = 0.9617437722419929, Aging Rate = 0.4886565836298932, Precision = 0.9840691852526172, f1 = 0.9727784026996625\n",
      "Test Loss = 0.11920704045647829, Recall = 0.9715302491103203, Aging Rate = 0.4957740213523132, precision = 0.9798115746971736\n",
      "\n",
      "Epoch 41: Train Loss = 0.12131247841802781, Recall = 0.9657473309608541, Aging Rate = 0.49088078291814946, Precision = 0.9836882646125963, f1 = 0.974635241301908\n",
      "Epoch 42: Train Loss = 0.1215840205815339, Recall = 0.9644128113879004, Aging Rate = 0.49065836298932386, Precision = 0.9827742520398912, f1 = 0.9735069600359229\n",
      "Epoch 43: Train Loss = 0.12118526534889941, Recall = 0.9648576512455516, Aging Rate = 0.49065836298932386, Precision = 0.9832275611967362, f1 = 0.9739559946115851\n",
      "Epoch 44: Train Loss = 0.12062003874481785, Recall = 0.9666370106761566, Aging Rate = 0.4904359430604982, Precision = 0.9854875283446712, f1 = 0.975971255333483\n",
      "Epoch 45: Train Loss = 0.1207260397723561, Recall = 0.9644128113879004, Aging Rate = 0.4915480427046263, Precision = 0.9809954751131221, f1 = 0.9726334679228353\n",
      "Test Loss = 0.11886801668757646, Recall = 0.9595195729537367, Aging Rate = 0.48487544483985767, precision = 0.9894495412844037\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model in epoch 45 is saved.\n",
      "\n",
      "Epoch 46: Train Loss = 0.1206400524891144, Recall = 0.9657473309608541, Aging Rate = 0.4902135231316726, Precision = 0.98502722323049, f1 = 0.9752920035938905\n",
      "Epoch 47: Train Loss = 0.11976207495796298, Recall = 0.9675266903914591, Aging Rate = 0.49065836298932386, Precision = 0.985947416137806, f1 = 0.9766502020655591\n",
      "Epoch 48: Train Loss = 0.11954626313732188, Recall = 0.9657473309608541, Aging Rate = 0.49065836298932386, Precision = 0.9841341795104261, f1 = 0.9748540637629097\n",
      "Epoch 49: Train Loss = 0.11988289770918809, Recall = 0.9675266903914591, Aging Rate = 0.49266014234875444, Precision = 0.981941309255079, f1 = 0.9746807080439166\n",
      "Epoch 50: Train Loss = 0.11904756242270147, Recall = 0.9621886120996441, Aging Rate = 0.48798932384341637, Precision = 0.9858705560619873, f1 = 0.9738856371004051\n",
      "Test Loss = 0.11578413260789104, Recall = 0.9644128113879004, Aging Rate = 0.4884341637010676, precision = 0.9872495446265938\n",
      "Model in epoch 50 is saved.\n",
      "\n",
      "Epoch 51: Train Loss = 0.11881866430684765, Recall = 0.9657473309608541, Aging Rate = 0.4904359430604982, Precision = 0.9845804988662131, f1 = 0.9750729845048282\n",
      "Epoch 52: Train Loss = 0.1195483377925866, Recall = 0.9657473309608541, Aging Rate = 0.49088078291814946, Precision = 0.9836882646125963, f1 = 0.974635241301908\n",
      "Epoch 53: Train Loss = 0.11921221754941227, Recall = 0.9661921708185054, Aging Rate = 0.489991103202847, Precision = 0.9859282796187018, f1 = 0.9759604583239722\n",
      "Epoch 54: Train Loss = 0.12018791763807955, Recall = 0.9653024911032029, Aging Rate = 0.4902135231316726, Precision = 0.984573502722323, f1 = 0.9748427672955974\n",
      "Epoch 55: Train Loss = 0.11880103660435863, Recall = 0.9653024911032029, Aging Rate = 0.48954626334519574, Precision = 0.9859154929577465, f1 = 0.9755001123848056\n",
      "Test Loss = 0.11785825249139101, Recall = 0.9741992882562278, Aging Rate = 0.4971085409252669, precision = 0.9798657718120806\n",
      "\n",
      "Epoch 56: Train Loss = 0.1195973891804651, Recall = 0.9661921708185054, Aging Rate = 0.4919928825622776, Precision = 0.9819168173598554, f1 = 0.9739910313901345\n",
      "Epoch 57: Train Loss = 0.12023882451218643, Recall = 0.9657473309608541, Aging Rate = 0.4904359430604982, Precision = 0.9845804988662131, f1 = 0.9750729845048282\n",
      "Epoch 58: Train Loss = 0.11948111594995994, Recall = 0.9648576512455516, Aging Rate = 0.4902135231316726, Precision = 0.9841197822141561, f1 = 0.9743935309973046\n",
      "Epoch 59: Train Loss = 0.11868213085305224, Recall = 0.9701957295373665, Aging Rate = 0.49266014234875444, Precision = 0.9846501128668171, f1 = 0.9773694824109344\n",
      "Epoch 60: Train Loss = 0.11898943246259384, Recall = 0.9644128113879004, Aging Rate = 0.4904359430604982, Precision = 0.9832199546485261, f1 = 0.973725578261846\n",
      "Test Loss = 0.11481430487594571, Recall = 0.9635231316725978, Aging Rate = 0.4886565836298932, precision = 0.9858898497951752\n",
      "\n",
      "Epoch 61: Train Loss = 0.1195653724182543, Recall = 0.9657473309608541, Aging Rate = 0.4915480427046263, Precision = 0.9823529411764705, f1 = 0.9739793629430238\n",
      "Epoch 62: Train Loss = 0.11921474321669107, Recall = 0.9648576512455516, Aging Rate = 0.4886565836298932, Precision = 0.9872553482020938, f1 = 0.9759280089988751\n",
      "Epoch 63: Train Loss = 0.11757994981422967, Recall = 0.9679715302491103, Aging Rate = 0.491770462633452, Precision = 0.9841700587969244, f1 = 0.9760035882484862\n",
      "Epoch 64: Train Loss = 0.11775935308682961, Recall = 0.9666370106761566, Aging Rate = 0.491770462633452, Precision = 0.9828132066938037, f1 = 0.9746579950661582\n",
      "Epoch 65: Train Loss = 0.11729000789839178, Recall = 0.9630782918149466, Aging Rate = 0.4891014234875445, Precision = 0.9845384265575261, f1 = 0.9736901281762986\n",
      "Test Loss = 0.11415733121255962, Recall = 0.9741992882562278, Aging Rate = 0.49354982206405695, precision = 0.9869310500225327\n",
      "Model in epoch 65 is saved.\n",
      "\n",
      "Epoch 66: Train Loss = 0.11778221191884784, Recall = 0.9657473309608541, Aging Rate = 0.49065836298932386, Precision = 0.9841341795104261, f1 = 0.9748540637629097\n",
      "Epoch 67: Train Loss = 0.11824202150424604, Recall = 0.9724199288256228, Aging Rate = 0.49243772241992884, Precision = 0.987353206865402, f1 = 0.9798296727924697\n",
      "Epoch 68: Train Loss = 0.1174048993511132, Recall = 0.9653024911032029, Aging Rate = 0.48954626334519574, Precision = 0.9859154929577465, f1 = 0.9755001123848056\n",
      "Epoch 69: Train Loss = 0.11814376271704338, Recall = 0.9653024911032029, Aging Rate = 0.49088078291814946, Precision = 0.983235160851835, f1 = 0.9741863075196409\n",
      "Epoch 70: Train Loss = 0.11822966345688626, Recall = 0.9657473309608541, Aging Rate = 0.4904359430604982, Precision = 0.9845804988662131, f1 = 0.9750729845048282\n",
      "Test Loss = 0.11425398274248605, Recall = 0.9675266903914591, Aging Rate = 0.4893238434163701, precision = 0.9886363636363636\n",
      "\n",
      "Epoch 71: Train Loss = 0.11751074723077415, Recall = 0.969306049822064, Aging Rate = 0.49243772241992884, Precision = 0.9841915085817525, f1 = 0.976692066337965\n",
      "Epoch 72: Train Loss = 0.11728407803167228, Recall = 0.9675266903914591, Aging Rate = 0.489991103202847, Precision = 0.9872900590104403, f1 = 0.97730847000674\n",
      "Epoch 73: Train Loss = 0.11762337169189045, Recall = 0.9657473309608541, Aging Rate = 0.48976868327402134, Precision = 0.9859218891916439, f1 = 0.9757303370786516\n",
      "Epoch 74: Train Loss = 0.11682590174081063, Recall = 0.9648576512455516, Aging Rate = 0.4904359430604982, Precision = 0.9836734693877551, f1 = 0.9741747136761733\n",
      "Epoch 75: Train Loss = 0.11889250793915203, Recall = 0.9639679715302492, Aging Rate = 0.4893238434163701, Precision = 0.985, f1 = 0.9743705035971223\n",
      "Test Loss = 0.11368562270525935, Recall = 0.9639679715302492, Aging Rate = 0.4884341637010676, precision = 0.9867941712204007\n",
      "\n",
      "Epoch 76: Train Loss = 0.11703827547645229, Recall = 0.9648576512455516, Aging Rate = 0.48954626334519574, Precision = 0.9854611540208996, f1 = 0.9750505731625085\n",
      "Epoch 77: Train Loss = 0.11646537519858825, Recall = 0.9661921708185054, Aging Rate = 0.4904359430604982, Precision = 0.9850340136054422, f1 = 0.9755221199191556\n",
      "Epoch 78: Train Loss = 0.1177311227574043, Recall = 0.9684163701067615, Aging Rate = 0.4928825622775801, Precision = 0.9824007220216606, f1 = 0.9753584229390682\n",
      "Epoch 79: Train Loss = 0.1175135866709027, Recall = 0.9657473309608541, Aging Rate = 0.4904359430604982, Precision = 0.9845804988662131, f1 = 0.9750729845048282\n",
      "Epoch 80: Train Loss = 0.117061739184254, Recall = 0.9661921708185054, Aging Rate = 0.489991103202847, Precision = 0.9859282796187018, f1 = 0.9759604583239722\n",
      "Test Loss = 0.11394684345484628, Recall = 0.9670818505338078, Aging Rate = 0.4902135231316726, precision = 0.9863883847549909\n",
      "\n",
      "Epoch 81: Train Loss = 0.11679343107650289, Recall = 0.9648576512455516, Aging Rate = 0.489991103202847, Precision = 0.9845665002269632, f1 = 0.9746124466412042\n",
      "Epoch 82: Train Loss = 0.11706082263026797, Recall = 0.9648576512455516, Aging Rate = 0.4902135231316726, Precision = 0.9841197822141561, f1 = 0.9743935309973046\n",
      "Epoch 83: Train Loss = 0.11743225936787832, Recall = 0.9666370106761566, Aging Rate = 0.4913256227758007, Precision = 0.9837030330466274, f1 = 0.9750953556203724\n",
      "Epoch 84: Train Loss = 0.11855138647386612, Recall = 0.9657473309608541, Aging Rate = 0.4888790035587189, Precision = 0.9877161055505005, f1 = 0.9766081871345029\n",
      "Epoch 85: Train Loss = 0.11593966159532079, Recall = 0.9688612099644128, Aging Rate = 0.491770462633452, Precision = 0.9850746268656716, f1 = 0.9769006503700381\n",
      "Test Loss = 0.1125795628570577, Recall = 0.9706405693950177, Aging Rate = 0.4919928825622776, precision = 0.9864376130198915\n",
      "\n",
      "Epoch 86: Train Loss = 0.11634349732848673, Recall = 0.9679715302491103, Aging Rate = 0.4922153024911032, Precision = 0.9832806145503841, f1 = 0.9755660165882089\n",
      "Epoch 87: Train Loss = 0.11622367009149327, Recall = 0.969306049822064, Aging Rate = 0.49243772241992884, Precision = 0.9841915085817525, f1 = 0.976692066337965\n",
      "Epoch 88: Train Loss = 0.1176835859320342, Recall = 0.9635231316725978, Aging Rate = 0.48954626334519574, Precision = 0.9840981372103589, f1 = 0.973701955495617\n",
      "Epoch 89: Train Loss = 0.11690440853507493, Recall = 0.9679715302491103, Aging Rate = 0.49110320284697506, Precision = 0.9855072463768116, f1 = 0.9766606822262119\n",
      "Epoch 90: Train Loss = 0.11592679643121903, Recall = 0.9670818505338078, Aging Rate = 0.49065836298932386, Precision = 0.985494106980961, f1 = 0.9762011674898967\n",
      "Test Loss = 0.11290660956576201, Recall = 0.9697508896797153, Aging Rate = 0.49110320284697506, precision = 0.9873188405797102\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 91: Train Loss = 0.11601160588637789, Recall = 0.9666370106761566, Aging Rate = 0.4902135231316726, Precision = 0.985934664246824, f1 = 0.9761904761904763\n",
      "Epoch 92: Train Loss = 0.11553778820190566, Recall = 0.9675266903914591, Aging Rate = 0.4902135231316726, Precision = 0.9868421052631579, f1 = 0.977088948787062\n",
      "Epoch 93: Train Loss = 0.11566518684617141, Recall = 0.9666370106761566, Aging Rate = 0.4904359430604982, Precision = 0.9854875283446712, f1 = 0.975971255333483\n",
      "Epoch 94: Train Loss = 0.11644113260019716, Recall = 0.9701957295373665, Aging Rate = 0.49266014234875444, Precision = 0.9846501128668171, f1 = 0.9773694824109344\n",
      "Epoch 95: Train Loss = 0.11621943004827058, Recall = 0.9635231316725978, Aging Rate = 0.4884341637010676, Precision = 0.9863387978142076, f1 = 0.9747974797479748\n",
      "Test Loss = 0.11245032911623076, Recall = 0.9719750889679716, Aging Rate = 0.4928825622775801, precision = 0.9860108303249098\n",
      "\n",
      "Epoch 96: Train Loss = 0.11683730820850122, Recall = 0.9675266903914591, Aging Rate = 0.4915480427046263, Precision = 0.9841628959276018, f1 = 0.9757738896366084\n",
      "Epoch 97: Train Loss = 0.11548060221179948, Recall = 0.9657473309608541, Aging Rate = 0.48976868327402134, Precision = 0.9859218891916439, f1 = 0.9757303370786516\n",
      "Epoch 98: Train Loss = 0.11560747592156467, Recall = 0.969306049822064, Aging Rate = 0.4928825622775801, Precision = 0.9833032490974729, f1 = 0.9762544802867383\n",
      "Epoch 99: Train Loss = 0.1157154558604298, Recall = 0.9684163701067615, Aging Rate = 0.49065836298932386, Precision = 0.9868540344514959, f1 = 0.9775482712168837\n",
      "Epoch 100: Train Loss = 0.11602894532298702, Recall = 0.9639679715302492, Aging Rate = 0.4888790035587189, Precision = 0.9858962693357598, f1 = 0.9748088169140802\n",
      "Test Loss = 0.11323708391274422, Recall = 0.9773131672597865, Aging Rate = 0.49666370106761565, precision = 0.9838781907747425\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cfa0e8cbf8c243caa8ec5e09cdb194b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss = 0.6319477719344279, Recall = 0.5929715302491103, Aging Rate = 0.4181494661921708, Precision = 0.7090425531914893, f1 = 0.6458333333333334\n",
      "Epoch 2: Train Loss = 0.4772962748580132, Recall = 0.7815836298932385, Aging Rate = 0.474644128113879, Precision = 0.823336457357076, f1 = 0.8019169329073482\n",
      "Epoch 3: Train Loss = 0.36626132739396283, Recall = 0.8643238434163701, Aging Rate = 0.5028914590747331, Precision = 0.8593542680229986, f1 = 0.8618318917720115\n",
      "Epoch 4: Train Loss = 0.30834944201533904, Recall = 0.8963523131672598, Aging Rate = 0.5086743772241993, Precision = 0.8810668998688238, f1 = 0.8886438809261301\n",
      "Epoch 5: Train Loss = 0.2757233934894575, Recall = 0.9110320284697508, Aging Rate = 0.5055604982206405, Precision = 0.9010118785745711, f1 = 0.9059942490599425\n",
      "Test Loss = 0.2600765230922937, Recall = 0.9448398576512456, Aging Rate = 0.5382562277580071, precision = 0.8776859504132232\n",
      "Model in epoch 5 is saved.\n",
      "\n",
      "Epoch 6: Train Loss = 0.2483291532645446, Recall = 0.923932384341637, Aging Rate = 0.5057829181494662, Precision = 0.9133685136323659, f1 = 0.9186200796107917\n",
      "Epoch 7: Train Loss = 0.23013904510443745, Recall = 0.9261565836298933, Aging Rate = 0.4973309608540925, Precision = 0.9311270125223614, f1 = 0.928635147190009\n",
      "Epoch 8: Train Loss = 0.2150084998365823, Recall = 0.931049822064057, Aging Rate = 0.4959964412811388, Precision = 0.9385650224215246, f1 = 0.9347923179991068\n",
      "Epoch 9: Train Loss = 0.20142654820056996, Recall = 0.9377224199288257, Aging Rate = 0.4968861209964413, Precision = 0.9435989256938228, f1 = 0.9406514948683624\n",
      "Epoch 10: Train Loss = 0.19324303272568033, Recall = 0.9354982206405694, Aging Rate = 0.489991103202847, Precision = 0.9546073536087154, f1 = 0.9449561896203101\n",
      "Test Loss = 0.1826825093650309, Recall = 0.9457295373665481, Aging Rate = 0.5008896797153025, precision = 0.9440497335701599\n",
      "Model in epoch 10 is saved.\n",
      "\n",
      "Epoch 11: Train Loss = 0.18153241886575028, Recall = 0.9399466192170819, Aging Rate = 0.4922153024911032, Precision = 0.9548124717577948, f1 = 0.9473212284241203\n",
      "Epoch 12: Train Loss = 0.1736872608233177, Recall = 0.9435053380782918, Aging Rate = 0.489991103202847, Precision = 0.9627780299591466, f1 = 0.9530442597169176\n",
      "Epoch 13: Train Loss = 0.16719123689305315, Recall = 0.9417259786476868, Aging Rate = 0.4884341637010676, Precision = 0.9640255009107468, f1 = 0.9527452745274527\n",
      "Epoch 14: Train Loss = 0.16081515065927945, Recall = 0.9470640569395018, Aging Rate = 0.48798932384341637, Precision = 0.9703737465815861, f1 = 0.9585772174696083\n",
      "Epoch 15: Train Loss = 0.15720071264433266, Recall = 0.951067615658363, Aging Rate = 0.4913256227758007, Precision = 0.9678587596197374, f1 = 0.9593897240296162\n",
      "Test Loss = 0.15402235525570732, Recall = 0.9363879003558719, Aging Rate = 0.4766459074733096, precision = 0.9822678488100793\n",
      "Model in epoch 15 is saved.\n",
      "\n",
      "Epoch 16: Train Loss = 0.15264571964528637, Recall = 0.9470640569395018, Aging Rate = 0.4873220640569395, Precision = 0.971702418986764, f1 = 0.9592250506870917\n",
      "Epoch 17: Train Loss = 0.14701561587348952, Recall = 0.9524021352313167, Aging Rate = 0.4884341637010676, Precision = 0.9749544626593807, f1 = 0.9635463546354635\n",
      "Epoch 18: Train Loss = 0.14453395426909693, Recall = 0.9532918149466192, Aging Rate = 0.4888790035587189, Precision = 0.9749772520473158, f1 = 0.9640125955915428\n",
      "Epoch 19: Train Loss = 0.14180328895825084, Recall = 0.9612989323843416, Aging Rate = 0.4939946619217082, Precision = 0.9729851418280054, f1 = 0.9671067352875364\n",
      "Epoch 20: Train Loss = 0.1408728329842625, Recall = 0.9648576512455516, Aging Rate = 0.4957740213523132, Precision = 0.9730820995962315, f1 = 0.968952423497878\n",
      "Test Loss = 0.13393589106530907, Recall = 0.9501779359430605, Aging Rate = 0.48398576512455516, precision = 0.9816176470588235\n",
      "Model in epoch 20 is saved.\n",
      "\n",
      "Epoch 21: Train Loss = 0.1378934532403946, Recall = 0.9568505338078291, Aging Rate = 0.4919928825622776, Precision = 0.9724231464737794, f1 = 0.9645739910313901\n",
      "Epoch 22: Train Loss = 0.134196522821311, Recall = 0.9626334519572953, Aging Rate = 0.491770462633452, Precision = 0.9787426503844414, f1 = 0.9706212155191746\n",
      "Epoch 23: Train Loss = 0.13420517493397316, Recall = 0.9612989323843416, Aging Rate = 0.49088078291814946, Precision = 0.9791572270049841, f1 = 0.9701459034792368\n",
      "Epoch 24: Train Loss = 0.13237691731639603, Recall = 0.9666370106761566, Aging Rate = 0.4942170818505338, Precision = 0.9779477947794779, f1 = 0.9722595078299776\n",
      "Epoch 25: Train Loss = 0.13100139462650884, Recall = 0.9639679715302492, Aging Rate = 0.49243772241992884, Precision = 0.9787714543812105, f1 = 0.971313312415957\n",
      "Test Loss = 0.12812461330160976, Recall = 0.9715302491103203, Aging Rate = 0.49777580071174377, precision = 0.9758713136729222\n",
      "Model in epoch 25 is saved.\n",
      "\n",
      "Epoch 26: Train Loss = 0.12934096709052864, Recall = 0.9701957295373665, Aging Rate = 0.4957740213523132, Precision = 0.9784656796769852, f1 = 0.974313156131338\n",
      "Epoch 27: Train Loss = 0.1283817269517858, Recall = 0.9630782918149466, Aging Rate = 0.4902135231316726, Precision = 0.9823049001814882, f1 = 0.972596585804133\n",
      "Epoch 28: Train Loss = 0.12742099110235947, Recall = 0.9666370106761566, Aging Rate = 0.49243772241992884, Precision = 0.9814814814814815, f1 = 0.9740026893769609\n",
      "Epoch 29: Train Loss = 0.12684698641512318, Recall = 0.9661921708185054, Aging Rate = 0.49266014234875444, Precision = 0.98058690744921, f1 = 0.9733363208604079\n",
      "Epoch 30: Train Loss = 0.1263692047035991, Recall = 0.9688612099644128, Aging Rate = 0.49243772241992884, Precision = 0.983739837398374, f1 = 0.9762438368444644\n",
      "Test Loss = 0.1231465399053173, Recall = 0.9755338078291815, Aging Rate = 0.4988879003558719, precision = 0.9777084262148907\n",
      "Model in epoch 30 is saved.\n",
      "\n",
      "Epoch 31: Train Loss = 0.12533511746396372, Recall = 0.9688612099644128, Aging Rate = 0.49466192170818507, Precision = 0.97931654676259, f1 = 0.9740608228980323\n",
      "Epoch 32: Train Loss = 0.1245016208004697, Recall = 0.9701957295373665, Aging Rate = 0.4931049822064057, Precision = 0.9837618403247632, f1 = 0.9769316909294512\n",
      "Epoch 33: Train Loss = 0.12512042360161546, Recall = 0.9706405693950177, Aging Rate = 0.49532918149466193, Precision = 0.9797934440951953, f1 = 0.975195530726257\n",
      "Epoch 34: Train Loss = 0.12421521189161891, Recall = 0.9684163701067615, Aging Rate = 0.49243772241992884, Precision = 0.9832881662149955, f1 = 0.9757956073509637\n",
      "Epoch 35: Train Loss = 0.12321955601939952, Recall = 0.9715302491103203, Aging Rate = 0.4951067615658363, Precision = 0.9811320754716981, f1 = 0.9763075547608404\n",
      "Test Loss = 0.11916336899762477, Recall = 0.9710854092526691, Aging Rate = 0.49377224199288255, precision = 0.9833333333333333\n",
      "Model in epoch 35 is saved.\n",
      "\n",
      "Epoch 36: Train Loss = 0.12224859969683813, Recall = 0.9675266903914591, Aging Rate = 0.4913256227758007, Precision = 0.9846084200995926, f1 = 0.9759928202827015\n",
      "Epoch 37: Train Loss = 0.12221349049293273, Recall = 0.969306049822064, Aging Rate = 0.49266014234875444, Precision = 0.9837471783295711, f1 = 0.9764732242885952\n",
      "Epoch 38: Train Loss = 0.12244643111882261, Recall = 0.9688612099644128, Aging Rate = 0.49243772241992884, Precision = 0.983739837398374, f1 = 0.9762438368444644\n",
      "Epoch 39: Train Loss = 0.12240864166797692, Recall = 0.9697508896797153, Aging Rate = 0.49377224199288255, Precision = 0.9819819819819819, f1 = 0.9758281110116384\n",
      "Epoch 40: Train Loss = 0.12180279919155128, Recall = 0.9719750889679716, Aging Rate = 0.4944395017793594, Precision = 0.9829059829059829, f1 = 0.9774099753970029\n",
      "Test Loss = 0.11760957030002757, Recall = 0.9706405693950177, Aging Rate = 0.4919928825622776, precision = 0.9864376130198915\n",
      "Model in epoch 40 is saved.\n",
      "\n",
      "Epoch 41: Train Loss = 0.12104985131169553, Recall = 0.9684163701067615, Aging Rate = 0.4915480427046263, Precision = 0.9850678733031675, f1 = 0.9766711529834006\n",
      "Epoch 42: Train Loss = 0.12306991299064134, Recall = 0.969306049822064, Aging Rate = 0.4928825622775801, Precision = 0.9833032490974729, f1 = 0.9762544802867383\n",
      "Epoch 43: Train Loss = 0.12153778145639922, Recall = 0.9697508896797153, Aging Rate = 0.4931049822064057, Precision = 0.9833107803337844, f1 = 0.9764837625979844\n",
      "Epoch 44: Train Loss = 0.1216467720758024, Recall = 0.9684163701067615, Aging Rate = 0.4915480427046263, Precision = 0.9850678733031675, f1 = 0.9766711529834006\n",
      "Epoch 45: Train Loss = 0.12030705072489498, Recall = 0.9719750889679716, Aging Rate = 0.49243772241992884, Precision = 0.9869015356820234, f1 = 0.9793814432989691\n",
      "Test Loss = 0.11737250279489361, Recall = 0.9773131672597865, Aging Rate = 0.4979982206405694, precision = 0.9812416257257704\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 46: Train Loss = 0.1204367948702646, Recall = 0.9697508896797153, Aging Rate = 0.4922153024911032, Precision = 0.9850881156800723, f1 = 0.9773593364716432\n",
      "Epoch 47: Train Loss = 0.11995580002294316, Recall = 0.9697508896797153, Aging Rate = 0.49354982206405695, Precision = 0.982424515547544, f1 = 0.9760465636892769\n",
      "Epoch 48: Train Loss = 0.12075758091707671, Recall = 0.9715302491103203, Aging Rate = 0.4933274021352313, Precision = 0.9846708746618575, f1 = 0.9780564263322883\n",
      "Epoch 49: Train Loss = 0.11920875310897827, Recall = 0.9724199288256228, Aging Rate = 0.4939946619217082, Precision = 0.9842413327330032, f1 = 0.9782949205638846\n",
      "Epoch 50: Train Loss = 0.11990515193056805, Recall = 0.9733096085409253, Aging Rate = 0.4939946619217082, Precision = 0.985141828005403, f1 = 0.9791899753859925\n",
      "Test Loss = 0.11728185168682892, Recall = 0.9764234875444839, Aging Rate = 0.49755338078291816, precision = 0.9812248547161377\n",
      "\n",
      "Epoch 51: Train Loss = 0.11977537660412092, Recall = 0.9724199288256228, Aging Rate = 0.4939946619217082, Precision = 0.9842413327330032, f1 = 0.9782949205638846\n",
      "Epoch 52: Train Loss = 0.11932581771841252, Recall = 0.9697508896797153, Aging Rate = 0.49243772241992884, Precision = 0.9846431797651309, f1 = 0.9771402958314658\n",
      "Epoch 53: Train Loss = 0.1198994078776166, Recall = 0.9715302491103203, Aging Rate = 0.4928825622775801, Precision = 0.9855595667870036, f1 = 0.978494623655914\n",
      "Epoch 54: Train Loss = 0.11994441858496106, Recall = 0.9715302491103203, Aging Rate = 0.4933274021352313, Precision = 0.9846708746618575, f1 = 0.9780564263322883\n",
      "Epoch 55: Train Loss = 0.11980440899782757, Recall = 0.9719750889679716, Aging Rate = 0.4933274021352313, Precision = 0.9851217312894499, f1 = 0.9785042543663234\n",
      "Test Loss = 0.11514866307006612, Recall = 0.9759786476868327, Aging Rate = 0.4962188612099644, precision = 0.9834155087404751\n",
      "\n",
      "Epoch 56: Train Loss = 0.11821518782725114, Recall = 0.972864768683274, Aging Rate = 0.49354982206405695, Precision = 0.985579089680036, f1 = 0.9791806581598388\n",
      "Epoch 57: Train Loss = 0.11895183041638752, Recall = 0.9710854092526691, Aging Rate = 0.49488434163701067, Precision = 0.981123595505618, f1 = 0.9760786943885537\n",
      "Epoch 58: Train Loss = 0.11833659583351366, Recall = 0.9719750889679716, Aging Rate = 0.49266014234875444, Precision = 0.9864559819413092, f1 = 0.9791619986556129\n",
      "Epoch 59: Train Loss = 0.11888606708457038, Recall = 0.9710854092526691, Aging Rate = 0.4931049822064057, Precision = 0.9846639603067208, f1 = 0.9778275475923853\n",
      "Epoch 60: Train Loss = 0.11794907196666847, Recall = 0.9737544483985765, Aging Rate = 0.4944395017793594, Precision = 0.9847053531264057, f1 = 0.9791992842764482\n",
      "Test Loss = 0.11516903855198218, Recall = 0.9697508896797153, Aging Rate = 0.48954626334519574, precision = 0.9904588823262154\n",
      "Model in epoch 60 is saved.\n",
      "\n",
      "Epoch 61: Train Loss = 0.11856576206421089, Recall = 0.9697508896797153, Aging Rate = 0.4919928825622776, Precision = 0.9855334538878843, f1 = 0.9775784753363229\n",
      "Epoch 62: Train Loss = 0.11806862989566504, Recall = 0.9701957295373665, Aging Rate = 0.49377224199288255, Precision = 0.9824324324324324, f1 = 0.9762757385854968\n",
      "Epoch 63: Train Loss = 0.12088408122283284, Recall = 0.969306049822064, Aging Rate = 0.4922153024911032, Precision = 0.9846362403976503, f1 = 0.9769110065007846\n",
      "Epoch 64: Train Loss = 0.11777224206097185, Recall = 0.9724199288256228, Aging Rate = 0.4931049822064057, Precision = 0.9860171402796571, f1 = 0.9791713325867861\n",
      "Epoch 65: Train Loss = 0.11804634862947294, Recall = 0.969306049822064, Aging Rate = 0.49266014234875444, Precision = 0.9837471783295711, f1 = 0.9764732242885952\n",
      "Test Loss = 0.11544702968351357, Recall = 0.9764234875444839, Aging Rate = 0.4971085409252669, precision = 0.9821029082774049\n",
      "\n",
      "Epoch 66: Train Loss = 0.11814254570049748, Recall = 0.972864768683274, Aging Rate = 0.4944395017793594, Precision = 0.9838056680161943, f1 = 0.9783046298367255\n",
      "Epoch 67: Train Loss = 0.11809002276629316, Recall = 0.969306049822064, Aging Rate = 0.4913256227758007, Precision = 0.9864191942055228, f1 = 0.9777877496073591\n",
      "Epoch 68: Train Loss = 0.11945145346515967, Recall = 0.9719750889679716, Aging Rate = 0.4942170818505338, Precision = 0.9833483348334834, f1 = 0.9776286353467563\n",
      "Epoch 69: Train Loss = 0.1182929766347824, Recall = 0.9719750889679716, Aging Rate = 0.49466192170818507, Precision = 0.9824640287769785, f1 = 0.9771914132379249\n",
      "Epoch 70: Train Loss = 0.11810394760976907, Recall = 0.9688612099644128, Aging Rate = 0.49110320284697506, Precision = 0.9864130434782609, f1 = 0.9775583482944344\n",
      "Test Loss = 0.11443801256049146, Recall = 0.9750889679715302, Aging Rate = 0.49266014234875444, precision = 0.9896162528216704\n",
      "Model in epoch 70 is saved.\n",
      "\n",
      "Epoch 71: Train Loss = 0.11823795658943916, Recall = 0.969306049822064, Aging Rate = 0.49065836298932386, Precision = 0.9877606527651859, f1 = 0.9784463403682084\n",
      "Epoch 72: Train Loss = 0.11803755922461744, Recall = 0.974644128113879, Aging Rate = 0.49377224199288255, Precision = 0.986936936936937, f1 = 0.9807520143240823\n",
      "Epoch 73: Train Loss = 0.1172695957468922, Recall = 0.9710854092526691, Aging Rate = 0.49243772241992884, Precision = 0.9859981933152665, f1 = 0.9784849843119678\n",
      "Epoch 74: Train Loss = 0.11647679049561456, Recall = 0.9759786476868327, Aging Rate = 0.49466192170818507, Precision = 0.9865107913669064, f1 = 0.9812164579606439\n",
      "Epoch 75: Train Loss = 0.11684019426115891, Recall = 0.9724199288256228, Aging Rate = 0.49377224199288255, Precision = 0.9846846846846847, f1 = 0.9785138764547896\n",
      "Test Loss = 0.11475590642979136, Recall = 0.9764234875444839, Aging Rate = 0.49532918149466193, precision = 0.9856308935788056\n",
      "\n",
      "Epoch 76: Train Loss = 0.11659382914733207, Recall = 0.972864768683274, Aging Rate = 0.4928825622775801, Precision = 0.9869133574007221, f1 = 0.9798387096774194\n",
      "Epoch 77: Train Loss = 0.11746635688369385, Recall = 0.972864768683274, Aging Rate = 0.4951067615658363, Precision = 0.9824797843665768, f1 = 0.9776486365668305\n",
      "Epoch 78: Train Loss = 0.11835740225595087, Recall = 0.9675266903914591, Aging Rate = 0.489991103202847, Precision = 0.9872900590104403, f1 = 0.97730847000674\n",
      "Epoch 79: Train Loss = 0.11811244819193972, Recall = 0.9710854092526691, Aging Rate = 0.4922153024911032, Precision = 0.9864437415273385, f1 = 0.9787043263842188\n",
      "Epoch 80: Train Loss = 0.11807144483637555, Recall = 0.9719750889679716, Aging Rate = 0.4931049822064057, Precision = 0.9855660802886784, f1 = 0.9787234042553191\n",
      "Test Loss = 0.11490842495842761, Recall = 0.9688612099644128, Aging Rate = 0.4891014234875445, precision = 0.990450204638472\n",
      "\n",
      "Epoch 81: Train Loss = 0.11698946229503672, Recall = 0.9715302491103203, Aging Rate = 0.4919928825622776, Precision = 0.9873417721518988, f1 = 0.979372197309417\n",
      "Epoch 82: Train Loss = 0.11641317982478498, Recall = 0.9724199288256228, Aging Rate = 0.4942170818505338, Precision = 0.9837983798379838, f1 = 0.9780760626398212\n",
      "Epoch 83: Train Loss = 0.11656822036169602, Recall = 0.9697508896797153, Aging Rate = 0.49110320284697506, Precision = 0.9873188405797102, f1 = 0.9784560143626572\n",
      "Epoch 84: Train Loss = 0.11697114956336513, Recall = 0.9719750889679716, Aging Rate = 0.4931049822064057, Precision = 0.9855660802886784, f1 = 0.9787234042553191\n",
      "Epoch 85: Train Loss = 0.1172836178456337, Recall = 0.9737544483985765, Aging Rate = 0.4933274021352313, Precision = 0.9869251577998197, f1 = 0.9802955665024631\n",
      "Test Loss = 0.11299710580250547, Recall = 0.9741992882562278, Aging Rate = 0.4931049822064057, precision = 0.9878213802435724\n",
      "\n",
      "Epoch 86: Train Loss = 0.11587373169927835, Recall = 0.9733096085409253, Aging Rate = 0.4939946619217082, Precision = 0.985141828005403, f1 = 0.9791899753859925\n",
      "Epoch 87: Train Loss = 0.11666863414316415, Recall = 0.9719750889679716, Aging Rate = 0.491770462633452, Precision = 0.9882406151062868, f1 = 0.98004036779547\n",
      "Epoch 88: Train Loss = 0.11634997652306675, Recall = 0.9733096085409253, Aging Rate = 0.4928825622775801, Precision = 0.9873646209386282, f1 = 0.9802867383512545\n",
      "Epoch 89: Train Loss = 0.11705309041242158, Recall = 0.9719750889679716, Aging Rate = 0.49243772241992884, Precision = 0.9869015356820234, f1 = 0.9793814432989691\n",
      "Epoch 90: Train Loss = 0.11676031287454626, Recall = 0.9737544483985765, Aging Rate = 0.4939946619217082, Precision = 0.9855920756416029, f1 = 0.9796375027970463\n",
      "Test Loss = 0.11295822111631203, Recall = 0.9741992882562278, Aging Rate = 0.49243772241992884, precision = 0.989159891598916\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 91: Train Loss = 0.1165752522249663, Recall = 0.9715302491103203, Aging Rate = 0.49243772241992884, Precision = 0.986449864498645, f1 = 0.9789332138054684\n",
      "Epoch 92: Train Loss = 0.11688010558963247, Recall = 0.9737544483985765, Aging Rate = 0.4933274021352313, Precision = 0.9869251577998197, f1 = 0.9802955665024631\n",
      "Epoch 93: Train Loss = 0.11571154332457913, Recall = 0.972864768683274, Aging Rate = 0.4919928825622776, Precision = 0.9886980108499096, f1 = 0.9807174887892376\n",
      "Epoch 94: Train Loss = 0.11599515749678493, Recall = 0.9737544483985765, Aging Rate = 0.49377224199288255, Precision = 0.9860360360360361, f1 = 0.9798567591763653\n",
      "Epoch 95: Train Loss = 0.11616401628879465, Recall = 0.9719750889679716, Aging Rate = 0.4915480427046263, Precision = 0.9886877828054299, f1 = 0.9802602063705698\n",
      "Test Loss = 0.1122116000255656, Recall = 0.9755338078291815, Aging Rate = 0.4933274021352313, precision = 0.9887285843101894\n",
      "\n",
      "Epoch 96: Train Loss = 0.11551351842612982, Recall = 0.9719750889679716, Aging Rate = 0.49266014234875444, Precision = 0.9864559819413092, f1 = 0.9791619986556129\n",
      "Epoch 97: Train Loss = 0.1165425668990909, Recall = 0.9733096085409253, Aging Rate = 0.49354982206405695, Precision = 0.9860297431275349, f1 = 0.9796283859413477\n",
      "Epoch 98: Train Loss = 0.1158041868133477, Recall = 0.972864768683274, Aging Rate = 0.4922153024911032, Precision = 0.9882512426570267, f1 = 0.9804976462676529\n",
      "Epoch 99: Train Loss = 0.11650912821611051, Recall = 0.972864768683274, Aging Rate = 0.4933274021352313, Precision = 0.9860234445446348, f1 = 0.9793999104343932\n",
      "Epoch 100: Train Loss = 0.11628659986940568, Recall = 0.972864768683274, Aging Rate = 0.49354982206405695, Precision = 0.985579089680036, f1 = 0.9791806581598388\n",
      "Test Loss = 0.11426775085862421, Recall = 0.9764234875444839, Aging Rate = 0.4971085409252669, precision = 0.9821029082774049\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5012dd1817f44cd89361bb41563bba0a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss = 0.29949054509083145, Recall = 0.9141459074733096, Aging Rate = 0.5536032028469751, Precision = 0.8256327842507031, f1 = 0.8676377454084865\n",
      "Epoch 2: Train Loss = 0.12538934392967258, Recall = 0.9621886120996441, Aging Rate = 0.5048932384341637, Precision = 0.952863436123348, f1 = 0.9575033200531209\n",
      "Epoch 3: Train Loss = 0.0834429737617961, Recall = 0.9724199288256228, Aging Rate = 0.49955516014234874, Precision = 0.9732858414959928, f1 = 0.9728526924788606\n",
      "Epoch 4: Train Loss = 0.06220064908796358, Recall = 0.9808718861209964, Aging Rate = 0.4991103202846975, Precision = 0.982620320855615, f1 = 0.9817453250222618\n",
      "Epoch 5: Train Loss = 0.04453550175319548, Recall = 0.9862099644128114, Aging Rate = 0.5008896797153025, Precision = 0.9844582593250444, f1 = 0.9853333333333334\n",
      "Test Loss = 0.01909140945541477, Recall = 0.9928825622775801, Aging Rate = 0.49644128113879005, precision = 1.0\n",
      "Model in epoch 5 is saved.\n",
      "\n",
      "Epoch 6: Train Loss = 0.01685772913431888, Recall = 0.9951067615658363, Aging Rate = 0.498220640569395, Precision = 0.9986607142857142, f1 = 0.996880570409982\n",
      "Epoch 7: Train Loss = 0.008789447790800571, Recall = 0.9986654804270463, Aging Rate = 0.49955516014234874, Precision = 0.9995547640249333, f1 = 0.9991099243435693\n",
      "Epoch 8: Train Loss = 0.007193214723217265, Recall = 0.9986654804270463, Aging Rate = 0.4997775800711744, Precision = 0.9991099243435692, f1 = 0.9988876529477195\n",
      "Epoch 9: Train Loss = 0.005463906056728227, Recall = 0.9995551601423488, Aging Rate = 0.5, Precision = 0.9995551601423488, f1 = 0.9995551601423488\n",
      "Epoch 10: Train Loss = 0.0031327658533400384, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0022416784394088322, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "Model in epoch 10 is saved.\n",
      "\n",
      "Epoch 11: Train Loss = 0.003102666244749311, Recall = 0.9995551601423488, Aging Rate = 0.4997775800711744, Precision = 0, f1 = 0.0\n",
      "Epoch 12: Train Loss = 0.002472269859204725, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 13: Train Loss = 0.0020792251920950635, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 14: Train Loss = 0.0021293540864278067, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 15: Train Loss = 0.002102519485567534, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.001909060366418597, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 16: Train Loss = 0.0023127693158418628, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 17: Train Loss = 0.008281615264448618, Recall = 0.9977758007117438, Aging Rate = 0.49955516014234874, Precision = 0.9986642920747997, f1 = 0.9982198486871383\n",
      "Epoch 18: Train Loss = 0.011827189170380928, Recall = 0.998220640569395, Aging Rate = 0.5013345195729537, Precision = 0.9955634427684117, f1 = 0.9968902709906707\n",
      "Epoch 19: Train Loss = 0.016509080700099044, Recall = 0.99644128113879, Aging Rate = 0.5013345195729537, Precision = 0.9937888198757764, f1 = 0.9951132829853399\n",
      "Epoch 20: Train Loss = 0.013184950816612011, Recall = 0.99644128113879, Aging Rate = 0.5006672597864769, Precision = 0.9951132829853399, f1 = 0.9957768392976216\n",
      "Test Loss = 0.02095541516915494, Recall = 1.0, Aging Rate = 0.5102313167259787, precision = 0.979947689625109\n",
      "\n",
      "Epoch 21: Train Loss = 0.013214820071854348, Recall = 0.9973309608540926, Aging Rate = 0.5013345195729537, Precision = 0.9946761313220941, f1 = 0.9960017769880053\n",
      "Epoch 22: Train Loss = 0.002896363014650276, Recall = 0.9995551601423488, Aging Rate = 0.5, Precision = 0.9995551601423488, f1 = 0.9995551601423488\n",
      "Epoch 23: Train Loss = 0.0016901792773605718, Recall = 1.0, Aging Rate = 0.5002224199288257, Precision = 0.9995553579368608, f1 = 0.9997776295307983\n",
      "Epoch 24: Train Loss = 0.0006928422651502214, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 25: Train Loss = 0.0005928048162511467, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0005699006095487174, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 26: Train Loss = 0.0006708335146942637, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 27: Train Loss = 0.0008175534699973899, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 28: Train Loss = 0.0009127991486115388, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 29: Train Loss = 0.0010715812557373606, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 30: Train Loss = 0.0011888941897728125, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.001182502241692509, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 31: Train Loss = 0.0013326924767351818, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 32: Train Loss = 0.0019069821499221795, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 33: Train Loss = 0.0017618810334590884, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 34: Train Loss = 0.0014903947561432432, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 35: Train Loss = 0.001668658382193023, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.001597767467096819, Recall = 0.9995551601423488, Aging Rate = 0.4997775800711744, precision = 1.0\n",
      "\n",
      "Epoch 36: Train Loss = 0.0026669149068300198, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 37: Train Loss = 0.051644059236980046, Recall = 0.9866548042704626, Aging Rate = 0.5057829181494662, Precision = 0.9753737906772207, f1 = 0.9809818664307828\n",
      "Epoch 38: Train Loss = 0.03618710753474769, Recall = 0.9906583629893239, Aging Rate = 0.5031138790035588, Precision = 0.984526967285588, f1 = 0.9875831485587583\n",
      "Epoch 39: Train Loss = 0.007788796710915983, Recall = 0.9977758007117438, Aging Rate = 0.5, Precision = 0.9977758007117438, f1 = 0.9977758007117438\n",
      "Epoch 40: Train Loss = 0.0014795484237254389, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0006993729991960966, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 41: Train Loss = 0.0007583143871469801, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 42: Train Loss = 0.0007425412312779721, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 43: Train Loss = 0.0008124629367230746, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 44: Train Loss = 0.000881220753059401, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 45: Train Loss = 0.000992110604544591, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0008905628611983274, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 46: Train Loss = 0.001006338762755761, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 47: Train Loss = 0.0010574966104820477, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 48: Train Loss = 0.0011219216624168793, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 49: Train Loss = 0.0011910581082980615, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 50: Train Loss = 0.0013275036691469256, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.001183480179903439, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 51: Train Loss = 0.001298054183681671, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 52: Train Loss = 0.001450417881907756, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 53: Train Loss = 0.001423035430957255, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 54: Train Loss = 0.0018040082219398159, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 55: Train Loss = 0.0018023802858223854, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.001704282426023425, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 56: Train Loss = 0.0021659650999780915, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 57: Train Loss = 0.027245679817218798, Recall = 0.9924377224199288, Aging Rate = 0.5020017793594306, Precision = 0.9884802835622508, f1 = 0.9904550499445061\n",
      "Epoch 58: Train Loss = 0.05973644601844012, Recall = 0.983540925266904, Aging Rate = 0.5040035587188612, Precision = 0.9757281553398058, f1 = 0.9796189632255207\n",
      "Epoch 59: Train Loss = 0.010698344053665767, Recall = 0.99644128113879, Aging Rate = 0.4997775800711744, Precision = 0.9968847352024922, f1 = 0.996662958843159\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 60: Train Loss = 0.003086583216772398, Recall = 0.9995551601423488, Aging Rate = 0.5004448398576512, Precision = 0.9986666666666667, f1 = 0.9991107158737217\n",
      "Test Loss = 0.0012654151524718704, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Training Finished at epoch 60.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f2933024f467429083a1495b004857b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss = 0.3324721493489802, Recall = 0.9092526690391459, Aging Rate = 0.5625, Precision = 0.808224594701463, f1 = 0.8557672179191961\n",
      "Epoch 2: Train Loss = 0.13477987941898062, Recall = 0.9590747330960854, Aging Rate = 0.505338078291815, Precision = 0.948943661971831, f1 = 0.9539823008849557\n",
      "Epoch 3: Train Loss = 0.08072038314527305, Recall = 0.9724199288256228, Aging Rate = 0.5006672597864769, Precision = 0.9711239449133718, f1 = 0.9717715047788399\n",
      "Epoch 4: Train Loss = 0.04919299345423742, Recall = 0.9830960854092526, Aging Rate = 0.4991103202846975, Precision = 0.9848484848484849, f1 = 0.9839715048975957\n",
      "Epoch 5: Train Loss = 0.048389452751527055, Recall = 0.9848754448398577, Aging Rate = 0.5002224199288257, Precision = 0.9844375277901289, f1 = 0.9846564376250834\n",
      "Test Loss = 0.017924610096165826, Recall = 0.9937722419928826, Aging Rate = 0.4979982206405694, precision = 0.9977668602054489\n",
      "Model in epoch 5 is saved.\n",
      "\n",
      "Epoch 6: Train Loss = 0.014368167993847904, Recall = 0.9968861209964412, Aging Rate = 0.4997775800711744, Precision = 0.9973297730307076, f1 = 0.9971078976640712\n",
      "Epoch 7: Train Loss = 0.007195227485095413, Recall = 0.9991103202846975, Aging Rate = 0.4997775800711744, Precision = 0.9995549621717846, f1 = 0.9993325917686319\n",
      "Epoch 8: Train Loss = 0.004161323264309162, Recall = 1.0, Aging Rate = 0.5002224199288257, Precision = 0.9995553579368608, f1 = 0.9997776295307983\n",
      "Epoch 9: Train Loss = 0.0035235080271429015, Recall = 0.9995551601423488, Aging Rate = 0.4997775800711744, Precision = 0, f1 = 0.0\n",
      "Epoch 10: Train Loss = 0.002622535270995053, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0020540488164646556, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "Model in epoch 10 is saved.\n",
      "\n",
      "Epoch 11: Train Loss = 0.0022886728145367734, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 12: Train Loss = 0.0021873071899113916, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 13: Train Loss = 0.0022124755187987537, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 14: Train Loss = 0.002205007021842372, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 15: Train Loss = 0.0021937565278971165, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.001710694933267065, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 16: Train Loss = 0.002193579465992669, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 17: Train Loss = 0.0032300528073003947, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 18: Train Loss = 0.0032250324224396957, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 19: Train Loss = 0.002065269978720284, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 20: Train Loss = 0.0024220795334180902, Recall = 0.9995551601423488, Aging Rate = 0.5, Precision = 0.9995551601423488, f1 = 0.9995551601423488\n",
      "Test Loss = 0.006214274921258945, Recall = 1.0, Aging Rate = 0.5002224199288257, precision = 0.9995553579368608\n",
      "\n",
      "Epoch 21: Train Loss = 0.01846788276411142, Recall = 0.994661921708185, Aging Rate = 0.5020017793594306, Precision = 0.9906956136464333, f1 = 0.9926748057713651\n",
      "Epoch 22: Train Loss = 0.054474300542495004, Recall = 0.9826512455516014, Aging Rate = 0.5015569395017794, Precision = 0.9796008869179601, f1 = 0.981123695314235\n",
      "Epoch 23: Train Loss = 0.011752439068723138, Recall = 0.9973309608540926, Aging Rate = 0.5006672597864769, Precision = 0.9960017769880053, f1 = 0.9966659257612803\n",
      "Epoch 24: Train Loss = 0.006470006410847833, Recall = 0.9991103202846975, Aging Rate = 0.5008896797153025, Precision = 0.9973357015985791, f1 = 0.9982222222222222\n",
      "Epoch 25: Train Loss = 0.001974113619148075, Recall = 0.9995551601423488, Aging Rate = 0.5, Precision = 0.9995551601423488, f1 = 0.9995551601423488\n",
      "Test Loss = 0.0008877146049913059, Recall = 1.0, Aging Rate = 0.5002224199288257, precision = 0.9995553579368608\n",
      "\n",
      "Epoch 26: Train Loss = 0.0011780733655677492, Recall = 1.0, Aging Rate = 0.5002224199288257, Precision = 0.9995553579368608, f1 = 0.9997776295307983\n",
      "Epoch 27: Train Loss = 0.0006044390041702609, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 28: Train Loss = 0.000637914179107572, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 29: Train Loss = 0.0007316587450151793, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 30: Train Loss = 0.0008472941979083143, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0008064486103768715, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 31: Train Loss = 0.000957262379969089, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 32: Train Loss = 0.0010221499864350064, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 33: Train Loss = 0.0011919472069111636, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 34: Train Loss = 0.0011672441639649115, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 35: Train Loss = 0.0013328006907840162, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0012656497082165923, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 36: Train Loss = 0.0016118268510558744, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 37: Train Loss = 0.0014032323884502636, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 38: Train Loss = 0.007107811951777795, Recall = 0.9991103202846975, Aging Rate = 0.5, Precision = 0.9991103202846975, f1 = 0.9991103202846975\n",
      "Epoch 39: Train Loss = 0.043124759752051475, Recall = 0.9879893238434164, Aging Rate = 0.5031138790035588, Precision = 0.9818744473916887, f1 = 0.9849223946784922\n",
      "Epoch 40: Train Loss = 0.028682003540129425, Recall = 0.9919928825622776, Aging Rate = 0.5004448398576512, Precision = 0.9911111111111112, f1 = 0.9915518008003557\n",
      "Test Loss = 0.022218056291580413, Recall = 1.0, Aging Rate = 0.510008896797153, precision = 0.9803750545137374\n",
      "\n",
      "Epoch 41: Train Loss = 0.016454981385193287, Recall = 0.9959964412811388, Aging Rate = 0.501779359430605, Precision = 0.9924645390070922, f1 = 0.994227353463588\n",
      "Epoch 42: Train Loss = 0.004624543221956583, Recall = 0.9995551601423488, Aging Rate = 0.5008896797153025, Precision = 0.9977797513321492, f1 = 0.9986666666666667\n",
      "Epoch 43: Train Loss = 0.0017025315530475535, Recall = 0.9995551601423488, Aging Rate = 0.5, Precision = 0.9995551601423488, f1 = 0.9995551601423488\n",
      "Epoch 44: Train Loss = 0.000594973208480498, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 45: Train Loss = 0.0005280589219286302, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.000531809589161879, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 46: Train Loss = 0.0005731198207965764, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 47: Train Loss = 0.0006600557064166909, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 48: Train Loss = 0.0007506632692473891, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 49: Train Loss = 0.0008408486937567114, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 50: Train Loss = 0.0009605054933332517, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0009225737631301896, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 51: Train Loss = 0.0010445572645486302, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 52: Train Loss = 0.0011673930543972, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 53: Train Loss = 0.0011301231218395868, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 54: Train Loss = 0.0012655666545845462, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 55: Train Loss = 0.0012957164889294322, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0012630357073944764, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 56: Train Loss = 0.0014030943256786285, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 57: Train Loss = 0.001496923767366642, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 58: Train Loss = 0.001540330797516711, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59: Train Loss = 0.0021922183562786022, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 60: Train Loss = 0.024588303710914007, Recall = 0.9937722419928826, Aging Rate = 0.5015569395017794, Precision = 0.9906873614190688, f1 = 0.9922274039529204\n",
      "Test Loss = 0.027763255606687152, Recall = 0.9942170818505338, Aging Rate = 0.5037811387900356, precision = 0.9867549668874173\n",
      "\n",
      "Training Finished at epoch 60.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc4859fb2acd44e4b6ff4db1805de374",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss = 0.3396742636092617, Recall = 0.9101423487544484, Aging Rate = 0.5622775800711743, Precision = 0.8093354430379747, f1 = 0.8567839195979899\n",
      "Epoch 2: Train Loss = 0.14304075286693846, Recall = 0.9568505338078291, Aging Rate = 0.5060053380782918, Precision = 0.9454945054945055, f1 = 0.9511386248065443\n",
      "Epoch 3: Train Loss = 0.08807049328428146, Recall = 0.972864768683274, Aging Rate = 0.5004448398576512, Precision = 0.972, f1 = 0.9724321920853713\n",
      "Epoch 4: Train Loss = 0.061067375503613006, Recall = 0.9808718861209964, Aging Rate = 0.4991103202846975, Precision = 0.982620320855615, f1 = 0.9817453250222618\n",
      "Epoch 5: Train Loss = 0.04029369290944626, Recall = 0.9893238434163701, Aging Rate = 0.49955516014234874, Precision = 0.9902048085485308, f1 = 0.9897641299510459\n",
      "Test Loss = 0.02229496397515527, Recall = 0.9977758007117438, Aging Rate = 0.5022241992882562, precision = 0.9933569530558016\n",
      "Model in epoch 5 is saved.\n",
      "\n",
      "Epoch 6: Train Loss = 0.019372718640705867, Recall = 0.9937722419928826, Aging Rate = 0.4991103202846975, Precision = 0.9955436720142602, f1 = 0.9946571682991986\n",
      "Epoch 7: Train Loss = 0.01010337224879776, Recall = 0.998220640569395, Aging Rate = 0.49933274021352314, Precision = 0.999554565701559, f1 = 0.9988871578010238\n",
      "Epoch 8: Train Loss = 0.0068908524119503985, Recall = 0.9986654804270463, Aging Rate = 0.49955516014234874, Precision = 0.9995547640249333, f1 = 0.9991099243435693\n",
      "Epoch 9: Train Loss = 0.00586513551846942, Recall = 0.9991103202846975, Aging Rate = 0.4997775800711744, Precision = 0.9995549621717846, f1 = 0.9993325917686319\n",
      "Epoch 10: Train Loss = 0.003457610460588198, Recall = 0.9995551601423488, Aging Rate = 0.4997775800711744, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.00305456594104988, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "Model in epoch 10 is saved.\n",
      "\n",
      "Epoch 11: Train Loss = 0.0034805221832771636, Recall = 1.0, Aging Rate = 0.5002224199288257, Precision = 0.9995553579368608, f1 = 0.9997776295307983\n",
      "Epoch 12: Train Loss = 0.0035450275493553738, Recall = 0.9995551601423488, Aging Rate = 0.5, Precision = 0.9995551601423488, f1 = 0.9995551601423488\n",
      "Epoch 13: Train Loss = 0.0031733231087052844, Recall = 0.9995551601423488, Aging Rate = 0.4997775800711744, Precision = 0, f1 = 0.0\n",
      "Epoch 14: Train Loss = 0.003092851355552567, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 15: Train Loss = 0.0024154537622120852, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0022998253949105844, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 16: Train Loss = 0.0033952081845277835, Recall = 0.9995551601423488, Aging Rate = 0.4997775800711744, Precision = 0, f1 = 0.0\n",
      "Epoch 17: Train Loss = 0.002831598510965705, Recall = 1.0, Aging Rate = 0.5002224199288257, Precision = 0.9995553579368608, f1 = 0.9997776295307983\n",
      "Epoch 18: Train Loss = 0.004650232444262112, Recall = 0.9991103202846975, Aging Rate = 0.5, Precision = 0.9991103202846975, f1 = 0.9991103202846975\n",
      "Epoch 19: Train Loss = 0.018052819292674178, Recall = 0.994661921708185, Aging Rate = 0.5008896797153025, Precision = 0.9928952042628775, f1 = 0.9937777777777778\n",
      "Epoch 20: Train Loss = 0.04045171132874659, Recall = 0.9884341637010676, Aging Rate = 0.5037811387900356, Precision = 0.9810154525386313, f1 = 0.9847108353645025\n",
      "Test Loss = 0.011559468370885506, Recall = 0.9973309608540926, Aging Rate = 0.5, precision = 0.9973309608540926\n",
      "\n",
      "Epoch 21: Train Loss = 0.013714483600636792, Recall = 0.9959964412811388, Aging Rate = 0.5002224199288257, Precision = 0.9955535793686082, f1 = 0.9957749610851679\n",
      "Epoch 22: Train Loss = 0.013074005809069852, Recall = 0.9955516014234875, Aging Rate = 0.5002224199288257, Precision = 0.9951089373054691, f1 = 0.9953302201467645\n",
      "Epoch 23: Train Loss = 0.0024733896997178907, Recall = 0.9991103202846975, Aging Rate = 0.49955516014234874, Precision = 0, f1 = 0.0\n",
      "Epoch 24: Train Loss = 0.00083753251072079, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 25: Train Loss = 0.0007150791338114632, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0006616942787930714, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 26: Train Loss = 0.0007117593522578, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 27: Train Loss = 0.0007811563008289214, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 28: Train Loss = 0.0008880756321044976, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 29: Train Loss = 0.001068632301519827, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 30: Train Loss = 0.0012324247115666172, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0011039113019364372, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 31: Train Loss = 0.0013484155441869674, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 32: Train Loss = 0.0013413938747663416, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 33: Train Loss = 0.004858565073480227, Recall = 0.9995551601423488, Aging Rate = 0.5, Precision = 0.9995551601423488, f1 = 0.9995551601423488\n",
      "Epoch 34: Train Loss = 0.0061876687964464265, Recall = 0.9991103202846975, Aging Rate = 0.5002224199288257, Precision = 0.9986660738105825, f1 = 0.9988881476539915\n",
      "Epoch 35: Train Loss = 0.006940627479312603, Recall = 0.9986654804270463, Aging Rate = 0.5, Precision = 0.9986654804270463, f1 = 0.9986654804270463\n",
      "Test Loss = 0.029779370386962153, Recall = 1.0, Aging Rate = 0.5108985765124555, precision = 0.978667827601219\n",
      "\n",
      "Epoch 36: Train Loss = 0.05114693245419642, Recall = 0.9853202846975089, Aging Rate = 0.505338078291815, Precision = 0.9749119718309859, f1 = 0.9800884955752212\n",
      "Epoch 37: Train Loss = 0.009953646456202976, Recall = 0.9968861209964412, Aging Rate = 0.5011120996441281, Precision = 0.9946737683089214, f1 = 0.9957787158409241\n",
      "Epoch 38: Train Loss = 0.0030469845199884577, Recall = 1.0, Aging Rate = 0.5006672597864769, Precision = 0.9986672589960017, f1 = 0.999333185152256\n",
      "Epoch 39: Train Loss = 0.0011397740392269586, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 40: Train Loss = 0.0007333606829555222, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0006512499109260221, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 41: Train Loss = 0.0007506789274188919, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 42: Train Loss = 0.0008469372254972813, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 43: Train Loss = 0.0008821944087090011, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 44: Train Loss = 0.0009720222568769154, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 45: Train Loss = 0.0013265681897996, Recall = 1.0, Aging Rate = 0.5002224199288257, Precision = 0.9995553579368608, f1 = 0.9997776295307983\n",
      "Test Loss = 0.0014383926319813496, Recall = 0.9995551601423488, Aging Rate = 0.4997775800711744, precision = 1.0\n",
      "\n",
      "Epoch 46: Train Loss = 0.0037432636384557255, Recall = 0.9995551601423488, Aging Rate = 0.5002224199288257, Precision = 0.9991107158737217, f1 = 0.9993328885923949\n",
      "Epoch 47: Train Loss = 0.004158278900278182, Recall = 0.9986654804270463, Aging Rate = 0.4997775800711744, Precision = 0.9991099243435692, f1 = 0.9988876529477195\n",
      "Epoch 48: Train Loss = 0.008443086744481665, Recall = 0.998220640569395, Aging Rate = 0.5002224199288257, Precision = 0.9977767896843042, f1 = 0.9979986657771848\n",
      "Epoch 49: Train Loss = 0.005749531488391667, Recall = 0.9995551601423488, Aging Rate = 0.5004448398576512, Precision = 0.9986666666666667, f1 = 0.9991107158737217\n",
      "Epoch 50: Train Loss = 0.0031633879986278433, Recall = 0.9995551601423488, Aging Rate = 0.5, Precision = 0.9995551601423488, f1 = 0.9995551601423488\n",
      "Test Loss = 0.0011412529010711788, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 51: Train Loss = 0.0010315554176732315, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 52: Train Loss = 0.0007704679263437505, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 53: Train Loss = 0.0008670413291605448, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 54: Train Loss = 0.00105790069427845, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 55: Train Loss = 0.0011931995348963436, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss = 0.0010778319108833516, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 56: Train Loss = 0.0012586962807015433, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 57: Train Loss = 0.0014540801581668127, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 58: Train Loss = 0.0015610682134254705, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 59: Train Loss = 0.0016316089951482957, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 60: Train Loss = 0.005584835482917037, Recall = 0.9995551601423488, Aging Rate = 0.5002224199288257, Precision = 0.9991107158737217, f1 = 0.9993328885923949\n",
      "Test Loss = 0.017361789839043948, Recall = 0.9937722419928826, Aging Rate = 0.4971085409252669, precision = 0.9995525727069351\n",
      "\n",
      "Training Finished at epoch 60.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "188039a54bc34543856a3ac5ad372686",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss = 0.32685191393747026, Recall = 0.9172597864768683, Aging Rate = 0.5682829181494662, Precision = 0.8070450097847358, f1 = 0.8586300229023527\n",
      "Epoch 2: Train Loss = 0.13796300756549496, Recall = 0.9559608540925267, Aging Rate = 0.5015569395017794, Precision = 0.9529933481152993, f1 = 0.9544747945813902\n",
      "Epoch 3: Train Loss = 0.08874264865901546, Recall = 0.9688612099644128, Aging Rate = 0.4986654804270463, Precision = 0.9714540588760036, f1 = 0.9701559020044543\n",
      "Epoch 4: Train Loss = 0.0644924525715066, Recall = 0.979982206405694, Aging Rate = 0.5006672597864769, Precision = 0.9786761439360284, f1 = 0.9793287397199377\n",
      "Epoch 5: Train Loss = 0.042669518801029045, Recall = 0.9897686832740213, Aging Rate = 0.5011120996441281, Precision = 0.98757212605415, f1 = 0.9886691846256387\n",
      "Test Loss = 0.022740267621505727, Recall = 0.9928825622775801, Aging Rate = 0.4979982206405694, precision = 0.9968736042876284\n",
      "Model in epoch 5 is saved.\n",
      "\n",
      "Epoch 6: Train Loss = 0.018253014466039226, Recall = 0.994661921708185, Aging Rate = 0.4991103202846975, Precision = 0.9964349376114082, f1 = 0.9955476402493321\n",
      "Epoch 7: Train Loss = 0.00982635084446851, Recall = 0.9991103202846975, Aging Rate = 0.5004448398576512, Precision = 0.9982222222222222, f1 = 0.9986660738105825\n",
      "Epoch 8: Train Loss = 0.008529911311575314, Recall = 1.0, Aging Rate = 0.5011120996441281, Precision = 0.9977807367953839, f1 = 0.9988891357476116\n",
      "Epoch 9: Train Loss = 0.004838476780291607, Recall = 0.9995551601423488, Aging Rate = 0.5002224199288257, Precision = 0.9991107158737217, f1 = 0.9993328885923949\n",
      "Epoch 10: Train Loss = 0.00395618395273345, Recall = 0.9995551601423488, Aging Rate = 0.5, Precision = 0.9995551601423488, f1 = 0.9995551601423488\n",
      "Test Loss = 0.0032009715218514574, Recall = 0.9991103202846975, Aging Rate = 0.49955516014234874, precision = 1.0\n",
      "Model in epoch 10 is saved.\n",
      "\n",
      "Epoch 11: Train Loss = 0.0033640772229792996, Recall = 0.9995551601423488, Aging Rate = 0.5, Precision = 0.9995551601423488, f1 = 0.9995551601423488\n",
      "Epoch 12: Train Loss = 0.0029115438340331207, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 13: Train Loss = 0.0027955570995635303, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 14: Train Loss = 0.0023021308491437352, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 15: Train Loss = 0.0022645418033388266, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0021295960233596507, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "Model in epoch 15 is saved.\n",
      "\n",
      "Epoch 16: Train Loss = 0.0030610216070990678, Recall = 1.0, Aging Rate = 0.5002224199288257, Precision = 0.9995553579368608, f1 = 0.9997776295307983\n",
      "Epoch 17: Train Loss = 0.0028304813174510977, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 18: Train Loss = 0.003553852391697705, Recall = 1.0, Aging Rate = 0.5002224199288257, Precision = 0.9995553579368608, f1 = 0.9997776295307983\n",
      "Epoch 19: Train Loss = 0.00396766666127402, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 20: Train Loss = 0.0022947914435219987, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0016028036255086192, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 21: Train Loss = 0.001622593709353848, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 22: Train Loss = 0.0015264185418099748, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 23: Train Loss = 0.0030825865484800626, Recall = 0.9995551601423488, Aging Rate = 0.4997775800711744, Precision = 0, f1 = 0.0\n",
      "Epoch 24: Train Loss = 0.023784377121654907, Recall = 0.9937722419928826, Aging Rate = 0.501779359430605, Precision = 0.9902482269503546, f1 = 0.9920071047957372\n",
      "Epoch 25: Train Loss = 0.051445299692392296, Recall = 0.9853202846975089, Aging Rate = 0.505338078291815, Precision = 0.9749119718309859, f1 = 0.9800884955752212\n",
      "Test Loss = 0.022705088913096017, Recall = 0.9955516014234875, Aging Rate = 0.5028914590747331, precision = 0.9898275099513489\n",
      "\n",
      "Epoch 26: Train Loss = 0.022556001081747032, Recall = 0.994661921708185, Aging Rate = 0.5024466192170819, Precision = 0.9898185037627268, f1 = 0.992234302196583\n",
      "Epoch 27: Train Loss = 0.006390691907401942, Recall = 0.9977758007117438, Aging Rate = 0.49933274021352314, Precision = 0.9991091314031181, f1 = 0.9984420209214333\n",
      "Epoch 28: Train Loss = 0.004630541735704909, Recall = 0.9977758007117438, Aging Rate = 0.4997775800711744, Precision = 0.9982198486871384, f1 = 0.9979977753058954\n",
      "Epoch 29: Train Loss = 0.005456340021546598, Recall = 0.9991103202846975, Aging Rate = 0.5004448398576512, Precision = 0.9982222222222222, f1 = 0.9986660738105825\n",
      "Epoch 30: Train Loss = 0.0012409759627810921, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0006150682181288949, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 31: Train Loss = 0.0005714670030791246, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 32: Train Loss = 0.000592856731736416, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 33: Train Loss = 0.0006803393459653489, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 34: Train Loss = 0.0007753430107969698, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 35: Train Loss = 0.0009109883998384786, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0008308934455893244, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 36: Train Loss = 0.0009939285478673982, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 37: Train Loss = 0.001103262628513153, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 38: Train Loss = 0.0012148001750772056, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 39: Train Loss = 0.0012952951520509037, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 40: Train Loss = 0.0013964636861578663, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.00121942197065469, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 41: Train Loss = 0.0016289801586227115, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 42: Train Loss = 0.003284222099777175, Recall = 1.0, Aging Rate = 0.5004448398576512, Precision = 0.9991111111111111, f1 = 0.9995553579368608\n",
      "Epoch 43: Train Loss = 0.02006517789986157, Recall = 0.9933274021352313, Aging Rate = 0.5004448398576512, Precision = 0.9924444444444445, f1 = 0.9928857269897732\n",
      "Epoch 44: Train Loss = 0.024189201099102078, Recall = 0.9942170818505338, Aging Rate = 0.5020017793594306, Precision = 0.9902525476295968, f1 = 0.9922308546059934\n",
      "Epoch 45: Train Loss = 0.009827009274614345, Recall = 0.9977758007117438, Aging Rate = 0.5008896797153025, Precision = 0.9960035523978685, f1 = 0.9968888888888889\n",
      "Test Loss = 0.006128692713117553, Recall = 0.9973309608540926, Aging Rate = 0.4988879003558719, precision = 0.9995541685242978\n",
      "\n",
      "Epoch 46: Train Loss = 0.010504000013598053, Recall = 0.998220640569395, Aging Rate = 0.5011120996441281, Precision = 0.996005326231691, f1 = 0.9971117529437902\n",
      "Epoch 47: Train Loss = 0.002617358476970862, Recall = 1.0, Aging Rate = 0.5002224199288257, Precision = 0.9995553579368608, f1 = 0.9997776295307983\n",
      "Epoch 48: Train Loss = 0.0010466291509101373, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 49: Train Loss = 0.0060483650055803435, Recall = 0.9991103202846975, Aging Rate = 0.5004448398576512, Precision = 0.9982222222222222, f1 = 0.9986660738105825\n",
      "Epoch 50: Train Loss = 0.003124817514591569, Recall = 0.9991103202846975, Aging Rate = 0.5, Precision = 0.9991103202846975, f1 = 0.9991103202846975\n",
      "Test Loss = 0.0021542724890193615, Recall = 0.9995551601423488, Aging Rate = 0.5, precision = 0.9995551601423488\n",
      "\n",
      "Epoch 51: Train Loss = 0.0012003622051772538, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 52: Train Loss = 0.0005709171373673857, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 53: Train Loss = 0.0005876187308031894, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 54: Train Loss = 0.0007139001705756682, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 55: Train Loss = 0.0008969047138702748, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.000924449608730835, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 56: Train Loss = 0.0010374192487335766, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57: Train Loss = 0.0010980084630432024, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 58: Train Loss = 0.0011524007236419305, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 59: Train Loss = 0.0013768186534214698, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 60: Train Loss = 0.0013803055089835435, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0012461293092680254, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 61: Train Loss = 0.0014812005323347937, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 62: Train Loss = 0.001936356500586581, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 63: Train Loss = 0.003367217256790325, Recall = 0.9995551601423488, Aging Rate = 0.4997775800711744, Precision = 0, f1 = 0.0\n",
      "Epoch 64: Train Loss = 0.021426626310428586, Recall = 0.994661921708185, Aging Rate = 0.5008896797153025, Precision = 0.9928952042628775, f1 = 0.9937777777777778\n",
      "Epoch 65: Train Loss = 0.04679612399764969, Recall = 0.9897686832740213, Aging Rate = 0.5048932384341637, Precision = 0.9801762114537445, f1 = 0.9849490925188136\n",
      "Test Loss = 0.012145258441734794, Recall = 0.99644128113879, Aging Rate = 0.4984430604982206, precision = 0.999553770638108\n",
      "\n",
      "Training Finished at epoch 65.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "569d00fbd4bb4445b9065ce1727b3a8d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss = 0.33967391409483666, Recall = 0.9030249110320284, Aging Rate = 0.5629448398576512, Precision = 0.8020545239035954, f1 = 0.8495501150868382\n",
      "Epoch 2: Train Loss = 0.14177251074237757, Recall = 0.9555160142348754, Aging Rate = 0.505338078291815, Precision = 0.9454225352112676, f1 = 0.9504424778761063\n",
      "Epoch 3: Train Loss = 0.08955155708081357, Recall = 0.969306049822064, Aging Rate = 0.501779359430605, Precision = 0.9658687943262412, f1 = 0.9675843694493783\n",
      "Epoch 4: Train Loss = 0.05943104904476434, Recall = 0.9817615658362989, Aging Rate = 0.4997775800711744, Precision = 0.9821984868713841, f1 = 0.981979977753059\n",
      "Epoch 5: Train Loss = 0.052646502123290535, Recall = 0.9857651245551602, Aging Rate = 0.5024466192170819, Precision = 0.9809650287737938, f1 = 0.9833592189926781\n",
      "Test Loss = 0.018278036312965734, Recall = 0.9968861209964412, Aging Rate = 0.4991103202846975, precision = 0.9986631016042781\n",
      "Model in epoch 5 is saved.\n",
      "\n",
      "Epoch 6: Train Loss = 0.01824098671836202, Recall = 0.9968861209964412, Aging Rate = 0.5, Precision = 0.9968861209964412, f1 = 0.9968861209964412\n",
      "Epoch 7: Train Loss = 0.010849619663761285, Recall = 0.998220640569395, Aging Rate = 0.5, Precision = 0.998220640569395, f1 = 0.998220640569395\n",
      "Epoch 8: Train Loss = 0.0063429970726755274, Recall = 0.9991103202846975, Aging Rate = 0.4997775800711744, Precision = 0.9995549621717846, f1 = 0.9993325917686319\n",
      "Epoch 9: Train Loss = 0.004855233921546794, Recall = 0.9995551601423488, Aging Rate = 0.5, Precision = 0.9995551601423488, f1 = 0.9995551601423488\n",
      "Epoch 10: Train Loss = 0.0035203726783235726, Recall = 0.9995551601423488, Aging Rate = 0.5, Precision = 0.9995551601423488, f1 = 0.9995551601423488\n",
      "Test Loss = 0.003038891646646467, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "Model in epoch 10 is saved.\n",
      "\n",
      "Epoch 11: Train Loss = 0.0050626765187577845, Recall = 0.9991103202846975, Aging Rate = 0.5, Precision = 0.9991103202846975, f1 = 0.9991103202846975\n",
      "Epoch 12: Train Loss = 0.0050732355206058065, Recall = 0.9995551601423488, Aging Rate = 0.5002224199288257, Precision = 0.9991107158737217, f1 = 0.9993328885923949\n",
      "Epoch 13: Train Loss = 0.002782736712688865, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 14: Train Loss = 0.002152520073644048, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 15: Train Loss = 0.002230889849146013, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0017850571490154732, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 16: Train Loss = 0.0020310899681491227, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 17: Train Loss = 0.001949351188955411, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 18: Train Loss = 0.0025555016578579473, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 19: Train Loss = 0.002482853587087098, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 20: Train Loss = 0.02158223329198106, Recall = 0.9942170818505338, Aging Rate = 0.5028914590747331, Precision = 0.988500663423264, f1 = 0.9913506320691949\n",
      "Test Loss = 0.01378195335445561, Recall = 0.998220640569395, Aging Rate = 0.5024466192170819, precision = 0.9933598937583001\n",
      "\n",
      "Epoch 21: Train Loss = 0.02170455593075537, Recall = 0.9937722419928826, Aging Rate = 0.5015569395017794, Precision = 0.9906873614190688, f1 = 0.9922274039529204\n",
      "Epoch 22: Train Loss = 0.010502747719066742, Recall = 0.9968861209964412, Aging Rate = 0.5008896797153025, Precision = 0.9951154529307282, f1 = 0.9959999999999999\n",
      "Epoch 23: Train Loss = 0.004616579432388456, Recall = 0.9991103202846975, Aging Rate = 0.5, Precision = 0.9991103202846975, f1 = 0.9991103202846975\n",
      "Epoch 24: Train Loss = 0.002164914607367846, Recall = 1.0, Aging Rate = 0.5002224199288257, Precision = 0.9995553579368608, f1 = 0.9997776295307983\n",
      "Epoch 25: Train Loss = 0.0012746961723956746, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0008832446314097015, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 26: Train Loss = 0.0009962919004944243, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 27: Train Loss = 0.0007241461720165144, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 28: Train Loss = 0.0008398372012114291, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 29: Train Loss = 0.0010903495905781662, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 30: Train Loss = 0.0012874609243466097, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.001039872581497153, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 31: Train Loss = 0.0013602722876993574, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 32: Train Loss = 0.0014322743302847515, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 33: Train Loss = 0.001673685532192504, Recall = 0.9995551601423488, Aging Rate = 0.4997775800711744, Precision = 0, f1 = 0.0\n",
      "Epoch 34: Train Loss = 0.016019551833309366, Recall = 0.9959964412811388, Aging Rate = 0.5013345195729537, Precision = 0.9933451641526175, f1 = 0.994669035984007\n",
      "Epoch 35: Train Loss = 0.025000318638347355, Recall = 0.994661921708185, Aging Rate = 0.5031138790035588, Precision = 0.9885057471264368, f1 = 0.9915742793791574\n",
      "Test Loss = 0.09561762346031005, Recall = 0.9212633451957295, Aging Rate = 0.46063167259786475, precision = 1.0\n",
      "\n",
      "Epoch 36: Train Loss = 0.02149220398010759, Recall = 0.9933274021352313, Aging Rate = 0.5006672597864769, Precision = 0.9920035539760107, f1 = 0.9926650366748166\n",
      "Epoch 37: Train Loss = 0.008334341122573275, Recall = 0.9973309608540926, Aging Rate = 0.5006672597864769, Precision = 0.9960017769880053, f1 = 0.9966659257612803\n",
      "Epoch 38: Train Loss = 0.0029725827529112512, Recall = 1.0, Aging Rate = 0.5004448398576512, Precision = 0.9991111111111111, f1 = 0.9995553579368608\n",
      "Epoch 39: Train Loss = 0.004696280173286199, Recall = 0.9986654804270463, Aging Rate = 0.5, Precision = 0.9986654804270463, f1 = 0.9986654804270463\n",
      "Epoch 40: Train Loss = 0.0033635028141419804, Recall = 0.9991103202846975, Aging Rate = 0.5004448398576512, Precision = 0.9982222222222222, f1 = 0.9986660738105825\n",
      "Test Loss = 0.0009013437730213793, Recall = 0.9995551601423488, Aging Rate = 0.4997775800711744, precision = 1.0\n",
      "\n",
      "Epoch 41: Train Loss = 0.0011061490251087366, Recall = 0.9995551601423488, Aging Rate = 0.5, Precision = 0.9995551601423488, f1 = 0.9995551601423488\n",
      "Epoch 42: Train Loss = 0.0005943863837005325, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 43: Train Loss = 0.000599731723496233, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 44: Train Loss = 0.0006662090125641192, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 45: Train Loss = 0.0008044950514899242, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0007781772795580726, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 46: Train Loss = 0.000932155741362922, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 47: Train Loss = 0.0009989731719724012, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 48: Train Loss = 0.001195598397821559, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 49: Train Loss = 0.0012029988531295037, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 50: Train Loss = 0.0013009570190994552, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0011927477114964807, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 51: Train Loss = 0.0014078846117199873, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 52: Train Loss = 0.0013565624164238413, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 53: Train Loss = 0.0017917668435505501, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 54: Train Loss = 0.0025610251980253706, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 55: Train Loss = 0.04211031475843484, Recall = 0.9893238434163701, Aging Rate = 0.5046708185053381, Precision = 0.9801674746584399, f1 = 0.9847243745849015\n",
      "Test Loss = 0.019532793342364536, Recall = 0.9924377224199288, Aging Rate = 0.49777580071174377, precision = 0.9968722073279714\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 56: Train Loss = 0.029707511661580872, Recall = 0.9919928825622776, Aging Rate = 0.5020017793594306, Precision = 0.9880372175454143, f1 = 0.9900110987791343\n",
      "Epoch 57: Train Loss = 0.012723309574549308, Recall = 0.9973309608540926, Aging Rate = 0.501779359430605, Precision = 0.9937943262411347, f1 = 0.9955595026642984\n",
      "Epoch 58: Train Loss = 0.0053875919686650255, Recall = 0.9991103202846975, Aging Rate = 0.5008896797153025, Precision = 0.9973357015985791, f1 = 0.9982222222222222\n",
      "Epoch 59: Train Loss = 0.0018145088280395363, Recall = 0.9995551601423488, Aging Rate = 0.4997775800711744, Precision = 0, f1 = 0.0\n",
      "Epoch 60: Train Loss = 0.001654473062334549, Recall = 0.9995551601423488, Aging Rate = 0.5, Precision = 0.9995551601423488, f1 = 0.9995551601423488\n",
      "Test Loss = 0.0006204164542218014, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Training Finished at epoch 60.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b156d6dbc2b4445cac44e14beb3ebb37",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss = 0.5258270373760169, Recall = 0.7339857651245552, Aging Rate = 0.4472864768683274, Precision = 0.8204873197414222, f1 = 0.7748297722470063\n",
      "Epoch 2: Train Loss = 0.2780466042061293, Recall = 0.9083629893238434, Aging Rate = 0.50355871886121, Precision = 0.9019434628975265, f1 = 0.9051418439716311\n",
      "Epoch 3: Train Loss = 0.1941535411886473, Recall = 0.9395017793594306, Aging Rate = 0.4988879003558719, Precision = 0.9415960766830138, f1 = 0.9405477621910486\n",
      "Epoch 4: Train Loss = 0.15175532499242084, Recall = 0.9488434163701067, Aging Rate = 0.4913256227758007, Precision = 0.9655952919873246, f1 = 0.957146062373794\n",
      "Epoch 5: Train Loss = 0.12354195332718065, Recall = 0.9568505338078291, Aging Rate = 0.49110320284697506, Precision = 0.9741847826086957, f1 = 0.9654398563734291\n",
      "Test Loss = 0.09680769243857615, Recall = 0.9741992882562278, Aging Rate = 0.49755338078291816, precision = 0.9789897183728208\n",
      "Model in epoch 5 is saved.\n",
      "\n",
      "Epoch 6: Train Loss = 0.08946218981914673, Recall = 0.9701957295373665, Aging Rate = 0.4915480427046263, Precision = 0.9868778280542987, f1 = 0.9784656796769853\n",
      "Epoch 7: Train Loss = 0.07145819135567047, Recall = 0.9755338078291815, Aging Rate = 0.49110320284697506, Precision = 0.9932065217391305, f1 = 0.9842908438061041\n",
      "Epoch 8: Train Loss = 0.0578223436381469, Recall = 0.9813167259786477, Aging Rate = 0.4928825622775801, Precision = 0.9954873646209387, f1 = 0.9883512544802867\n",
      "Epoch 9: Train Loss = 0.047556212337627954, Recall = 0.9848754448398577, Aging Rate = 0.4944395017793594, Precision = 0.9959514170040485, f1 = 0.9903824647729814\n",
      "Epoch 10: Train Loss = 0.03924349021312393, Recall = 0.9879893238434164, Aging Rate = 0.49555160142348753, Precision = 0.9968581687612208, f1 = 0.9924039320822162\n",
      "Test Loss = 0.033757041380790415, Recall = 0.9924377224199288, Aging Rate = 0.49777580071174377, precision = 0.9968722073279714\n",
      "Model in epoch 10 is saved.\n",
      "\n",
      "Epoch 11: Train Loss = 0.033803011015640885, Recall = 0.9906583629893239, Aging Rate = 0.49666370106761565, Precision = 0.9973130317957905, f1 = 0.9939745592501674\n",
      "Epoch 12: Train Loss = 0.027723981803316238, Recall = 0.9915480427046264, Aging Rate = 0.4962188612099644, Precision = 0.9991035410129987, f1 = 0.9953114534494307\n",
      "Epoch 13: Train Loss = 0.02364829980049057, Recall = 0.9937722419928826, Aging Rate = 0.4973309608540925, Precision = 0.9991055456171736, f1 = 0.9964317573595005\n",
      "Epoch 14: Train Loss = 0.020009015073661703, Recall = 0.9951067615658363, Aging Rate = 0.4979982206405694, Precision = 0.9991067440821796, f1 = 0.9971027412525072\n",
      "Epoch 15: Train Loss = 0.01723303145221915, Recall = 0.9959964412811388, Aging Rate = 0.498220640569395, Precision = 0.9995535714285714, f1 = 0.99777183600713\n",
      "Test Loss = 0.016507485036297412, Recall = 0.9991103202846975, Aging Rate = 0.5, precision = 0.9991103202846975\n",
      "Model in epoch 15 is saved.\n",
      "\n",
      "Epoch 16: Train Loss = 0.0148533369295193, Recall = 0.9977758007117438, Aging Rate = 0.4991103202846975, Precision = 0.999554367201426, f1 = 0.9986642920747996\n",
      "Epoch 17: Train Loss = 0.013422876054560268, Recall = 0.9977758007117438, Aging Rate = 0.49933274021352314, Precision = 0.9991091314031181, f1 = 0.9984420209214333\n",
      "Epoch 18: Train Loss = 0.011424706978690264, Recall = 0.9986654804270463, Aging Rate = 0.49955516014234874, Precision = 0.9995547640249333, f1 = 0.9991099243435693\n",
      "Epoch 19: Train Loss = 0.009872880857106418, Recall = 0.9991103202846975, Aging Rate = 0.49955516014234874, Precision = 0, f1 = 0.0\n",
      "Epoch 20: Train Loss = 0.008945669818941331, Recall = 0.9991103202846975, Aging Rate = 0.4997775800711744, Precision = 0.9995549621717846, f1 = 0.9993325917686319\n",
      "Test Loss = 0.007699561300372632, Recall = 0.9995551601423488, Aging Rate = 0.4997775800711744, precision = 1.0\n",
      "Model in epoch 20 is saved.\n",
      "\n",
      "Epoch 21: Train Loss = 0.008357651138121388, Recall = 0.9991103202846975, Aging Rate = 0.4997775800711744, Precision = 0.9995549621717846, f1 = 0.9993325917686319\n",
      "Epoch 22: Train Loss = 0.007741887080963714, Recall = 0.9991103202846975, Aging Rate = 0.49955516014234874, Precision = 0, f1 = 0.0\n",
      "Epoch 23: Train Loss = 0.006605831389166282, Recall = 0.9991103202846975, Aging Rate = 0.49955516014234874, Precision = 0, f1 = 0.0\n",
      "Epoch 24: Train Loss = 0.00571881772890634, Recall = 0.9995551601423488, Aging Rate = 0.4997775800711744, Precision = 0, f1 = 0.0\n",
      "Epoch 25: Train Loss = 0.005577323009140683, Recall = 0.9995551601423488, Aging Rate = 0.4997775800711744, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0046075435472963866, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "Model in epoch 25 is saved.\n",
      "\n",
      "Epoch 26: Train Loss = 0.004935965446582946, Recall = 0.9995551601423488, Aging Rate = 0.4997775800711744, Precision = 0, f1 = 0.0\n",
      "Epoch 27: Train Loss = 0.004693832822240147, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 28: Train Loss = 0.00422077254952326, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 29: Train Loss = 0.004063543035844308, Recall = 0.9995551601423488, Aging Rate = 0.4997775800711744, Precision = 0, f1 = 0.0\n",
      "Epoch 30: Train Loss = 0.0037638289196038903, Recall = 0.9995551601423488, Aging Rate = 0.4997775800711744, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.003371441510408202, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 31: Train Loss = 0.003564093068484018, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 32: Train Loss = 0.0032899185312494266, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 33: Train Loss = 0.0031350585419702877, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 34: Train Loss = 0.0031074198709429637, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 35: Train Loss = 0.0027418698942756076, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0022989809910809868, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 36: Train Loss = 0.002611952669358418, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 37: Train Loss = 0.0024134852733708307, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 38: Train Loss = 0.0024382985177121763, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 39: Train Loss = 0.0024369882247361, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 40: Train Loss = 0.002472694488648272, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0019589360874623487, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 41: Train Loss = 0.0022609836802638906, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 42: Train Loss = 0.0020736098213674785, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 43: Train Loss = 0.0019585390351928135, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 44: Train Loss = 0.002168596825757962, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 45: Train Loss = 0.0019298769988109659, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.002329802427696084, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 46: Train Loss = 0.0020641719456762075, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 47: Train Loss = 0.0018774423262707598, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 48: Train Loss = 0.001852010272143349, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 49: Train Loss = 0.001802592600026297, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 50: Train Loss = 0.0018448123956526698, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0016148980488185356, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 51: Train Loss = 0.0017121369694442458, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 52: Train Loss = 0.001826752378755279, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 53: Train Loss = 0.00175764718655583, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 54: Train Loss = 0.001692506069258631, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 55: Train Loss = 0.001861421476711529, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.001635180734880136, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 56: Train Loss = 0.00154793885469377, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57: Train Loss = 0.0017037487313734678, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 58: Train Loss = 0.0018608873828937335, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 59: Train Loss = 0.0024515660829739347, Recall = 0.9995551601423488, Aging Rate = 0.4997775800711744, Precision = 0, f1 = 0.0\n",
      "Epoch 60: Train Loss = 0.003070113079264442, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0015299942725987648, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 61: Train Loss = 0.0014463449180792368, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 62: Train Loss = 0.0013650228674158959, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 63: Train Loss = 0.001447271006728698, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 64: Train Loss = 0.0012662542185968193, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 65: Train Loss = 0.0013561669182574237, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0012739544609657678, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 66: Train Loss = 0.0014543269926208168, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 67: Train Loss = 0.0016049532076009149, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 68: Train Loss = 0.0014802212944980114, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 69: Train Loss = 0.0015837792663427328, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 70: Train Loss = 0.0015965701537405629, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0013870166391349692, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 71: Train Loss = 0.001938186429301774, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 72: Train Loss = 0.002679307585055161, Recall = 0.9995551601423488, Aging Rate = 0.5, Precision = 0.9995551601423488, f1 = 0.9995551601423488\n",
      "Epoch 73: Train Loss = 0.0015016907775937, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 74: Train Loss = 0.0012974989041396056, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 75: Train Loss = 0.0012701838853142599, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0011513741279693711, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Training Finished at epoch 75.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b623cd78bcb4899ae4ef7b313e66054",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss = 0.5262421291069628, Recall = 0.7237544483985765, Aging Rate = 0.4544039145907473, Precision = 0.7963778756730299, f1 = 0.7583313912840831\n",
      "Epoch 2: Train Loss = 0.29456506303620933, Recall = 0.8945729537366548, Aging Rate = 0.4997775800711744, Precision = 0.894971072541166, f1 = 0.8947719688542826\n",
      "Epoch 3: Train Loss = 0.21096751024926685, Recall = 0.9234875444839857, Aging Rate = 0.49532918149466193, Precision = 0.9321957790749887, f1 = 0.9278212290502793\n",
      "Epoch 4: Train Loss = 0.17001076403249626, Recall = 0.9354982206405694, Aging Rate = 0.48954626334519574, Precision = 0.955474784189005, f1 = 0.9453809844908969\n",
      "Epoch 5: Train Loss = 0.14329042017884103, Recall = 0.9461743772241993, Aging Rate = 0.49088078291814946, Precision = 0.9637516991391029, f1 = 0.9548821548821548\n",
      "Test Loss = 0.111391697065686, Recall = 0.969306049822064, Aging Rate = 0.5, precision = 0.969306049822064\n",
      "Model in epoch 5 is saved.\n",
      "\n",
      "Epoch 6: Train Loss = 0.10359913651629275, Recall = 0.9621886120996441, Aging Rate = 0.491770462633452, Precision = 0.9782903663500678, f1 = 0.9701726844583988\n",
      "Epoch 7: Train Loss = 0.08498652431835484, Recall = 0.9661921708185054, Aging Rate = 0.4902135231316726, Precision = 0.985480943738657, f1 = 0.9757412398921833\n",
      "Epoch 8: Train Loss = 0.06996890524687292, Recall = 0.972864768683274, Aging Rate = 0.4922153024911032, Precision = 0.9882512426570267, f1 = 0.9804976462676529\n",
      "Epoch 9: Train Loss = 0.058076336290488466, Recall = 0.9773131672597865, Aging Rate = 0.49266014234875444, Precision = 0.9918735891647855, f1 = 0.9845395473896482\n",
      "Epoch 10: Train Loss = 0.04730494119876538, Recall = 0.9826512455516014, Aging Rate = 0.49377224199288255, Precision = 0.9950450450450451, f1 = 0.9888093106535362\n",
      "Test Loss = 0.03978815317498619, Recall = 0.9870996441281139, Aging Rate = 0.4942170818505338, precision = 0.9986498649864987\n",
      "Model in epoch 10 is saved.\n",
      "\n",
      "Epoch 11: Train Loss = 0.03970144554521902, Recall = 0.9862099644128114, Aging Rate = 0.4951067615658363, Precision = 0.9959568733153639, f1 = 0.9910594546267323\n",
      "Epoch 12: Train Loss = 0.03311054463899327, Recall = 0.9902135231316725, Aging Rate = 0.4962188612099644, Precision = 0.9977588525324966, f1 = 0.9939718687206965\n",
      "Epoch 13: Train Loss = 0.028328217622356693, Recall = 0.9937722419928826, Aging Rate = 0.49755338078291816, Precision = 0.9986589181940099, f1 = 0.9962095875139354\n",
      "Epoch 14: Train Loss = 0.023834213594577915, Recall = 0.9955516014234875, Aging Rate = 0.4979982206405694, Precision = 0.9995533720410897, f1 = 0.9975484733675061\n",
      "Epoch 15: Train Loss = 0.02038557183501241, Recall = 0.9968861209964412, Aging Rate = 0.4984430604982206, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.01687658461659245, Recall = 0.998220640569395, Aging Rate = 0.4991103202846975, precision = 1.0\n",
      "Model in epoch 15 is saved.\n",
      "\n",
      "Epoch 16: Train Loss = 0.01776758396958276, Recall = 0.9977758007117438, Aging Rate = 0.4991103202846975, Precision = 0.999554367201426, f1 = 0.9986642920747996\n",
      "Epoch 17: Train Loss = 0.015003936119158868, Recall = 0.9995551601423488, Aging Rate = 0.4997775800711744, Precision = 0, f1 = 0.0\n",
      "Epoch 18: Train Loss = 0.013006730974582272, Recall = 0.9995551601423488, Aging Rate = 0.4997775800711744, Precision = 0, f1 = 0.0\n",
      "Epoch 19: Train Loss = 0.011615661161809206, Recall = 0.9995551601423488, Aging Rate = 0.4997775800711744, Precision = 0, f1 = 0.0\n",
      "Epoch 20: Train Loss = 0.009865744036930578, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.008501477864342228, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "Model in epoch 20 is saved.\n",
      "\n",
      "Epoch 21: Train Loss = 0.008770577580538773, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 22: Train Loss = 0.0078062618572225136, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 23: Train Loss = 0.007103816658304838, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 24: Train Loss = 0.006362740112819918, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 25: Train Loss = 0.005590247287782857, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.005164397089142233, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 26: Train Loss = 0.005162702129699714, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 27: Train Loss = 0.004798236540833561, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 28: Train Loss = 0.0043750876988353895, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 29: Train Loss = 0.0039812649125432155, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 30: Train Loss = 0.0038731311061800692, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.003369251325779538, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 31: Train Loss = 0.00341903567115289, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 32: Train Loss = 0.003282324312374102, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 33: Train Loss = 0.00312085529404868, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 34: Train Loss = 0.00283553018201527, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 35: Train Loss = 0.0026765947182102665, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0024340751709737997, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 36: Train Loss = 0.0025427191695562993, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 37: Train Loss = 0.0024959499658967015, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 38: Train Loss = 0.0024706034782737015, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 39: Train Loss = 0.0023110312056724394, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 40: Train Loss = 0.0022022691335747834, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.002069785022690521, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 41: Train Loss = 0.0021481530374625295, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 42: Train Loss = 0.00206824287555091, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 43: Train Loss = 0.002163625098358893, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 44: Train Loss = 0.001966671000468442, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 45: Train Loss = 0.002025971433157731, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0024617939045672634, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 46: Train Loss = 0.002206614297968783, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 47: Train Loss = 0.0018718891876113345, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 48: Train Loss = 0.0017658663210144193, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 49: Train Loss = 0.0017452983415993826, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 50: Train Loss = 0.0017199661264534099, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.001506953043871463, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 51: Train Loss = 0.004320309105083956, Recall = 0.9995551601423488, Aging Rate = 0.5, Precision = 0.9995551601423488, f1 = 0.9995551601423488\n",
      "Epoch 52: Train Loss = 0.001782883270817653, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 53: Train Loss = 0.0014874127115954868, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 54: Train Loss = 0.0014369636055271, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 55: Train Loss = 0.0014533073727532, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0013046887942699192, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 56: Train Loss = 0.0015106903017478668, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 57: Train Loss = 0.0015658338821834463, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 58: Train Loss = 0.0016278985553641481, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 59: Train Loss = 0.0016535811038817082, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 60: Train Loss = 0.001526752181079411, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss = 0.0014518105192524232, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 61: Train Loss = 0.0015859299820344033, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 62: Train Loss = 0.0016971026594689268, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 63: Train Loss = 0.0018646952402413396, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 64: Train Loss = 0.0018513079859429037, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 65: Train Loss = 0.0015361663621097962, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0016947406355715838, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 66: Train Loss = 0.001605538531824668, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 67: Train Loss = 0.0016248090833995584, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 68: Train Loss = 0.0014038800568074597, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 69: Train Loss = 0.0014141742392771238, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 70: Train Loss = 0.0015022837775643398, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.001439928754938773, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Training Finished at epoch 70.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "033740ae5b6f462f9ca2296556433aa1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss = 0.5396175325128956, Recall = 0.7402135231316725, Aging Rate = 0.4695284697508897, Precision = 0.788252013263856, f1 = 0.7634778618949299\n",
      "Epoch 2: Train Loss = 0.30081009843595513, Recall = 0.8981316725978647, Aging Rate = 0.5026690391459074, Precision = 0.893362831858407, f1 = 0.8957409050576752\n",
      "Epoch 3: Train Loss = 0.22189847607947755, Recall = 0.9306049822064056, Aging Rate = 0.5, Precision = 0.9306049822064056, f1 = 0.9306049822064056\n",
      "Epoch 4: Train Loss = 0.17161144591947466, Recall = 0.9412811387900356, Aging Rate = 0.49377224199288255, Precision = 0.9531531531531532, f1 = 0.9471799462846913\n",
      "Epoch 5: Train Loss = 0.1391358219643929, Recall = 0.9479537366548043, Aging Rate = 0.4891014234875445, Precision = 0.9690768531150523, f1 = 0.9583989206206432\n",
      "Test Loss = 0.1092473353222808, Recall = 0.9470640569395018, Aging Rate = 0.4795373665480427, precision = 0.9874768089053804\n",
      "Model in epoch 5 is saved.\n",
      "\n",
      "Epoch 6: Train Loss = 0.10276110577678765, Recall = 0.9568505338078291, Aging Rate = 0.48687722419928825, Precision = 0.9826404751027866, f1 = 0.9695740365111563\n",
      "Epoch 7: Train Loss = 0.08222740130280261, Recall = 0.9724199288256228, Aging Rate = 0.49266014234875444, Precision = 0.9869074492099322, f1 = 0.9796101277167825\n",
      "Epoch 8: Train Loss = 0.06557786049738898, Recall = 0.9759786476868327, Aging Rate = 0.49243772241992884, Precision = 0.99096657633243, f1 = 0.9834155087404752\n",
      "Epoch 9: Train Loss = 0.05305773497714903, Recall = 0.979982206405694, Aging Rate = 0.4942170818505338, Precision = 0.9914491449144914, f1 = 0.985682326621924\n",
      "Epoch 10: Train Loss = 0.04369410016703224, Recall = 0.983540925266904, Aging Rate = 0.49377224199288255, Precision = 0.995945945945946, f1 = 0.9897045658012533\n",
      "Test Loss = 0.03598037534443085, Recall = 0.9893238434163701, Aging Rate = 0.49555160142348753, precision = 0.9982046678635548\n",
      "Model in epoch 10 is saved.\n",
      "\n",
      "Epoch 11: Train Loss = 0.036333193147415795, Recall = 0.9888790035587188, Aging Rate = 0.4957740213523132, Precision = 0.9973082099596231, f1 = 0.9930757203484476\n",
      "Epoch 12: Train Loss = 0.030155637931224503, Recall = 0.9951067615658363, Aging Rate = 0.4991103202846975, Precision = 0.9968805704099821, f1 = 0.9959928762243989\n",
      "Epoch 13: Train Loss = 0.0257442862232915, Recall = 0.994661921708185, Aging Rate = 0.49777580071174377, Precision = 0.9991063449508489, f1 = 0.9968791796700847\n",
      "Epoch 14: Train Loss = 0.022274009863517887, Recall = 0.9959964412811388, Aging Rate = 0.4986654804270463, Precision = 0.9986619090098127, f1 = 0.997327394209354\n",
      "Epoch 15: Train Loss = 0.018760711627472126, Recall = 0.9973309608540926, Aging Rate = 0.4988879003558719, Precision = 0.9995541685242978, f1 = 0.9984413270986416\n",
      "Test Loss = 0.015681502570023636, Recall = 0.9991103202846975, Aging Rate = 0.4997775800711744, precision = 0.9995549621717846\n",
      "Model in epoch 15 is saved.\n",
      "\n",
      "Epoch 16: Train Loss = 0.01615951748836613, Recall = 0.9986654804270463, Aging Rate = 0.49955516014234874, Precision = 0.9995547640249333, f1 = 0.9991099243435693\n",
      "Epoch 17: Train Loss = 0.014346383455676752, Recall = 0.998220640569395, Aging Rate = 0.49933274021352314, Precision = 0.999554565701559, f1 = 0.9988871578010238\n",
      "Epoch 18: Train Loss = 0.012172509579723734, Recall = 0.9995551601423488, Aging Rate = 0.5, Precision = 0.9995551601423488, f1 = 0.9995551601423488\n",
      "Epoch 19: Train Loss = 0.010941558189398454, Recall = 0.9986654804270463, Aging Rate = 0.49955516014234874, Precision = 0.9995547640249333, f1 = 0.9991099243435693\n",
      "Epoch 20: Train Loss = 0.009218424643983142, Recall = 0.9991103202846975, Aging Rate = 0.49955516014234874, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.009471551520133464, Recall = 0.9995551601423488, Aging Rate = 0.4997775800711744, precision = 1.0\n",
      "Model in epoch 20 is saved.\n",
      "\n",
      "Epoch 21: Train Loss = 0.008390900137870708, Recall = 0.9995551601423488, Aging Rate = 0.4997775800711744, Precision = 0, f1 = 0.0\n",
      "Epoch 22: Train Loss = 0.00759430368036509, Recall = 0.9995551601423488, Aging Rate = 0.4997775800711744, Precision = 0, f1 = 0.0\n",
      "Epoch 23: Train Loss = 0.006736926836776962, Recall = 0.9995551601423488, Aging Rate = 0.4997775800711744, Precision = 0, f1 = 0.0\n",
      "Epoch 24: Train Loss = 0.0059131790846138794, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 25: Train Loss = 0.005535260840481499, Recall = 0.9995551601423488, Aging Rate = 0.4997775800711744, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0048726041870874445, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "Model in epoch 25 is saved.\n",
      "\n",
      "Epoch 26: Train Loss = 0.004873203738837825, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 27: Train Loss = 0.004497996166023655, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 28: Train Loss = 0.004154884087806733, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 29: Train Loss = 0.0038368982773313953, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 30: Train Loss = 0.003583782831839952, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0031253421389965137, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 31: Train Loss = 0.0033588942813146793, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 32: Train Loss = 0.0031366306555944616, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 33: Train Loss = 0.00304603853736908, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 34: Train Loss = 0.0028531271392592226, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 35: Train Loss = 0.002717678731260158, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0024215091542702074, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 36: Train Loss = 0.0025490053355183414, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 37: Train Loss = 0.0024527325127124654, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 38: Train Loss = 0.0024920730114984077, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 39: Train Loss = 0.002294152491606666, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 40: Train Loss = 0.0021080616954796917, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0020191693654469482, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 41: Train Loss = 0.002270197021042484, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 42: Train Loss = 0.002109434876136906, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 43: Train Loss = 0.0019803423649097838, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 44: Train Loss = 0.0018974750433647441, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 45: Train Loss = 0.0020362355201952557, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0016791082840343255, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 46: Train Loss = 0.0019988128138636488, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 47: Train Loss = 0.0018099742208058977, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 48: Train Loss = 0.0018128957514472147, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 49: Train Loss = 0.0018147889498183736, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 50: Train Loss = 0.0018521160534848177, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0016108563756470791, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 51: Train Loss = 0.0018478026893238447, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 52: Train Loss = 0.0030294189602882333, Recall = 1.0, Aging Rate = 0.5002224199288257, Precision = 0.9995553579368608, f1 = 0.9997776295307983\n",
      "Epoch 53: Train Loss = 0.0017082133755879974, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 54: Train Loss = 0.00151450285423726, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 55: Train Loss = 0.001521520335036678, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0014477468707210972, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 56: Train Loss = 0.0015990035991628531, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 57: Train Loss = 0.0016210916449209789, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58: Train Loss = 0.0016535997862622699, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 59: Train Loss = 0.0016042338135267783, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 60: Train Loss = 0.0016827419772247033, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0016808137055271011, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 61: Train Loss = 0.0021237926617732068, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 62: Train Loss = 0.0022739378730865906, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 63: Train Loss = 0.0016499405952163863, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 64: Train Loss = 0.0013181639150003787, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 65: Train Loss = 0.0013337936878968296, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.001315452245866144, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 66: Train Loss = 0.0014099017824659463, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 67: Train Loss = 0.0017967660641264554, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 68: Train Loss = 0.001508981297273202, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 69: Train Loss = 0.0014949589319364748, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 70: Train Loss = 0.0014285926236456187, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0013173684248704053, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 71: Train Loss = 0.0016347841662934773, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 72: Train Loss = 0.002012570869397982, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 73: Train Loss = 0.004052452891576187, Recall = 0.9995551601423488, Aging Rate = 0.5, Precision = 0.9995551601423488, f1 = 0.9995551601423488\n",
      "Epoch 74: Train Loss = 0.0037794857200158898, Recall = 0.9995551601423488, Aging Rate = 0.5, Precision = 0.9995551601423488, f1 = 0.9995551601423488\n",
      "Epoch 75: Train Loss = 0.001260720833670348, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0010843514037041783, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Training Finished at epoch 75.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e8c79e00c9804fa1b51ec5665fcdb588",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss = 0.5417583434182979, Recall = 0.702846975088968, Aging Rate = 0.4435053380782918, Precision = 0.7923771313941825, f1 = 0.7449316360207449\n",
      "Epoch 2: Train Loss = 0.28994352290957, Recall = 0.9025800711743772, Aging Rate = 0.5044483985765125, Precision = 0.894620811287478, f1 = 0.8985828166519043\n",
      "Epoch 3: Train Loss = 0.2054881103787558, Recall = 0.931049822064057, Aging Rate = 0.4939946619217082, Precision = 0.9423683025664116, f1 = 0.9366748713358694\n",
      "Epoch 4: Train Loss = 0.16429684287288435, Recall = 0.9443950177935944, Aging Rate = 0.4919928825622776, Precision = 0.9597649186256781, f1 = 0.952017937219731\n",
      "Epoch 5: Train Loss = 0.13392843417425596, Recall = 0.9537366548042705, Aging Rate = 0.49110320284697506, Precision = 0.9710144927536232, f1 = 0.96229802513465\n",
      "Test Loss = 0.10409494636586977, Recall = 0.9630782918149466, Aging Rate = 0.4891014234875445, precision = 0.9845384265575261\n",
      "Model in epoch 5 is saved.\n",
      "\n",
      "Epoch 6: Train Loss = 0.09835390625952402, Recall = 0.9635231316725978, Aging Rate = 0.48976868327402134, Precision = 0.9836512261580381, f1 = 0.9734831460674157\n",
      "Epoch 7: Train Loss = 0.08035459736647131, Recall = 0.9715302491103203, Aging Rate = 0.4915480427046263, Precision = 0.9882352941176471, f1 = 0.9798115746971735\n",
      "Epoch 8: Train Loss = 0.06673844999822645, Recall = 0.974644128113879, Aging Rate = 0.49243772241992884, Precision = 0.9896115627822945, f1 = 0.982070820259973\n",
      "Epoch 9: Train Loss = 0.055240357742111244, Recall = 0.978202846975089, Aging Rate = 0.4931049822064057, Precision = 0.9918809201623816, f1 = 0.9849944008958565\n",
      "Epoch 10: Train Loss = 0.04589329573103754, Recall = 0.9813167259786477, Aging Rate = 0.4931049822064057, Precision = 0.9950383400992332, f1 = 0.9881298992161255\n",
      "Test Loss = 0.03765704587526169, Recall = 0.9884341637010676, Aging Rate = 0.4959964412811388, precision = 0.9964125560538116\n",
      "Model in epoch 10 is saved.\n",
      "\n",
      "Epoch 11: Train Loss = 0.03846877414958545, Recall = 0.9848754448398577, Aging Rate = 0.4942170818505338, Precision = 0.9963996399639964, f1 = 0.9906040268456375\n",
      "Epoch 12: Train Loss = 0.03238892468401758, Recall = 0.9902135231316725, Aging Rate = 0.4973309608540925, Precision = 0.9955277280858676, f1 = 0.9928635147190009\n",
      "Epoch 13: Train Loss = 0.027363165720859773, Recall = 0.9928825622775801, Aging Rate = 0.49755338078291816, Precision = 0.997764863656683, f1 = 0.9953177257525084\n",
      "Epoch 14: Train Loss = 0.022793121672371318, Recall = 0.99644128113879, Aging Rate = 0.4988879003558719, Precision = 0.9986625055728935, f1 = 0.9975506568692941\n",
      "Epoch 15: Train Loss = 0.019403528180172224, Recall = 0.99644128113879, Aging Rate = 0.498220640569395, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.016097500090059755, Recall = 0.9991103202846975, Aging Rate = 0.49955516014234874, precision = 1.0\n",
      "Model in epoch 15 is saved.\n",
      "\n",
      "Epoch 16: Train Loss = 0.01660143185963728, Recall = 0.9977758007117438, Aging Rate = 0.49933274021352314, Precision = 0.9991091314031181, f1 = 0.9984420209214333\n",
      "Epoch 17: Train Loss = 0.01524983830186555, Recall = 0.998220640569395, Aging Rate = 0.49933274021352314, Precision = 0.999554565701559, f1 = 0.9988871578010238\n",
      "Epoch 18: Train Loss = 0.013188852913664435, Recall = 0.998220640569395, Aging Rate = 0.49933274021352314, Precision = 0.999554565701559, f1 = 0.9988871578010238\n",
      "Epoch 19: Train Loss = 0.011163193921416044, Recall = 0.9991103202846975, Aging Rate = 0.49955516014234874, Precision = 0, f1 = 0.0\n",
      "Epoch 20: Train Loss = 0.009885159386587048, Recall = 0.9991103202846975, Aging Rate = 0.49955516014234874, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.008949336967036606, Recall = 1.0, Aging Rate = 0.5002224199288257, precision = 0.9995553579368608\n",
      "Model in epoch 20 is saved.\n",
      "\n",
      "Epoch 21: Train Loss = 0.008725833107992423, Recall = 1.0, Aging Rate = 0.5002224199288257, Precision = 0.9995553579368608, f1 = 0.9997776295307983\n",
      "Epoch 22: Train Loss = 0.007636438039366779, Recall = 0.9995551601423488, Aging Rate = 0.5, Precision = 0.9995551601423488, f1 = 0.9995551601423488\n",
      "Epoch 23: Train Loss = 0.007143724470289947, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 24: Train Loss = 0.0061261253764942365, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 25: Train Loss = 0.005633940919405148, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.005343808697244928, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "Model in epoch 25 is saved.\n",
      "\n",
      "Epoch 26: Train Loss = 0.005255489877766508, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 27: Train Loss = 0.004662238276858559, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 28: Train Loss = 0.00435013453218443, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 29: Train Loss = 0.004072310801950081, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 30: Train Loss = 0.003825592340692692, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0033667675141589816, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 31: Train Loss = 0.003504813778847191, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 32: Train Loss = 0.0032819696860321634, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 33: Train Loss = 0.0031949731424364704, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 34: Train Loss = 0.0029214092317365404, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 35: Train Loss = 0.0029654259954204655, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0024627962504311387, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 36: Train Loss = 0.0027148178318727534, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 37: Train Loss = 0.0025772049542917503, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 38: Train Loss = 0.0024076654713309216, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 39: Train Loss = 0.002450088722410933, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 40: Train Loss = 0.0022387742454325283, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0020098954025288096, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 41: Train Loss = 0.0022065254200491855, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 42: Train Loss = 0.002339925177418544, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 43: Train Loss = 0.002203604414208968, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 44: Train Loss = 0.0020383242869855722, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 45: Train Loss = 0.0020304878741118303, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0019155829924065951, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 46: Train Loss = 0.0019070910400913173, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 47: Train Loss = 0.0019381312326962308, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 48: Train Loss = 0.002094148738795288, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 49: Train Loss = 0.001882326888836907, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 50: Train Loss = 0.0017457962307699515, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.001476385379814977, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 51: Train Loss = 0.0018201050654325461, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 52: Train Loss = 0.0017246484917628304, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 53: Train Loss = 0.0021374930260583654, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 54: Train Loss = 0.0018332001263875633, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 55: Train Loss = 0.001752451199746535, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.00164420023896927, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 56: Train Loss = 0.0032486156334692873, Recall = 0.9995551601423488, Aging Rate = 0.5, Precision = 0.9995551601423488, f1 = 0.9995551601423488\n",
      "Epoch 57: Train Loss = 0.0034696697322709746, Recall = 1.0, Aging Rate = 0.5002224199288257, Precision = 0.9995553579368608, f1 = 0.9997776295307983\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58: Train Loss = 0.0014059645061843507, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 59: Train Loss = 0.0014480788650544645, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 60: Train Loss = 0.0013871395196500516, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.00127499835011367, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 61: Train Loss = 0.0014684280656937683, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 62: Train Loss = 0.0015144051821965366, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 63: Train Loss = 0.0015031729967356577, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 64: Train Loss = 0.0016054497744632866, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 65: Train Loss = 0.0016700278881032458, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0013681300180413995, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 66: Train Loss = 0.0015551058647597334, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 67: Train Loss = 0.001617948164429277, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 68: Train Loss = 0.0016390686883513228, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 69: Train Loss = 0.0018478549082243145, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 70: Train Loss = 0.0015745251738835868, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0015548893770043907, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 71: Train Loss = 0.0017233703820303322, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 72: Train Loss = 0.001441386847523144, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 73: Train Loss = 0.0015766397491428883, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 74: Train Loss = 0.0016198766602574454, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 75: Train Loss = 0.0016053556287503766, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0013836254502457709, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Training Finished at epoch 75.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2323403baf5a452eb5276cd7830ccd02",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss = 0.5159579018044727, Recall = 0.7531138790035588, Aging Rate = 0.48287366548042704, Precision = 0.7798249654537079, f1 = 0.7662367051369088\n",
      "Epoch 2: Train Loss = 0.2984813101244991, Recall = 0.8959074733096085, Aging Rate = 0.5008896797153025, Precision = 0.894316163410302, f1 = 0.8951111111111111\n",
      "Epoch 3: Train Loss = 0.21753920702217314, Recall = 0.9279359430604982, Aging Rate = 0.4984430604982206, Precision = 0.930834448906738, f1 = 0.9293829360659389\n",
      "Epoch 4: Train Loss = 0.175238997513077, Recall = 0.9337188612099644, Aging Rate = 0.48821174377224197, Precision = 0.9562642369020501, f1 = 0.9448570785505289\n",
      "Epoch 5: Train Loss = 0.14451210452674546, Recall = 0.9479537366548043, Aging Rate = 0.49065836298932386, Precision = 0.9660018132366274, f1 = 0.9568926807364168\n",
      "Test Loss = 0.11262818232337775, Recall = 0.9644128113879004, Aging Rate = 0.4939946619217082, precision = 0.9761368752814048\n",
      "Model in epoch 5 is saved.\n",
      "\n",
      "Epoch 6: Train Loss = 0.10651777390377377, Recall = 0.9621886120996441, Aging Rate = 0.49266014234875444, Precision = 0.9765237020316027, f1 = 0.9693031593098812\n",
      "Epoch 7: Train Loss = 0.084209255012435, Recall = 0.9715302491103203, Aging Rate = 0.49266014234875444, Precision = 0.9860045146726862, f1 = 0.9787138695944432\n",
      "Epoch 8: Train Loss = 0.06821237399749909, Recall = 0.9764234875444839, Aging Rate = 0.49354982206405695, Precision = 0.9891843172600271, f1 = 0.9827624804119096\n",
      "Epoch 9: Train Loss = 0.05587944090764081, Recall = 0.9804270462633452, Aging Rate = 0.4939946619217082, Precision = 0.9923457901846016, f1 = 0.9863504139628552\n",
      "Epoch 10: Train Loss = 0.046902345884525055, Recall = 0.9870996441281139, Aging Rate = 0.49666370106761565, Precision = 0.9937304075235109, f1 = 0.990403927694711\n",
      "Test Loss = 0.03915219486183968, Recall = 0.9924377224199288, Aging Rate = 0.4991103202846975, precision = 0.9942067736185384\n",
      "Model in epoch 10 is saved.\n",
      "\n",
      "Epoch 11: Train Loss = 0.038877145655691836, Recall = 0.9902135231316725, Aging Rate = 0.49755338078291816, Precision = 0.9950827000447027, f1 = 0.9926421404682274\n",
      "Epoch 12: Train Loss = 0.03249161843594919, Recall = 0.9915480427046264, Aging Rate = 0.49755338078291816, Precision = 0.9964237818506929, f1 = 0.9939799331103679\n",
      "Epoch 13: Train Loss = 0.028366511127517105, Recall = 0.9937722419928826, Aging Rate = 0.4986654804270463, Precision = 0.9964317573595004, f1 = 0.9951002227171492\n",
      "Epoch 14: Train Loss = 0.024383515331668784, Recall = 0.9951067615658363, Aging Rate = 0.4984430604982206, Precision = 0.998215082552432, f1 = 0.996658498552016\n",
      "Epoch 15: Train Loss = 0.021262855726390334, Recall = 0.9959964412811388, Aging Rate = 0.4984430604982206, Precision = 0.9991075412762159, f1 = 0.9975495656048117\n",
      "Test Loss = 0.018983868325255095, Recall = 0.9991103202846975, Aging Rate = 0.5006672597864769, precision = 0.9977787649933363\n",
      "Model in epoch 15 is saved.\n",
      "\n",
      "Epoch 16: Train Loss = 0.019042253530720164, Recall = 0.9955516014234875, Aging Rate = 0.4984430604982206, Precision = 0.998661311914324, f1 = 0.9971040320784138\n",
      "Epoch 17: Train Loss = 0.015990274858883054, Recall = 0.9977758007117438, Aging Rate = 0.49933274021352314, Precision = 0.9991091314031181, f1 = 0.9984420209214333\n",
      "Epoch 18: Train Loss = 0.014009664915634644, Recall = 0.9977758007117438, Aging Rate = 0.4991103202846975, Precision = 0.999554367201426, f1 = 0.9986642920747996\n",
      "Epoch 19: Train Loss = 0.012168484140068186, Recall = 0.9991103202846975, Aging Rate = 0.4997775800711744, Precision = 0.9995549621717846, f1 = 0.9993325917686319\n",
      "Epoch 20: Train Loss = 0.010764123792378929, Recall = 0.998220640569395, Aging Rate = 0.4991103202846975, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.009102721904069716, Recall = 0.9995551601423488, Aging Rate = 0.4997775800711744, precision = 1.0\n",
      "Model in epoch 20 is saved.\n",
      "\n",
      "Epoch 21: Train Loss = 0.009705710952299452, Recall = 0.9986654804270463, Aging Rate = 0.49955516014234874, Precision = 0.9995547640249333, f1 = 0.9991099243435693\n",
      "Epoch 22: Train Loss = 0.008705316093630983, Recall = 0.9991103202846975, Aging Rate = 0.4997775800711744, Precision = 0.9995549621717846, f1 = 0.9993325917686319\n",
      "Epoch 23: Train Loss = 0.007676050658553203, Recall = 0.9995551601423488, Aging Rate = 0.4997775800711744, Precision = 0, f1 = 0.0\n",
      "Epoch 24: Train Loss = 0.007479437400696276, Recall = 0.9995551601423488, Aging Rate = 0.5, Precision = 0.9995551601423488, f1 = 0.9995551601423488\n",
      "Epoch 25: Train Loss = 0.006361243398727524, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0054046664655447215, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "Model in epoch 25 is saved.\n",
      "\n",
      "Epoch 26: Train Loss = 0.005805426964112077, Recall = 1.0, Aging Rate = 0.5002224199288257, Precision = 0.9995553579368608, f1 = 0.9997776295307983\n",
      "Epoch 27: Train Loss = 0.005550506456798188, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 28: Train Loss = 0.005041123809064225, Recall = 0.9995551601423488, Aging Rate = 0.4997775800711744, Precision = 0, f1 = 0.0\n",
      "Epoch 29: Train Loss = 0.004492101874335063, Recall = 0.9995551601423488, Aging Rate = 0.4997775800711744, Precision = 0, f1 = 0.0\n",
      "Epoch 30: Train Loss = 0.004160537749439398, Recall = 1.0, Aging Rate = 0.5002224199288257, Precision = 0.9995553579368608, f1 = 0.9997776295307983\n",
      "Test Loss = 0.0037446594560929837, Recall = 0.9991103202846975, Aging Rate = 0.49955516014234874, precision = 1.0\n",
      "\n",
      "Epoch 31: Train Loss = 0.004044781463449403, Recall = 0.9995551601423488, Aging Rate = 0.5, Precision = 0.9995551601423488, f1 = 0.9995551601423488\n",
      "Epoch 32: Train Loss = 0.003762152385475359, Recall = 0.9995551601423488, Aging Rate = 0.4997775800711744, Precision = 0, f1 = 0.0\n",
      "Epoch 33: Train Loss = 0.003572643917630629, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 34: Train Loss = 0.0036165920538609032, Recall = 0.9995551601423488, Aging Rate = 0.5, Precision = 0.9995551601423488, f1 = 0.9995551601423488\n",
      "Epoch 35: Train Loss = 0.0030691189139590886, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0027107209977246423, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 36: Train Loss = 0.0030237419250689684, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 37: Train Loss = 0.002727657099986893, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 38: Train Loss = 0.002844724459681342, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 39: Train Loss = 0.0024137707502544722, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 40: Train Loss = 0.0023157959292291453, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0022919115416118975, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 41: Train Loss = 0.0022633415998997053, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 42: Train Loss = 0.0023474244970921095, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 43: Train Loss = 0.0021943509598590727, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 44: Train Loss = 0.002116113417662574, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 45: Train Loss = 0.0021601329684784484, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.001783889477651606, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 46: Train Loss = 0.0020577591198440177, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 47: Train Loss = 0.0019551676466441265, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 48: Train Loss = 0.0020024376424001298, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 49: Train Loss = 0.0019429033200399042, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 50: Train Loss = 0.0019176563637884618, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0015279497214662594, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 51: Train Loss = 0.001729585720040567, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 52: Train Loss = 0.0018671214380848397, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 53: Train Loss = 0.0021501100200370907, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 54: Train Loss = 0.002032987641467252, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 55: Train Loss = 0.0017294007373370522, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.002334365871129226, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 56: Train Loss = 0.0017876560359387874, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 57: Train Loss = 0.00161027888128587, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 58: Train Loss = 0.0015844648295443413, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 59: Train Loss = 0.0017777411180160596, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 60: Train Loss = 0.0019021320139767197, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.002267550600831831, Recall = 1.0, Aging Rate = 0.5002224199288257, precision = 0.9995553579368608\n",
      "\n",
      "Epoch 61: Train Loss = 0.001853763436139611, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 62: Train Loss = 0.0018334054873653048, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 63: Train Loss = 0.0017336209839478374, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 64: Train Loss = 0.001534266794660523, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 65: Train Loss = 0.0013903847094326946, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0012066292489905349, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 66: Train Loss = 0.001386326187318423, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 67: Train Loss = 0.001499591749269197, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 68: Train Loss = 0.0016304562164526897, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 69: Train Loss = 0.0016735344886981958, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 70: Train Loss = 0.003999861463526549, Recall = 1.0, Aging Rate = 0.5004448398576512, Precision = 0.9991111111111111, f1 = 0.9995553579368608\n",
      "Test Loss = 0.0020446630333155872, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 71: Train Loss = 0.001920234621585317, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 72: Train Loss = 0.001272935716284512, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 73: Train Loss = 0.0012191663155650381, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 74: Train Loss = 0.0012867305408318086, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 75: Train Loss = 0.0013467711962020402, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0012152845001020519, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Training Finished at epoch 75.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f0cbf29f875455f9811e68506a8434e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "32f4621473c1401cbf79adc4e17ed9d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss = 0.33534161479570485, Recall = 0.008888888888888889, Aging Rate = 0.01213101496158512, Precision = 0.06666666666666667, f1 = 0.01568627450980392\n",
      "Epoch 2: Train Loss = 0.22239134783355322, Recall = 0.11555555555555555, Aging Rate = 0.010513546300040437, Precision = 0, f1 = 0.0\n",
      "Epoch 3: Train Loss = 0.17663804077145256, Recall = 0.31555555555555553, Aging Rate = 0.032753740396279825, Precision = 0.8765432098765432, f1 = 0.4640522875816993\n",
      "Epoch 4: Train Loss = 0.16540303421415783, Recall = 0.36444444444444446, Aging Rate = 0.03881924787707238, Precision = 0.8541666666666666, f1 = 0.5109034267912773\n",
      "Epoch 5: Train Loss = 0.1373560250504413, Recall = 0.4622222222222222, Aging Rate = 0.042458552365547915, Precision = 0.9904761904761905, f1 = 0.6303030303030304\n",
      "Test Loss = 0.1067075839727888, Recall = 0.6355555555555555, Aging Rate = 0.0578245046502224, precision = 1.0\n",
      "Model in epoch 5 is saved.\n",
      "\n",
      "Epoch 6: Train Loss = 0.10672059303900513, Recall = 0.6933333333333334, Aging Rate = 0.06591184795794582, Precision = 0.9570552147239264, f1 = 0.8041237113402062\n",
      "Epoch 7: Train Loss = 0.0786838460799489, Recall = 0.8, Aging Rate = 0.07602102709260009, Precision = 0.9574468085106383, f1 = 0.8716707021791769\n",
      "Epoch 8: Train Loss = 0.06447798014892242, Recall = 0.8311111111111111, Aging Rate = 0.07844723008491711, Precision = 0.9639175257731959, f1 = 0.892601431980907\n",
      "Epoch 9: Train Loss = 0.05203806478161104, Recall = 0.8711111111111111, Aging Rate = 0.08087343307723413, Precision = 0.98, f1 = 0.9223529411764706\n",
      "Epoch 10: Train Loss = 0.04896548711097872, Recall = 0.8844444444444445, Aging Rate = 0.08249090173877881, Precision = 0.9754901960784313, f1 = 0.9277389277389277\n",
      "Test Loss = 0.03540762956301259, Recall = 0.9422222222222222, Aging Rate = 0.08613020622725434, precision = 0.9953051643192489\n",
      "Model in epoch 10 is saved.\n",
      "\n",
      "Epoch 11: Train Loss = 0.03584110614980371, Recall = 0.9244444444444444, Aging Rate = 0.08491710473109583, Precision = 0.9904761904761905, f1 = 0.9563218390804598\n",
      "Epoch 12: Train Loss = 0.03014675138259869, Recall = 0.9155555555555556, Aging Rate = 0.08451273756570966, Precision = 0.9856459330143541, f1 = 0.9493087557603687\n",
      "Epoch 13: Train Loss = 0.02219863988766413, Recall = 0.96, Aging Rate = 0.0881520420541852, Precision = 0.9908256880733946, f1 = 0.9751693002257336\n",
      "Epoch 14: Train Loss = 0.016765360013961044, Recall = 0.9777777777777777, Aging Rate = 0.08896077638495754, Precision = 0, f1 = 0.0\n",
      "Epoch 15: Train Loss = 0.013269075014381047, Recall = 0.9866666666666667, Aging Rate = 0.09017387788111605, Precision = 0.9955156950672646, f1 = 0.9910714285714286\n",
      "Test Loss = 0.009750560153497166, Recall = 0.9911111111111112, Aging Rate = 0.09017387788111605, precision = 1.0\n",
      "Model in epoch 15 is saved.\n",
      "\n",
      "Epoch 16: Train Loss = 0.01204281532101324, Recall = 0.9866666666666667, Aging Rate = 0.08976951071572989, Precision = 0, f1 = 0.0\n",
      "Epoch 17: Train Loss = 0.01132134102537981, Recall = 0.9866666666666667, Aging Rate = 0.08976951071572989, Precision = 0, f1 = 0.0\n",
      "Epoch 18: Train Loss = 0.010451788824990097, Recall = 0.9911111111111112, Aging Rate = 0.09017387788111605, Precision = 0, f1 = 0.0\n",
      "Epoch 19: Train Loss = 0.00814679485688862, Recall = 0.9955555555555555, Aging Rate = 0.09057824504650222, Precision = 0, f1 = 0.0\n",
      "Epoch 20: Train Loss = 0.007069031739105827, Recall = 0.9911111111111112, Aging Rate = 0.09017387788111605, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0052144097181596695, Recall = 0.9955555555555555, Aging Rate = 0.09057824504650222, precision = 1.0\n",
      "Model in epoch 20 is saved.\n",
      "\n",
      "Epoch 21: Train Loss = 0.006737896316002014, Recall = 0.9955555555555555, Aging Rate = 0.09057824504650222, Precision = 0, f1 = 0.0\n",
      "Epoch 22: Train Loss = 0.005437320873127731, Recall = 0.9955555555555555, Aging Rate = 0.09057824504650222, Precision = 0, f1 = 0.0\n",
      "Epoch 23: Train Loss = 0.005379160603653719, Recall = 0.9955555555555555, Aging Rate = 0.0909826122118884, Precision = 0.9955555555555555, f1 = 0.9955555555555555\n",
      "Epoch 24: Train Loss = 0.005483754949694672, Recall = 0.9955555555555555, Aging Rate = 0.09057824504650222, Precision = 0, f1 = 0.0\n",
      "Epoch 25: Train Loss = 0.0054879660806266516, Recall = 0.9955555555555555, Aging Rate = 0.09057824504650222, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0034766762172430453, Recall = 0.9955555555555555, Aging Rate = 0.09057824504650222, precision = 1.0\n",
      "\n",
      "Epoch 26: Train Loss = 0.004264361355276729, Recall = 0.9955555555555555, Aging Rate = 0.09057824504650222, Precision = 0, f1 = 0.0\n",
      "Epoch 27: Train Loss = 0.003953579157493704, Recall = 0.9955555555555555, Aging Rate = 0.09057824504650222, Precision = 0, f1 = 0.0\n",
      "Epoch 28: Train Loss = 0.003641517426810324, Recall = 0.9955555555555555, Aging Rate = 0.09057824504650222, Precision = 0, f1 = 0.0\n",
      "Epoch 29: Train Loss = 0.0035837692505345984, Recall = 0.9955555555555555, Aging Rate = 0.09057824504650222, Precision = 0, f1 = 0.0\n",
      "Epoch 30: Train Loss = 0.00307110143622803, Recall = 0.9955555555555555, Aging Rate = 0.09057824504650222, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0030978842213067494, Recall = 1.0, Aging Rate = 0.0909826122118884, precision = 1.0\n",
      "Model in epoch 30 is saved.\n",
      "\n",
      "Epoch 31: Train Loss = 0.0035020315273428765, Recall = 0.9955555555555555, Aging Rate = 0.0909826122118884, Precision = 0.9955555555555555, f1 = 0.9955555555555555\n",
      "Epoch 32: Train Loss = 0.0032187358377741638, Recall = 0.9955555555555555, Aging Rate = 0.09057824504650222, Precision = 0, f1 = 0.0\n",
      "Epoch 33: Train Loss = 0.002572320871378246, Recall = 1.0, Aging Rate = 0.0909826122118884, Precision = 0, f1 = 0.0\n",
      "Epoch 34: Train Loss = 0.003323031978977688, Recall = 0.9955555555555555, Aging Rate = 0.09057824504650222, Precision = 0, f1 = 0.0\n",
      "Epoch 35: Train Loss = 0.004366393174126509, Recall = 1.0, Aging Rate = 0.0909826122118884, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.004786114949730006, Recall = 1.0, Aging Rate = 0.0909826122118884, precision = 1.0\n",
      "\n",
      "Epoch 36: Train Loss = 0.003974148181468185, Recall = 1.0, Aging Rate = 0.0909826122118884, Precision = 0, f1 = 0.0\n",
      "Epoch 37: Train Loss = 0.002704771238692132, Recall = 1.0, Aging Rate = 0.0909826122118884, Precision = 0, f1 = 0.0\n",
      "Epoch 38: Train Loss = 0.00246585508242846, Recall = 0.9955555555555555, Aging Rate = 0.09057824504650222, Precision = 0, f1 = 0.0\n",
      "Epoch 39: Train Loss = 0.0026860532051067552, Recall = 1.0, Aging Rate = 0.0909826122118884, Precision = 0, f1 = 0.0\n",
      "Epoch 40: Train Loss = 0.002020185899736606, Recall = 1.0, Aging Rate = 0.0909826122118884, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.001776133818686343, Recall = 1.0, Aging Rate = 0.0909826122118884, precision = 1.0\n",
      "\n",
      "Epoch 41: Train Loss = 0.0019796566554340293, Recall = 1.0, Aging Rate = 0.0909826122118884, Precision = 0, f1 = 0.0\n",
      "Epoch 42: Train Loss = 0.0023206151497286317, Recall = 1.0, Aging Rate = 0.0909826122118884, Precision = 0, f1 = 0.0\n",
      "Epoch 43: Train Loss = 0.0021153305208775957, Recall = 1.0, Aging Rate = 0.0909826122118884, Precision = 0, f1 = 0.0\n",
      "Epoch 44: Train Loss = 0.0017705411714544234, Recall = 1.0, Aging Rate = 0.0909826122118884, Precision = 0, f1 = 0.0\n",
      "Epoch 45: Train Loss = 0.0017711097838525054, Recall = 1.0, Aging Rate = 0.0909826122118884, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0018308327516452008, Recall = 1.0, Aging Rate = 0.0909826122118884, precision = 1.0\n",
      "\n",
      "Epoch 46: Train Loss = 0.0018224759116615185, Recall = 1.0, Aging Rate = 0.0909826122118884, Precision = 0, f1 = 0.0\n",
      "Epoch 47: Train Loss = 0.0017754943203727093, Recall = 1.0, Aging Rate = 0.0909826122118884, Precision = 0, f1 = 0.0\n",
      "Epoch 48: Train Loss = 0.0018839805058945155, Recall = 1.0, Aging Rate = 0.0909826122118884, Precision = 0, f1 = 0.0\n",
      "Epoch 49: Train Loss = 0.00196613129785716, Recall = 1.0, Aging Rate = 0.0909826122118884, Precision = 0, f1 = 0.0\n",
      "Epoch 50: Train Loss = 0.002200880529753656, Recall = 1.0, Aging Rate = 0.0909826122118884, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.001809279295324743, Recall = 1.0, Aging Rate = 0.0909826122118884, precision = 1.0\n",
      "\n",
      "Epoch 51: Train Loss = 0.002361354389571759, Recall = 1.0, Aging Rate = 0.0909826122118884, Precision = 0, f1 = 0.0\n",
      "Epoch 52: Train Loss = 0.002174414875357891, Recall = 1.0, Aging Rate = 0.0909826122118884, Precision = 0, f1 = 0.0\n",
      "Epoch 53: Train Loss = 0.002553391883791275, Recall = 0.9955555555555555, Aging Rate = 0.09057824504650222, Precision = 0, f1 = 0.0\n",
      "Epoch 54: Train Loss = 0.002456278820569957, Recall = 1.0, Aging Rate = 0.0909826122118884, Precision = 0, f1 = 0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 55: Train Loss = 0.00677779881194011, Recall = 0.9822222222222222, Aging Rate = 0.09017387788111605, Precision = 0.9910313901345291, f1 = 0.9866071428571429\n",
      "Test Loss = 0.012843603139846397, Recall = 0.9511111111111111, Aging Rate = 0.08653457339264052, precision = 1.0\n",
      "\n",
      "Epoch 56: Train Loss = 0.049202906352713, Recall = 0.88, Aging Rate = 0.08693894055802669, Precision = 0.9209302325581395, f1 = 0.9\n",
      "Epoch 57: Train Loss = 0.03174975291542254, Recall = 0.9422222222222222, Aging Rate = 0.09017387788111605, Precision = 0.9506726457399103, f1 = 0.9464285714285714\n",
      "Epoch 58: Train Loss = 0.01854285147994624, Recall = 0.9377777777777778, Aging Rate = 0.08693894055802669, Precision = 0.9813953488372092, f1 = 0.959090909090909\n",
      "Epoch 59: Train Loss = 0.007784674283193505, Recall = 0.9822222222222222, Aging Rate = 0.09057824504650222, Precision = 0.9866071428571429, f1 = 0.9844097995545658\n",
      "Epoch 60: Train Loss = 0.0032006513235188216, Recall = 0.9911111111111112, Aging Rate = 0.09017387788111605, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0016188176758801078, Recall = 1.0, Aging Rate = 0.0909826122118884, precision = 1.0\n",
      "\n",
      "Epoch 61: Train Loss = 0.0016960733282250634, Recall = 1.0, Aging Rate = 0.0909826122118884, Precision = 0, f1 = 0.0\n",
      "Epoch 62: Train Loss = 0.001153347439166901, Recall = 1.0, Aging Rate = 0.0909826122118884, Precision = 0, f1 = 0.0\n",
      "Epoch 63: Train Loss = 0.0009755295952891248, Recall = 1.0, Aging Rate = 0.0909826122118884, Precision = 0, f1 = 0.0\n",
      "Epoch 64: Train Loss = 0.0009834698140221993, Recall = 1.0, Aging Rate = 0.0909826122118884, Precision = 0, f1 = 0.0\n",
      "Epoch 65: Train Loss = 0.0009746297346495825, Recall = 1.0, Aging Rate = 0.0909826122118884, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0009547191486741747, Recall = 1.0, Aging Rate = 0.0909826122118884, precision = 1.0\n",
      "\n",
      "Epoch 66: Train Loss = 0.0010638100315778665, Recall = 1.0, Aging Rate = 0.0909826122118884, Precision = 0, f1 = 0.0\n",
      "Epoch 67: Train Loss = 0.0009281796991096014, Recall = 1.0, Aging Rate = 0.0909826122118884, Precision = 0, f1 = 0.0\n",
      "Epoch 68: Train Loss = 0.001041797353578012, Recall = 1.0, Aging Rate = 0.0909826122118884, Precision = 0, f1 = 0.0\n",
      "Epoch 69: Train Loss = 0.0009908969125236294, Recall = 1.0, Aging Rate = 0.0909826122118884, Precision = 0, f1 = 0.0\n",
      "Epoch 70: Train Loss = 0.0010477385761986798, Recall = 1.0, Aging Rate = 0.0909826122118884, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0008965993215911033, Recall = 1.0, Aging Rate = 0.0909826122118884, precision = 1.0\n",
      "\n",
      "Epoch 71: Train Loss = 0.000962971208630837, Recall = 1.0, Aging Rate = 0.0909826122118884, Precision = 0, f1 = 0.0\n",
      "Epoch 72: Train Loss = 0.000991309054114536, Recall = 1.0, Aging Rate = 0.0909826122118884, Precision = 0, f1 = 0.0\n",
      "Epoch 73: Train Loss = 0.0010326791518347868, Recall = 1.0, Aging Rate = 0.0909826122118884, Precision = 0, f1 = 0.0\n",
      "Epoch 74: Train Loss = 0.0010514133789185306, Recall = 1.0, Aging Rate = 0.0909826122118884, Precision = 0, f1 = 0.0\n",
      "Epoch 75: Train Loss = 0.0010808807790857087, Recall = 1.0, Aging Rate = 0.0909826122118884, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0009906482513733373, Recall = 1.0, Aging Rate = 0.0909826122118884, precision = 1.0\n",
      "\n",
      "Epoch 76: Train Loss = 0.0011452415683508232, Recall = 1.0, Aging Rate = 0.0909826122118884, Precision = 0, f1 = 0.0\n",
      "Epoch 77: Train Loss = 0.001125231194437933, Recall = 1.0, Aging Rate = 0.0909826122118884, Precision = 0, f1 = 0.0\n",
      "Epoch 78: Train Loss = 0.0010983867181828069, Recall = 1.0, Aging Rate = 0.0909826122118884, Precision = 0, f1 = 0.0\n",
      "Epoch 79: Train Loss = 0.001115162109427404, Recall = 1.0, Aging Rate = 0.0909826122118884, Precision = 0, f1 = 0.0\n",
      "Epoch 80: Train Loss = 0.0012290754831978637, Recall = 1.0, Aging Rate = 0.0909826122118884, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0011410077035259884, Recall = 1.0, Aging Rate = 0.0909826122118884, precision = 1.0\n",
      "\n",
      "Training Finished at epoch 80.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5eec6b4f1c5d4d31a006b6e76385413f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss = 0.32576742423626753, Recall = 0.017777777777777778, Aging Rate = 0.009300444803881924, Precision = 0.17391304347826086, f1 = 0.03225806451612903\n",
      "Epoch 2: Train Loss = 0.22451376096107098, Recall = 0.035555555555555556, Aging Rate = 0.003234937323089365, Precision = 0, f1 = 0.0\n",
      "Epoch 3: Train Loss = 0.17977742523593648, Recall = 0.26666666666666666, Aging Rate = 0.02547513141932875, Precision = 0.9523809523809523, f1 = 0.4166666666666667\n",
      "Epoch 4: Train Loss = 0.15041100460052298, Recall = 0.3688888888888889, Aging Rate = 0.03517994338859685, Precision = 0.9540229885057471, f1 = 0.532051282051282\n",
      "Epoch 5: Train Loss = 0.1318458071181131, Recall = 0.4488888888888889, Aging Rate = 0.04205418520016175, Precision = 0.9711538461538461, f1 = 0.6139817629179332\n",
      "Test Loss = 0.10540267621162108, Recall = 0.5466666666666666, Aging Rate = 0.05014152850788516, precision = 0.9919354838709677\n",
      "Model in epoch 5 is saved.\n",
      "\n",
      "Epoch 6: Train Loss = 0.10001590307478089, Recall = 0.6266666666666667, Aging Rate = 0.058228871815608575, Precision = 0.9791666666666666, f1 = 0.7642276422764227\n",
      "Epoch 7: Train Loss = 0.07774912919871753, Recall = 0.7511111111111111, Aging Rate = 0.068742418115649, Precision = 0.9941176470588236, f1 = 0.8556962025316456\n",
      "Epoch 8: Train Loss = 0.06188000691922821, Recall = 0.84, Aging Rate = 0.07682976142337242, Precision = 0.9947368421052631, f1 = 0.9108433734939758\n",
      "Epoch 9: Train Loss = 0.048746792311086085, Recall = 0.8755555555555555, Aging Rate = 0.08006469874646178, Precision = 0.9949494949494949, f1 = 0.9314420803782505\n",
      "Epoch 10: Train Loss = 0.041349479884174346, Recall = 0.92, Aging Rate = 0.08370400323493732, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.03352731803874231, Recall = 0.9377777777777778, Aging Rate = 0.08532147189648201, precision = 1.0\n",
      "Model in epoch 10 is saved.\n",
      "\n",
      "Epoch 11: Train Loss = 0.03485778446681722, Recall = 0.9244444444444444, Aging Rate = 0.0841083704003235, Precision = 0, f1 = 0.0\n",
      "Epoch 12: Train Loss = 0.02991475387835281, Recall = 0.9511111111111111, Aging Rate = 0.08653457339264052, Precision = 0, f1 = 0.0\n",
      "Epoch 13: Train Loss = 0.025700231930455647, Recall = 0.9555555555555556, Aging Rate = 0.08734330772341285, Precision = 0.9953703703703703, f1 = 0.9750566893424036\n",
      "Epoch 14: Train Loss = 0.01998232856763431, Recall = 0.9777777777777777, Aging Rate = 0.08896077638495754, Precision = 0, f1 = 0.0\n",
      "Epoch 15: Train Loss = 0.017004205245378524, Recall = 0.9822222222222222, Aging Rate = 0.08936514355034371, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.016316310102266914, Recall = 0.9955555555555555, Aging Rate = 0.09057824504650222, precision = 1.0\n",
      "Model in epoch 15 is saved.\n",
      "\n",
      "Epoch 16: Train Loss = 0.015280390376344872, Recall = 0.9866666666666667, Aging Rate = 0.08976951071572989, Precision = 0, f1 = 0.0\n",
      "Epoch 17: Train Loss = 0.013833869516388564, Recall = 0.9911111111111112, Aging Rate = 0.09017387788111605, Precision = 0, f1 = 0.0\n",
      "Epoch 18: Train Loss = 0.011836396324272417, Recall = 0.9911111111111112, Aging Rate = 0.09017387788111605, Precision = 0, f1 = 0.0\n",
      "Epoch 19: Train Loss = 0.01021857130201138, Recall = 0.9955555555555555, Aging Rate = 0.09057824504650222, Precision = 0, f1 = 0.0\n",
      "Epoch 20: Train Loss = 0.00913430850375165, Recall = 1.0, Aging Rate = 0.0909826122118884, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.008239067809409969, Recall = 1.0, Aging Rate = 0.0909826122118884, precision = 1.0\n",
      "Model in epoch 20 is saved.\n",
      "\n",
      "Epoch 21: Train Loss = 0.008331015145310471, Recall = 0.9955555555555555, Aging Rate = 0.09057824504650222, Precision = 0, f1 = 0.0\n",
      "Epoch 22: Train Loss = 0.007672593627219927, Recall = 1.0, Aging Rate = 0.0909826122118884, Precision = 0, f1 = 0.0\n",
      "Epoch 23: Train Loss = 0.007111792916976581, Recall = 1.0, Aging Rate = 0.0909826122118884, Precision = 0, f1 = 0.0\n",
      "Epoch 24: Train Loss = 0.00658227414874909, Recall = 1.0, Aging Rate = 0.0909826122118884, Precision = 0, f1 = 0.0\n",
      "Epoch 25: Train Loss = 0.00648893434898924, Recall = 1.0, Aging Rate = 0.0909826122118884, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.005769819263470526, Recall = 1.0, Aging Rate = 0.0909826122118884, precision = 1.0\n",
      "\n",
      "Epoch 26: Train Loss = 0.005866555227407357, Recall = 1.0, Aging Rate = 0.0909826122118884, Precision = 0, f1 = 0.0\n",
      "Epoch 27: Train Loss = 0.00556770978070678, Recall = 1.0, Aging Rate = 0.0909826122118884, Precision = 0, f1 = 0.0\n",
      "Epoch 28: Train Loss = 0.005102908319548478, Recall = 1.0, Aging Rate = 0.0909826122118884, Precision = 0, f1 = 0.0\n",
      "Epoch 29: Train Loss = 0.004958574980747044, Recall = 1.0, Aging Rate = 0.0909826122118884, Precision = 0, f1 = 0.0\n",
      "Epoch 30: Train Loss = 0.004654405147776466, Recall = 1.0, Aging Rate = 0.0909826122118884, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.004307818870759485, Recall = 1.0, Aging Rate = 0.0909826122118884, precision = 1.0\n",
      "\n",
      "Epoch 31: Train Loss = 0.004558285684454727, Recall = 1.0, Aging Rate = 0.0909826122118884, Precision = 0, f1 = 0.0\n",
      "Epoch 32: Train Loss = 0.004390035989469093, Recall = 1.0, Aging Rate = 0.0909826122118884, Precision = 0, f1 = 0.0\n",
      "Epoch 33: Train Loss = 0.0042570751767456415, Recall = 1.0, Aging Rate = 0.0909826122118884, Precision = 0, f1 = 0.0\n",
      "Epoch 34: Train Loss = 0.004084793730739472, Recall = 1.0, Aging Rate = 0.0909826122118884, Precision = 0, f1 = 0.0\n",
      "Epoch 35: Train Loss = 0.0039665099934611155, Recall = 1.0, Aging Rate = 0.0909826122118884, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.003767711400486351, Recall = 1.0, Aging Rate = 0.0909826122118884, precision = 1.0\n",
      "\n",
      "Epoch 36: Train Loss = 0.003929819396158075, Recall = 1.0, Aging Rate = 0.0909826122118884, Precision = 0, f1 = 0.0\n",
      "Epoch 37: Train Loss = 0.003786283281060848, Recall = 1.0, Aging Rate = 0.0909826122118884, Precision = 0, f1 = 0.0\n",
      "Epoch 38: Train Loss = 0.003930633417938885, Recall = 1.0, Aging Rate = 0.0909826122118884, Precision = 0, f1 = 0.0\n",
      "Epoch 39: Train Loss = 0.004562643543036419, Recall = 1.0, Aging Rate = 0.0909826122118884, Precision = 0, f1 = 0.0\n",
      "Epoch 40: Train Loss = 0.005804501214711273, Recall = 0.9955555555555555, Aging Rate = 0.09057824504650222, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.007048786339322553, Recall = 1.0, Aging Rate = 0.09179134654266073, precision = 0.9911894273127754\n",
      "\n",
      "Epoch 41: Train Loss = 0.017504184387452534, Recall = 0.9777777777777777, Aging Rate = 0.08976951071572989, Precision = 0.990990990990991, f1 = 0.9843400447427293\n",
      "Epoch 42: Train Loss = 0.017534483000831932, Recall = 0.9688888888888889, Aging Rate = 0.08936514355034371, Precision = 0.9864253393665159, f1 = 0.9775784753363229\n",
      "Epoch 43: Train Loss = 0.013067472600323489, Recall = 0.9733333333333334, Aging Rate = 0.08896077638495754, Precision = 0.9954545454545455, f1 = 0.9842696629213483\n",
      "Epoch 44: Train Loss = 0.008450424502759244, Recall = 0.9911111111111112, Aging Rate = 0.0909826122118884, Precision = 0.9911111111111112, f1 = 0.9911111111111112\n",
      "Epoch 45: Train Loss = 0.006537346939044695, Recall = 0.9911111111111112, Aging Rate = 0.09017387788111605, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.003948812309149435, Recall = 1.0, Aging Rate = 0.0909826122118884, precision = 1.0\n",
      "\n",
      "Epoch 46: Train Loss = 0.003464296551664566, Recall = 1.0, Aging Rate = 0.0909826122118884, Precision = 0, f1 = 0.0\n",
      "Epoch 47: Train Loss = 0.0023265790946618192, Recall = 1.0, Aging Rate = 0.0909826122118884, Precision = 0, f1 = 0.0\n",
      "Epoch 48: Train Loss = 0.0017280329505205336, Recall = 1.0, Aging Rate = 0.0909826122118884, Precision = 0, f1 = 0.0\n",
      "Epoch 49: Train Loss = 0.001222692312380119, Recall = 1.0, Aging Rate = 0.0909826122118884, Precision = 0, f1 = 0.0\n",
      "Epoch 50: Train Loss = 0.0010829386685937614, Recall = 1.0, Aging Rate = 0.0909826122118884, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0010147345729859141, Recall = 1.0, Aging Rate = 0.0909826122118884, precision = 1.0\n",
      "\n",
      "Epoch 51: Train Loss = 0.0010888030164296263, Recall = 1.0, Aging Rate = 0.0909826122118884, Precision = 0, f1 = 0.0\n",
      "Epoch 52: Train Loss = 0.0010844037642689657, Recall = 1.0, Aging Rate = 0.0909826122118884, Precision = 0, f1 = 0.0\n",
      "Epoch 53: Train Loss = 0.0010825803887898919, Recall = 1.0, Aging Rate = 0.0909826122118884, Precision = 0, f1 = 0.0\n",
      "Epoch 54: Train Loss = 0.0011782441288468175, Recall = 1.0, Aging Rate = 0.0909826122118884, Precision = 0, f1 = 0.0\n",
      "Epoch 55: Train Loss = 0.0012106272443568615, Recall = 1.0, Aging Rate = 0.0909826122118884, Precision = 0, f1 = 0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss = 0.0010197905585650141, Recall = 1.0, Aging Rate = 0.0909826122118884, precision = 1.0\n",
      "\n",
      "Epoch 56: Train Loss = 0.0011031934880853765, Recall = 1.0, Aging Rate = 0.0909826122118884, Precision = 0, f1 = 0.0\n",
      "Epoch 57: Train Loss = 0.0011689154367861547, Recall = 1.0, Aging Rate = 0.0909826122118884, Precision = 0, f1 = 0.0\n",
      "Epoch 58: Train Loss = 0.0011743162653672186, Recall = 1.0, Aging Rate = 0.0909826122118884, Precision = 0, f1 = 0.0\n",
      "Epoch 59: Train Loss = 0.0012547678533610855, Recall = 1.0, Aging Rate = 0.0909826122118884, Precision = 0, f1 = 0.0\n",
      "Epoch 60: Train Loss = 0.0013177037061415417, Recall = 1.0, Aging Rate = 0.0909826122118884, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0012199635306931354, Recall = 1.0, Aging Rate = 0.0909826122118884, precision = 1.0\n",
      "\n",
      "Epoch 61: Train Loss = 0.001421991609772415, Recall = 1.0, Aging Rate = 0.0909826122118884, Precision = 0, f1 = 0.0\n",
      "Epoch 62: Train Loss = 0.0013671137068271516, Recall = 1.0, Aging Rate = 0.0909826122118884, Precision = 0, f1 = 0.0\n",
      "Epoch 63: Train Loss = 0.0014165487995337705, Recall = 1.0, Aging Rate = 0.0909826122118884, Precision = 0, f1 = 0.0\n",
      "Epoch 64: Train Loss = 0.001795193858974185, Recall = 1.0, Aging Rate = 0.0909826122118884, Precision = 0, f1 = 0.0\n",
      "Epoch 65: Train Loss = 0.0015965570521334189, Recall = 1.0, Aging Rate = 0.0909826122118884, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0015754921095974116, Recall = 1.0, Aging Rate = 0.09138697937727457, precision = 0.995575221238938\n",
      "\n",
      "Epoch 66: Train Loss = 0.0016336784649770624, Recall = 1.0, Aging Rate = 0.0909826122118884, Precision = 0, f1 = 0.0\n",
      "Epoch 67: Train Loss = 0.0025458449992666445, Recall = 1.0, Aging Rate = 0.0909826122118884, Precision = 0, f1 = 0.0\n",
      "Epoch 68: Train Loss = 0.004874579721890026, Recall = 0.9955555555555555, Aging Rate = 0.0909826122118884, Precision = 0.9955555555555555, f1 = 0.9955555555555555\n",
      "Epoch 69: Train Loss = 0.004742447638961766, Recall = 0.9955555555555555, Aging Rate = 0.09057824504650222, Precision = 0, f1 = 0.0\n",
      "Epoch 70: Train Loss = 0.004706599314703112, Recall = 0.9955555555555555, Aging Rate = 0.0909826122118884, Precision = 0.9955555555555555, f1 = 0.9955555555555555\n",
      "Test Loss = 0.0037221195419336675, Recall = 1.0, Aging Rate = 0.09138697937727457, precision = 0.995575221238938\n",
      "\n",
      "Training Finished at epoch 70.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "77d29fa73c534bb39e0452a46a77aefd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss = 0.31902079851797027, Recall = 0.03111111111111111, Aging Rate = 0.014961585119288313, Precision = 0.1891891891891892, f1 = 0.05343511450381679\n",
      "Epoch 2: Train Loss = 0.21844172188496233, Recall = 0.17333333333333334, Aging Rate = 0.016579053780832995, Precision = 0.9512195121951219, f1 = 0.29323308270676696\n",
      "Epoch 3: Train Loss = 0.1698375363678668, Recall = 0.39555555555555555, Aging Rate = 0.041245450869389404, Precision = 0.8725490196078431, f1 = 0.5443425076452598\n",
      "Epoch 4: Train Loss = 0.14400252890560342, Recall = 0.48444444444444446, Aging Rate = 0.048119692680954305, Precision = 0.9159663865546218, f1 = 0.633720930232558\n",
      "Epoch 5: Train Loss = 0.1250062530285619, Recall = 0.5511111111111111, Aging Rate = 0.05418520016174687, Precision = 0.9253731343283582, f1 = 0.6908077994428969\n",
      "Test Loss = 0.11742590387979597, Recall = 0.48444444444444446, Aging Rate = 0.04448038819247877, precision = 0.990909090909091\n",
      "Model in epoch 5 is saved.\n",
      "\n",
      "Epoch 6: Train Loss = 0.09999420810483314, Recall = 0.6577777777777778, Aging Rate = 0.06227254346947028, Precision = 0.961038961038961, f1 = 0.7810026385224275\n",
      "Epoch 7: Train Loss = 0.0803142286915433, Recall = 0.7333333333333333, Aging Rate = 0.06752931661949049, Precision = 0.9880239520958084, f1 = 0.8418367346938775\n",
      "Epoch 8: Train Loss = 0.07122452409762484, Recall = 0.7955555555555556, Aging Rate = 0.07521229276182774, Precision = 0.9623655913978495, f1 = 0.8710462287104623\n",
      "Epoch 9: Train Loss = 0.05476387865537099, Recall = 0.84, Aging Rate = 0.07682976142337242, Precision = 0.9947368421052631, f1 = 0.9108433734939758\n",
      "Epoch 10: Train Loss = 0.05027261240956902, Recall = 0.8488888888888889, Aging Rate = 0.07885159725030327, Precision = 0.9794871794871794, f1 = 0.9095238095238095\n",
      "Test Loss = 0.03561844047741928, Recall = 0.8888888888888888, Aging Rate = 0.08087343307723413, precision = 1.0\n",
      "Model in epoch 10 is saved.\n",
      "\n",
      "Epoch 11: Train Loss = 0.03734130548743333, Recall = 0.9022222222222223, Aging Rate = 0.08208653457339264, Precision = 0, f1 = 0.0\n",
      "Epoch 12: Train Loss = 0.030918434952953253, Recall = 0.8977777777777778, Aging Rate = 0.08208653457339264, Precision = 0.9950738916256158, f1 = 0.9439252336448599\n",
      "Epoch 13: Train Loss = 0.02189189530050422, Recall = 0.9422222222222222, Aging Rate = 0.08572583906186818, Precision = 0, f1 = 0.0\n",
      "Epoch 14: Train Loss = 0.018905307936417735, Recall = 0.9644444444444444, Aging Rate = 0.08774767488879903, Precision = 0, f1 = 0.0\n",
      "Epoch 15: Train Loss = 0.01653974247381567, Recall = 0.9733333333333334, Aging Rate = 0.08855640921957138, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.014218248331635359, Recall = 0.9822222222222222, Aging Rate = 0.08936514355034371, precision = 1.0\n",
      "Model in epoch 15 is saved.\n",
      "\n",
      "Epoch 16: Train Loss = 0.014008675457505239, Recall = 0.96, Aging Rate = 0.08734330772341285, Precision = 0, f1 = 0.0\n",
      "Epoch 17: Train Loss = 0.012851322409453973, Recall = 0.9733333333333334, Aging Rate = 0.08855640921957138, Precision = 0, f1 = 0.0\n",
      "Epoch 18: Train Loss = 0.011877105732889394, Recall = 0.9866666666666667, Aging Rate = 0.08976951071572989, Precision = 0, f1 = 0.0\n",
      "Epoch 19: Train Loss = 0.010205160647184802, Recall = 0.9955555555555555, Aging Rate = 0.09057824504650222, Precision = 0, f1 = 0.0\n",
      "Epoch 20: Train Loss = 0.007969869327273112, Recall = 0.9955555555555555, Aging Rate = 0.09057824504650222, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.005736536170505484, Recall = 0.9955555555555555, Aging Rate = 0.09057824504650222, precision = 1.0\n",
      "Model in epoch 20 is saved.\n",
      "\n",
      "Epoch 21: Train Loss = 0.006359043526129923, Recall = 0.9955555555555555, Aging Rate = 0.0909826122118884, Precision = 0.9955555555555555, f1 = 0.9955555555555555\n",
      "Epoch 22: Train Loss = 0.005393670192850754, Recall = 0.9955555555555555, Aging Rate = 0.09057824504650222, Precision = 0, f1 = 0.0\n",
      "Epoch 23: Train Loss = 0.004784203701536972, Recall = 0.9955555555555555, Aging Rate = 0.0909826122118884, Precision = 0.9955555555555555, f1 = 0.9955555555555555\n",
      "Epoch 24: Train Loss = 0.004454518862112338, Recall = 0.9955555555555555, Aging Rate = 0.09057824504650222, Precision = 0, f1 = 0.0\n",
      "Epoch 25: Train Loss = 0.004556708384321809, Recall = 0.9955555555555555, Aging Rate = 0.09057824504650222, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.003943322384198981, Recall = 1.0, Aging Rate = 0.0909826122118884, precision = 1.0\n",
      "Model in epoch 25 is saved.\n",
      "\n",
      "Epoch 26: Train Loss = 0.003667736095626749, Recall = 0.9955555555555555, Aging Rate = 0.09057824504650222, Precision = 0, f1 = 0.0\n",
      "Epoch 27: Train Loss = 0.003680085491056125, Recall = 0.9955555555555555, Aging Rate = 0.09057824504650222, Precision = 0, f1 = 0.0\n",
      "Epoch 28: Train Loss = 0.003024473247350654, Recall = 0.9955555555555555, Aging Rate = 0.09057824504650222, Precision = 0, f1 = 0.0\n",
      "Epoch 29: Train Loss = 0.0027955450471400236, Recall = 1.0, Aging Rate = 0.0909826122118884, Precision = 0, f1 = 0.0\n",
      "Epoch 30: Train Loss = 0.0028463794303371795, Recall = 0.9955555555555555, Aging Rate = 0.09057824504650222, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0029540775433029064, Recall = 1.0, Aging Rate = 0.0909826122118884, precision = 1.0\n",
      "\n",
      "Epoch 31: Train Loss = 0.002737937939354794, Recall = 1.0, Aging Rate = 0.0909826122118884, Precision = 0, f1 = 0.0\n",
      "Epoch 32: Train Loss = 0.0025658826292874696, Recall = 0.9955555555555555, Aging Rate = 0.09057824504650222, Precision = 0, f1 = 0.0\n",
      "Epoch 33: Train Loss = 0.0025650889961462463, Recall = 1.0, Aging Rate = 0.0909826122118884, Precision = 0, f1 = 0.0\n",
      "Epoch 34: Train Loss = 0.0024305488635570087, Recall = 1.0, Aging Rate = 0.0909826122118884, Precision = 0, f1 = 0.0\n",
      "Epoch 35: Train Loss = 0.002509760824015181, Recall = 1.0, Aging Rate = 0.0909826122118884, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.002585126304648006, Recall = 1.0, Aging Rate = 0.0909826122118884, precision = 1.0\n",
      "\n",
      "Epoch 36: Train Loss = 0.0026016017332450127, Recall = 1.0, Aging Rate = 0.0909826122118884, Precision = 0, f1 = 0.0\n",
      "Epoch 37: Train Loss = 0.002433604434444398, Recall = 1.0, Aging Rate = 0.0909826122118884, Precision = 0, f1 = 0.0\n",
      "Epoch 38: Train Loss = 0.002602935442813961, Recall = 1.0, Aging Rate = 0.0909826122118884, Precision = 0, f1 = 0.0\n",
      "Epoch 39: Train Loss = 0.0023581917426205067, Recall = 1.0, Aging Rate = 0.0909826122118884, Precision = 0, f1 = 0.0\n",
      "Epoch 40: Train Loss = 0.002198660753795774, Recall = 1.0, Aging Rate = 0.0909826122118884, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0021149525154318723, Recall = 1.0, Aging Rate = 0.0909826122118884, precision = 1.0\n",
      "\n",
      "Epoch 41: Train Loss = 0.0021003232878138373, Recall = 1.0, Aging Rate = 0.0909826122118884, Precision = 0, f1 = 0.0\n",
      "Epoch 42: Train Loss = 0.00191020887630159, Recall = 1.0, Aging Rate = 0.0909826122118884, Precision = 0, f1 = 0.0\n",
      "Epoch 43: Train Loss = 0.0023006502563115757, Recall = 1.0, Aging Rate = 0.0909826122118884, Precision = 0, f1 = 0.0\n",
      "Epoch 44: Train Loss = 0.002122759527545249, Recall = 1.0, Aging Rate = 0.0909826122118884, Precision = 0, f1 = 0.0\n",
      "Epoch 45: Train Loss = 0.001958517179200392, Recall = 1.0, Aging Rate = 0.0909826122118884, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0014637781756098153, Recall = 1.0, Aging Rate = 0.0909826122118884, precision = 1.0\n",
      "\n",
      "Epoch 46: Train Loss = 0.0019606390317959965, Recall = 1.0, Aging Rate = 0.0909826122118884, Precision = 0, f1 = 0.0\n",
      "Epoch 47: Train Loss = 0.0017367973907442453, Recall = 1.0, Aging Rate = 0.0909826122118884, Precision = 0, f1 = 0.0\n",
      "Epoch 48: Train Loss = 0.001605876641721023, Recall = 1.0, Aging Rate = 0.0909826122118884, Precision = 0, f1 = 0.0\n",
      "Epoch 49: Train Loss = 0.0016204188047771542, Recall = 1.0, Aging Rate = 0.0909826122118884, Precision = 0, f1 = 0.0\n",
      "Epoch 50: Train Loss = 0.0015826916287841823, Recall = 1.0, Aging Rate = 0.0909826122118884, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0014616691460230399, Recall = 1.0, Aging Rate = 0.0909826122118884, precision = 1.0\n",
      "\n",
      "Epoch 51: Train Loss = 0.0016157123136111553, Recall = 1.0, Aging Rate = 0.0909826122118884, Precision = 0, f1 = 0.0\n",
      "Epoch 52: Train Loss = 0.0018364623583645363, Recall = 1.0, Aging Rate = 0.0909826122118884, Precision = 0, f1 = 0.0\n",
      "Epoch 53: Train Loss = 0.0018364710550080401, Recall = 1.0, Aging Rate = 0.0909826122118884, Precision = 0, f1 = 0.0\n",
      "Epoch 54: Train Loss = 0.0018258963986851646, Recall = 1.0, Aging Rate = 0.0909826122118884, Precision = 0, f1 = 0.0\n",
      "Epoch 55: Train Loss = 0.0019931694410976327, Recall = 1.0, Aging Rate = 0.0909826122118884, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.002086333265046793, Recall = 0.9955555555555555, Aging Rate = 0.09057824504650222, precision = 1.0\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 56: Train Loss = 0.0028620131575158624, Recall = 0.9955555555555555, Aging Rate = 0.0909826122118884, Precision = 0.9955555555555555, f1 = 0.9955555555555555\n",
      "Epoch 57: Train Loss = 0.021472222331777258, Recall = 0.9466666666666667, Aging Rate = 0.08774767488879903, Precision = 0.9815668202764977, f1 = 0.9638009049773756\n",
      "Epoch 58: Train Loss = 0.04189490473588565, Recall = 0.8977777777777778, Aging Rate = 0.08774767488879903, Precision = 0.9308755760368663, f1 = 0.9140271493212669\n",
      "Epoch 59: Train Loss = 0.03162816487888407, Recall = 0.9333333333333333, Aging Rate = 0.09057824504650222, Precision = 0.9375, f1 = 0.9354120267260579\n",
      "Epoch 60: Train Loss = 0.010960303072987468, Recall = 0.9777777777777777, Aging Rate = 0.0909826122118884, Precision = 0.9777777777777777, f1 = 0.9777777777777777\n",
      "Test Loss = 0.017778399713176237, Recall = 1.0, Aging Rate = 0.09826122118883947, precision = 0.9259259259259259\n",
      "\n",
      "Epoch 61: Train Loss = 0.012835687578471623, Recall = 0.9555555555555556, Aging Rate = 0.08855640921957138, Precision = 0.9817351598173516, f1 = 0.9684684684684685\n",
      "Epoch 62: Train Loss = 0.012209964695048028, Recall = 0.9822222222222222, Aging Rate = 0.0909826122118884, Precision = 0.9822222222222222, f1 = 0.9822222222222222\n",
      "Epoch 63: Train Loss = 0.00474147320571749, Recall = 0.9822222222222222, Aging Rate = 0.08936514355034371, Precision = 0, f1 = 0.0\n",
      "Epoch 64: Train Loss = 0.0027898916555888684, Recall = 0.9955555555555555, Aging Rate = 0.09057824504650222, Precision = 0, f1 = 0.0\n",
      "Epoch 65: Train Loss = 0.0012611296987089487, Recall = 1.0, Aging Rate = 0.0909826122118884, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0008870228482031833, Recall = 1.0, Aging Rate = 0.0909826122118884, precision = 1.0\n",
      "\n",
      "Epoch 66: Train Loss = 0.0007769169963390129, Recall = 1.0, Aging Rate = 0.0909826122118884, Precision = 0, f1 = 0.0\n",
      "Epoch 67: Train Loss = 0.0007549330638853394, Recall = 1.0, Aging Rate = 0.0909826122118884, Precision = 0, f1 = 0.0\n",
      "Epoch 68: Train Loss = 0.0007086909726601782, Recall = 1.0, Aging Rate = 0.0909826122118884, Precision = 0, f1 = 0.0\n",
      "Epoch 69: Train Loss = 0.000647499623954721, Recall = 1.0, Aging Rate = 0.0909826122118884, Precision = 0, f1 = 0.0\n",
      "Epoch 70: Train Loss = 0.0006598866449290901, Recall = 1.0, Aging Rate = 0.0909826122118884, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0006195911675944113, Recall = 1.0, Aging Rate = 0.0909826122118884, precision = 1.0\n",
      "\n",
      "Epoch 71: Train Loss = 0.0006642509716929354, Recall = 1.0, Aging Rate = 0.0909826122118884, Precision = 0, f1 = 0.0\n",
      "Epoch 72: Train Loss = 0.0007022651771702599, Recall = 1.0, Aging Rate = 0.0909826122118884, Precision = 0, f1 = 0.0\n",
      "Epoch 73: Train Loss = 0.0007235871395284481, Recall = 1.0, Aging Rate = 0.0909826122118884, Precision = 0, f1 = 0.0\n",
      "Epoch 74: Train Loss = 0.000732190240849769, Recall = 1.0, Aging Rate = 0.0909826122118884, Precision = 0, f1 = 0.0\n",
      "Epoch 75: Train Loss = 0.0007352170523510643, Recall = 1.0, Aging Rate = 0.0909826122118884, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0007206729232505705, Recall = 1.0, Aging Rate = 0.0909826122118884, precision = 1.0\n",
      "\n",
      "Training Finished at epoch 75.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8275488242cb46f5b537b439049d8be4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss = 0.36105981381784025, Recall = 0.05333333333333334, Aging Rate = 0.03841488071168621, Precision = 0.12631578947368421, f1 = 0.075\n",
      "Epoch 2: Train Loss = 0.24411495292037302, Recall = 0.022222222222222223, Aging Rate = 0.0020218358269308533, Precision = 0, f1 = 0.0\n",
      "Epoch 3: Train Loss = 0.19571468517262589, Recall = 0.15555555555555556, Aging Rate = 0.014152850788515973, Precision = 0, f1 = 0.0\n",
      "Epoch 4: Train Loss = 0.1624840627399187, Recall = 0.3466666666666667, Aging Rate = 0.03234937323089365, Precision = 0.975, f1 = 0.5114754098360655\n",
      "Epoch 5: Train Loss = 0.14506889763410594, Recall = 0.4222222222222222, Aging Rate = 0.042458552365547915, Precision = 0.9047619047619048, f1 = 0.5757575757575758\n",
      "Test Loss = 0.11930157556027186, Recall = 0.6266666666666667, Aging Rate = 0.05984634047715325, precision = 0.9527027027027027\n",
      "Model in epoch 5 is saved.\n",
      "\n",
      "Epoch 6: Train Loss = 0.11645053403306672, Recall = 0.6133333333333333, Aging Rate = 0.05742013748483623, Precision = 0.971830985915493, f1 = 0.7520435967302452\n",
      "Epoch 7: Train Loss = 0.09698667363676039, Recall = 0.7022222222222222, Aging Rate = 0.06793368378487667, Precision = 0.9404761904761905, f1 = 0.8040712468193384\n",
      "Epoch 8: Train Loss = 0.0807550198308524, Recall = 0.7555555555555555, Aging Rate = 0.0715729882733522, Precision = 0.96045197740113, f1 = 0.845771144278607\n",
      "Epoch 9: Train Loss = 0.06727652475870528, Recall = 0.7911111111111111, Aging Rate = 0.07399919126566923, Precision = 0.9726775956284153, f1 = 0.8725490196078431\n",
      "Epoch 10: Train Loss = 0.053688377150990826, Recall = 0.8577777777777778, Aging Rate = 0.07966033158107562, Precision = 0.9796954314720813, f1 = 0.9146919431279622\n",
      "Test Loss = 0.0542163219961183, Recall = 0.96, Aging Rate = 0.09138697937727457, precision = 0.9557522123893806\n",
      "Model in epoch 10 is saved.\n",
      "\n",
      "Epoch 11: Train Loss = 0.046253038292356795, Recall = 0.8933333333333333, Aging Rate = 0.0841083704003235, Precision = 0.9663461538461539, f1 = 0.9284064665127021\n",
      "Epoch 12: Train Loss = 0.03824822751076849, Recall = 0.9155555555555556, Aging Rate = 0.08370400323493732, Precision = 0.9951690821256038, f1 = 0.9537037037037037\n",
      "Epoch 13: Train Loss = 0.030037047690194097, Recall = 0.9244444444444444, Aging Rate = 0.08451273756570966, Precision = 0.9952153110047847, f1 = 0.9585253456221197\n",
      "Epoch 14: Train Loss = 0.02514520818928729, Recall = 0.9555555555555556, Aging Rate = 0.08693894055802669, Precision = 0, f1 = 0.0\n",
      "Epoch 15: Train Loss = 0.02005348614241146, Recall = 0.9688888888888889, Aging Rate = 0.08855640921957138, Precision = 0.9954337899543378, f1 = 0.9819819819819819\n",
      "Test Loss = 0.01784333248208083, Recall = 0.9822222222222222, Aging Rate = 0.09017387788111605, precision = 0.9910313901345291\n",
      "Model in epoch 15 is saved.\n",
      "\n",
      "Epoch 16: Train Loss = 0.0174262834689514, Recall = 0.9777777777777777, Aging Rate = 0.08896077638495754, Precision = 0, f1 = 0.0\n",
      "Epoch 17: Train Loss = 0.016651780363375654, Recall = 0.9777777777777777, Aging Rate = 0.08936514355034371, Precision = 0.995475113122172, f1 = 0.9865470852017937\n",
      "Epoch 18: Train Loss = 0.014945574614132373, Recall = 0.9777777777777777, Aging Rate = 0.08936514355034371, Precision = 0.995475113122172, f1 = 0.9865470852017937\n",
      "Epoch 19: Train Loss = 0.010930216461841847, Recall = 0.9822222222222222, Aging Rate = 0.08936514355034371, Precision = 0, f1 = 0.0\n",
      "Epoch 20: Train Loss = 0.010055951611430742, Recall = 0.9866666666666667, Aging Rate = 0.08976951071572989, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.006906054656311653, Recall = 0.9911111111111112, Aging Rate = 0.09017387788111605, precision = 1.0\n",
      "Model in epoch 20 is saved.\n",
      "\n",
      "Epoch 21: Train Loss = 0.008838507940701228, Recall = 0.9822222222222222, Aging Rate = 0.08936514355034371, Precision = 0, f1 = 0.0\n",
      "Epoch 22: Train Loss = 0.007092374546797566, Recall = 0.9911111111111112, Aging Rate = 0.09017387788111605, Precision = 0, f1 = 0.0\n",
      "Epoch 23: Train Loss = 0.007630487271270866, Recall = 0.9911111111111112, Aging Rate = 0.0909826122118884, Precision = 0.9911111111111112, f1 = 0.9911111111111112\n",
      "Epoch 24: Train Loss = 0.0070376941272171705, Recall = 0.9911111111111112, Aging Rate = 0.09017387788111605, Precision = 0, f1 = 0.0\n",
      "Epoch 25: Train Loss = 0.008436713372972925, Recall = 0.9911111111111112, Aging Rate = 0.09057824504650222, Precision = 0.9955357142857143, f1 = 0.9933184855233853\n",
      "Test Loss = 0.004942119367468877, Recall = 0.9911111111111112, Aging Rate = 0.09017387788111605, precision = 1.0\n",
      "\n",
      "Epoch 26: Train Loss = 0.005976712045433385, Recall = 0.9955555555555555, Aging Rate = 0.09057824504650222, Precision = 0, f1 = 0.0\n",
      "Epoch 27: Train Loss = 0.0047836395173932, Recall = 1.0, Aging Rate = 0.0909826122118884, Precision = 0, f1 = 0.0\n",
      "Epoch 28: Train Loss = 0.004102186547378376, Recall = 1.0, Aging Rate = 0.0909826122118884, Precision = 0, f1 = 0.0\n",
      "Epoch 29: Train Loss = 0.003567113615821006, Recall = 0.9955555555555555, Aging Rate = 0.09057824504650222, Precision = 0, f1 = 0.0\n",
      "Epoch 30: Train Loss = 0.0032513760134963384, Recall = 1.0, Aging Rate = 0.0909826122118884, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.002998764799680716, Recall = 1.0, Aging Rate = 0.0909826122118884, precision = 1.0\n",
      "Model in epoch 30 is saved.\n",
      "\n",
      "Epoch 31: Train Loss = 0.0032415132628986518, Recall = 1.0, Aging Rate = 0.0909826122118884, Precision = 0, f1 = 0.0\n",
      "Epoch 32: Train Loss = 0.0030845946367201874, Recall = 1.0, Aging Rate = 0.0909826122118884, Precision = 0, f1 = 0.0\n",
      "Epoch 33: Train Loss = 0.0029728640029240768, Recall = 1.0, Aging Rate = 0.0909826122118884, Precision = 0, f1 = 0.0\n",
      "Epoch 34: Train Loss = 0.002927495111958747, Recall = 1.0, Aging Rate = 0.0909826122118884, Precision = 0, f1 = 0.0\n",
      "Epoch 35: Train Loss = 0.0027363217655897707, Recall = 1.0, Aging Rate = 0.0909826122118884, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0026481752067799066, Recall = 1.0, Aging Rate = 0.0909826122118884, precision = 1.0\n",
      "\n",
      "Epoch 36: Train Loss = 0.0027275890233563814, Recall = 1.0, Aging Rate = 0.0909826122118884, Precision = 0, f1 = 0.0\n",
      "Epoch 37: Train Loss = 0.0026318212864514527, Recall = 1.0, Aging Rate = 0.0909826122118884, Precision = 0, f1 = 0.0\n",
      "Epoch 38: Train Loss = 0.0026913696566345812, Recall = 1.0, Aging Rate = 0.0909826122118884, Precision = 0, f1 = 0.0\n",
      "Epoch 39: Train Loss = 0.002886169404958876, Recall = 0.9955555555555555, Aging Rate = 0.09057824504650222, Precision = 0, f1 = 0.0\n",
      "Epoch 40: Train Loss = 0.003636207210304486, Recall = 1.0, Aging Rate = 0.0909826122118884, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.00288667401496217, Recall = 1.0, Aging Rate = 0.0909826122118884, precision = 1.0\n",
      "\n",
      "Epoch 41: Train Loss = 0.0037131849152901805, Recall = 1.0, Aging Rate = 0.0909826122118884, Precision = 0, f1 = 0.0\n",
      "Epoch 42: Train Loss = 0.00434390944720604, Recall = 1.0, Aging Rate = 0.0909826122118884, Precision = 0, f1 = 0.0\n",
      "Epoch 43: Train Loss = 0.0033492827949931736, Recall = 1.0, Aging Rate = 0.0909826122118884, Precision = 0, f1 = 0.0\n",
      "Epoch 44: Train Loss = 0.002466508671750563, Recall = 1.0, Aging Rate = 0.0909826122118884, Precision = 0, f1 = 0.0\n",
      "Epoch 45: Train Loss = 0.002133013150800476, Recall = 1.0, Aging Rate = 0.0909826122118884, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0017010309077043115, Recall = 1.0, Aging Rate = 0.0909826122118884, precision = 1.0\n",
      "\n",
      "Epoch 46: Train Loss = 0.00208887766934276, Recall = 1.0, Aging Rate = 0.0909826122118884, Precision = 0, f1 = 0.0\n",
      "Epoch 47: Train Loss = 0.0021977406935679723, Recall = 1.0, Aging Rate = 0.0909826122118884, Precision = 0, f1 = 0.0\n",
      "Epoch 48: Train Loss = 0.002265319854687271, Recall = 1.0, Aging Rate = 0.0909826122118884, Precision = 0, f1 = 0.0\n",
      "Epoch 49: Train Loss = 0.0020046607490990112, Recall = 1.0, Aging Rate = 0.0909826122118884, Precision = 0, f1 = 0.0\n",
      "Epoch 50: Train Loss = 0.0018542005778039894, Recall = 1.0, Aging Rate = 0.0909826122118884, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0016509345365918681, Recall = 1.0, Aging Rate = 0.0909826122118884, precision = 1.0\n",
      "\n",
      "Epoch 51: Train Loss = 0.001905261299737081, Recall = 1.0, Aging Rate = 0.0909826122118884, Precision = 0, f1 = 0.0\n",
      "Epoch 52: Train Loss = 0.0018499516995451979, Recall = 1.0, Aging Rate = 0.0909826122118884, Precision = 0, f1 = 0.0\n",
      "Epoch 53: Train Loss = 0.0018967474216510182, Recall = 1.0, Aging Rate = 0.0909826122118884, Precision = 0, f1 = 0.0\n",
      "Epoch 54: Train Loss = 0.0020833936702758316, Recall = 1.0, Aging Rate = 0.0909826122118884, Precision = 0, f1 = 0.0\n",
      "Epoch 55: Train Loss = 0.0023276204665278466, Recall = 1.0, Aging Rate = 0.0909826122118884, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0018834020378779104, Recall = 1.0, Aging Rate = 0.0909826122118884, precision = 1.0\n",
      "\n",
      "Epoch 56: Train Loss = 0.002473625820600855, Recall = 1.0, Aging Rate = 0.0909826122118884, Precision = 0, f1 = 0.0\n",
      "Epoch 57: Train Loss = 0.0024957978297036262, Recall = 1.0, Aging Rate = 0.0909826122118884, Precision = 0, f1 = 0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58: Train Loss = 0.0019761953049848135, Recall = 1.0, Aging Rate = 0.0909826122118884, Precision = 0, f1 = 0.0\n",
      "Epoch 59: Train Loss = 0.0025209382900782157, Recall = 1.0, Aging Rate = 0.0909826122118884, Precision = 0, f1 = 0.0\n",
      "Epoch 60: Train Loss = 0.008479152835101143, Recall = 0.9866666666666667, Aging Rate = 0.09017387788111605, Precision = 0.9955156950672646, f1 = 0.9910714285714286\n",
      "Test Loss = 0.0158226139912381, Recall = 1.0, Aging Rate = 0.0950262838657501, precision = 0.9574468085106383\n",
      "\n",
      "Epoch 61: Train Loss = 0.018444036769846756, Recall = 0.9511111111111111, Aging Rate = 0.08774767488879903, Precision = 0.9861751152073732, f1 = 0.9683257918552037\n",
      "Epoch 62: Train Loss = 0.041908271758362585, Recall = 0.9155555555555556, Aging Rate = 0.09017387788111605, Precision = 0.9237668161434978, f1 = 0.9196428571428571\n",
      "Epoch 63: Train Loss = 0.036118015749368695, Recall = 0.9244444444444444, Aging Rate = 0.08774767488879903, Precision = 0.9585253456221198, f1 = 0.9411764705882352\n",
      "Epoch 64: Train Loss = 0.01862146066342813, Recall = 0.9555555555555556, Aging Rate = 0.08855640921957138, Precision = 0.9817351598173516, f1 = 0.9684684684684685\n",
      "Epoch 65: Train Loss = 0.007518326284441445, Recall = 0.9822222222222222, Aging Rate = 0.09017387788111605, Precision = 0.9910313901345291, f1 = 0.9866071428571429\n",
      "Test Loss = 0.003908812669167966, Recall = 0.9911111111111112, Aging Rate = 0.09057824504650222, precision = 0.9955357142857143\n",
      "\n",
      "Epoch 66: Train Loss = 0.003776146795862764, Recall = 1.0, Aging Rate = 0.09179134654266073, Precision = 0.9911894273127754, f1 = 0.9955752212389382\n",
      "Epoch 67: Train Loss = 0.0017637807823713074, Recall = 1.0, Aging Rate = 0.0909826122118884, Precision = 0, f1 = 0.0\n",
      "Epoch 68: Train Loss = 0.0014160434503896855, Recall = 1.0, Aging Rate = 0.0909826122118884, Precision = 0, f1 = 0.0\n",
      "Epoch 69: Train Loss = 0.0013423511393901506, Recall = 1.0, Aging Rate = 0.0909826122118884, Precision = 0, f1 = 0.0\n",
      "Epoch 70: Train Loss = 0.001424661299879966, Recall = 1.0, Aging Rate = 0.09138697937727457, Precision = 0.995575221238938, f1 = 0.9977827050997783\n",
      "Test Loss = 0.0010571612872539112, Recall = 1.0, Aging Rate = 0.0909826122118884, precision = 1.0\n",
      "\n",
      "Epoch 71: Train Loss = 0.001123463040917473, Recall = 1.0, Aging Rate = 0.0909826122118884, Precision = 0, f1 = 0.0\n",
      "Epoch 72: Train Loss = 0.0011195317132935512, Recall = 1.0, Aging Rate = 0.0909826122118884, Precision = 0, f1 = 0.0\n",
      "Epoch 73: Train Loss = 0.001196453770813922, Recall = 1.0, Aging Rate = 0.0909826122118884, Precision = 0, f1 = 0.0\n",
      "Epoch 74: Train Loss = 0.0010458026353061369, Recall = 1.0, Aging Rate = 0.0909826122118884, Precision = 0, f1 = 0.0\n",
      "Epoch 75: Train Loss = 0.0011617262447870488, Recall = 1.0, Aging Rate = 0.0909826122118884, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0010397687431589052, Recall = 1.0, Aging Rate = 0.0909826122118884, precision = 1.0\n",
      "\n",
      "Epoch 76: Train Loss = 0.0010859981676391516, Recall = 1.0, Aging Rate = 0.0909826122118884, Precision = 0, f1 = 0.0\n",
      "Epoch 77: Train Loss = 0.0011009490072474506, Recall = 1.0, Aging Rate = 0.0909826122118884, Precision = 0, f1 = 0.0\n",
      "Epoch 78: Train Loss = 0.001124943162772064, Recall = 1.0, Aging Rate = 0.0909826122118884, Precision = 0, f1 = 0.0\n",
      "Epoch 79: Train Loss = 0.0011389447875051458, Recall = 1.0, Aging Rate = 0.0909826122118884, Precision = 0, f1 = 0.0\n",
      "Epoch 80: Train Loss = 0.0011984869737774616, Recall = 1.0, Aging Rate = 0.0909826122118884, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0011568842651104058, Recall = 1.0, Aging Rate = 0.0909826122118884, precision = 1.0\n",
      "\n",
      "Training Finished at epoch 80.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ae2c5465bf040dba0cbb5ec425abe49",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss = 0.32115543568597255, Recall = 0.026785714285714284, Aging Rate = 0.024271844660194174, Precision = 0.1, f1 = 0.04225352112676056\n",
      "Epoch 2: Train Loss = 0.2193255793411755, Recall = 0.12053571428571429, Aging Rate = 0.012135922330097087, Precision = 0.9, f1 = 0.2125984251968504\n",
      "Epoch 3: Train Loss = 0.1784442823054721, Recall = 0.2767857142857143, Aging Rate = 0.02669902912621359, Precision = 0.9393939393939394, f1 = 0.4275862068965517\n",
      "Epoch 4: Train Loss = 0.14433542038630515, Recall = 0.4017857142857143, Aging Rate = 0.03762135922330097, Precision = 0.967741935483871, f1 = 0.5678233438485805\n",
      "Epoch 5: Train Loss = 0.12588523704450108, Recall = 0.5044642857142857, Aging Rate = 0.04813915857605178, Precision = 0.9495798319327731, f1 = 0.6588921282798833\n",
      "Test Loss = 0.09870057690490797, Recall = 0.6696428571428571, Aging Rate = 0.06108414239482201, precision = 0.9933774834437086\n",
      "Model in epoch 5 is saved.\n",
      "\n",
      "Epoch 6: Train Loss = 0.09919866688043169, Recall = 0.7098214285714286, Aging Rate = 0.06715210355987054, Precision = 0.9578313253012049, f1 = 0.8153846153846154\n",
      "Epoch 7: Train Loss = 0.07593278613990372, Recall = 0.8080357142857143, Aging Rate = 0.0744336569579288, Precision = 0.9836956521739131, f1 = 0.8872549019607843\n",
      "Epoch 8: Train Loss = 0.055420421045816064, Recall = 0.8571428571428571, Aging Rate = 0.07766990291262135, Precision = 0, f1 = 0.0\n",
      "Epoch 9: Train Loss = 0.04263532252132314, Recall = 0.8973214285714286, Aging Rate = 0.08131067961165049, Precision = 0, f1 = 0.0\n",
      "Epoch 10: Train Loss = 0.032032362194460574, Recall = 0.9330357142857143, Aging Rate = 0.08454692556634304, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.025184347755411295, Recall = 0.9553571428571429, Aging Rate = 0.08656957928802589, precision = 1.0\n",
      "Model in epoch 10 is saved.\n",
      "\n",
      "Epoch 11: Train Loss = 0.024689614790880565, Recall = 0.9508928571428571, Aging Rate = 0.08616504854368932, Precision = 0, f1 = 0.0\n",
      "Epoch 12: Train Loss = 0.01971651787318072, Recall = 0.9642857142857143, Aging Rate = 0.08737864077669903, Precision = 0, f1 = 0.0\n",
      "Epoch 13: Train Loss = 0.017587415259150627, Recall = 0.9642857142857143, Aging Rate = 0.08737864077669903, Precision = 0, f1 = 0.0\n",
      "Epoch 14: Train Loss = 0.012653421447838395, Recall = 0.9821428571428571, Aging Rate = 0.0889967637540453, Precision = 0, f1 = 0.0\n",
      "Epoch 15: Train Loss = 0.01236615616611196, Recall = 0.9776785714285714, Aging Rate = 0.0889967637540453, Precision = 0.9954545454545455, f1 = 0.9864864864864865\n",
      "Test Loss = 0.008695854611007624, Recall = 0.9866071428571429, Aging Rate = 0.08980582524271845, precision = 0.9954954954954955\n",
      "Model in epoch 15 is saved.\n",
      "\n",
      "Epoch 16: Train Loss = 0.008900723808888093, Recall = 0.9910714285714286, Aging Rate = 0.09021035598705501, Precision = 0.9955156950672646, f1 = 0.9932885906040269\n",
      "Epoch 17: Train Loss = 0.007952639959680223, Recall = 0.9955357142857143, Aging Rate = 0.09061488673139159, Precision = 0.9955357142857143, f1 = 0.9955357142857143\n",
      "Epoch 18: Train Loss = 0.006039358051584184, Recall = 0.9910714285714286, Aging Rate = 0.09021035598705501, Precision = 0.9955156950672646, f1 = 0.9932885906040269\n",
      "Epoch 19: Train Loss = 0.004834590873057113, Recall = 0.9955357142857143, Aging Rate = 0.09021035598705501, Precision = 0, f1 = 0.0\n",
      "Epoch 20: Train Loss = 0.004019363195572084, Recall = 1.0, Aging Rate = 0.09101941747572816, Precision = 0.9955555555555555, f1 = 0.9977728285077951\n",
      "Test Loss = 0.0038424942018554626, Recall = 0.9955357142857143, Aging Rate = 0.09021035598705501, precision = 1.0\n",
      "Model in epoch 20 is saved.\n",
      "\n",
      "Epoch 21: Train Loss = 0.005201674586397062, Recall = 0.9910714285714286, Aging Rate = 0.08980582524271845, Precision = 0, f1 = 0.0\n",
      "Epoch 22: Train Loss = 0.00462795204926029, Recall = 1.0, Aging Rate = 0.09101941747572816, Precision = 0.9955555555555555, f1 = 0.9977728285077951\n",
      "Epoch 23: Train Loss = 0.0037687676077148, Recall = 0.9955357142857143, Aging Rate = 0.09021035598705501, Precision = 0, f1 = 0.0\n",
      "Epoch 24: Train Loss = 0.00320650603920583, Recall = 1.0, Aging Rate = 0.09061488673139159, Precision = 0, f1 = 0.0\n",
      "Epoch 25: Train Loss = 0.003196465850635929, Recall = 1.0, Aging Rate = 0.09061488673139159, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0033737108274136934, Recall = 1.0, Aging Rate = 0.09061488673139159, precision = 1.0\n",
      "Model in epoch 25 is saved.\n",
      "\n",
      "Epoch 26: Train Loss = 0.002827341605014014, Recall = 1.0, Aging Rate = 0.09061488673139159, Precision = 0, f1 = 0.0\n",
      "Epoch 27: Train Loss = 0.0025401521989515106, Recall = 1.0, Aging Rate = 0.09061488673139159, Precision = 0, f1 = 0.0\n",
      "Epoch 28: Train Loss = 0.0024308928964406396, Recall = 1.0, Aging Rate = 0.09061488673139159, Precision = 0, f1 = 0.0\n",
      "Epoch 29: Train Loss = 0.0027056799102936264, Recall = 1.0, Aging Rate = 0.09061488673139159, Precision = 0, f1 = 0.0\n",
      "Epoch 30: Train Loss = 0.0023264896070349563, Recall = 1.0, Aging Rate = 0.09061488673139159, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.002310970011483697, Recall = 1.0, Aging Rate = 0.09061488673139159, precision = 1.0\n",
      "\n",
      "Epoch 31: Train Loss = 0.0023389457062664397, Recall = 1.0, Aging Rate = 0.09061488673139159, Precision = 0, f1 = 0.0\n",
      "Epoch 32: Train Loss = 0.002279841970625216, Recall = 1.0, Aging Rate = 0.09061488673139159, Precision = 0, f1 = 0.0\n",
      "Epoch 33: Train Loss = 0.0023371492833513946, Recall = 1.0, Aging Rate = 0.09061488673139159, Precision = 0, f1 = 0.0\n",
      "Epoch 34: Train Loss = 0.0021910165929353064, Recall = 1.0, Aging Rate = 0.09061488673139159, Precision = 0, f1 = 0.0\n",
      "Epoch 35: Train Loss = 0.002044558305817756, Recall = 1.0, Aging Rate = 0.09061488673139159, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0019466306367726292, Recall = 1.0, Aging Rate = 0.09061488673139159, precision = 1.0\n",
      "\n",
      "Epoch 36: Train Loss = 0.0021531905241997788, Recall = 1.0, Aging Rate = 0.09061488673139159, Precision = 0, f1 = 0.0\n",
      "Epoch 37: Train Loss = 0.0029828624157867962, Recall = 1.0, Aging Rate = 0.09101941747572816, Precision = 0.9955555555555555, f1 = 0.9977728285077951\n",
      "Epoch 38: Train Loss = 0.004255634838787531, Recall = 0.9955357142857143, Aging Rate = 0.09021035598705501, Precision = 0, f1 = 0.0\n",
      "Epoch 39: Train Loss = 0.015634654575814175, Recall = 0.9732142857142857, Aging Rate = 0.08940129449838188, Precision = 0.9864253393665159, f1 = 0.9797752808988764\n",
      "Epoch 40: Train Loss = 0.028863160292283425, Recall = 0.9285714285714286, Aging Rate = 0.08656957928802589, Precision = 0.9719626168224299, f1 = 0.949771689497717\n",
      "Test Loss = 0.021114915175345337, Recall = 0.9955357142857143, Aging Rate = 0.09385113268608414, precision = 0.9612068965517241\n",
      "\n",
      "Epoch 41: Train Loss = 0.026114914869184342, Recall = 0.9375, Aging Rate = 0.08859223300970874, Precision = 0.958904109589041, f1 = 0.9480812641083523\n",
      "Epoch 42: Train Loss = 0.0137623946941955, Recall = 0.96875, Aging Rate = 0.08940129449838188, Precision = 0.9819004524886877, f1 = 0.9752808988764045\n",
      "Epoch 43: Train Loss = 0.009788269963730308, Recall = 0.9821428571428571, Aging Rate = 0.08940129449838188, Precision = 0.995475113122172, f1 = 0.9887640449438202\n",
      "Epoch 44: Train Loss = 0.004197179351128565, Recall = 0.9955357142857143, Aging Rate = 0.09021035598705501, Precision = 0, f1 = 0.0\n",
      "Epoch 45: Train Loss = 0.0016888777264258237, Recall = 1.0, Aging Rate = 0.09061488673139159, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0016036284160664649, Recall = 1.0, Aging Rate = 0.09061488673139159, precision = 1.0\n",
      "\n",
      "Epoch 46: Train Loss = 0.0013763354407415444, Recall = 1.0, Aging Rate = 0.09061488673139159, Precision = 0, f1 = 0.0\n",
      "Epoch 47: Train Loss = 0.0010790442770970896, Recall = 1.0, Aging Rate = 0.09061488673139159, Precision = 0, f1 = 0.0\n",
      "Epoch 48: Train Loss = 0.0008810155937963536, Recall = 1.0, Aging Rate = 0.09061488673139159, Precision = 0, f1 = 0.0\n",
      "Epoch 49: Train Loss = 0.0008651984751550029, Recall = 1.0, Aging Rate = 0.09061488673139159, Precision = 0, f1 = 0.0\n",
      "Epoch 50: Train Loss = 0.0008249212467807878, Recall = 1.0, Aging Rate = 0.09061488673139159, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0007721930617936751, Recall = 1.0, Aging Rate = 0.09061488673139159, precision = 1.0\n",
      "\n",
      "Epoch 51: Train Loss = 0.0008444441516332112, Recall = 1.0, Aging Rate = 0.09061488673139159, Precision = 0, f1 = 0.0\n",
      "Epoch 52: Train Loss = 0.0008754617666251487, Recall = 1.0, Aging Rate = 0.09061488673139159, Precision = 0, f1 = 0.0\n",
      "Epoch 53: Train Loss = 0.0009261514054548031, Recall = 1.0, Aging Rate = 0.09061488673139159, Precision = 0, f1 = 0.0\n",
      "Epoch 54: Train Loss = 0.0010016765552844165, Recall = 1.0, Aging Rate = 0.09061488673139159, Precision = 0, f1 = 0.0\n",
      "Epoch 55: Train Loss = 0.0010129549016145247, Recall = 1.0, Aging Rate = 0.09061488673139159, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0008965842821409257, Recall = 1.0, Aging Rate = 0.09061488673139159, precision = 1.0\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 56: Train Loss = 0.0009572539875256712, Recall = 1.0, Aging Rate = 0.09061488673139159, Precision = 0, f1 = 0.0\n",
      "Epoch 57: Train Loss = 0.001021059887773059, Recall = 1.0, Aging Rate = 0.09061488673139159, Precision = 0, f1 = 0.0\n",
      "Epoch 58: Train Loss = 0.0010970595272402595, Recall = 1.0, Aging Rate = 0.09061488673139159, Precision = 0, f1 = 0.0\n",
      "Epoch 59: Train Loss = 0.0011112378182305583, Recall = 1.0, Aging Rate = 0.09061488673139159, Precision = 0, f1 = 0.0\n",
      "Epoch 60: Train Loss = 0.001120353723396954, Recall = 1.0, Aging Rate = 0.09061488673139159, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.001036446743861781, Recall = 1.0, Aging Rate = 0.09061488673139159, precision = 1.0\n",
      "\n",
      "Epoch 61: Train Loss = 0.0011546377327691004, Recall = 1.0, Aging Rate = 0.09061488673139159, Precision = 0, f1 = 0.0\n",
      "Epoch 62: Train Loss = 0.0012674299272193202, Recall = 1.0, Aging Rate = 0.09061488673139159, Precision = 0, f1 = 0.0\n",
      "Epoch 63: Train Loss = 0.0012187322848069581, Recall = 1.0, Aging Rate = 0.09061488673139159, Precision = 0, f1 = 0.0\n",
      "Epoch 64: Train Loss = 0.0011991220255138226, Recall = 1.0, Aging Rate = 0.09061488673139159, Precision = 0, f1 = 0.0\n",
      "Epoch 65: Train Loss = 0.0012875661351130282, Recall = 1.0, Aging Rate = 0.09061488673139159, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.001194468969524413, Recall = 1.0, Aging Rate = 0.09061488673139159, precision = 1.0\n",
      "\n",
      "Epoch 66: Train Loss = 0.0013509845661758943, Recall = 1.0, Aging Rate = 0.09061488673139159, Precision = 0, f1 = 0.0\n",
      "Epoch 67: Train Loss = 0.0014214790720058588, Recall = 1.0, Aging Rate = 0.09061488673139159, Precision = 0, f1 = 0.0\n",
      "Epoch 68: Train Loss = 0.0013101195500603, Recall = 1.0, Aging Rate = 0.09061488673139159, Precision = 0, f1 = 0.0\n",
      "Epoch 69: Train Loss = 0.0013790011046526647, Recall = 1.0, Aging Rate = 0.09061488673139159, Precision = 0, f1 = 0.0\n",
      "Epoch 70: Train Loss = 0.0013927922570553509, Recall = 1.0, Aging Rate = 0.09061488673139159, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0013783817401029242, Recall = 1.0, Aging Rate = 0.09061488673139159, precision = 1.0\n",
      "\n",
      "Epoch 71: Train Loss = 0.0014356735718517918, Recall = 1.0, Aging Rate = 0.09061488673139159, Precision = 0, f1 = 0.0\n",
      "Epoch 72: Train Loss = 0.0015356020800751245, Recall = 1.0, Aging Rate = 0.09061488673139159, Precision = 0, f1 = 0.0\n",
      "Epoch 73: Train Loss = 0.001708510034554864, Recall = 1.0, Aging Rate = 0.09061488673139159, Precision = 0, f1 = 0.0\n",
      "Epoch 74: Train Loss = 0.0031322924334338856, Recall = 1.0, Aging Rate = 0.09101941747572816, Precision = 0.9955555555555555, f1 = 0.9977728285077951\n",
      "Epoch 75: Train Loss = 0.011601548804675491, Recall = 0.9821428571428571, Aging Rate = 0.08980582524271845, Precision = 0.990990990990991, f1 = 0.9865470852017937\n",
      "Test Loss = 0.004561589449843012, Recall = 0.9821428571428571, Aging Rate = 0.0889967637540453, precision = 1.0\n",
      "\n",
      "Training Finished at epoch 75.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f3afe18f6f54445c85c23197587914ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss = 0.4606275772980915, Recall = 0.04888888888888889, Aging Rate = 0.03639304488475536, Precision = 0.12222222222222222, f1 = 0.06984126984126984\n",
      "Epoch 2: Train Loss = 0.3275213864376995, Recall = 0.3422222222222222, Aging Rate = 0.04569348968863728, Precision = 0.6814159292035398, f1 = 0.45562130177514787\n",
      "Epoch 3: Train Loss = 0.26638763377746494, Recall = 0.5333333333333333, Aging Rate = 0.07197735543873837, Precision = 0.6741573033707865, f1 = 0.5955334987593052\n",
      "Epoch 4: Train Loss = 0.22278364502824466, Recall = 0.6266666666666667, Aging Rate = 0.07238172260412455, Precision = 0.7877094972067039, f1 = 0.698019801980198\n",
      "Epoch 5: Train Loss = 0.1837289592682761, Recall = 0.6933333333333334, Aging Rate = 0.07885159725030327, Precision = 0.8, f1 = 0.7428571428571429\n",
      "Test Loss = 0.12251580652079985, Recall = 0.8533333333333334, Aging Rate = 0.08572583906186818, precision = 0.9056603773584906\n",
      "Model in epoch 5 is saved.\n",
      "\n",
      "Epoch 6: Train Loss = 0.12105296272596174, Recall = 0.8355555555555556, Aging Rate = 0.08208653457339264, Precision = 0.9261083743842364, f1 = 0.8785046728971964\n",
      "Epoch 7: Train Loss = 0.08652513782131108, Recall = 0.8888888888888888, Aging Rate = 0.08896077638495754, Precision = 0.9090909090909091, f1 = 0.8988764044943819\n",
      "Epoch 8: Train Loss = 0.0684498429518333, Recall = 0.9288888888888889, Aging Rate = 0.08774767488879903, Precision = 0.9631336405529954, f1 = 0.9457013574660633\n",
      "Epoch 9: Train Loss = 0.04436437290100086, Recall = 0.9688888888888889, Aging Rate = 0.09057824504650222, Precision = 0.9732142857142857, f1 = 0.9710467706013364\n",
      "Epoch 10: Train Loss = 0.032147799109760636, Recall = 0.9777777777777777, Aging Rate = 0.09138697937727457, Precision = 0.9734513274336283, f1 = 0.975609756097561\n",
      "Test Loss = 0.025213419492900662, Recall = 0.9955555555555555, Aging Rate = 0.09260008087343308, precision = 0.9781659388646288\n",
      "Model in epoch 10 is saved.\n",
      "\n",
      "Epoch 11: Train Loss = 0.024453283032252512, Recall = 0.9866666666666667, Aging Rate = 0.09057824504650222, Precision = 0.9910714285714286, f1 = 0.9888641425389756\n",
      "Epoch 12: Train Loss = 0.019013096369031684, Recall = 0.9866666666666667, Aging Rate = 0.0909826122118884, Precision = 0.9866666666666667, f1 = 0.9866666666666668\n",
      "Epoch 13: Train Loss = 0.0158440996514271, Recall = 0.9955555555555555, Aging Rate = 0.09138697937727457, Precision = 0.9911504424778761, f1 = 0.9933481152993349\n",
      "Epoch 14: Train Loss = 0.013707319123341314, Recall = 0.9955555555555555, Aging Rate = 0.0909826122118884, Precision = 0.9955555555555555, f1 = 0.9955555555555555\n",
      "Epoch 15: Train Loss = 0.013694124521512132, Recall = 0.9955555555555555, Aging Rate = 0.09138697937727457, Precision = 0.9911504424778761, f1 = 0.9933481152993349\n",
      "Test Loss = 0.010605142304573616, Recall = 1.0, Aging Rate = 0.09179134654266073, precision = 0.9911894273127754\n",
      "Model in epoch 15 is saved.\n",
      "\n",
      "Epoch 16: Train Loss = 0.011519885134272762, Recall = 0.9955555555555555, Aging Rate = 0.0909826122118884, Precision = 0.9955555555555555, f1 = 0.9955555555555555\n",
      "Epoch 17: Train Loss = 0.008976523895110382, Recall = 1.0, Aging Rate = 0.09179134654266073, Precision = 0.9911894273127754, f1 = 0.9955752212389382\n",
      "Epoch 18: Train Loss = 0.008444822956369176, Recall = 0.9955555555555555, Aging Rate = 0.09179134654266073, Precision = 0.986784140969163, f1 = 0.9911504424778761\n",
      "Epoch 19: Train Loss = 0.006457091880426733, Recall = 0.9955555555555555, Aging Rate = 0.09057824504650222, Precision = 0, f1 = 0.0\n",
      "Epoch 20: Train Loss = 0.0056174362684252455, Recall = 1.0, Aging Rate = 0.09138697937727457, Precision = 0.995575221238938, f1 = 0.9977827050997783\n",
      "Test Loss = 0.003717029893626201, Recall = 1.0, Aging Rate = 0.0909826122118884, precision = 1.0\n",
      "Model in epoch 20 is saved.\n",
      "\n",
      "Epoch 21: Train Loss = 0.004265224659763461, Recall = 1.0, Aging Rate = 0.09138697937727457, Precision = 0.995575221238938, f1 = 0.9977827050997783\n",
      "Epoch 22: Train Loss = 0.004109991652596541, Recall = 1.0, Aging Rate = 0.0909826122118884, Precision = 0, f1 = 0.0\n",
      "Epoch 23: Train Loss = 0.00407997218479982, Recall = 1.0, Aging Rate = 0.09138697937727457, Precision = 0.995575221238938, f1 = 0.9977827050997783\n",
      "Epoch 24: Train Loss = 0.003077725493742678, Recall = 1.0, Aging Rate = 0.0909826122118884, Precision = 0, f1 = 0.0\n",
      "Epoch 25: Train Loss = 0.0027071307780932117, Recall = 1.0, Aging Rate = 0.0909826122118884, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.00250910914356542, Recall = 1.0, Aging Rate = 0.0909826122118884, precision = 1.0\n",
      "\n",
      "Epoch 26: Train Loss = 0.0027363574372591686, Recall = 1.0, Aging Rate = 0.0909826122118884, Precision = 0, f1 = 0.0\n",
      "Epoch 27: Train Loss = 0.0025854821339870242, Recall = 1.0, Aging Rate = 0.0909826122118884, Precision = 0, f1 = 0.0\n",
      "Epoch 28: Train Loss = 0.002684998705753815, Recall = 1.0, Aging Rate = 0.0909826122118884, Precision = 0, f1 = 0.0\n",
      "Epoch 29: Train Loss = 0.0024028122897707662, Recall = 1.0, Aging Rate = 0.0909826122118884, Precision = 0, f1 = 0.0\n",
      "Epoch 30: Train Loss = 0.0023939641334438074, Recall = 1.0, Aging Rate = 0.0909826122118884, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.002321704755456432, Recall = 1.0, Aging Rate = 0.0909826122118884, precision = 1.0\n",
      "\n",
      "Epoch 31: Train Loss = 0.002338326641942536, Recall = 1.0, Aging Rate = 0.0909826122118884, Precision = 0, f1 = 0.0\n",
      "Epoch 32: Train Loss = 0.0022636059118232178, Recall = 1.0, Aging Rate = 0.0909826122118884, Precision = 0, f1 = 0.0\n",
      "Epoch 33: Train Loss = 0.002046222928546149, Recall = 1.0, Aging Rate = 0.0909826122118884, Precision = 0, f1 = 0.0\n",
      "Epoch 34: Train Loss = 0.0021076689727922236, Recall = 1.0, Aging Rate = 0.0909826122118884, Precision = 0, f1 = 0.0\n",
      "Epoch 35: Train Loss = 0.002194981914528808, Recall = 1.0, Aging Rate = 0.0909826122118884, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0018610041107913857, Recall = 1.0, Aging Rate = 0.0909826122118884, precision = 1.0\n",
      "\n",
      "Epoch 36: Train Loss = 0.002063807208140731, Recall = 1.0, Aging Rate = 0.0909826122118884, Precision = 0, f1 = 0.0\n",
      "Epoch 37: Train Loss = 0.002254346152579241, Recall = 1.0, Aging Rate = 0.0909826122118884, Precision = 0, f1 = 0.0\n",
      "Epoch 38: Train Loss = 0.0029600028263452416, Recall = 1.0, Aging Rate = 0.0909826122118884, Precision = 0, f1 = 0.0\n",
      "Epoch 39: Train Loss = 0.003909818950499714, Recall = 1.0, Aging Rate = 0.09138697937727457, Precision = 0.995575221238938, f1 = 0.9977827050997783\n",
      "Epoch 40: Train Loss = 0.0061684704427688326, Recall = 0.9955555555555555, Aging Rate = 0.09057824504650222, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.003886068948562262, Recall = 1.0, Aging Rate = 0.09138697937727457, precision = 0.995575221238938\n",
      "\n",
      "Epoch 41: Train Loss = 0.004687706416313116, Recall = 1.0, Aging Rate = 0.09138697937727457, Precision = 0.995575221238938, f1 = 0.9977827050997783\n",
      "Epoch 42: Train Loss = 0.008264072279318161, Recall = 0.9955555555555555, Aging Rate = 0.0909826122118884, Precision = 0.9955555555555555, f1 = 0.9955555555555555\n",
      "Epoch 43: Train Loss = 0.014521840970332064, Recall = 0.9866666666666667, Aging Rate = 0.09179134654266073, Precision = 0.9779735682819384, f1 = 0.9823008849557522\n",
      "Epoch 44: Train Loss = 0.017925943249480304, Recall = 0.9777777777777777, Aging Rate = 0.09219571370804691, Precision = 0.9649122807017544, f1 = 0.9713024282560706\n",
      "Epoch 45: Train Loss = 0.013219327924963655, Recall = 0.9955555555555555, Aging Rate = 0.09260008087343308, Precision = 0.9781659388646288, f1 = 0.986784140969163\n",
      "Test Loss = 0.012741798587524536, Recall = 1.0, Aging Rate = 0.0950262838657501, precision = 0.9574468085106383\n",
      "\n",
      "Epoch 46: Train Loss = 0.013706150613280801, Recall = 0.9955555555555555, Aging Rate = 0.09340881520420542, Precision = 0.9696969696969697, f1 = 0.9824561403508771\n",
      "Epoch 47: Train Loss = 0.004928268361001569, Recall = 1.0, Aging Rate = 0.09138697937727457, Precision = 0.995575221238938, f1 = 0.9977827050997783\n",
      "Epoch 48: Train Loss = 0.001967587112693897, Recall = 1.0, Aging Rate = 0.0909826122118884, Precision = 0, f1 = 0.0\n",
      "Epoch 49: Train Loss = 0.0010271301945717383, Recall = 1.0, Aging Rate = 0.0909826122118884, Precision = 0, f1 = 0.0\n",
      "Epoch 50: Train Loss = 0.0008473933605760415, Recall = 1.0, Aging Rate = 0.0909826122118884, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.000762406757607562, Recall = 1.0, Aging Rate = 0.0909826122118884, precision = 1.0\n",
      "\n",
      "Epoch 51: Train Loss = 0.000784681128589169, Recall = 1.0, Aging Rate = 0.0909826122118884, Precision = 0, f1 = 0.0\n",
      "Epoch 52: Train Loss = 0.0007975797327175086, Recall = 1.0, Aging Rate = 0.0909826122118884, Precision = 0, f1 = 0.0\n",
      "Epoch 53: Train Loss = 0.000791498927302166, Recall = 1.0, Aging Rate = 0.0909826122118884, Precision = 0, f1 = 0.0\n",
      "Epoch 54: Train Loss = 0.0008259022124849781, Recall = 1.0, Aging Rate = 0.0909826122118884, Precision = 0, f1 = 0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 55: Train Loss = 0.0008366868542273801, Recall = 1.0, Aging Rate = 0.0909826122118884, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0008057634284472401, Recall = 1.0, Aging Rate = 0.0909826122118884, precision = 1.0\n",
      "\n",
      "Epoch 56: Train Loss = 0.0008447377207574879, Recall = 1.0, Aging Rate = 0.0909826122118884, Precision = 0, f1 = 0.0\n",
      "Epoch 57: Train Loss = 0.0008759006820306532, Recall = 1.0, Aging Rate = 0.0909826122118884, Precision = 0, f1 = 0.0\n",
      "Epoch 58: Train Loss = 0.0008956068950948888, Recall = 1.0, Aging Rate = 0.0909826122118884, Precision = 0, f1 = 0.0\n",
      "Epoch 59: Train Loss = 0.0009144489872587556, Recall = 1.0, Aging Rate = 0.0909826122118884, Precision = 0, f1 = 0.0\n",
      "Epoch 60: Train Loss = 0.0009679155509630456, Recall = 1.0, Aging Rate = 0.0909826122118884, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0009002134559935526, Recall = 1.0, Aging Rate = 0.0909826122118884, precision = 1.0\n",
      "\n",
      "Epoch 61: Train Loss = 0.001003087559962337, Recall = 1.0, Aging Rate = 0.0909826122118884, Precision = 0, f1 = 0.0\n",
      "Epoch 62: Train Loss = 0.0010206489016430348, Recall = 1.0, Aging Rate = 0.0909826122118884, Precision = 0, f1 = 0.0\n",
      "Epoch 63: Train Loss = 0.001094808742412269, Recall = 1.0, Aging Rate = 0.0909826122118884, Precision = 0, f1 = 0.0\n",
      "Epoch 64: Train Loss = 0.0011516976941040248, Recall = 1.0, Aging Rate = 0.0909826122118884, Precision = 0, f1 = 0.0\n",
      "Epoch 65: Train Loss = 0.0011951338393019427, Recall = 1.0, Aging Rate = 0.0909826122118884, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0010914010633806762, Recall = 1.0, Aging Rate = 0.0909826122118884, precision = 1.0\n",
      "\n",
      "Epoch 66: Train Loss = 0.0011689090179145755, Recall = 1.0, Aging Rate = 0.0909826122118884, Precision = 0, f1 = 0.0\n",
      "Epoch 67: Train Loss = 0.0011506046912660374, Recall = 1.0, Aging Rate = 0.0909826122118884, Precision = 0, f1 = 0.0\n",
      "Epoch 68: Train Loss = 0.0011438325755870563, Recall = 1.0, Aging Rate = 0.0909826122118884, Precision = 0, f1 = 0.0\n",
      "Epoch 69: Train Loss = 0.0012219754661355444, Recall = 1.0, Aging Rate = 0.0909826122118884, Precision = 0, f1 = 0.0\n",
      "Epoch 70: Train Loss = 0.0011766826892305531, Recall = 1.0, Aging Rate = 0.0909826122118884, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.001105573072905618, Recall = 1.0, Aging Rate = 0.0909826122118884, precision = 1.0\n",
      "\n",
      "Training Finished at epoch 70.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "774d0c27028844c08c620afda4867aef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss = 0.4445347801013558, Recall = 0.05333333333333334, Aging Rate = 0.026283865750101092, Precision = 0.18461538461538463, f1 = 0.08275862068965517\n",
      "Epoch 2: Train Loss = 0.31518835933209427, Recall = 0.39555555555555555, Aging Rate = 0.059037606146380914, Precision = 0.6095890410958904, f1 = 0.47978436657681933\n",
      "Epoch 3: Train Loss = 0.23828934290921983, Recall = 0.5466666666666666, Aging Rate = 0.06672058228871816, Precision = 0.7454545454545455, f1 = 0.6307692307692307\n",
      "Epoch 4: Train Loss = 0.1933489193318105, Recall = 0.7155555555555555, Aging Rate = 0.08046906591184796, Precision = 0.8090452261306532, f1 = 0.7594339622641509\n",
      "Epoch 5: Train Loss = 0.13749902523388227, Recall = 0.8044444444444444, Aging Rate = 0.08572583906186818, Precision = 0.8537735849056604, f1 = 0.8283752860411898\n",
      "Test Loss = 0.11925614322432129, Recall = 0.7644444444444445, Aging Rate = 0.06955115244642135, precision = 1.0\n",
      "Model in epoch 5 is saved.\n",
      "\n",
      "Epoch 6: Train Loss = 0.09916726891456035, Recall = 0.8888888888888888, Aging Rate = 0.08855640921957138, Precision = 0.91324200913242, f1 = 0.9009009009009009\n",
      "Epoch 7: Train Loss = 0.06918987133033691, Recall = 0.9511111111111111, Aging Rate = 0.08976951071572989, Precision = 0.963963963963964, f1 = 0.9574944071588367\n",
      "Epoch 8: Train Loss = 0.04756986179072342, Recall = 0.96, Aging Rate = 0.08976951071572989, Precision = 0.972972972972973, f1 = 0.9664429530201343\n",
      "Epoch 9: Train Loss = 0.03435925990825137, Recall = 0.9688888888888889, Aging Rate = 0.08976951071572989, Precision = 0.9819819819819819, f1 = 0.9753914988814317\n",
      "Epoch 10: Train Loss = 0.025301088215583644, Recall = 0.9911111111111112, Aging Rate = 0.09138697937727457, Precision = 0.9867256637168141, f1 = 0.9889135254988914\n",
      "Test Loss = 0.02895073035337992, Recall = 0.9555555555555556, Aging Rate = 0.08693894055802669, precision = 1.0\n",
      "Model in epoch 10 is saved.\n",
      "\n",
      "Epoch 11: Train Loss = 0.02152863282821786, Recall = 0.9866666666666667, Aging Rate = 0.0909826122118884, Precision = 0.9866666666666667, f1 = 0.9866666666666668\n",
      "Epoch 12: Train Loss = 0.014724029825372924, Recall = 0.9866666666666667, Aging Rate = 0.09017387788111605, Precision = 0.9955156950672646, f1 = 0.9910714285714286\n",
      "Epoch 13: Train Loss = 0.008969740403211291, Recall = 1.0, Aging Rate = 0.0909826122118884, Precision = 0, f1 = 0.0\n",
      "Epoch 14: Train Loss = 0.006989620284776527, Recall = 1.0, Aging Rate = 0.0909826122118884, Precision = 0, f1 = 0.0\n",
      "Epoch 15: Train Loss = 0.005577040162860889, Recall = 1.0, Aging Rate = 0.0909826122118884, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.004614662138004801, Recall = 1.0, Aging Rate = 0.0909826122118884, precision = 1.0\n",
      "Model in epoch 15 is saved.\n",
      "\n",
      "Epoch 16: Train Loss = 0.004872200534567147, Recall = 1.0, Aging Rate = 0.0909826122118884, Precision = 0, f1 = 0.0\n",
      "Epoch 17: Train Loss = 0.0046807962209528585, Recall = 1.0, Aging Rate = 0.0909826122118884, Precision = 0, f1 = 0.0\n",
      "Epoch 18: Train Loss = 0.0041034246903715755, Recall = 1.0, Aging Rate = 0.0909826122118884, Precision = 0, f1 = 0.0\n",
      "Epoch 19: Train Loss = 0.0036322748985403628, Recall = 1.0, Aging Rate = 0.0909826122118884, Precision = 0, f1 = 0.0\n",
      "Epoch 20: Train Loss = 0.0033044899494477217, Recall = 1.0, Aging Rate = 0.0909826122118884, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0030474934230411326, Recall = 1.0, Aging Rate = 0.0909826122118884, precision = 1.0\n",
      "\n",
      "Epoch 21: Train Loss = 0.003045347082555547, Recall = 1.0, Aging Rate = 0.0909826122118884, Precision = 0, f1 = 0.0\n",
      "Epoch 22: Train Loss = 0.002891544483487562, Recall = 1.0, Aging Rate = 0.0909826122118884, Precision = 0, f1 = 0.0\n",
      "Epoch 23: Train Loss = 0.0027571449359804334, Recall = 1.0, Aging Rate = 0.0909826122118884, Precision = 0, f1 = 0.0\n",
      "Epoch 24: Train Loss = 0.002764400955081721, Recall = 1.0, Aging Rate = 0.0909826122118884, Precision = 0, f1 = 0.0\n",
      "Epoch 25: Train Loss = 0.0024696911182036127, Recall = 1.0, Aging Rate = 0.0909826122118884, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0022258832996121386, Recall = 1.0, Aging Rate = 0.0909826122118884, precision = 1.0\n",
      "\n",
      "Epoch 26: Train Loss = 0.002434088930535084, Recall = 1.0, Aging Rate = 0.0909826122118884, Precision = 0, f1 = 0.0\n",
      "Epoch 27: Train Loss = 0.0022536608200517264, Recall = 1.0, Aging Rate = 0.0909826122118884, Precision = 0, f1 = 0.0\n",
      "Epoch 28: Train Loss = 0.0022575002052741, Recall = 1.0, Aging Rate = 0.0909826122118884, Precision = 0, f1 = 0.0\n",
      "Epoch 29: Train Loss = 0.0022434083633034443, Recall = 1.0, Aging Rate = 0.0909826122118884, Precision = 0, f1 = 0.0\n",
      "Epoch 30: Train Loss = 0.0022863798000496913, Recall = 1.0, Aging Rate = 0.0909826122118884, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0020063178286802217, Recall = 1.0, Aging Rate = 0.0909826122118884, precision = 1.0\n",
      "\n",
      "Epoch 31: Train Loss = 0.0023973400064725603, Recall = 1.0, Aging Rate = 0.0909826122118884, Precision = 0, f1 = 0.0\n",
      "Epoch 32: Train Loss = 0.0022536791250783025, Recall = 1.0, Aging Rate = 0.0909826122118884, Precision = 0, f1 = 0.0\n",
      "Epoch 33: Train Loss = 0.0020455889267962934, Recall = 1.0, Aging Rate = 0.0909826122118884, Precision = 0, f1 = 0.0\n",
      "Epoch 34: Train Loss = 0.0019536606485970856, Recall = 1.0, Aging Rate = 0.0909826122118884, Precision = 0, f1 = 0.0\n",
      "Epoch 35: Train Loss = 0.0017885341470194186, Recall = 1.0, Aging Rate = 0.0909826122118884, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0016061375241499174, Recall = 1.0, Aging Rate = 0.0909826122118884, precision = 1.0\n",
      "\n",
      "Epoch 36: Train Loss = 0.001779548387170091, Recall = 1.0, Aging Rate = 0.0909826122118884, Precision = 0, f1 = 0.0\n",
      "Epoch 37: Train Loss = 0.0017565099249533282, Recall = 1.0, Aging Rate = 0.0909826122118884, Precision = 0, f1 = 0.0\n",
      "Epoch 38: Train Loss = 0.001728061532859306, Recall = 1.0, Aging Rate = 0.0909826122118884, Precision = 0, f1 = 0.0\n",
      "Epoch 39: Train Loss = 0.0017911488034194159, Recall = 1.0, Aging Rate = 0.0909826122118884, Precision = 0, f1 = 0.0\n",
      "Epoch 40: Train Loss = 0.002112395011799563, Recall = 1.0, Aging Rate = 0.0909826122118884, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0016134590210089535, Recall = 1.0, Aging Rate = 0.0909826122118884, precision = 1.0\n",
      "\n",
      "Epoch 41: Train Loss = 0.002894631126674108, Recall = 1.0, Aging Rate = 0.0909826122118884, Precision = 0, f1 = 0.0\n",
      "Epoch 42: Train Loss = 0.004410320736454281, Recall = 1.0, Aging Rate = 0.0909826122118884, Precision = 0, f1 = 0.0\n",
      "Epoch 43: Train Loss = 0.0030191862764378527, Recall = 1.0, Aging Rate = 0.0909826122118884, Precision = 0, f1 = 0.0\n",
      "Epoch 44: Train Loss = 0.0019818378454793564, Recall = 1.0, Aging Rate = 0.0909826122118884, Precision = 0, f1 = 0.0\n",
      "Epoch 45: Train Loss = 0.0014782984532209491, Recall = 1.0, Aging Rate = 0.0909826122118884, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0011975057632125706, Recall = 1.0, Aging Rate = 0.0909826122118884, precision = 1.0\n",
      "\n",
      "Epoch 46: Train Loss = 0.0013653271515419489, Recall = 1.0, Aging Rate = 0.0909826122118884, Precision = 0, f1 = 0.0\n",
      "Epoch 47: Train Loss = 0.0013373758622399598, Recall = 1.0, Aging Rate = 0.0909826122118884, Precision = 0, f1 = 0.0\n",
      "Epoch 48: Train Loss = 0.0014465338541281413, Recall = 1.0, Aging Rate = 0.0909826122118884, Precision = 0, f1 = 0.0\n",
      "Epoch 49: Train Loss = 0.001358464473427838, Recall = 1.0, Aging Rate = 0.0909826122118884, Precision = 0, f1 = 0.0\n",
      "Epoch 50: Train Loss = 0.0012775835380303868, Recall = 1.0, Aging Rate = 0.0909826122118884, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.001156571602954025, Recall = 1.0, Aging Rate = 0.0909826122118884, precision = 1.0\n",
      "\n",
      "Epoch 51: Train Loss = 0.0013226404335324189, Recall = 1.0, Aging Rate = 0.0909826122118884, Precision = 0, f1 = 0.0\n",
      "Epoch 52: Train Loss = 0.0014769746637626356, Recall = 1.0, Aging Rate = 0.0909826122118884, Precision = 0, f1 = 0.0\n",
      "Epoch 53: Train Loss = 0.0015936435035607272, Recall = 1.0, Aging Rate = 0.0909826122118884, Precision = 0, f1 = 0.0\n",
      "Epoch 54: Train Loss = 0.0017060492732108327, Recall = 1.0, Aging Rate = 0.0909826122118884, Precision = 0, f1 = 0.0\n",
      "Epoch 55: Train Loss = 0.001802134078189586, Recall = 1.0, Aging Rate = 0.0909826122118884, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.002086845451319689, Recall = 1.0, Aging Rate = 0.0909826122118884, precision = 1.0\n",
      "\n",
      "Epoch 56: Train Loss = 0.002057743205721281, Recall = 1.0, Aging Rate = 0.0909826122118884, Precision = 0, f1 = 0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57: Train Loss = 0.0019988604102248314, Recall = 1.0, Aging Rate = 0.0909826122118884, Precision = 0, f1 = 0.0\n",
      "Epoch 58: Train Loss = 0.004269353246818693, Recall = 1.0, Aging Rate = 0.0909826122118884, Precision = 0, f1 = 0.0\n",
      "Epoch 59: Train Loss = 0.06587876042662195, Recall = 0.9288888888888889, Aging Rate = 0.09623938536190861, Precision = 0.8781512605042017, f1 = 0.9028077753779697\n",
      "Epoch 60: Train Loss = 0.07138497094080316, Recall = 0.9155555555555556, Aging Rate = 0.09543065103113627, Precision = 0.8728813559322034, f1 = 0.8937093275488069\n",
      "Test Loss = 0.03679486862890305, Recall = 0.9822222222222222, Aging Rate = 0.09987868985038414, precision = 0.8947368421052632\n",
      "\n",
      "Epoch 61: Train Loss = 0.04377376139344737, Recall = 0.9466666666666667, Aging Rate = 0.09260008087343308, Precision = 0.9301310043668122, f1 = 0.9383259911894273\n",
      "Epoch 62: Train Loss = 0.014563576920877643, Recall = 0.9866666666666667, Aging Rate = 0.09219571370804691, Precision = 0.9736842105263158, f1 = 0.9801324503311258\n",
      "Epoch 63: Train Loss = 0.0045873565060601355, Recall = 0.9955555555555555, Aging Rate = 0.09057824504650222, Precision = 0, f1 = 0.0\n",
      "Epoch 64: Train Loss = 0.0018708320560323181, Recall = 1.0, Aging Rate = 0.0909826122118884, Precision = 0, f1 = 0.0\n",
      "Epoch 65: Train Loss = 0.0011132531214239558, Recall = 1.0, Aging Rate = 0.0909826122118884, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0009667022442819873, Recall = 1.0, Aging Rate = 0.0909826122118884, precision = 1.0\n",
      "\n",
      "Training Finished at epoch 65.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "caacd22501574f53897e79aa8452ceed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss = 0.4474816558889373, Recall = 0.057777777777777775, Aging Rate = 0.014557217953902144, Precision = 0.3611111111111111, f1 = 0.0996168582375479\n",
      "Epoch 2: Train Loss = 0.31875376969732544, Recall = 0.41333333333333333, Aging Rate = 0.06752931661949049, Precision = 0.5568862275449101, f1 = 0.4744897959183673\n",
      "Epoch 3: Train Loss = 0.258639265049145, Recall = 0.5555555555555556, Aging Rate = 0.06631621512333198, Precision = 0.7621951219512195, f1 = 0.6426735218508998\n",
      "Epoch 4: Train Loss = 0.2055457849831317, Recall = 0.7155555555555555, Aging Rate = 0.08734330772341285, Precision = 0.7453703703703703, f1 = 0.7301587301587301\n",
      "Epoch 5: Train Loss = 0.15382796416892922, Recall = 0.7777777777777778, Aging Rate = 0.08249090173877881, Precision = 0.8578431372549019, f1 = 0.8158508158508159\n",
      "Test Loss = 0.11425423077422503, Recall = 0.8711111111111111, Aging Rate = 0.08855640921957138, precision = 0.8949771689497716\n",
      "Model in epoch 5 is saved.\n",
      "\n",
      "Epoch 6: Train Loss = 0.11403626588569013, Recall = 0.8622222222222222, Aging Rate = 0.0881520420541852, Precision = 0.8899082568807339, f1 = 0.8758465011286682\n",
      "Epoch 7: Train Loss = 0.09254794805229698, Recall = 0.9022222222222223, Aging Rate = 0.08734330772341285, Precision = 0.9398148148148148, f1 = 0.9206349206349207\n",
      "Epoch 8: Train Loss = 0.06468747890627051, Recall = 0.9155555555555556, Aging Rate = 0.08734330772341285, Precision = 0.9537037037037037, f1 = 0.9342403628117913\n",
      "Epoch 9: Train Loss = 0.041637884373853816, Recall = 0.96, Aging Rate = 0.0881520420541852, Precision = 0.9908256880733946, f1 = 0.9751693002257336\n",
      "Epoch 10: Train Loss = 0.032616734326193074, Recall = 0.9866666666666667, Aging Rate = 0.0909826122118884, Precision = 0.9866666666666667, f1 = 0.9866666666666668\n",
      "Test Loss = 0.025958781130235302, Recall = 0.9911111111111112, Aging Rate = 0.09179134654266073, precision = 0.9823788546255506\n",
      "Model in epoch 10 is saved.\n",
      "\n",
      "Epoch 11: Train Loss = 0.022865813216469424, Recall = 0.9866666666666667, Aging Rate = 0.0909826122118884, Precision = 0.9866666666666667, f1 = 0.9866666666666668\n",
      "Epoch 12: Train Loss = 0.01800449824490156, Recall = 0.9955555555555555, Aging Rate = 0.09057824504650222, Precision = 0, f1 = 0.0\n",
      "Epoch 13: Train Loss = 0.012045224182521626, Recall = 0.9955555555555555, Aging Rate = 0.0909826122118884, Precision = 0.9955555555555555, f1 = 0.9955555555555555\n",
      "Epoch 14: Train Loss = 0.010183505485722328, Recall = 0.9911111111111112, Aging Rate = 0.09057824504650222, Precision = 0.9955357142857143, f1 = 0.9933184855233853\n",
      "Epoch 15: Train Loss = 0.009365394095006353, Recall = 0.9955555555555555, Aging Rate = 0.0909826122118884, Precision = 0.9955555555555555, f1 = 0.9955555555555555\n",
      "Test Loss = 0.006315667507115539, Recall = 1.0, Aging Rate = 0.0909826122118884, precision = 1.0\n",
      "Model in epoch 15 is saved.\n",
      "\n",
      "Epoch 16: Train Loss = 0.006834346888789487, Recall = 0.9955555555555555, Aging Rate = 0.09057824504650222, Precision = 0, f1 = 0.0\n",
      "Epoch 17: Train Loss = 0.0068206102527027255, Recall = 1.0, Aging Rate = 0.09138697937727457, Precision = 0.995575221238938, f1 = 0.9977827050997783\n",
      "Epoch 18: Train Loss = 0.005580291468341294, Recall = 0.9955555555555555, Aging Rate = 0.09057824504650222, Precision = 0, f1 = 0.0\n",
      "Epoch 19: Train Loss = 0.0055271718026659675, Recall = 1.0, Aging Rate = 0.09138697937727457, Precision = 0.995575221238938, f1 = 0.9977827050997783\n",
      "Epoch 20: Train Loss = 0.0046171085704517206, Recall = 1.0, Aging Rate = 0.0909826122118884, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.004005699439574556, Recall = 1.0, Aging Rate = 0.0909826122118884, precision = 1.0\n",
      "\n",
      "Epoch 21: Train Loss = 0.003792655911937573, Recall = 1.0, Aging Rate = 0.09138697937727457, Precision = 0.995575221238938, f1 = 0.9977827050997783\n",
      "Epoch 22: Train Loss = 0.003632258324303167, Recall = 1.0, Aging Rate = 0.0909826122118884, Precision = 0, f1 = 0.0\n",
      "Epoch 23: Train Loss = 0.003241207749080824, Recall = 1.0, Aging Rate = 0.0909826122118884, Precision = 0, f1 = 0.0\n",
      "Epoch 24: Train Loss = 0.0031164747654274707, Recall = 1.0, Aging Rate = 0.0909826122118884, Precision = 0, f1 = 0.0\n",
      "Epoch 25: Train Loss = 0.002684075566098317, Recall = 1.0, Aging Rate = 0.0909826122118884, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0023180546478721964, Recall = 1.0, Aging Rate = 0.0909826122118884, precision = 1.0\n",
      "\n",
      "Epoch 26: Train Loss = 0.0026579332212005014, Recall = 1.0, Aging Rate = 0.0909826122118884, Precision = 0, f1 = 0.0\n",
      "Epoch 27: Train Loss = 0.0024919275822757386, Recall = 1.0, Aging Rate = 0.0909826122118884, Precision = 0, f1 = 0.0\n",
      "Epoch 28: Train Loss = 0.0022934715015368572, Recall = 1.0, Aging Rate = 0.0909826122118884, Precision = 0, f1 = 0.0\n",
      "Epoch 29: Train Loss = 0.0021801529636925176, Recall = 1.0, Aging Rate = 0.0909826122118884, Precision = 0, f1 = 0.0\n",
      "Epoch 30: Train Loss = 0.0021676165989483, Recall = 1.0, Aging Rate = 0.0909826122118884, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.002036018759865966, Recall = 1.0, Aging Rate = 0.0909826122118884, precision = 1.0\n",
      "\n",
      "Epoch 31: Train Loss = 0.0021765622257805227, Recall = 1.0, Aging Rate = 0.0909826122118884, Precision = 0, f1 = 0.0\n",
      "Epoch 32: Train Loss = 0.0021592469632119434, Recall = 1.0, Aging Rate = 0.0909826122118884, Precision = 0, f1 = 0.0\n",
      "Epoch 33: Train Loss = 0.0021701921125910828, Recall = 1.0, Aging Rate = 0.0909826122118884, Precision = 0, f1 = 0.0\n",
      "Epoch 34: Train Loss = 0.002120063658630467, Recall = 1.0, Aging Rate = 0.0909826122118884, Precision = 0, f1 = 0.0\n",
      "Epoch 35: Train Loss = 0.0021252435590812745, Recall = 1.0, Aging Rate = 0.0909826122118884, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0018134425652958678, Recall = 1.0, Aging Rate = 0.0909826122118884, precision = 1.0\n",
      "\n",
      "Epoch 36: Train Loss = 0.0021194001958015182, Recall = 1.0, Aging Rate = 0.0909826122118884, Precision = 0, f1 = 0.0\n",
      "Epoch 37: Train Loss = 0.00197951925946328, Recall = 1.0, Aging Rate = 0.0909826122118884, Precision = 0, f1 = 0.0\n",
      "Epoch 38: Train Loss = 0.0018995218520782198, Recall = 1.0, Aging Rate = 0.0909826122118884, Precision = 0, f1 = 0.0\n",
      "Epoch 39: Train Loss = 0.0019168074771323536, Recall = 1.0, Aging Rate = 0.0909826122118884, Precision = 0, f1 = 0.0\n",
      "Epoch 40: Train Loss = 0.001882916605474749, Recall = 1.0, Aging Rate = 0.0909826122118884, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0016781469546753673, Recall = 1.0, Aging Rate = 0.0909826122118884, precision = 1.0\n",
      "\n",
      "Epoch 41: Train Loss = 0.0018442432363914893, Recall = 1.0, Aging Rate = 0.0909826122118884, Precision = 0, f1 = 0.0\n",
      "Epoch 42: Train Loss = 0.0019379205778342838, Recall = 1.0, Aging Rate = 0.0909826122118884, Precision = 0, f1 = 0.0\n",
      "Epoch 43: Train Loss = 0.0019123775653278976, Recall = 1.0, Aging Rate = 0.0909826122118884, Precision = 0, f1 = 0.0\n",
      "Epoch 44: Train Loss = 0.0018929610665028203, Recall = 1.0, Aging Rate = 0.0909826122118884, Precision = 0, f1 = 0.0\n",
      "Epoch 45: Train Loss = 0.0019501373316325153, Recall = 1.0, Aging Rate = 0.0909826122118884, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0017526060771825996, Recall = 1.0, Aging Rate = 0.0909826122118884, precision = 1.0\n",
      "\n",
      "Epoch 46: Train Loss = 0.001888746163253083, Recall = 1.0, Aging Rate = 0.0909826122118884, Precision = 0, f1 = 0.0\n",
      "Epoch 47: Train Loss = 0.0018155939368722418, Recall = 1.0, Aging Rate = 0.0909826122118884, Precision = 0, f1 = 0.0\n",
      "Epoch 48: Train Loss = 0.0017326430952269848, Recall = 1.0, Aging Rate = 0.0909826122118884, Precision = 0, f1 = 0.0\n",
      "Epoch 49: Train Loss = 0.001760776211280531, Recall = 1.0, Aging Rate = 0.0909826122118884, Precision = 0, f1 = 0.0\n",
      "Epoch 50: Train Loss = 0.0017492040411165844, Recall = 1.0, Aging Rate = 0.0909826122118884, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0016021945922768434, Recall = 1.0, Aging Rate = 0.0909826122118884, precision = 1.0\n",
      "\n",
      "Epoch 51: Train Loss = 0.001751492339707203, Recall = 1.0, Aging Rate = 0.0909826122118884, Precision = 0, f1 = 0.0\n",
      "Epoch 52: Train Loss = 0.0017460197142242114, Recall = 1.0, Aging Rate = 0.0909826122118884, Precision = 0, f1 = 0.0\n",
      "Epoch 53: Train Loss = 0.001702787172033467, Recall = 1.0, Aging Rate = 0.0909826122118884, Precision = 0, f1 = 0.0\n",
      "Epoch 54: Train Loss = 0.001715831225361333, Recall = 1.0, Aging Rate = 0.0909826122118884, Precision = 0, f1 = 0.0\n",
      "Epoch 55: Train Loss = 0.0017548010966432117, Recall = 1.0, Aging Rate = 0.0909826122118884, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0014464601067635217, Recall = 1.0, Aging Rate = 0.0909826122118884, precision = 1.0\n",
      "\n",
      "Epoch 56: Train Loss = 0.001773427223697835, Recall = 1.0, Aging Rate = 0.0909826122118884, Precision = 0, f1 = 0.0\n",
      "Epoch 57: Train Loss = 0.0023184749196587433, Recall = 1.0, Aging Rate = 0.0909826122118884, Precision = 0, f1 = 0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58: Train Loss = 0.0017523818062426312, Recall = 1.0, Aging Rate = 0.0909826122118884, Precision = 0, f1 = 0.0\n",
      "Epoch 59: Train Loss = 0.0018918624832613105, Recall = 1.0, Aging Rate = 0.0909826122118884, Precision = 0, f1 = 0.0\n",
      "Epoch 60: Train Loss = 0.0021916655684247753, Recall = 1.0, Aging Rate = 0.0909826122118884, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.002313731355461553, Recall = 1.0, Aging Rate = 0.09138697937727457, precision = 0.995575221238938\n",
      "\n",
      "Epoch 61: Train Loss = 0.008467689029619344, Recall = 0.9911111111111112, Aging Rate = 0.0909826122118884, Precision = 0.9911111111111112, f1 = 0.9911111111111112\n",
      "Epoch 62: Train Loss = 0.10478570843111683, Recall = 0.8977777777777778, Aging Rate = 0.10109179134654266, Precision = 0.808, f1 = 0.8505263157894737\n",
      "Epoch 63: Train Loss = 0.07307469095542177, Recall = 0.9155555555555556, Aging Rate = 0.09462191670036393, Precision = 0.8803418803418803, f1 = 0.8976034858387799\n",
      "Epoch 64: Train Loss = 0.02596146312675575, Recall = 0.9777777777777777, Aging Rate = 0.09543065103113627, Precision = 0.9322033898305084, f1 = 0.9544468546637744\n",
      "Epoch 65: Train Loss = 0.007084038574530999, Recall = 0.9955555555555555, Aging Rate = 0.0909826122118884, Precision = 0.9955555555555555, f1 = 0.9955555555555555\n",
      "Test Loss = 0.004357721403488205, Recall = 0.9955555555555555, Aging Rate = 0.09057824504650222, precision = 1.0\n",
      "\n",
      "Training Finished at epoch 65.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "87ca557a1f2a41d0b21da9575ac0287a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss = 0.4789950094071661, Recall = 0.057777777777777775, Aging Rate = 0.026283865750101092, Precision = 0.2, f1 = 0.0896551724137931\n",
      "Epoch 2: Train Loss = 0.33188750013690993, Recall = 0.37333333333333335, Aging Rate = 0.05175899716942984, Precision = 0.65625, f1 = 0.4759206798866856\n",
      "Epoch 3: Train Loss = 0.2727569589068231, Recall = 0.5333333333333333, Aging Rate = 0.07238172260412455, Precision = 0.6703910614525139, f1 = 0.5940594059405939\n",
      "Epoch 4: Train Loss = 0.24891156839109652, Recall = 0.6488888888888888, Aging Rate = 0.08896077638495754, Precision = 0.6636363636363637, f1 = 0.6561797752808989\n",
      "Epoch 5: Train Loss = 0.18873769341332683, Recall = 0.7111111111111111, Aging Rate = 0.0772341285887586, Precision = 0.837696335078534, f1 = 0.7692307692307692\n",
      "Test Loss = 0.15195459134355518, Recall = 0.8888888888888888, Aging Rate = 0.10473109583501819, precision = 0.7722007722007722\n",
      "Model in epoch 5 is saved.\n",
      "\n",
      "Epoch 6: Train Loss = 0.13436570153501995, Recall = 0.8266666666666667, Aging Rate = 0.08653457339264052, Precision = 0.8691588785046729, f1 = 0.847380410022779\n",
      "Epoch 7: Train Loss = 0.10075449857377254, Recall = 0.8711111111111111, Aging Rate = 0.0881520420541852, Precision = 0.8990825688073395, f1 = 0.8848758465011286\n",
      "Epoch 8: Train Loss = 0.07239494656219783, Recall = 0.9288888888888889, Aging Rate = 0.09017387788111605, Precision = 0.9372197309417041, f1 = 0.9330357142857143\n",
      "Epoch 9: Train Loss = 0.05691255249152336, Recall = 0.9377777777777778, Aging Rate = 0.0881520420541852, Precision = 0.9678899082568807, f1 = 0.9525959367945823\n",
      "Epoch 10: Train Loss = 0.0406044684410746, Recall = 0.9733333333333334, Aging Rate = 0.09179134654266073, Precision = 0.9647577092511013, f1 = 0.9690265486725663\n",
      "Test Loss = 0.02939926680016267, Recall = 0.9733333333333334, Aging Rate = 0.08976951071572989, precision = 0.9864864864864865\n",
      "Model in epoch 10 is saved.\n",
      "\n",
      "Epoch 11: Train Loss = 0.03142861908266311, Recall = 0.9688888888888889, Aging Rate = 0.09017387788111605, Precision = 0.9775784753363229, f1 = 0.9732142857142856\n",
      "Epoch 12: Train Loss = 0.025468100740559614, Recall = 0.9822222222222222, Aging Rate = 0.0909826122118884, Precision = 0.9822222222222222, f1 = 0.9822222222222222\n",
      "Epoch 13: Train Loss = 0.01995358063571616, Recall = 0.9866666666666667, Aging Rate = 0.0909826122118884, Precision = 0.9866666666666667, f1 = 0.9866666666666668\n",
      "Epoch 14: Train Loss = 0.015262387496345061, Recall = 0.9911111111111112, Aging Rate = 0.0909826122118884, Precision = 0.9911111111111112, f1 = 0.9911111111111112\n",
      "Epoch 15: Train Loss = 0.012737040429045037, Recall = 0.9911111111111112, Aging Rate = 0.09057824504650222, Precision = 0.9955357142857143, f1 = 0.9933184855233853\n",
      "Test Loss = 0.010409135471809515, Recall = 0.9911111111111112, Aging Rate = 0.09057824504650222, precision = 0.9955357142857143\n",
      "Model in epoch 15 is saved.\n",
      "\n",
      "Epoch 16: Train Loss = 0.01055794225303698, Recall = 0.9955555555555555, Aging Rate = 0.0909826122118884, Precision = 0.9955555555555555, f1 = 0.9955555555555555\n",
      "Epoch 17: Train Loss = 0.009731607956211492, Recall = 0.9955555555555555, Aging Rate = 0.0909826122118884, Precision = 0.9955555555555555, f1 = 0.9955555555555555\n",
      "Epoch 18: Train Loss = 0.008313433494640298, Recall = 0.9955555555555555, Aging Rate = 0.0909826122118884, Precision = 0.9955555555555555, f1 = 0.9955555555555555\n",
      "Epoch 19: Train Loss = 0.00716465543603447, Recall = 0.9911111111111112, Aging Rate = 0.09017387788111605, Precision = 0, f1 = 0.0\n",
      "Epoch 20: Train Loss = 0.006528791973246446, Recall = 1.0, Aging Rate = 0.0909826122118884, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.005840128315729418, Recall = 1.0, Aging Rate = 0.0909826122118884, precision = 1.0\n",
      "Model in epoch 20 is saved.\n",
      "\n",
      "Epoch 21: Train Loss = 0.006262996412223914, Recall = 1.0, Aging Rate = 0.09138697937727457, Precision = 0.995575221238938, f1 = 0.9977827050997783\n",
      "Epoch 22: Train Loss = 0.005785111687099053, Recall = 1.0, Aging Rate = 0.0909826122118884, Precision = 0, f1 = 0.0\n",
      "Epoch 23: Train Loss = 0.00576416860167743, Recall = 0.9955555555555555, Aging Rate = 0.09057824504650222, Precision = 0, f1 = 0.0\n",
      "Epoch 24: Train Loss = 0.005608862651767359, Recall = 1.0, Aging Rate = 0.0909826122118884, Precision = 0, f1 = 0.0\n",
      "Epoch 25: Train Loss = 0.004692094325959031, Recall = 1.0, Aging Rate = 0.0909826122118884, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.004322486577195511, Recall = 1.0, Aging Rate = 0.0909826122118884, precision = 1.0\n",
      "\n",
      "Epoch 26: Train Loss = 0.004648729344228116, Recall = 1.0, Aging Rate = 0.0909826122118884, Precision = 0, f1 = 0.0\n",
      "Epoch 27: Train Loss = 0.004404862451992606, Recall = 1.0, Aging Rate = 0.0909826122118884, Precision = 0, f1 = 0.0\n",
      "Epoch 28: Train Loss = 0.003948180728301623, Recall = 1.0, Aging Rate = 0.0909826122118884, Precision = 0, f1 = 0.0\n",
      "Epoch 29: Train Loss = 0.003836676587222247, Recall = 1.0, Aging Rate = 0.0909826122118884, Precision = 0, f1 = 0.0\n",
      "Epoch 30: Train Loss = 0.0036590245928580685, Recall = 1.0, Aging Rate = 0.0909826122118884, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.003624112498741243, Recall = 1.0, Aging Rate = 0.0909826122118884, precision = 1.0\n",
      "\n",
      "Epoch 31: Train Loss = 0.003751406959776593, Recall = 1.0, Aging Rate = 0.0909826122118884, Precision = 0, f1 = 0.0\n",
      "Epoch 32: Train Loss = 0.003644509097878334, Recall = 1.0, Aging Rate = 0.0909826122118884, Precision = 0, f1 = 0.0\n",
      "Epoch 33: Train Loss = 0.0035345146611496336, Recall = 1.0, Aging Rate = 0.0909826122118884, Precision = 0, f1 = 0.0\n",
      "Epoch 34: Train Loss = 0.0035241543380502166, Recall = 1.0, Aging Rate = 0.0909826122118884, Precision = 0, f1 = 0.0\n",
      "Epoch 35: Train Loss = 0.003564745617455743, Recall = 1.0, Aging Rate = 0.0909826122118884, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.003365133440587481, Recall = 1.0, Aging Rate = 0.0909826122118884, precision = 1.0\n",
      "\n",
      "Epoch 36: Train Loss = 0.0035206697077377032, Recall = 1.0, Aging Rate = 0.0909826122118884, Precision = 0, f1 = 0.0\n",
      "Epoch 37: Train Loss = 0.0032641296912349228, Recall = 1.0, Aging Rate = 0.0909826122118884, Precision = 0, f1 = 0.0\n",
      "Epoch 38: Train Loss = 0.003287595605799304, Recall = 1.0, Aging Rate = 0.0909826122118884, Precision = 0, f1 = 0.0\n",
      "Epoch 39: Train Loss = 0.0032346443175400347, Recall = 1.0, Aging Rate = 0.0909826122118884, Precision = 0, f1 = 0.0\n",
      "Epoch 40: Train Loss = 0.0032485844254843193, Recall = 1.0, Aging Rate = 0.0909826122118884, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0031019461479036494, Recall = 1.0, Aging Rate = 0.0909826122118884, precision = 1.0\n",
      "\n",
      "Epoch 41: Train Loss = 0.003383228264495224, Recall = 1.0, Aging Rate = 0.0909826122118884, Precision = 0, f1 = 0.0\n",
      "Epoch 42: Train Loss = 0.0031789948930681425, Recall = 1.0, Aging Rate = 0.0909826122118884, Precision = 0, f1 = 0.0\n",
      "Epoch 43: Train Loss = 0.003149082530945166, Recall = 1.0, Aging Rate = 0.0909826122118884, Precision = 0, f1 = 0.0\n",
      "Epoch 44: Train Loss = 0.0033746589091182768, Recall = 1.0, Aging Rate = 0.0909826122118884, Precision = 0, f1 = 0.0\n",
      "Epoch 45: Train Loss = 0.0030171121928194637, Recall = 1.0, Aging Rate = 0.0909826122118884, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0030220028779740955, Recall = 1.0, Aging Rate = 0.0909826122118884, precision = 1.0\n",
      "\n",
      "Epoch 46: Train Loss = 0.0030339988065470015, Recall = 1.0, Aging Rate = 0.0909826122118884, Precision = 0, f1 = 0.0\n",
      "Epoch 47: Train Loss = 0.002721159642105082, Recall = 1.0, Aging Rate = 0.0909826122118884, Precision = 0, f1 = 0.0\n",
      "Epoch 48: Train Loss = 0.002851831128694994, Recall = 1.0, Aging Rate = 0.0909826122118884, Precision = 0, f1 = 0.0\n",
      "Epoch 49: Train Loss = 0.0031002932889074436, Recall = 1.0, Aging Rate = 0.0909826122118884, Precision = 0, f1 = 0.0\n",
      "Epoch 50: Train Loss = 0.0027185710989845653, Recall = 1.0, Aging Rate = 0.0909826122118884, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.002393909315902512, Recall = 1.0, Aging Rate = 0.0909826122118884, precision = 1.0\n",
      "\n",
      "Epoch 51: Train Loss = 0.002751816989322224, Recall = 1.0, Aging Rate = 0.0909826122118884, Precision = 0, f1 = 0.0\n",
      "Epoch 52: Train Loss = 0.0026613230170404144, Recall = 1.0, Aging Rate = 0.0909826122118884, Precision = 0, f1 = 0.0\n",
      "Epoch 53: Train Loss = 0.0027897395098486254, Recall = 1.0, Aging Rate = 0.0909826122118884, Precision = 0, f1 = 0.0\n",
      "Epoch 54: Train Loss = 0.0027916185971909855, Recall = 1.0, Aging Rate = 0.0909826122118884, Precision = 0, f1 = 0.0\n",
      "Epoch 55: Train Loss = 0.002827897574865548, Recall = 1.0, Aging Rate = 0.0909826122118884, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0018466431198448088, Recall = 1.0, Aging Rate = 0.0909826122118884, precision = 1.0\n",
      "\n",
      "Epoch 56: Train Loss = 0.001998126572709767, Recall = 1.0, Aging Rate = 0.0909826122118884, Precision = 0, f1 = 0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57: Train Loss = 0.002024842325064741, Recall = 1.0, Aging Rate = 0.0909826122118884, Precision = 0, f1 = 0.0\n",
      "Epoch 58: Train Loss = 0.002167956663025984, Recall = 1.0, Aging Rate = 0.0909826122118884, Precision = 0, f1 = 0.0\n",
      "Epoch 59: Train Loss = 0.008218090822227266, Recall = 0.9955555555555555, Aging Rate = 0.09179134654266073, Precision = 0.986784140969163, f1 = 0.9911504424778761\n",
      "Epoch 60: Train Loss = 0.03516778939927439, Recall = 0.9555555555555556, Aging Rate = 0.09260008087343308, Precision = 0.9388646288209607, f1 = 0.947136563876652\n",
      "Test Loss = 0.038156288516098764, Recall = 0.9333333333333333, Aging Rate = 0.08572583906186818, precision = 0.9905660377358491\n",
      "\n",
      "Epoch 61: Train Loss = 0.05007640445311928, Recall = 0.9288888888888889, Aging Rate = 0.09623938536190861, Precision = 0.8781512605042017, f1 = 0.9028077753779697\n",
      "Epoch 62: Train Loss = 0.06974243083904737, Recall = 0.9111111111111111, Aging Rate = 0.09583501819652245, Precision = 0.8649789029535865, f1 = 0.8874458874458875\n",
      "Epoch 63: Train Loss = 0.01754541977715791, Recall = 0.9777777777777777, Aging Rate = 0.09057824504650222, Precision = 0.9821428571428571, f1 = 0.9799554565701558\n",
      "Epoch 64: Train Loss = 0.008120106186607029, Recall = 0.9955555555555555, Aging Rate = 0.09300444803881924, Precision = 0.9739130434782609, f1 = 0.9846153846153847\n",
      "Epoch 65: Train Loss = 0.003828484679128277, Recall = 1.0, Aging Rate = 0.09179134654266073, Precision = 0.9911894273127754, f1 = 0.9955752212389382\n",
      "Test Loss = 0.001549646256047535, Recall = 1.0, Aging Rate = 0.0909826122118884, precision = 1.0\n",
      "\n",
      "Epoch 66: Train Loss = 0.0011990709357687453, Recall = 1.0, Aging Rate = 0.0909826122118884, Precision = 0, f1 = 0.0\n",
      "Epoch 67: Train Loss = 0.001024022679807964, Recall = 1.0, Aging Rate = 0.0909826122118884, Precision = 0, f1 = 0.0\n",
      "Epoch 68: Train Loss = 0.0009419845165387308, Recall = 1.0, Aging Rate = 0.0909826122118884, Precision = 0, f1 = 0.0\n",
      "Epoch 69: Train Loss = 0.000895385633064965, Recall = 1.0, Aging Rate = 0.0909826122118884, Precision = 0, f1 = 0.0\n",
      "Epoch 70: Train Loss = 0.0009065178910524913, Recall = 1.0, Aging Rate = 0.0909826122118884, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0008115894328279355, Recall = 1.0, Aging Rate = 0.0909826122118884, precision = 1.0\n",
      "\n",
      "Training Finished at epoch 70.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a5ddb328e8a247729c10f80d93504270",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss = 0.47500105679613874, Recall = 0.07142857142857142, Aging Rate = 0.0412621359223301, Precision = 0.1568627450980392, f1 = 0.09815950920245398\n",
      "Epoch 2: Train Loss = 0.32212878112654086, Recall = 0.3794642857142857, Aging Rate = 0.05542071197411003, Precision = 0.6204379562043796, f1 = 0.4709141274238227\n",
      "Epoch 3: Train Loss = 0.25752578516608304, Recall = 0.5580357142857143, Aging Rate = 0.07483818770226537, Precision = 0.6756756756756757, f1 = 0.6112469437652812\n",
      "Epoch 4: Train Loss = 0.20573211265999136, Recall = 0.6830357142857143, Aging Rate = 0.08050161812297735, Precision = 0.7688442211055276, f1 = 0.7234042553191489\n",
      "Epoch 5: Train Loss = 0.1829394275702319, Recall = 0.7053571428571429, Aging Rate = 0.07766990291262135, Precision = 0.8229166666666666, f1 = 0.7596153846153847\n",
      "Test Loss = 0.14531802827293433, Recall = 0.7410714285714286, Aging Rate = 0.07200647249190939, precision = 0.9325842696629213\n",
      "Model in epoch 5 is saved.\n",
      "\n",
      "Epoch 6: Train Loss = 0.142296413194786, Recall = 0.7991071428571429, Aging Rate = 0.08454692556634304, Precision = 0.8564593301435407, f1 = 0.8267898383371826\n",
      "Epoch 7: Train Loss = 0.10792373265456227, Recall = 0.8794642857142857, Aging Rate = 0.08616504854368932, Precision = 0.9248826291079812, f1 = 0.9016018306636155\n",
      "Epoch 8: Train Loss = 0.08117110506423468, Recall = 0.9241071428571429, Aging Rate = 0.08737864077669903, Precision = 0.9583333333333334, f1 = 0.9409090909090909\n",
      "Epoch 9: Train Loss = 0.06207765382036422, Recall = 0.9285714285714286, Aging Rate = 0.08737864077669903, Precision = 0.9629629629629629, f1 = 0.9454545454545454\n",
      "Epoch 10: Train Loss = 0.04861766716591941, Recall = 0.9553571428571429, Aging Rate = 0.08818770226537216, Precision = 0.981651376146789, f1 = 0.9683257918552036\n",
      "Test Loss = 0.03784187698682535, Recall = 0.9866071428571429, Aging Rate = 0.0918284789644013, precision = 0.973568281938326\n",
      "Model in epoch 10 is saved.\n",
      "\n",
      "Epoch 11: Train Loss = 0.03830662785658558, Recall = 0.9508928571428571, Aging Rate = 0.08737864077669903, Precision = 0.9861111111111112, f1 = 0.968181818181818\n",
      "Epoch 12: Train Loss = 0.029100715209847514, Recall = 0.9821428571428571, Aging Rate = 0.09021035598705501, Precision = 0.9865470852017937, f1 = 0.9843400447427293\n",
      "Epoch 13: Train Loss = 0.020951611559512546, Recall = 0.9866071428571429, Aging Rate = 0.09021035598705501, Precision = 0.9910313901345291, f1 = 0.9888143176733781\n",
      "Epoch 14: Train Loss = 0.01777257371549178, Recall = 0.9821428571428571, Aging Rate = 0.08980582524271845, Precision = 0.990990990990991, f1 = 0.9865470852017937\n",
      "Epoch 15: Train Loss = 0.014990595142239506, Recall = 0.9910714285714286, Aging Rate = 0.09061488673139159, Precision = 0.9910714285714286, f1 = 0.9910714285714286\n",
      "Test Loss = 0.012204558416767028, Recall = 0.9955357142857143, Aging Rate = 0.09061488673139159, precision = 0.9955357142857143\n",
      "Model in epoch 15 is saved.\n",
      "\n",
      "Epoch 16: Train Loss = 0.011743087556610987, Recall = 1.0, Aging Rate = 0.09142394822006472, Precision = 0.9911504424778761, f1 = 0.9955555555555555\n",
      "Epoch 17: Train Loss = 0.009809435883229509, Recall = 0.9955357142857143, Aging Rate = 0.09101941747572816, Precision = 0.9911111111111112, f1 = 0.9933184855233853\n",
      "Epoch 18: Train Loss = 0.00876553457917519, Recall = 1.0, Aging Rate = 0.09061488673139159, Precision = 0, f1 = 0.0\n",
      "Epoch 19: Train Loss = 0.007267619641407311, Recall = 0.9955357142857143, Aging Rate = 0.09061488673139159, Precision = 0.9955357142857143, f1 = 0.9955357142857143\n",
      "Epoch 20: Train Loss = 0.00667929605951587, Recall = 0.9955357142857143, Aging Rate = 0.09101941747572816, Precision = 0.9911111111111112, f1 = 0.9933184855233853\n",
      "Test Loss = 0.0056264012875668346, Recall = 1.0, Aging Rate = 0.09061488673139159, precision = 1.0\n",
      "Model in epoch 20 is saved.\n",
      "\n",
      "Epoch 21: Train Loss = 0.005993726437242285, Recall = 1.0, Aging Rate = 0.09061488673139159, Precision = 0, f1 = 0.0\n",
      "Epoch 22: Train Loss = 0.005347556355454534, Recall = 1.0, Aging Rate = 0.09061488673139159, Precision = 0, f1 = 0.0\n",
      "Epoch 23: Train Loss = 0.004947856110995364, Recall = 1.0, Aging Rate = 0.09061488673139159, Precision = 0, f1 = 0.0\n",
      "Epoch 24: Train Loss = 0.0047680696391147895, Recall = 1.0, Aging Rate = 0.09061488673139159, Precision = 0, f1 = 0.0\n",
      "Epoch 25: Train Loss = 0.00448080023425152, Recall = 1.0, Aging Rate = 0.09061488673139159, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.004279386396836308, Recall = 1.0, Aging Rate = 0.09061488673139159, precision = 1.0\n",
      "\n",
      "Epoch 26: Train Loss = 0.004252077812708697, Recall = 1.0, Aging Rate = 0.09061488673139159, Precision = 0, f1 = 0.0\n",
      "Epoch 27: Train Loss = 0.003969568863185575, Recall = 1.0, Aging Rate = 0.09061488673139159, Precision = 0, f1 = 0.0\n",
      "Epoch 28: Train Loss = 0.0038163035845799934, Recall = 1.0, Aging Rate = 0.09061488673139159, Precision = 0, f1 = 0.0\n",
      "Epoch 29: Train Loss = 0.003763978749296619, Recall = 1.0, Aging Rate = 0.09061488673139159, Precision = 0, f1 = 0.0\n",
      "Epoch 30: Train Loss = 0.00349860238612096, Recall = 1.0, Aging Rate = 0.09061488673139159, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.003192556248887361, Recall = 1.0, Aging Rate = 0.09061488673139159, precision = 1.0\n",
      "\n",
      "Epoch 31: Train Loss = 0.0034523791389413252, Recall = 1.0, Aging Rate = 0.09061488673139159, Precision = 0, f1 = 0.0\n",
      "Epoch 32: Train Loss = 0.0034449935904297146, Recall = 1.0, Aging Rate = 0.09061488673139159, Precision = 0, f1 = 0.0\n",
      "Epoch 33: Train Loss = 0.0034348022699066737, Recall = 1.0, Aging Rate = 0.09061488673139159, Precision = 0, f1 = 0.0\n",
      "Epoch 34: Train Loss = 0.0036226240239892768, Recall = 1.0, Aging Rate = 0.09061488673139159, Precision = 0, f1 = 0.0\n",
      "Epoch 35: Train Loss = 0.0034779992928836963, Recall = 1.0, Aging Rate = 0.09061488673139159, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0029546300602570465, Recall = 1.0, Aging Rate = 0.09061488673139159, precision = 1.0\n",
      "\n",
      "Epoch 36: Train Loss = 0.003015991560301011, Recall = 1.0, Aging Rate = 0.09061488673139159, Precision = 0, f1 = 0.0\n",
      "Epoch 37: Train Loss = 0.002939399549945538, Recall = 1.0, Aging Rate = 0.09061488673139159, Precision = 0, f1 = 0.0\n",
      "Epoch 38: Train Loss = 0.002896073285616862, Recall = 1.0, Aging Rate = 0.09061488673139159, Precision = 0, f1 = 0.0\n",
      "Epoch 39: Train Loss = 0.002952490354553588, Recall = 1.0, Aging Rate = 0.09061488673139159, Precision = 0, f1 = 0.0\n",
      "Epoch 40: Train Loss = 0.003063166143318403, Recall = 1.0, Aging Rate = 0.09061488673139159, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0028596451411077987, Recall = 1.0, Aging Rate = 0.09061488673139159, precision = 1.0\n",
      "\n",
      "Epoch 41: Train Loss = 0.002896750144642389, Recall = 1.0, Aging Rate = 0.09061488673139159, Precision = 0, f1 = 0.0\n",
      "Epoch 42: Train Loss = 0.002739226000238825, Recall = 1.0, Aging Rate = 0.09061488673139159, Precision = 0, f1 = 0.0\n",
      "Epoch 43: Train Loss = 0.0028732074266390024, Recall = 1.0, Aging Rate = 0.09061488673139159, Precision = 0, f1 = 0.0\n",
      "Epoch 44: Train Loss = 0.0026223059060974316, Recall = 1.0, Aging Rate = 0.09061488673139159, Precision = 0, f1 = 0.0\n",
      "Epoch 45: Train Loss = 0.0027057246996758924, Recall = 1.0, Aging Rate = 0.09061488673139159, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.002385230559756238, Recall = 1.0, Aging Rate = 0.09061488673139159, precision = 1.0\n",
      "\n",
      "Epoch 46: Train Loss = 0.002545563350386411, Recall = 1.0, Aging Rate = 0.09061488673139159, Precision = 0, f1 = 0.0\n",
      "Epoch 47: Train Loss = 0.00269063030035027, Recall = 1.0, Aging Rate = 0.09061488673139159, Precision = 0, f1 = 0.0\n",
      "Epoch 48: Train Loss = 0.0024877474914549043, Recall = 1.0, Aging Rate = 0.09101941747572816, Precision = 0.9955555555555555, f1 = 0.9977728285077951\n",
      "Epoch 49: Train Loss = 0.0025111564086949074, Recall = 1.0, Aging Rate = 0.09061488673139159, Precision = 0, f1 = 0.0\n",
      "Epoch 50: Train Loss = 0.0022947502953172163, Recall = 1.0, Aging Rate = 0.09061488673139159, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.002097590830972762, Recall = 1.0, Aging Rate = 0.09061488673139159, precision = 1.0\n",
      "\n",
      "Epoch 51: Train Loss = 0.0025144469974001924, Recall = 1.0, Aging Rate = 0.09061488673139159, Precision = 0, f1 = 0.0\n",
      "Epoch 52: Train Loss = 0.0024470075483442946, Recall = 1.0, Aging Rate = 0.09061488673139159, Precision = 0, f1 = 0.0\n",
      "Epoch 53: Train Loss = 0.00196279852551598, Recall = 1.0, Aging Rate = 0.09061488673139159, Precision = 0, f1 = 0.0\n",
      "Epoch 54: Train Loss = 0.0020246804811657197, Recall = 1.0, Aging Rate = 0.09061488673139159, Precision = 0, f1 = 0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 55: Train Loss = 0.0018911375099051634, Recall = 1.0, Aging Rate = 0.09061488673139159, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0015591847426619707, Recall = 1.0, Aging Rate = 0.09061488673139159, precision = 1.0\n",
      "\n",
      "Epoch 56: Train Loss = 0.001979018495987775, Recall = 1.0, Aging Rate = 0.09061488673139159, Precision = 0, f1 = 0.0\n",
      "Epoch 57: Train Loss = 0.0038116487755792813, Recall = 1.0, Aging Rate = 0.09101941747572816, Precision = 0.9955555555555555, f1 = 0.9977728285077951\n",
      "Epoch 58: Train Loss = 0.009701152937938867, Recall = 0.9955357142857143, Aging Rate = 0.0918284789644013, Precision = 0.9823788546255506, f1 = 0.9889135254988914\n",
      "Epoch 59: Train Loss = 0.0634193007734794, Recall = 0.9285714285714286, Aging Rate = 0.09627831715210355, Precision = 0.8739495798319328, f1 = 0.9004329004329005\n",
      "Epoch 60: Train Loss = 0.05874697101817837, Recall = 0.9285714285714286, Aging Rate = 0.09466019417475728, Precision = 0.8888888888888888, f1 = 0.9082969432314411\n",
      "Test Loss = 0.026911132941836294, Recall = 0.9642857142857143, Aging Rate = 0.0918284789644013, precision = 0.9515418502202643\n",
      "\n",
      "Epoch 61: Train Loss = 0.02483580934191213, Recall = 0.9642857142857143, Aging Rate = 0.09263754045307443, Precision = 0.9432314410480349, f1 = 0.9536423841059601\n",
      "Epoch 62: Train Loss = 0.02097205140004025, Recall = 0.9821428571428571, Aging Rate = 0.09263754045307443, Precision = 0.9606986899563319, f1 = 0.9713024282560705\n",
      "Epoch 63: Train Loss = 0.006335671560486182, Recall = 0.9955357142857143, Aging Rate = 0.09021035598705501, Precision = 0, f1 = 0.0\n",
      "Epoch 64: Train Loss = 0.0029458024056438466, Recall = 1.0, Aging Rate = 0.09061488673139159, Precision = 0, f1 = 0.0\n",
      "Epoch 65: Train Loss = 0.001783303169361813, Recall = 1.0, Aging Rate = 0.09061488673139159, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0014505439168927305, Recall = 1.0, Aging Rate = 0.09061488673139159, precision = 1.0\n",
      "\n",
      "Epoch 66: Train Loss = 0.0014486464177873167, Recall = 1.0, Aging Rate = 0.09061488673139159, Precision = 0, f1 = 0.0\n",
      "Epoch 67: Train Loss = 0.0013841217744290756, Recall = 1.0, Aging Rate = 0.09061488673139159, Precision = 0, f1 = 0.0\n",
      "Epoch 68: Train Loss = 0.0012781561676693122, Recall = 1.0, Aging Rate = 0.09061488673139159, Precision = 0, f1 = 0.0\n",
      "Epoch 69: Train Loss = 0.0011749017324741676, Recall = 1.0, Aging Rate = 0.09061488673139159, Precision = 0, f1 = 0.0\n",
      "Epoch 70: Train Loss = 0.0011124965549419517, Recall = 1.0, Aging Rate = 0.09061488673139159, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0010168358171584754, Recall = 1.0, Aging Rate = 0.09061488673139159, precision = 1.0\n",
      "\n",
      "Training Finished at epoch 70.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a0a4bf5dfc5c40c49b750c956ef7a718",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss = 0.48484771455582754, Recall = 0.008888888888888889, Aging Rate = 0.004852405984634048, Precision = 0.16666666666666666, f1 = 0.016877637130801686\n",
      "Epoch 2: Train Loss = 0.40820019394822127, Recall = 0.022222222222222223, Aging Rate = 0.0020218358269308533, Precision = 0, f1 = 0.0\n",
      "Epoch 3: Train Loss = 0.34632233319087785, Recall = 0.2222222222222222, Aging Rate = 0.02426202992317024, Precision = 0.8333333333333334, f1 = 0.3508771929824561\n",
      "Epoch 4: Train Loss = 0.297030339622324, Recall = 0.4, Aging Rate = 0.05014152850788516, Precision = 0.7258064516129032, f1 = 0.5157593123209169\n",
      "Epoch 5: Train Loss = 0.256410794217385, Recall = 0.5511111111111111, Aging Rate = 0.06389001213101496, Precision = 0.7848101265822784, f1 = 0.6475195822454308\n",
      "Test Loss = 0.2325468518162275, Recall = 0.6977777777777778, Aging Rate = 0.08613020622725434, precision = 0.7370892018779343\n",
      "Model in epoch 5 is saved.\n",
      "\n",
      "Epoch 6: Train Loss = 0.22296120308933112, Recall = 0.6622222222222223, Aging Rate = 0.07399919126566923, Precision = 0.8142076502732241, f1 = 0.7303921568627451\n",
      "Epoch 7: Train Loss = 0.19802209848799399, Recall = 0.6755555555555556, Aging Rate = 0.07399919126566923, Precision = 0.8306010928961749, f1 = 0.7450980392156864\n",
      "Epoch 8: Train Loss = 0.1787585255543423, Recall = 0.7066666666666667, Aging Rate = 0.0772341285887586, Precision = 0.8324607329842932, f1 = 0.764423076923077\n",
      "Epoch 9: Train Loss = 0.15690770806737916, Recall = 0.7777777777777778, Aging Rate = 0.07844723008491711, Precision = 0.9020618556701031, f1 = 0.8353221957040573\n",
      "Epoch 10: Train Loss = 0.13854752520300384, Recall = 0.8088888888888889, Aging Rate = 0.0812778002426203, Precision = 0.9054726368159204, f1 = 0.8544600938967135\n",
      "Test Loss = 0.12014944445879605, Recall = 0.8222222222222222, Aging Rate = 0.07763849575414476, precision = 0.9635416666666666\n",
      "Model in epoch 10 is saved.\n",
      "\n",
      "Epoch 11: Train Loss = 0.1278552558503554, Recall = 0.8177777777777778, Aging Rate = 0.08006469874646178, Precision = 0.9292929292929293, f1 = 0.8699763593380615\n",
      "Epoch 12: Train Loss = 0.10898896273913963, Recall = 0.8711111111111111, Aging Rate = 0.08451273756570966, Precision = 0.937799043062201, f1 = 0.903225806451613\n",
      "Epoch 13: Train Loss = 0.09433008014276063, Recall = 0.88, Aging Rate = 0.08370400323493732, Precision = 0.9565217391304348, f1 = 0.9166666666666666\n",
      "Epoch 14: Train Loss = 0.08484394066231578, Recall = 0.9066666666666666, Aging Rate = 0.08613020622725434, Precision = 0.9577464788732394, f1 = 0.9315068493150686\n",
      "Epoch 15: Train Loss = 0.07434353757358927, Recall = 0.9333333333333333, Aging Rate = 0.08734330772341285, Precision = 0.9722222222222222, f1 = 0.9523809523809524\n",
      "Test Loss = 0.06999859021313028, Recall = 0.8933333333333333, Aging Rate = 0.0812778002426203, precision = 1.0\n",
      "Model in epoch 15 is saved.\n",
      "\n",
      "Epoch 16: Train Loss = 0.06960610633138288, Recall = 0.9244444444444444, Aging Rate = 0.08572583906186818, Precision = 0.9811320754716981, f1 = 0.9519450800915331\n",
      "Epoch 17: Train Loss = 0.06076877833834747, Recall = 0.9555555555555556, Aging Rate = 0.08855640921957138, Precision = 0.9817351598173516, f1 = 0.9684684684684685\n",
      "Epoch 18: Train Loss = 0.05736485540601728, Recall = 0.9511111111111111, Aging Rate = 0.08774767488879903, Precision = 0.9861751152073732, f1 = 0.9683257918552037\n",
      "Epoch 19: Train Loss = 0.05040477766450894, Recall = 0.9777777777777777, Aging Rate = 0.09138697937727457, Precision = 0.9734513274336283, f1 = 0.975609756097561\n",
      "Epoch 20: Train Loss = 0.04500405881154696, Recall = 0.9822222222222222, Aging Rate = 0.09017387788111605, Precision = 0.9910313901345291, f1 = 0.9866071428571429\n",
      "Test Loss = 0.03943714515591892, Recall = 0.9866666666666667, Aging Rate = 0.09057824504650222, precision = 0.9910714285714286\n",
      "Model in epoch 20 is saved.\n",
      "\n",
      "Epoch 21: Train Loss = 0.04125025748093324, Recall = 0.9866666666666667, Aging Rate = 0.08976951071572989, Precision = 0, f1 = 0.0\n",
      "Epoch 22: Train Loss = 0.03782542465647078, Recall = 0.9866666666666667, Aging Rate = 0.08976951071572989, Precision = 0, f1 = 0.0\n",
      "Epoch 23: Train Loss = 0.03572287949858843, Recall = 0.9822222222222222, Aging Rate = 0.08976951071572989, Precision = 0.9954954954954955, f1 = 0.988814317673378\n",
      "Epoch 24: Train Loss = 0.03307884627274545, Recall = 0.9911111111111112, Aging Rate = 0.09057824504650222, Precision = 0.9955357142857143, f1 = 0.9933184855233853\n",
      "Epoch 25: Train Loss = 0.03292504368742323, Recall = 0.9955555555555555, Aging Rate = 0.09138697937727457, Precision = 0.9911504424778761, f1 = 0.9933481152993349\n",
      "Test Loss = 0.027985304850501977, Recall = 0.9955555555555555, Aging Rate = 0.0909826122118884, precision = 0.9955555555555555\n",
      "Model in epoch 25 is saved.\n",
      "\n",
      "Epoch 26: Train Loss = 0.02935905763604503, Recall = 0.9911111111111112, Aging Rate = 0.09057824504650222, Precision = 0.9955357142857143, f1 = 0.9933184855233853\n",
      "Epoch 27: Train Loss = 0.032442816059013585, Recall = 0.9866666666666667, Aging Rate = 0.09138697937727457, Precision = 0.9823008849557522, f1 = 0.9844789356984479\n",
      "Epoch 28: Train Loss = 0.025384156390409984, Recall = 0.9955555555555555, Aging Rate = 0.09057824504650222, Precision = 0, f1 = 0.0\n",
      "Epoch 29: Train Loss = 0.02447846592744768, Recall = 0.9955555555555555, Aging Rate = 0.0909826122118884, Precision = 0.9955555555555555, f1 = 0.9955555555555555\n",
      "Epoch 30: Train Loss = 0.023805329710956145, Recall = 0.9955555555555555, Aging Rate = 0.0909826122118884, Precision = 0.9955555555555555, f1 = 0.9955555555555555\n",
      "Test Loss = 0.020473750996573996, Recall = 0.9955555555555555, Aging Rate = 0.09057824504650222, precision = 1.0\n",
      "Model in epoch 30 is saved.\n",
      "\n",
      "Epoch 31: Train Loss = 0.022615440704268915, Recall = 0.9955555555555555, Aging Rate = 0.09057824504650222, Precision = 0, f1 = 0.0\n",
      "Epoch 32: Train Loss = 0.0216631637946422, Recall = 0.9955555555555555, Aging Rate = 0.09057824504650222, Precision = 0, f1 = 0.0\n",
      "Epoch 33: Train Loss = 0.020905671991465116, Recall = 0.9955555555555555, Aging Rate = 0.0909826122118884, Precision = 0.9955555555555555, f1 = 0.9955555555555555\n",
      "Epoch 34: Train Loss = 0.020299910531924217, Recall = 0.9955555555555555, Aging Rate = 0.0909826122118884, Precision = 0.9955555555555555, f1 = 0.9955555555555555\n",
      "Epoch 35: Train Loss = 0.02052985282077801, Recall = 0.9955555555555555, Aging Rate = 0.0909826122118884, Precision = 0.9955555555555555, f1 = 0.9955555555555555\n",
      "Test Loss = 0.016936049143999536, Recall = 0.9955555555555555, Aging Rate = 0.09057824504650222, precision = 1.0\n",
      "\n",
      "Epoch 36: Train Loss = 0.018493333932357282, Recall = 0.9955555555555555, Aging Rate = 0.09057824504650222, Precision = 0, f1 = 0.0\n",
      "Epoch 37: Train Loss = 0.018347568600221992, Recall = 0.9955555555555555, Aging Rate = 0.09057824504650222, Precision = 0, f1 = 0.0\n",
      "Epoch 38: Train Loss = 0.018138082519480923, Recall = 0.9955555555555555, Aging Rate = 0.0909826122118884, Precision = 0.9955555555555555, f1 = 0.9955555555555555\n",
      "Epoch 39: Train Loss = 0.01750557499798749, Recall = 0.9955555555555555, Aging Rate = 0.09057824504650222, Precision = 0, f1 = 0.0\n",
      "Epoch 40: Train Loss = 0.016738475920060808, Recall = 1.0, Aging Rate = 0.0909826122118884, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.014941868713834341, Recall = 0.9955555555555555, Aging Rate = 0.09057824504650222, precision = 1.0\n",
      "\n",
      "Epoch 41: Train Loss = 0.016558276936396794, Recall = 0.9955555555555555, Aging Rate = 0.0909826122118884, Precision = 0.9955555555555555, f1 = 0.9955555555555555\n",
      "Epoch 42: Train Loss = 0.017003020132694873, Recall = 0.9955555555555555, Aging Rate = 0.0909826122118884, Precision = 0.9955555555555555, f1 = 0.9955555555555555\n",
      "Epoch 43: Train Loss = 0.01638184952464149, Recall = 0.9955555555555555, Aging Rate = 0.0909826122118884, Precision = 0.9955555555555555, f1 = 0.9955555555555555\n",
      "Epoch 44: Train Loss = 0.015147137173477468, Recall = 1.0, Aging Rate = 0.0909826122118884, Precision = 0, f1 = 0.0\n",
      "Epoch 45: Train Loss = 0.016022641169569342, Recall = 0.9955555555555555, Aging Rate = 0.09057824504650222, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.01387739039541761, Recall = 1.0, Aging Rate = 0.0909826122118884, precision = 1.0\n",
      "Model in epoch 45 is saved.\n",
      "\n",
      "Epoch 46: Train Loss = 0.0155741491306421, Recall = 1.0, Aging Rate = 0.09138697937727457, Precision = 0.995575221238938, f1 = 0.9977827050997783\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 47: Train Loss = 0.015873298820995436, Recall = 1.0, Aging Rate = 0.0909826122118884, Precision = 0, f1 = 0.0\n",
      "Epoch 48: Train Loss = 0.015159628445714158, Recall = 0.9955555555555555, Aging Rate = 0.09057824504650222, Precision = 0, f1 = 0.0\n",
      "Epoch 49: Train Loss = 0.015271520347918545, Recall = 0.9955555555555555, Aging Rate = 0.0909826122118884, Precision = 0.9955555555555555, f1 = 0.9955555555555555\n",
      "Epoch 50: Train Loss = 0.01449635316585023, Recall = 0.9955555555555555, Aging Rate = 0.09057824504650222, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.012945820418142424, Recall = 1.0, Aging Rate = 0.09138697937727457, precision = 0.995575221238938\n",
      "\n",
      "Epoch 51: Train Loss = 0.014433446437048131, Recall = 1.0, Aging Rate = 0.09138697937727457, Precision = 0.995575221238938, f1 = 0.9977827050997783\n",
      "Epoch 52: Train Loss = 0.014531883139583536, Recall = 0.9955555555555555, Aging Rate = 0.09057824504650222, Precision = 0, f1 = 0.0\n",
      "Epoch 53: Train Loss = 0.014813757626195934, Recall = 1.0, Aging Rate = 0.0909826122118884, Precision = 0, f1 = 0.0\n",
      "Epoch 54: Train Loss = 0.014292942587884268, Recall = 1.0, Aging Rate = 0.0909826122118884, Precision = 0, f1 = 0.0\n",
      "Epoch 55: Train Loss = 0.015708392772942576, Recall = 0.9955555555555555, Aging Rate = 0.09057824504650222, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.012985321739632027, Recall = 0.9955555555555555, Aging Rate = 0.09057824504650222, precision = 1.0\n",
      "\n",
      "Epoch 56: Train Loss = 0.014677571983604244, Recall = 0.9955555555555555, Aging Rate = 0.09057824504650222, Precision = 0, f1 = 0.0\n",
      "Epoch 57: Train Loss = 0.013416274769319801, Recall = 1.0, Aging Rate = 0.0909826122118884, Precision = 0, f1 = 0.0\n",
      "Epoch 58: Train Loss = 0.014327457333958998, Recall = 1.0, Aging Rate = 0.0909826122118884, Precision = 0, f1 = 0.0\n",
      "Epoch 59: Train Loss = 0.013403093207701347, Recall = 0.9955555555555555, Aging Rate = 0.09057824504650222, Precision = 0, f1 = 0.0\n",
      "Epoch 60: Train Loss = 0.013403286615870908, Recall = 1.0, Aging Rate = 0.0909826122118884, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.011900254517524012, Recall = 0.9955555555555555, Aging Rate = 0.09057824504650222, precision = 1.0\n",
      "\n",
      "Epoch 61: Train Loss = 0.014422159094033552, Recall = 0.9955555555555555, Aging Rate = 0.0909826122118884, Precision = 0.9955555555555555, f1 = 0.9955555555555555\n",
      "Epoch 62: Train Loss = 0.013169551510747945, Recall = 1.0, Aging Rate = 0.0909826122118884, Precision = 0, f1 = 0.0\n",
      "Epoch 63: Train Loss = 0.01315407860975937, Recall = 1.0, Aging Rate = 0.09138697937727457, Precision = 0.995575221238938, f1 = 0.9977827050997783\n",
      "Epoch 64: Train Loss = 0.013352302627263645, Recall = 0.9955555555555555, Aging Rate = 0.09057824504650222, Precision = 0, f1 = 0.0\n",
      "Epoch 65: Train Loss = 0.013953646254419581, Recall = 1.0, Aging Rate = 0.09138697937727457, Precision = 0.995575221238938, f1 = 0.9977827050997783\n",
      "Test Loss = 0.011024386903705672, Recall = 1.0, Aging Rate = 0.0909826122118884, precision = 1.0\n",
      "\n",
      "Epoch 66: Train Loss = 0.014000320880629764, Recall = 0.9955555555555555, Aging Rate = 0.09057824504650222, Precision = 0, f1 = 0.0\n",
      "Epoch 67: Train Loss = 0.013810726830165636, Recall = 1.0, Aging Rate = 0.0909826122118884, Precision = 0, f1 = 0.0\n",
      "Epoch 68: Train Loss = 0.0135316207287159, Recall = 1.0, Aging Rate = 0.0909826122118884, Precision = 0, f1 = 0.0\n",
      "Epoch 69: Train Loss = 0.013606665930132657, Recall = 0.9955555555555555, Aging Rate = 0.09057824504650222, Precision = 0, f1 = 0.0\n",
      "Epoch 70: Train Loss = 0.012958922763865365, Recall = 1.0, Aging Rate = 0.0909826122118884, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.010693673295256246, Recall = 1.0, Aging Rate = 0.0909826122118884, precision = 1.0\n",
      "\n",
      "Epoch 71: Train Loss = 0.012976167709225833, Recall = 1.0, Aging Rate = 0.09138697937727457, Precision = 0.995575221238938, f1 = 0.9977827050997783\n",
      "Epoch 72: Train Loss = 0.012955193938081123, Recall = 1.0, Aging Rate = 0.0909826122118884, Precision = 0, f1 = 0.0\n",
      "Epoch 73: Train Loss = 0.012786012328182017, Recall = 0.9955555555555555, Aging Rate = 0.09057824504650222, Precision = 0, f1 = 0.0\n",
      "Epoch 74: Train Loss = 0.01273689748854156, Recall = 1.0, Aging Rate = 0.0909826122118884, Precision = 0, f1 = 0.0\n",
      "Epoch 75: Train Loss = 0.012758779712605075, Recall = 1.0, Aging Rate = 0.09138697937727457, Precision = 0.995575221238938, f1 = 0.9977827050997783\n",
      "Test Loss = 0.012721145821202757, Recall = 1.0, Aging Rate = 0.0909826122118884, precision = 1.0\n",
      "\n",
      "Epoch 76: Train Loss = 0.012880274063007123, Recall = 1.0, Aging Rate = 0.0909826122118884, Precision = 0, f1 = 0.0\n",
      "Epoch 77: Train Loss = 0.01240270294691935, Recall = 1.0, Aging Rate = 0.0909826122118884, Precision = 0, f1 = 0.0\n",
      "Epoch 78: Train Loss = 0.01321893675291208, Recall = 1.0, Aging Rate = 0.09138697937727457, Precision = 0.995575221238938, f1 = 0.9977827050997783\n",
      "Epoch 79: Train Loss = 0.012300787924412672, Recall = 1.0, Aging Rate = 0.0909826122118884, Precision = 0, f1 = 0.0\n",
      "Epoch 80: Train Loss = 0.013136743162383935, Recall = 1.0, Aging Rate = 0.0909826122118884, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.013810345198427358, Recall = 1.0, Aging Rate = 0.0909826122118884, precision = 1.0\n",
      "\n",
      "Epoch 81: Train Loss = 0.013350368590006403, Recall = 1.0, Aging Rate = 0.09138697937727457, Precision = 0.995575221238938, f1 = 0.9977827050997783\n",
      "Epoch 82: Train Loss = 0.012237166274479055, Recall = 0.9955555555555555, Aging Rate = 0.09057824504650222, Precision = 0, f1 = 0.0\n",
      "Epoch 83: Train Loss = 0.012680663710653637, Recall = 1.0, Aging Rate = 0.0909826122118884, Precision = 0, f1 = 0.0\n",
      "Epoch 84: Train Loss = 0.012558745826246933, Recall = 1.0, Aging Rate = 0.09138697937727457, Precision = 0.995575221238938, f1 = 0.9977827050997783\n",
      "Epoch 85: Train Loss = 0.012146616522170034, Recall = 0.9955555555555555, Aging Rate = 0.09057824504650222, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.01605274522540736, Recall = 1.0, Aging Rate = 0.09138697937727457, precision = 0.995575221238938\n",
      "\n",
      "Epoch 86: Train Loss = 0.0129799404263638, Recall = 1.0, Aging Rate = 0.0909826122118884, Precision = 0, f1 = 0.0\n",
      "Epoch 87: Train Loss = 0.012867138100794775, Recall = 1.0, Aging Rate = 0.0909826122118884, Precision = 0, f1 = 0.0\n",
      "Epoch 88: Train Loss = 0.013217254233381983, Recall = 0.9955555555555555, Aging Rate = 0.09057824504650222, Precision = 0, f1 = 0.0\n",
      "Epoch 89: Train Loss = 0.013683076128453993, Recall = 1.0, Aging Rate = 0.09138697937727457, Precision = 0.995575221238938, f1 = 0.9977827050997783\n",
      "Epoch 90: Train Loss = 0.01237855307732246, Recall = 1.0, Aging Rate = 0.0909826122118884, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.010841467267891269, Recall = 1.0, Aging Rate = 0.0909826122118884, precision = 1.0\n",
      "\n",
      "Epoch 91: Train Loss = 0.012418555944639809, Recall = 1.0, Aging Rate = 0.0909826122118884, Precision = 0, f1 = 0.0\n",
      "Epoch 92: Train Loss = 0.012699676967563776, Recall = 0.9955555555555555, Aging Rate = 0.09057824504650222, Precision = 0, f1 = 0.0\n",
      "Epoch 93: Train Loss = 0.012647484818957761, Recall = 1.0, Aging Rate = 0.0909826122118884, Precision = 0, f1 = 0.0\n",
      "Epoch 94: Train Loss = 0.012875178373154002, Recall = 1.0, Aging Rate = 0.0909826122118884, Precision = 0, f1 = 0.0\n",
      "Epoch 95: Train Loss = 0.011627268305238905, Recall = 1.0, Aging Rate = 0.0909826122118884, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.010693500743929584, Recall = 1.0, Aging Rate = 0.0909826122118884, precision = 1.0\n",
      "\n",
      "Training Finished at epoch 95.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39d42c4f402a4baf8a3966749b3344c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss = 0.506189209606018, Recall = 0.03111111111111111, Aging Rate = 0.058228871815608575, Precision = 0.04861111111111111, f1 = 0.037940379403794036\n",
      "Epoch 2: Train Loss = 0.4079822874833252, Recall = 0.008888888888888889, Aging Rate = 0.0008087343307723412, Precision = 0, f1 = 0.0\n",
      "Epoch 3: Train Loss = 0.3431230160542167, Recall = 0.24888888888888888, Aging Rate = 0.02668823291548726, Precision = 0.8484848484848485, f1 = 0.3848797250859107\n",
      "Epoch 4: Train Loss = 0.2906703722414294, Recall = 0.4266666666666667, Aging Rate = 0.044884755357864944, Precision = 0.8648648648648649, f1 = 0.5714285714285715\n",
      "Epoch 5: Train Loss = 0.25495074387508704, Recall = 0.5555555555555556, Aging Rate = 0.06267691063485645, Precision = 0.8064516129032258, f1 = 0.6578947368421053\n",
      "Test Loss = 0.2223787629262089, Recall = 0.5733333333333334, Aging Rate = 0.0578245046502224, precision = 0.9020979020979021\n",
      "Model in epoch 5 is saved.\n",
      "\n",
      "Epoch 6: Train Loss = 0.2216577579527551, Recall = 0.5955555555555555, Aging Rate = 0.06752931661949049, Precision = 0.8023952095808383, f1 = 0.6836734693877551\n",
      "Epoch 7: Train Loss = 0.19541326926225022, Recall = 0.6711111111111111, Aging Rate = 0.0703598867771937, Precision = 0.867816091954023, f1 = 0.7568922305764411\n",
      "Epoch 8: Train Loss = 0.17194575378637394, Recall = 0.7555555555555555, Aging Rate = 0.07763849575414476, Precision = 0.8854166666666666, f1 = 0.815347721822542\n",
      "Epoch 9: Train Loss = 0.15754882118213143, Recall = 0.7911111111111111, Aging Rate = 0.08329963606955115, Precision = 0.8640776699029126, f1 = 0.8259860788863109\n",
      "Epoch 10: Train Loss = 0.13818268900909647, Recall = 0.8266666666666667, Aging Rate = 0.0841083704003235, Precision = 0.8942307692307693, f1 = 0.8591224018475752\n",
      "Test Loss = 0.12127606749076666, Recall = 0.88, Aging Rate = 0.08774767488879903, precision = 0.9124423963133641\n",
      "Model in epoch 10 is saved.\n",
      "\n",
      "Epoch 11: Train Loss = 0.12347802707644498, Recall = 0.88, Aging Rate = 0.08734330772341285, Precision = 0.9166666666666666, f1 = 0.8979591836734694\n",
      "Epoch 12: Train Loss = 0.11018470820872542, Recall = 0.8933333333333333, Aging Rate = 0.08653457339264052, Precision = 0.9392523364485982, f1 = 0.9157175398633257\n",
      "Epoch 13: Train Loss = 0.09974962775096496, Recall = 0.92, Aging Rate = 0.08855640921957138, Precision = 0.9452054794520548, f1 = 0.9324324324324323\n",
      "Epoch 14: Train Loss = 0.09425269046800608, Recall = 0.9288888888888889, Aging Rate = 0.0909826122118884, Precision = 0.9288888888888889, f1 = 0.9288888888888889\n",
      "Epoch 15: Train Loss = 0.08075232973892439, Recall = 0.9244444444444444, Aging Rate = 0.08693894055802669, Precision = 0.9674418604651163, f1 = 0.9454545454545454\n",
      "Test Loss = 0.07670655787244192, Recall = 0.9333333333333333, Aging Rate = 0.08532147189648201, precision = 0.995260663507109\n",
      "Model in epoch 15 is saved.\n",
      "\n",
      "Epoch 16: Train Loss = 0.07913574983403117, Recall = 0.9422222222222222, Aging Rate = 0.08855640921957138, Precision = 0.9680365296803652, f1 = 0.9549549549549549\n",
      "Epoch 17: Train Loss = 0.06783120675796543, Recall = 0.9422222222222222, Aging Rate = 0.08734330772341285, Precision = 0.9814814814814815, f1 = 0.9614512471655329\n",
      "Epoch 18: Train Loss = 0.06303311795225232, Recall = 0.9511111111111111, Aging Rate = 0.08855640921957138, Precision = 0.9771689497716894, f1 = 0.9639639639639639\n",
      "Epoch 19: Train Loss = 0.05789663097634761, Recall = 0.9644444444444444, Aging Rate = 0.08976951071572989, Precision = 0.9774774774774775, f1 = 0.970917225950783\n",
      "Epoch 20: Train Loss = 0.054000023163454376, Recall = 0.96, Aging Rate = 0.08896077638495754, Precision = 0.9818181818181818, f1 = 0.9707865168539325\n",
      "Test Loss = 0.045926714348397756, Recall = 0.9733333333333334, Aging Rate = 0.08976951071572989, precision = 0.9864864864864865\n",
      "Model in epoch 20 is saved.\n",
      "\n",
      "Epoch 21: Train Loss = 0.05075108383891797, Recall = 0.96, Aging Rate = 0.08855640921957138, Precision = 0.9863013698630136, f1 = 0.9729729729729729\n",
      "Epoch 22: Train Loss = 0.044984274041818983, Recall = 0.9644444444444444, Aging Rate = 0.0881520420541852, Precision = 0.9954128440366973, f1 = 0.979683972911964\n",
      "Epoch 23: Train Loss = 0.04224367640755115, Recall = 0.9733333333333334, Aging Rate = 0.08936514355034371, Precision = 0.9909502262443439, f1 = 0.9820627802690584\n",
      "Epoch 24: Train Loss = 0.03848872776115008, Recall = 0.9733333333333334, Aging Rate = 0.08855640921957138, Precision = 0, f1 = 0.0\n",
      "Epoch 25: Train Loss = 0.03575819822422199, Recall = 0.9777777777777777, Aging Rate = 0.08936514355034371, Precision = 0.995475113122172, f1 = 0.9865470852017937\n",
      "Test Loss = 0.03322613787122924, Recall = 0.9733333333333334, Aging Rate = 0.08855640921957138, precision = 1.0\n",
      "Model in epoch 25 is saved.\n",
      "\n",
      "Epoch 26: Train Loss = 0.03484918407228159, Recall = 0.9777777777777777, Aging Rate = 0.08936514355034371, Precision = 0.995475113122172, f1 = 0.9865470852017937\n",
      "Epoch 27: Train Loss = 0.03228792459905461, Recall = 0.9822222222222222, Aging Rate = 0.09017387788111605, Precision = 0.9910313901345291, f1 = 0.9866071428571429\n",
      "Epoch 28: Train Loss = 0.030502406581995267, Recall = 0.9777777777777777, Aging Rate = 0.08896077638495754, Precision = 0, f1 = 0.0\n",
      "Epoch 29: Train Loss = 0.028324606872453317, Recall = 0.9866666666666667, Aging Rate = 0.08976951071572989, Precision = 0, f1 = 0.0\n",
      "Epoch 30: Train Loss = 0.026769873006755145, Recall = 0.9911111111111112, Aging Rate = 0.09057824504650222, Precision = 0.9955357142857143, f1 = 0.9933184855233853\n",
      "Test Loss = 0.022959728962510185, Recall = 0.9955555555555555, Aging Rate = 0.09057824504650222, precision = 1.0\n",
      "Model in epoch 30 is saved.\n",
      "\n",
      "Epoch 31: Train Loss = 0.02595311177844009, Recall = 0.9866666666666667, Aging Rate = 0.08976951071572989, Precision = 0, f1 = 0.0\n",
      "Epoch 32: Train Loss = 0.024796041961758577, Recall = 0.9911111111111112, Aging Rate = 0.09057824504650222, Precision = 0.9955357142857143, f1 = 0.9933184855233853\n",
      "Epoch 33: Train Loss = 0.022474472779664634, Recall = 0.9955555555555555, Aging Rate = 0.09057824504650222, Precision = 0, f1 = 0.0\n",
      "Epoch 34: Train Loss = 0.02210444781712335, Recall = 0.9955555555555555, Aging Rate = 0.09057824504650222, Precision = 0, f1 = 0.0\n",
      "Epoch 35: Train Loss = 0.02068303140670022, Recall = 0.9911111111111112, Aging Rate = 0.09017387788111605, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.018281822856944966, Recall = 1.0, Aging Rate = 0.0909826122118884, precision = 1.0\n",
      "Model in epoch 35 is saved.\n",
      "\n",
      "Epoch 36: Train Loss = 0.019846310982916743, Recall = 1.0, Aging Rate = 0.0909826122118884, Precision = 0, f1 = 0.0\n",
      "Epoch 37: Train Loss = 0.01945909460591513, Recall = 0.9955555555555555, Aging Rate = 0.09057824504650222, Precision = 0, f1 = 0.0\n",
      "Epoch 38: Train Loss = 0.019409956545348692, Recall = 1.0, Aging Rate = 0.0909826122118884, Precision = 0, f1 = 0.0\n",
      "Epoch 39: Train Loss = 0.019004825502069153, Recall = 1.0, Aging Rate = 0.09138697937727457, Precision = 0.995575221238938, f1 = 0.9977827050997783\n",
      "Epoch 40: Train Loss = 0.01806866948963947, Recall = 0.9955555555555555, Aging Rate = 0.09057824504650222, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.015974819263254298, Recall = 1.0, Aging Rate = 0.0909826122118884, precision = 1.0\n",
      "\n",
      "Epoch 41: Train Loss = 0.017188177779588053, Recall = 1.0, Aging Rate = 0.0909826122118884, Precision = 0, f1 = 0.0\n",
      "Epoch 42: Train Loss = 0.017269892851549798, Recall = 1.0, Aging Rate = 0.0909826122118884, Precision = 0, f1 = 0.0\n",
      "Epoch 43: Train Loss = 0.016254356732758442, Recall = 1.0, Aging Rate = 0.0909826122118884, Precision = 0, f1 = 0.0\n",
      "Epoch 44: Train Loss = 0.01602810582961756, Recall = 1.0, Aging Rate = 0.0909826122118884, Precision = 0, f1 = 0.0\n",
      "Epoch 45: Train Loss = 0.01584227761239404, Recall = 1.0, Aging Rate = 0.0909826122118884, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.01633549287833885, Recall = 1.0, Aging Rate = 0.0909826122118884, precision = 1.0\n",
      "\n",
      "Epoch 46: Train Loss = 0.01707423747555958, Recall = 1.0, Aging Rate = 0.0909826122118884, Precision = 0, f1 = 0.0\n",
      "Epoch 47: Train Loss = 0.01582806674613675, Recall = 1.0, Aging Rate = 0.0909826122118884, Precision = 0, f1 = 0.0\n",
      "Epoch 48: Train Loss = 0.015548971582925663, Recall = 1.0, Aging Rate = 0.09138697937727457, Precision = 0.995575221238938, f1 = 0.9977827050997783\n",
      "Epoch 49: Train Loss = 0.014894583452307666, Recall = 1.0, Aging Rate = 0.0909826122118884, Precision = 0, f1 = 0.0\n",
      "Epoch 50: Train Loss = 0.0146721593818706, Recall = 1.0, Aging Rate = 0.0909826122118884, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.012833570823106528, Recall = 1.0, Aging Rate = 0.0909826122118884, precision = 1.0\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 51: Train Loss = 0.01524498743813649, Recall = 1.0, Aging Rate = 0.09138697937727457, Precision = 0.995575221238938, f1 = 0.9977827050997783\n",
      "Epoch 52: Train Loss = 0.013999453205366729, Recall = 1.0, Aging Rate = 0.0909826122118884, Precision = 0, f1 = 0.0\n",
      "Epoch 53: Train Loss = 0.014969897510320419, Recall = 1.0, Aging Rate = 0.0909826122118884, Precision = 0, f1 = 0.0\n",
      "Epoch 54: Train Loss = 0.014888976616528845, Recall = 1.0, Aging Rate = 0.0909826122118884, Precision = 0, f1 = 0.0\n",
      "Epoch 55: Train Loss = 0.013767071060190076, Recall = 1.0, Aging Rate = 0.0909826122118884, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.012826504601558066, Recall = 1.0, Aging Rate = 0.0909826122118884, precision = 1.0\n",
      "\n",
      "Epoch 56: Train Loss = 0.013281108887570135, Recall = 1.0, Aging Rate = 0.0909826122118884, Precision = 0, f1 = 0.0\n",
      "Epoch 57: Train Loss = 0.01316741192799997, Recall = 1.0, Aging Rate = 0.0909826122118884, Precision = 0, f1 = 0.0\n",
      "Epoch 58: Train Loss = 0.013564673803858361, Recall = 1.0, Aging Rate = 0.0909826122118884, Precision = 0, f1 = 0.0\n",
      "Epoch 59: Train Loss = 0.013411720028373812, Recall = 1.0, Aging Rate = 0.0909826122118884, Precision = 0, f1 = 0.0\n",
      "Epoch 60: Train Loss = 0.013706516055145451, Recall = 1.0, Aging Rate = 0.0909826122118884, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.012178866690935344, Recall = 1.0, Aging Rate = 0.0909826122118884, precision = 1.0\n",
      "\n",
      "Epoch 61: Train Loss = 0.012863335759652756, Recall = 1.0, Aging Rate = 0.0909826122118884, Precision = 0, f1 = 0.0\n",
      "Epoch 62: Train Loss = 0.012864932491682437, Recall = 1.0, Aging Rate = 0.0909826122118884, Precision = 0, f1 = 0.0\n",
      "Epoch 63: Train Loss = 0.013023023103434235, Recall = 1.0, Aging Rate = 0.0909826122118884, Precision = 0, f1 = 0.0\n",
      "Epoch 64: Train Loss = 0.013009424625643222, Recall = 1.0, Aging Rate = 0.0909826122118884, Precision = 0, f1 = 0.0\n",
      "Epoch 65: Train Loss = 0.013052814890917886, Recall = 1.0, Aging Rate = 0.0909826122118884, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.011083394700189238, Recall = 1.0, Aging Rate = 0.0909826122118884, precision = 1.0\n",
      "\n",
      "Epoch 66: Train Loss = 0.01351515885127661, Recall = 1.0, Aging Rate = 0.0909826122118884, Precision = 0, f1 = 0.0\n",
      "Epoch 67: Train Loss = 0.01321687330060638, Recall = 1.0, Aging Rate = 0.0909826122118884, Precision = 0, f1 = 0.0\n",
      "Epoch 68: Train Loss = 0.012773401057827816, Recall = 1.0, Aging Rate = 0.0909826122118884, Precision = 0, f1 = 0.0\n",
      "Epoch 69: Train Loss = 0.012940494995526563, Recall = 1.0, Aging Rate = 0.0909826122118884, Precision = 0, f1 = 0.0\n",
      "Epoch 70: Train Loss = 0.012539702787256456, Recall = 1.0, Aging Rate = 0.0909826122118884, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.011132643457345463, Recall = 1.0, Aging Rate = 0.0909826122118884, precision = 1.0\n",
      "\n",
      "Epoch 71: Train Loss = 0.012817513672171746, Recall = 1.0, Aging Rate = 0.0909826122118884, Precision = 0, f1 = 0.0\n",
      "Epoch 72: Train Loss = 0.013998755910258712, Recall = 1.0, Aging Rate = 0.09138697937727457, Precision = 0.995575221238938, f1 = 0.9977827050997783\n",
      "Epoch 73: Train Loss = 0.012916565141755465, Recall = 1.0, Aging Rate = 0.0909826122118884, Precision = 0, f1 = 0.0\n",
      "Epoch 74: Train Loss = 0.012363301326467641, Recall = 1.0, Aging Rate = 0.0909826122118884, Precision = 0, f1 = 0.0\n",
      "Epoch 75: Train Loss = 0.01284777055303553, Recall = 1.0, Aging Rate = 0.0909826122118884, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.010950679671444117, Recall = 1.0, Aging Rate = 0.0909826122118884, precision = 1.0\n",
      "\n",
      "Epoch 76: Train Loss = 0.012512458528076052, Recall = 1.0, Aging Rate = 0.0909826122118884, Precision = 0, f1 = 0.0\n",
      "Epoch 77: Train Loss = 0.012201622964530352, Recall = 1.0, Aging Rate = 0.0909826122118884, Precision = 0, f1 = 0.0\n",
      "Epoch 78: Train Loss = 0.012612830366211723, Recall = 1.0, Aging Rate = 0.0909826122118884, Precision = 0, f1 = 0.0\n",
      "Epoch 79: Train Loss = 0.011882092941927491, Recall = 1.0, Aging Rate = 0.0909826122118884, Precision = 0, f1 = 0.0\n",
      "Epoch 80: Train Loss = 0.011490485170352232, Recall = 1.0, Aging Rate = 0.0909826122118884, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.01029040658785489, Recall = 1.0, Aging Rate = 0.0909826122118884, precision = 1.0\n",
      "\n",
      "Epoch 81: Train Loss = 0.011925918157440277, Recall = 1.0, Aging Rate = 0.0909826122118884, Precision = 0, f1 = 0.0\n",
      "Epoch 82: Train Loss = 0.01207453762194284, Recall = 1.0, Aging Rate = 0.0909826122118884, Precision = 0, f1 = 0.0\n",
      "Epoch 83: Train Loss = 0.013382986866561353, Recall = 1.0, Aging Rate = 0.0909826122118884, Precision = 0, f1 = 0.0\n",
      "Epoch 84: Train Loss = 0.01204718195664174, Recall = 1.0, Aging Rate = 0.0909826122118884, Precision = 0, f1 = 0.0\n",
      "Epoch 85: Train Loss = 0.011751908530453669, Recall = 1.0, Aging Rate = 0.0909826122118884, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.010525354961128405, Recall = 1.0, Aging Rate = 0.0909826122118884, precision = 1.0\n",
      "\n",
      "Training Finished at epoch 85.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed86671049a14327b78df0cee26fd5da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss = 0.4909127623481496, Recall = 0.13777777777777778, Aging Rate = 0.06955115244642135, Precision = 0.18023255813953487, f1 = 0.1561712846347607\n",
      "Epoch 2: Train Loss = 0.38840718716202216, Recall = 0.08888888888888889, Aging Rate = 0.008896077638495753, Precision = 0.9090909090909091, f1 = 0.1619433198380567\n",
      "Epoch 3: Train Loss = 0.328066931506472, Recall = 0.3244444444444444, Aging Rate = 0.03881924787707238, Precision = 0.7604166666666666, f1 = 0.45482866043613707\n",
      "Epoch 4: Train Loss = 0.289370748237396, Recall = 0.4666666666666667, Aging Rate = 0.057015770319450064, Precision = 0.7446808510638298, f1 = 0.5737704918032787\n",
      "Epoch 5: Train Loss = 0.2506706471499575, Recall = 0.5377777777777778, Aging Rate = 0.06348564496562879, Precision = 0.7707006369426752, f1 = 0.6335078534031414\n",
      "Test Loss = 0.2265693141991823, Recall = 0.64, Aging Rate = 0.07480792559644157, precision = 0.7783783783783784\n",
      "Model in epoch 5 is saved.\n",
      "\n",
      "Epoch 6: Train Loss = 0.22291431648922602, Recall = 0.6222222222222222, Aging Rate = 0.0703598867771937, Precision = 0.8045977011494253, f1 = 0.7017543859649121\n",
      "Epoch 7: Train Loss = 0.2010700333226296, Recall = 0.6933333333333334, Aging Rate = 0.07319045693489688, Precision = 0.861878453038674, f1 = 0.768472906403941\n",
      "Epoch 8: Train Loss = 0.18038697133734793, Recall = 0.7333333333333333, Aging Rate = 0.07682976142337242, Precision = 0.868421052631579, f1 = 0.7951807228915663\n",
      "Epoch 9: Train Loss = 0.15873419097860092, Recall = 0.7644444444444445, Aging Rate = 0.0744035584310554, Precision = 0.9347826086956522, f1 = 0.8410757946210269\n",
      "Epoch 10: Train Loss = 0.14257959702292822, Recall = 0.7955555555555556, Aging Rate = 0.08087343307723413, Precision = 0.895, f1 = 0.8423529411764705\n",
      "Test Loss = 0.12588052729387975, Recall = 0.8622222222222222, Aging Rate = 0.08370400323493732, precision = 0.9371980676328503\n",
      "Model in epoch 10 is saved.\n",
      "\n",
      "Epoch 11: Train Loss = 0.12936938214509341, Recall = 0.8222222222222222, Aging Rate = 0.08249090173877881, Precision = 0.9068627450980392, f1 = 0.8624708624708624\n",
      "Epoch 12: Train Loss = 0.11653189590969791, Recall = 0.8622222222222222, Aging Rate = 0.08532147189648201, Precision = 0.919431279620853, f1 = 0.8899082568807339\n",
      "Epoch 13: Train Loss = 0.10552772114507544, Recall = 0.8622222222222222, Aging Rate = 0.0841083704003235, Precision = 0.9326923076923077, f1 = 0.8960739030023095\n",
      "Epoch 14: Train Loss = 0.0929118929859409, Recall = 0.9022222222222223, Aging Rate = 0.08734330772341285, Precision = 0.9398148148148148, f1 = 0.9206349206349207\n",
      "Epoch 15: Train Loss = 0.085821096456598, Recall = 0.9066666666666666, Aging Rate = 0.08653457339264052, Precision = 0.9532710280373832, f1 = 0.929384965831435\n",
      "Test Loss = 0.07680489743498237, Recall = 0.9555555555555556, Aging Rate = 0.09300444803881924, precision = 0.9347826086956522\n",
      "Model in epoch 15 is saved.\n",
      "\n",
      "Epoch 16: Train Loss = 0.07739644426531604, Recall = 0.92, Aging Rate = 0.0881520420541852, Precision = 0.9495412844036697, f1 = 0.9345372460496613\n",
      "Epoch 17: Train Loss = 0.07017360800885498, Recall = 0.9466666666666667, Aging Rate = 0.0881520420541852, Precision = 0.9770642201834863, f1 = 0.9616252821670429\n",
      "Epoch 18: Train Loss = 0.06404025873769598, Recall = 0.9466666666666667, Aging Rate = 0.08896077638495754, Precision = 0.9681818181818181, f1 = 0.9573033707865168\n",
      "Epoch 19: Train Loss = 0.06162900985299553, Recall = 0.9555555555555556, Aging Rate = 0.08896077638495754, Precision = 0.9772727272727273, f1 = 0.9662921348314608\n",
      "Epoch 20: Train Loss = 0.05261703129530893, Recall = 0.9777777777777777, Aging Rate = 0.08976951071572989, Precision = 0.990990990990991, f1 = 0.9843400447427293\n",
      "Test Loss = 0.04678514884280932, Recall = 0.9866666666666667, Aging Rate = 0.09057824504650222, precision = 0.9910714285714286\n",
      "Model in epoch 20 is saved.\n",
      "\n",
      "Epoch 21: Train Loss = 0.05086663104533498, Recall = 0.9733333333333334, Aging Rate = 0.08936514355034371, Precision = 0.9909502262443439, f1 = 0.9820627802690584\n",
      "Epoch 22: Train Loss = 0.046545755488702364, Recall = 0.9733333333333334, Aging Rate = 0.08976951071572989, Precision = 0.9864864864864865, f1 = 0.9798657718120806\n",
      "Epoch 23: Train Loss = 0.04404614584387144, Recall = 0.9866666666666667, Aging Rate = 0.09057824504650222, Precision = 0.9910714285714286, f1 = 0.9888641425389756\n",
      "Epoch 24: Train Loss = 0.039879510198745034, Recall = 0.9866666666666667, Aging Rate = 0.09017387788111605, Precision = 0.9955156950672646, f1 = 0.9910714285714286\n",
      "Epoch 25: Train Loss = 0.038210098237383715, Recall = 0.9822222222222222, Aging Rate = 0.08976951071572989, Precision = 0.9954954954954955, f1 = 0.988814317673378\n",
      "Test Loss = 0.03640206568651097, Recall = 0.9911111111111112, Aging Rate = 0.09057824504650222, precision = 0.9955357142857143\n",
      "Model in epoch 25 is saved.\n",
      "\n",
      "Epoch 26: Train Loss = 0.036448346391422665, Recall = 0.9911111111111112, Aging Rate = 0.09017387788111605, Precision = 0, f1 = 0.0\n",
      "Epoch 27: Train Loss = 0.034574969567349456, Recall = 0.9866666666666667, Aging Rate = 0.09017387788111605, Precision = 0.9955156950672646, f1 = 0.9910714285714286\n",
      "Epoch 28: Train Loss = 0.032608289147128024, Recall = 0.9911111111111112, Aging Rate = 0.09017387788111605, Precision = 0, f1 = 0.0\n",
      "Epoch 29: Train Loss = 0.030314703764573937, Recall = 0.9866666666666667, Aging Rate = 0.08976951071572989, Precision = 0, f1 = 0.0\n",
      "Epoch 30: Train Loss = 0.029552942321903544, Recall = 0.9866666666666667, Aging Rate = 0.08976951071572989, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.02550747302943427, Recall = 0.9911111111111112, Aging Rate = 0.09017387788111605, precision = 1.0\n",
      "Model in epoch 30 is saved.\n",
      "\n",
      "Epoch 31: Train Loss = 0.028073234309800483, Recall = 0.9911111111111112, Aging Rate = 0.09017387788111605, Precision = 0, f1 = 0.0\n",
      "Epoch 32: Train Loss = 0.02741983665316827, Recall = 0.9911111111111112, Aging Rate = 0.09057824504650222, Precision = 0.9955357142857143, f1 = 0.9933184855233853\n",
      "Epoch 33: Train Loss = 0.02642123100660015, Recall = 0.9911111111111112, Aging Rate = 0.09057824504650222, Precision = 0.9955357142857143, f1 = 0.9933184855233853\n",
      "Epoch 34: Train Loss = 0.024233911285124903, Recall = 0.9911111111111112, Aging Rate = 0.09017387788111605, Precision = 0, f1 = 0.0\n",
      "Epoch 35: Train Loss = 0.02484873946179179, Recall = 0.9911111111111112, Aging Rate = 0.09017387788111605, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.020802312488021803, Recall = 0.9955555555555555, Aging Rate = 0.0909826122118884, precision = 0.9955555555555555\n",
      "\n",
      "Epoch 36: Train Loss = 0.02444748309306466, Recall = 0.9911111111111112, Aging Rate = 0.09017387788111605, Precision = 0, f1 = 0.0\n",
      "Epoch 37: Train Loss = 0.02199093765231566, Recall = 0.9955555555555555, Aging Rate = 0.09057824504650222, Precision = 0, f1 = 0.0\n",
      "Epoch 38: Train Loss = 0.02146913592499902, Recall = 0.9955555555555555, Aging Rate = 0.09057824504650222, Precision = 0, f1 = 0.0\n",
      "Epoch 39: Train Loss = 0.020923646862117375, Recall = 0.9955555555555555, Aging Rate = 0.0909826122118884, Precision = 0.9955555555555555, f1 = 0.9955555555555555\n",
      "Epoch 40: Train Loss = 0.02122844835977551, Recall = 0.9955555555555555, Aging Rate = 0.0909826122118884, Precision = 0.9955555555555555, f1 = 0.9955555555555555\n",
      "Test Loss = 0.018025529230811122, Recall = 0.9955555555555555, Aging Rate = 0.09057824504650222, precision = 1.0\n",
      "Model in epoch 40 is saved.\n",
      "\n",
      "Epoch 41: Train Loss = 0.020544087329749102, Recall = 0.9955555555555555, Aging Rate = 0.09057824504650222, Precision = 0, f1 = 0.0\n",
      "Epoch 42: Train Loss = 0.020452180868289607, Recall = 0.9955555555555555, Aging Rate = 0.09057824504650222, Precision = 0, f1 = 0.0\n",
      "Epoch 43: Train Loss = 0.020454772088821304, Recall = 0.9955555555555555, Aging Rate = 0.09057824504650222, Precision = 0, f1 = 0.0\n",
      "Epoch 44: Train Loss = 0.018425481871833963, Recall = 0.9955555555555555, Aging Rate = 0.09057824504650222, Precision = 0, f1 = 0.0\n",
      "Epoch 45: Train Loss = 0.018848444578067232, Recall = 0.9911111111111112, Aging Rate = 0.09057824504650222, Precision = 0.9955357142857143, f1 = 0.9933184855233853\n",
      "Test Loss = 0.017729481212942405, Recall = 1.0, Aging Rate = 0.09138697937727457, precision = 0.995575221238938\n",
      "\n",
      "Epoch 46: Train Loss = 0.01930962957884684, Recall = 0.9955555555555555, Aging Rate = 0.09138697937727457, Precision = 0.9911504424778761, f1 = 0.9933481152993349\n",
      "Epoch 47: Train Loss = 0.01759153286415407, Recall = 0.9955555555555555, Aging Rate = 0.0909826122118884, Precision = 0.9955555555555555, f1 = 0.9955555555555555\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 48: Train Loss = 0.016849427547620657, Recall = 0.9955555555555555, Aging Rate = 0.09057824504650222, Precision = 0, f1 = 0.0\n",
      "Epoch 49: Train Loss = 0.01789151541165649, Recall = 0.9955555555555555, Aging Rate = 0.09057824504650222, Precision = 0, f1 = 0.0\n",
      "Epoch 50: Train Loss = 0.0165126822069566, Recall = 0.9955555555555555, Aging Rate = 0.0909826122118884, Precision = 0.9955555555555555, f1 = 0.9955555555555555\n",
      "Test Loss = 0.014552479448663865, Recall = 1.0, Aging Rate = 0.0909826122118884, precision = 1.0\n",
      "Model in epoch 50 is saved.\n",
      "\n",
      "Epoch 51: Train Loss = 0.01678798807159012, Recall = 0.9955555555555555, Aging Rate = 0.0909826122118884, Precision = 0.9955555555555555, f1 = 0.9955555555555555\n",
      "Epoch 52: Train Loss = 0.015952608626907533, Recall = 0.9955555555555555, Aging Rate = 0.09057824504650222, Precision = 0, f1 = 0.0\n",
      "Epoch 53: Train Loss = 0.016330785414801284, Recall = 0.9955555555555555, Aging Rate = 0.09057824504650222, Precision = 0, f1 = 0.0\n",
      "Epoch 54: Train Loss = 0.016177953966187892, Recall = 0.9955555555555555, Aging Rate = 0.09057824504650222, Precision = 0, f1 = 0.0\n",
      "Epoch 55: Train Loss = 0.016066320344814755, Recall = 0.9955555555555555, Aging Rate = 0.0909826122118884, Precision = 0.9955555555555555, f1 = 0.9955555555555555\n",
      "Test Loss = 0.016397592814972876, Recall = 1.0, Aging Rate = 0.0909826122118884, precision = 1.0\n",
      "\n",
      "Epoch 56: Train Loss = 0.015955715283173036, Recall = 0.9955555555555555, Aging Rate = 0.09057824504650222, Precision = 0, f1 = 0.0\n",
      "Epoch 57: Train Loss = 0.016059924187451252, Recall = 1.0, Aging Rate = 0.0909826122118884, Precision = 0, f1 = 0.0\n",
      "Epoch 58: Train Loss = 0.015993922786900885, Recall = 0.9955555555555555, Aging Rate = 0.0909826122118884, Precision = 0.9955555555555555, f1 = 0.9955555555555555\n",
      "Epoch 59: Train Loss = 0.015711224930540925, Recall = 0.9955555555555555, Aging Rate = 0.09057824504650222, Precision = 0, f1 = 0.0\n",
      "Epoch 60: Train Loss = 0.01586798907871845, Recall = 0.9955555555555555, Aging Rate = 0.09057824504650222, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.01368921565692578, Recall = 1.0, Aging Rate = 0.09138697937727457, precision = 0.995575221238938\n",
      "\n",
      "Epoch 61: Train Loss = 0.015804228665487176, Recall = 0.9955555555555555, Aging Rate = 0.09057824504650222, Precision = 0, f1 = 0.0\n",
      "Epoch 62: Train Loss = 0.01577165553435153, Recall = 1.0, Aging Rate = 0.09138697937727457, Precision = 0.995575221238938, f1 = 0.9977827050997783\n",
      "Epoch 63: Train Loss = 0.014851316022568032, Recall = 0.9955555555555555, Aging Rate = 0.09057824504650222, Precision = 0, f1 = 0.0\n",
      "Epoch 64: Train Loss = 0.01541472933629096, Recall = 0.9955555555555555, Aging Rate = 0.0909826122118884, Precision = 0.9955555555555555, f1 = 0.9955555555555555\n",
      "Epoch 65: Train Loss = 0.014801134921390423, Recall = 1.0, Aging Rate = 0.0909826122118884, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.013535077381973994, Recall = 1.0, Aging Rate = 0.0909826122118884, precision = 1.0\n",
      "\n",
      "Epoch 66: Train Loss = 0.014754961220283186, Recall = 1.0, Aging Rate = 0.0909826122118884, Precision = 0, f1 = 0.0\n",
      "Epoch 67: Train Loss = 0.01477803538368508, Recall = 0.9955555555555555, Aging Rate = 0.0909826122118884, Precision = 0.9955555555555555, f1 = 0.9955555555555555\n",
      "Epoch 68: Train Loss = 0.014678727983607425, Recall = 1.0, Aging Rate = 0.0909826122118884, Precision = 0, f1 = 0.0\n",
      "Epoch 69: Train Loss = 0.015389244494680277, Recall = 0.9955555555555555, Aging Rate = 0.09057824504650222, Precision = 0, f1 = 0.0\n",
      "Epoch 70: Train Loss = 0.014347961409717159, Recall = 0.9955555555555555, Aging Rate = 0.09057824504650222, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.013360125455949598, Recall = 1.0, Aging Rate = 0.0909826122118884, precision = 1.0\n",
      "\n",
      "Epoch 71: Train Loss = 0.014611750071377973, Recall = 0.9955555555555555, Aging Rate = 0.09057824504650222, Precision = 0, f1 = 0.0\n",
      "Epoch 72: Train Loss = 0.0141940970656195, Recall = 1.0, Aging Rate = 0.09138697937727457, Precision = 0.995575221238938, f1 = 0.9977827050997783\n",
      "Epoch 73: Train Loss = 0.014368192203119969, Recall = 1.0, Aging Rate = 0.0909826122118884, Precision = 0, f1 = 0.0\n",
      "Epoch 74: Train Loss = 0.014419318431008455, Recall = 0.9955555555555555, Aging Rate = 0.09057824504650222, Precision = 0, f1 = 0.0\n",
      "Epoch 75: Train Loss = 0.013884467272286774, Recall = 0.9955555555555555, Aging Rate = 0.09057824504650222, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.012881276626674647, Recall = 1.0, Aging Rate = 0.09138697937727457, precision = 0.995575221238938\n",
      "\n",
      "Epoch 76: Train Loss = 0.01487957812646864, Recall = 0.9911111111111112, Aging Rate = 0.09017387788111605, Precision = 0, f1 = 0.0\n",
      "Epoch 77: Train Loss = 0.014666901274708134, Recall = 1.0, Aging Rate = 0.09138697937727457, Precision = 0.995575221238938, f1 = 0.9977827050997783\n",
      "Epoch 78: Train Loss = 0.014393716936067101, Recall = 1.0, Aging Rate = 0.0909826122118884, Precision = 0, f1 = 0.0\n",
      "Epoch 79: Train Loss = 0.014406633608154666, Recall = 0.9955555555555555, Aging Rate = 0.09057824504650222, Precision = 0, f1 = 0.0\n",
      "Epoch 80: Train Loss = 0.01412677690401836, Recall = 0.9955555555555555, Aging Rate = 0.09057824504650222, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.01198922739515975, Recall = 1.0, Aging Rate = 0.0909826122118884, precision = 1.0\n",
      "\n",
      "Epoch 81: Train Loss = 0.013751875579031767, Recall = 1.0, Aging Rate = 0.0909826122118884, Precision = 0, f1 = 0.0\n",
      "Epoch 82: Train Loss = 0.015645916646762965, Recall = 0.9955555555555555, Aging Rate = 0.09057824504650222, Precision = 0, f1 = 0.0\n",
      "Epoch 83: Train Loss = 0.013687240250474178, Recall = 1.0, Aging Rate = 0.0909826122118884, Precision = 0, f1 = 0.0\n",
      "Epoch 84: Train Loss = 0.014188078894542384, Recall = 0.9955555555555555, Aging Rate = 0.0909826122118884, Precision = 0.9955555555555555, f1 = 0.9955555555555555\n",
      "Epoch 85: Train Loss = 0.014847210507871552, Recall = 0.9955555555555555, Aging Rate = 0.09057824504650222, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.013647420908028039, Recall = 1.0, Aging Rate = 0.0909826122118884, precision = 1.0\n",
      "\n",
      "Epoch 86: Train Loss = 0.013552936868048418, Recall = 1.0, Aging Rate = 0.0909826122118884, Precision = 0, f1 = 0.0\n",
      "Epoch 87: Train Loss = 0.0133361627927349, Recall = 0.9955555555555555, Aging Rate = 0.09057824504650222, Precision = 0, f1 = 0.0\n",
      "Epoch 88: Train Loss = 0.014293800518153935, Recall = 1.0, Aging Rate = 0.0909826122118884, Precision = 0, f1 = 0.0\n",
      "Epoch 89: Train Loss = 0.015115834970488162, Recall = 0.9955555555555555, Aging Rate = 0.09057824504650222, Precision = 0, f1 = 0.0\n",
      "Epoch 90: Train Loss = 0.013028516257509403, Recall = 1.0, Aging Rate = 0.0909826122118884, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.01383929330218407, Recall = 1.0, Aging Rate = 0.0909826122118884, precision = 1.0\n",
      "\n",
      "Epoch 91: Train Loss = 0.013138846690369958, Recall = 1.0, Aging Rate = 0.0909826122118884, Precision = 0, f1 = 0.0\n",
      "Epoch 92: Train Loss = 0.014122194154478017, Recall = 0.9955555555555555, Aging Rate = 0.0909826122118884, Precision = 0.9955555555555555, f1 = 0.9955555555555555\n",
      "Epoch 93: Train Loss = 0.013788911540722539, Recall = 0.9955555555555555, Aging Rate = 0.09057824504650222, Precision = 0, f1 = 0.0\n",
      "Epoch 94: Train Loss = 0.0138156799915116, Recall = 1.0, Aging Rate = 0.0909826122118884, Precision = 0, f1 = 0.0\n",
      "Epoch 95: Train Loss = 0.014004691069491142, Recall = 0.9955555555555555, Aging Rate = 0.09057824504650222, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.012336393116754538, Recall = 1.0, Aging Rate = 0.0909826122118884, precision = 1.0\n",
      "\n",
      "Epoch 96: Train Loss = 0.013458242336927556, Recall = 1.0, Aging Rate = 0.0909826122118884, Precision = 0, f1 = 0.0\n",
      "Epoch 97: Train Loss = 0.013889173462646504, Recall = 0.9955555555555555, Aging Rate = 0.09057824504650222, Precision = 0, f1 = 0.0\n",
      "Epoch 98: Train Loss = 0.013019108085771077, Recall = 1.0, Aging Rate = 0.0909826122118884, Precision = 0, f1 = 0.0\n",
      "Epoch 99: Train Loss = 0.014201241743845397, Recall = 0.9955555555555555, Aging Rate = 0.0909826122118884, Precision = 0.9955555555555555, f1 = 0.9955555555555555\n",
      "Epoch 100: Train Loss = 0.01344250350963856, Recall = 1.0, Aging Rate = 0.0909826122118884, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.011578236802586938, Recall = 1.0, Aging Rate = 0.0909826122118884, precision = 1.0\n",
      "\n",
      "Training Finished at epoch 100.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec0083f7bac849ad8ad9bf24f6ba3b17",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss = 0.5000418435994595, Recall = 0.02666666666666667, Aging Rate = 0.021835826930853213, Precision = 0.1111111111111111, f1 = 0.04301075268817204\n",
      "Epoch 2: Train Loss = 0.3977820982925332, Recall = 0.057777777777777775, Aging Rate = 0.005256773150020219, Precision = 0, f1 = 0.0\n",
      "Epoch 3: Train Loss = 0.3434904954643612, Recall = 0.2577777777777778, Aging Rate = 0.028305701577031946, Precision = 0.8285714285714286, f1 = 0.39322033898305087\n",
      "Epoch 4: Train Loss = 0.2919821566022749, Recall = 0.4444444444444444, Aging Rate = 0.0509502628386575, Precision = 0.7936507936507936, f1 = 0.5698005698005697\n",
      "Epoch 5: Train Loss = 0.25346679900563107, Recall = 0.5288888888888889, Aging Rate = 0.059441973311767086, Precision = 0.8095238095238095, f1 = 0.6397849462365591\n",
      "Test Loss = 0.22672707928827404, Recall = 0.5422222222222223, Aging Rate = 0.0578245046502224, precision = 0.8531468531468531\n",
      "Model in epoch 5 is saved.\n",
      "\n",
      "Epoch 6: Train Loss = 0.2202320523391332, Recall = 0.6044444444444445, Aging Rate = 0.06550748079255965, Precision = 0.8395061728395061, f1 = 0.7028423772609819\n",
      "Epoch 7: Train Loss = 0.19203104223382653, Recall = 0.6533333333333333, Aging Rate = 0.07116862110796603, Precision = 0.8352272727272727, f1 = 0.7331670822942643\n",
      "Epoch 8: Train Loss = 0.1689516652376966, Recall = 0.7422222222222222, Aging Rate = 0.07804286291953093, Precision = 0.8652849740932642, f1 = 0.7990430622009569\n",
      "Epoch 9: Train Loss = 0.14735701399393233, Recall = 0.7822222222222223, Aging Rate = 0.08208653457339264, Precision = 0.8669950738916257, f1 = 0.8224299065420562\n",
      "Epoch 10: Train Loss = 0.1314132065545004, Recall = 0.8311111111111111, Aging Rate = 0.08087343307723413, Precision = 0.935, f1 = 0.88\n",
      "Test Loss = 0.1120097165297622, Recall = 0.8488888888888889, Aging Rate = 0.08208653457339264, precision = 0.9408866995073891\n",
      "Model in epoch 10 is saved.\n",
      "\n",
      "Epoch 11: Train Loss = 0.11194578652656903, Recall = 0.8755555555555555, Aging Rate = 0.08734330772341285, Precision = 0.9120370370370371, f1 = 0.8934240362811792\n",
      "Epoch 12: Train Loss = 0.10220335315637294, Recall = 0.8755555555555555, Aging Rate = 0.0841083704003235, Precision = 0.9471153846153846, f1 = 0.9099307159353348\n",
      "Epoch 13: Train Loss = 0.09064164570936827, Recall = 0.9155555555555556, Aging Rate = 0.0881520420541852, Precision = 0.944954128440367, f1 = 0.9300225733634311\n",
      "Epoch 14: Train Loss = 0.08109431644827067, Recall = 0.9155555555555556, Aging Rate = 0.08734330772341285, Precision = 0.9537037037037037, f1 = 0.9342403628117913\n",
      "Epoch 15: Train Loss = 0.07262928603880568, Recall = 0.9466666666666667, Aging Rate = 0.09057824504650222, Precision = 0.9508928571428571, f1 = 0.9487750556792873\n",
      "Test Loss = 0.06503796764998555, Recall = 0.96, Aging Rate = 0.09138697937727457, precision = 0.9557522123893806\n",
      "Model in epoch 15 is saved.\n",
      "\n",
      "Epoch 16: Train Loss = 0.06526195942102248, Recall = 0.9333333333333333, Aging Rate = 0.08734330772341285, Precision = 0.9722222222222222, f1 = 0.9523809523809524\n",
      "Epoch 17: Train Loss = 0.06274136052053803, Recall = 0.9511111111111111, Aging Rate = 0.09017387788111605, Precision = 0.9596412556053812, f1 = 0.9553571428571429\n",
      "Epoch 18: Train Loss = 0.054477879660805854, Recall = 0.9466666666666667, Aging Rate = 0.08774767488879903, Precision = 0.9815668202764977, f1 = 0.9638009049773756\n",
      "Epoch 19: Train Loss = 0.05097299957029548, Recall = 0.9555555555555556, Aging Rate = 0.09017387788111605, Precision = 0.9641255605381166, f1 = 0.9598214285714286\n",
      "Epoch 20: Train Loss = 0.04603019802015029, Recall = 0.9511111111111111, Aging Rate = 0.0881520420541852, Precision = 0.981651376146789, f1 = 0.9661399548532731\n",
      "Test Loss = 0.04428149972320374, Recall = 0.9911111111111112, Aging Rate = 0.09340881520420542, precision = 0.9653679653679653\n",
      "Model in epoch 20 is saved.\n",
      "\n",
      "Epoch 21: Train Loss = 0.043274191523394845, Recall = 0.9733333333333334, Aging Rate = 0.08976951071572989, Precision = 0.9864864864864865, f1 = 0.9798657718120806\n",
      "Epoch 22: Train Loss = 0.04012985853346504, Recall = 0.9733333333333334, Aging Rate = 0.09017387788111605, Precision = 0.9820627802690582, f1 = 0.9776785714285715\n",
      "Epoch 23: Train Loss = 0.03884653649505663, Recall = 0.9688888888888889, Aging Rate = 0.08976951071572989, Precision = 0.9819819819819819, f1 = 0.9753914988814317\n",
      "Epoch 24: Train Loss = 0.03580294587049487, Recall = 0.9866666666666667, Aging Rate = 0.09138697937727457, Precision = 0.9823008849557522, f1 = 0.9844789356984479\n",
      "Epoch 25: Train Loss = 0.03239700177837324, Recall = 0.9911111111111112, Aging Rate = 0.09138697937727457, Precision = 0.9867256637168141, f1 = 0.9889135254988914\n",
      "Test Loss = 0.03091037934578223, Recall = 0.9822222222222222, Aging Rate = 0.08936514355034371, precision = 1.0\n",
      "Model in epoch 25 is saved.\n",
      "\n",
      "Epoch 26: Train Loss = 0.031144293340723668, Recall = 0.9866666666666667, Aging Rate = 0.09017387788111605, Precision = 0.9955156950672646, f1 = 0.9910714285714286\n",
      "Epoch 27: Train Loss = 0.028572915906739584, Recall = 0.9955555555555555, Aging Rate = 0.0909826122118884, Precision = 0.9955555555555555, f1 = 0.9955555555555555\n",
      "Epoch 28: Train Loss = 0.02652754496332609, Recall = 0.9866666666666667, Aging Rate = 0.09057824504650222, Precision = 0.9910714285714286, f1 = 0.9888641425389756\n",
      "Epoch 29: Train Loss = 0.025579634449812646, Recall = 0.9955555555555555, Aging Rate = 0.0909826122118884, Precision = 0.9955555555555555, f1 = 0.9955555555555555\n",
      "Epoch 30: Train Loss = 0.027046736827654197, Recall = 0.9911111111111112, Aging Rate = 0.09138697937727457, Precision = 0.9867256637168141, f1 = 0.9889135254988914\n",
      "Test Loss = 0.02413790455947412, Recall = 1.0, Aging Rate = 0.09138697937727457, precision = 0.995575221238938\n",
      "Model in epoch 30 is saved.\n",
      "\n",
      "Epoch 31: Train Loss = 0.02378943172579852, Recall = 0.9955555555555555, Aging Rate = 0.0909826122118884, Precision = 0.9955555555555555, f1 = 0.9955555555555555\n",
      "Epoch 32: Train Loss = 0.02289030791907671, Recall = 1.0, Aging Rate = 0.09179134654266073, Precision = 0.9911894273127754, f1 = 0.9955752212389382\n",
      "Epoch 33: Train Loss = 0.02210533134661859, Recall = 1.0, Aging Rate = 0.09179134654266073, Precision = 0.9911894273127754, f1 = 0.9955752212389382\n",
      "Epoch 34: Train Loss = 0.02222304541848862, Recall = 1.0, Aging Rate = 0.09179134654266073, Precision = 0.9911894273127754, f1 = 0.9955752212389382\n",
      "Epoch 35: Train Loss = 0.020610694227430608, Recall = 0.9955555555555555, Aging Rate = 0.0909826122118884, Precision = 0.9955555555555555, f1 = 0.9955555555555555\n",
      "Test Loss = 0.017709543408047947, Recall = 1.0, Aging Rate = 0.0909826122118884, precision = 1.0\n",
      "Model in epoch 35 is saved.\n",
      "\n",
      "Epoch 36: Train Loss = 0.020695238488094014, Recall = 0.9911111111111112, Aging Rate = 0.09057824504650222, Precision = 0.9955357142857143, f1 = 0.9933184855233853\n",
      "Epoch 37: Train Loss = 0.020141745097648985, Recall = 1.0, Aging Rate = 0.09179134654266073, Precision = 0.9911894273127754, f1 = 0.9955752212389382\n",
      "Epoch 38: Train Loss = 0.019567448299361585, Recall = 0.9955555555555555, Aging Rate = 0.0909826122118884, Precision = 0.9955555555555555, f1 = 0.9955555555555555\n",
      "Epoch 39: Train Loss = 0.018463801745439434, Recall = 1.0, Aging Rate = 0.09138697937727457, Precision = 0.995575221238938, f1 = 0.9977827050997783\n",
      "Epoch 40: Train Loss = 0.018496159108613987, Recall = 1.0, Aging Rate = 0.09179134654266073, Precision = 0.9911894273127754, f1 = 0.9955752212389382\n",
      "Test Loss = 0.016452876327117227, Recall = 1.0, Aging Rate = 0.09138697937727457, precision = 0.995575221238938\n",
      "\n",
      "Epoch 41: Train Loss = 0.017984221140513994, Recall = 1.0, Aging Rate = 0.09138697937727457, Precision = 0.995575221238938, f1 = 0.9977827050997783\n",
      "Epoch 42: Train Loss = 0.016804926358750846, Recall = 1.0, Aging Rate = 0.0909826122118884, Precision = 0, f1 = 0.0\n",
      "Epoch 43: Train Loss = 0.016755641586822485, Recall = 1.0, Aging Rate = 0.0909826122118884, Precision = 0, f1 = 0.0\n",
      "Epoch 44: Train Loss = 0.01719894466467512, Recall = 1.0, Aging Rate = 0.0909826122118884, Precision = 0, f1 = 0.0\n",
      "Epoch 45: Train Loss = 0.01682247801654092, Recall = 1.0, Aging Rate = 0.0909826122118884, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.01444564952115497, Recall = 1.0, Aging Rate = 0.09138697937727457, precision = 0.995575221238938\n",
      "\n",
      "Epoch 46: Train Loss = 0.015536447359127355, Recall = 1.0, Aging Rate = 0.09138697937727457, Precision = 0.995575221238938, f1 = 0.9977827050997783\n",
      "Epoch 47: Train Loss = 0.015941985691131196, Recall = 1.0, Aging Rate = 0.09179134654266073, Precision = 0.9911894273127754, f1 = 0.9955752212389382\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 48: Train Loss = 0.01583169057763423, Recall = 1.0, Aging Rate = 0.09138697937727457, Precision = 0.995575221238938, f1 = 0.9977827050997783\n",
      "Epoch 49: Train Loss = 0.016261733062128476, Recall = 1.0, Aging Rate = 0.09138697937727457, Precision = 0.995575221238938, f1 = 0.9977827050997783\n",
      "Epoch 50: Train Loss = 0.015614711677917689, Recall = 1.0, Aging Rate = 0.0909826122118884, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.013118295070556701, Recall = 1.0, Aging Rate = 0.0909826122118884, precision = 1.0\n",
      "\n",
      "Epoch 51: Train Loss = 0.015222108595071717, Recall = 1.0, Aging Rate = 0.09179134654266073, Precision = 0.9911894273127754, f1 = 0.9955752212389382\n",
      "Epoch 52: Train Loss = 0.015383793699400319, Recall = 1.0, Aging Rate = 0.09138697937727457, Precision = 0.995575221238938, f1 = 0.9977827050997783\n",
      "Epoch 53: Train Loss = 0.015090230227215687, Recall = 1.0, Aging Rate = 0.09179134654266073, Precision = 0.9911894273127754, f1 = 0.9955752212389382\n",
      "Epoch 54: Train Loss = 0.014513109076711293, Recall = 1.0, Aging Rate = 0.0909826122118884, Precision = 0, f1 = 0.0\n",
      "Epoch 55: Train Loss = 0.015248969729027187, Recall = 1.0, Aging Rate = 0.09138697937727457, Precision = 0.995575221238938, f1 = 0.9977827050997783\n",
      "Test Loss = 0.012787756420872666, Recall = 1.0, Aging Rate = 0.09138697937727457, precision = 0.995575221238938\n",
      "\n",
      "Epoch 56: Train Loss = 0.014272996494482512, Recall = 1.0, Aging Rate = 0.09138697937727457, Precision = 0.995575221238938, f1 = 0.9977827050997783\n",
      "Epoch 57: Train Loss = 0.01423242646489809, Recall = 1.0, Aging Rate = 0.0909826122118884, Precision = 0, f1 = 0.0\n",
      "Epoch 58: Train Loss = 0.015224474087659551, Recall = 0.9955555555555555, Aging Rate = 0.0909826122118884, Precision = 0.9955555555555555, f1 = 0.9955555555555555\n",
      "Epoch 59: Train Loss = 0.0139971412169407, Recall = 1.0, Aging Rate = 0.09138697937727457, Precision = 0.995575221238938, f1 = 0.9977827050997783\n",
      "Epoch 60: Train Loss = 0.013649147866294542, Recall = 1.0, Aging Rate = 0.0909826122118884, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.012184233118482823, Recall = 1.0, Aging Rate = 0.0909826122118884, precision = 1.0\n",
      "\n",
      "Epoch 61: Train Loss = 0.013954020871299147, Recall = 1.0, Aging Rate = 0.09138697937727457, Precision = 0.995575221238938, f1 = 0.9977827050997783\n",
      "Epoch 62: Train Loss = 0.014299481844674876, Recall = 0.9955555555555555, Aging Rate = 0.0909826122118884, Precision = 0.9955555555555555, f1 = 0.9955555555555555\n",
      "Epoch 63: Train Loss = 0.013603451103273307, Recall = 1.0, Aging Rate = 0.0909826122118884, Precision = 0, f1 = 0.0\n",
      "Epoch 64: Train Loss = 0.013132060636580593, Recall = 1.0, Aging Rate = 0.0909826122118884, Precision = 0, f1 = 0.0\n",
      "Epoch 65: Train Loss = 0.014066515474030775, Recall = 1.0, Aging Rate = 0.09138697937727457, Precision = 0.995575221238938, f1 = 0.9977827050997783\n",
      "Test Loss = 0.01322545848404209, Recall = 1.0, Aging Rate = 0.0909826122118884, precision = 1.0\n",
      "\n",
      "Epoch 66: Train Loss = 0.014444813951571257, Recall = 1.0, Aging Rate = 0.09138697937727457, Precision = 0.995575221238938, f1 = 0.9977827050997783\n",
      "Epoch 67: Train Loss = 0.016960097769078725, Recall = 1.0, Aging Rate = 0.09138697937727457, Precision = 0.995575221238938, f1 = 0.9977827050997783\n",
      "Epoch 68: Train Loss = 0.015254609844147605, Recall = 0.9955555555555555, Aging Rate = 0.0909826122118884, Precision = 0.9955555555555555, f1 = 0.9955555555555555\n",
      "Epoch 69: Train Loss = 0.01610821775347898, Recall = 0.9955555555555555, Aging Rate = 0.09057824504650222, Precision = 0, f1 = 0.0\n",
      "Epoch 70: Train Loss = 0.012919630732174904, Recall = 1.0, Aging Rate = 0.0909826122118884, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.012406239499971782, Recall = 1.0, Aging Rate = 0.0909826122118884, precision = 1.0\n",
      "\n",
      "Epoch 71: Train Loss = 0.012260737604082379, Recall = 1.0, Aging Rate = 0.0909826122118884, Precision = 0, f1 = 0.0\n",
      "Epoch 72: Train Loss = 0.013014301808315205, Recall = 1.0, Aging Rate = 0.0909826122118884, Precision = 0, f1 = 0.0\n",
      "Epoch 73: Train Loss = 0.012668113450542712, Recall = 1.0, Aging Rate = 0.09138697937727457, Precision = 0.995575221238938, f1 = 0.9977827050997783\n",
      "Epoch 74: Train Loss = 0.012783536190386248, Recall = 1.0, Aging Rate = 0.0909826122118884, Precision = 0, f1 = 0.0\n",
      "Epoch 75: Train Loss = 0.01276805275035107, Recall = 1.0, Aging Rate = 0.0909826122118884, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.01189889320599053, Recall = 1.0, Aging Rate = 0.09138697937727457, precision = 0.995575221238938\n",
      "\n",
      "Epoch 76: Train Loss = 0.013805636564428585, Recall = 1.0, Aging Rate = 0.09138697937727457, Precision = 0.995575221238938, f1 = 0.9977827050997783\n",
      "Epoch 77: Train Loss = 0.012382572338857235, Recall = 1.0, Aging Rate = 0.0909826122118884, Precision = 0, f1 = 0.0\n",
      "Epoch 78: Train Loss = 0.01230881027549692, Recall = 1.0, Aging Rate = 0.0909826122118884, Precision = 0, f1 = 0.0\n",
      "Epoch 79: Train Loss = 0.012476649840715994, Recall = 1.0, Aging Rate = 0.09138697937727457, Precision = 0.995575221238938, f1 = 0.9977827050997783\n",
      "Epoch 80: Train Loss = 0.013099347174941914, Recall = 1.0, Aging Rate = 0.09138697937727457, Precision = 0.995575221238938, f1 = 0.9977827050997783\n",
      "Test Loss = 0.014601141396643322, Recall = 0.9911111111111112, Aging Rate = 0.09017387788111605, precision = 1.0\n",
      "\n",
      "Epoch 81: Train Loss = 0.013221342330783443, Recall = 1.0, Aging Rate = 0.0909826122118884, Precision = 0, f1 = 0.0\n",
      "Epoch 82: Train Loss = 0.013034672448671436, Recall = 1.0, Aging Rate = 0.09138697937727457, Precision = 0.995575221238938, f1 = 0.9977827050997783\n",
      "Epoch 83: Train Loss = 0.012813509865206381, Recall = 1.0, Aging Rate = 0.0909826122118884, Precision = 0, f1 = 0.0\n",
      "Epoch 84: Train Loss = 0.013273034109577711, Recall = 1.0, Aging Rate = 0.0909826122118884, Precision = 0, f1 = 0.0\n",
      "Epoch 85: Train Loss = 0.012199558286403796, Recall = 1.0, Aging Rate = 0.0909826122118884, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.01281731824958874, Recall = 1.0, Aging Rate = 0.0909826122118884, precision = 1.0\n",
      "\n",
      "Training Finished at epoch 85.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec2248867123417b878b77dd6ca1e481",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss = 0.5055210145738904, Recall = 0.05357142857142857, Aging Rate = 0.05784789644012945, Precision = 0.08391608391608392, f1 = 0.0653950953678474\n",
      "Epoch 2: Train Loss = 0.4033100062010743, Recall = 0.026785714285714284, Aging Rate = 0.0024271844660194173, Precision = 0, f1 = 0.0\n",
      "Epoch 3: Train Loss = 0.34434510562508625, Recall = 0.24107142857142858, Aging Rate = 0.027103559870550162, Precision = 0.8059701492537313, f1 = 0.3711340206185567\n",
      "Epoch 4: Train Loss = 0.2948480703684119, Recall = 0.4330357142857143, Aging Rate = 0.055825242718446605, Precision = 0.7028985507246377, f1 = 0.5359116022099447\n",
      "Epoch 5: Train Loss = 0.26367294653333895, Recall = 0.5401785714285714, Aging Rate = 0.061488673139158574, Precision = 0.7960526315789473, f1 = 0.6436170212765957\n",
      "Test Loss = 0.2359030338359882, Recall = 0.6607142857142857, Aging Rate = 0.08050161812297735, precision = 0.7437185929648241\n",
      "Model in epoch 5 is saved.\n",
      "\n",
      "Epoch 6: Train Loss = 0.23233968260604587, Recall = 0.6428571428571429, Aging Rate = 0.07483818770226537, Precision = 0.7783783783783784, f1 = 0.7041564792176039\n",
      "Epoch 7: Train Loss = 0.20440853963392067, Recall = 0.6741071428571429, Aging Rate = 0.0732200647249191, Precision = 0.8342541436464088, f1 = 0.745679012345679\n",
      "Epoch 8: Train Loss = 0.1848184403429911, Recall = 0.7232142857142857, Aging Rate = 0.07605177993527508, Precision = 0.8617021276595744, f1 = 0.7864077669902912\n",
      "Epoch 9: Train Loss = 0.1638496438445204, Recall = 0.7723214285714286, Aging Rate = 0.08050161812297735, Precision = 0.8693467336683417, f1 = 0.8179669030732861\n",
      "Epoch 10: Train Loss = 0.14560608785225734, Recall = 0.8125, Aging Rate = 0.08090614886731391, Precision = 0.91, f1 = 0.8584905660377358\n",
      "Test Loss = 0.1263288995883997, Recall = 0.8214285714285714, Aging Rate = 0.07766990291262135, precision = 0.9583333333333334\n",
      "Model in epoch 10 is saved.\n",
      "\n",
      "Epoch 11: Train Loss = 0.12778960626487978, Recall = 0.8392857142857143, Aging Rate = 0.0825242718446602, Precision = 0.9215686274509803, f1 = 0.8785046728971961\n",
      "Epoch 12: Train Loss = 0.11750038897672903, Recall = 0.8616071428571429, Aging Rate = 0.0877831715210356, Precision = 0.8894009216589862, f1 = 0.8752834467120182\n",
      "Epoch 13: Train Loss = 0.10831024662914014, Recall = 0.8705357142857143, Aging Rate = 0.0825242718446602, Precision = 0.9558823529411765, f1 = 0.9112149532710281\n",
      "Epoch 14: Train Loss = 0.09614538199428023, Recall = 0.8883928571428571, Aging Rate = 0.08454692556634304, Precision = 0.9521531100478469, f1 = 0.9191685912240184\n",
      "Epoch 15: Train Loss = 0.0876256738665806, Recall = 0.9151785714285714, Aging Rate = 0.08656957928802589, Precision = 0.9579439252336449, f1 = 0.9360730593607306\n",
      "Test Loss = 0.07427057358632196, Recall = 0.9285714285714286, Aging Rate = 0.08535598705501618, precision = 0.985781990521327\n",
      "Model in epoch 15 is saved.\n",
      "\n",
      "Epoch 16: Train Loss = 0.0787896395911098, Recall = 0.9330357142857143, Aging Rate = 0.0877831715210356, Precision = 0.9631336405529954, f1 = 0.9478458049886621\n",
      "Epoch 17: Train Loss = 0.07231242079468607, Recall = 0.9464285714285714, Aging Rate = 0.08818770226537216, Precision = 0.9724770642201835, f1 = 0.9592760180995474\n",
      "Epoch 18: Train Loss = 0.06533381394728488, Recall = 0.9508928571428571, Aging Rate = 0.0889967637540453, Precision = 0.9681818181818181, f1 = 0.9594594594594594\n",
      "Epoch 19: Train Loss = 0.06056289923374321, Recall = 0.9419642857142857, Aging Rate = 0.08656957928802589, Precision = 0.985981308411215, f1 = 0.9634703196347033\n",
      "Epoch 20: Train Loss = 0.05470650007761412, Recall = 0.9642857142857143, Aging Rate = 0.08818770226537216, Precision = 0.9908256880733946, f1 = 0.9773755656108598\n",
      "Test Loss = 0.04810995154661461, Recall = 0.9776785714285714, Aging Rate = 0.09021035598705501, precision = 0.9820627802690582\n",
      "Model in epoch 20 is saved.\n",
      "\n",
      "Epoch 21: Train Loss = 0.04978431590070231, Recall = 0.96875, Aging Rate = 0.0889967637540453, Precision = 0.9863636363636363, f1 = 0.9774774774774775\n",
      "Epoch 22: Train Loss = 0.04632220507680791, Recall = 0.96875, Aging Rate = 0.08859223300970874, Precision = 0.9908675799086758, f1 = 0.9796839729119637\n",
      "Epoch 23: Train Loss = 0.0441262216268041, Recall = 0.9776785714285714, Aging Rate = 0.08980582524271845, Precision = 0.9864864864864865, f1 = 0.9820627802690582\n",
      "Epoch 24: Train Loss = 0.03991785679844398, Recall = 0.96875, Aging Rate = 0.08859223300970874, Precision = 0.9908675799086758, f1 = 0.9796839729119637\n",
      "Epoch 25: Train Loss = 0.03866493893850559, Recall = 0.9821428571428571, Aging Rate = 0.08980582524271845, Precision = 0.990990990990991, f1 = 0.9865470852017937\n",
      "Test Loss = 0.03277980603133012, Recall = 0.9866071428571429, Aging Rate = 0.09021035598705501, precision = 0.9910313901345291\n",
      "Model in epoch 25 is saved.\n",
      "\n",
      "Epoch 26: Train Loss = 0.035065577513143466, Recall = 0.9866071428571429, Aging Rate = 0.09061488673139159, Precision = 0.9866071428571429, f1 = 0.9866071428571429\n",
      "Epoch 27: Train Loss = 0.03389155899376449, Recall = 0.9732142857142857, Aging Rate = 0.0889967637540453, Precision = 0.990909090909091, f1 = 0.9819819819819819\n",
      "Epoch 28: Train Loss = 0.031045241151035168, Recall = 0.9866071428571429, Aging Rate = 0.09021035598705501, Precision = 0.9910313901345291, f1 = 0.9888143176733781\n",
      "Epoch 29: Train Loss = 0.029346355101437245, Recall = 0.9866071428571429, Aging Rate = 0.08980582524271845, Precision = 0.9954954954954955, f1 = 0.9910313901345291\n",
      "Epoch 30: Train Loss = 0.029070237820250703, Recall = 0.9821428571428571, Aging Rate = 0.08980582524271845, Precision = 0.990990990990991, f1 = 0.9865470852017937\n",
      "Test Loss = 0.02516964417324676, Recall = 1.0, Aging Rate = 0.09142394822006472, precision = 0.9911504424778761\n",
      "Model in epoch 30 is saved.\n",
      "\n",
      "Epoch 31: Train Loss = 0.027342600934810238, Recall = 0.9866071428571429, Aging Rate = 0.09021035598705501, Precision = 0.9910313901345291, f1 = 0.9888143176733781\n",
      "Epoch 32: Train Loss = 0.025948018251547536, Recall = 0.9866071428571429, Aging Rate = 0.08980582524271845, Precision = 0.9954954954954955, f1 = 0.9910313901345291\n",
      "Epoch 33: Train Loss = 0.024158768578881586, Recall = 0.9910714285714286, Aging Rate = 0.09021035598705501, Precision = 0.9955156950672646, f1 = 0.9932885906040269\n",
      "Epoch 34: Train Loss = 0.022783638164627102, Recall = 1.0, Aging Rate = 0.09101941747572816, Precision = 0.9955555555555555, f1 = 0.9977728285077951\n",
      "Epoch 35: Train Loss = 0.02264640770828454, Recall = 0.9866071428571429, Aging Rate = 0.08980582524271845, Precision = 0.9954954954954955, f1 = 0.9910313901345291\n",
      "Test Loss = 0.01964957594063772, Recall = 1.0, Aging Rate = 0.09101941747572816, precision = 0.9955555555555555\n",
      "Model in epoch 35 is saved.\n",
      "\n",
      "Epoch 36: Train Loss = 0.02109185540837667, Recall = 1.0, Aging Rate = 0.09101941747572816, Precision = 0.9955555555555555, f1 = 0.9977728285077951\n",
      "Epoch 37: Train Loss = 0.021125125768066997, Recall = 0.9955357142857143, Aging Rate = 0.09061488673139159, Precision = 0.9955357142857143, f1 = 0.9955357142857143\n",
      "Epoch 38: Train Loss = 0.020301836247414252, Recall = 1.0, Aging Rate = 0.09101941747572816, Precision = 0.9955555555555555, f1 = 0.9977728285077951\n",
      "Epoch 39: Train Loss = 0.019253304378886053, Recall = 1.0, Aging Rate = 0.09101941747572816, Precision = 0.9955555555555555, f1 = 0.9977728285077951\n",
      "Epoch 40: Train Loss = 0.019425520533243718, Recall = 0.9910714285714286, Aging Rate = 0.09021035598705501, Precision = 0.9955156950672646, f1 = 0.9932885906040269\n",
      "Test Loss = 0.016723098974783444, Recall = 1.0, Aging Rate = 0.09101941747572816, precision = 0.9955555555555555\n",
      "\n",
      "Epoch 41: Train Loss = 0.018717711899899743, Recall = 0.9955357142857143, Aging Rate = 0.09061488673139159, Precision = 0.9955357142857143, f1 = 0.9955357142857143\n",
      "Epoch 42: Train Loss = 0.01835846504299, Recall = 1.0, Aging Rate = 0.09101941747572816, Precision = 0.9955555555555555, f1 = 0.9977728285077951\n",
      "Epoch 43: Train Loss = 0.01773552460638161, Recall = 1.0, Aging Rate = 0.09101941747572816, Precision = 0.9955555555555555, f1 = 0.9977728285077951\n",
      "Epoch 44: Train Loss = 0.017294763566317296, Recall = 0.9955357142857143, Aging Rate = 0.09061488673139159, Precision = 0.9955357142857143, f1 = 0.9955357142857143\n",
      "Epoch 45: Train Loss = 0.017204648124891964, Recall = 1.0, Aging Rate = 0.09101941747572816, Precision = 0.9955555555555555, f1 = 0.9977728285077951\n",
      "Test Loss = 0.015237764758283942, Recall = 1.0, Aging Rate = 0.09101941747572816, precision = 0.9955555555555555\n",
      "\n",
      "Epoch 46: Train Loss = 0.017264556813334088, Recall = 1.0, Aging Rate = 0.09101941747572816, Precision = 0.9955555555555555, f1 = 0.9977728285077951\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 47: Train Loss = 0.018076971504825217, Recall = 0.9955357142857143, Aging Rate = 0.09061488673139159, Precision = 0.9955357142857143, f1 = 0.9955357142857143\n",
      "Epoch 48: Train Loss = 0.016809653828348543, Recall = 1.0, Aging Rate = 0.09101941747572816, Precision = 0.9955555555555555, f1 = 0.9977728285077951\n",
      "Epoch 49: Train Loss = 0.015656484761139722, Recall = 1.0, Aging Rate = 0.09101941747572816, Precision = 0.9955555555555555, f1 = 0.9977728285077951\n",
      "Epoch 50: Train Loss = 0.016012222295880174, Recall = 1.0, Aging Rate = 0.09142394822006472, Precision = 0.9911504424778761, f1 = 0.9955555555555555\n",
      "Test Loss = 0.01375017565913185, Recall = 1.0, Aging Rate = 0.09101941747572816, precision = 0.9955555555555555\n",
      "\n",
      "Epoch 51: Train Loss = 0.015555504399041334, Recall = 1.0, Aging Rate = 0.09101941747572816, Precision = 0.9955555555555555, f1 = 0.9977728285077951\n",
      "Epoch 52: Train Loss = 0.016959684280057747, Recall = 1.0, Aging Rate = 0.09101941747572816, Precision = 0.9955555555555555, f1 = 0.9977728285077951\n",
      "Epoch 53: Train Loss = 0.01539720929887833, Recall = 1.0, Aging Rate = 0.09101941747572816, Precision = 0.9955555555555555, f1 = 0.9977728285077951\n",
      "Epoch 54: Train Loss = 0.014847553270329453, Recall = 1.0, Aging Rate = 0.09101941747572816, Precision = 0.9955555555555555, f1 = 0.9977728285077951\n",
      "Epoch 55: Train Loss = 0.015263871883545492, Recall = 1.0, Aging Rate = 0.09101941747572816, Precision = 0.9955555555555555, f1 = 0.9977728285077951\n",
      "Test Loss = 0.012864046397055334, Recall = 1.0, Aging Rate = 0.09101941747572816, precision = 0.9955555555555555\n",
      "\n",
      "Epoch 56: Train Loss = 0.014252544053706634, Recall = 1.0, Aging Rate = 0.09101941747572816, Precision = 0.9955555555555555, f1 = 0.9977728285077951\n",
      "Epoch 57: Train Loss = 0.014118410054666615, Recall = 1.0, Aging Rate = 0.09101941747572816, Precision = 0.9955555555555555, f1 = 0.9977728285077951\n",
      "Epoch 58: Train Loss = 0.013960797032250942, Recall = 1.0, Aging Rate = 0.09101941747572816, Precision = 0.9955555555555555, f1 = 0.9977728285077951\n",
      "Epoch 59: Train Loss = 0.01572878010010401, Recall = 0.9955357142857143, Aging Rate = 0.09061488673139159, Precision = 0.9955357142857143, f1 = 0.9955357142857143\n",
      "Epoch 60: Train Loss = 0.014425996102507206, Recall = 1.0, Aging Rate = 0.09101941747572816, Precision = 0.9955555555555555, f1 = 0.9977728285077951\n",
      "Test Loss = 0.012307018352051577, Recall = 1.0, Aging Rate = 0.09101941747572816, precision = 0.9955555555555555\n",
      "\n",
      "Epoch 61: Train Loss = 0.013778436178504263, Recall = 1.0, Aging Rate = 0.09061488673139159, Precision = 0, f1 = 0.0\n",
      "Epoch 62: Train Loss = 0.014303710245343474, Recall = 1.0, Aging Rate = 0.09101941747572816, Precision = 0.9955555555555555, f1 = 0.9977728285077951\n",
      "Epoch 63: Train Loss = 0.013773185612398733, Recall = 1.0, Aging Rate = 0.09142394822006472, Precision = 0.9911504424778761, f1 = 0.9955555555555555\n",
      "Epoch 64: Train Loss = 0.01418706232495003, Recall = 1.0, Aging Rate = 0.09061488673139159, Precision = 0, f1 = 0.0\n",
      "Epoch 65: Train Loss = 0.014099062224518519, Recall = 1.0, Aging Rate = 0.09101941747572816, Precision = 0.9955555555555555, f1 = 0.9977728285077951\n",
      "Test Loss = 0.011672477584488954, Recall = 1.0, Aging Rate = 0.09101941747572816, precision = 0.9955555555555555\n",
      "\n",
      "Epoch 66: Train Loss = 0.013079120106181329, Recall = 1.0, Aging Rate = 0.09101941747572816, Precision = 0.9955555555555555, f1 = 0.9977728285077951\n",
      "Epoch 67: Train Loss = 0.01354207143995272, Recall = 1.0, Aging Rate = 0.09101941747572816, Precision = 0.9955555555555555, f1 = 0.9977728285077951\n",
      "Epoch 68: Train Loss = 0.014100876118397056, Recall = 1.0, Aging Rate = 0.09101941747572816, Precision = 0.9955555555555555, f1 = 0.9977728285077951\n",
      "Epoch 69: Train Loss = 0.013779260441178642, Recall = 1.0, Aging Rate = 0.09101941747572816, Precision = 0.9955555555555555, f1 = 0.9977728285077951\n",
      "Epoch 70: Train Loss = 0.014433345826746576, Recall = 1.0, Aging Rate = 0.09061488673139159, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0134064936045931, Recall = 1.0, Aging Rate = 0.09061488673139159, precision = 1.0\n",
      "Model in epoch 70 is saved.\n",
      "\n",
      "Epoch 71: Train Loss = 0.01449533105861022, Recall = 0.9955357142857143, Aging Rate = 0.09021035598705501, Precision = 0, f1 = 0.0\n",
      "Epoch 72: Train Loss = 0.013360450282379454, Recall = 1.0, Aging Rate = 0.09061488673139159, Precision = 0, f1 = 0.0\n",
      "Epoch 73: Train Loss = 0.013369817536890892, Recall = 1.0, Aging Rate = 0.09061488673139159, Precision = 0, f1 = 0.0\n",
      "Epoch 74: Train Loss = 0.013526094167170787, Recall = 1.0, Aging Rate = 0.09142394822006472, Precision = 0.9911504424778761, f1 = 0.9955555555555555\n",
      "Epoch 75: Train Loss = 0.012930353765879248, Recall = 1.0, Aging Rate = 0.09101941747572816, Precision = 0.9955555555555555, f1 = 0.9977728285077951\n",
      "Test Loss = 0.011107419857086197, Recall = 1.0, Aging Rate = 0.09101941747572816, precision = 0.9955555555555555\n",
      "\n",
      "Epoch 76: Train Loss = 0.012443287017782337, Recall = 1.0, Aging Rate = 0.09101941747572816, Precision = 0.9955555555555555, f1 = 0.9977728285077951\n",
      "Epoch 77: Train Loss = 0.013658318891639076, Recall = 1.0, Aging Rate = 0.09101941747572816, Precision = 0.9955555555555555, f1 = 0.9977728285077951\n",
      "Epoch 78: Train Loss = 0.01303999167249137, Recall = 1.0, Aging Rate = 0.09101941747572816, Precision = 0.9955555555555555, f1 = 0.9977728285077951\n",
      "Epoch 79: Train Loss = 0.012504198464857336, Recall = 1.0, Aging Rate = 0.09061488673139159, Precision = 0, f1 = 0.0\n",
      "Epoch 80: Train Loss = 0.013121160858274592, Recall = 1.0, Aging Rate = 0.09101941747572816, Precision = 0.9955555555555555, f1 = 0.9977728285077951\n",
      "Test Loss = 0.0116573612802454, Recall = 1.0, Aging Rate = 0.09061488673139159, precision = 1.0\n",
      "\n",
      "Epoch 81: Train Loss = 0.013309617795074256, Recall = 0.9955357142857143, Aging Rate = 0.09061488673139159, Precision = 0.9955357142857143, f1 = 0.9955357142857143\n",
      "Epoch 82: Train Loss = 0.013726643068131216, Recall = 1.0, Aging Rate = 0.09061488673139159, Precision = 0, f1 = 0.0\n",
      "Epoch 83: Train Loss = 0.012997046638955286, Recall = 1.0, Aging Rate = 0.09101941747572816, Precision = 0.9955555555555555, f1 = 0.9977728285077951\n",
      "Epoch 84: Train Loss = 0.014132196421231653, Recall = 1.0, Aging Rate = 0.09061488673139159, Precision = 0, f1 = 0.0\n",
      "Epoch 85: Train Loss = 0.013240433157900872, Recall = 1.0, Aging Rate = 0.09101941747572816, Precision = 0.9955555555555555, f1 = 0.9977728285077951\n",
      "Test Loss = 0.010810880756011674, Recall = 1.0, Aging Rate = 0.09061488673139159, precision = 1.0\n",
      "\n",
      "Epoch 86: Train Loss = 0.013162148191102308, Recall = 1.0, Aging Rate = 0.09101941747572816, Precision = 0.9955555555555555, f1 = 0.9977728285077951\n",
      "Epoch 87: Train Loss = 0.012836047396980058, Recall = 1.0, Aging Rate = 0.09101941747572816, Precision = 0.9955555555555555, f1 = 0.9977728285077951\n",
      "Epoch 88: Train Loss = 0.012637239473971348, Recall = 1.0, Aging Rate = 0.09061488673139159, Precision = 0, f1 = 0.0\n",
      "Epoch 89: Train Loss = 0.01339885820920992, Recall = 1.0, Aging Rate = 0.09061488673139159, Precision = 0, f1 = 0.0\n",
      "Epoch 90: Train Loss = 0.013645003542219647, Recall = 1.0, Aging Rate = 0.09142394822006472, Precision = 0.9911504424778761, f1 = 0.9955555555555555\n",
      "Test Loss = 0.01088881215629165, Recall = 1.0, Aging Rate = 0.09101941747572816, precision = 0.9955555555555555\n",
      "\n",
      "Epoch 91: Train Loss = 0.0127107313499578, Recall = 1.0, Aging Rate = 0.09061488673139159, Precision = 0, f1 = 0.0\n",
      "Epoch 92: Train Loss = 0.012337765134991565, Recall = 1.0, Aging Rate = 0.09101941747572816, Precision = 0.9955555555555555, f1 = 0.9977728285077951\n",
      "Epoch 93: Train Loss = 0.014304559596461578, Recall = 1.0, Aging Rate = 0.09142394822006472, Precision = 0.9911504424778761, f1 = 0.9955555555555555\n",
      "Epoch 94: Train Loss = 0.012021207717822979, Recall = 1.0, Aging Rate = 0.09101941747572816, Precision = 0.9955555555555555, f1 = 0.9977728285077951\n",
      "Epoch 95: Train Loss = 0.012616747935998786, Recall = 1.0, Aging Rate = 0.09101941747572816, Precision = 0.9955555555555555, f1 = 0.9977728285077951\n",
      "Test Loss = 0.011517600397015002, Recall = 1.0, Aging Rate = 0.09061488673139159, precision = 1.0\n",
      "\n",
      "Epoch 96: Train Loss = 0.012821799141134838, Recall = 0.9955357142857143, Aging Rate = 0.09021035598705501, Precision = 0, f1 = 0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 97: Train Loss = 0.012261425090718616, Recall = 1.0, Aging Rate = 0.09101941747572816, Precision = 0.9955555555555555, f1 = 0.9977728285077951\n",
      "Epoch 98: Train Loss = 0.012335030290051016, Recall = 1.0, Aging Rate = 0.09101941747572816, Precision = 0.9955555555555555, f1 = 0.9977728285077951\n",
      "Epoch 99: Train Loss = 0.01220170985967596, Recall = 1.0, Aging Rate = 0.09101941747572816, Precision = 0.9955555555555555, f1 = 0.9977728285077951\n",
      "Epoch 100: Train Loss = 0.012790630939250818, Recall = 1.0, Aging Rate = 0.09101941747572816, Precision = 0.9955555555555555, f1 = 0.9977728285077951\n",
      "Test Loss = 0.011202560290151719, Recall = 1.0, Aging Rate = 0.09061488673139159, precision = 1.0\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6df84884eee849f69f2872c33498529c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "104ffb3d55464b1abdc3e515e4c96171",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fcf5ab7f6fc64f1ebac40b3f726901a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss = 0.02327182764537491, Recall = 0.0, Aging Rate = 0.0012817554923222846, Precision = 0.0, f1 = 0\n",
      "Epoch 2: Train Loss = 0.01910676519722648, Recall = 0.0, Aging Rate = 0.0, Precision = 0, f1 = 0\n",
      "Epoch 3: Train Loss = 0.01759255959720359, Recall = 0.0, Aging Rate = 0.0, Precision = 0, f1 = 0\n",
      "Epoch 4: Train Loss = 0.01815354815344488, Recall = 0.0, Aging Rate = 0.0, Precision = 0, f1 = 0\n",
      "Epoch 5: Train Loss = 0.016582189549400658, Recall = 0.015151515151515152, Aging Rate = 5.1270219692891383e-05, Precision = 0.5, f1 = 0.029411764705882356\n",
      "Test Loss = 0.014256838146004723, Recall = 0.0, Aging Rate = 0.0, precision = 0\n",
      "\n",
      "Epoch 6: Train Loss = 0.01574846932439806, Recall = 0.015151515151515152, Aging Rate = 0.00015381065907867414, Precision = 0.16666666666666666, f1 = 0.027777777777777776\n",
      "Epoch 7: Train Loss = 0.015198996290822681, Recall = 0.015151515151515152, Aging Rate = 0.00010254043938578277, Precision = 0.25, f1 = 0.028571428571428574\n",
      "Epoch 8: Train Loss = 0.015553101630090112, Recall = 0.06060606060606061, Aging Rate = 0.00015381065907867414, Precision = 0.6666666666666666, f1 = 0.1111111111111111\n",
      "Epoch 9: Train Loss = 0.01563633569354618, Recall = 0.030303030303030304, Aging Rate = 0.00015381065907867414, Precision = 0.3333333333333333, f1 = 0.05555555555555555\n",
      "Epoch 10: Train Loss = 0.013994881533577435, Recall = 0.045454545454545456, Aging Rate = 0.00015381065907867414, Precision = 0.5, f1 = 0.08333333333333334\n",
      "Test Loss = 0.012971916616316994, Recall = 0.0, Aging Rate = 0.0, precision = 0\n",
      "\n",
      "Epoch 11: Train Loss = 0.015163121707858603, Recall = 0.06060606060606061, Aging Rate = 0.00017944576892511984, Precision = 0.5714285714285714, f1 = 0.10958904109589043\n",
      "Epoch 12: Train Loss = 0.014353575069888708, Recall = 0.045454545454545456, Aging Rate = 0.0002563510984644569, Precision = 0.3, f1 = 0.07894736842105263\n",
      "Epoch 13: Train Loss = 0.014726916319947901, Recall = 0.07575757575757576, Aging Rate = 0.00017944576892511984, Precision = 0.7142857142857143, f1 = 0.136986301369863\n",
      "Epoch 14: Train Loss = 0.016295361315850666, Recall = 0.06060606060606061, Aging Rate = 0.00020508087877156553, Precision = 0.5, f1 = 0.10810810810810813\n",
      "Epoch 15: Train Loss = 0.014352927283420875, Recall = 0.07575757575757576, Aging Rate = 0.00017944576892511984, Precision = 0.7142857142857143, f1 = 0.136986301369863\n",
      "Test Loss = 0.013569335671712202, Recall = 0.07575757575757576, Aging Rate = 0.0002563510984644569, precision = 0.5\n",
      "Model in epoch 15 is saved.\n",
      "\n",
      "Epoch 16: Train Loss = 0.01486287645921668, Recall = 0.045454545454545456, Aging Rate = 0.00012817554923222845, Precision = 0.6, f1 = 0.08450704225352113\n",
      "Epoch 17: Train Loss = 0.013696841738682675, Recall = 0.06060606060606061, Aging Rate = 0.00017944576892511984, Precision = 0.5714285714285714, f1 = 0.10958904109589043\n",
      "Epoch 18: Train Loss = 0.014863193539571143, Recall = 0.045454545454545456, Aging Rate = 0.00020508087877156553, Precision = 0.375, f1 = 0.08108108108108107\n",
      "Epoch 19: Train Loss = 0.013950889321779519, Recall = 0.06060606060606061, Aging Rate = 0.00023071598861801123, Precision = 0.4444444444444444, f1 = 0.10666666666666667\n",
      "Epoch 20: Train Loss = 0.014225334825573123, Recall = 0.06060606060606061, Aging Rate = 0.00015381065907867414, Precision = 0.6666666666666666, f1 = 0.1111111111111111\n",
      "Test Loss = 0.011422286193326444, Recall = 0.12121212121212122, Aging Rate = 0.0003845266476966854, precision = 0.5333333333333333\n",
      "Model in epoch 20 is saved.\n",
      "\n",
      "Epoch 21: Train Loss = 0.013798488615677063, Recall = 0.045454545454545456, Aging Rate = 0.0002563510984644569, Precision = 0.3, f1 = 0.07894736842105263\n",
      "Epoch 22: Train Loss = 0.014440969908897998, Recall = 0.030303030303030304, Aging Rate = 0.0002563510984644569, Precision = 0.2, f1 = 0.052631578947368425\n",
      "Epoch 23: Train Loss = 0.014298622709699279, Recall = 0.06060606060606061, Aging Rate = 0.0003076213181573483, Precision = 0.3333333333333333, f1 = 0.10256410256410256\n",
      "Epoch 24: Train Loss = 0.013178683812104382, Recall = 0.015151515151515152, Aging Rate = 0.0003588915378502397, Precision = 0.07142857142857142, f1 = 0.025\n",
      "Epoch 25: Train Loss = 0.012950389625745101, Recall = 0.07575757575757576, Aging Rate = 0.0002819862083109026, Precision = 0.45454545454545453, f1 = 0.12987012987012989\n",
      "Test Loss = 0.010982476600681855, Recall = 0.09090909090909091, Aging Rate = 0.00017944576892511984, precision = 0.8571428571428571\n",
      "Model in epoch 25 is saved.\n",
      "\n",
      "Epoch 26: Train Loss = 0.012419252836005508, Recall = 0.06060606060606061, Aging Rate = 0.00023071598861801123, Precision = 0.4444444444444444, f1 = 0.10666666666666667\n",
      "Epoch 27: Train Loss = 0.013044609418855253, Recall = 0.10606060606060606, Aging Rate = 0.000333256428003794, Precision = 0.5384615384615384, f1 = 0.17721518987341772\n",
      "Epoch 28: Train Loss = 0.012199149634268424, Recall = 0.12121212121212122, Aging Rate = 0.0003588915378502397, Precision = 0.5714285714285714, f1 = 0.2\n",
      "Epoch 29: Train Loss = 0.012161983959253022, Recall = 0.10606060606060606, Aging Rate = 0.000333256428003794, Precision = 0.5384615384615384, f1 = 0.17721518987341772\n",
      "Epoch 30: Train Loss = 0.012910548745257842, Recall = 0.06060606060606061, Aging Rate = 0.0003076213181573483, Precision = 0.3333333333333333, f1 = 0.10256410256410256\n",
      "Test Loss = 0.020742979078176467, Recall = 0.09090909090909091, Aging Rate = 0.0002563510984644569, precision = 0.6\n",
      "\n",
      "Epoch 31: Train Loss = 0.014379543740643744, Recall = 0.10606060606060606, Aging Rate = 0.0005127021969289138, Precision = 0.35, f1 = 0.1627906976744186\n",
      "Epoch 32: Train Loss = 0.011353485044212715, Recall = 0.15151515151515152, Aging Rate = 0.0004870670870824681, Precision = 0.5263157894736842, f1 = 0.23529411764705885\n",
      "Epoch 33: Train Loss = 0.011486014151048647, Recall = 0.13636363636363635, Aging Rate = 0.0004870670870824681, Precision = 0.47368421052631576, f1 = 0.2117647058823529\n",
      "Epoch 34: Train Loss = 0.012856085371889871, Recall = 0.07575757575757576, Aging Rate = 0.0003845266476966854, Precision = 0.3333333333333333, f1 = 0.1234567901234568\n",
      "Epoch 35: Train Loss = 0.011486166090907768, Recall = 0.12121212121212122, Aging Rate = 0.00041016175754313107, Precision = 0.5, f1 = 0.1951219512195122\n",
      "Test Loss = 0.01164117739911303, Recall = 0.030303030303030304, Aging Rate = 0.00012817554923222845, precision = 0.4\n",
      "\n",
      "Epoch 36: Train Loss = 0.013554351957524108, Recall = 0.16666666666666666, Aging Rate = 0.0005639724166218052, Precision = 0.5, f1 = 0.25\n",
      "Epoch 37: Train Loss = 0.011742947411306657, Recall = 0.07575757575757576, Aging Rate = 0.0003076213181573483, Precision = 0.4166666666666667, f1 = 0.12820512820512822\n",
      "Epoch 38: Train Loss = 0.013166813805266969, Recall = 0.15151515151515152, Aging Rate = 0.0004357968673895768, Precision = 0.5882352941176471, f1 = 0.24096385542168675\n",
      "Epoch 39: Train Loss = 0.012682160383367598, Recall = 0.15151515151515152, Aging Rate = 0.0004357968673895768, Precision = 0.5882352941176471, f1 = 0.24096385542168675\n",
      "Epoch 40: Train Loss = 0.012293359628916877, Recall = 0.16666666666666666, Aging Rate = 0.0006152426363146966, Precision = 0.4583333333333333, f1 = 0.2444444444444444\n",
      "Test Loss = 0.01032492825911668, Recall = 0.12121212121212122, Aging Rate = 0.00023071598861801123, precision = 0.8888888888888888\n",
      "Model in epoch 40 is saved.\n",
      "\n",
      "Epoch 41: Train Loss = 0.011957013391977467, Recall = 0.07575757575757576, Aging Rate = 0.000333256428003794, Precision = 0.38461538461538464, f1 = 0.12658227848101267\n",
      "Epoch 42: Train Loss = 0.01239692910547489, Recall = 0.06060606060606061, Aging Rate = 0.0003076213181573483, Precision = 0.3333333333333333, f1 = 0.10256410256410256\n",
      "Epoch 43: Train Loss = 0.013098923090222706, Recall = 0.13636363636363635, Aging Rate = 0.0006152426363146966, Precision = 0.375, f1 = 0.19999999999999998\n",
      "Epoch 44: Train Loss = 0.014386573949648233, Recall = 0.09090909090909091, Aging Rate = 0.0004870670870824681, Precision = 0.3157894736842105, f1 = 0.1411764705882353\n",
      "Epoch 45: Train Loss = 0.011923584496329792, Recall = 0.13636363636363635, Aging Rate = 0.0005127021969289138, Precision = 0.45, f1 = 0.20930232558139533\n",
      "Test Loss = 0.011373959979888621, Recall = 0.36363636363636365, Aging Rate = 0.0013073906021687303, precision = 0.47058823529411764\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 46: Train Loss = 0.012944534860407784, Recall = 0.09090909090909091, Aging Rate = 0.00046143197723602246, Precision = 0.3333333333333333, f1 = 0.14285714285714288\n",
      "Epoch 47: Train Loss = 0.011592205259397944, Recall = 0.13636363636363635, Aging Rate = 0.0005127021969289138, Precision = 0.45, f1 = 0.20930232558139533\n",
      "Epoch 48: Train Loss = 0.012679694261294328, Recall = 0.09090909090909091, Aging Rate = 0.0003076213181573483, Precision = 0.5, f1 = 0.15384615384615385\n",
      "Epoch 49: Train Loss = 0.010962408232979557, Recall = 0.19696969696969696, Aging Rate = 0.0004357968673895768, Precision = 0.7647058823529411, f1 = 0.3132530120481927\n",
      "Epoch 50: Train Loss = 0.011382465128871712, Recall = 0.09090909090909091, Aging Rate = 0.00046143197723602246, Precision = 0.3333333333333333, f1 = 0.14285714285714288\n",
      "Test Loss = 0.011707211270756343, Recall = 0.21212121212121213, Aging Rate = 0.0010510395037042733, precision = 0.34146341463414637\n",
      "\n",
      "Epoch 51: Train Loss = 0.011892783747312952, Recall = 0.10606060606060606, Aging Rate = 0.0004357968673895768, Precision = 0.4117647058823529, f1 = 0.1686746987951807\n",
      "Epoch 52: Train Loss = 0.01268158256497519, Recall = 0.15151515151515152, Aging Rate = 0.000589607526468251, Precision = 0.43478260869565216, f1 = 0.2247191011235955\n",
      "Epoch 53: Train Loss = 0.012453577690739214, Recall = 0.10606060606060606, Aging Rate = 0.0005383373067753595, Precision = 0.3333333333333333, f1 = 0.16091954022988506\n",
      "Epoch 54: Train Loss = 0.012179785991487753, Recall = 0.13636363636363635, Aging Rate = 0.0005383373067753595, Precision = 0.42857142857142855, f1 = 0.20689655172413793\n",
      "Epoch 55: Train Loss = 0.011951930263631718, Recall = 0.12121212121212122, Aging Rate = 0.0005383373067753595, Precision = 0.38095238095238093, f1 = 0.1839080459770115\n",
      "Test Loss = 0.009577280386181563, Recall = 0.19696969696969696, Aging Rate = 0.0007177830757004794, precision = 0.4642857142857143\n",
      "\n",
      "Epoch 56: Train Loss = 0.012467454913746855, Recall = 0.15151515151515152, Aging Rate = 0.0006408777461611423, Precision = 0.4, f1 = 0.21978021978021978\n",
      "Epoch 57: Train Loss = 0.011315282564651785, Recall = 0.09090909090909091, Aging Rate = 0.00046143197723602246, Precision = 0.3333333333333333, f1 = 0.14285714285714288\n",
      "Epoch 58: Train Loss = 0.010953440392745768, Recall = 0.13636363636363635, Aging Rate = 0.0005127021969289138, Precision = 0.45, f1 = 0.20930232558139533\n",
      "Epoch 59: Train Loss = 0.010579594553151273, Recall = 0.15151515151515152, Aging Rate = 0.000589607526468251, Precision = 0.43478260869565216, f1 = 0.2247191011235955\n",
      "Epoch 60: Train Loss = 0.011500994847733365, Recall = 0.12121212121212122, Aging Rate = 0.0005639724166218052, Precision = 0.36363636363636365, f1 = 0.18181818181818182\n",
      "Test Loss = 0.0091177418979805, Recall = 0.18181818181818182, Aging Rate = 0.0003845266476966854, precision = 0.8\n",
      "\n",
      "Epoch 61: Train Loss = 0.011648923772488906, Recall = 0.19696969696969696, Aging Rate = 0.000589607526468251, Precision = 0.5652173913043478, f1 = 0.29213483146067415\n",
      "Epoch 62: Train Loss = 0.01163377630604182, Recall = 0.22727272727272727, Aging Rate = 0.000666512856007588, Precision = 0.5769230769230769, f1 = 0.3260869565217391\n",
      "Epoch 63: Train Loss = 0.011759918454876254, Recall = 0.12121212121212122, Aging Rate = 0.0005383373067753595, Precision = 0.38095238095238093, f1 = 0.1839080459770115\n",
      "Epoch 64: Train Loss = 0.010975317501025641, Recall = 0.16666666666666666, Aging Rate = 0.0006408777461611423, Precision = 0.44, f1 = 0.24175824175824176\n",
      "Epoch 65: Train Loss = 0.01150199806175899, Recall = 0.15151515151515152, Aging Rate = 0.0004357968673895768, Precision = 0.5882352941176471, f1 = 0.24096385542168675\n",
      "Test Loss = 0.00957819011655356, Recall = 0.3939393939393939, Aging Rate = 0.0009228639544720449, precision = 0.7222222222222222\n",
      "\n",
      "Epoch 66: Train Loss = 0.011233132607772874, Recall = 0.13636363636363635, Aging Rate = 0.0004870670870824681, Precision = 0.47368421052631576, f1 = 0.2117647058823529\n",
      "Epoch 67: Train Loss = 0.01066176186579347, Recall = 0.22727272727272727, Aging Rate = 0.000589607526468251, Precision = 0.6521739130434783, f1 = 0.33707865168539325\n",
      "Epoch 68: Train Loss = 0.01287582574311091, Recall = 0.07575757575757576, Aging Rate = 0.0005127021969289138, Precision = 0.25, f1 = 0.11627906976744187\n",
      "Epoch 69: Train Loss = 0.010671362104563377, Recall = 0.24242424242424243, Aging Rate = 0.0006408777461611423, Precision = 0.64, f1 = 0.3516483516483516\n",
      "Epoch 70: Train Loss = 0.011030751933641664, Recall = 0.22727272727272727, Aging Rate = 0.0006408777461611423, Precision = 0.6, f1 = 0.32967032967032966\n",
      "Test Loss = 0.013715732758824225, Recall = 0.0, Aging Rate = 0.0, precision = 0\n",
      "\n",
      "Epoch 71: Train Loss = 0.012776669811640988, Recall = 0.12121212121212122, Aging Rate = 0.00046143197723602246, Precision = 0.4444444444444444, f1 = 0.19047619047619047\n",
      "Epoch 72: Train Loss = 0.010580948703714647, Recall = 0.18181818181818182, Aging Rate = 0.0006152426363146966, Precision = 0.5, f1 = 0.26666666666666666\n",
      "Epoch 73: Train Loss = 0.011757089812813646, Recall = 0.19696969696969696, Aging Rate = 0.0005639724166218052, Precision = 0.5909090909090909, f1 = 0.29545454545454547\n",
      "Epoch 74: Train Loss = 0.010608176246578588, Recall = 0.19696969696969696, Aging Rate = 0.0005127021969289138, Precision = 0.65, f1 = 0.3023255813953488\n",
      "Epoch 75: Train Loss = 0.010762099276915432, Recall = 0.16666666666666666, Aging Rate = 0.0005639724166218052, Precision = 0.5, f1 = 0.25\n",
      "Test Loss = 0.008898267097225281, Recall = 0.19696969696969696, Aging Rate = 0.0003588915378502397, precision = 0.9285714285714286\n",
      "Model in epoch 75 is saved.\n",
      "\n",
      "Epoch 76: Train Loss = 0.010987873401217036, Recall = 0.13636363636363635, Aging Rate = 0.0004357968673895768, Precision = 0.5294117647058824, f1 = 0.21686746987951808\n",
      "Epoch 77: Train Loss = 0.013169465664638124, Recall = 0.12121212121212122, Aging Rate = 0.0005639724166218052, Precision = 0.36363636363636365, f1 = 0.18181818181818182\n",
      "Epoch 78: Train Loss = 0.011346370265564093, Recall = 0.12121212121212122, Aging Rate = 0.0006408777461611423, Precision = 0.32, f1 = 0.1758241758241758\n",
      "Epoch 79: Train Loss = 0.011976859832440121, Recall = 0.15151515151515152, Aging Rate = 0.0005383373067753595, Precision = 0.47619047619047616, f1 = 0.22988505747126436\n",
      "Epoch 80: Train Loss = 0.011248329343147359, Recall = 0.10606060606060606, Aging Rate = 0.000589607526468251, Precision = 0.30434782608695654, f1 = 0.15730337078651685\n",
      "Test Loss = 0.012453300478220629, Recall = 0.10606060606060606, Aging Rate = 0.00017944576892511984, precision = 1.0\n",
      "Model in epoch 80 is saved.\n",
      "\n",
      "Epoch 81: Train Loss = 0.011170987560645815, Recall = 0.18181818181818182, Aging Rate = 0.0005639724166218052, Precision = 0.5454545454545454, f1 = 0.2727272727272727\n",
      "Epoch 82: Train Loss = 0.01206970204436307, Recall = 0.10606060606060606, Aging Rate = 0.00046143197723602246, Precision = 0.3888888888888889, f1 = 0.16666666666666666\n",
      "Epoch 83: Train Loss = 0.011063664140508135, Recall = 0.15151515151515152, Aging Rate = 0.0005639724166218052, Precision = 0.45454545454545453, f1 = 0.22727272727272727\n",
      "Epoch 84: Train Loss = 0.0120838460791667, Recall = 0.19696969696969696, Aging Rate = 0.000666512856007588, Precision = 0.5, f1 = 0.2826086956521739\n",
      "Epoch 85: Train Loss = 0.011626680242207435, Recall = 0.13636363636363635, Aging Rate = 0.000666512856007588, Precision = 0.34615384615384615, f1 = 0.1956521739130435\n",
      "Test Loss = 0.008693631013592766, Recall = 0.24242424242424243, Aging Rate = 0.0005383373067753595, precision = 0.7619047619047619\n",
      "\n",
      "Epoch 86: Train Loss = 0.010901518362649807, Recall = 0.18181818181818182, Aging Rate = 0.000666512856007588, Precision = 0.46153846153846156, f1 = 0.26086956521739135\n",
      "Epoch 87: Train Loss = 0.011037816538079849, Recall = 0.19696969696969696, Aging Rate = 0.0006408777461611423, Precision = 0.52, f1 = 0.28571428571428564\n",
      "Epoch 88: Train Loss = 0.011210728353544417, Recall = 0.10606060606060606, Aging Rate = 0.0005639724166218052, Precision = 0.3181818181818182, f1 = 0.1590909090909091\n",
      "Epoch 89: Train Loss = 0.012052845849400003, Recall = 0.13636363636363635, Aging Rate = 0.0006408777461611423, Precision = 0.36, f1 = 0.1978021978021978\n",
      "Epoch 90: Train Loss = 0.01119178384488229, Recall = 0.16666666666666666, Aging Rate = 0.0006408777461611423, Precision = 0.44, f1 = 0.24175824175824176\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss = 0.00886985316676515, Recall = 0.19696969696969696, Aging Rate = 0.0005639724166218052, precision = 0.5909090909090909\n",
      "\n",
      "Epoch 91: Train Loss = 0.010758251323177474, Recall = 0.16666666666666666, Aging Rate = 0.0005639724166218052, Precision = 0.5, f1 = 0.25\n",
      "Epoch 92: Train Loss = 0.011427803598282878, Recall = 0.15151515151515152, Aging Rate = 0.0006152426363146966, Precision = 0.4166666666666667, f1 = 0.2222222222222222\n",
      "Epoch 93: Train Loss = 0.011528987764499433, Recall = 0.10606060606060606, Aging Rate = 0.00046143197723602246, Precision = 0.3888888888888889, f1 = 0.16666666666666666\n",
      "Epoch 94: Train Loss = 0.012361967552391752, Recall = 0.15151515151515152, Aging Rate = 0.0006408777461611423, Precision = 0.4, f1 = 0.21978021978021978\n",
      "Epoch 95: Train Loss = 0.011012763946322257, Recall = 0.16666666666666666, Aging Rate = 0.0005639724166218052, Precision = 0.5, f1 = 0.25\n",
      "Test Loss = 0.00967349473119948, Recall = 0.06060606060606061, Aging Rate = 0.00017944576892511984, precision = 0.5714285714285714\n",
      "\n",
      "Epoch 96: Train Loss = 0.010312731333135016, Recall = 0.21212121212121213, Aging Rate = 0.0007177830757004794, Precision = 0.5, f1 = 0.2978723404255319\n",
      "Epoch 97: Train Loss = 0.011610236796243992, Recall = 0.12121212121212122, Aging Rate = 0.0007177830757004794, Precision = 0.2857142857142857, f1 = 0.1702127659574468\n",
      "Epoch 98: Train Loss = 0.01210728157608059, Recall = 0.15151515151515152, Aging Rate = 0.0005639724166218052, Precision = 0.45454545454545453, f1 = 0.22727272727272727\n",
      "Epoch 99: Train Loss = 0.011010367588858563, Recall = 0.16666666666666666, Aging Rate = 0.000589607526468251, Precision = 0.4782608695652174, f1 = 0.24719101123595505\n",
      "Epoch 100: Train Loss = 0.010273319017781895, Recall = 0.21212121212121213, Aging Rate = 0.0006152426363146966, Precision = 0.5833333333333334, f1 = 0.3111111111111111\n",
      "Test Loss = 0.009473117510041465, Recall = 0.2878787878787879, Aging Rate = 0.0007177830757004794, precision = 0.6785714285714286\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f9df49f8e9814950aa468f13f0779022",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss = 0.036067032110158444, Recall = 0.009523809523809525, Aging Rate = 0.003361149745016226, Precision = 0.0049261083743842365, f1 = 0.006493506493506493\n",
      "Epoch 2: Train Loss = 0.017681016472271705, Recall = 0.0, Aging Rate = 0.0, Precision = 0, f1 = 0\n",
      "Epoch 3: Train Loss = 0.016892606762172895, Recall = 0.0, Aging Rate = 0.0, Precision = 0, f1 = 0\n",
      "Epoch 4: Train Loss = 0.01676347513128751, Recall = 0.0, Aging Rate = 0.0, Precision = 0, f1 = 0\n",
      "Epoch 5: Train Loss = 0.01621313365192974, Recall = 0.0, Aging Rate = 0.0, Precision = 0, f1 = 0\n",
      "Test Loss = 0.015110491984676493, Recall = 0.0, Aging Rate = 0.0, precision = 0\n",
      "\n",
      "Epoch 6: Train Loss = 0.01564827100660159, Recall = 0.0, Aging Rate = 0.0, Precision = 0, f1 = 0\n",
      "Epoch 7: Train Loss = 0.015284345944917406, Recall = 0.0, Aging Rate = 0.0, Precision = 0, f1 = 0\n",
      "Epoch 8: Train Loss = 0.014377867474722437, Recall = 0.0, Aging Rate = 0.0, Precision = 0, f1 = 0\n",
      "Epoch 9: Train Loss = 0.01323801838782128, Recall = 0.009523809523809525, Aging Rate = 3.3114775812967744e-05, Precision = 0.5, f1 = 0.01869158878504673\n",
      "Epoch 10: Train Loss = 0.012341996405892461, Recall = 0.01904761904761905, Aging Rate = 3.3114775812967744e-05, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.01106570835901432, Recall = 0.0, Aging Rate = 0.0, precision = 0\n",
      "\n",
      "Epoch 11: Train Loss = 0.011478596331853106, Recall = 0.01904761904761905, Aging Rate = 3.3114775812967744e-05, Precision = 0, f1 = 0.0\n",
      "Epoch 12: Train Loss = 0.010742527080301774, Recall = 0.09523809523809523, Aging Rate = 0.00019868865487780648, Precision = 0.8333333333333334, f1 = 0.17094017094017092\n",
      "Epoch 13: Train Loss = 0.010164290340002031, Recall = 0.11428571428571428, Aging Rate = 0.0002483608185972581, Precision = 0.8, f1 = 0.19999999999999998\n",
      "Epoch 14: Train Loss = 0.009499827431214719, Recall = 0.13333333333333333, Aging Rate = 0.00028147559441022585, Precision = 0.8235294117647058, f1 = 0.22950819672131148\n",
      "Epoch 15: Train Loss = 0.00909808542943115, Recall = 0.23809523809523808, Aging Rate = 0.0004967216371945162, Precision = 0.8333333333333334, f1 = 0.37037037037037035\n",
      "Test Loss = 0.007900855915466227, Recall = 0.18095238095238095, Aging Rate = 0.0003145903702231936, precision = 1.0\n",
      "Model in epoch 15 is saved.\n",
      "\n",
      "Epoch 16: Train Loss = 0.008683577224041563, Recall = 0.21904761904761905, Aging Rate = 0.0004304920855685807, Precision = 0.8846153846153846, f1 = 0.35114503816793885\n",
      "Epoch 17: Train Loss = 0.008179256544124054, Recall = 0.23809523809523808, Aging Rate = 0.0004636068613815484, Precision = 0.8928571428571429, f1 = 0.37593984962406013\n",
      "Epoch 18: Train Loss = 0.007804812526135316, Recall = 0.2, Aging Rate = 0.0003642625339426452, Precision = 0.9545454545454546, f1 = 0.33070866141732286\n",
      "Epoch 19: Train Loss = 0.007451246576828739, Recall = 0.2761904761904762, Aging Rate = 0.0005463938009139678, Precision = 0.8787878787878788, f1 = 0.4202898550724638\n",
      "Epoch 20: Train Loss = 0.007034697521425386, Recall = 0.2761904761904762, Aging Rate = 0.0005795085767269356, Precision = 0.8285714285714286, f1 = 0.4142857142857143\n",
      "Test Loss = 0.00629761330063549, Recall = 0.45714285714285713, Aging Rate = 0.0008775415590436453, precision = 0.9056603773584906\n",
      "Model in epoch 20 is saved.\n",
      "\n",
      "Epoch 21: Train Loss = 0.006735054600212043, Recall = 0.29523809523809524, Aging Rate = 0.0006126233525399033, Precision = 0.8378378378378378, f1 = 0.4366197183098592\n",
      "Epoch 22: Train Loss = 0.006504770630011888, Recall = 0.2761904761904762, Aging Rate = 0.0005298364130074839, Precision = 0.90625, f1 = 0.4233576642335767\n",
      "Epoch 23: Train Loss = 0.006214338551721757, Recall = 0.3523809523809524, Aging Rate = 0.0006457381283528711, Precision = 0.9487179487179487, f1 = 0.513888888888889\n",
      "Epoch 24: Train Loss = 0.005903334006395679, Recall = 0.3619047619047619, Aging Rate = 0.0006954102920723226, Precision = 0.9047619047619048, f1 = 0.5170068027210885\n",
      "Epoch 25: Train Loss = 0.005770254705000218, Recall = 0.3904761904761905, Aging Rate = 0.0007450824557917743, Precision = 0.9111111111111111, f1 = 0.5466666666666666\n",
      "Test Loss = 0.004731070711261697, Recall = 0.5428571428571428, Aging Rate = 0.0010100006622955162, precision = 0.9344262295081968\n",
      "Model in epoch 25 is saved.\n",
      "\n",
      "Epoch 26: Train Loss = 0.005361688745032478, Recall = 0.34285714285714286, Aging Rate = 0.0006457381283528711, Precision = 0.9230769230769231, f1 = 0.5000000000000001\n",
      "Epoch 27: Train Loss = 0.005091267765946809, Recall = 0.3904761904761905, Aging Rate = 0.0007285250678852904, Precision = 0.9318181818181818, f1 = 0.5503355704697986\n",
      "Epoch 28: Train Loss = 0.00495734098951667, Recall = 0.44761904761904764, Aging Rate = 0.0008444267832306775, Precision = 0.9215686274509803, f1 = 0.6025641025641025\n",
      "Epoch 29: Train Loss = 0.004887973502251126, Recall = 0.41904761904761906, Aging Rate = 0.0007947546195112259, Precision = 0.9166666666666666, f1 = 0.5751633986928104\n",
      "Epoch 30: Train Loss = 0.004588656908751627, Recall = 0.44761904761904764, Aging Rate = 0.0008278693953241937, Precision = 0.94, f1 = 0.6064516129032259\n",
      "Test Loss = 0.003898039708221074, Recall = 0.6, Aging Rate = 0.001175574541360355, precision = 0.8873239436619719\n",
      "\n",
      "Epoch 31: Train Loss = 0.004495059466610522, Recall = 0.4666666666666667, Aging Rate = 0.0008609841711371614, Precision = 0.9423076923076923, f1 = 0.624203821656051\n",
      "Epoch 32: Train Loss = 0.004380898666706883, Recall = 0.44761904761904764, Aging Rate = 0.0008609841711371614, Precision = 0.9038461538461539, f1 = 0.5987261146496815\n",
      "Epoch 33: Train Loss = 0.004122978475315102, Recall = 0.5047619047619047, Aging Rate = 0.0010100006622955162, Precision = 0.8688524590163934, f1 = 0.6385542168674699\n",
      "Epoch 34: Train Loss = 0.004481096530155797, Recall = 0.5238095238095238, Aging Rate = 0.0009437711106695807, Precision = 0.9649122807017544, f1 = 0.6790123456790124\n",
      "Epoch 35: Train Loss = 0.0038827026213773524, Recall = 0.5238095238095238, Aging Rate = 0.0009603284985760646, Precision = 0.9482758620689655, f1 = 0.6748466257668712\n",
      "Test Loss = 0.0033571744942503317, Recall = 0.5428571428571428, Aging Rate = 0.0009437711106695807, precision = 1.0\n",
      "Model in epoch 35 is saved.\n",
      "\n",
      "Epoch 36: Train Loss = 0.003963306115309169, Recall = 0.49523809523809526, Aging Rate = 0.0008940989469501292, Precision = 0.9629629629629629, f1 = 0.6540880503144655\n",
      "Epoch 37: Train Loss = 0.003839904609292275, Recall = 0.5428571428571428, Aging Rate = 0.0010100006622955162, Precision = 0.9344262295081968, f1 = 0.6867469879518071\n",
      "Epoch 38: Train Loss = 0.003791796123130055, Recall = 0.5238095238095238, Aging Rate = 0.0009768858864825484, Precision = 0.9322033898305084, f1 = 0.6707317073170731\n",
      "Epoch 39: Train Loss = 0.003742410005248836, Recall = 0.5238095238095238, Aging Rate = 0.0009768858864825484, Precision = 0.9322033898305084, f1 = 0.6707317073170731\n",
      "Epoch 40: Train Loss = 0.0035231036184766042, Recall = 0.5333333333333333, Aging Rate = 0.0009934432743890324, Precision = 0.9333333333333333, f1 = 0.6787878787878787\n",
      "Test Loss = 0.0030800605248709812, Recall = 0.7047619047619048, Aging Rate = 0.0012749188687992583, precision = 0.961038961038961\n",
      "Model in epoch 40 is saved.\n",
      "\n",
      "Epoch 41: Train Loss = 0.0035128575750990603, Recall = 0.5714285714285714, Aging Rate = 0.0010762302139214518, Precision = 0.9230769230769231, f1 = 0.7058823529411765\n",
      "Epoch 42: Train Loss = 0.0034985357815739875, Recall = 0.580952380952381, Aging Rate = 0.0010762302139214518, Precision = 0.9384615384615385, f1 = 0.7176470588235295\n",
      "Epoch 43: Train Loss = 0.003315069551508459, Recall = 0.6, Aging Rate = 0.0011259023776409034, Precision = 0.9264705882352942, f1 = 0.7283236994219654\n",
      "Epoch 44: Train Loss = 0.0036087840725871323, Recall = 0.580952380952381, Aging Rate = 0.0010596728260149678, Precision = 0.953125, f1 = 0.7218934911242604\n",
      "Epoch 45: Train Loss = 0.003302866299062103, Recall = 0.5904761904761905, Aging Rate = 0.0010762302139214518, Precision = 0.9538461538461539, f1 = 0.7294117647058824\n",
      "Test Loss = 0.00279693947083539, Recall = 0.7714285714285715, Aging Rate = 0.0013908205841446453, precision = 0.9642857142857143\n",
      "Model in epoch 45 is saved.\n",
      "\n",
      "Epoch 46: Train Loss = 0.003214449834687065, Recall = 0.5904761904761905, Aging Rate = 0.0010927876018279356, Precision = 0.9393939393939394, f1 = 0.7251461988304092\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 47: Train Loss = 0.0030621048745112017, Recall = 0.6476190476190476, Aging Rate = 0.0011590171534538712, Precision = 0.9714285714285714, f1 = 0.7771428571428572\n",
      "Epoch 48: Train Loss = 0.003187423957851892, Recall = 0.638095238095238, Aging Rate = 0.001192131929266839, Precision = 0.9305555555555556, f1 = 0.7570621468926554\n",
      "Epoch 49: Train Loss = 0.00314151548199974, Recall = 0.638095238095238, Aging Rate = 0.0011259023776409034, Precision = 0.9852941176470589, f1 = 0.7745664739884393\n",
      "Epoch 50: Train Loss = 0.00300916587179523, Recall = 0.638095238095238, Aging Rate = 0.0011424597655473872, Precision = 0.9710144927536232, f1 = 0.7701149425287357\n",
      "Test Loss = 0.002647340742380986, Recall = 0.580952380952381, Aging Rate = 0.0010596728260149678, precision = 0.953125\n",
      "\n",
      "Epoch 51: Train Loss = 0.00309531274834526, Recall = 0.6285714285714286, Aging Rate = 0.0011424597655473872, Precision = 0.9565217391304348, f1 = 0.7586206896551724\n",
      "Epoch 52: Train Loss = 0.002876863536689454, Recall = 0.6857142857142857, Aging Rate = 0.0012583614808927743, Precision = 0.9473684210526315, f1 = 0.7955801104972374\n",
      "Epoch 53: Train Loss = 0.0030264131298171014, Recall = 0.6571428571428571, Aging Rate = 0.0011590171534538712, Precision = 0.9857142857142858, f1 = 0.7885714285714286\n",
      "Epoch 54: Train Loss = 0.002959592281147755, Recall = 0.6761904761904762, Aging Rate = 0.0012418040929862905, Precision = 0.9466666666666667, f1 = 0.7888888888888891\n",
      "Epoch 55: Train Loss = 0.0028552012831465257, Recall = 0.6285714285714286, Aging Rate = 0.0011093449897344196, Precision = 0.9850746268656716, f1 = 0.7674418604651162\n",
      "Test Loss = 0.0024510880438794102, Recall = 0.7428571428571429, Aging Rate = 0.0012914762567057421, precision = 1.0\n",
      "Model in epoch 55 is saved.\n",
      "\n",
      "Epoch 56: Train Loss = 0.002891342277925801, Recall = 0.7047619047619048, Aging Rate = 0.001308033644612226, Precision = 0.9367088607594937, f1 = 0.8043478260869565\n",
      "Epoch 57: Train Loss = 0.0029230411027993185, Recall = 0.638095238095238, Aging Rate = 0.001175574541360355, Precision = 0.9436619718309859, f1 = 0.7613636363636362\n",
      "Epoch 58: Train Loss = 0.002857502359338438, Recall = 0.6095238095238096, Aging Rate = 0.0010927876018279356, Precision = 0.9696969696969697, f1 = 0.7485380116959065\n",
      "Epoch 59: Train Loss = 0.002862348456756198, Recall = 0.6857142857142857, Aging Rate = 0.0012418040929862905, Precision = 0.96, f1 = 0.7999999999999999\n",
      "Epoch 60: Train Loss = 0.0027808654303165636, Recall = 0.6666666666666666, Aging Rate = 0.001175574541360355, Precision = 0.9859154929577465, f1 = 0.7954545454545454\n",
      "Test Loss = 0.002585345662765933, Recall = 0.9142857142857143, Aging Rate = 0.0016060666269289356, precision = 0.9896907216494846\n",
      "Model in epoch 60 is saved.\n",
      "\n",
      "Epoch 61: Train Loss = 0.00267105705227637, Recall = 0.6761904761904762, Aging Rate = 0.001192131929266839, Precision = 0.9861111111111112, f1 = 0.8022598870056498\n",
      "Epoch 62: Train Loss = 0.002801551258547397, Recall = 0.6571428571428571, Aging Rate = 0.001175574541360355, Precision = 0.971830985915493, f1 = 0.7840909090909092\n",
      "Epoch 63: Train Loss = 0.0028752235163500696, Recall = 0.6285714285714286, Aging Rate = 0.0011259023776409034, Precision = 0.9705882352941176, f1 = 0.7630057803468207\n",
      "Epoch 64: Train Loss = 0.0028182768516246946, Recall = 0.6666666666666666, Aging Rate = 0.0012086893171733227, Precision = 0.958904109589041, f1 = 0.7865168539325843\n",
      "Epoch 65: Train Loss = 0.0027334045520017248, Recall = 0.6952380952380952, Aging Rate = 0.0012418040929862905, Precision = 0.9733333333333334, f1 = 0.8111111111111111\n",
      "Test Loss = 0.0021635925214269123, Recall = 0.7714285714285715, Aging Rate = 0.0013411484204251937, precision = 1.0\n",
      "\n",
      "Epoch 66: Train Loss = 0.0025916635798588386, Recall = 0.6952380952380952, Aging Rate = 0.0012418040929862905, Precision = 0.9733333333333334, f1 = 0.8111111111111111\n",
      "Epoch 67: Train Loss = 0.0027149852397337225, Recall = 0.6857142857142857, Aging Rate = 0.0012252467050798065, Precision = 0.972972972972973, f1 = 0.8044692737430168\n",
      "Epoch 68: Train Loss = 0.002631847001003857, Recall = 0.7238095238095238, Aging Rate = 0.001308033644612226, Precision = 0.9620253164556962, f1 = 0.8260869565217392\n",
      "Epoch 69: Train Loss = 0.0028510205740967316, Recall = 0.6476190476190476, Aging Rate = 0.001175574541360355, Precision = 0.9577464788732394, f1 = 0.7727272727272727\n",
      "Epoch 70: Train Loss = 0.002715926791946222, Recall = 0.6857142857142857, Aging Rate = 0.0012252467050798065, Precision = 0.972972972972973, f1 = 0.8044692737430168\n",
      "Test Loss = 0.002277511721927724, Recall = 0.6761904761904762, Aging Rate = 0.001192131929266839, precision = 0.9861111111111112\n",
      "\n",
      "Epoch 71: Train Loss = 0.0026053400162635927, Recall = 0.7238095238095238, Aging Rate = 0.00132459103251871, Precision = 0.95, f1 = 0.8216216216216217\n",
      "Epoch 72: Train Loss = 0.002685483525432996, Recall = 0.6761904761904762, Aging Rate = 0.0012086893171733227, Precision = 0.9726027397260274, f1 = 0.797752808988764\n",
      "Epoch 73: Train Loss = 0.0026872276923955852, Recall = 0.7142857142857143, Aging Rate = 0.0012914762567057421, Precision = 0.9615384615384616, f1 = 0.819672131147541\n",
      "Epoch 74: Train Loss = 0.0026987477752276725, Recall = 0.7238095238095238, Aging Rate = 0.0012749188687992583, Precision = 0.987012987012987, f1 = 0.8351648351648352\n",
      "Epoch 75: Train Loss = 0.002580918903965814, Recall = 0.7047619047619048, Aging Rate = 0.0012252467050798065, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.002240886970425891, Recall = 0.7523809523809524, Aging Rate = 0.0013411484204251937, precision = 0.9753086419753086\n",
      "\n",
      "Epoch 76: Train Loss = 0.0026617340113862737, Recall = 0.7619047619047619, Aging Rate = 0.0013577058083316777, Precision = 0.975609756097561, f1 = 0.855614973262032\n",
      "Epoch 77: Train Loss = 0.0025513722759044513, Recall = 0.7047619047619048, Aging Rate = 0.0012252467050798065, Precision = 0, f1 = 0.0\n",
      "Epoch 78: Train Loss = 0.0026887672487322517, Recall = 0.7428571428571429, Aging Rate = 0.0013411484204251937, Precision = 0.9629629629629629, f1 = 0.8387096774193549\n",
      "Epoch 79: Train Loss = 0.0026150977988622843, Recall = 0.7047619047619048, Aging Rate = 0.0012418040929862905, Precision = 0.9866666666666667, f1 = 0.8222222222222222\n",
      "Epoch 80: Train Loss = 0.0025672341056714697, Recall = 0.6761904761904762, Aging Rate = 0.0012086893171733227, Precision = 0.9726027397260274, f1 = 0.797752808988764\n",
      "Test Loss = 0.0022146425835454986, Recall = 0.8476190476190476, Aging Rate = 0.0015067222994900324, precision = 0.978021978021978\n",
      "\n",
      "Epoch 81: Train Loss = 0.002582712863011168, Recall = 0.6857142857142857, Aging Rate = 0.0012086893171733227, Precision = 0.9863013698630136, f1 = 0.8089887640449438\n",
      "Epoch 82: Train Loss = 0.002469017636007782, Recall = 0.7428571428571429, Aging Rate = 0.00132459103251871, Precision = 0.975, f1 = 0.8432432432432432\n",
      "Epoch 83: Train Loss = 0.0026603594564927765, Recall = 0.6761904761904762, Aging Rate = 0.0012086893171733227, Precision = 0.9726027397260274, f1 = 0.797752808988764\n",
      "Epoch 84: Train Loss = 0.00246022723824916, Recall = 0.7333333333333333, Aging Rate = 0.001308033644612226, Precision = 0.9746835443037974, f1 = 0.8369565217391304\n",
      "Epoch 85: Train Loss = 0.0025374341033210916, Recall = 0.7714285714285715, Aging Rate = 0.0013577058083316777, Precision = 0.9878048780487805, f1 = 0.8663101604278075\n",
      "Test Loss = 0.0022778362718618686, Recall = 0.8666666666666667, Aging Rate = 0.001556394463209484, precision = 0.9680851063829787\n",
      "\n",
      "Epoch 86: Train Loss = 0.002574493447745198, Recall = 0.6857142857142857, Aging Rate = 0.0012583614808927743, Precision = 0.9473684210526315, f1 = 0.7955801104972374\n",
      "Epoch 87: Train Loss = 0.0024965306253707416, Recall = 0.7238095238095238, Aging Rate = 0.0012914762567057421, Precision = 0.9743589743589743, f1 = 0.8306010928961748\n",
      "Epoch 88: Train Loss = 0.0026145185656389807, Recall = 0.7047619047619048, Aging Rate = 0.0012583614808927743, Precision = 0.9736842105263158, f1 = 0.8176795580110497\n",
      "Epoch 89: Train Loss = 0.002473054517072832, Recall = 0.7047619047619048, Aging Rate = 0.0012418040929862905, Precision = 0.9866666666666667, f1 = 0.8222222222222222\n",
      "Epoch 90: Train Loss = 0.0026097318225256363, Recall = 0.7238095238095238, Aging Rate = 0.0012749188687992583, Precision = 0.987012987012987, f1 = 0.8351648351648352\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss = 0.0025573428246582985, Recall = 0.5428571428571428, Aging Rate = 0.0009437711106695807, precision = 1.0\n",
      "\n",
      "Epoch 91: Train Loss = 0.002545780674254522, Recall = 0.7142857142857143, Aging Rate = 0.0012749188687992583, Precision = 0.974025974025974, f1 = 0.8241758241758242\n",
      "Epoch 92: Train Loss = 0.0025333085340715944, Recall = 0.6952380952380952, Aging Rate = 0.0012583614808927743, Precision = 0.9605263157894737, f1 = 0.8066298342541437\n",
      "Epoch 93: Train Loss = 0.002481871794327, Recall = 0.7238095238095238, Aging Rate = 0.0012583614808927743, Precision = 0, f1 = 0.0\n",
      "Epoch 94: Train Loss = 0.0025996204503752358, Recall = 0.6952380952380952, Aging Rate = 0.0012252467050798065, Precision = 0.9864864864864865, f1 = 0.8156424581005586\n",
      "Epoch 95: Train Loss = 0.0023459608522681426, Recall = 0.7333333333333333, Aging Rate = 0.001308033644612226, Precision = 0.9746835443037974, f1 = 0.8369565217391304\n",
      "Test Loss = 0.00288933688693656, Recall = 0.9142857142857143, Aging Rate = 0.0016226240148354196, precision = 0.9795918367346939\n",
      "\n",
      "Epoch 96: Train Loss = 0.0025378761071148414, Recall = 0.7142857142857143, Aging Rate = 0.0012749188687992583, Precision = 0.974025974025974, f1 = 0.8241758241758242\n",
      "Epoch 97: Train Loss = 0.002503399519938528, Recall = 0.7142857142857143, Aging Rate = 0.0012418040929862905, Precision = 0, f1 = 0.0\n",
      "Epoch 98: Train Loss = 0.002510391295526268, Recall = 0.7428571428571429, Aging Rate = 0.0013411484204251937, Precision = 0.9629629629629629, f1 = 0.8387096774193549\n",
      "Epoch 99: Train Loss = 0.0025916662263420487, Recall = 0.638095238095238, Aging Rate = 0.0011424597655473872, Precision = 0.9710144927536232, f1 = 0.7701149425287357\n",
      "Epoch 100: Train Loss = 0.0024213127346690683, Recall = 0.7333333333333333, Aging Rate = 0.0012749188687992583, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0019798333016082647, Recall = 0.8095238095238095, Aging Rate = 0.0014404927478640969, precision = 0.9770114942528736\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac09c3b504654386811de671e6c336bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss = 0.042786802704241234, Recall = 0.0, Aging Rate = 0.0005195434944495436, Precision = 0.0, f1 = 0\n",
      "Epoch 2: Train Loss = 0.027863819386378847, Recall = 0.0, Aging Rate = 0.0, Precision = 0, f1 = 0\n",
      "Epoch 3: Train Loss = 0.02709524604485228, Recall = 0.0, Aging Rate = 0.0, Precision = 0, f1 = 0\n",
      "Epoch 4: Train Loss = 0.026811893417784647, Recall = 0.0, Aging Rate = 0.0, Precision = 0, f1 = 0\n",
      "Epoch 5: Train Loss = 0.02607405632582043, Recall = 0.0, Aging Rate = 0.0, Precision = 0, f1 = 0\n",
      "Test Loss = 0.024227682530633593, Recall = 0.0, Aging Rate = 0.0, precision = 0\n",
      "\n",
      "Epoch 6: Train Loss = 0.0249919639918149, Recall = 0.0, Aging Rate = 0.0, Precision = 0, f1 = 0\n",
      "Epoch 7: Train Loss = 0.023782316970525158, Recall = 0.0, Aging Rate = 1.7318116481651455e-05, Precision = 0.0, f1 = 0\n",
      "Epoch 8: Train Loss = 0.022630109869478134, Recall = 0.01818181818181818, Aging Rate = 5.195434944495437e-05, Precision = 0.6666666666666666, f1 = 0.035398230088495575\n",
      "Epoch 9: Train Loss = 0.020952594230463136, Recall = 0.03636363636363636, Aging Rate = 8.659058240825728e-05, Precision = 0.8, f1 = 0.06956521739130435\n",
      "Epoch 10: Train Loss = 0.019658044513331155, Recall = 0.07272727272727272, Aging Rate = 0.00013854493185321164, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.01797860760765028, Recall = 0.12727272727272726, Aging Rate = 0.00045027102852293784, precision = 0.5384615384615384\n",
      "Model in epoch 10 is saved.\n",
      "\n",
      "Epoch 11: Train Loss = 0.017990144254952514, Recall = 0.07272727272727272, Aging Rate = 0.00020781739777981747, Precision = 0.6666666666666666, f1 = 0.13114754098360654\n",
      "Epoch 12: Train Loss = 0.01674124045919138, Recall = 0.09090909090909091, Aging Rate = 0.00020781739777981747, Precision = 0.8333333333333334, f1 = 0.16393442622950818\n",
      "Epoch 13: Train Loss = 0.015079183019925243, Recall = 0.10909090909090909, Aging Rate = 0.0002597717472247718, Precision = 0.8, f1 = 0.192\n",
      "Epoch 14: Train Loss = 0.014300665211245971, Recall = 0.12727272727272726, Aging Rate = 0.0002770898637064233, Precision = 0.875, f1 = 0.22222222222222224\n",
      "Epoch 15: Train Loss = 0.013546405488963324, Recall = 0.14545454545454545, Aging Rate = 0.00043295291204128636, Precision = 0.64, f1 = 0.23703703703703705\n",
      "Test Loss = 0.011137499691255407, Recall = 0.2, Aging Rate = 0.00041563479555963495, precision = 0.9166666666666666\n",
      "Model in epoch 15 is saved.\n",
      "\n",
      "Epoch 16: Train Loss = 0.012495083294308002, Recall = 0.12727272727272726, Aging Rate = 0.00041563479555963495, Precision = 0.5833333333333334, f1 = 0.20895522388059698\n",
      "Epoch 17: Train Loss = 0.011787478390461525, Recall = 0.2727272727272727, Aging Rate = 0.0006927246592660582, Precision = 0.75, f1 = 0.39999999999999997\n",
      "Epoch 18: Train Loss = 0.0107657562624157, Recall = 0.2636363636363636, Aging Rate = 0.0005888159603761495, Precision = 0.8529411764705882, f1 = 0.40277777777777773\n",
      "Epoch 19: Train Loss = 0.010198196521664963, Recall = 0.32727272727272727, Aging Rate = 0.0008312695911192699, Precision = 0.75, f1 = 0.4556962025316456\n",
      "Epoch 20: Train Loss = 0.009274252844108075, Recall = 0.37272727272727274, Aging Rate = 0.0008832239405642242, Precision = 0.803921568627451, f1 = 0.5093167701863354\n",
      "Test Loss = 0.007882824544243818, Recall = 0.43636363636363634, Aging Rate = 0.0009005420570458757, precision = 0.9230769230769231\n",
      "Model in epoch 20 is saved.\n",
      "\n",
      "Epoch 21: Train Loss = 0.008853322939263454, Recall = 0.38181818181818183, Aging Rate = 0.0009524964064908301, Precision = 0.7636363636363637, f1 = 0.509090909090909\n",
      "Epoch 22: Train Loss = 0.0082761907781724, Recall = 0.43636363636363634, Aging Rate = 0.0009698145229724816, Precision = 0.8571428571428571, f1 = 0.5783132530120482\n",
      "Epoch 23: Train Loss = 0.00791111152766887, Recall = 0.4727272727272727, Aging Rate = 0.001021768872417436, Precision = 0.8813559322033898, f1 = 0.6153846153846153\n",
      "Epoch 24: Train Loss = 0.007394805613146753, Recall = 0.42727272727272725, Aging Rate = 0.0010044507559357845, Precision = 0.8103448275862069, f1 = 0.5595238095238095\n",
      "Epoch 25: Train Loss = 0.006664077957941757, Recall = 0.5272727272727272, Aging Rate = 0.0011949500372339505, Precision = 0.8405797101449275, f1 = 0.6480446927374302\n",
      "Test Loss = 0.00546881272376735, Recall = 0.6363636363636364, Aging Rate = 0.0012815406196422076, precision = 0.9459459459459459\n",
      "Model in epoch 25 is saved.\n",
      "\n",
      "Epoch 26: Train Loss = 0.006427460866184059, Recall = 0.5454545454545454, Aging Rate = 0.0011603138042706475, Precision = 0.8955223880597015, f1 = 0.6779661016949153\n",
      "Epoch 27: Train Loss = 0.006171548950432886, Recall = 0.5636363636363636, Aging Rate = 0.001212268153715602, Precision = 0.8857142857142857, f1 = 0.6888888888888889\n",
      "Epoch 28: Train Loss = 0.005692426010629065, Recall = 0.6181818181818182, Aging Rate = 0.001333494969087162, Precision = 0.8831168831168831, f1 = 0.7272727272727273\n",
      "Epoch 29: Train Loss = 0.005543679949620189, Recall = 0.6272727272727273, Aging Rate = 0.0013161768526055106, Precision = 0.9078947368421053, f1 = 0.7419354838709677\n",
      "Epoch 30: Train Loss = 0.005095658070120909, Recall = 0.6636363636363637, Aging Rate = 0.0013854493185321165, Precision = 0.9125, f1 = 0.768421052631579\n",
      "Test Loss = 0.004764083512712712, Recall = 0.7727272727272727, Aging Rate = 0.0017144935316834942, precision = 0.8585858585858586\n",
      "\n",
      "Epoch 31: Train Loss = 0.005079786219522375, Recall = 0.6454545454545455, Aging Rate = 0.0014200855514954194, Precision = 0.8658536585365854, f1 = 0.7395833333333335\n",
      "Epoch 32: Train Loss = 0.004823779510538485, Recall = 0.6909090909090909, Aging Rate = 0.0013854493185321165, Precision = 0.95, f1 = 0.8\n",
      "Epoch 33: Train Loss = 0.004559040826155681, Recall = 0.6818181818181818, Aging Rate = 0.0014547217844587223, Precision = 0.8928571428571429, f1 = 0.7731958762886597\n",
      "Epoch 34: Train Loss = 0.0042812207368513435, Recall = 0.7181818181818181, Aging Rate = 0.0014374036679770709, Precision = 0.9518072289156626, f1 = 0.8186528497409326\n",
      "Epoch 35: Train Loss = 0.004218486169629643, Recall = 0.7727272727272727, Aging Rate = 0.001558630483348631, Precision = 0.9444444444444444, f1 = 0.85\n",
      "Test Loss = 0.003726409791222066, Recall = 0.6454545454545455, Aging Rate = 0.001246904386678905, precision = 0.9861111111111112\n",
      "Model in epoch 35 is saved.\n",
      "\n",
      "Epoch 36: Train Loss = 0.004204920617632701, Recall = 0.7272727272727273, Aging Rate = 0.0014893580174220253, Precision = 0.9302325581395349, f1 = 0.8163265306122448\n",
      "Epoch 37: Train Loss = 0.004092250608017431, Recall = 0.7090909090909091, Aging Rate = 0.001523994250385328, Precision = 0.8863636363636364, f1 = 0.7878787878787878\n",
      "Epoch 38: Train Loss = 0.0036732731267898238, Recall = 0.8090909090909091, Aging Rate = 0.001593266716311934, Precision = 0.967391304347826, f1 = 0.8811881188118811\n",
      "Epoch 39: Train Loss = 0.0035908022713716575, Recall = 0.7363636363636363, Aging Rate = 0.0014720399009403738, Precision = 0.9529411764705882, f1 = 0.8307692307692307\n",
      "Epoch 40: Train Loss = 0.0035176129751671157, Recall = 0.8090909090909091, Aging Rate = 0.0016625391822385398, Precision = 0.9270833333333334, f1 = 0.8640776699029126\n",
      "Test Loss = 0.002890124767335347, Recall = 0.8090909090909091, Aging Rate = 0.0015759485998302824, precision = 0.978021978021978\n",
      "Model in epoch 40 is saved.\n",
      "\n",
      "Epoch 41: Train Loss = 0.0034865896197839863, Recall = 0.8090909090909091, Aging Rate = 0.0016452210657568883, Precision = 0.9368421052631579, f1 = 0.8682926829268293\n",
      "Epoch 42: Train Loss = 0.00332111969790984, Recall = 0.8272727272727273, Aging Rate = 0.0016452210657568883, Precision = 0.9578947368421052, f1 = 0.8878048780487805\n",
      "Epoch 43: Train Loss = 0.0033868080357833917, Recall = 0.8090909090909091, Aging Rate = 0.001593266716311934, Precision = 0.967391304347826, f1 = 0.8811881188118811\n",
      "Epoch 44: Train Loss = 0.0032432246807445053, Recall = 0.7636363636363637, Aging Rate = 0.001523994250385328, Precision = 0.9545454545454546, f1 = 0.8484848484848485\n",
      "Epoch 45: Train Loss = 0.0032404120603085327, Recall = 0.8090909090909091, Aging Rate = 0.0016279029492752368, Precision = 0.9468085106382979, f1 = 0.8725490196078431\n",
      "Test Loss = 0.002642786151756314, Recall = 0.7818181818181819, Aging Rate = 0.0014893580174220253, precision = 1.0\n",
      "Model in epoch 45 is saved.\n",
      "\n",
      "Epoch 46: Train Loss = 0.003248533583429636, Recall = 0.7909090909090909, Aging Rate = 0.0015759485998302824, Precision = 0.9560439560439561, f1 = 0.8656716417910447\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 47: Train Loss = 0.0030544824265110776, Recall = 0.8545454545454545, Aging Rate = 0.0016971754152018427, Precision = 0.9591836734693877, f1 = 0.9038461538461537\n",
      "Epoch 48: Train Loss = 0.0028877798387936396, Recall = 0.8454545454545455, Aging Rate = 0.0017144935316834942, Precision = 0.9393939393939394, f1 = 0.8899521531100478\n",
      "Epoch 49: Train Loss = 0.0031226752024687988, Recall = 0.8, Aging Rate = 0.0015413123668669795, Precision = 0.9887640449438202, f1 = 0.8844221105527638\n",
      "Epoch 50: Train Loss = 0.003024208071797762, Recall = 0.8272727272727273, Aging Rate = 0.001593266716311934, Precision = 0.9891304347826086, f1 = 0.9009900990099009\n",
      "Test Loss = 0.003412742761039688, Recall = 0.9818181818181818, Aging Rate = 0.001974265278908266, precision = 0.9473684210526315\n",
      "Model in epoch 50 is saved.\n",
      "\n",
      "Epoch 51: Train Loss = 0.0030993624288116707, Recall = 0.8363636363636363, Aging Rate = 0.0016971754152018427, Precision = 0.9387755102040817, f1 = 0.8846153846153846\n",
      "Epoch 52: Train Loss = 0.002844204696230244, Recall = 0.8818181818181818, Aging Rate = 0.0017318116481651455, Precision = 0.97, f1 = 0.9238095238095237\n",
      "Epoch 53: Train Loss = 0.0028594613294379567, Recall = 0.8454545454545455, Aging Rate = 0.0016452210657568883, Precision = 0.9789473684210527, f1 = 0.9073170731707316\n",
      "Epoch 54: Train Loss = 0.002768718561747106, Recall = 0.8909090909090909, Aging Rate = 0.0016971754152018427, Precision = 0, f1 = 0.0\n",
      "Epoch 55: Train Loss = 0.0027069581411650542, Recall = 0.8909090909090909, Aging Rate = 0.001749129764646797, Precision = 0.9702970297029703, f1 = 0.9289099526066351\n",
      "Test Loss = 0.0021943696704089925, Recall = 0.9272727272727272, Aging Rate = 0.0017837659976100999, precision = 0.9902912621359223\n",
      "Model in epoch 55 is saved.\n",
      "\n",
      "Epoch 56: Train Loss = 0.002878379276913396, Recall = 0.8727272727272727, Aging Rate = 0.0017318116481651455, Precision = 0.96, f1 = 0.9142857142857144\n",
      "Epoch 57: Train Loss = 0.002754354879715281, Recall = 0.8545454545454545, Aging Rate = 0.0016452210657568883, Precision = 0.9894736842105263, f1 = 0.9170731707317074\n",
      "Epoch 58: Train Loss = 0.0028057463292143307, Recall = 0.8272727272727273, Aging Rate = 0.001593266716311934, Precision = 0.9891304347826086, f1 = 0.9009900990099009\n",
      "Epoch 59: Train Loss = 0.0025598547189980433, Recall = 0.8909090909090909, Aging Rate = 0.001749129764646797, Precision = 0.9702970297029703, f1 = 0.9289099526066351\n",
      "Epoch 60: Train Loss = 0.0027311891604046056, Recall = 0.8909090909090909, Aging Rate = 0.0017318116481651455, Precision = 0.98, f1 = 0.9333333333333333\n",
      "Test Loss = 0.002278587937138126, Recall = 0.9181818181818182, Aging Rate = 0.0017664478811284484, precision = 0.9901960784313726\n",
      "\n",
      "Epoch 61: Train Loss = 0.0026077935264110187, Recall = 0.8636363636363636, Aging Rate = 0.0016798572987201913, Precision = 0.979381443298969, f1 = 0.9178743961352657\n",
      "Epoch 62: Train Loss = 0.002617815479964227, Recall = 0.9, Aging Rate = 0.001749129764646797, Precision = 0.9801980198019802, f1 = 0.9383886255924171\n",
      "Epoch 63: Train Loss = 0.0026356467251436814, Recall = 0.8727272727272727, Aging Rate = 0.0016971754152018427, Precision = 0.9795918367346939, f1 = 0.923076923076923\n",
      "Epoch 64: Train Loss = 0.0028024023999887694, Recall = 0.8727272727272727, Aging Rate = 0.0017144935316834942, Precision = 0.9696969696969697, f1 = 0.9186602870813397\n",
      "Epoch 65: Train Loss = 0.0025088705599936372, Recall = 0.9090909090909091, Aging Rate = 0.0017664478811284484, Precision = 0.9803921568627451, f1 = 0.9433962264150944\n",
      "Test Loss = 0.002476756646676684, Recall = 0.8363636363636363, Aging Rate = 0.001593266716311934, precision = 1.0\n",
      "\n",
      "Epoch 66: Train Loss = 0.002633159351108133, Recall = 0.8909090909090909, Aging Rate = 0.0017318116481651455, Precision = 0.98, f1 = 0.9333333333333333\n",
      "Epoch 67: Train Loss = 0.0025648499807540658, Recall = 0.8818181818181818, Aging Rate = 0.0017144935316834942, Precision = 0.9797979797979798, f1 = 0.9282296650717704\n",
      "Epoch 68: Train Loss = 0.0025559719548713467, Recall = 0.9090909090909091, Aging Rate = 0.001749129764646797, Precision = 0.9900990099009901, f1 = 0.947867298578199\n",
      "Epoch 69: Train Loss = 0.002471924084600395, Recall = 0.9181818181818182, Aging Rate = 0.0017837659976100999, Precision = 0.9805825242718447, f1 = 0.9483568075117371\n",
      "Epoch 70: Train Loss = 0.002499832569622205, Recall = 0.8727272727272727, Aging Rate = 0.0016798572987201913, Precision = 0.9896907216494846, f1 = 0.9275362318840581\n",
      "Test Loss = 0.0020911143350600147, Recall = 0.9636363636363636, Aging Rate = 0.0019049928129816602, precision = 0.9636363636363636\n",
      "\n",
      "Epoch 71: Train Loss = 0.0025458282153131484, Recall = 0.8818181818181818, Aging Rate = 0.0016971754152018427, Precision = 0.9897959183673469, f1 = 0.9326923076923076\n",
      "Epoch 72: Train Loss = 0.0024563948516870154, Recall = 0.9090909090909091, Aging Rate = 0.0017837659976100999, Precision = 0.970873786407767, f1 = 0.9389671361502346\n",
      "Epoch 73: Train Loss = 0.002506815255691278, Recall = 0.9090909090909091, Aging Rate = 0.0017837659976100999, Precision = 0.970873786407767, f1 = 0.9389671361502346\n",
      "Epoch 74: Train Loss = 0.0025379382704592106, Recall = 0.8636363636363636, Aging Rate = 0.0016798572987201913, Precision = 0.979381443298969, f1 = 0.9178743961352657\n",
      "Epoch 75: Train Loss = 0.0026574147419057923, Recall = 0.8727272727272727, Aging Rate = 0.0017318116481651455, Precision = 0.96, f1 = 0.9142857142857144\n",
      "Test Loss = 0.0019744483230780237, Recall = 0.9727272727272728, Aging Rate = 0.0018530384635367058, precision = 1.0\n",
      "Model in epoch 75 is saved.\n",
      "\n",
      "Epoch 76: Train Loss = 0.002423435726536954, Recall = 0.9181818181818182, Aging Rate = 0.001749129764646797, Precision = 0, f1 = 0.0\n",
      "Epoch 77: Train Loss = 0.002481817481875787, Recall = 0.9090909090909091, Aging Rate = 0.0017664478811284484, Precision = 0.9803921568627451, f1 = 0.9433962264150944\n",
      "Epoch 78: Train Loss = 0.0023732793814578994, Recall = 0.9181818181818182, Aging Rate = 0.0017664478811284484, Precision = 0.9901960784313726, f1 = 0.9528301886792454\n",
      "Epoch 79: Train Loss = 0.0024083428178813403, Recall = 0.9090909090909091, Aging Rate = 0.001749129764646797, Precision = 0.9900990099009901, f1 = 0.947867298578199\n",
      "Epoch 80: Train Loss = 0.0025151879156146894, Recall = 0.9, Aging Rate = 0.0017318116481651455, Precision = 0.99, f1 = 0.9428571428571428\n",
      "Test Loss = 0.0019249161305694143, Recall = 0.9272727272727272, Aging Rate = 0.0017664478811284484, precision = 1.0\n",
      "\n",
      "Epoch 81: Train Loss = 0.0024545717865738386, Recall = 0.9090909090909091, Aging Rate = 0.0017837659976100999, Precision = 0.970873786407767, f1 = 0.9389671361502346\n",
      "Epoch 82: Train Loss = 0.0024458177487083634, Recall = 0.9272727272727272, Aging Rate = 0.0018010841140917513, Precision = 0.9807692307692307, f1 = 0.9532710280373831\n",
      "Epoch 83: Train Loss = 0.002334971036451238, Recall = 0.8818181818181818, Aging Rate = 0.0016971754152018427, Precision = 0.9897959183673469, f1 = 0.9326923076923076\n",
      "Epoch 84: Train Loss = 0.002280409218529181, Recall = 0.9363636363636364, Aging Rate = 0.0017837659976100999, Precision = 0, f1 = 0.0\n",
      "Epoch 85: Train Loss = 0.0025438280391635623, Recall = 0.8909090909090909, Aging Rate = 0.001749129764646797, Precision = 0.9702970297029703, f1 = 0.9289099526066351\n",
      "Test Loss = 0.00207183267086375, Recall = 0.9545454545454546, Aging Rate = 0.0018184022305734028, precision = 1.0\n",
      "\n",
      "Epoch 86: Train Loss = 0.0024180721832651993, Recall = 0.8909090909090909, Aging Rate = 0.0017318116481651455, Precision = 0.98, f1 = 0.9333333333333333\n",
      "Epoch 87: Train Loss = 0.0021639125467114244, Recall = 0.9272727272727272, Aging Rate = 0.0017837659976100999, Precision = 0.9902912621359223, f1 = 0.9577464788732394\n",
      "Epoch 88: Train Loss = 0.0024769307544531285, Recall = 0.9, Aging Rate = 0.001749129764646797, Precision = 0.9801980198019802, f1 = 0.9383886255924171\n",
      "Epoch 89: Train Loss = 0.0023172924771466792, Recall = 0.9454545454545454, Aging Rate = 0.0018184022305734028, Precision = 0.9904761904761905, f1 = 0.9674418604651163\n",
      "Epoch 90: Train Loss = 0.0023035324115791398, Recall = 0.9, Aging Rate = 0.0017144935316834942, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.002116337505723554, Recall = 0.9363636363636364, Aging Rate = 0.0017837659976100999, precision = 1.0\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 91: Train Loss = 0.0025022560776860998, Recall = 0.9181818181818182, Aging Rate = 0.001749129764646797, Precision = 0, f1 = 0.0\n",
      "Epoch 92: Train Loss = 0.0024852457898315323, Recall = 0.8909090909090909, Aging Rate = 0.0017144935316834942, Precision = 0.98989898989899, f1 = 0.937799043062201\n",
      "Epoch 93: Train Loss = 0.0023510727136043428, Recall = 0.9090909090909091, Aging Rate = 0.0017318116481651455, Precision = 0, f1 = 0.0\n",
      "Epoch 94: Train Loss = 0.0022774320788668733, Recall = 0.9363636363636364, Aging Rate = 0.0018010841140917513, Precision = 0.9903846153846154, f1 = 0.9626168224299064\n",
      "Epoch 95: Train Loss = 0.0023563271897031743, Recall = 0.8909090909090909, Aging Rate = 0.0016971754152018427, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0023325206853821337, Recall = 0.9818181818181818, Aging Rate = 0.0019049928129816602, precision = 0.9818181818181818\n",
      "\n",
      "Epoch 96: Train Loss = 0.0024472455247031466, Recall = 0.9, Aging Rate = 0.0017144935316834942, Precision = 0, f1 = 0.0\n",
      "Epoch 97: Train Loss = 0.0023286510922752345, Recall = 0.9363636363636364, Aging Rate = 0.0017837659976100999, Precision = 0, f1 = 0.0\n",
      "Epoch 98: Train Loss = 0.002273994260111184, Recall = 0.9363636363636364, Aging Rate = 0.0018010841140917513, Precision = 0.9903846153846154, f1 = 0.9626168224299064\n",
      "Epoch 99: Train Loss = 0.002249155174422194, Recall = 0.9454545454545454, Aging Rate = 0.0018184022305734028, Precision = 0.9904761904761905, f1 = 0.9674418604651163\n",
      "Epoch 100: Train Loss = 0.0024483207437494894, Recall = 0.9181818181818182, Aging Rate = 0.0017837659976100999, Precision = 0.9805825242718447, f1 = 0.9483568075117371\n",
      "Test Loss = 0.001933445576318867, Recall = 0.9818181818181818, Aging Rate = 0.0018876746965000087, precision = 0.9908256880733946\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e33c150ef394e17a04ceb7c104fb276",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da4efac6f69744cfbe4bb39a66be2f45",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss = 0.45161159207791457, Recall = 0.7114197530864198, Aging Rate = 0.4212962962962963, Precision = 0.8443223443223443, f1 = 0.7721943048576215\n",
      "Epoch 2: Train Loss = 0.13922572135925293, Recall = 0.9675925925925926, Aging Rate = 0.503858024691358, Precision = 0.9601837672281777, f1 = 0.9638739431206764\n",
      "Epoch 3: Train Loss = 0.07110559606901658, Recall = 0.9691358024691358, Aging Rate = 0.49382716049382713, Precision = 0.98125, f1 = 0.9751552795031055\n",
      "Epoch 4: Train Loss = 0.04298235889938143, Recall = 0.9876543209876543, Aging Rate = 0.4976851851851852, Precision = 0.9922480620155039, f1 = 0.9899458623356534\n",
      "Epoch 5: Train Loss = 0.025080191937309725, Recall = 0.9969135802469136, Aging Rate = 0.4992283950617284, Precision = 0.9984544049459042, f1 = 0.9976833976833976\n",
      "Test Loss = 0.012352144127182755, Recall = 0.9984567901234568, Aging Rate = 0.4992283950617284, precision = 1.0\n",
      "Model in epoch 5 is saved.\n",
      "\n",
      "Epoch 6: Train Loss = 0.011735803763853548, Recall = 0.9984567901234568, Aging Rate = 0.4992283950617284, Precision = 0, f1 = 0.0\n",
      "Epoch 7: Train Loss = 0.00883366026122261, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 8: Train Loss = 0.007755043381756103, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 9: Train Loss = 0.008165045928807907, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 10: Train Loss = 0.0066061371960389765, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.006472976297646025, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "Model in epoch 10 is saved.\n",
      "\n",
      "Epoch 11: Train Loss = 0.006767250597476959, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 12: Train Loss = 0.006446341133136072, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 13: Train Loss = 0.006548593924553306, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 14: Train Loss = 0.006024931224040043, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 15: Train Loss = 0.006361228839298825, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.005312475548298271, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 16: Train Loss = 0.005834597456096499, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 17: Train Loss = 0.006340047971196013, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 18: Train Loss = 0.005757862851483587, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 19: Train Loss = 0.005995594925120657, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 20: Train Loss = 0.00582095969721307, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.006636818273015964, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 21: Train Loss = 0.006831532597173879, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 22: Train Loss = 0.01093845019824113, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 23: Train Loss = 0.005612506542676761, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 24: Train Loss = 0.004249537047458652, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 25: Train Loss = 0.004817113975913804, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0047456937623612675, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 26: Train Loss = 0.004947176260620724, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 27: Train Loss = 0.006970460584134232, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 28: Train Loss = 0.006255449479974714, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 29: Train Loss = 0.005258097914105028, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 30: Train Loss = 0.004996740949098711, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.004675310266054707, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 31: Train Loss = 0.0056627461827578555, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 32: Train Loss = 0.005712689889341961, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 33: Train Loss = 0.011389675492673744, Recall = 1.0, Aging Rate = 0.5007716049382716, Precision = 0.9984591679506933, f1 = 0.9992289899768697\n",
      "Epoch 34: Train Loss = 0.005843364009863616, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 35: Train Loss = 0.005049625607092439, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.003800282639991722, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 36: Train Loss = 0.004722295265736772, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 37: Train Loss = 0.00580264001302881, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 38: Train Loss = 0.004820316443564715, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 39: Train Loss = 0.004626910759848945, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 40: Train Loss = 0.005247968668693009, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.006343455691994341, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 41: Train Loss = 0.006168487843953901, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 42: Train Loss = 0.006165036141159542, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 43: Train Loss = 0.004815506610881399, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 44: Train Loss = 0.007223567591957104, Recall = 0.9984567901234568, Aging Rate = 0.4992283950617284, Precision = 0, f1 = 0.0\n",
      "Epoch 45: Train Loss = 0.007762663037642652, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.003918015524561023, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 46: Train Loss = 0.004700770705110497, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 47: Train Loss = 0.005582748532847122, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 48: Train Loss = 0.005553964272509386, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 49: Train Loss = 0.01625302440866276, Recall = 0.9969135802469136, Aging Rate = 0.5007716049382716, Precision = 0.9953775038520801, f1 = 0.9961449498843484\n",
      "Epoch 50: Train Loss = 0.013941585741661213, Recall = 0.9938271604938271, Aging Rate = 0.49691358024691357, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.013924543895287278, Recall = 0.9907407407407407, Aging Rate = 0.49614197530864196, precision = 0.9984447900466563\n",
      "\n",
      "Epoch 51: Train Loss = 0.007346739831530017, Recall = 0.9969135802469136, Aging Rate = 0.4984567901234568, Precision = 0, f1 = 0.0\n",
      "Epoch 52: Train Loss = 0.004774561450805193, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 53: Train Loss = 0.0033765759227084523, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 54: Train Loss = 0.003342119315754116, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 55: Train Loss = 0.004175474631519597, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.004225885265587289, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 56: Train Loss = 0.005360835596896064, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 57: Train Loss = 0.005686759748956028, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 58: Train Loss = 0.004814757218147501, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 59: Train Loss = 0.0050296047185030245, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 60: Train Loss = 0.005424798443269582, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.005111123412203641, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Training Finished at epoch 60.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c1e28cbc03e34bc5bea1495b7db2a232",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss = 0.3155625395162809, Recall = 0.9473180076628352, Aging Rate = 0.6422413793103449, Precision = 0.7375093214019388, f1 = 0.8293501048218029\n",
      "Epoch 2: Train Loss = 0.0819563338697185, Recall = 0.9818007662835249, Aging Rate = 0.5167624521072797, Precision = 0.9499536607970342, f1 = 0.9656146961846443\n",
      "Epoch 3: Train Loss = 0.0450687475539958, Recall = 0.9885057471264368, Aging Rate = 0.5033524904214559, Precision = 0.9819219790675547, f1 = 0.9852028639618139\n",
      "Epoch 4: Train Loss = 0.014941510577352496, Recall = 0.9990421455938697, Aging Rate = 0.5038314176245211, Precision = 0.9914448669201521, f1 = 0.9952290076335879\n",
      "Epoch 5: Train Loss = 0.015290842575317256, Recall = 0.9971264367816092, Aging Rate = 0.5019157088122606, Precision = 0.9933206106870229, f1 = 0.9952198852772466\n",
      "Test Loss = 0.00941881501308546, Recall = 1.0, Aging Rate = 0.5014367816091954, precision = 0.997134670487106\n",
      "Model in epoch 5 is saved.\n",
      "\n",
      "Epoch 6: Train Loss = 0.004749071323339581, Recall = 0.9990421455938697, Aging Rate = 0.5, Precision = 0.9990421455938697, f1 = 0.9990421455938697\n",
      "Epoch 7: Train Loss = 0.0019535657472933474, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 8: Train Loss = 0.0013489763036555829, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 9: Train Loss = 0.0009874222740812863, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 10: Train Loss = 0.0009238852710521983, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0008545144687681477, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "Model in epoch 10 is saved.\n",
      "\n",
      "Epoch 11: Train Loss = 0.0009592393432365609, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 12: Train Loss = 0.00090940580601845, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 13: Train Loss = 0.0010192770467646478, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 14: Train Loss = 0.0010960732827095094, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 15: Train Loss = 0.0010140189661027087, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0008168532129491312, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 16: Train Loss = 0.0008756617910203691, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 17: Train Loss = 0.0009119029432736779, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 18: Train Loss = 0.0009367183569847281, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 19: Train Loss = 0.002487333697959124, Recall = 1.0, Aging Rate = 0.5004789272030651, Precision = 0.999043062200957, f1 = 0.9995213020584012\n",
      "Epoch 20: Train Loss = 0.03789089593443225, Recall = 0.9913793103448276, Aging Rate = 0.5076628352490421, Precision = 0.9764150943396226, f1 = 0.9838403041825095\n",
      "Test Loss = 0.042092645588336274, Recall = 0.9712643678160919, Aging Rate = 0.4861111111111111, precision = 0.9990147783251232\n",
      "\n",
      "Epoch 21: Train Loss = 0.026732509489768002, Recall = 0.9952107279693486, Aging Rate = 0.5043103448275862, Precision = 0.9867046533713201, f1 = 0.9909394372913686\n",
      "Epoch 22: Train Loss = 0.0050134815820278705, Recall = 0.9990421455938697, Aging Rate = 0.5014367816091954, Precision = 0.9961795606494747, f1 = 0.997608799617408\n",
      "Epoch 23: Train Loss = 0.00047954104154306494, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 24: Train Loss = 0.00033655417485383847, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 25: Train Loss = 0.00034277370746846943, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.000324514283936014, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 26: Train Loss = 0.000357052272719142, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 27: Train Loss = 0.0003800754876043719, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 28: Train Loss = 0.0003990752140097534, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 29: Train Loss = 0.00042515292708401593, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 30: Train Loss = 0.00046924021009398605, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.00044912332116931294, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 31: Train Loss = 0.0004780998302291779, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 32: Train Loss = 0.0005286233856753532, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 33: Train Loss = 0.0005538409861951881, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 34: Train Loss = 0.0005894790618088082, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 35: Train Loss = 0.000630018348364923, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0005914314626693775, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 36: Train Loss = 0.0006458404519902078, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 37: Train Loss = 0.0006700504202773916, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 38: Train Loss = 0.0006666870221162885, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 39: Train Loss = 0.0007036934696830153, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 40: Train Loss = 0.0007204114883411962, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0006951280919499553, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 41: Train Loss = 0.0007726287085008076, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 42: Train Loss = 0.000748243554445319, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 43: Train Loss = 0.0007559020490157222, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 44: Train Loss = 0.0008046227158047259, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 45: Train Loss = 0.0007757974604668339, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0007034293581085758, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 46: Train Loss = 0.0007695229602504835, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 47: Train Loss = 0.0008479604728152383, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 48: Train Loss = 0.018742565280611544, Recall = 0.9971264367816092, Aging Rate = 0.5023946360153256, Precision = 0.9923736892278361, f1 = 0.9947443860487339\n",
      "Epoch 49: Train Loss = 0.06798330359731826, Recall = 0.9818007662835249, Aging Rate = 0.5105363984674329, Precision = 0.9615384615384616, f1 = 0.971563981042654\n",
      "Epoch 50: Train Loss = 0.010920776565866082, Recall = 0.9980842911877394, Aging Rate = 0.5028735632183908, Precision = 0.9923809523809524, f1 = 0.9952244508118434\n",
      "Test Loss = 0.003638220793733523, Recall = 1.0, Aging Rate = 0.5014367816091954, precision = 0.997134670487106\n",
      "\n",
      "Epoch 51: Train Loss = 0.002350585865792622, Recall = 1.0, Aging Rate = 0.5009578544061303, Precision = 0.9980879541108987, f1 = 0.999043062200957\n",
      "Epoch 52: Train Loss = 0.0006779382540911287, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 53: Train Loss = 0.00034493913398333023, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 54: Train Loss = 0.0003460700481182671, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 55: Train Loss = 0.00037183027029380033, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.00036103614413944855, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 56: Train Loss = 0.0003902705663269193, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 57: Train Loss = 0.0004284970423405619, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 58: Train Loss = 0.0004692258762902227, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 59: Train Loss = 0.00047358656665613566, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 60: Train Loss = 0.0004873987686707927, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.00047984500339797115, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Training Finished at epoch 60.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc82b70146184f2d935a5cd6acfc8c91",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss = 0.4846238622522265, Recall = 0.8799249530956847, Aging Rate = 0.6238273921200751, Precision = 0.7052631578947368, f1 = 0.7829716193656093\n",
      "Epoch 2: Train Loss = 0.21427391955933026, Recall = 0.949343339587242, Aging Rate = 0.5262664165103189, Precision = 0.9019607843137255, f1 = 0.9250457038391225\n",
      "Epoch 3: Train Loss = 0.11693356578949468, Recall = 0.9784240150093808, Aging Rate = 0.5121951219512195, Precision = 0.9551282051282052, f1 = 0.9666357738646895\n",
      "Epoch 4: Train Loss = 0.066201193408436, Recall = 0.9868667917448405, Aging Rate = 0.5037523452157598, Precision = 0.9795158286778398, f1 = 0.983177570093458\n",
      "Epoch 5: Train Loss = 0.038771274372040664, Recall = 0.9971857410881801, Aging Rate = 0.5056285178236398, Precision = 0.9860853432282004, f1 = 0.9916044776119404\n",
      "Test Loss = 0.017698758071215077, Recall = 0.99812382739212, Aging Rate = 0.50093808630394, precision = 0.9962546816479401\n",
      "Model in epoch 5 is saved.\n",
      "\n",
      "Epoch 6: Train Loss = 0.016564720484129315, Recall = 0.99812382739212, Aging Rate = 0.50187617260788, Precision = 0.994392523364486, f1 = 0.9962546816479401\n",
      "Epoch 7: Train Loss = 0.009430726773435805, Recall = 1.0, Aging Rate = 0.50093808630394, Precision = 0.99812734082397, f1 = 0.9990627928772258\n",
      "Epoch 8: Train Loss = 0.006503135662204385, Recall = 1.0, Aging Rate = 0.5004690431519699, Precision = 0.9990627928772259, f1 = 0.9995311767463666\n",
      "Epoch 9: Train Loss = 0.0055271928717590185, Recall = 0.99906191369606, Aging Rate = 0.49953095684803, Precision = 0, f1 = 0.0\n",
      "Epoch 10: Train Loss = 0.004472120257014126, Recall = 1.0, Aging Rate = 0.5004690431519699, Precision = 0.9990627928772259, f1 = 0.9995311767463666\n",
      "Test Loss = 0.0033168233599073444, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "Model in epoch 10 is saved.\n",
      "\n",
      "Epoch 11: Train Loss = 0.003282047730414494, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 12: Train Loss = 0.0030124188600873353, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 13: Train Loss = 0.002465626870074063, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 14: Train Loss = 0.00220492494787923, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 15: Train Loss = 0.002055805682346197, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0019445640727786756, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 16: Train Loss = 0.0019429216867288327, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 17: Train Loss = 0.0019076837909951332, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 18: Train Loss = 0.0017706650666591988, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 19: Train Loss = 0.0016126466816069303, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 20: Train Loss = 0.0015280836449209146, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.001463227784986246, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 21: Train Loss = 0.0014987678416020903, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 22: Train Loss = 0.0014208339040707551, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 23: Train Loss = 0.0013812088469169182, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 24: Train Loss = 0.0013656264841975907, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 25: Train Loss = 0.0013292502471216122, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0012540479337422642, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 26: Train Loss = 0.001352684388870258, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 27: Train Loss = 0.001275999832804023, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 28: Train Loss = 0.0012897732178374817, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 29: Train Loss = 0.0012215944043623623, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 30: Train Loss = 0.001193561969284758, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0011221971741779647, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 31: Train Loss = 0.0013078436609069287, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 32: Train Loss = 0.0012173745377115053, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 33: Train Loss = 0.0011582114511190461, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 34: Train Loss = 0.0011332019113832437, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 35: Train Loss = 0.001121251647295972, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0010749445631872954, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 36: Train Loss = 0.0011426054027960696, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 37: Train Loss = 0.0011271716847510809, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 38: Train Loss = 0.0010895324237758248, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 39: Train Loss = 0.0011057095998796803, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 40: Train Loss = 0.0011364800124263172, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0012294558496310551, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 41: Train Loss = 0.0013315559253026688, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 42: Train Loss = 0.0012169865931525798, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 43: Train Loss = 0.0010391393766824093, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 44: Train Loss = 0.0010513026331941027, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 45: Train Loss = 0.0010178980983681907, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0009455030119919356, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 46: Train Loss = 0.0010179854744012636, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 47: Train Loss = 0.0010249673369896247, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 48: Train Loss = 0.0010222162807615402, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 49: Train Loss = 0.0009975887419600004, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 50: Train Loss = 0.0010369037139084448, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0010308141056334646, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 51: Train Loss = 0.0010424729036499255, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 52: Train Loss = 0.0016145328958352809, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 53: Train Loss = 0.006174024424470234, Recall = 0.99906191369606, Aging Rate = 0.5004690431519699, Precision = 0.9981255857544518, f1 = 0.9985935302390998\n",
      "Epoch 54: Train Loss = 0.020792395379053565, Recall = 0.9953095684803002, Aging Rate = 0.5032833020637899, Precision = 0.9888164026095061, f1 = 0.992052360916316\n",
      "Epoch 55: Train Loss = 0.01907386793623946, Recall = 0.9953095684803002, Aging Rate = 0.50187617260788, Precision = 0.991588785046729, f1 = 0.9934456928838952\n",
      "Test Loss = 0.012755068128431211, Recall = 1.0, Aging Rate = 0.50093808630394, precision = 0.99812734082397\n",
      "\n",
      "Epoch 56: Train Loss = 0.007550007045988909, Recall = 1.0, Aging Rate = 0.50187617260788, Precision = 0.9962616822429906, f1 = 0.99812734082397\n",
      "Epoch 57: Train Loss = 0.0019805038875968357, Recall = 1.0, Aging Rate = 0.50093808630394, Precision = 0.99812734082397, f1 = 0.9990627928772258\n",
      "Epoch 58: Train Loss = 0.001073304542656385, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 59: Train Loss = 0.00030624886989326166, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 60: Train Loss = 0.0002537030361863168, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0002480838399484848, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Training Finished at epoch 60.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb22f026a41f4bbeba81fd3d4e0cd5a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a3357d19d41e4a9fba3766ffbe35de50",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss = 0.29572031570043533, Recall = 0.9233038348082596, Aging Rate = 0.5653883972468043, Precision = 0.8165217391304348, f1 = 0.8666359021688971\n",
      "Epoch 2: Train Loss = 0.08336120176668423, Recall = 0.9734513274336283, Aging Rate = 0.5029498525073747, Precision = 0.967741935483871, f1 = 0.9705882352941176\n",
      "Epoch 3: Train Loss = 0.06300315714002594, Recall = 0.9852507374631269, Aging Rate = 0.5024582104228122, Precision = 0.9804305283757339, f1 = 0.9828347229033839\n",
      "Epoch 4: Train Loss = 0.045628192396825334, Recall = 0.9901671583087512, Aging Rate = 0.504424778761062, Precision = 0.9814814814814815, f1 = 0.9858051884483602\n",
      "Epoch 5: Train Loss = 0.03616404780640011, Recall = 0.992133726647001, Aging Rate = 0.5024582104228122, Precision = 0.987279843444227, f1 = 0.9897008337420303\n",
      "Test Loss = 0.020087518161501564, Recall = 0.9990167158308751, Aging Rate = 0.5039331366764995, precision = 0.9912195121951219\n",
      "Model in epoch 5 is saved.\n",
      "\n",
      "Epoch 6: Train Loss = 0.01890345083388446, Recall = 0.9980334316617503, Aging Rate = 0.5014749262536873, Precision = 0.9950980392156863, f1 = 0.9965635738831615\n",
      "Epoch 7: Train Loss = 0.014695692155418612, Recall = 0.9990167158308751, Aging Rate = 0.5009832841691249, Precision = 0.9970559371933267, f1 = 0.9980353634577603\n",
      "Epoch 8: Train Loss = 0.014952453036472978, Recall = 0.9980334316617503, Aging Rate = 0.5004916420845624, Precision = 0.9970530451866405, f1 = 0.9975429975429977\n",
      "Epoch 9: Train Loss = 0.01531938030846937, Recall = 0.9980334316617503, Aging Rate = 0.5004916420845624, Precision = 0.9970530451866405, f1 = 0.9975429975429977\n",
      "Epoch 10: Train Loss = 0.01925433487718377, Recall = 0.9960668633235005, Aging Rate = 0.5004916420845624, Precision = 0.9950884086444007, f1 = 0.9955773955773956\n",
      "Test Loss = 0.014605176681790028, Recall = 1.0, Aging Rate = 0.5014749262536873, precision = 0.9970588235294118\n",
      "Model in epoch 10 is saved.\n",
      "\n",
      "Epoch 11: Train Loss = 0.01328745244561732, Recall = 0.9960668633235005, Aging Rate = 0.5004916420845624, Precision = 0.9950884086444007, f1 = 0.9955773955773956\n",
      "Epoch 12: Train Loss = 0.022152564318936717, Recall = 0.9970501474926253, Aging Rate = 0.5014749262536873, Precision = 0.9941176470588236, f1 = 0.995581737849779\n",
      "Epoch 13: Train Loss = 0.015710339461148314, Recall = 0.9980334316617503, Aging Rate = 0.5014749262536873, Precision = 0.9950980392156863, f1 = 0.9965635738831615\n",
      "Epoch 14: Train Loss = 0.01568337476417613, Recall = 0.9970501474926253, Aging Rate = 0.5014749262536873, Precision = 0.9941176470588236, f1 = 0.995581737849779\n",
      "Epoch 15: Train Loss = 0.013881122598180962, Recall = 0.9980334316617503, Aging Rate = 0.5009832841691249, Precision = 0.9960745829244357, f1 = 0.9970530451866405\n",
      "Test Loss = 0.00876207627454954, Recall = 0.9980334316617503, Aging Rate = 0.49901671583087515, precision = 1.0\n",
      "Model in epoch 15 is saved.\n",
      "\n",
      "Epoch 16: Train Loss = 0.014970509925602607, Recall = 0.9990167158308751, Aging Rate = 0.5004916420845624, Precision = 0.9980353634577603, f1 = 0.9985257985257985\n",
      "Epoch 17: Train Loss = 0.013717464425014066, Recall = 0.9980334316617503, Aging Rate = 0.5009832841691249, Precision = 0.9960745829244357, f1 = 0.9970530451866405\n",
      "Epoch 18: Train Loss = 0.01205360289294943, Recall = 0.9980334316617503, Aging Rate = 0.5, Precision = 0.9980334316617503, f1 = 0.9980334316617503\n",
      "Epoch 19: Train Loss = 0.024228218038114945, Recall = 0.9970501474926253, Aging Rate = 0.5034414945919371, Precision = 0.990234375, f1 = 0.9936305732484076\n",
      "Epoch 20: Train Loss = 0.015909487750626655, Recall = 0.9980334316617503, Aging Rate = 0.5009832841691249, Precision = 0.9960745829244357, f1 = 0.9970530451866405\n",
      "Test Loss = 0.009807046193303495, Recall = 0.9960668633235005, Aging Rate = 0.49803343166175024, precision = 1.0\n",
      "\n",
      "Epoch 21: Train Loss = 0.012264057854694133, Recall = 0.9980334316617503, Aging Rate = 0.5004916420845624, Precision = 0.9970530451866405, f1 = 0.9975429975429977\n",
      "Epoch 22: Train Loss = 0.013489168930355544, Recall = 0.9980334316617503, Aging Rate = 0.5009832841691249, Precision = 0.9960745829244357, f1 = 0.9970530451866405\n",
      "Epoch 23: Train Loss = 0.017177696772022293, Recall = 0.9960668633235005, Aging Rate = 0.5004916420845624, Precision = 0.9950884086444007, f1 = 0.9955773955773956\n",
      "Epoch 24: Train Loss = 0.011426950983461377, Recall = 0.9990167158308751, Aging Rate = 0.5009832841691249, Precision = 0.9970559371933267, f1 = 0.9980353634577603\n",
      "Epoch 25: Train Loss = 0.021532599909932535, Recall = 0.9960668633235005, Aging Rate = 0.5009832841691249, Precision = 0.9941118743866536, f1 = 0.9950884086444007\n",
      "Test Loss = 0.026933744022734428, Recall = 0.9891838741396264, Aging Rate = 0.4970501474926254, precision = 0.9950544015825915\n",
      "\n",
      "Epoch 26: Train Loss = 0.024690406445977933, Recall = 0.992133726647001, Aging Rate = 0.4995083579154376, Precision = 0.9931102362204725, f1 = 0.9926217412690604\n",
      "Epoch 27: Train Loss = 0.009158886927193728, Recall = 0.9990167158308751, Aging Rate = 0.5004916420845624, Precision = 0.9980353634577603, f1 = 0.9985257985257985\n",
      "Epoch 28: Train Loss = 0.011316571771574729, Recall = 0.9980334316617503, Aging Rate = 0.5004916420845624, Precision = 0.9970530451866405, f1 = 0.9975429975429977\n",
      "Epoch 29: Train Loss = 0.01089872419467835, Recall = 1.0, Aging Rate = 0.5009832841691249, Precision = 0.9980372914622179, f1 = 0.9990176817288801\n",
      "Epoch 30: Train Loss = 0.009004251170636043, Recall = 1.0, Aging Rate = 0.5009832841691249, Precision = 0.9980372914622179, f1 = 0.9990176817288801\n",
      "Test Loss = 0.014505238003933558, Recall = 1.0, Aging Rate = 0.5019665683382497, precision = 0.9960822722820764\n",
      "\n",
      "Epoch 31: Train Loss = 0.015467158833751226, Recall = 0.9980334316617503, Aging Rate = 0.5004916420845624, Precision = 0.9970530451866405, f1 = 0.9975429975429977\n",
      "Epoch 32: Train Loss = 0.012539825680818602, Recall = 0.9980334316617503, Aging Rate = 0.5004916420845624, Precision = 0.9970530451866405, f1 = 0.9975429975429977\n",
      "Epoch 33: Train Loss = 0.01889926100272462, Recall = 0.9960668633235005, Aging Rate = 0.5004916420845624, Precision = 0.9950884086444007, f1 = 0.9955773955773956\n",
      "Epoch 34: Train Loss = 0.022349561343126132, Recall = 0.9950835791543756, Aging Rate = 0.5014749262536873, Precision = 0.9921568627450981, f1 = 0.9936180657830143\n",
      "Epoch 35: Train Loss = 0.019765877710232253, Recall = 0.9960668633235005, Aging Rate = 0.5009832841691249, Precision = 0.9941118743866536, f1 = 0.9950884086444007\n",
      "Test Loss = 0.007400443972154331, Recall = 0.9990167158308751, Aging Rate = 0.5004916420845624, precision = 0.9980353634577603\n",
      "\n",
      "Epoch 36: Train Loss = 0.008424494627976722, Recall = 1.0, Aging Rate = 0.5004916420845624, Precision = 0.9990176817288802, f1 = 0.9995085995085995\n",
      "Epoch 37: Train Loss = 0.013683802736675845, Recall = 0.9990167158308751, Aging Rate = 0.5019665683382497, Precision = 0.9951028403525954, f1 = 0.9970559371933267\n",
      "Epoch 38: Train Loss = 0.017583941397025463, Recall = 0.9950835791543756, Aging Rate = 0.49901671583087515, Precision = 0.9970443349753695, f1 = 0.9960629921259843\n",
      "Epoch 39: Train Loss = 0.00985403887326797, Recall = 1.0, Aging Rate = 0.5019665683382497, Precision = 0.9960822722820764, f1 = 0.9980372914622179\n",
      "Epoch 40: Train Loss = 0.009398758672397573, Recall = 0.9990167158308751, Aging Rate = 0.5004916420845624, Precision = 0.9980353634577603, f1 = 0.9985257985257985\n",
      "Test Loss = 0.010153847068892526, Recall = 0.9990167158308751, Aging Rate = 0.5004916420845624, precision = 0.9980353634577603\n",
      "\n",
      "Epoch 41: Train Loss = 0.016673714365725907, Recall = 0.9980334316617503, Aging Rate = 0.5009832841691249, Precision = 0.9960745829244357, f1 = 0.9970530451866405\n",
      "Epoch 42: Train Loss = 0.013312259308935209, Recall = 0.9980334316617503, Aging Rate = 0.5004916420845624, Precision = 0.9970530451866405, f1 = 0.9975429975429977\n",
      "Epoch 43: Train Loss = 0.010533062799310818, Recall = 0.9990167158308751, Aging Rate = 0.5, Precision = 0.9990167158308751, f1 = 0.9990167158308751\n",
      "Epoch 44: Train Loss = 0.015191735390247731, Recall = 0.9990167158308751, Aging Rate = 0.5019665683382497, Precision = 0.9951028403525954, f1 = 0.9970559371933267\n",
      "Epoch 45: Train Loss = 0.010911440495548142, Recall = 0.9990167158308751, Aging Rate = 0.5004916420845624, Precision = 0.9980353634577603, f1 = 0.9985257985257985\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss = 0.01197101697192922, Recall = 0.9980334316617503, Aging Rate = 0.5, precision = 0.9980334316617503\n",
      "\n",
      "Epoch 46: Train Loss = 0.010990148764598159, Recall = 0.9990167158308751, Aging Rate = 0.5009832841691249, Precision = 0.9970559371933267, f1 = 0.9980353634577603\n",
      "Epoch 47: Train Loss = 0.015574874275344751, Recall = 0.9990167158308751, Aging Rate = 0.5014749262536873, Precision = 0.996078431372549, f1 = 0.9975454099165441\n",
      "Epoch 48: Train Loss = 0.014446606379709296, Recall = 0.9990167158308751, Aging Rate = 0.5009832841691249, Precision = 0.9970559371933267, f1 = 0.9980353634577603\n",
      "Epoch 49: Train Loss = 0.011417526316773164, Recall = 1.0, Aging Rate = 0.5019665683382497, Precision = 0.9960822722820764, f1 = 0.9980372914622179\n",
      "Epoch 50: Train Loss = 0.016266268698156113, Recall = 0.9970501474926253, Aging Rate = 0.4995083579154376, Precision = 0.9980314960629921, f1 = 0.9975405804230201\n",
      "Test Loss = 0.030736131601826807, Recall = 1.0, Aging Rate = 0.5088495575221239, precision = 0.9826086956521739\n",
      "\n",
      "Epoch 51: Train Loss = 0.017899334912381576, Recall = 0.9970501474926253, Aging Rate = 0.5019665683382497, Precision = 0.9931439764936337, f1 = 0.9950932286555446\n",
      "Epoch 52: Train Loss = 0.012466498825519604, Recall = 0.9970501474926253, Aging Rate = 0.4995083579154376, Precision = 0.9980314960629921, f1 = 0.9975405804230201\n",
      "Epoch 53: Train Loss = 0.012903984526177775, Recall = 0.9990167158308751, Aging Rate = 0.5019665683382497, Precision = 0.9951028403525954, f1 = 0.9970559371933267\n",
      "Epoch 54: Train Loss = 0.01709358735539334, Recall = 0.9960668633235005, Aging Rate = 0.5, Precision = 0.9960668633235005, f1 = 0.9960668633235005\n",
      "Epoch 55: Train Loss = 0.014105316191992285, Recall = 0.9970501474926253, Aging Rate = 0.5004916420845624, Precision = 0.9960707269155207, f1 = 0.9965601965601965\n",
      "Test Loss = 0.00759362536340571, Recall = 1.0, Aging Rate = 0.5019665683382497, precision = 0.9960822722820764\n",
      "\n",
      "Epoch 56: Train Loss = 0.009787652069645967, Recall = 0.9990167158308751, Aging Rate = 0.5009832841691249, Precision = 0.9970559371933267, f1 = 0.9980353634577603\n",
      "Epoch 57: Train Loss = 0.012103958352539421, Recall = 0.9990167158308751, Aging Rate = 0.5009832841691249, Precision = 0.9970559371933267, f1 = 0.9980353634577603\n",
      "Epoch 58: Train Loss = 0.013085384358676662, Recall = 0.9990167158308751, Aging Rate = 0.5014749262536873, Precision = 0.996078431372549, f1 = 0.9975454099165441\n",
      "Epoch 59: Train Loss = 0.0107277268937614, Recall = 0.9990167158308751, Aging Rate = 0.5004916420845624, Precision = 0.9980353634577603, f1 = 0.9985257985257985\n",
      "Epoch 60: Train Loss = 0.012259932618584546, Recall = 0.9990167158308751, Aging Rate = 0.5009832841691249, Precision = 0.9970559371933267, f1 = 0.9980353634577603\n",
      "Test Loss = 0.008443785665122721, Recall = 0.9990167158308751, Aging Rate = 0.5004916420845624, precision = 0.9980353634577603\n",
      "\n",
      "Epoch 61: Train Loss = 0.017353632625635627, Recall = 0.9980334316617503, Aging Rate = 0.5009832841691249, Precision = 0.9960745829244357, f1 = 0.9970530451866405\n",
      "Epoch 62: Train Loss = 0.018878865302077906, Recall = 0.9970501474926253, Aging Rate = 0.5009832841691249, Precision = 0.9950932286555446, f1 = 0.9960707269155207\n",
      "Epoch 63: Train Loss = 0.019098296416273218, Recall = 0.9960668633235005, Aging Rate = 0.5009832841691249, Precision = 0.9941118743866536, f1 = 0.9950884086444007\n",
      "Epoch 64: Train Loss = 0.01826674071522457, Recall = 0.9960668633235005, Aging Rate = 0.5009832841691249, Precision = 0.9941118743866536, f1 = 0.9950884086444007\n",
      "Epoch 65: Train Loss = 0.008524139826126478, Recall = 1.0, Aging Rate = 0.5009832841691249, Precision = 0.9980372914622179, f1 = 0.9990176817288801\n",
      "Test Loss = 0.0074873313998241224, Recall = 0.9990167158308751, Aging Rate = 0.5004916420845624, precision = 0.9980353634577603\n",
      "\n",
      "Training Finished at epoch 65.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e5d171f55594791b03373abaa716478",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss = 0.6396420976825964, Recall = 0.8746105919003115, Aging Rate = 0.8309968847352025, Precision = 0.5262417994376757, f1 = 0.6571094207138677\n",
      "Epoch 2: Train Loss = 0.5145807834429161, Recall = 0.9626168224299065, Aging Rate = 0.7083333333333334, Precision = 0.679494227597581, f1 = 0.7966484047695779\n",
      "Epoch 3: Train Loss = 0.39463448970117304, Recall = 0.9462616822429907, Aging Rate = 0.6121495327102804, Precision = 0.7729007633587787, f1 = 0.8508403361344539\n",
      "Epoch 4: Train Loss = 0.31348495644943736, Recall = 0.9283489096573209, Aging Rate = 0.5588006230529595, Precision = 0.8306620209059233, f1 = 0.8767929385803603\n",
      "Epoch 5: Train Loss = 0.25999246885843363, Recall = 0.9400311526479751, Aging Rate = 0.5463395638629284, Precision = 0.8602993585174625, f1 = 0.8983997022701897\n",
      "Test Loss = 0.22699544307227446, Recall = 0.9633956386292835, Aging Rate = 0.5541277258566978, precision = 0.8692902319044272\n",
      "Model in epoch 5 is saved.\n",
      "\n",
      "Epoch 6: Train Loss = 0.2118513634271711, Recall = 0.9595015576323987, Aging Rate = 0.5397196261682243, Precision = 0.8888888888888888, f1 = 0.9228464419475655\n",
      "Epoch 7: Train Loss = 0.1793349773805832, Recall = 0.9750778816199377, Aging Rate = 0.5342679127725857, Precision = 0.9125364431486881, f1 = 0.9427710843373494\n",
      "Epoch 8: Train Loss = 0.1536317568655326, Recall = 0.9758566978193146, Aging Rate = 0.5241433021806854, Precision = 0.9309063893016345, f1 = 0.9528517110266159\n",
      "Epoch 9: Train Loss = 0.132774876378407, Recall = 0.9797507788161994, Aging Rate = 0.5190809968847352, Precision = 0.9437359339834959, f1 = 0.96140619029423\n",
      "Epoch 10: Train Loss = 0.11614108371121862, Recall = 0.9828660436137072, Aging Rate = 0.514797507788162, Precision = 0.9546142208774584, f1 = 0.9685341519570223\n",
      "Test Loss = 0.10666285796421711, Recall = 0.9890965732087228, Aging Rate = 0.5190809968847352, precision = 0.9527381845461366\n",
      "Model in epoch 10 is saved.\n",
      "\n",
      "Epoch 11: Train Loss = 0.10176162017840092, Recall = 0.9875389408099688, Aging Rate = 0.5144080996884736, Precision = 0.9598788796366389, f1 = 0.9735124760076775\n",
      "Epoch 12: Train Loss = 0.08978251068391532, Recall = 0.9875389408099688, Aging Rate = 0.508177570093458, Precision = 0.9716475095785441, f1 = 0.9795287755890305\n",
      "Epoch 13: Train Loss = 0.07868413097947557, Recall = 0.9906542056074766, Aging Rate = 0.5077881619937694, Precision = 0.9754601226993865, f1 = 0.9829984544049459\n",
      "Epoch 14: Train Loss = 0.07143195112731969, Recall = 0.9922118380062306, Aging Rate = 0.5077881619937694, Precision = 0.9769938650306749, f1 = 0.9845440494590418\n",
      "Epoch 15: Train Loss = 0.06351481120441561, Recall = 0.9929906542056075, Aging Rate = 0.5062305295950156, Precision = 0.9807692307692307, f1 = 0.986842105263158\n",
      "Test Loss = 0.06164703382370628, Recall = 0.9976635514018691, Aging Rate = 0.5105140186915887, precision = 0.977116704805492\n",
      "Model in epoch 15 is saved.\n",
      "\n",
      "Epoch 16: Train Loss = 0.05820768730384167, Recall = 0.9937694704049844, Aging Rate = 0.5050623052959502, Precision = 0.9838087895142636, f1 = 0.9887640449438202\n",
      "Epoch 17: Train Loss = 0.051991474753785356, Recall = 0.9945482866043613, Aging Rate = 0.5046728971962616, Precision = 0.9853395061728395, f1 = 0.9899224806201549\n",
      "Epoch 18: Train Loss = 0.047381468813553033, Recall = 0.9961059190031153, Aging Rate = 0.5019470404984424, Precision = 0.9922420480993018, f1 = 0.9941702293043141\n",
      "Epoch 19: Train Loss = 0.04298882134189116, Recall = 0.9961059190031153, Aging Rate = 0.5003894080996885, Precision = 0.9953307392996109, f1 = 0.9957181782794862\n",
      "Epoch 20: Train Loss = 0.039888213031759885, Recall = 0.9992211838006231, Aging Rate = 0.5035046728971962, Precision = 0.9922660479505027, f1 = 0.9957314707023672\n",
      "Test Loss = 0.03697728141097822, Recall = 1.0, Aging Rate = 0.5035046728971962, precision = 0.9930394431554525\n",
      "Model in epoch 20 is saved.\n",
      "\n",
      "Epoch 21: Train Loss = 0.0365997084599232, Recall = 0.9984423676012462, Aging Rate = 0.5023364485981309, Precision = 0.993798449612403, f1 = 0.9961149961149961\n",
      "Epoch 22: Train Loss = 0.03405567255114841, Recall = 1.0, Aging Rate = 0.5015576323987538, Precision = 0.9968944099378882, f1 = 0.9984447900466563\n",
      "Epoch 23: Train Loss = 0.03183266464794907, Recall = 1.0, Aging Rate = 0.5015576323987538, Precision = 0.9968944099378882, f1 = 0.9984447900466563\n",
      "Epoch 24: Train Loss = 0.029502722565258776, Recall = 1.0, Aging Rate = 0.5003894080996885, Precision = 0.9992217898832685, f1 = 0.9996107434799533\n",
      "Epoch 25: Train Loss = 0.027796891770351714, Recall = 1.0, Aging Rate = 0.5003894080996885, Precision = 0.9992217898832685, f1 = 0.9996107434799533\n",
      "Test Loss = 0.026482597533091207, Recall = 1.0, Aging Rate = 0.5003894080996885, precision = 0.9992217898832685\n",
      "Model in epoch 25 is saved.\n",
      "\n",
      "Epoch 26: Train Loss = 0.026662342285162934, Recall = 1.0, Aging Rate = 0.5007788161993769, Precision = 0.9984447900466563, f1 = 0.9992217898832686\n",
      "Epoch 27: Train Loss = 0.024681674995433504, Recall = 1.0, Aging Rate = 0.5003894080996885, Precision = 0.9992217898832685, f1 = 0.9996107434799533\n",
      "Epoch 28: Train Loss = 0.023574890081431266, Recall = 1.0, Aging Rate = 0.5003894080996885, Precision = 0.9992217898832685, f1 = 0.9996107434799533\n",
      "Epoch 29: Train Loss = 0.022493457926489484, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 30: Train Loss = 0.02151134242869426, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.020172187222916388, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "Model in epoch 30 is saved.\n",
      "\n",
      "Epoch 31: Train Loss = 0.020586957789470103, Recall = 1.0, Aging Rate = 0.5003894080996885, Precision = 0.9992217898832685, f1 = 0.9996107434799533\n",
      "Epoch 32: Train Loss = 0.01952574788549236, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 33: Train Loss = 0.018769453027259523, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 34: Train Loss = 0.018034580555335383, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 35: Train Loss = 0.01747480243722969, Recall = 1.0, Aging Rate = 0.5003894080996885, Precision = 0.9992217898832685, f1 = 0.9996107434799533\n",
      "Test Loss = 0.016658117768363418, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 36: Train Loss = 0.016909848689754432, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 37: Train Loss = 0.016278357175396423, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 38: Train Loss = 0.015964071492655812, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 39: Train Loss = 0.015622366637548554, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 40: Train Loss = 0.015115842188351622, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.014388588466028744, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 41: Train Loss = 0.01466692705577779, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 42: Train Loss = 0.014310950570017378, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 43: Train Loss = 0.014008547083657478, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 44: Train Loss = 0.01392948415095561, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 45: Train Loss = 0.013495574896789599, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.012926625113969093, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 46: Train Loss = 0.013170684592049812, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 47: Train Loss = 0.012981809884588295, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 48: Train Loss = 0.012654066146743075, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 49: Train Loss = 0.012455438107043226, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 50: Train Loss = 0.012339638563517098, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.011977540773000115, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 51: Train Loss = 0.01223278512185979, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 52: Train Loss = 0.012010807711108823, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 53: Train Loss = 0.011903954843912169, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 54: Train Loss = 0.0119113133106137, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 55: Train Loss = 0.011691802155191654, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss = 0.011101214293494959, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 56: Train Loss = 0.011451777836708265, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 57: Train Loss = 0.011387974441608537, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 58: Train Loss = 0.011160607980651277, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 59: Train Loss = 0.011027124057584834, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 60: Train Loss = 0.010884862367028946, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.010553027411800957, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 61: Train Loss = 0.010931738539137573, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 62: Train Loss = 0.010646302635981658, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 63: Train Loss = 0.010619424266096588, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 64: Train Loss = 0.010515789901750667, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 65: Train Loss = 0.010470758601326808, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.010071518343533868, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 66: Train Loss = 0.010415867275654156, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 67: Train Loss = 0.010513809239752939, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 68: Train Loss = 0.010223589028083832, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 69: Train Loss = 0.010208296076020348, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 70: Train Loss = 0.010218719960512402, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.009665513158749754, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 71: Train Loss = 0.009996311451856778, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 72: Train Loss = 0.009980842906320207, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 73: Train Loss = 0.009964931860705403, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 74: Train Loss = 0.010075371164097407, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 75: Train Loss = 0.009846967827772425, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.00955436749070465, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 76: Train Loss = 0.009848548961089594, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 77: Train Loss = 0.009765414312203353, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 78: Train Loss = 0.009674181857050579, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 79: Train Loss = 0.009682268774676546, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 80: Train Loss = 0.009725510795539785, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.009683279951633973, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Training Finished at epoch 80.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f634af500d90474d9e6def77be9ed520",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss = 0.5963666389722837, Recall = 0.9654002713704206, Aging Rate = 0.9633649932157394, Precision = 0.5010563380281691, f1 = 0.6597125637459434\n",
      "Epoch 2: Train Loss = 0.4771153873067698, Recall = 0.9884667571234735, Aging Rate = 0.871438263229308, Precision = 0.5671467497080576, f1 = 0.7207519168933959\n",
      "Epoch 3: Train Loss = 0.36071076617150327, Recall = 0.9762550881953868, Aging Rate = 0.6930122116689281, Precision = 0.7043563387175722, f1 = 0.8183110605629798\n",
      "Epoch 4: Train Loss = 0.28692419598513413, Recall = 0.9667571234735414, Aging Rate = 0.6166892808683854, Precision = 0.7838283828382838, f1 = 0.8657351154313487\n",
      "Epoch 5: Train Loss = 0.24756843813036644, Recall = 0.9620081411126187, Aging Rate = 0.5776797829036635, Precision = 0.8326482677627716, f1 = 0.8926660371419578\n",
      "Test Loss = 0.20773354120138057, Recall = 0.9762550881953868, Aging Rate = 0.5742876526458616, precision = 0.8499704666272888\n",
      "Model in epoch 5 is saved.\n",
      "\n",
      "Epoch 6: Train Loss = 0.19469759927675875, Recall = 0.9789687924016283, Aging Rate = 0.5685210312075983, Precision = 0.8609785202863962, f1 = 0.9161904761904763\n",
      "Epoch 7: Train Loss = 0.16825345918799028, Recall = 0.985753052917232, Aging Rate = 0.5641112618724559, Precision = 0.8737221888153939, f1 = 0.9263627669748168\n",
      "Epoch 8: Train Loss = 0.14400010031308053, Recall = 0.9830393487109905, Aging Rate = 0.5417232021709634, Precision = 0.9073262366938009, f1 = 0.9436665581243894\n",
      "Epoch 9: Train Loss = 0.12247719545943443, Recall = 0.9843962008141113, Aging Rate = 0.5329036635006784, Precision = 0.9236155315085932, f1 = 0.9530377668308704\n",
      "Epoch 10: Train Loss = 0.10612545276169376, Recall = 0.989145183175034, Aging Rate = 0.5264586160108549, Precision = 0.9394329896907216, f1 = 0.9636483807005949\n",
      "Test Loss = 0.09724878457221967, Recall = 0.9952510176390773, Aging Rate = 0.5305291723202171, precision = 0.9379795396419437\n",
      "Model in epoch 10 is saved.\n",
      "\n",
      "Epoch 11: Train Loss = 0.09213916921995711, Recall = 0.9932157394843962, Aging Rate = 0.5227272727272727, Precision = 0.9500324464633355, f1 = 0.9711442786069652\n",
      "Epoch 12: Train Loss = 0.08107644202266005, Recall = 0.9932157394843962, Aging Rate = 0.51797829036635, Precision = 0.9587426326129665, f1 = 0.9756747750749749\n",
      "Epoch 13: Train Loss = 0.07450090963368176, Recall = 0.9952510176390773, Aging Rate = 0.51797829036635, Precision = 0.9607072691552063, f1 = 0.9776741086304565\n",
      "Epoch 14: Train Loss = 0.06425270213514284, Recall = 0.9966078697421981, Aging Rate = 0.5128900949796472, Precision = 0.9715608465608465, f1 = 0.9839249832551908\n",
      "Epoch 15: Train Loss = 0.057600013906669426, Recall = 0.9972862957937585, Aging Rate = 0.510854816824966, Precision = 0.9760956175298805, f1 = 0.9865771812080537\n",
      "Test Loss = 0.052605531089958135, Recall = 0.9972862957937585, Aging Rate = 0.5098371777476255, precision = 0.9780439121756487\n",
      "Model in epoch 15 is saved.\n",
      "\n",
      "Epoch 16: Train Loss = 0.05231380584969449, Recall = 0.9972862957937585, Aging Rate = 0.510854816824966, Precision = 0.9760956175298805, f1 = 0.9865771812080537\n",
      "Epoch 17: Train Loss = 0.04984630160589716, Recall = 0.9972862957937585, Aging Rate = 0.5105156037991859, Precision = 0.9767441860465116, f1 = 0.986908358509567\n",
      "Epoch 18: Train Loss = 0.0436339552237512, Recall = 0.9972862957937585, Aging Rate = 0.5091587516960652, Precision = 0.9793471019320453, f1 = 0.988235294117647\n",
      "Epoch 19: Train Loss = 0.04168552186926435, Recall = 0.9966078697421981, Aging Rate = 0.5078018995929444, Precision = 0.9812959251837008, f1 = 0.9888926287445304\n",
      "Epoch 20: Train Loss = 0.037359232130982335, Recall = 0.9972862957937585, Aging Rate = 0.5078018995929444, Precision = 0.9819639278557114, f1 = 0.9895658027600134\n",
      "Test Loss = 0.036469952990597916, Recall = 0.9993215739484396, Aging Rate = 0.5101763907734057, precision = 0.9793882978723404\n",
      "Model in epoch 20 is saved.\n",
      "\n",
      "Epoch 21: Train Loss = 0.034314024662712696, Recall = 0.9986431478968792, Aging Rate = 0.508819538670285, Precision = 0.9813333333333333, f1 = 0.9899125756556826\n",
      "Epoch 22: Train Loss = 0.03206030717132211, Recall = 0.9986431478968792, Aging Rate = 0.5064450474898237, Precision = 0.9859343603482921, f1 = 0.9922480620155039\n",
      "Epoch 23: Train Loss = 0.029627877844843806, Recall = 0.9993215739484396, Aging Rate = 0.5074626865671642, Precision = 0.9846256684491979, f1 = 0.9919191919191919\n",
      "Epoch 24: Train Loss = 0.028325023151696577, Recall = 0.9993215739484396, Aging Rate = 0.5067842605156038, Precision = 0.9859437751004017, f1 = 0.9925876010781671\n",
      "Epoch 25: Train Loss = 0.02604105409482441, Recall = 0.9986431478968792, Aging Rate = 0.5061058344640434, Precision = 0.9865951742627346, f1 = 0.992582602832097\n",
      "Test Loss = 0.024235810210051337, Recall = 0.9993215739484396, Aging Rate = 0.5057666214382632, precision = 0.9879275653923542\n",
      "Model in epoch 25 is saved.\n",
      "\n",
      "Epoch 26: Train Loss = 0.024517075694450448, Recall = 0.9986431478968792, Aging Rate = 0.5061058344640434, Precision = 0.9865951742627346, f1 = 0.992582602832097\n",
      "Epoch 27: Train Loss = 0.02288556008522615, Recall = 1.0, Aging Rate = 0.5061058344640434, Precision = 0.9879356568364611, f1 = 0.9939312204989886\n",
      "Epoch 28: Train Loss = 0.021933180604160357, Recall = 0.9993215739484396, Aging Rate = 0.505427408412483, Precision = 0.9885906040268456, f1 = 0.9939271255060729\n",
      "Epoch 29: Train Loss = 0.02065671730396089, Recall = 0.9986431478968792, Aging Rate = 0.505427408412483, Precision = 0.9879194630872483, f1 = 0.9932523616734144\n",
      "Epoch 30: Train Loss = 0.0197349671474083, Recall = 0.9993215739484396, Aging Rate = 0.505427408412483, Precision = 0.9885906040268456, f1 = 0.9939271255060729\n",
      "Test Loss = 0.018386645833967985, Recall = 0.9993215739484396, Aging Rate = 0.505427408412483, precision = 0.9885906040268456\n",
      "Model in epoch 30 is saved.\n",
      "\n",
      "Epoch 31: Train Loss = 0.01881859567536994, Recall = 0.9993215739484396, Aging Rate = 0.5061058344640434, Precision = 0.9872654155495979, f1 = 0.9932569116655429\n",
      "Epoch 32: Train Loss = 0.017985359703669556, Recall = 0.9993215739484396, Aging Rate = 0.505427408412483, Precision = 0.9885906040268456, f1 = 0.9939271255060729\n",
      "Epoch 33: Train Loss = 0.017190066957001208, Recall = 1.0, Aging Rate = 0.5047489823609227, Precision = 0.9905913978494624, f1 = 0.9952734638757595\n",
      "Epoch 34: Train Loss = 0.016176232118146897, Recall = 0.9986431478968792, Aging Rate = 0.503731343283582, Precision = 0.9912457912457913, f1 = 0.9949307198377831\n",
      "Epoch 35: Train Loss = 0.015821684892396753, Recall = 1.0, Aging Rate = 0.5050881953867028, Precision = 0.989926124916051, f1 = 0.994937563280459\n",
      "Test Loss = 0.014550834918505888, Recall = 1.0, Aging Rate = 0.5040705563093623, precision = 0.9919246298788694\n",
      "Model in epoch 35 is saved.\n",
      "\n",
      "Epoch 36: Train Loss = 0.014666651450148107, Recall = 1.0, Aging Rate = 0.5040705563093623, Precision = 0.9919246298788694, f1 = 0.9959459459459459\n",
      "Epoch 37: Train Loss = 0.014527872076676338, Recall = 1.0, Aging Rate = 0.5044097693351425, Precision = 0.9912575655682583, f1 = 0.9956095913542722\n",
      "Epoch 38: Train Loss = 0.013803175776903714, Recall = 1.0, Aging Rate = 0.5033921302578019, Precision = 0.9932614555256065, f1 = 0.9966193373901285\n",
      "Epoch 39: Train Loss = 0.013595527624319658, Recall = 0.9993215739484396, Aging Rate = 0.5033921302578019, Precision = 0.9925876010781671, f1 = 0.9959432048681541\n",
      "Epoch 40: Train Loss = 0.012937038509317976, Recall = 1.0, Aging Rate = 0.5033921302578019, Precision = 0.9932614555256065, f1 = 0.9966193373901285\n",
      "Test Loss = 0.012114868494283958, Recall = 1.0, Aging Rate = 0.501696065128901, precision = 0.9966193373901284\n",
      "Model in epoch 40 is saved.\n",
      "\n",
      "Epoch 41: Train Loss = 0.012285452628295914, Recall = 1.0, Aging Rate = 0.5030529172320217, Precision = 0.9939312204989885, f1 = 0.9969563747040919\n",
      "Epoch 42: Train Loss = 0.011978687544124582, Recall = 0.9986431478968792, Aging Rate = 0.501696065128901, Precision = 0.9952670723461798, f1 = 0.9969522519471725\n",
      "Epoch 43: Train Loss = 0.01875374907642866, Recall = 0.9966078697421981, Aging Rate = 0.5006784260515604, Precision = 0.9952574525745257, f1 = 0.9959322033898305\n",
      "Epoch 44: Train Loss = 0.011666586893099504, Recall = 0.9993215739484396, Aging Rate = 0.5023744911804613, Precision = 0.9945982444294396, f1 = 0.9969543147208121\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45: Train Loss = 0.011302005876174128, Recall = 0.9986431478968792, Aging Rate = 0.501696065128901, Precision = 0.9952670723461798, f1 = 0.9969522519471725\n",
      "Test Loss = 0.010062571522733007, Recall = 1.0, Aging Rate = 0.5027137042062415, precision = 0.9946018893387314\n",
      "\n",
      "Epoch 46: Train Loss = 0.010319182832486513, Recall = 0.9993215739484396, Aging Rate = 0.5023744911804613, Precision = 0.9945982444294396, f1 = 0.9969543147208121\n",
      "Epoch 47: Train Loss = 0.01068947451259294, Recall = 0.9993215739484396, Aging Rate = 0.5013568521031208, Precision = 0.996617050067659, f1 = 0.9979674796747967\n",
      "Epoch 48: Train Loss = 0.009948474229938949, Recall = 1.0, Aging Rate = 0.5027137042062415, Precision = 0.9946018893387314, f1 = 0.9972936400541271\n",
      "Epoch 49: Train Loss = 0.009457513275512038, Recall = 0.9993215739484396, Aging Rate = 0.5013568521031208, Precision = 0.996617050067659, f1 = 0.9979674796747967\n",
      "Epoch 50: Train Loss = 0.010859971457531264, Recall = 0.9993215739484396, Aging Rate = 0.5010176390773405, Precision = 0.997291807718348, f1 = 0.9983056590986107\n",
      "Test Loss = 0.009250213891227339, Recall = 0.9993215739484396, Aging Rate = 0.5010176390773405, precision = 0.997291807718348\n",
      "Model in epoch 50 is saved.\n",
      "\n",
      "Epoch 51: Train Loss = 0.009030307391329873, Recall = 0.9993215739484396, Aging Rate = 0.5013568521031208, Precision = 0.996617050067659, f1 = 0.9979674796747967\n",
      "Epoch 52: Train Loss = 0.008736174812526512, Recall = 0.9993215739484396, Aging Rate = 0.5020352781546812, Precision = 0.9952702702702703, f1 = 0.9972918077183479\n",
      "Epoch 53: Train Loss = 0.008221645726730068, Recall = 1.0, Aging Rate = 0.5020352781546812, Precision = 0.995945945945946, f1 = 0.997968855788761\n",
      "Epoch 54: Train Loss = 0.00833175524821558, Recall = 0.9993215739484396, Aging Rate = 0.5010176390773405, Precision = 0.997291807718348, f1 = 0.9983056590986107\n",
      "Epoch 55: Train Loss = 0.008086422007003978, Recall = 1.0, Aging Rate = 0.501696065128901, Precision = 0.9966193373901284, f1 = 0.998306806637318\n",
      "Test Loss = 0.007286217167286084, Recall = 0.9993215739484396, Aging Rate = 0.5010176390773405, precision = 0.997291807718348\n",
      "\n",
      "Epoch 56: Train Loss = 0.007747857304943252, Recall = 0.9993215739484396, Aging Rate = 0.501696065128901, Precision = 0.9959432048681541, f1 = 0.9976295292922451\n",
      "Epoch 57: Train Loss = 0.007412744667052495, Recall = 1.0, Aging Rate = 0.5013568521031208, Precision = 0.9972936400541272, f1 = 0.9986449864498645\n",
      "Epoch 58: Train Loss = 0.007333099388415082, Recall = 0.9993215739484396, Aging Rate = 0.501696065128901, Precision = 0.9959432048681541, f1 = 0.9976295292922451\n",
      "Epoch 59: Train Loss = 0.007148586547196801, Recall = 0.9993215739484396, Aging Rate = 0.5010176390773405, Precision = 0.997291807718348, f1 = 0.9983056590986107\n",
      "Epoch 60: Train Loss = 0.0074900750262255865, Recall = 1.0, Aging Rate = 0.501696065128901, Precision = 0.9966193373901284, f1 = 0.998306806637318\n",
      "Test Loss = 0.006396069812607033, Recall = 1.0, Aging Rate = 0.5013568521031208, precision = 0.9972936400541272\n",
      "Model in epoch 60 is saved.\n",
      "\n",
      "Epoch 61: Train Loss = 0.006770419801005353, Recall = 0.9993215739484396, Aging Rate = 0.5013568521031208, Precision = 0.996617050067659, f1 = 0.9979674796747967\n",
      "Epoch 62: Train Loss = 0.007917445559898742, Recall = 0.9993215739484396, Aging Rate = 0.501696065128901, Precision = 0.9959432048681541, f1 = 0.9976295292922451\n",
      "Epoch 63: Train Loss = 0.006704255521677818, Recall = 0.9993215739484396, Aging Rate = 0.5013568521031208, Precision = 0.996617050067659, f1 = 0.9979674796747967\n",
      "Epoch 64: Train Loss = 0.006184169208805305, Recall = 1.0, Aging Rate = 0.5013568521031208, Precision = 0.9972936400541272, f1 = 0.9986449864498645\n",
      "Epoch 65: Train Loss = 0.006160764754929907, Recall = 0.9993215739484396, Aging Rate = 0.5006784260515604, Precision = 0.9979674796747967, f1 = 0.9986440677966101\n",
      "Test Loss = 0.005600152082306559, Recall = 1.0, Aging Rate = 0.5013568521031208, precision = 0.9972936400541272\n",
      "\n",
      "Epoch 66: Train Loss = 0.006346264742870829, Recall = 1.0, Aging Rate = 0.501696065128901, Precision = 0.9966193373901284, f1 = 0.998306806637318\n",
      "Epoch 67: Train Loss = 0.00587885995574014, Recall = 1.0, Aging Rate = 0.5010176390773405, Precision = 0.997968855788761, f1 = 0.9989833954591665\n",
      "Epoch 68: Train Loss = 0.005554771725608989, Recall = 1.0, Aging Rate = 0.5013568521031208, Precision = 0.9972936400541272, f1 = 0.9986449864498645\n",
      "Epoch 69: Train Loss = 0.005360573144956414, Recall = 0.9993215739484396, Aging Rate = 0.5006784260515604, Precision = 0.9979674796747967, f1 = 0.9986440677966101\n",
      "Epoch 70: Train Loss = 0.005565031222399486, Recall = 1.0, Aging Rate = 0.5013568521031208, Precision = 0.9972936400541272, f1 = 0.9986449864498645\n",
      "Test Loss = 0.004863809646022591, Recall = 0.9993215739484396, Aging Rate = 0.5006784260515604, precision = 0.9979674796747967\n",
      "Model in epoch 70 is saved.\n",
      "\n",
      "Epoch 71: Train Loss = 0.0053214013015439425, Recall = 0.9993215739484396, Aging Rate = 0.5006784260515604, Precision = 0.9979674796747967, f1 = 0.9986440677966101\n",
      "Epoch 72: Train Loss = 0.005463183574676084, Recall = 0.9993215739484396, Aging Rate = 0.5006784260515604, Precision = 0.9979674796747967, f1 = 0.9986440677966101\n",
      "Epoch 73: Train Loss = 0.004869678995252639, Recall = 1.0, Aging Rate = 0.5013568521031208, Precision = 0.9972936400541272, f1 = 0.9986449864498645\n",
      "Epoch 74: Train Loss = 0.005011279285529039, Recall = 0.9993215739484396, Aging Rate = 0.5006784260515604, Precision = 0.9979674796747967, f1 = 0.9986440677966101\n",
      "Epoch 75: Train Loss = 0.0046580327059340685, Recall = 1.0, Aging Rate = 0.5013568521031208, Precision = 0.9972936400541272, f1 = 0.9986449864498645\n",
      "Test Loss = 0.004572280775621379, Recall = 1.0, Aging Rate = 0.5013568521031208, precision = 0.9972936400541272\n",
      "\n",
      "Epoch 76: Train Loss = 0.004688167880103498, Recall = 1.0, Aging Rate = 0.501696065128901, Precision = 0.9966193373901284, f1 = 0.998306806637318\n",
      "Epoch 77: Train Loss = 0.004785847815600388, Recall = 0.9993215739484396, Aging Rate = 0.5010176390773405, Precision = 0.997291807718348, f1 = 0.9983056590986107\n",
      "Epoch 78: Train Loss = 0.004276834161676658, Recall = 1.0, Aging Rate = 0.5010176390773405, Precision = 0.997968855788761, f1 = 0.9989833954591665\n",
      "Epoch 79: Train Loss = 0.004450339228458187, Recall = 1.0, Aging Rate = 0.5010176390773405, Precision = 0.997968855788761, f1 = 0.9989833954591665\n",
      "Epoch 80: Train Loss = 0.004323947408616927, Recall = 1.0, Aging Rate = 0.5003392130257802, Precision = 0.9993220338983051, f1 = 0.9996609020006783\n",
      "Test Loss = 0.004008453406154695, Recall = 1.0, Aging Rate = 0.5010176390773405, precision = 0.997968855788761\n",
      "Model in epoch 80 is saved.\n",
      "\n",
      "Epoch 81: Train Loss = 0.004306435898727304, Recall = 1.0, Aging Rate = 0.5010176390773405, Precision = 0.997968855788761, f1 = 0.9989833954591665\n",
      "Epoch 82: Train Loss = 0.004208546949125917, Recall = 0.9993215739484396, Aging Rate = 0.5003392130257802, Precision = 0.9986440677966102, f1 = 0.9989827060020345\n",
      "Epoch 83: Train Loss = 0.003933105519195587, Recall = 1.0, Aging Rate = 0.5010176390773405, Precision = 0.997968855788761, f1 = 0.9989833954591665\n",
      "Epoch 84: Train Loss = 0.0040099621619150965, Recall = 1.0, Aging Rate = 0.5010176390773405, Precision = 0.997968855788761, f1 = 0.9989833954591665\n",
      "Epoch 85: Train Loss = 0.003922963633155892, Recall = 1.0, Aging Rate = 0.5010176390773405, Precision = 0.997968855788761, f1 = 0.9989833954591665\n",
      "Test Loss = 0.0035439582251415437, Recall = 1.0, Aging Rate = 0.5006784260515604, precision = 0.9986449864498645\n",
      "Model in epoch 85 is saved.\n",
      "\n",
      "Epoch 86: Train Loss = 0.003814652437847923, Recall = 1.0, Aging Rate = 0.5003392130257802, Precision = 0.9993220338983051, f1 = 0.9996609020006783\n",
      "Epoch 87: Train Loss = 0.003534979627971895, Recall = 1.0, Aging Rate = 0.5006784260515604, Precision = 0.9986449864498645, f1 = 0.9993220338983051\n",
      "Epoch 88: Train Loss = 0.004267866052449441, Recall = 1.0, Aging Rate = 0.501696065128901, Precision = 0.9966193373901284, f1 = 0.998306806637318\n",
      "Epoch 89: Train Loss = 0.0034784064098233496, Recall = 1.0, Aging Rate = 0.5006784260515604, Precision = 0.9986449864498645, f1 = 0.9993220338983051\n",
      "Epoch 90: Train Loss = 0.0033158333713439606, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0030391536239743754, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "Model in epoch 90 is saved.\n",
      "\n",
      "Epoch 91: Train Loss = 0.003395996160433707, Recall = 1.0, Aging Rate = 0.5006784260515604, Precision = 0.9986449864498645, f1 = 0.9993220338983051\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 92: Train Loss = 0.0032525146270285803, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 93: Train Loss = 0.0034759215027437606, Recall = 1.0, Aging Rate = 0.5003392130257802, Precision = 0.9993220338983051, f1 = 0.9996609020006783\n",
      "Epoch 94: Train Loss = 0.005435771780345068, Recall = 0.9993215739484396, Aging Rate = 0.5003392130257802, Precision = 0.9986440677966102, f1 = 0.9989827060020345\n",
      "Epoch 95: Train Loss = 0.0033214015123564523, Recall = 1.0, Aging Rate = 0.5010176390773405, Precision = 0.997968855788761, f1 = 0.9989833954591665\n",
      "Test Loss = 0.002866950322048716, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 96: Train Loss = 0.002991400199741368, Recall = 1.0, Aging Rate = 0.5003392130257802, Precision = 0.9993220338983051, f1 = 0.9996609020006783\n",
      "Epoch 97: Train Loss = 0.0030011843446957447, Recall = 1.0, Aging Rate = 0.5003392130257802, Precision = 0.9993220338983051, f1 = 0.9996609020006783\n",
      "Epoch 98: Train Loss = 0.0029184224377111424, Recall = 1.0, Aging Rate = 0.5006784260515604, Precision = 0.9986449864498645, f1 = 0.9993220338983051\n",
      "Epoch 99: Train Loss = 0.002821516564639988, Recall = 1.0, Aging Rate = 0.5003392130257802, Precision = 0.9993220338983051, f1 = 0.9996609020006783\n",
      "Epoch 100: Train Loss = 0.0029136741091513037, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0025314654437180615, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e55005eb1b06457c89361b769eb4ff8e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df491777248344d488c644cd2ec7c492",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss = 0.6530256920097941, Recall = 0.8756906077348067, Aging Rate = 0.8570441988950276, Precision = 0.5108783239323127, f1 = 0.6452926208651399\n",
      "Epoch 2: Train Loss = 0.5778695167098915, Recall = 0.9972375690607734, Aging Rate = 0.9330110497237569, Precision = 0.5344189489267209, f1 = 0.6959036144578312\n",
      "Epoch 3: Train Loss = 0.5081801358507483, Recall = 0.9737569060773481, Aging Rate = 0.7099447513812155, Precision = 0.6857976653696498, f1 = 0.8047945205479452\n",
      "Epoch 4: Train Loss = 0.43306513599927915, Recall = 0.9488950276243094, Aging Rate = 0.5973756906077348, Precision = 0.7942196531791907, f1 = 0.8646947765890497\n",
      "Epoch 5: Train Loss = 0.37259323499808655, Recall = 0.9212707182320442, Aging Rate = 0.5511049723756906, Precision = 0.8358395989974937, f1 = 0.8764783180026281\n",
      "Test Loss = 0.3271939202896139, Recall = 0.9337016574585635, Aging Rate = 0.5331491712707183, precision = 0.8756476683937824\n",
      "Model in epoch 5 is saved.\n",
      "\n",
      "Epoch 6: Train Loss = 0.30825289696948965, Recall = 0.9378453038674033, Aging Rate = 0.5359116022099447, Precision = 0.875, f1 = 0.9053333333333333\n",
      "Epoch 7: Train Loss = 0.26912141307282844, Recall = 0.9281767955801105, Aging Rate = 0.5158839779005525, Precision = 0.8995983935742972, f1 = 0.9136641740312712\n",
      "Epoch 8: Train Loss = 0.23815173083576707, Recall = 0.9350828729281768, Aging Rate = 0.5138121546961326, Precision = 0.9099462365591398, f1 = 0.9223433242506811\n",
      "Epoch 9: Train Loss = 0.21616016855226697, Recall = 0.93646408839779, Aging Rate = 0.5075966850828729, Precision = 0.9224489795918367, f1 = 0.9294037011651817\n",
      "Epoch 10: Train Loss = 0.19770178709240907, Recall = 0.9502762430939227, Aging Rate = 0.5179558011049724, Precision = 0.9173333333333333, f1 = 0.9335142469470827\n",
      "Test Loss = 0.18649563876634145, Recall = 0.9433701657458563, Aging Rate = 0.5041436464088398, precision = 0.9356164383561644\n",
      "Model in epoch 10 is saved.\n",
      "\n",
      "Epoch 11: Train Loss = 0.1813468358464004, Recall = 0.9433701657458563, Aging Rate = 0.5013812154696132, Precision = 0.940771349862259, f1 = 0.9420689655172414\n",
      "Epoch 12: Train Loss = 0.16688075859243698, Recall = 0.9558011049723757, Aging Rate = 0.5069060773480663, Precision = 0.9427792915531336, f1 = 0.9492455418381345\n",
      "Epoch 13: Train Loss = 0.15752565317391032, Recall = 0.9502762430939227, Aging Rate = 0.4979281767955801, Precision = 0.9542302357836339, f1 = 0.9522491349480969\n",
      "Epoch 14: Train Loss = 0.1434027593768104, Recall = 0.9599447513812155, Aging Rate = 0.5034530386740331, Precision = 0.953360768175583, f1 = 0.9566414315209911\n",
      "Epoch 15: Train Loss = 0.1335795278048647, Recall = 0.9723756906077348, Aging Rate = 0.513121546961326, Precision = 0.9475100942126514, f1 = 0.9597818677573278\n",
      "Test Loss = 0.125916993420427, Recall = 0.9682320441988951, Aging Rate = 0.5041436464088398, precision = 0.9602739726027397\n",
      "Model in epoch 15 is saved.\n",
      "\n",
      "Epoch 16: Train Loss = 0.12327279842031595, Recall = 0.9640883977900553, Aging Rate = 0.5, Precision = 0.9640883977900553, f1 = 0.9640883977900553\n",
      "Epoch 17: Train Loss = 0.11323662480925986, Recall = 0.9751381215469613, Aging Rate = 0.5062154696132597, Precision = 0.9631650750341064, f1 = 0.9691146190803019\n",
      "Epoch 18: Train Loss = 0.10507793298495409, Recall = 0.988950276243094, Aging Rate = 0.5151933701657458, Precision = 0.9597855227882037, f1 = 0.9741496598639456\n",
      "Epoch 19: Train Loss = 0.09582399930907877, Recall = 0.9820441988950276, Aging Rate = 0.5048342541436464, Precision = 0.9726402188782489, f1 = 0.977319587628866\n",
      "Epoch 20: Train Loss = 0.08930466665747416, Recall = 0.9903314917127072, Aging Rate = 0.5089779005524862, Precision = 0.9728629579375848, f1 = 0.9815195071868583\n",
      "Test Loss = 0.08353023103422881, Recall = 0.9903314917127072, Aging Rate = 0.5089779005524862, precision = 0.9728629579375848\n",
      "Model in epoch 20 is saved.\n",
      "\n",
      "Epoch 21: Train Loss = 0.0829975512804906, Recall = 0.9903314917127072, Aging Rate = 0.5089779005524862, Precision = 0.9728629579375848, f1 = 0.9815195071868583\n",
      "Epoch 22: Train Loss = 0.07929630322350982, Recall = 0.9875690607734806, Aging Rate = 0.5041436464088398, Precision = 0.9794520547945206, f1 = 0.983493810178817\n",
      "Epoch 23: Train Loss = 0.07136341707153215, Recall = 0.9917127071823204, Aging Rate = 0.5062154696132597, Precision = 0.9795361527967258, f1 = 0.9855868222374742\n",
      "Epoch 24: Train Loss = 0.06533679090316782, Recall = 0.9917127071823204, Aging Rate = 0.5069060773480663, Precision = 0.9782016348773842, f1 = 0.9849108367626885\n",
      "Epoch 25: Train Loss = 0.06008547778596371, Recall = 0.9917127071823204, Aging Rate = 0.505524861878453, Precision = 0.9808743169398907, f1 = 0.9862637362637362\n",
      "Test Loss = 0.05694216926124215, Recall = 0.9917127071823204, Aging Rate = 0.505524861878453, precision = 0.9808743169398907\n",
      "Model in epoch 25 is saved.\n",
      "\n",
      "Epoch 26: Train Loss = 0.05633303299752059, Recall = 0.9917127071823204, Aging Rate = 0.5041436464088398, Precision = 0.9835616438356164, f1 = 0.9876203576341128\n",
      "Epoch 27: Train Loss = 0.052211882978760074, Recall = 0.994475138121547, Aging Rate = 0.505524861878453, Precision = 0.9836065573770492, f1 = 0.989010989010989\n",
      "Epoch 28: Train Loss = 0.04864154567746497, Recall = 0.9958563535911602, Aging Rate = 0.5013812154696132, Precision = 0.9931129476584022, f1 = 0.9944827586206897\n",
      "Epoch 29: Train Loss = 0.045679731448875605, Recall = 0.9958563535911602, Aging Rate = 0.5006906077348067, Precision = 0.9944827586206897, f1 = 0.9951690821256038\n",
      "Epoch 30: Train Loss = 0.0425354685243322, Recall = 0.9986187845303868, Aging Rate = 0.5041436464088398, Precision = 0.9904109589041096, f1 = 0.9944979367262724\n",
      "Test Loss = 0.040241128543793164, Recall = 0.9986187845303868, Aging Rate = 0.5020718232044199, precision = 0.9944979367262724\n",
      "Model in epoch 30 is saved.\n",
      "\n",
      "Epoch 31: Train Loss = 0.040265032429844964, Recall = 1.0, Aging Rate = 0.5034530386740331, Precision = 0.9931412894375857, f1 = 0.9965588437715073\n",
      "Epoch 32: Train Loss = 0.037966985749440955, Recall = 1.0, Aging Rate = 0.5034530386740331, Precision = 0.9931412894375857, f1 = 0.9965588437715073\n",
      "Epoch 33: Train Loss = 0.035317132192874814, Recall = 0.9986187845303868, Aging Rate = 0.5013812154696132, Precision = 0.9958677685950413, f1 = 0.9972413793103448\n",
      "Epoch 34: Train Loss = 0.03287041820688636, Recall = 1.0, Aging Rate = 0.5020718232044199, Precision = 0.9958734525447043, f1 = 0.9979324603721571\n",
      "Epoch 35: Train Loss = 0.031040472848063015, Recall = 1.0, Aging Rate = 0.5020718232044199, Precision = 0.9958734525447043, f1 = 0.9979324603721571\n",
      "Test Loss = 0.029524150062661146, Recall = 1.0, Aging Rate = 0.5020718232044199, precision = 0.9958734525447043\n",
      "Model in epoch 35 is saved.\n",
      "\n",
      "Epoch 36: Train Loss = 0.029403073193495114, Recall = 1.0, Aging Rate = 0.5020718232044199, Precision = 0.9958734525447043, f1 = 0.9979324603721571\n",
      "Epoch 37: Train Loss = 0.027410103136786768, Recall = 1.0, Aging Rate = 0.5020718232044199, Precision = 0.9958734525447043, f1 = 0.9979324603721571\n",
      "Epoch 38: Train Loss = 0.026012867977276692, Recall = 1.0, Aging Rate = 0.5020718232044199, Precision = 0.9958734525447043, f1 = 0.9979324603721571\n",
      "Epoch 39: Train Loss = 0.02497315051764744, Recall = 1.0, Aging Rate = 0.5020718232044199, Precision = 0.9958734525447043, f1 = 0.9979324603721571\n",
      "Epoch 40: Train Loss = 0.023461012344663315, Recall = 1.0, Aging Rate = 0.5020718232044199, Precision = 0.9958734525447043, f1 = 0.9979324603721571\n",
      "Test Loss = 0.02248641709637576, Recall = 1.0, Aging Rate = 0.5020718232044199, precision = 0.9958734525447043\n",
      "\n",
      "Epoch 41: Train Loss = 0.022788626563771324, Recall = 1.0, Aging Rate = 0.5020718232044199, Precision = 0.9958734525447043, f1 = 0.9979324603721571\n",
      "Epoch 42: Train Loss = 0.021185959694464563, Recall = 1.0, Aging Rate = 0.5006906077348067, Precision = 0.9986206896551724, f1 = 0.9993098688750862\n",
      "Epoch 43: Train Loss = 0.019939985157129515, Recall = 1.0, Aging Rate = 0.5006906077348067, Precision = 0.9986206896551724, f1 = 0.9993098688750862\n",
      "Epoch 44: Train Loss = 0.01896862771094504, Recall = 1.0, Aging Rate = 0.5006906077348067, Precision = 0.9986206896551724, f1 = 0.9993098688750862\n",
      "Epoch 45: Train Loss = 0.01828590897812369, Recall = 1.0, Aging Rate = 0.5006906077348067, Precision = 0.9986206896551724, f1 = 0.9993098688750862\n",
      "Test Loss = 0.017415436890326152, Recall = 1.0, Aging Rate = 0.5006906077348067, precision = 0.9986206896551724\n",
      "Model in epoch 45 is saved.\n",
      "\n",
      "Epoch 46: Train Loss = 0.017779951843752098, Recall = 1.0, Aging Rate = 0.5020718232044199, Precision = 0.9958734525447043, f1 = 0.9979324603721571\n",
      "Epoch 47: Train Loss = 0.016700041547252988, Recall = 1.0, Aging Rate = 0.5013812154696132, Precision = 0.9972451790633609, f1 = 0.9986206896551724\n",
      "Epoch 48: Train Loss = 0.015812086157541906, Recall = 1.0, Aging Rate = 0.5006906077348067, Precision = 0.9986206896551724, f1 = 0.9993098688750862\n",
      "Epoch 49: Train Loss = 0.01501704769553771, Recall = 1.0, Aging Rate = 0.5006906077348067, Precision = 0.9986206896551724, f1 = 0.9993098688750862\n",
      "Epoch 50: Train Loss = 0.014371567627013717, Recall = 1.0, Aging Rate = 0.5006906077348067, Precision = 0.9986206896551724, f1 = 0.9993098688750862\n",
      "Test Loss = 0.013848145039577181, Recall = 1.0, Aging Rate = 0.5006906077348067, precision = 0.9986206896551724\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 51: Train Loss = 0.013968567713806971, Recall = 1.0, Aging Rate = 0.5006906077348067, Precision = 0.9986206896551724, f1 = 0.9993098688750862\n",
      "Epoch 52: Train Loss = 0.013386716808897355, Recall = 1.0, Aging Rate = 0.5006906077348067, Precision = 0.9986206896551724, f1 = 0.9993098688750862\n",
      "Epoch 53: Train Loss = 0.012756601248698011, Recall = 1.0, Aging Rate = 0.5006906077348067, Precision = 0.9986206896551724, f1 = 0.9993098688750862\n",
      "Epoch 54: Train Loss = 0.01216603161057056, Recall = 1.0, Aging Rate = 0.5006906077348067, Precision = 0.9986206896551724, f1 = 0.9993098688750862\n",
      "Epoch 55: Train Loss = 0.011738383743747327, Recall = 1.0, Aging Rate = 0.5006906077348067, Precision = 0.9986206896551724, f1 = 0.9993098688750862\n",
      "Test Loss = 0.01134286045472431, Recall = 1.0, Aging Rate = 0.5006906077348067, precision = 0.9986206896551724\n",
      "\n",
      "Epoch 56: Train Loss = 0.011251454226137525, Recall = 1.0, Aging Rate = 0.5006906077348067, Precision = 0.9986206896551724, f1 = 0.9993098688750862\n",
      "Epoch 57: Train Loss = 0.011664548641821957, Recall = 1.0, Aging Rate = 0.5006906077348067, Precision = 0.9986206896551724, f1 = 0.9993098688750862\n",
      "Epoch 58: Train Loss = 0.010918074184565583, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 59: Train Loss = 0.010154814503119631, Recall = 1.0, Aging Rate = 0.5006906077348067, Precision = 0.9986206896551724, f1 = 0.9993098688750862\n",
      "Epoch 60: Train Loss = 0.009658376825201577, Recall = 1.0, Aging Rate = 0.5006906077348067, Precision = 0.9986206896551724, f1 = 0.9993098688750862\n",
      "Test Loss = 0.009366653867333468, Recall = 1.0, Aging Rate = 0.5006906077348067, precision = 0.9986206896551724\n",
      "\n",
      "Epoch 61: Train Loss = 0.009339914855274542, Recall = 1.0, Aging Rate = 0.5006906077348067, Precision = 0.9986206896551724, f1 = 0.9993098688750862\n",
      "Epoch 62: Train Loss = 0.008990298771397185, Recall = 1.0, Aging Rate = 0.5006906077348067, Precision = 0.9986206896551724, f1 = 0.9993098688750862\n",
      "Epoch 63: Train Loss = 0.008713283321372547, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 64: Train Loss = 0.008393763026186569, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 65: Train Loss = 0.008097019859522745, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.007881764744444446, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "Model in epoch 65 is saved.\n",
      "\n",
      "Epoch 66: Train Loss = 0.007864244040410492, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 67: Train Loss = 0.007599858634009217, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 68: Train Loss = 0.007393622626351111, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 69: Train Loss = 0.007169124660035852, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 70: Train Loss = 0.006998135403405813, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.006789699389769063, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 71: Train Loss = 0.006797755584738202, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 72: Train Loss = 0.006699698518586051, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 73: Train Loss = 0.006407288370077699, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 74: Train Loss = 0.0062279651270798556, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 75: Train Loss = 0.006216287368507181, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.005942864632954337, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 76: Train Loss = 0.005891427374573537, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 77: Train Loss = 0.00572540161575484, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 78: Train Loss = 0.005590898660783404, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 79: Train Loss = 0.005404721828465716, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 80: Train Loss = 0.005299099067545069, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0051659648113714235, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 81: Train Loss = 0.005164401379004841, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 82: Train Loss = 0.005021847033286621, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 83: Train Loss = 0.004955536317985855, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 84: Train Loss = 0.004890832647382801, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 85: Train Loss = 0.004695096830142796, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.004586333751122761, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 86: Train Loss = 0.004589016400071797, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 87: Train Loss = 0.004472550148792689, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 88: Train Loss = 0.004455347365998143, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 89: Train Loss = 0.004279175045184832, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 90: Train Loss = 0.0041973146440162845, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.004079463937993866, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 91: Train Loss = 0.004079510587092633, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 92: Train Loss = 0.004049700826987912, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 93: Train Loss = 0.0038851511269776943, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 94: Train Loss = 0.003839626049015733, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 95: Train Loss = 0.003780028497213652, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0037108831730213285, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 96: Train Loss = 0.0036923082671462665, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 97: Train Loss = 0.003610349839131312, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 98: Train Loss = 0.0035442472499851857, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 99: Train Loss = 0.003453281883006267, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 100: Train Loss = 0.003457188036405991, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0033590776732613367, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1bf9718d57f044c3ba12bd9cef77c17f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss = 0.28542295365827763, Recall = 0.9115351257588898, Aging Rate = 0.5490026019080659, Precision = 0.830173775671406, f1 = 0.8689541132699463\n",
      "Epoch 2: Train Loss = 0.0862926377754106, Recall = 0.9774501300954033, Aging Rate = 0.5060711188204683, Precision = 0.9657240788346186, f1 = 0.971551724137931\n",
      "Epoch 3: Train Loss = 0.043121423521818206, Recall = 0.9852558542931483, Aging Rate = 0.4978317432784042, Precision = 0.9895470383275261, f1 = 0.9873967840069534\n",
      "Epoch 4: Train Loss = 0.0316187279090505, Recall = 0.9913269731136166, Aging Rate = 0.49956634865568084, Precision = 0.9921875, f1 = 0.9917570498915401\n",
      "Epoch 5: Train Loss = 0.05378370787040358, Recall = 0.9800520381613183, Aging Rate = 0.497398091934085, Precision = 0.985178727114211, f1 = 0.9826086956521738\n",
      "Test Loss = 0.009386951691840176, Recall = 0.997398091934085, Aging Rate = 0.4986990459670425, precision = 1.0\n",
      "Model in epoch 5 is saved.\n",
      "\n",
      "Epoch 6: Train Loss = 0.0059129745123545204, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 7: Train Loss = 0.0020917431480383117, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 8: Train Loss = 0.0013524132968100832, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 9: Train Loss = 0.00110567248436129, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 10: Train Loss = 0.0010412357376398905, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0009247244320868806, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "Model in epoch 10 is saved.\n",
      "\n",
      "Epoch 11: Train Loss = 0.001004547666702161, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 12: Train Loss = 0.0009365577694167547, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 13: Train Loss = 0.0009228968770953633, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 14: Train Loss = 0.000903926906529297, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 15: Train Loss = 0.00089622301835864, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0008143431402347879, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 16: Train Loss = 0.0009033231915945348, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 17: Train Loss = 0.0009029262175873174, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 18: Train Loss = 0.0009207154133664856, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 19: Train Loss = 0.0009455536632261062, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 20: Train Loss = 0.0009150715562968708, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0007947063707994541, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 21: Train Loss = 0.0009287531102680563, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 22: Train Loss = 0.0009000949833551398, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 23: Train Loss = 0.0009163862978075312, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 24: Train Loss = 0.0009307703372023129, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 25: Train Loss = 0.0009419040865930612, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0008498688447729386, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 26: Train Loss = 0.0009436425158839762, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 27: Train Loss = 0.0009607656824078204, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 28: Train Loss = 0.000912183340614038, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 29: Train Loss = 0.0009413580992590384, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 30: Train Loss = 0.0010147314500616959, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0009045850849758718, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 31: Train Loss = 0.0009865601480827835, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 32: Train Loss = 0.0013013014960672597, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 33: Train Loss = 0.0008752695710863965, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 34: Train Loss = 0.0008196865431786695, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 35: Train Loss = 0.0008328101483229402, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0010265453409844588, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 36: Train Loss = 0.0010201315917181706, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 37: Train Loss = 0.07064320344973843, Recall = 0.9791847354726799, Aging Rate = 0.5047701647875108, Precision = 0.9699312714776632, f1 = 0.9745360379801468\n",
      "Epoch 38: Train Loss = 0.05077743570498818, Recall = 0.9861231569817867, Aging Rate = 0.5017346053772767, Precision = 0.982713915298185, f1 = 0.9844155844155845\n",
      "Epoch 39: Train Loss = 0.013022355689664741, Recall = 0.9956634865568084, Aging Rate = 0.5, Precision = 0.9956634865568084, f1 = 0.9956634865568084\n",
      "Epoch 40: Train Loss = 0.002301585591204297, Recall = 0.9991326973113617, Aging Rate = 0.49956634865568084, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.001262211415367998, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 41: Train Loss = 0.0014007089329072474, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 42: Train Loss = 0.0005202584211557284, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 43: Train Loss = 0.00043402327064194095, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 44: Train Loss = 0.0004281598909974909, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 45: Train Loss = 0.0004614576464645114, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.00042518840659507473, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 46: Train Loss = 0.0004714399667865462, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 47: Train Loss = 0.000498218934448696, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 48: Train Loss = 0.0005187156966798575, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 49: Train Loss = 0.0005500500929913042, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 50: Train Loss = 0.0005702095760308425, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0005304219512956387, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 51: Train Loss = 0.0006206425844350374, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 52: Train Loss = 0.0006357941189924679, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 53: Train Loss = 0.0006762634764295411, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 54: Train Loss = 0.0006841083407749767, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 55: Train Loss = 0.0007125799236735345, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0006295300434333017, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 56: Train Loss = 0.0007274184932937104, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 57: Train Loss = 0.0063859524882010025, Recall = 0.9991326973113617, Aging Rate = 0.5008673026886383, Precision = 0.9974025974025974, f1 = 0.9982668977469671\n",
      "Epoch 58: Train Loss = 0.01849828346338404, Recall = 0.9913269731136166, Aging Rate = 0.5, Precision = 0.9913269731136166, f1 = 0.9913269731136166\n",
      "Epoch 59: Train Loss = 0.01681504921603611, Recall = 0.9939288811795317, Aging Rate = 0.5013009540329575, Precision = 0.9913494809688581, f1 = 0.992637505413599\n",
      "Epoch 60: Train Loss = 0.012979136733812784, Recall = 0.99479618386817, Aging Rate = 0.4991326973113617, Precision = 0.996524761077324, f1 = 0.9956597222222222\n",
      "Test Loss = 0.017614276761401943, Recall = 1.0, Aging Rate = 0.5099739809193409, precision = 0.9804421768707483\n",
      "\n",
      "Training Finished at epoch 60.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a3a5a799741e4ff2bc1ab6323dfd27e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss = 0.34719061844094096, Recall = 0.9436619718309859, Aging Rate = 0.6710853355426678, Precision = 0.7030864197530864, f1 = 0.8058012026883621\n",
      "Epoch 2: Train Loss = 0.11594302712012987, Recall = 0.9817729908864954, Aging Rate = 0.5223695111847556, Precision = 0.9397303727200634, f1 = 0.960291734197731\n",
      "Epoch 3: Train Loss = 0.06729450112003478, Recall = 0.9817729908864954, Aging Rate = 0.5053852526926264, Precision = 0.9713114754098361, f1 = 0.9765142150803462\n",
      "Epoch 4: Train Loss = 0.05411111227643322, Recall = 0.9900579950289975, Aging Rate = 0.5074565037282519, Precision = 0.9755102040816327, f1 = 0.9827302631578947\n",
      "Epoch 5: Train Loss = 0.0428796410591472, Recall = 0.9900579950289975, Aging Rate = 0.5016570008285004, Precision = 0.9867877786952931, f1 = 0.988420181968569\n",
      "Test Loss = 0.0178247872676759, Recall = 1.0, Aging Rate = 0.5008285004142502, precision = 0.9983457402812241\n",
      "Model in epoch 5 is saved.\n",
      "\n",
      "Epoch 6: Train Loss = 0.012522433954657556, Recall = 1.0, Aging Rate = 0.5004142502071252, Precision = 0.9991721854304636, f1 = 0.9995859213250518\n",
      "Epoch 7: Train Loss = 0.01036518227942473, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 8: Train Loss = 0.010536031459566967, Recall = 1.0, Aging Rate = 0.5004142502071252, Precision = 0.9991721854304636, f1 = 0.9995859213250518\n",
      "Epoch 9: Train Loss = 0.010309432335768911, Recall = 1.0, Aging Rate = 0.5004142502071252, Precision = 0.9991721854304636, f1 = 0.9995859213250518\n",
      "Epoch 10: Train Loss = 0.010899237746738557, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.010519511041685926, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "Model in epoch 10 is saved.\n",
      "\n",
      "Epoch 11: Train Loss = 0.013219095167781858, Recall = 1.0, Aging Rate = 0.5004142502071252, Precision = 0.9991721854304636, f1 = 0.9995859213250518\n",
      "Epoch 12: Train Loss = 0.01484023816243135, Recall = 1.0, Aging Rate = 0.5004142502071252, Precision = 0.9991721854304636, f1 = 0.9995859213250518\n",
      "Epoch 13: Train Loss = 0.032888559610663906, Recall = 0.9942004971002486, Aging Rate = 0.5057995028997514, Precision = 0.9828009828009828, f1 = 0.9884678747940693\n",
      "Epoch 14: Train Loss = 0.040233652875160716, Recall = 0.9933719966859983, Aging Rate = 0.5086992543496272, Precision = 0.9763843648208469, f1 = 0.9848049281314168\n",
      "Epoch 15: Train Loss = 0.01919160325258782, Recall = 0.9966859983429992, Aging Rate = 0.5004142502071252, Precision = 0.9958609271523179, f1 = 0.9962732919254658\n",
      "Test Loss = 0.007856092291136443, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 16: Train Loss = 0.007847225381093842, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 17: Train Loss = 0.007456745583542438, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 18: Train Loss = 0.008543610473664195, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 19: Train Loss = 0.010423671704189976, Recall = 1.0, Aging Rate = 0.5004142502071252, Precision = 0.9991721854304636, f1 = 0.9995859213250518\n",
      "Epoch 20: Train Loss = 0.012102005971239164, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.007908537463063579, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 21: Train Loss = 0.013346693275593586, Recall = 1.0, Aging Rate = 0.5008285004142502, Precision = 0.9983457402812241, f1 = 0.9991721854304636\n",
      "Epoch 22: Train Loss = 0.018667262782093505, Recall = 0.9983429991714996, Aging Rate = 0.5012427506213754, Precision = 0.9958677685950413, f1 = 0.9971038477451386\n",
      "Epoch 23: Train Loss = 0.02420744682679936, Recall = 0.9966859983429992, Aging Rate = 0.5016570008285004, Precision = 0.9933938893476466, f1 = 0.9950372208436724\n",
      "Epoch 24: Train Loss = 0.02488060287865806, Recall = 0.9933719966859983, Aging Rate = 0.5028997514498758, Precision = 0.9876441515650741, f1 = 0.9904997934737712\n",
      "Epoch 25: Train Loss = 0.03026514840848565, Recall = 0.9908864954432477, Aging Rate = 0.5008285004142502, Precision = 0.989247311827957, f1 = 0.9900662251655629\n",
      "Test Loss = 0.013611007463295003, Recall = 1.0, Aging Rate = 0.5012427506213754, precision = 0.9975206611570248\n",
      "\n",
      "Epoch 26: Train Loss = 0.010332264882387391, Recall = 0.9991714995857498, Aging Rate = 0.5004142502071252, Precision = 0.9983443708609272, f1 = 0.9987577639751554\n",
      "Epoch 27: Train Loss = 0.009797633623252157, Recall = 1.0, Aging Rate = 0.5008285004142502, Precision = 0.9983457402812241, f1 = 0.9991721854304636\n",
      "Epoch 28: Train Loss = 0.007146904434447039, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 29: Train Loss = 0.009287327123680881, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 30: Train Loss = 0.011284966683424175, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.00915415815363986, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 31: Train Loss = 0.012102347547103525, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 32: Train Loss = 0.009488698620929412, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 33: Train Loss = 0.01121520942621791, Recall = 1.0, Aging Rate = 0.5004142502071252, Precision = 0.9991721854304636, f1 = 0.9995859213250518\n",
      "Epoch 34: Train Loss = 0.027036018026861508, Recall = 0.995857497928749, Aging Rate = 0.5012427506213754, Precision = 0.9933884297520661, f1 = 0.9946214315266859\n",
      "Epoch 35: Train Loss = 0.03344701574582918, Recall = 0.9917149958574979, Aging Rate = 0.504142502071251, Precision = 0.9835661462612982, f1 = 0.9876237623762376\n",
      "Test Loss = 0.017138234906781284, Recall = 1.0, Aging Rate = 0.5020712510356256, precision = 0.9958745874587459\n",
      "\n",
      "Epoch 36: Train Loss = 0.02745735677412087, Recall = 0.9933719966859983, Aging Rate = 0.5020712510356256, Precision = 0.9892739273927392, f1 = 0.9913187267465895\n",
      "Epoch 37: Train Loss = 0.013052662035146328, Recall = 0.9991714995857498, Aging Rate = 0.5004142502071252, Precision = 0.9983443708609272, f1 = 0.9987577639751554\n",
      "Epoch 38: Train Loss = 0.00947602919681737, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 39: Train Loss = 0.008581688806997934, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 40: Train Loss = 0.007971850936605835, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.007514570948113043, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 41: Train Loss = 0.009338755480013016, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 42: Train Loss = 0.010561988639622903, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 43: Train Loss = 0.010960782834891209, Recall = 1.0, Aging Rate = 0.5004142502071252, Precision = 0.9991721854304636, f1 = 0.9995859213250518\n",
      "Epoch 44: Train Loss = 0.010993666840792813, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 45: Train Loss = 0.014104161165383055, Recall = 1.0, Aging Rate = 0.5012427506213754, Precision = 0.9975206611570248, f1 = 0.9987587918907737\n",
      "Test Loss = 0.010248036244953577, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 46: Train Loss = 0.01085072296788081, Recall = 1.0, Aging Rate = 0.5004142502071252, Precision = 0.9991721854304636, f1 = 0.9995859213250518\n",
      "Epoch 47: Train Loss = 0.03683700323623374, Recall = 0.9925434962717481, Aging Rate = 0.5049710024855012, Precision = 0.9827727645611156, f1 = 0.9876339653751031\n",
      "Epoch 48: Train Loss = 0.028950379635944233, Recall = 0.9933719966859983, Aging Rate = 0.5028997514498758, Precision = 0.9876441515650741, f1 = 0.9904997934737712\n",
      "Epoch 49: Train Loss = 0.008471991543140333, Recall = 0.9991714995857498, Aging Rate = 0.5004142502071252, Precision = 0.9983443708609272, f1 = 0.9987577639751554\n",
      "Epoch 50: Train Loss = 0.008147322717828748, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0068416525845129625, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 51: Train Loss = 0.009008765191321247, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 52: Train Loss = 0.009707631481550603, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 53: Train Loss = 0.009204148271683582, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 54: Train Loss = 0.011061368797162692, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 55: Train Loss = 0.013797731219783931, Recall = 0.9991714995857498, Aging Rate = 0.5008285004142502, Precision = 0.9975186104218362, f1 = 0.9983443708609271\n",
      "Test Loss = 0.025880969529963764, Recall = 0.995857497928749, Aging Rate = 0.4991714995857498, precision = 0.9975103734439834\n",
      "\n",
      "Epoch 56: Train Loss = 0.024305902548788644, Recall = 0.995857497928749, Aging Rate = 0.5016570008285004, Precision = 0.9925681255161024, f1 = 0.9942100909842846\n",
      "Epoch 57: Train Loss = 0.015018256742263394, Recall = 0.9983429991714996, Aging Rate = 0.5016570008285004, Precision = 0.9950454170107349, f1 = 0.9966914805624484\n",
      "Epoch 58: Train Loss = 0.008514571163337292, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 59: Train Loss = 0.008854196252580654, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 60: Train Loss = 0.011290642043981506, Recall = 0.9991714995857498, Aging Rate = 0.4995857497928749, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.008017021526876519, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Training Finished at epoch 60.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e9f3c1ee2864f47b8c839dcb43d3e9d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "06554a71bf1446bba44f98dafec5c3cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss = 0.3083913841933915, Recall = 0.9075757575757576, Aging Rate = 0.5492424242424242, Precision = 0.8262068965517242, f1 = 0.8649819494584838\n",
      "Epoch 2: Train Loss = 0.07252572284954967, Recall = 0.9818181818181818, Aging Rate = 0.5022727272727273, Precision = 0.9773755656108597, f1 = 0.9795918367346939\n",
      "Epoch 3: Train Loss = 0.03752090889734752, Recall = 0.9893939393939394, Aging Rate = 0.5007575757575757, Precision = 0.9878971255673222, f1 = 0.9886449659348978\n",
      "Epoch 4: Train Loss = 0.025669873731605935, Recall = 0.9939393939393939, Aging Rate = 0.49772727272727274, Precision = 0.9984779299847792, f1 = 0.9962034927866362\n",
      "Epoch 5: Train Loss = 0.016278458766244126, Recall = 0.996969696969697, Aging Rate = 0.49924242424242427, Precision = 0.9984825493171472, f1 = 0.9977255496588324\n",
      "Test Loss = 0.005938253222936482, Recall = 0.996969696969697, Aging Rate = 0.4984848484848485, precision = 1.0\n",
      "Model in epoch 5 is saved.\n",
      "\n",
      "Epoch 6: Train Loss = 0.004239071515798005, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 7: Train Loss = 0.0028160958028765337, Recall = 0.9984848484848485, Aging Rate = 0.49924242424242427, Precision = 0, f1 = 0.0\n",
      "Epoch 8: Train Loss = 0.0019163843399534622, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 9: Train Loss = 0.001427445292585727, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 10: Train Loss = 0.0012066517450324626, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0009944512361526547, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "Model in epoch 10 is saved.\n",
      "\n",
      "Epoch 11: Train Loss = 0.0010344833985789482, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 12: Train Loss = 0.0009546859495017226, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 13: Train Loss = 0.0009509232618394449, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 14: Train Loss = 0.0008351550448093225, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 15: Train Loss = 0.0008226290172332841, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0007395219029576489, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 16: Train Loss = 0.0008266164145121972, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 17: Train Loss = 0.0007688015651762147, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 18: Train Loss = 0.0007471489544100636, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 19: Train Loss = 0.0007408714567480439, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 20: Train Loss = 0.0007342367537079774, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0006730602288646906, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 21: Train Loss = 0.0007205981729467484, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 22: Train Loss = 0.000732208884349375, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 23: Train Loss = 0.0007308031621064539, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 24: Train Loss = 0.0006863261352533079, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 25: Train Loss = 0.0006799446133134718, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0006285475662232122, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 26: Train Loss = 0.000696239671246572, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 27: Train Loss = 0.0006925321928451233, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 28: Train Loss = 0.0007178169329453147, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 29: Train Loss = 0.0007076040083175581, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 30: Train Loss = 0.0006358084113647541, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0005817044103010134, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 31: Train Loss = 0.0006663522085132586, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 32: Train Loss = 0.000646645076587006, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 33: Train Loss = 0.0006714270429008386, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 34: Train Loss = 0.0006536439107025437, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 35: Train Loss = 0.0006378656240871571, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.000607834897660227, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 36: Train Loss = 0.0006475518732755022, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 37: Train Loss = 0.0005991593304894526, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 38: Train Loss = 0.0007264541368578758, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 39: Train Loss = 0.0006118276092985814, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 40: Train Loss = 0.0006301671479983876, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0005810114174065264, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 41: Train Loss = 0.0007096597131087699, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 42: Train Loss = 0.0006702239518441881, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 43: Train Loss = 0.0006098820199964172, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 44: Train Loss = 0.000645655846385511, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 45: Train Loss = 0.0006007441917476667, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0005848802636716176, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 46: Train Loss = 0.0006377518879052139, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 47: Train Loss = 0.0006302519292203766, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 48: Train Loss = 0.0006096776878235467, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 49: Train Loss = 0.0006320295686071569, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 50: Train Loss = 0.0005589436092343407, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0005571640639876325, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 51: Train Loss = 0.0006638474612510905, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 52: Train Loss = 0.0006476723922374235, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 53: Train Loss = 0.0006537424439253906, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 54: Train Loss = 0.0007349898156738191, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 55: Train Loss = 0.0005563312530284748, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.000518112448679114, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 56: Train Loss = 0.0006183283821552654, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 57: Train Loss = 0.000593460301487622, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 58: Train Loss = 0.0005734727437480946, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 59: Train Loss = 0.0006089728069844458, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 60: Train Loss = 0.0006420690575120689, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0004696984606033022, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Training Finished at epoch 60.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf8cd6bfa678441a8a581b95e054ba9f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss = 0.5988167187145778, Recall = 0.8666666666666667, Aging Rate = 0.741904761904762, Precision = 0.5840821566110398, f1 = 0.6978527607361963\n",
      "Epoch 2: Train Loss = 0.33967594044549126, Recall = 0.9542857142857143, Aging Rate = 0.5585714285714286, Precision = 0.8542199488491049, f1 = 0.9014844804318488\n",
      "Epoch 3: Train Loss = 0.20495358543736594, Recall = 0.9628571428571429, Aging Rate = 0.5295238095238095, Precision = 0.9091726618705036, f1 = 0.9352451433857539\n",
      "Epoch 4: Train Loss = 0.14738123726277125, Recall = 0.979047619047619, Aging Rate = 0.5223809523809524, Precision = 0.9371011850501367, f1 = 0.9576152771308803\n",
      "Epoch 5: Train Loss = 0.11601771305004756, Recall = 0.9780952380952381, Aging Rate = 0.5095238095238095, Precision = 0.9598130841121495, f1 = 0.968867924528302\n",
      "Test Loss = 0.09499265754506701, Recall = 0.981904761904762, Aging Rate = 0.5071428571428571, precision = 0.968075117370892\n",
      "Model in epoch 5 is saved.\n",
      "\n",
      "Epoch 6: Train Loss = 0.09108151036713805, Recall = 0.9828571428571429, Aging Rate = 0.5076190476190476, Precision = 0.9681050656660413, f1 = 0.9754253308128544\n",
      "Epoch 7: Train Loss = 0.07464632269882021, Recall = 0.9838095238095238, Aging Rate = 0.5023809523809524, Precision = 0.9791469194312796, f1 = 0.9814726840855107\n",
      "Epoch 8: Train Loss = 0.06217829262926465, Recall = 0.9857142857142858, Aging Rate = 0.5009523809523809, Precision = 0.9838403041825095, f1 = 0.9847764034253093\n",
      "Epoch 9: Train Loss = 0.05276571236905597, Recall = 0.9866666666666667, Aging Rate = 0.49952380952380954, Precision = 0.9876072449952336, f1 = 0.9871367317770366\n",
      "Epoch 10: Train Loss = 0.043475813198657266, Recall = 0.9876190476190476, Aging Rate = 0.49857142857142855, Precision = 0.9904489016236867, f1 = 0.9890319504053409\n",
      "Test Loss = 0.03882315445868742, Recall = 0.9952380952380953, Aging Rate = 0.5033333333333333, precision = 0.988647114474929\n",
      "Model in epoch 10 is saved.\n",
      "\n",
      "Epoch 11: Train Loss = 0.036828420077051435, Recall = 0.9933333333333333, Aging Rate = 0.5009523809523809, Precision = 0.9914448669201521, f1 = 0.9923882017126546\n",
      "Epoch 12: Train Loss = 0.030983265134550277, Recall = 0.9952380952380953, Aging Rate = 0.5004761904761905, Precision = 0.994291151284491, f1 = 0.9947643979057591\n",
      "Epoch 13: Train Loss = 0.026042340710049582, Recall = 0.9952380952380953, Aging Rate = 0.5, Precision = 0.9952380952380953, f1 = 0.9952380952380953\n",
      "Epoch 14: Train Loss = 0.02165669807898147, Recall = 0.9961904761904762, Aging Rate = 0.5, Precision = 0.9961904761904762, f1 = 0.9961904761904762\n",
      "Epoch 15: Train Loss = 0.01865886398014568, Recall = 0.9961904761904762, Aging Rate = 0.4990476190476191, Precision = 0.9980916030534351, f1 = 0.9971401334604386\n",
      "Test Loss = 0.01644794574450879, Recall = 0.9961904761904762, Aging Rate = 0.4980952380952381, precision = 1.0\n",
      "Model in epoch 15 is saved.\n",
      "\n",
      "Epoch 16: Train Loss = 0.0154938590384665, Recall = 0.9990476190476191, Aging Rate = 0.5, Precision = 0.9990476190476191, f1 = 0.9990476190476191\n",
      "Epoch 17: Train Loss = 0.013060001755754154, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 18: Train Loss = 0.011434066618482272, Recall = 0.9990476190476191, Aging Rate = 0.49952380952380954, Precision = 0, f1 = 0.0\n",
      "Epoch 19: Train Loss = 0.010131734613151777, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 20: Train Loss = 0.008779995154057231, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.007941300865440142, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "Model in epoch 20 is saved.\n",
      "\n",
      "Epoch 21: Train Loss = 0.007731217791636785, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 22: Train Loss = 0.0070796798608664955, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 23: Train Loss = 0.006257475680183797, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 24: Train Loss = 0.005615645339269014, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 25: Train Loss = 0.005206421761374388, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.004655160565993616, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 26: Train Loss = 0.00464821687456043, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 27: Train Loss = 0.004332113603484773, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 28: Train Loss = 0.003994150081915514, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 29: Train Loss = 0.0036593722019876754, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 30: Train Loss = 0.0034152149568711008, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0031300487085467294, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 31: Train Loss = 0.0031589832839866478, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 32: Train Loss = 0.002930218317501602, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 33: Train Loss = 0.0028171495594350353, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 34: Train Loss = 0.0026216769790542976, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 35: Train Loss = 0.00251907641201147, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.002307335839252032, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 36: Train Loss = 0.002357647517429931, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 37: Train Loss = 0.0022290076490580324, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 38: Train Loss = 0.002139736092205913, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 39: Train Loss = 0.0019854251397330137, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 40: Train Loss = 0.001944430343961964, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0018112119061074086, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 41: Train Loss = 0.0018427725096366236, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 42: Train Loss = 0.001774907807730848, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 43: Train Loss = 0.0017218299999478318, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 44: Train Loss = 0.0016712023388771784, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 45: Train Loss = 0.001599260794797114, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0014979241974651814, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 46: Train Loss = 0.0015604441722721926, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 47: Train Loss = 0.001539692430357848, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 48: Train Loss = 0.0015111986640840768, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 49: Train Loss = 0.0014049989663596665, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 50: Train Loss = 0.0013606260479649618, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0013153565107356935, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 51: Train Loss = 0.001323343931442304, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 52: Train Loss = 0.0012953193853831007, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 53: Train Loss = 0.00125859452832845, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 54: Train Loss = 0.0012294268027125369, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 55: Train Loss = 0.0011965420345465341, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0011582547364135582, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 56: Train Loss = 0.0012005200230383447, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 57: Train Loss = 0.0011663077833751838, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 58: Train Loss = 0.001145635665216971, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 59: Train Loss = 0.001097789747152655, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 60: Train Loss = 0.0010990962785269534, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0010360630039524818, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 61: Train Loss = 0.0010926514615615208, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 62: Train Loss = 0.001082967482839844, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 63: Train Loss = 0.0010417541221804207, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 64: Train Loss = 0.0010222259048549903, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 65: Train Loss = 0.001010884038350057, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0009936030005060492, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 66: Train Loss = 0.001008254277569774, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 67: Train Loss = 0.0009901784150861204, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 68: Train Loss = 0.0010148422539766346, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 69: Train Loss = 0.0009653283079110441, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 70: Train Loss = 0.000977017796997513, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0009061477218000662, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Training Finished at epoch 70.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da2e13946bd141a284020e4e83af04a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss = 0.6322288727413209, Recall = 0.9281164695177434, Aging Rate = 0.7998180163785259, Precision = 0.5802047781569966, f1 = 0.7140357017850893\n",
      "Epoch 2: Train Loss = 0.485112018700184, Recall = 0.9481346678798908, Aging Rate = 0.6574158325750682, Precision = 0.7211072664359861, f1 = 0.8191823899371069\n",
      "Epoch 3: Train Loss = 0.35261023321186447, Recall = 0.9272065514103731, Aging Rate = 0.556869881710646, Precision = 0.8325163398692811, f1 = 0.8773138183383556\n",
      "Epoch 4: Train Loss = 0.26636097182242624, Recall = 0.9417652411282984, Aging Rate = 0.5414012738853503, Precision = 0.8697478991596639, f1 = 0.9043250327653997\n",
      "Epoch 5: Train Loss = 0.21708951981312802, Recall = 0.9608735213830755, Aging Rate = 0.532302092811647, Precision = 0.9025641025641026, f1 = 0.9308065226972233\n",
      "Test Loss = 0.18721236761750906, Recall = 0.9790718835304822, Aging Rate = 0.5354868061874432, precision = 0.9141886151231946\n",
      "Model in epoch 5 is saved.\n",
      "\n",
      "Epoch 6: Train Loss = 0.17423073865398697, Recall = 0.9763421292083713, Aging Rate = 0.5268425841674249, Precision = 0.9265975820379966, f1 = 0.9508196721311476\n",
      "Epoch 7: Train Loss = 0.14751955761054736, Recall = 0.9772520473157416, Aging Rate = 0.5154686078252957, Precision = 0.9479258605472197, f1 = 0.9623655913978493\n",
      "Epoch 8: Train Loss = 0.12740070997204317, Recall = 0.978161965423112, Aging Rate = 0.5131938125568699, Precision = 0.9530141843971631, f1 = 0.9654243376740009\n",
      "Epoch 9: Train Loss = 0.1090873108534405, Recall = 0.9790718835304822, Aging Rate = 0.5077343039126478, Precision = 0.96415770609319, f1 = 0.9715575620767494\n",
      "Epoch 10: Train Loss = 0.09427268742782838, Recall = 0.9836214740673339, Aging Rate = 0.5077343039126478, Precision = 0.9686379928315412, f1 = 0.9760722347629797\n",
      "Test Loss = 0.08521397986717935, Recall = 0.986351228389445, Aging Rate = 0.508189262966333, precision = 0.9704565801253358\n",
      "Model in epoch 10 is saved.\n",
      "\n",
      "Epoch 11: Train Loss = 0.08186446360775945, Recall = 0.9845313921747043, Aging Rate = 0.5031847133757962, Precision = 0.9783001808318263, f1 = 0.98140589569161\n",
      "Epoch 12: Train Loss = 0.07168124504624658, Recall = 0.986351228389445, Aging Rate = 0.5013648771610555, Precision = 0.9836660617059891, f1 = 0.9850068150840527\n",
      "Epoch 13: Train Loss = 0.06287404692802134, Recall = 0.9872611464968153, Aging Rate = 0.5009099181073703, Precision = 0.9854677565849228, f1 = 0.9863636363636364\n",
      "Epoch 14: Train Loss = 0.055994887938816185, Recall = 0.9872611464968153, Aging Rate = 0.5, Precision = 0.9872611464968153, f1 = 0.9872611464968153\n",
      "Epoch 15: Train Loss = 0.05056223384459741, Recall = 0.989080982711556, Aging Rate = 0.5, Precision = 0.989080982711556, f1 = 0.989080982711556\n",
      "Test Loss = 0.046092329662059305, Recall = 0.989080982711556, Aging Rate = 0.4981801637852593, precision = 0.9926940639269406\n",
      "Model in epoch 15 is saved.\n",
      "\n",
      "Epoch 16: Train Loss = 0.04548000484989707, Recall = 0.9909008189262967, Aging Rate = 0.49954504094631486, Precision = 0.9918032786885246, f1 = 0.9913518434228493\n",
      "Epoch 17: Train Loss = 0.04119107003465254, Recall = 0.991810737033667, Aging Rate = 0.49954504094631486, Precision = 0.9927140255009107, f1 = 0.9922621756941283\n",
      "Epoch 18: Train Loss = 0.03809581159379289, Recall = 0.9936305732484076, Aging Rate = 0.5004549590536852, Precision = 0.9927272727272727, f1 = 0.9931787175989085\n",
      "Epoch 19: Train Loss = 0.03513568082571816, Recall = 0.9927206551410374, Aging Rate = 0.4986351228389445, Precision = 0.9954379562043796, f1 = 0.9940774487471526\n",
      "Epoch 20: Train Loss = 0.03188400675590956, Recall = 0.9945404913557779, Aging Rate = 0.49954504094631486, Precision = 0.9954462659380692, f1 = 0.9949931725079654\n",
      "Test Loss = 0.030092014713353522, Recall = 0.9954504094631483, Aging Rate = 0.4986351228389445, precision = 0.9981751824817519\n",
      "Model in epoch 20 is saved.\n",
      "\n",
      "Epoch 21: Train Loss = 0.029506060009223966, Recall = 0.9945404913557779, Aging Rate = 0.49909008189262966, Precision = 0.9963536918869644, f1 = 0.9954462659380692\n",
      "Epoch 22: Train Loss = 0.02777333323631073, Recall = 0.9963603275705186, Aging Rate = 0.49954504094631486, Precision = 0.9972677595628415, f1 = 0.9968138370505234\n",
      "Epoch 23: Train Loss = 0.026152845932250406, Recall = 0.9963603275705186, Aging Rate = 0.49954504094631486, Precision = 0.9972677595628415, f1 = 0.9968138370505234\n",
      "Epoch 24: Train Loss = 0.02412239274686309, Recall = 0.9963603275705186, Aging Rate = 0.5, Precision = 0.9963603275705186, f1 = 0.9963603275705186\n",
      "Epoch 25: Train Loss = 0.022783822133404977, Recall = 0.997270245677889, Aging Rate = 0.5, Precision = 0.997270245677889, f1 = 0.997270245677889\n",
      "Test Loss = 0.021140600694470563, Recall = 0.997270245677889, Aging Rate = 0.49954504094631486, precision = 0.9981785063752276\n",
      "Model in epoch 25 is saved.\n",
      "\n",
      "Epoch 26: Train Loss = 0.0213060371562486, Recall = 0.997270245677889, Aging Rate = 0.49954504094631486, Precision = 0.9981785063752276, f1 = 0.9977241693218024\n",
      "Epoch 27: Train Loss = 0.020292003167025386, Recall = 0.997270245677889, Aging Rate = 0.49954504094631486, Precision = 0.9981785063752276, f1 = 0.9977241693218024\n",
      "Epoch 28: Train Loss = 0.01944530133015601, Recall = 0.9981801637852593, Aging Rate = 0.5, Precision = 0.9981801637852593, f1 = 0.9981801637852593\n",
      "Epoch 29: Train Loss = 0.018446449897979965, Recall = 0.9990900818926297, Aging Rate = 0.5004549590536852, Precision = 0.9981818181818182, f1 = 0.9986357435197818\n",
      "Epoch 30: Train Loss = 0.017700963862091166, Recall = 0.9990900818926297, Aging Rate = 0.5004549590536852, Precision = 0.9981818181818182, f1 = 0.9986357435197818\n",
      "Test Loss = 0.016771265442861928, Recall = 1.0, Aging Rate = 0.5013648771610555, precision = 0.9972776769509982\n",
      "Model in epoch 30 is saved.\n",
      "\n",
      "Epoch 31: Train Loss = 0.0170043044849837, Recall = 1.0, Aging Rate = 0.5009099181073703, Precision = 0.9981834695731153, f1 = 0.999090909090909\n",
      "Epoch 32: Train Loss = 0.016365420717315525, Recall = 1.0, Aging Rate = 0.5009099181073703, Precision = 0.9981834695731153, f1 = 0.999090909090909\n",
      "Epoch 33: Train Loss = 0.016001661574201926, Recall = 0.9990900818926297, Aging Rate = 0.5004549590536852, Precision = 0.9981818181818182, f1 = 0.9986357435197818\n",
      "Epoch 34: Train Loss = 0.015362916679525777, Recall = 1.0, Aging Rate = 0.5009099181073703, Precision = 0.9981834695731153, f1 = 0.999090909090909\n",
      "Epoch 35: Train Loss = 0.015063704597383222, Recall = 1.0, Aging Rate = 0.5004549590536852, Precision = 0.9990909090909091, f1 = 0.9995452478399274\n",
      "Test Loss = 0.013844197520645534, Recall = 1.0, Aging Rate = 0.5004549590536852, precision = 0.9990909090909091\n",
      "Model in epoch 35 is saved.\n",
      "\n",
      "Epoch 36: Train Loss = 0.014299254778016687, Recall = 1.0, Aging Rate = 0.5004549590536852, Precision = 0.9990909090909091, f1 = 0.9995452478399274\n",
      "Epoch 37: Train Loss = 0.014510821670571765, Recall = 0.9990900818926297, Aging Rate = 0.5004549590536852, Precision = 0.9981818181818182, f1 = 0.9986357435197818\n",
      "Epoch 38: Train Loss = 0.013603966740350679, Recall = 1.0, Aging Rate = 0.5004549590536852, Precision = 0.9990909090909091, f1 = 0.9995452478399274\n",
      "Epoch 39: Train Loss = 0.013166388217105553, Recall = 1.0, Aging Rate = 0.5004549590536852, Precision = 0.9990909090909091, f1 = 0.9995452478399274\n",
      "Epoch 40: Train Loss = 0.013071220890162098, Recall = 1.0, Aging Rate = 0.5004549590536852, Precision = 0.9990909090909091, f1 = 0.9995452478399274\n",
      "Test Loss = 0.012165468811541388, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "Model in epoch 40 is saved.\n",
      "\n",
      "Epoch 41: Train Loss = 0.012629249039105223, Recall = 1.0, Aging Rate = 0.5004549590536852, Precision = 0.9990909090909091, f1 = 0.9995452478399274\n",
      "Epoch 42: Train Loss = 0.012336892792760132, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 43: Train Loss = 0.012366321864957371, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 44: Train Loss = 0.012021769945754638, Recall = 1.0, Aging Rate = 0.5004549590536852, Precision = 0.9990909090909091, f1 = 0.9995452478399274\n",
      "Epoch 45: Train Loss = 0.01165843430442144, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.011064161959225422, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 46: Train Loss = 0.011697002345046963, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 47: Train Loss = 0.0113661882507397, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 48: Train Loss = 0.01131388004970914, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 49: Train Loss = 0.011108254588415018, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 50: Train Loss = 0.011078740459094816, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.010506103379233274, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 51: Train Loss = 0.01079980569728078, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 52: Train Loss = 0.010655949756611575, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 53: Train Loss = 0.011051029099102341, Recall = 0.9990900818926297, Aging Rate = 0.49954504094631486, Precision = 0, f1 = 0.0\n",
      "Epoch 54: Train Loss = 0.010542661674469845, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 55: Train Loss = 0.010319863503893755, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.009923276988902994, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 56: Train Loss = 0.010472014117596148, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 57: Train Loss = 0.0103741337505387, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 58: Train Loss = 0.0099861293677766, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 59: Train Loss = 0.010100280682982587, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 60: Train Loss = 0.009934053738076948, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.009838035716179477, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 61: Train Loss = 0.010162208203880542, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 62: Train Loss = 0.009894554339708579, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 63: Train Loss = 0.010288068653508899, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 64: Train Loss = 0.009615353741653405, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 65: Train Loss = 0.009685209473498416, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.009904210148099555, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 66: Train Loss = 0.00993052355434959, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 67: Train Loss = 0.009499455296228537, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 68: Train Loss = 0.009644430089831773, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 69: Train Loss = 0.009471375103895846, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 70: Train Loss = 0.00974651015540746, Recall = 1.0, Aging Rate = 0.5004549590536852, Precision = 0.9990909090909091, f1 = 0.9995452478399274\n",
      "Test Loss = 0.008898499412453641, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 71: Train Loss = 0.009745535897929983, Recall = 1.0, Aging Rate = 0.5004549590536852, Precision = 0.9990909090909091, f1 = 0.9995452478399274\n",
      "Epoch 72: Train Loss = 0.009297187923978305, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 73: Train Loss = 0.009626678571620239, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 74: Train Loss = 0.009406386984781691, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 75: Train Loss = 0.009319684479650012, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.008750989729770755, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 76: Train Loss = 0.009162026198599505, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 77: Train Loss = 0.009070213455740732, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 78: Train Loss = 0.009193623584235007, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 79: Train Loss = 0.009491049273581912, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 80: Train Loss = 0.00941689460249355, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.008461733753314144, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 81: Train Loss = 0.009252598463431395, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 82: Train Loss = 0.008977340717373706, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 83: Train Loss = 0.008939196356488316, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 84: Train Loss = 0.008806095144171624, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 85: Train Loss = 0.008991167092487365, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.00827959735790527, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 86: Train Loss = 0.00884447296152571, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 87: Train Loss = 0.009084399241710029, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 88: Train Loss = 0.00871346947534503, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 89: Train Loss = 0.008894065963621299, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 90: Train Loss = 0.009203513092941878, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.00834781771824035, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Training Finished at epoch 90.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "abb2d38117d94ca7903975e4d796d17b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "53681c248d2c4949993961441a85e0ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss = 0.654084622495957, Recall = 0.7738461538461539, Aging Rate = 0.7824427480916031, Precision = 0.49073170731707316, f1 = 0.6005970149253731\n",
      "Epoch 2: Train Loss = 0.507473157789871, Recall = 0.9938461538461538, Aging Rate = 0.8442748091603054, Precision = 0.5840867992766727, f1 = 0.735763097949886\n",
      "Epoch 3: Train Loss = 0.36400925676331264, Recall = 0.9830769230769231, Aging Rate = 0.6564885496183206, Precision = 0.7430232558139535, f1 = 0.8463576158940397\n",
      "Epoch 4: Train Loss = 0.265271066732079, Recall = 0.9769230769230769, Aging Rate = 0.5893129770992367, Precision = 0.822538860103627, f1 = 0.8931082981715894\n",
      "Epoch 5: Train Loss = 0.20206273229977556, Recall = 0.98, Aging Rate = 0.5648854961832062, Precision = 0.8608108108108108, f1 = 0.916546762589928\n",
      "Test Loss = 0.17041074758722582, Recall = 0.9892307692307692, Aging Rate = 0.5709923664122137, precision = 0.8596256684491979\n",
      "Model in epoch 5 is saved.\n",
      "\n",
      "Epoch 6: Train Loss = 0.15262387780515294, Recall = 0.9876923076923076, Aging Rate = 0.5450381679389313, Precision = 0.8991596638655462, f1 = 0.9413489736070382\n",
      "Epoch 7: Train Loss = 0.12032575716499154, Recall = 0.9876923076923076, Aging Rate = 0.5259541984732824, Precision = 0.9317851959361393, f1 = 0.958924570575056\n",
      "Epoch 8: Train Loss = 0.09562804734206382, Recall = 0.9892307692307692, Aging Rate = 0.5137404580152671, Precision = 0.9554234769687965, f1 = 0.9720332577475435\n",
      "Epoch 9: Train Loss = 0.07661800825868854, Recall = 0.9938461538461538, Aging Rate = 0.5106870229007634, Precision = 0.9656203288490284, f1 = 0.979529946929492\n",
      "Epoch 10: Train Loss = 0.06233054783963065, Recall = 0.9984615384615385, Aging Rate = 0.5099236641221374, Precision = 0.9715568862275449, f1 = 0.9848254931714719\n",
      "Test Loss = 0.05509574466761742, Recall = 1.0, Aging Rate = 0.5137404580152671, precision = 0.9658246656760773\n",
      "Model in epoch 10 is saved.\n",
      "\n",
      "Epoch 11: Train Loss = 0.05031735248693073, Recall = 1.0, Aging Rate = 0.5061068702290077, Precision = 0.9803921568627451, f1 = 0.99009900990099\n",
      "Epoch 12: Train Loss = 0.04208381419418422, Recall = 1.0, Aging Rate = 0.5038167938931297, Precision = 0.9848484848484849, f1 = 0.9923664122137404\n",
      "Epoch 13: Train Loss = 0.03614366603091018, Recall = 1.0, Aging Rate = 0.5022900763358779, Precision = 0.9878419452887538, f1 = 0.9938837920489296\n",
      "Epoch 14: Train Loss = 0.028659684697294054, Recall = 1.0, Aging Rate = 0.5, Precision = 0.9923664122137404, f1 = 0.9961685823754789\n",
      "Epoch 15: Train Loss = 0.02408906941565166, Recall = 1.0, Aging Rate = 0.49694656488549616, Precision = 0.9984639016897081, f1 = 0.9992313604919293\n",
      "Test Loss = 0.02151876795212276, Recall = 1.0, Aging Rate = 0.4961832061068702, precision = 1.0\n",
      "Model in epoch 15 is saved.\n",
      "\n",
      "Epoch 16: Train Loss = 0.02059417428974887, Recall = 1.0, Aging Rate = 0.49694656488549616, Precision = 0.9984639016897081, f1 = 0.9992313604919293\n",
      "Epoch 17: Train Loss = 0.017772802010974812, Recall = 1.0, Aging Rate = 0.4961832061068702, Precision = 0, f1 = 0.0\n",
      "Epoch 18: Train Loss = 0.015514911301718413, Recall = 1.0, Aging Rate = 0.4961832061068702, Precision = 0, f1 = 0.0\n",
      "Epoch 19: Train Loss = 0.013531416853648106, Recall = 1.0, Aging Rate = 0.4961832061068702, Precision = 0, f1 = 0.0\n",
      "Epoch 20: Train Loss = 0.011904434396224168, Recall = 1.0, Aging Rate = 0.4961832061068702, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.011093286804513621, Recall = 1.0, Aging Rate = 0.4961832061068702, precision = 1.0\n",
      "\n",
      "Epoch 21: Train Loss = 0.010665766327492608, Recall = 1.0, Aging Rate = 0.4961832061068702, Precision = 0, f1 = 0.0\n",
      "Epoch 22: Train Loss = 0.009650278628896211, Recall = 1.0, Aging Rate = 0.4961832061068702, Precision = 0, f1 = 0.0\n",
      "Epoch 23: Train Loss = 0.008660993503961172, Recall = 1.0, Aging Rate = 0.4961832061068702, Precision = 0, f1 = 0.0\n",
      "Epoch 24: Train Loss = 0.007812176806894878, Recall = 1.0, Aging Rate = 0.4961832061068702, Precision = 0, f1 = 0.0\n",
      "Epoch 25: Train Loss = 0.00709141441443153, Recall = 1.0, Aging Rate = 0.4961832061068702, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.006701980992966822, Recall = 1.0, Aging Rate = 0.4961832061068702, precision = 1.0\n",
      "\n",
      "Epoch 26: Train Loss = 0.006500155730386272, Recall = 1.0, Aging Rate = 0.4961832061068702, Precision = 0, f1 = 0.0\n",
      "Epoch 27: Train Loss = 0.005907416618109204, Recall = 1.0, Aging Rate = 0.4961832061068702, Precision = 0, f1 = 0.0\n",
      "Epoch 28: Train Loss = 0.005464034902202037, Recall = 1.0, Aging Rate = 0.4961832061068702, Precision = 0, f1 = 0.0\n",
      "Epoch 29: Train Loss = 0.005003318240339974, Recall = 1.0, Aging Rate = 0.4961832061068702, Precision = 0, f1 = 0.0\n",
      "Epoch 30: Train Loss = 0.004689338315235636, Recall = 1.0, Aging Rate = 0.4961832061068702, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.004453119041241762, Recall = 1.0, Aging Rate = 0.4961832061068702, precision = 1.0\n",
      "\n",
      "Epoch 31: Train Loss = 0.0043572677135865654, Recall = 1.0, Aging Rate = 0.4961832061068702, Precision = 0, f1 = 0.0\n",
      "Epoch 32: Train Loss = 0.0040462886402738915, Recall = 1.0, Aging Rate = 0.4961832061068702, Precision = 0, f1 = 0.0\n",
      "Epoch 33: Train Loss = 0.0037964715533498816, Recall = 1.0, Aging Rate = 0.4961832061068702, Precision = 0, f1 = 0.0\n",
      "Epoch 34: Train Loss = 0.0035518967589178614, Recall = 1.0, Aging Rate = 0.4961832061068702, Precision = 0, f1 = 0.0\n",
      "Epoch 35: Train Loss = 0.0033587406069495295, Recall = 1.0, Aging Rate = 0.4961832061068702, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.003212809173447144, Recall = 1.0, Aging Rate = 0.4961832061068702, precision = 1.0\n",
      "\n",
      "Epoch 36: Train Loss = 0.003153029345118135, Recall = 1.0, Aging Rate = 0.4961832061068702, Precision = 0, f1 = 0.0\n",
      "Epoch 37: Train Loss = 0.002991230325872889, Recall = 1.0, Aging Rate = 0.4961832061068702, Precision = 0, f1 = 0.0\n",
      "Epoch 38: Train Loss = 0.0028295274006330784, Recall = 1.0, Aging Rate = 0.4961832061068702, Precision = 0, f1 = 0.0\n",
      "Epoch 39: Train Loss = 0.0026899272531541135, Recall = 1.0, Aging Rate = 0.4961832061068702, Precision = 0, f1 = 0.0\n",
      "Epoch 40: Train Loss = 0.0025408560459907275, Recall = 1.0, Aging Rate = 0.4961832061068702, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0024333231979341225, Recall = 1.0, Aging Rate = 0.4961832061068702, precision = 1.0\n",
      "\n",
      "Epoch 41: Train Loss = 0.002409451106876021, Recall = 1.0, Aging Rate = 0.4961832061068702, Precision = 0, f1 = 0.0\n",
      "Epoch 42: Train Loss = 0.002306469295614662, Recall = 1.0, Aging Rate = 0.4961832061068702, Precision = 0, f1 = 0.0\n",
      "Epoch 43: Train Loss = 0.0022268501339650906, Recall = 1.0, Aging Rate = 0.4961832061068702, Precision = 0, f1 = 0.0\n",
      "Epoch 44: Train Loss = 0.002108672114785846, Recall = 1.0, Aging Rate = 0.4961832061068702, Precision = 0, f1 = 0.0\n",
      "Epoch 45: Train Loss = 0.002012854417828658, Recall = 1.0, Aging Rate = 0.4961832061068702, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0019645665047107307, Recall = 1.0, Aging Rate = 0.4961832061068702, precision = 1.0\n",
      "\n",
      "Epoch 46: Train Loss = 0.0019491641330781557, Recall = 1.0, Aging Rate = 0.4961832061068702, Precision = 0, f1 = 0.0\n",
      "Epoch 47: Train Loss = 0.001853876708089623, Recall = 1.0, Aging Rate = 0.4961832061068702, Precision = 0, f1 = 0.0\n",
      "Epoch 48: Train Loss = 0.0017889769758517278, Recall = 1.0, Aging Rate = 0.4961832061068702, Precision = 0, f1 = 0.0\n",
      "Epoch 49: Train Loss = 0.0017319924103892373, Recall = 1.0, Aging Rate = 0.4961832061068702, Precision = 0, f1 = 0.0\n",
      "Epoch 50: Train Loss = 0.0016644740233709681, Recall = 1.0, Aging Rate = 0.4961832061068702, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0016038115390484, Recall = 1.0, Aging Rate = 0.4961832061068702, precision = 1.0\n",
      "\n",
      "Epoch 51: Train Loss = 0.0016122317428608204, Recall = 1.0, Aging Rate = 0.4961832061068702, Precision = 0, f1 = 0.0\n",
      "Epoch 52: Train Loss = 0.0015474199775947642, Recall = 1.0, Aging Rate = 0.4961832061068702, Precision = 0, f1 = 0.0\n",
      "Epoch 53: Train Loss = 0.0015093536667156082, Recall = 1.0, Aging Rate = 0.4961832061068702, Precision = 0, f1 = 0.0\n",
      "Epoch 54: Train Loss = 0.0014464978027363656, Recall = 1.0, Aging Rate = 0.4961832061068702, Precision = 0, f1 = 0.0\n",
      "Epoch 55: Train Loss = 0.0014139675721881614, Recall = 1.0, Aging Rate = 0.4961832061068702, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.001359351079214279, Recall = 1.0, Aging Rate = 0.4961832061068702, precision = 1.0\n",
      "\n",
      "Epoch 56: Train Loss = 0.0013618609926642012, Recall = 1.0, Aging Rate = 0.4961832061068702, Precision = 0, f1 = 0.0\n",
      "Epoch 57: Train Loss = 0.0013278467809952057, Recall = 1.0, Aging Rate = 0.4961832061068702, Precision = 0, f1 = 0.0\n",
      "Epoch 58: Train Loss = 0.0013015537997281164, Recall = 1.0, Aging Rate = 0.4961832061068702, Precision = 0, f1 = 0.0\n",
      "Epoch 59: Train Loss = 0.0012510812337481851, Recall = 1.0, Aging Rate = 0.4961832061068702, Precision = 0, f1 = 0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 60: Train Loss = 0.0012275408580188305, Recall = 1.0, Aging Rate = 0.4961832061068702, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0011907685357003778, Recall = 1.0, Aging Rate = 0.4961832061068702, precision = 1.0\n",
      "\n",
      "Epoch 61: Train Loss = 0.0011959040610347198, Recall = 1.0, Aging Rate = 0.4961832061068702, Precision = 0, f1 = 0.0\n",
      "Epoch 62: Train Loss = 0.0011538335591384018, Recall = 1.0, Aging Rate = 0.4961832061068702, Precision = 0, f1 = 0.0\n",
      "Epoch 63: Train Loss = 0.001140487047075827, Recall = 1.0, Aging Rate = 0.4961832061068702, Precision = 0, f1 = 0.0\n",
      "Epoch 64: Train Loss = 0.001113064660253501, Recall = 1.0, Aging Rate = 0.4961832061068702, Precision = 0, f1 = 0.0\n",
      "Epoch 65: Train Loss = 0.001085013672282905, Recall = 1.0, Aging Rate = 0.4961832061068702, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0010802121831189472, Recall = 1.0, Aging Rate = 0.4961832061068702, precision = 1.0\n",
      "\n",
      "Training Finished at epoch 65.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8d21d99ef37448ea3cd839c8d63e00d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss = 0.3244529926368363, Recall = 0.9086584205518554, Aging Rate = 0.5630652070442647, Precision = 0.8072696534234995, f1 = 0.8549686660698299\n",
      "Epoch 2: Train Loss = 0.09885956357893264, Recall = 0.9828734538534729, Aging Rate = 0.5130890052356021, Precision = 0.9582560296846011, f1 = 0.9704086425551902\n",
      "Epoch 3: Train Loss = 0.04733470251791708, Recall = 0.994291151284491, Aging Rate = 0.5078534031413613, Precision = 0.979381443298969, f1 = 0.9867799811142588\n",
      "Epoch 4: Train Loss = 0.02496225778891154, Recall = 0.9952426260704091, Aging Rate = 0.504045692527368, Precision = 0.987724268177526, f1 = 0.9914691943127963\n",
      "Epoch 5: Train Loss = 0.021453268005947507, Recall = 0.9961941008563273, Aging Rate = 0.5016658733936221, Precision = 0.9933586337760911, f1 = 0.9947743467933492\n",
      "Test Loss = 0.007359604395328463, Recall = 1.0, Aging Rate = 0.5016658733936221, precision = 0.9971537001897534\n",
      "Model in epoch 5 is saved.\n",
      "\n",
      "Epoch 6: Train Loss = 0.004612940790128142, Recall = 1.0, Aging Rate = 0.5007139457401237, Precision = 0.9990494296577946, f1 = 0.9995244888254874\n",
      "Epoch 7: Train Loss = 0.0017248231703240419, Recall = 1.0, Aging Rate = 0.5002379819133745, Precision = 0, f1 = 0.0\n",
      "Epoch 8: Train Loss = 0.0012399367455624465, Recall = 1.0, Aging Rate = 0.5002379819133745, Precision = 0, f1 = 0.0\n",
      "Epoch 9: Train Loss = 0.0010968930157134642, Recall = 1.0, Aging Rate = 0.5002379819133745, Precision = 0, f1 = 0.0\n",
      "Epoch 10: Train Loss = 0.0009936896547420692, Recall = 1.0, Aging Rate = 0.5002379819133745, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0009159873705301903, Recall = 1.0, Aging Rate = 0.5002379819133745, precision = 1.0\n",
      "Model in epoch 10 is saved.\n",
      "\n",
      "Epoch 11: Train Loss = 0.0009393445246594505, Recall = 1.0, Aging Rate = 0.5002379819133745, Precision = 0, f1 = 0.0\n",
      "Epoch 12: Train Loss = 0.0009269883262963415, Recall = 1.0, Aging Rate = 0.5002379819133745, Precision = 0, f1 = 0.0\n",
      "Epoch 13: Train Loss = 0.0009073318030019386, Recall = 1.0, Aging Rate = 0.5002379819133745, Precision = 0, f1 = 0.0\n",
      "Epoch 14: Train Loss = 0.0008912252997573925, Recall = 1.0, Aging Rate = 0.5002379819133745, Precision = 0, f1 = 0.0\n",
      "Epoch 15: Train Loss = 0.0009033273195886434, Recall = 1.0, Aging Rate = 0.5002379819133745, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.000813383640279716, Recall = 1.0, Aging Rate = 0.5002379819133745, precision = 1.0\n",
      "\n",
      "Epoch 16: Train Loss = 0.0009110464206584213, Recall = 1.0, Aging Rate = 0.5002379819133745, Precision = 0, f1 = 0.0\n",
      "Epoch 17: Train Loss = 0.001092794486783624, Recall = 1.0, Aging Rate = 0.5002379819133745, Precision = 0, f1 = 0.0\n",
      "Epoch 18: Train Loss = 0.0008528952818078657, Recall = 1.0, Aging Rate = 0.5002379819133745, Precision = 0, f1 = 0.0\n",
      "Epoch 19: Train Loss = 0.0008616435570738321, Recall = 1.0, Aging Rate = 0.5002379819133745, Precision = 0, f1 = 0.0\n",
      "Epoch 20: Train Loss = 0.0008644780311515171, Recall = 1.0, Aging Rate = 0.5002379819133745, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0008310295490514547, Recall = 1.0, Aging Rate = 0.5002379819133745, precision = 1.0\n",
      "\n",
      "Epoch 21: Train Loss = 0.00125220938914166, Recall = 1.0, Aging Rate = 0.5002379819133745, Precision = 0, f1 = 0.0\n",
      "Epoch 22: Train Loss = 0.029249494952078323, Recall = 0.9961941008563273, Aging Rate = 0.5064255116611137, Precision = 0.9840225563909775, f1 = 0.9900709219858156\n",
      "Epoch 23: Train Loss = 0.024474149436443007, Recall = 0.9980970504281637, Aging Rate = 0.504045692527368, Precision = 0.9905571293673276, f1 = 0.9943127962085307\n",
      "Epoch 24: Train Loss = 0.011593389529027824, Recall = 0.9980970504281637, Aging Rate = 0.5016658733936221, Precision = 0.9952561669829222, f1 = 0.9966745843230403\n",
      "Epoch 25: Train Loss = 0.004299394504100247, Recall = 1.0, Aging Rate = 0.5007139457401237, Precision = 0.9990494296577946, f1 = 0.9995244888254874\n",
      "Test Loss = 0.00027389228931027086, Recall = 1.0, Aging Rate = 0.5002379819133745, precision = 1.0\n",
      "\n",
      "Epoch 26: Train Loss = 0.0002999311181130832, Recall = 1.0, Aging Rate = 0.5002379819133745, Precision = 0, f1 = 0.0\n",
      "Epoch 27: Train Loss = 0.00022973014950469227, Recall = 1.0, Aging Rate = 0.5002379819133745, Precision = 0, f1 = 0.0\n",
      "Epoch 28: Train Loss = 0.00023720775746000075, Recall = 1.0, Aging Rate = 0.5002379819133745, Precision = 0, f1 = 0.0\n",
      "Epoch 29: Train Loss = 0.0002541733023941939, Recall = 1.0, Aging Rate = 0.5002379819133745, Precision = 0, f1 = 0.0\n",
      "Epoch 30: Train Loss = 0.00028691304876300185, Recall = 1.0, Aging Rate = 0.5002379819133745, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.00027765837072575203, Recall = 1.0, Aging Rate = 0.5002379819133745, precision = 1.0\n",
      "\n",
      "Epoch 31: Train Loss = 0.00030563155314991465, Recall = 1.0, Aging Rate = 0.5002379819133745, Precision = 0, f1 = 0.0\n",
      "Epoch 32: Train Loss = 0.0003337805396237804, Recall = 1.0, Aging Rate = 0.5002379819133745, Precision = 0, f1 = 0.0\n",
      "Epoch 33: Train Loss = 0.0003722799186222876, Recall = 1.0, Aging Rate = 0.5002379819133745, Precision = 0, f1 = 0.0\n",
      "Epoch 34: Train Loss = 0.0003854107129672806, Recall = 1.0, Aging Rate = 0.5002379819133745, Precision = 0, f1 = 0.0\n",
      "Epoch 35: Train Loss = 0.0004324989972050093, Recall = 1.0, Aging Rate = 0.5002379819133745, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.00042140697894718984, Recall = 1.0, Aging Rate = 0.5002379819133745, precision = 1.0\n",
      "\n",
      "Epoch 36: Train Loss = 0.00047178669788984175, Recall = 1.0, Aging Rate = 0.5002379819133745, Precision = 0, f1 = 0.0\n",
      "Epoch 37: Train Loss = 0.0004845738207264451, Recall = 1.0, Aging Rate = 0.5002379819133745, Precision = 0, f1 = 0.0\n",
      "Epoch 38: Train Loss = 0.0005197805663467035, Recall = 1.0, Aging Rate = 0.5002379819133745, Precision = 0, f1 = 0.0\n",
      "Epoch 39: Train Loss = 0.0005533499098531388, Recall = 1.0, Aging Rate = 0.5002379819133745, Precision = 0, f1 = 0.0\n",
      "Epoch 40: Train Loss = 0.0005879076361755483, Recall = 1.0, Aging Rate = 0.5002379819133745, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0005636617076372208, Recall = 1.0, Aging Rate = 0.5002379819133745, precision = 1.0\n",
      "\n",
      "Epoch 41: Train Loss = 0.0006290831842922075, Recall = 1.0, Aging Rate = 0.5002379819133745, Precision = 0, f1 = 0.0\n",
      "Epoch 42: Train Loss = 0.0006583377710807987, Recall = 1.0, Aging Rate = 0.5002379819133745, Precision = 0, f1 = 0.0\n",
      "Epoch 43: Train Loss = 0.0006583520569058418, Recall = 1.0, Aging Rate = 0.5002379819133745, Precision = 0, f1 = 0.0\n",
      "Epoch 44: Train Loss = 0.0006847808688638758, Recall = 1.0, Aging Rate = 0.5002379819133745, Precision = 0, f1 = 0.0\n",
      "Epoch 45: Train Loss = 0.0006896833897109938, Recall = 1.0, Aging Rate = 0.5002379819133745, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0006862731272939181, Recall = 1.0, Aging Rate = 0.5002379819133745, precision = 1.0\n",
      "\n",
      "Epoch 46: Train Loss = 0.0007410286691628028, Recall = 1.0, Aging Rate = 0.5002379819133745, Precision = 0, f1 = 0.0\n",
      "Epoch 47: Train Loss = 0.0007289819552255941, Recall = 1.0, Aging Rate = 0.5002379819133745, Precision = 0, f1 = 0.0\n",
      "Epoch 48: Train Loss = 0.000793860037323497, Recall = 1.0, Aging Rate = 0.5002379819133745, Precision = 0, f1 = 0.0\n",
      "Epoch 49: Train Loss = 0.01854011476011517, Recall = 0.9980970504281637, Aging Rate = 0.5030937648738696, Precision = 0.9924314096499527, f1 = 0.9952561669829222\n",
      "Epoch 50: Train Loss = 0.055223916447461, Recall = 0.9895337773549001, Aging Rate = 0.5064255116611137, Precision = 0.9774436090225563, f1 = 0.983451536643026\n",
      "Test Loss = 0.009823874528096481, Recall = 0.9990485252140818, Aging Rate = 0.5016658733936221, precision = 0.9962049335863378\n",
      "\n",
      "Epoch 51: Train Loss = 0.005814266911504355, Recall = 0.9990485252140818, Aging Rate = 0.5011899095668729, Precision = 0.9971509971509972, f1 = 0.9980988593155894\n",
      "Epoch 52: Train Loss = 0.000525957339426976, Recall = 1.0, Aging Rate = 0.5002379819133745, Precision = 0, f1 = 0.0\n",
      "Epoch 53: Train Loss = 0.00029318425949618706, Recall = 1.0, Aging Rate = 0.5002379819133745, Precision = 0, f1 = 0.0\n",
      "Epoch 54: Train Loss = 0.00027834397330299475, Recall = 1.0, Aging Rate = 0.5002379819133745, Precision = 0, f1 = 0.0\n",
      "Epoch 55: Train Loss = 0.00029608684807962853, Recall = 1.0, Aging Rate = 0.5002379819133745, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.00029158100737859433, Recall = 1.0, Aging Rate = 0.5002379819133745, precision = 1.0\n",
      "\n",
      "Epoch 56: Train Loss = 0.000322236062357422, Recall = 1.0, Aging Rate = 0.5002379819133745, Precision = 0, f1 = 0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57: Train Loss = 0.0003579430993324343, Recall = 1.0, Aging Rate = 0.5002379819133745, Precision = 0, f1 = 0.0\n",
      "Epoch 58: Train Loss = 0.00039294770843318813, Recall = 1.0, Aging Rate = 0.5002379819133745, Precision = 0, f1 = 0.0\n",
      "Epoch 59: Train Loss = 0.00042769723533576704, Recall = 1.0, Aging Rate = 0.5002379819133745, Precision = 0, f1 = 0.0\n",
      "Epoch 60: Train Loss = 0.0004570952718779365, Recall = 1.0, Aging Rate = 0.5002379819133745, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0007455604376989696, Recall = 1.0, Aging Rate = 0.5002379819133745, precision = 1.0\n",
      "\n",
      "Training Finished at epoch 60.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "004391c80a4042a083b1b951f0083e63",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss = 0.46110661492345534, Recall = 0.9113573407202216, Aging Rate = 0.6321575813101237, Precision = 0.7152173913043478, f1 = 0.8014616321559074\n",
      "Epoch 2: Train Loss = 0.20501554340287953, Recall = 0.9501385041551247, Aging Rate = 0.515803939532753, Precision = 0.9138543516873889, f1 = 0.9316432775011317\n",
      "Epoch 3: Train Loss = 0.10666649214551364, Recall = 0.9796860572483841, Aging Rate = 0.505267979844251, Precision = 0.9619220308250227, f1 = 0.970722781335773\n",
      "Epoch 4: Train Loss = 0.06219057557550636, Recall = 0.9916897506925207, Aging Rate = 0.5038937242327073, Precision = 0.9763636363636363, f1 = 0.9839670178653229\n",
      "Epoch 5: Train Loss = 0.04433466041434182, Recall = 0.9953831948291783, Aging Rate = 0.5006871278057718, Precision = 0.9862763037511436, f1 = 0.9908088235294117\n",
      "Test Loss = 0.02659723753228176, Recall = 1.0, Aging Rate = 0.5034356390288593, precision = 0.9854413102820746\n",
      "Model in epoch 5 is saved.\n",
      "\n",
      "Epoch 6: Train Loss = 0.02495339644865478, Recall = 0.9990766389658357, Aging Rate = 0.49977095739807603, Precision = 0.9917506874427131, f1 = 0.9954001839926403\n",
      "Epoch 7: Train Loss = 0.016503487782321608, Recall = 0.9990766389658357, Aging Rate = 0.49748053137883647, Precision = 0.996316758747698, f1 = 0.9976947902259106\n",
      "Epoch 8: Train Loss = 0.014762175278384042, Recall = 1.0, Aging Rate = 0.4979386165826844, Precision = 0.9963201471941122, f1 = 0.9981566820276497\n",
      "Epoch 9: Train Loss = 0.012421686093498276, Recall = 1.0, Aging Rate = 0.49656436097114065, Precision = 0.9990774907749077, f1 = 0.9995385325334565\n",
      "Epoch 10: Train Loss = 0.012561058628991881, Recall = 1.0, Aging Rate = 0.4979386165826844, Precision = 0.9963201471941122, f1 = 0.9981566820276497\n",
      "Test Loss = 0.012452898545346838, Recall = 1.0, Aging Rate = 0.49702244617498853, precision = 0.9981566820276497\n",
      "Model in epoch 10 is saved.\n",
      "\n",
      "Epoch 11: Train Loss = 0.012470722498403768, Recall = 1.0, Aging Rate = 0.49748053137883647, Precision = 0.9972375690607734, f1 = 0.9986168741355463\n",
      "Epoch 12: Train Loss = 0.016009748898415842, Recall = 1.0, Aging Rate = 0.49748053137883647, Precision = 0.9972375690607734, f1 = 0.9986168741355463\n",
      "Epoch 13: Train Loss = 0.01864571945995188, Recall = 0.9963065558633426, Aging Rate = 0.4961062757672927, Precision = 0.9963065558633426, f1 = 0.9963065558633426\n",
      "Epoch 14: Train Loss = 0.016366821155719975, Recall = 0.9990766389658357, Aging Rate = 0.49702244617498853, Precision = 0.9972350230414746, f1 = 0.9981549815498154\n",
      "Epoch 15: Train Loss = 0.010558319989245417, Recall = 1.0, Aging Rate = 0.49748053137883647, Precision = 0.9972375690607734, f1 = 0.9986168741355463\n",
      "Test Loss = 0.009102821914309339, Recall = 1.0, Aging Rate = 0.49656436097114065, precision = 0.9990774907749077\n",
      "Model in epoch 15 is saved.\n",
      "\n",
      "Epoch 16: Train Loss = 0.009620788078405308, Recall = 1.0, Aging Rate = 0.49656436097114065, Precision = 0.9990774907749077, f1 = 0.9995385325334565\n",
      "Epoch 17: Train Loss = 0.009698629160413788, Recall = 1.0, Aging Rate = 0.49656436097114065, Precision = 0.9990774907749077, f1 = 0.9995385325334565\n",
      "Epoch 18: Train Loss = 0.009768496177479645, Recall = 1.0, Aging Rate = 0.49702244617498853, Precision = 0.9981566820276497, f1 = 0.9990774907749077\n",
      "Epoch 19: Train Loss = 0.011365741492170999, Recall = 1.0, Aging Rate = 0.49702244617498853, Precision = 0.9981566820276497, f1 = 0.9990774907749077\n",
      "Epoch 20: Train Loss = 0.01139582444811722, Recall = 1.0, Aging Rate = 0.49656436097114065, Precision = 0.9990774907749077, f1 = 0.9995385325334565\n",
      "Test Loss = 0.009257508443512339, Recall = 1.0, Aging Rate = 0.49656436097114065, precision = 0.9990774907749077\n",
      "\n",
      "Epoch 21: Train Loss = 0.01084357897264254, Recall = 1.0, Aging Rate = 0.49702244617498853, Precision = 0.9981566820276497, f1 = 0.9990774907749077\n",
      "Epoch 22: Train Loss = 0.017878400154609748, Recall = 0.9990766389658357, Aging Rate = 0.49702244617498853, Precision = 0.9972350230414746, f1 = 0.9981549815498154\n",
      "Epoch 23: Train Loss = 0.016853229431550654, Recall = 0.997229916897507, Aging Rate = 0.4961062757672927, Precision = 0.997229916897507, f1 = 0.997229916897507\n",
      "Epoch 24: Train Loss = 0.0116577249978538, Recall = 0.9981532779316713, Aging Rate = 0.4961062757672927, Precision = 0.9981532779316713, f1 = 0.9981532779316713\n",
      "Epoch 25: Train Loss = 0.009472120822455514, Recall = 1.0, Aging Rate = 0.49702244617498853, Precision = 0.9981566820276497, f1 = 0.9990774907749077\n",
      "Test Loss = 0.008546067731547972, Recall = 1.0, Aging Rate = 0.4961062757672927, precision = 1.0\n",
      "Model in epoch 25 is saved.\n",
      "\n",
      "Epoch 26: Train Loss = 0.008909650605583186, Recall = 1.0, Aging Rate = 0.49656436097114065, Precision = 0.9990774907749077, f1 = 0.9995385325334565\n",
      "Epoch 27: Train Loss = 0.01081487025546812, Recall = 1.0, Aging Rate = 0.49702244617498853, Precision = 0.9981566820276497, f1 = 0.9990774907749077\n",
      "Epoch 28: Train Loss = 0.009592005263278504, Recall = 1.0, Aging Rate = 0.49702244617498853, Precision = 0.9981566820276497, f1 = 0.9990774907749077\n",
      "Epoch 29: Train Loss = 0.009965641708618803, Recall = 1.0, Aging Rate = 0.49702244617498853, Precision = 0.9981566820276497, f1 = 0.9990774907749077\n",
      "Epoch 30: Train Loss = 0.010311637340822572, Recall = 1.0, Aging Rate = 0.49656436097114065, Precision = 0.9990774907749077, f1 = 0.9995385325334565\n",
      "Test Loss = 0.008985255054354777, Recall = 1.0, Aging Rate = 0.49702244617498853, precision = 0.9981566820276497\n",
      "\n",
      "Epoch 31: Train Loss = 0.010774714998522048, Recall = 1.0, Aging Rate = 0.49702244617498853, Precision = 0.9981566820276497, f1 = 0.9990774907749077\n",
      "Epoch 32: Train Loss = 0.010992871500138727, Recall = 1.0, Aging Rate = 0.49702244617498853, Precision = 0.9981566820276497, f1 = 0.9990774907749077\n",
      "Epoch 33: Train Loss = 0.013505714421172892, Recall = 0.997229916897507, Aging Rate = 0.49656436097114065, Precision = 0.996309963099631, f1 = 0.9967697277341948\n",
      "Epoch 34: Train Loss = 0.01682193390555779, Recall = 0.9981532779316713, Aging Rate = 0.49748053137883647, Precision = 0.9953959484346224, f1 = 0.9967727063162748\n",
      "Epoch 35: Train Loss = 0.014659986290713816, Recall = 1.0, Aging Rate = 0.4988547869903802, Precision = 0.9944903581267218, f1 = 0.9972375690607734\n",
      "Test Loss = 0.006753767560698191, Recall = 1.0, Aging Rate = 0.49656436097114065, precision = 0.9990774907749077\n",
      "\n",
      "Epoch 36: Train Loss = 0.008910837142966753, Recall = 1.0, Aging Rate = 0.49702244617498853, Precision = 0.9981566820276497, f1 = 0.9990774907749077\n",
      "Epoch 37: Train Loss = 0.008388387209527191, Recall = 1.0, Aging Rate = 0.49702244617498853, Precision = 0.9981566820276497, f1 = 0.9990774907749077\n",
      "Epoch 38: Train Loss = 0.008292864586396866, Recall = 1.0, Aging Rate = 0.4961062757672927, Precision = 0, f1 = 0.0\n",
      "Epoch 39: Train Loss = 0.0089628479955014, Recall = 1.0, Aging Rate = 0.49656436097114065, Precision = 0.9990774907749077, f1 = 0.9995385325334565\n",
      "Epoch 40: Train Loss = 0.009785410099967024, Recall = 1.0, Aging Rate = 0.4961062757672927, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.008785979889258163, Recall = 1.0, Aging Rate = 0.4961062757672927, precision = 1.0\n",
      "\n",
      "Epoch 41: Train Loss = 0.009744006266243213, Recall = 1.0, Aging Rate = 0.4961062757672927, Precision = 0, f1 = 0.0\n",
      "Epoch 42: Train Loss = 0.009240221487297631, Recall = 1.0, Aging Rate = 0.49702244617498853, Precision = 0.9981566820276497, f1 = 0.9990774907749077\n",
      "Epoch 43: Train Loss = 0.014190093043336642, Recall = 0.9990766389658357, Aging Rate = 0.4983967017865323, Precision = 0.9944852941176471, f1 = 0.99677567941041\n",
      "Epoch 44: Train Loss = 0.018047731427754822, Recall = 0.9981532779316713, Aging Rate = 0.49748053137883647, Precision = 0.9953959484346224, f1 = 0.9967727063162748\n",
      "Epoch 45: Train Loss = 0.013740032220168012, Recall = 0.9990766389658357, Aging Rate = 0.49748053137883647, Precision = 0.996316758747698, f1 = 0.9976947902259106\n",
      "Test Loss = 0.008602037293767361, Recall = 1.0, Aging Rate = 0.4961062757672927, precision = 1.0\n",
      "\n",
      "Epoch 46: Train Loss = 0.010136591199319596, Recall = 1.0, Aging Rate = 0.49702244617498853, Precision = 0.9981566820276497, f1 = 0.9990774907749077\n",
      "Epoch 47: Train Loss = 0.008435313242598105, Recall = 1.0, Aging Rate = 0.4961062757672927, Precision = 0, f1 = 0.0\n",
      "Epoch 48: Train Loss = 0.007863420984983799, Recall = 1.0, Aging Rate = 0.4961062757672927, Precision = 0, f1 = 0.0\n",
      "Epoch 49: Train Loss = 0.008799431041357471, Recall = 1.0, Aging Rate = 0.49656436097114065, Precision = 0.9990774907749077, f1 = 0.9995385325334565\n",
      "Epoch 50: Train Loss = 0.009936554658180167, Recall = 1.0, Aging Rate = 0.49656436097114065, Precision = 0.9990774907749077, f1 = 0.9995385325334565\n",
      "Test Loss = 0.008687799179135551, Recall = 1.0, Aging Rate = 0.49656436097114065, precision = 0.9990774907749077\n",
      "\n",
      "Epoch 51: Train Loss = 0.009818551341772242, Recall = 0.9990766389658357, Aging Rate = 0.49656436097114065, Precision = 0.9981549815498155, f1 = 0.9986155976003692\n",
      "Epoch 52: Train Loss = 0.013763236706164306, Recall = 1.0, Aging Rate = 0.49702244617498853, Precision = 0.9981566820276497, f1 = 0.9990774907749077\n",
      "Epoch 53: Train Loss = 0.013847889788013653, Recall = 0.9990766389658357, Aging Rate = 0.4979386165826844, Precision = 0.9954001839926403, f1 = 0.9972350230414747\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 54: Train Loss = 0.011309130751262058, Recall = 0.9981532779316713, Aging Rate = 0.4951901053595969, Precision = 0, f1 = 0.0\n",
      "Epoch 55: Train Loss = 0.007776180558474892, Recall = 1.0, Aging Rate = 0.4961062757672927, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.007939001673084235, Recall = 1.0, Aging Rate = 0.49702244617498853, precision = 0.9981566820276497\n",
      "\n",
      "Epoch 56: Train Loss = 0.00929600020944799, Recall = 1.0, Aging Rate = 0.49656436097114065, Precision = 0.9990774907749077, f1 = 0.9995385325334565\n",
      "Epoch 57: Train Loss = 0.00868855877913811, Recall = 1.0, Aging Rate = 0.4961062757672927, Precision = 0, f1 = 0.0\n",
      "Epoch 58: Train Loss = 0.009925084905310667, Recall = 1.0, Aging Rate = 0.4961062757672927, Precision = 0, f1 = 0.0\n",
      "Epoch 59: Train Loss = 0.008799478499559268, Recall = 1.0, Aging Rate = 0.49702244617498853, Precision = 0.9981566820276497, f1 = 0.9990774907749077\n",
      "Epoch 60: Train Loss = 0.012421645983913678, Recall = 0.9990766389658357, Aging Rate = 0.49702244617498853, Precision = 0.9972350230414746, f1 = 0.9981549815498154\n",
      "Test Loss = 0.010357709301177428, Recall = 1.0, Aging Rate = 0.49702244617498853, precision = 0.9981566820276497\n",
      "\n",
      "Epoch 61: Train Loss = 0.009817348105855972, Recall = 1.0, Aging Rate = 0.49656436097114065, Precision = 0.9990774907749077, f1 = 0.9995385325334565\n",
      "Epoch 62: Train Loss = 0.0109548300745301, Recall = 0.9990766389658357, Aging Rate = 0.4961062757672927, Precision = 0.9990766389658357, f1 = 0.9990766389658357\n",
      "Epoch 63: Train Loss = 0.009527803318889874, Recall = 1.0, Aging Rate = 0.49702244617498853, Precision = 0.9981566820276497, f1 = 0.9990774907749077\n",
      "Epoch 64: Train Loss = 0.014266991585516978, Recall = 0.9990766389658357, Aging Rate = 0.49748053137883647, Precision = 0.996316758747698, f1 = 0.9976947902259106\n",
      "Epoch 65: Train Loss = 0.010730851333259007, Recall = 1.0, Aging Rate = 0.4983967017865323, Precision = 0.9954044117647058, f1 = 0.9976969138645785\n",
      "Test Loss = 0.01198677299864184, Recall = 1.0, Aging Rate = 0.49656436097114065, precision = 0.9990774907749077\n",
      "\n",
      "Epoch 66: Train Loss = 0.009943019745054864, Recall = 1.0, Aging Rate = 0.49702244617498853, Precision = 0.9981566820276497, f1 = 0.9990774907749077\n",
      "Epoch 67: Train Loss = 0.01061351324183729, Recall = 0.9990766389658357, Aging Rate = 0.49656436097114065, Precision = 0.9981549815498155, f1 = 0.9986155976003692\n",
      "Epoch 68: Train Loss = 0.011449267216149651, Recall = 1.0, Aging Rate = 0.49748053137883647, Precision = 0.9972375690607734, f1 = 0.9986168741355463\n",
      "Epoch 69: Train Loss = 0.009037578771120356, Recall = 1.0, Aging Rate = 0.4961062757672927, Precision = 0, f1 = 0.0\n",
      "Epoch 70: Train Loss = 0.009373966397131412, Recall = 1.0, Aging Rate = 0.4961062757672927, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.006827748142544605, Recall = 1.0, Aging Rate = 0.4961062757672927, precision = 1.0\n",
      "\n",
      "Epoch 71: Train Loss = 0.0085548404951896, Recall = 1.0, Aging Rate = 0.4961062757672927, Precision = 0, f1 = 0.0\n",
      "Epoch 72: Train Loss = 0.008782416251899723, Recall = 1.0, Aging Rate = 0.49656436097114065, Precision = 0.9990774907749077, f1 = 0.9995385325334565\n",
      "Epoch 73: Train Loss = 0.00950478641866641, Recall = 1.0, Aging Rate = 0.49702244617498853, Precision = 0.9981566820276497, f1 = 0.9990774907749077\n",
      "Epoch 74: Train Loss = 0.011063672718218691, Recall = 1.0, Aging Rate = 0.49656436097114065, Precision = 0.9990774907749077, f1 = 0.9995385325334565\n",
      "Epoch 75: Train Loss = 0.010383014351750697, Recall = 1.0, Aging Rate = 0.4961062757672927, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.00880888752268983, Recall = 1.0, Aging Rate = 0.4961062757672927, precision = 1.0\n",
      "\n",
      "Training Finished at epoch 75.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e29015b2a87423380500f6027bd9d37",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "adccead4a9c04d5382917557f036e619",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss = 0.34276006034776274, Recall = 0.9204204204204204, Aging Rate = 0.6025641025641025, Precision = 0.7672090112640801, f1 = 0.8368600682593857\n",
      "Epoch 2: Train Loss = 0.1593024558071637, Recall = 0.9654654654654654, Aging Rate = 0.526395173453997, Precision = 0.9212034383954155, f1 = 0.9428152492668621\n",
      "Epoch 3: Train Loss = 0.10946724142424122, Recall = 0.9774774774774775, Aging Rate = 0.5165912518853696, Precision = 0.9503649635036496, f1 = 0.9637305699481865\n",
      "Epoch 4: Train Loss = 0.09657888937612284, Recall = 0.9804804804804805, Aging Rate = 0.5105580693815988, Precision = 0.9645494830132939, f1 = 0.9724497393894267\n",
      "Epoch 5: Train Loss = 0.09218670846964619, Recall = 0.9834834834834835, Aging Rate = 0.5120663650075414, Precision = 0.9646539027982327, f1 = 0.9739776951672863\n",
      "Test Loss = 0.06839945386437808, Recall = 0.9834834834834835, Aging Rate = 0.5007541478129713, precision = 0.9864457831325302\n",
      "Model in epoch 5 is saved.\n",
      "\n",
      "Epoch 6: Train Loss = 0.08069089641106254, Recall = 0.984984984984985, Aging Rate = 0.5075414781297134, Precision = 0.974739970282318, f1 = 0.9798356982823001\n",
      "Epoch 7: Train Loss = 0.06779808499379755, Recall = 0.990990990990991, Aging Rate = 0.5052790346907994, Precision = 0.9850746268656716, f1 = 0.9880239520958084\n",
      "Epoch 8: Train Loss = 0.06381433830227068, Recall = 0.9924924924924925, Aging Rate = 0.502262443438914, Precision = 0.9924924924924925, f1 = 0.9924924924924925\n",
      "Epoch 9: Train Loss = 0.05963272800272946, Recall = 0.9954954954954955, Aging Rate = 0.5037707390648567, Precision = 0.9925149700598802, f1 = 0.9940029985007497\n",
      "Epoch 10: Train Loss = 0.0652448455402754, Recall = 0.990990990990991, Aging Rate = 0.502262443438914, Precision = 0.990990990990991, f1 = 0.990990990990991\n",
      "Test Loss = 0.049728632316015785, Recall = 0.993993993993994, Aging Rate = 0.502262443438914, precision = 0.993993993993994\n",
      "Model in epoch 10 is saved.\n",
      "\n",
      "Epoch 11: Train Loss = 0.0637098357648916, Recall = 0.9924924924924925, Aging Rate = 0.504524886877828, Precision = 0.9880418535127056, f1 = 0.9902621722846442\n",
      "Epoch 12: Train Loss = 0.05767185328075968, Recall = 0.9954954954954955, Aging Rate = 0.504524886877828, Precision = 0.9910313901345291, f1 = 0.9932584269662922\n",
      "Epoch 13: Train Loss = 0.0621478356656985, Recall = 0.9954954954954955, Aging Rate = 0.502262443438914, Precision = 0.9954954954954955, f1 = 0.9954954954954955\n",
      "Epoch 14: Train Loss = 0.06580830890218957, Recall = 0.987987987987988, Aging Rate = 0.5007541478129713, Precision = 0.9909638554216867, f1 = 0.9894736842105263\n",
      "Epoch 15: Train Loss = 0.05718707563538177, Recall = 0.9984984984984985, Aging Rate = 0.5075414781297134, Precision = 0.9881129271916791, f1 = 0.9932785660941\n",
      "Test Loss = 0.04896205138319578, Recall = 0.996996996996997, Aging Rate = 0.5015082956259427, precision = 0.9984962406015038\n",
      "Model in epoch 15 is saved.\n",
      "\n",
      "Epoch 16: Train Loss = 0.06062981104801323, Recall = 0.9954954954954955, Aging Rate = 0.5037707390648567, Precision = 0.9925149700598802, f1 = 0.9940029985007497\n",
      "Epoch 17: Train Loss = 0.06175181700048763, Recall = 0.990990990990991, Aging Rate = 0.5052790346907994, Precision = 0.9850746268656716, f1 = 0.9880239520958084\n",
      "Epoch 18: Train Loss = 0.05926642483760509, Recall = 0.9924924924924925, Aging Rate = 0.5007541478129713, Precision = 0.9954819277108434, f1 = 0.9939849624060151\n",
      "Epoch 19: Train Loss = 0.06806335947722152, Recall = 0.990990990990991, Aging Rate = 0.502262443438914, Precision = 0.990990990990991, f1 = 0.990990990990991\n",
      "Epoch 20: Train Loss = 0.07002183004966508, Recall = 0.990990990990991, Aging Rate = 0.5067873303167421, Precision = 0.9821428571428571, f1 = 0.9865470852017937\n",
      "Test Loss = 0.06801330063317876, Recall = 1.0, Aging Rate = 0.5165912518853696, precision = 0.9722627737226277\n",
      "\n",
      "Epoch 21: Train Loss = 0.05998457932555388, Recall = 0.9924924924924925, Aging Rate = 0.502262443438914, Precision = 0.9924924924924925, f1 = 0.9924924924924925\n",
      "Epoch 22: Train Loss = 0.05983118401618385, Recall = 0.990990990990991, Aging Rate = 0.5, Precision = 0.995475113122172, f1 = 0.9932279909706545\n",
      "Epoch 23: Train Loss = 0.06618169338342651, Recall = 0.990990990990991, Aging Rate = 0.5037707390648567, Precision = 0.9880239520958084, f1 = 0.9895052473763118\n",
      "Epoch 24: Train Loss = 0.07264232822043504, Recall = 0.987987987987988, Aging Rate = 0.504524886877828, Precision = 0.9835575485799701, f1 = 0.9857677902621723\n",
      "Epoch 25: Train Loss = 0.057523739137890474, Recall = 0.996996996996997, Aging Rate = 0.5037707390648567, Precision = 0.9940119760479041, f1 = 0.9955022488755623\n",
      "Test Loss = 0.06028097365079602, Recall = 1.0, Aging Rate = 0.5090497737556561, precision = 0.9866666666666667\n",
      "\n",
      "Epoch 26: Train Loss = 0.05843425130817146, Recall = 0.9924924924924925, Aging Rate = 0.5, Precision = 0.9969834087481146, f1 = 0.9947328818660647\n",
      "Epoch 27: Train Loss = 0.06011835963298113, Recall = 0.993993993993994, Aging Rate = 0.5030165912518854, Precision = 0.992503748125937, f1 = 0.9932483120780194\n",
      "Epoch 28: Train Loss = 0.06428851797435078, Recall = 0.993993993993994, Aging Rate = 0.5037707390648567, Precision = 0.9910179640718563, f1 = 0.992503748125937\n",
      "Epoch 29: Train Loss = 0.0637573412005673, Recall = 0.9924924924924925, Aging Rate = 0.5030165912518854, Precision = 0.9910044977511244, f1 = 0.991747936984246\n",
      "Epoch 30: Train Loss = 0.05605381236132094, Recall = 0.996996996996997, Aging Rate = 0.5030165912518854, Precision = 0.9955022488755623, f1 = 0.9962490622655664\n",
      "Test Loss = 0.051398412797875354, Recall = 1.0, Aging Rate = 0.5082956259426847, precision = 0.9881305637982196\n",
      "\n",
      "Epoch 31: Train Loss = 0.05573836833710584, Recall = 0.9984984984984985, Aging Rate = 0.5037707390648567, Precision = 0.9955089820359282, f1 = 0.9970014992503747\n",
      "Epoch 32: Train Loss = 0.05977176082057831, Recall = 0.996996996996997, Aging Rate = 0.5067873303167421, Precision = 0.9880952380952381, f1 = 0.992526158445441\n",
      "Epoch 33: Train Loss = 0.05936108645877687, Recall = 0.996996996996997, Aging Rate = 0.5067873303167421, Precision = 0.9880952380952381, f1 = 0.992526158445441\n",
      "Epoch 34: Train Loss = 0.05650144922764772, Recall = 0.990990990990991, Aging Rate = 0.49924585218702866, Precision = 0.9969788519637462, f1 = 0.9939759036144578\n",
      "Epoch 35: Train Loss = 0.06214852831122742, Recall = 0.9924924924924925, Aging Rate = 0.5030165912518854, Precision = 0.9910044977511244, f1 = 0.991747936984246\n",
      "Test Loss = 0.05742545027516187, Recall = 0.996996996996997, Aging Rate = 0.5007541478129713, precision = 1.0\n",
      "Model in epoch 35 is saved.\n",
      "\n",
      "Epoch 36: Train Loss = 0.05948947308806992, Recall = 0.9924924924924925, Aging Rate = 0.504524886877828, Precision = 0.9880418535127056, f1 = 0.9902621722846442\n",
      "Epoch 37: Train Loss = 0.06023394251256327, Recall = 0.9924924924924925, Aging Rate = 0.5, Precision = 0.9969834087481146, f1 = 0.9947328818660647\n",
      "Epoch 38: Train Loss = 0.06173518760239377, Recall = 0.9924924924924925, Aging Rate = 0.5037707390648567, Precision = 0.9895209580838323, f1 = 0.9910044977511244\n",
      "Epoch 39: Train Loss = 0.06115642261338809, Recall = 0.9924924924924925, Aging Rate = 0.5037707390648567, Precision = 0.9895209580838323, f1 = 0.9910044977511244\n",
      "Epoch 40: Train Loss = 0.0602992247132694, Recall = 0.9954954954954955, Aging Rate = 0.5037707390648567, Precision = 0.9925149700598802, f1 = 0.9940029985007497\n",
      "Test Loss = 0.05100576622835831, Recall = 1.0, Aging Rate = 0.502262443438914, precision = 1.0\n",
      "Model in epoch 40 is saved.\n",
      "\n",
      "Epoch 41: Train Loss = 0.06587192589251344, Recall = 0.9864864864864865, Aging Rate = 0.5015082956259427, Precision = 0.98796992481203, f1 = 0.9872276483846731\n",
      "Epoch 42: Train Loss = 0.05605453225821931, Recall = 0.993993993993994, Aging Rate = 0.502262443438914, Precision = 0.993993993993994, f1 = 0.993993993993994\n",
      "Epoch 43: Train Loss = 0.06124984512883793, Recall = 0.996996996996997, Aging Rate = 0.504524886877828, Precision = 0.992526158445441, f1 = 0.9947565543071161\n",
      "Epoch 44: Train Loss = 0.05348981174093925, Recall = 0.996996996996997, Aging Rate = 0.502262443438914, Precision = 0.996996996996997, f1 = 0.996996996996997\n",
      "Epoch 45: Train Loss = 0.058356549663870945, Recall = 0.996996996996997, Aging Rate = 0.5030165912518854, Precision = 0.9955022488755623, f1 = 0.9962490622655664\n",
      "Test Loss = 0.05626543325851046, Recall = 0.993993993993994, Aging Rate = 0.49924585218702866, precision = 1.0\n",
      "\n",
      "Epoch 46: Train Loss = 0.05771322832702691, Recall = 0.9954954954954955, Aging Rate = 0.502262443438914, Precision = 0.9954954954954955, f1 = 0.9954954954954955\n",
      "Epoch 47: Train Loss = 0.06079505124939873, Recall = 0.9954954954954955, Aging Rate = 0.5037707390648567, Precision = 0.9925149700598802, f1 = 0.9940029985007497\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 48: Train Loss = 0.05791531217763506, Recall = 0.990990990990991, Aging Rate = 0.5, Precision = 0.995475113122172, f1 = 0.9932279909706545\n",
      "Epoch 49: Train Loss = 0.05542862774919421, Recall = 0.996996996996997, Aging Rate = 0.5015082956259427, Precision = 0.9984962406015038, f1 = 0.9977460555972953\n",
      "Epoch 50: Train Loss = 0.05824298811669083, Recall = 0.9954954954954955, Aging Rate = 0.5037707390648567, Precision = 0.9925149700598802, f1 = 0.9940029985007497\n",
      "Test Loss = 0.0630365397281057, Recall = 0.987987987987988, Aging Rate = 0.4962292609351433, precision = 1.0\n",
      "\n",
      "Epoch 51: Train Loss = 0.06355868544019365, Recall = 0.990990990990991, Aging Rate = 0.502262443438914, Precision = 0.990990990990991, f1 = 0.990990990990991\n",
      "Epoch 52: Train Loss = 0.05710788654391043, Recall = 0.9954954954954955, Aging Rate = 0.502262443438914, Precision = 0.9954954954954955, f1 = 0.9954954954954955\n",
      "Epoch 53: Train Loss = 0.06087784489355476, Recall = 0.9954954954954955, Aging Rate = 0.502262443438914, Precision = 0.9954954954954955, f1 = 0.9954954954954955\n",
      "Epoch 54: Train Loss = 0.05407237001943373, Recall = 0.9954954954954955, Aging Rate = 0.502262443438914, Precision = 0.9954954954954955, f1 = 0.9954954954954955\n",
      "Epoch 55: Train Loss = 0.06304987640222633, Recall = 0.9924924924924925, Aging Rate = 0.5052790346907994, Precision = 0.9865671641791045, f1 = 0.9895209580838323\n",
      "Test Loss = 0.04829704794094394, Recall = 1.0, Aging Rate = 0.5067873303167421, precision = 0.9910714285714286\n",
      "\n",
      "Epoch 56: Train Loss = 0.061545847306873645, Recall = 0.993993993993994, Aging Rate = 0.504524886877828, Precision = 0.9895366218236173, f1 = 0.9917602996254681\n",
      "Epoch 57: Train Loss = 0.05641739754228211, Recall = 0.993993993993994, Aging Rate = 0.5030165912518854, Precision = 0.992503748125937, f1 = 0.9932483120780194\n",
      "Epoch 58: Train Loss = 0.059834298971326826, Recall = 0.9894894894894894, Aging Rate = 0.5, Precision = 0.9939668174962293, f1 = 0.9917231000752446\n",
      "Epoch 59: Train Loss = 0.05612233826724832, Recall = 0.9984984984984985, Aging Rate = 0.504524886877828, Precision = 0.9940209267563528, f1 = 0.9962546816479401\n",
      "Epoch 60: Train Loss = 0.058011077726498626, Recall = 0.9954954954954955, Aging Rate = 0.504524886877828, Precision = 0.9910313901345291, f1 = 0.9932584269662922\n",
      "Test Loss = 0.05142045573950892, Recall = 1.0, Aging Rate = 0.5030165912518854, precision = 0.9985007496251874\n",
      "\n",
      "Epoch 61: Train Loss = 0.061311619066904396, Recall = 0.9924924924924925, Aging Rate = 0.502262443438914, Precision = 0.9924924924924925, f1 = 0.9924924924924925\n",
      "Epoch 62: Train Loss = 0.056714515520616536, Recall = 0.9954954954954955, Aging Rate = 0.5030165912518854, Precision = 0.9940029985007496, f1 = 0.994748687171793\n",
      "Epoch 63: Train Loss = 0.05621663994558976, Recall = 0.996996996996997, Aging Rate = 0.502262443438914, Precision = 0.996996996996997, f1 = 0.996996996996997\n",
      "Epoch 64: Train Loss = 0.05808685614332714, Recall = 0.996996996996997, Aging Rate = 0.5030165912518854, Precision = 0.9955022488755623, f1 = 0.9962490622655664\n",
      "Epoch 65: Train Loss = 0.05626032503706657, Recall = 0.9954954954954955, Aging Rate = 0.5037707390648567, Precision = 0.9925149700598802, f1 = 0.9940029985007497\n",
      "Test Loss = 0.05678648481406777, Recall = 1.0, Aging Rate = 0.5067873303167421, precision = 0.9910714285714286\n",
      "\n",
      "Epoch 66: Train Loss = 0.05904465624964255, Recall = 0.993993993993994, Aging Rate = 0.5015082956259427, Precision = 0.9954887218045113, f1 = 0.9947407963936891\n",
      "Epoch 67: Train Loss = 0.058599944314940484, Recall = 0.993993993993994, Aging Rate = 0.5015082956259427, Precision = 0.9954887218045113, f1 = 0.9947407963936891\n",
      "Epoch 68: Train Loss = 0.05994383128834706, Recall = 0.993993993993994, Aging Rate = 0.5015082956259427, Precision = 0.9954887218045113, f1 = 0.9947407963936891\n",
      "Epoch 69: Train Loss = 0.06279926039109943, Recall = 0.993993993993994, Aging Rate = 0.5060331825037707, Precision = 0.9865871833084948, f1 = 0.9902767389678384\n",
      "Epoch 70: Train Loss = 0.05581541427974428, Recall = 0.9954954954954955, Aging Rate = 0.5015082956259427, Precision = 0.9969924812030075, f1 = 0.9962434259954922\n",
      "Test Loss = 0.05194285270922324, Recall = 0.9984984984984985, Aging Rate = 0.5015082956259427, precision = 1.0\n",
      "\n",
      "Epoch 71: Train Loss = 0.05680478600220443, Recall = 0.993993993993994, Aging Rate = 0.5037707390648567, Precision = 0.9910179640718563, f1 = 0.992503748125937\n",
      "Epoch 72: Train Loss = 0.06027256588410828, Recall = 0.993993993993994, Aging Rate = 0.502262443438914, Precision = 0.993993993993994, f1 = 0.993993993993994\n",
      "Epoch 73: Train Loss = 0.057535224955186225, Recall = 0.996996996996997, Aging Rate = 0.502262443438914, Precision = 0.996996996996997, f1 = 0.996996996996997\n",
      "Epoch 74: Train Loss = 0.05925711094883592, Recall = 0.9924924924924925, Aging Rate = 0.5030165912518854, Precision = 0.9910044977511244, f1 = 0.991747936984246\n",
      "Epoch 75: Train Loss = 0.061235716125364575, Recall = 0.993993993993994, Aging Rate = 0.5052790346907994, Precision = 0.9880597014925373, f1 = 0.9910179640718564\n",
      "Test Loss = 0.05678175022294618, Recall = 0.990990990990991, Aging Rate = 0.497737556561086, precision = 1.0\n",
      "\n",
      "Epoch 76: Train Loss = 0.05827518123262428, Recall = 0.9954954954954955, Aging Rate = 0.502262443438914, Precision = 0.9954954954954955, f1 = 0.9954954954954955\n",
      "Epoch 77: Train Loss = 0.05706057404231162, Recall = 0.993993993993994, Aging Rate = 0.502262443438914, Precision = 0.993993993993994, f1 = 0.993993993993994\n",
      "Epoch 78: Train Loss = 0.05799390515523259, Recall = 0.9924924924924925, Aging Rate = 0.5007541478129713, Precision = 0.9954819277108434, f1 = 0.9939849624060151\n",
      "Epoch 79: Train Loss = 0.05546840449983358, Recall = 0.9954954954954955, Aging Rate = 0.5007541478129713, Precision = 0.9984939759036144, f1 = 0.9969924812030075\n",
      "Epoch 80: Train Loss = 0.05788637454962838, Recall = 0.9954954954954955, Aging Rate = 0.504524886877828, Precision = 0.9910313901345291, f1 = 0.9932584269662922\n",
      "Test Loss = 0.05046509879431933, Recall = 1.0, Aging Rate = 0.5060331825037707, precision = 0.992548435171386\n",
      "\n",
      "Epoch 81: Train Loss = 0.05959845343843485, Recall = 0.993993993993994, Aging Rate = 0.5037707390648567, Precision = 0.9910179640718563, f1 = 0.992503748125937\n",
      "Epoch 82: Train Loss = 0.05501922568359706, Recall = 1.0, Aging Rate = 0.5067873303167421, Precision = 0.9910714285714286, f1 = 0.9955156950672646\n",
      "Epoch 83: Train Loss = 0.057442074149936934, Recall = 0.9984984984984985, Aging Rate = 0.504524886877828, Precision = 0.9940209267563528, f1 = 0.9962546816479401\n",
      "Epoch 84: Train Loss = 0.057250945552127216, Recall = 0.9954954954954955, Aging Rate = 0.502262443438914, Precision = 0.9954954954954955, f1 = 0.9954954954954955\n",
      "Epoch 85: Train Loss = 0.057620939401120265, Recall = 0.9954954954954955, Aging Rate = 0.5030165912518854, Precision = 0.9940029985007496, f1 = 0.994748687171793\n",
      "Test Loss = 0.05105979327634989, Recall = 0.9984984984984985, Aging Rate = 0.502262443438914, precision = 0.9984984984984985\n",
      "\n",
      "Epoch 86: Train Loss = 0.05836041331808132, Recall = 0.9954954954954955, Aging Rate = 0.502262443438914, Precision = 0.9954954954954955, f1 = 0.9954954954954955\n",
      "Epoch 87: Train Loss = 0.053944835340994694, Recall = 0.9954954954954955, Aging Rate = 0.5015082956259427, Precision = 0.9969924812030075, f1 = 0.9962434259954922\n",
      "Epoch 88: Train Loss = 0.0578912157750777, Recall = 0.996996996996997, Aging Rate = 0.5030165912518854, Precision = 0.9955022488755623, f1 = 0.9962490622655664\n",
      "Epoch 89: Train Loss = 0.06263892609642911, Recall = 0.9954954954954955, Aging Rate = 0.5052790346907994, Precision = 0.9895522388059701, f1 = 0.9925149700598802\n",
      "Epoch 90: Train Loss = 0.05649167485816087, Recall = 0.9954954954954955, Aging Rate = 0.5037707390648567, Precision = 0.9925149700598802, f1 = 0.9940029985007497\n",
      "Test Loss = 0.05632602759436065, Recall = 1.0, Aging Rate = 0.5090497737556561, precision = 0.9866666666666667\n",
      "\n",
      "Training Finished at epoch 90.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e0f486b6927245e486f77c3935a33c52",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss = 0.5597061535876284, Recall = 1.0, Aging Rate = 1.0, Precision = 0.5483870967741935, f1 = 0.7083333333333333\n",
      "Epoch 2: Train Loss = 0.41497942821953887, Recall = 0.9968627450980392, Aging Rate = 0.8886021505376344, Precision = 0.6151984511132623, f1 = 0.7608500448967375\n",
      "Epoch 3: Train Loss = 0.2792493427568866, Recall = 0.9780392156862745, Aging Rate = 0.6868817204301075, Precision = 0.7808390732623669, f1 = 0.8683844011142061\n",
      "Epoch 4: Train Loss = 0.21261574060045263, Recall = 0.9756862745098039, Aging Rate = 0.6262365591397849, Precision = 0.8543956043956044, f1 = 0.9110216038081289\n",
      "Epoch 5: Train Loss = 0.1770895879499374, Recall = 0.9811764705882353, Aging Rate = 0.6180645161290322, Precision = 0.8705636743215032, f1 = 0.922566371681416\n",
      "Test Loss = 0.1526011336298399, Recall = 0.984313725490196, Aging Rate = 0.5978494623655914, precision = 0.9028776978417267\n",
      "Model in epoch 5 is saved.\n",
      "\n",
      "Epoch 6: Train Loss = 0.14347244686336927, Recall = 0.9850980392156863, Aging Rate = 0.5965591397849462, Precision = 0.905551550108147, f1 = 0.9436513899323816\n",
      "Epoch 7: Train Loss = 0.12430155173905434, Recall = 0.9866666666666667, Aging Rate = 0.5939784946236559, Precision = 0.9109341057204924, f1 = 0.947289156626506\n",
      "Epoch 8: Train Loss = 0.1087716067350039, Recall = 0.9913725490196078, Aging Rate = 0.5918279569892473, Precision = 0.9186046511627907, f1 = 0.953602414183327\n",
      "Epoch 9: Train Loss = 0.09564762279871972, Recall = 0.9913725490196078, Aging Rate = 0.5789247311827957, Precision = 0.9390787518573551, f1 = 0.964517359786341\n",
      "Epoch 10: Train Loss = 0.08303635534900491, Recall = 0.9921568627450981, Aging Rate = 0.5724731182795699, Precision = 0.9504132231404959, f1 = 0.9708365310821181\n",
      "Test Loss = 0.07557737736612238, Recall = 0.9945098039215686, Aging Rate = 0.5750537634408602, precision = 0.9483919222139118\n",
      "Model in epoch 10 is saved.\n",
      "\n",
      "Epoch 11: Train Loss = 0.0746968880071435, Recall = 0.9929411764705882, Aging Rate = 0.5724731182795699, Precision = 0.9511645379413974, f1 = 0.9716039907904835\n",
      "Epoch 12: Train Loss = 0.06510877479148168, Recall = 0.9945098039215686, Aging Rate = 0.5651612903225807, Precision = 0.9649923896499238, f1 = 0.9795287755890305\n",
      "Epoch 13: Train Loss = 0.05762556855717013, Recall = 0.996078431372549, Aging Rate = 0.5625806451612904, Precision = 0.9709480122324159, f1 = 0.9833526906697638\n",
      "Epoch 14: Train Loss = 0.052085374497598216, Recall = 0.9968627450980392, Aging Rate = 0.5608602150537635, Precision = 0.9746932515337423, f1 = 0.9856533540131833\n",
      "Epoch 15: Train Loss = 0.04607803247308218, Recall = 0.9952941176470588, Aging Rate = 0.5561290322580645, Precision = 0.9814385150812065, f1 = 0.9883177570093458\n",
      "Test Loss = 0.042034173248115404, Recall = 0.9992156862745099, Aging Rate = 0.5574193548387096, precision = 0.9830246913580247\n",
      "Model in epoch 15 is saved.\n",
      "\n",
      "Epoch 16: Train Loss = 0.04214266370060624, Recall = 0.9984313725490196, Aging Rate = 0.5565591397849462, Precision = 0.9837712519319938, f1 = 0.9910471000389257\n",
      "Epoch 17: Train Loss = 0.038821520912711335, Recall = 0.9968627450980392, Aging Rate = 0.5539784946236559, Precision = 0.9868012422360248, f1 = 0.9918064767850175\n",
      "Epoch 18: Train Loss = 0.03482691637450649, Recall = 0.9992156862745099, Aging Rate = 0.5548387096774193, Precision = 0.9875968992248062, f1 = 0.9933723196881091\n",
      "Epoch 19: Train Loss = 0.031552543004834524, Recall = 0.9984313725490196, Aging Rate = 0.552258064516129, Precision = 0.9914330218068536, f1 = 0.9949198905822587\n",
      "Epoch 20: Train Loss = 0.029652695223208396, Recall = 0.9984313725490196, Aging Rate = 0.5518279569892474, Precision = 0.9922057677318784, f1 = 0.9953088350273651\n",
      "Test Loss = 0.027188900975129937, Recall = 0.9992156862745099, Aging Rate = 0.5518279569892474, precision = 0.9929851909586905\n",
      "Model in epoch 20 is saved.\n",
      "\n",
      "Epoch 21: Train Loss = 0.02736534034773227, Recall = 0.9992156862745099, Aging Rate = 0.552258064516129, Precision = 0.9922118380062306, f1 = 0.9957014458772958\n",
      "Epoch 22: Train Loss = 0.02558693246495339, Recall = 0.9992156862745099, Aging Rate = 0.5518279569892474, Precision = 0.9929851909586905, f1 = 0.9960906958561376\n",
      "Epoch 23: Train Loss = 0.024577658534530672, Recall = 0.9992156862745099, Aging Rate = 0.5509677419354839, Precision = 0.994535519125683, f1 = 0.996870109546166\n",
      "Epoch 24: Train Loss = 0.022665757341410523, Recall = 0.9992156862745099, Aging Rate = 0.5509677419354839, Precision = 0.994535519125683, f1 = 0.996870109546166\n",
      "Epoch 25: Train Loss = 0.021383502287089184, Recall = 0.9992156862745099, Aging Rate = 0.5509677419354839, Precision = 0.994535519125683, f1 = 0.996870109546166\n",
      "Test Loss = 0.020009132763471014, Recall = 0.9992156862745099, Aging Rate = 0.5509677419354839, precision = 0.994535519125683\n",
      "Model in epoch 25 is saved.\n",
      "\n",
      "Epoch 26: Train Loss = 0.02063342088653195, Recall = 0.9992156862745099, Aging Rate = 0.5509677419354839, Precision = 0.994535519125683, f1 = 0.996870109546166\n",
      "Epoch 27: Train Loss = 0.019863969743331916, Recall = 0.9992156862745099, Aging Rate = 0.5505376344086022, Precision = 0.9953125, f1 = 0.9972602739726028\n",
      "Epoch 28: Train Loss = 0.018789302989920622, Recall = 0.9984313725490196, Aging Rate = 0.5496774193548387, Precision = 0.9960876369327074, f1 = 0.9972581276929103\n",
      "Epoch 29: Train Loss = 0.01832860170192616, Recall = 0.9992156862745099, Aging Rate = 0.5505376344086022, Precision = 0.9953125, f1 = 0.9972602739726028\n",
      "Epoch 30: Train Loss = 0.01748661048109493, Recall = 0.9992156862745099, Aging Rate = 0.5501075268817204, Precision = 0.9960906958561376, f1 = 0.9976507439310887\n",
      "Test Loss = 0.016112120477582818, Recall = 0.9992156862745099, Aging Rate = 0.5501075268817204, precision = 0.9960906958561376\n",
      "Model in epoch 30 is saved.\n",
      "\n",
      "Epoch 31: Train Loss = 0.016635190578357828, Recall = 1.0, Aging Rate = 0.5496774193548387, Precision = 0.9976525821596244, f1 = 0.9988249118683901\n",
      "Epoch 32: Train Loss = 0.01600728076632305, Recall = 0.9984313725490196, Aging Rate = 0.5492473118279569, Precision = 0.9968676585747847, f1 = 0.9976489028213167\n",
      "Epoch 33: Train Loss = 0.015927644703657397, Recall = 0.9992156862745099, Aging Rate = 0.5501075268817204, Precision = 0.9960906958561376, f1 = 0.9976507439310887\n",
      "Epoch 34: Train Loss = 0.01509444993770411, Recall = 1.0, Aging Rate = 0.5496774193548387, Precision = 0.9976525821596244, f1 = 0.9988249118683901\n",
      "Epoch 35: Train Loss = 0.01490854269093884, Recall = 0.9984313725490196, Aging Rate = 0.5483870967741935, Precision = 0.9984313725490196, f1 = 0.9984313725490196\n",
      "Test Loss = 0.013811168687778616, Recall = 0.9992156862745099, Aging Rate = 0.5488172043010753, precision = 0.9984326018808778\n",
      "Model in epoch 35 is saved.\n",
      "\n",
      "Epoch 36: Train Loss = 0.014241354200908895, Recall = 1.0, Aging Rate = 0.5496774193548387, Precision = 0.9976525821596244, f1 = 0.9988249118683901\n",
      "Epoch 37: Train Loss = 0.014012435014529895, Recall = 0.9992156862745099, Aging Rate = 0.5496774193548387, Precision = 0.9968701095461658, f1 = 0.9980415197806503\n",
      "Epoch 38: Train Loss = 0.01385679850094421, Recall = 0.9992156862745099, Aging Rate = 0.5488172043010753, Precision = 0.9984326018808778, f1 = 0.9988239905919247\n",
      "Epoch 39: Train Loss = 0.013777158957335257, Recall = 1.0, Aging Rate = 0.5496774193548387, Precision = 0.9976525821596244, f1 = 0.9988249118683901\n",
      "Epoch 40: Train Loss = 0.013504174924505655, Recall = 1.0, Aging Rate = 0.5492473118279569, Precision = 0.9984338292873923, f1 = 0.9992163009404388\n",
      "Test Loss = 0.012816690139232144, Recall = 0.9992156862745099, Aging Rate = 0.5483870967741935, precision = 0.9992156862745099\n",
      "Model in epoch 40 is saved.\n",
      "\n",
      "Epoch 41: Train Loss = 0.012982271199104606, Recall = 0.9984313725490196, Aging Rate = 0.5483870967741935, Precision = 0.9984313725490196, f1 = 0.9984313725490196\n",
      "Epoch 42: Train Loss = 0.012891798991189208, Recall = 0.9992156862745099, Aging Rate = 0.5492473118279569, Precision = 0.9976507439310884, f1 = 0.9984326018808778\n",
      "Epoch 43: Train Loss = 0.01224136044621788, Recall = 0.9992156862745099, Aging Rate = 0.5492473118279569, Precision = 0.9976507439310884, f1 = 0.9984326018808778\n",
      "Epoch 44: Train Loss = 0.012424409880993827, Recall = 0.9992156862745099, Aging Rate = 0.5492473118279569, Precision = 0.9976507439310884, f1 = 0.9984326018808778\n",
      "Epoch 45: Train Loss = 0.012210636154137632, Recall = 0.9992156862745099, Aging Rate = 0.5488172043010753, Precision = 0.9984326018808778, f1 = 0.9988239905919247\n",
      "Test Loss = 0.011471300248096707, Recall = 1.0, Aging Rate = 0.5488172043010753, precision = 0.9992163009404389\n",
      "Model in epoch 45 is saved.\n",
      "\n",
      "Epoch 46: Train Loss = 0.012083374726115375, Recall = 0.9992156862745099, Aging Rate = 0.5492473118279569, Precision = 0.9976507439310884, f1 = 0.9984326018808778\n",
      "Epoch 47: Train Loss = 0.012049705072516395, Recall = 1.0, Aging Rate = 0.5492473118279569, Precision = 0.9984338292873923, f1 = 0.9992163009404388\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 48: Train Loss = 0.011682157522087457, Recall = 1.0, Aging Rate = 0.5496774193548387, Precision = 0.9976525821596244, f1 = 0.9988249118683901\n",
      "Epoch 49: Train Loss = 0.011346150826542608, Recall = 1.0, Aging Rate = 0.5488172043010753, Precision = 0.9992163009404389, f1 = 0.999607996863975\n",
      "Epoch 50: Train Loss = 0.011285662071438886, Recall = 0.9984313725490196, Aging Rate = 0.5479569892473118, Precision = 0.9992150706436421, f1 = 0.9988230678697528\n",
      "Test Loss = 0.011679235288212375, Recall = 1.0, Aging Rate = 0.5496774193548387, precision = 0.9976525821596244\n",
      "\n",
      "Epoch 51: Train Loss = 0.011016776614612148, Recall = 1.0, Aging Rate = 0.5492473118279569, Precision = 0.9984338292873923, f1 = 0.9992163009404388\n",
      "Epoch 52: Train Loss = 0.011278768530896594, Recall = 1.0, Aging Rate = 0.5488172043010753, Precision = 0.9992163009404389, f1 = 0.999607996863975\n",
      "Epoch 53: Train Loss = 0.010799401894772565, Recall = 0.9992156862745099, Aging Rate = 0.5483870967741935, Precision = 0.9992156862745099, f1 = 0.9992156862745099\n",
      "Epoch 54: Train Loss = 0.010762558169662952, Recall = 1.0, Aging Rate = 0.5488172043010753, Precision = 0.9992163009404389, f1 = 0.999607996863975\n",
      "Epoch 55: Train Loss = 0.010729948082357966, Recall = 1.0, Aging Rate = 0.5483870967741935, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.010091345690751588, Recall = 1.0, Aging Rate = 0.5488172043010753, precision = 0.9992163009404389\n",
      "\n",
      "Epoch 56: Train Loss = 0.010590602267653711, Recall = 1.0, Aging Rate = 0.5488172043010753, Precision = 0.9992163009404389, f1 = 0.999607996863975\n",
      "Epoch 57: Train Loss = 0.010804080993577998, Recall = 1.0, Aging Rate = 0.5488172043010753, Precision = 0.9992163009404389, f1 = 0.999607996863975\n",
      "Epoch 58: Train Loss = 0.01054623129266885, Recall = 1.0, Aging Rate = 0.5483870967741935, Precision = 0, f1 = 0.0\n",
      "Epoch 59: Train Loss = 0.010285316128884593, Recall = 1.0, Aging Rate = 0.5483870967741935, Precision = 0, f1 = 0.0\n",
      "Epoch 60: Train Loss = 0.01082556650362989, Recall = 1.0, Aging Rate = 0.5492473118279569, Precision = 0.9984338292873923, f1 = 0.9992163009404388\n",
      "Test Loss = 0.010946367286866711, Recall = 1.0, Aging Rate = 0.5496774193548387, precision = 0.9976525821596244\n",
      "\n",
      "Epoch 61: Train Loss = 0.010525768451713106, Recall = 1.0, Aging Rate = 0.5488172043010753, Precision = 0.9992163009404389, f1 = 0.999607996863975\n",
      "Epoch 62: Train Loss = 0.010166041378372459, Recall = 1.0, Aging Rate = 0.5488172043010753, Precision = 0.9992163009404389, f1 = 0.999607996863975\n",
      "Epoch 63: Train Loss = 0.010322960122057828, Recall = 1.0, Aging Rate = 0.5496774193548387, Precision = 0.9976525821596244, f1 = 0.9988249118683901\n",
      "Epoch 64: Train Loss = 0.010139584861575596, Recall = 0.9992156862745099, Aging Rate = 0.5479569892473118, Precision = 0, f1 = 0.0\n",
      "Epoch 65: Train Loss = 0.009799728621478362, Recall = 1.0, Aging Rate = 0.5488172043010753, Precision = 0.9992163009404389, f1 = 0.999607996863975\n",
      "Test Loss = 0.00959984271516723, Recall = 1.0, Aging Rate = 0.5483870967741935, precision = 1.0\n",
      "Model in epoch 65 is saved.\n",
      "\n",
      "Epoch 66: Train Loss = 0.010490735575396528, Recall = 0.9992156862745099, Aging Rate = 0.5479569892473118, Precision = 0, f1 = 0.0\n",
      "Epoch 67: Train Loss = 0.009901237487993254, Recall = 1.0, Aging Rate = 0.5488172043010753, Precision = 0.9992163009404389, f1 = 0.999607996863975\n",
      "Epoch 68: Train Loss = 0.009772578164214087, Recall = 1.0, Aging Rate = 0.5488172043010753, Precision = 0.9992163009404389, f1 = 0.999607996863975\n",
      "Epoch 69: Train Loss = 0.009651457816963234, Recall = 1.0, Aging Rate = 0.5492473118279569, Precision = 0.9984338292873923, f1 = 0.9992163009404388\n",
      "Epoch 70: Train Loss = 0.009578765328693133, Recall = 1.0, Aging Rate = 0.5483870967741935, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.00895277885499821, Recall = 1.0, Aging Rate = 0.5483870967741935, precision = 1.0\n",
      "\n",
      "Epoch 71: Train Loss = 0.009644435662776231, Recall = 1.0, Aging Rate = 0.5488172043010753, Precision = 0.9992163009404389, f1 = 0.999607996863975\n",
      "Epoch 72: Train Loss = 0.009655084462375731, Recall = 1.0, Aging Rate = 0.5492473118279569, Precision = 0.9984338292873923, f1 = 0.9992163009404388\n",
      "Epoch 73: Train Loss = 0.00979638979439774, Recall = 1.0, Aging Rate = 0.5488172043010753, Precision = 0.9992163009404389, f1 = 0.999607996863975\n",
      "Epoch 74: Train Loss = 0.009708370258731227, Recall = 0.9992156862745099, Aging Rate = 0.5479569892473118, Precision = 0, f1 = 0.0\n",
      "Epoch 75: Train Loss = 0.009763538790966874, Recall = 1.0, Aging Rate = 0.5488172043010753, Precision = 0.9992163009404389, f1 = 0.999607996863975\n",
      "Test Loss = 0.008898190038018328, Recall = 1.0, Aging Rate = 0.5483870967741935, precision = 1.0\n",
      "\n",
      "Epoch 76: Train Loss = 0.009733296143471874, Recall = 1.0, Aging Rate = 0.5483870967741935, Precision = 0, f1 = 0.0\n",
      "Epoch 77: Train Loss = 0.00932783517986536, Recall = 1.0, Aging Rate = 0.5483870967741935, Precision = 0, f1 = 0.0\n",
      "Epoch 78: Train Loss = 0.009432268671851646, Recall = 1.0, Aging Rate = 0.5488172043010753, Precision = 0.9992163009404389, f1 = 0.999607996863975\n",
      "Epoch 79: Train Loss = 0.009373484774622865, Recall = 1.0, Aging Rate = 0.5483870967741935, Precision = 0, f1 = 0.0\n",
      "Epoch 80: Train Loss = 0.009479260557000676, Recall = 1.0, Aging Rate = 0.5488172043010753, Precision = 0.9992163009404389, f1 = 0.999607996863975\n",
      "Test Loss = 0.008836996915439765, Recall = 1.0, Aging Rate = 0.5488172043010753, precision = 0.9992163009404389\n",
      "\n",
      "Epoch 81: Train Loss = 0.009144590021942251, Recall = 1.0, Aging Rate = 0.5483870967741935, Precision = 0, f1 = 0.0\n",
      "Epoch 82: Train Loss = 0.009254697004072769, Recall = 1.0, Aging Rate = 0.5492473118279569, Precision = 0.9984338292873923, f1 = 0.9992163009404388\n",
      "Epoch 83: Train Loss = 0.009475956420984961, Recall = 1.0, Aging Rate = 0.5488172043010753, Precision = 0.9992163009404389, f1 = 0.999607996863975\n",
      "Epoch 84: Train Loss = 0.009312821504289425, Recall = 1.0, Aging Rate = 0.5488172043010753, Precision = 0.9992163009404389, f1 = 0.999607996863975\n",
      "Epoch 85: Train Loss = 0.009094991707593524, Recall = 1.0, Aging Rate = 0.5483870967741935, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.008476121856841028, Recall = 1.0, Aging Rate = 0.5483870967741935, precision = 1.0\n",
      "\n",
      "Epoch 86: Train Loss = 0.009295996919434557, Recall = 1.0, Aging Rate = 0.5488172043010753, Precision = 0.9992163009404389, f1 = 0.999607996863975\n",
      "Epoch 87: Train Loss = 0.010583130083978176, Recall = 1.0, Aging Rate = 0.5496774193548387, Precision = 0.9976525821596244, f1 = 0.9988249118683901\n",
      "Epoch 88: Train Loss = 0.009271514498057866, Recall = 1.0, Aging Rate = 0.5483870967741935, Precision = 0, f1 = 0.0\n",
      "Epoch 89: Train Loss = 0.008832359000720004, Recall = 1.0, Aging Rate = 0.5492473118279569, Precision = 0.9984338292873923, f1 = 0.9992163009404388\n",
      "Epoch 90: Train Loss = 0.00897637193641996, Recall = 1.0, Aging Rate = 0.5488172043010753, Precision = 0.9992163009404389, f1 = 0.999607996863975\n",
      "Test Loss = 0.008584327886421834, Recall = 1.0, Aging Rate = 0.5483870967741935, precision = 1.0\n",
      "\n",
      "Epoch 91: Train Loss = 0.008915572869441201, Recall = 1.0, Aging Rate = 0.5483870967741935, Precision = 0, f1 = 0.0\n",
      "Epoch 92: Train Loss = 0.0089378298987304, Recall = 1.0, Aging Rate = 0.5488172043010753, Precision = 0.9992163009404389, f1 = 0.999607996863975\n",
      "Epoch 93: Train Loss = 0.008822504699390422, Recall = 1.0, Aging Rate = 0.5483870967741935, Precision = 0, f1 = 0.0\n",
      "Epoch 94: Train Loss = 0.009055009089129908, Recall = 1.0, Aging Rate = 0.5483870967741935, Precision = 0, f1 = 0.0\n",
      "Epoch 95: Train Loss = 0.00903064978278933, Recall = 1.0, Aging Rate = 0.5488172043010753, Precision = 0.9992163009404389, f1 = 0.999607996863975\n",
      "Test Loss = 0.008396729548932403, Recall = 1.0, Aging Rate = 0.5483870967741935, precision = 1.0\n",
      "\n",
      "Epoch 96: Train Loss = 0.008900483869697138, Recall = 1.0, Aging Rate = 0.5483870967741935, Precision = 0, f1 = 0.0\n",
      "Epoch 97: Train Loss = 0.008891629761345284, Recall = 1.0, Aging Rate = 0.5483870967741935, Precision = 0, f1 = 0.0\n",
      "Epoch 98: Train Loss = 0.008921914559098021, Recall = 1.0, Aging Rate = 0.5488172043010753, Precision = 0.9992163009404389, f1 = 0.999607996863975\n",
      "Epoch 99: Train Loss = 0.00922684189773375, Recall = 1.0, Aging Rate = 0.5483870967741935, Precision = 0, f1 = 0.0\n",
      "Epoch 100: Train Loss = 0.009183322918671433, Recall = 1.0, Aging Rate = 0.5488172043010753, Precision = 0.9992163009404389, f1 = 0.999607996863975\n",
      "Test Loss = 0.008262777536086017, Recall = 1.0, Aging Rate = 0.5483870967741935, precision = 1.0\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "015e92728daf4319968fdeeece5dae45",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss = 0.5115183445540341, Recall = 0.9723905723905724, Aging Rate = 0.962862669245648, Precision = 0.5801526717557252, f1 = 0.7267237040764973\n",
      "Epoch 2: Train Loss = 0.3311473264223833, Recall = 0.9831649831649831, Aging Rate = 0.8015473887814313, Precision = 0.7046332046332047, f1 = 0.8209165026707901\n",
      "Epoch 3: Train Loss = 0.22843546478268717, Recall = 0.9764309764309764, Aging Rate = 0.6750483558994197, Precision = 0.830945558739255, f1 = 0.8978328173374613\n",
      "Epoch 4: Train Loss = 0.17903634513542777, Recall = 0.9845117845117846, Aging Rate = 0.6460348162475822, Precision = 0.8754491017964072, f1 = 0.9267828843106181\n",
      "Epoch 5: Train Loss = 0.14224598760531074, Recall = 0.9878787878787879, Aging Rate = 0.6263056092843327, Precision = 0.9061148857319333, f1 = 0.9452319587628867\n",
      "Test Loss = 0.11603658993654602, Recall = 0.9925925925925926, Aging Rate = 0.6104448742746615, precision = 0.9340937896070975\n",
      "Model in epoch 5 is saved.\n",
      "\n",
      "Epoch 6: Train Loss = 0.10903389451870374, Recall = 0.9925925925925926, Aging Rate = 0.6100580270793037, Precision = 0.9346861128725428, f1 = 0.9627694317439581\n",
      "Epoch 7: Train Loss = 0.09016622626862167, Recall = 0.9939393939393939, Aging Rate = 0.602321083172147, Precision = 0.9479768786127167, f1 = 0.9704142011834319\n",
      "Epoch 8: Train Loss = 0.07572441421867109, Recall = 0.9946127946127946, Aging Rate = 0.5972920696324951, Precision = 0.9566062176165803, f1 = 0.9752393529217563\n",
      "Epoch 9: Train Loss = 0.06381086829033765, Recall = 0.9939393939393939, Aging Rate = 0.5914893617021276, Precision = 0.9653368214519293, f1 = 0.9794293297942933\n",
      "Epoch 10: Train Loss = 0.05490116542871731, Recall = 0.9932659932659933, Aging Rate = 0.5868471953578337, Precision = 0.972313777191826, f1 = 0.982678214523651\n",
      "Test Loss = 0.05032338991876497, Recall = 0.997979797979798, Aging Rate = 0.590715667311412, precision = 0.9705304518664047\n",
      "Model in epoch 10 is saved.\n",
      "\n",
      "Epoch 11: Train Loss = 0.047165572770098425, Recall = 0.9952861952861953, Aging Rate = 0.5849129593810445, Precision = 0.9775132275132276, f1 = 0.9863196529863197\n",
      "Epoch 12: Train Loss = 0.043216410737549546, Recall = 0.9952861952861953, Aging Rate = 0.5822050290135397, Precision = 0.9820598006644519, f1 = 0.9886287625418061\n",
      "Epoch 13: Train Loss = 0.03802336051526914, Recall = 0.997979797979798, Aging Rate = 0.583752417794971, Precision = 0.9821073558648111, f1 = 0.9899799599198396\n",
      "Epoch 14: Train Loss = 0.03396619711453149, Recall = 0.997979797979798, Aging Rate = 0.581431334622824, Precision = 0.9860279441117764, f1 = 0.9919678714859437\n",
      "Epoch 15: Train Loss = 0.030831641212422798, Recall = 0.9966329966329966, Aging Rate = 0.5802707930367504, Precision = 0.9866666666666667, f1 = 0.9916247906197655\n",
      "Test Loss = 0.02690063458173833, Recall = 0.997979797979798, Aging Rate = 0.579110251450677, precision = 0.9899799599198397\n",
      "Model in epoch 15 is saved.\n",
      "\n",
      "Epoch 16: Train Loss = 0.02758522407805666, Recall = 0.997979797979798, Aging Rate = 0.5806576402321083, Precision = 0.9873417721518988, f1 = 0.9926322839919625\n",
      "Epoch 17: Train Loss = 0.025429252255527838, Recall = 0.9986531986531987, Aging Rate = 0.5794970986460348, Precision = 0.9899866488651535, f1 = 0.9943010392222595\n",
      "Epoch 18: Train Loss = 0.0234013438109503, Recall = 0.997979797979798, Aging Rate = 0.579110251450677, Precision = 0.9899799599198397, f1 = 0.993963782696177\n",
      "Epoch 19: Train Loss = 0.02135946578841577, Recall = 0.9986531986531987, Aging Rate = 0.5779497098646035, Precision = 0.9926372155287818, f1 = 0.995636119503189\n",
      "Epoch 20: Train Loss = 0.019064246674835666, Recall = 0.9986531986531987, Aging Rate = 0.5779497098646035, Precision = 0.9926372155287818, f1 = 0.995636119503189\n",
      "Test Loss = 0.01864168400762736, Recall = 1.0, Aging Rate = 0.5802707930367504, precision = 0.99\n",
      "Model in epoch 20 is saved.\n",
      "\n",
      "Epoch 21: Train Loss = 0.018340990541780247, Recall = 0.9993265993265993, Aging Rate = 0.5783365570599613, Precision = 0.9926421404682274, f1 = 0.9959731543624161\n",
      "Epoch 22: Train Loss = 0.017125788958638734, Recall = 0.9993265993265993, Aging Rate = 0.5779497098646035, Precision = 0.9933065595716198, f1 = 0.9963074857334676\n",
      "Epoch 23: Train Loss = 0.015374656870773844, Recall = 1.0, Aging Rate = 0.5775628626692456, Precision = 0.9946416610850636, f1 = 0.9973136333109469\n",
      "Epoch 24: Train Loss = 0.01383466746953516, Recall = 1.0, Aging Rate = 0.5771760154738879, Precision = 0.9953083109919572, f1 = 0.997648639570037\n",
      "Epoch 25: Train Loss = 0.013407827916283095, Recall = 1.0, Aging Rate = 0.5771760154738879, Precision = 0.9953083109919572, f1 = 0.997648639570037\n",
      "Test Loss = 0.012051944777268621, Recall = 1.0, Aging Rate = 0.5775628626692456, precision = 0.9946416610850636\n",
      "Model in epoch 25 is saved.\n",
      "\n",
      "Epoch 26: Train Loss = 0.012623308030474116, Recall = 1.0, Aging Rate = 0.57678916827853, Precision = 0.9959758551307847, f1 = 0.9979838709677419\n",
      "Epoch 27: Train Loss = 0.011276267691582038, Recall = 1.0, Aging Rate = 0.5775628626692456, Precision = 0.9946416610850636, f1 = 0.9973136333109469\n",
      "Epoch 28: Train Loss = 0.010731570814633508, Recall = 1.0, Aging Rate = 0.5764023210831721, Precision = 0.9966442953020134, f1 = 0.9983193277310924\n",
      "Epoch 29: Train Loss = 0.010201897851157235, Recall = 1.0, Aging Rate = 0.57678916827853, Precision = 0.9959758551307847, f1 = 0.9979838709677419\n",
      "Epoch 30: Train Loss = 0.009471101454698717, Recall = 1.0, Aging Rate = 0.5760154738878143, Precision = 0.9973136333109469, f1 = 0.9986550100874243\n",
      "Test Loss = 0.008438123009983645, Recall = 1.0, Aging Rate = 0.5764023210831721, precision = 0.9966442953020134\n",
      "Model in epoch 30 is saved.\n",
      "\n",
      "Epoch 31: Train Loss = 0.008683247814347653, Recall = 1.0, Aging Rate = 0.5760154738878143, Precision = 0.9973136333109469, f1 = 0.9986550100874243\n",
      "Epoch 32: Train Loss = 0.008406493122143602, Recall = 1.0, Aging Rate = 0.5764023210831721, Precision = 0.9966442953020134, f1 = 0.9983193277310924\n",
      "Epoch 33: Train Loss = 0.007961777322412229, Recall = 1.0, Aging Rate = 0.5764023210831721, Precision = 0.9966442953020134, f1 = 0.9983193277310924\n",
      "Epoch 34: Train Loss = 0.007511705500244863, Recall = 1.0, Aging Rate = 0.5760154738878143, Precision = 0.9973136333109469, f1 = 0.9986550100874243\n",
      "Epoch 35: Train Loss = 0.0072080196746997895, Recall = 1.0, Aging Rate = 0.5764023210831721, Precision = 0.9966442953020134, f1 = 0.9983193277310924\n",
      "Test Loss = 0.006801465700103089, Recall = 1.0, Aging Rate = 0.5756286266924565, precision = 0.9979838709677419\n",
      "Model in epoch 35 is saved.\n",
      "\n",
      "Epoch 36: Train Loss = 0.007190759827669284, Recall = 1.0, Aging Rate = 0.5760154738878143, Precision = 0.9973136333109469, f1 = 0.9986550100874243\n",
      "Epoch 37: Train Loss = 0.0064544550107154324, Recall = 1.0, Aging Rate = 0.5756286266924565, Precision = 0.9979838709677419, f1 = 0.9989909182643794\n",
      "Epoch 38: Train Loss = 0.006280161634495579, Recall = 1.0, Aging Rate = 0.5756286266924565, Precision = 0.9979838709677419, f1 = 0.9989909182643794\n",
      "Epoch 39: Train Loss = 0.00581701043759053, Recall = 1.0, Aging Rate = 0.5756286266924565, Precision = 0.9979838709677419, f1 = 0.9989909182643794\n",
      "Epoch 40: Train Loss = 0.005543221415126808, Recall = 1.0, Aging Rate = 0.5756286266924565, Precision = 0.9979838709677419, f1 = 0.9989909182643794\n",
      "Test Loss = 0.0047371390054085265, Recall = 1.0, Aging Rate = 0.5752417794970986, precision = 0.9986550100874243\n",
      "Model in epoch 40 is saved.\n",
      "\n",
      "Epoch 41: Train Loss = 0.005366296705211615, Recall = 1.0, Aging Rate = 0.5756286266924565, Precision = 0.9979838709677419, f1 = 0.9989909182643794\n",
      "Epoch 42: Train Loss = 0.0052440819299889715, Recall = 1.0, Aging Rate = 0.5756286266924565, Precision = 0.9979838709677419, f1 = 0.9989909182643794\n",
      "Epoch 43: Train Loss = 0.00498176357381017, Recall = 1.0, Aging Rate = 0.5756286266924565, Precision = 0.9979838709677419, f1 = 0.9989909182643794\n",
      "Epoch 44: Train Loss = 0.004644705798491346, Recall = 1.0, Aging Rate = 0.5756286266924565, Precision = 0.9979838709677419, f1 = 0.9989909182643794\n",
      "Epoch 45: Train Loss = 0.004616605963493108, Recall = 1.0, Aging Rate = 0.5756286266924565, Precision = 0.9979838709677419, f1 = 0.9989909182643794\n",
      "Test Loss = 0.0041475647543439895, Recall = 1.0, Aging Rate = 0.5752417794970986, precision = 0.9986550100874243\n",
      "\n",
      "Epoch 46: Train Loss = 0.004192039179498586, Recall = 1.0, Aging Rate = 0.5756286266924565, Precision = 0.9979838709677419, f1 = 0.9989909182643794\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 47: Train Loss = 0.00415029217132387, Recall = 1.0, Aging Rate = 0.5756286266924565, Precision = 0.9979838709677419, f1 = 0.9989909182643794\n",
      "Epoch 48: Train Loss = 0.004019366864050149, Recall = 1.0, Aging Rate = 0.5756286266924565, Precision = 0.9979838709677419, f1 = 0.9989909182643794\n",
      "Epoch 49: Train Loss = 0.003813222552446119, Recall = 1.0, Aging Rate = 0.5752417794970986, Precision = 0.9986550100874243, f1 = 0.9993270524899057\n",
      "Epoch 50: Train Loss = 0.0036893470420878618, Recall = 1.0, Aging Rate = 0.5756286266924565, Precision = 0.9979838709677419, f1 = 0.9989909182643794\n",
      "Test Loss = 0.003238192296765269, Recall = 1.0, Aging Rate = 0.5752417794970986, precision = 0.9986550100874243\n",
      "\n",
      "Epoch 51: Train Loss = 0.003734846585349142, Recall = 1.0, Aging Rate = 0.5756286266924565, Precision = 0.9979838709677419, f1 = 0.9989909182643794\n",
      "Epoch 52: Train Loss = 0.0034623932071314763, Recall = 1.0, Aging Rate = 0.5752417794970986, Precision = 0.9986550100874243, f1 = 0.9993270524899057\n",
      "Epoch 53: Train Loss = 0.0032466494139172207, Recall = 1.0, Aging Rate = 0.5752417794970986, Precision = 0.9986550100874243, f1 = 0.9993270524899057\n",
      "Epoch 54: Train Loss = 0.003334537112853009, Recall = 1.0, Aging Rate = 0.5752417794970986, Precision = 0.9986550100874243, f1 = 0.9993270524899057\n",
      "Epoch 55: Train Loss = 0.0032320758617866777, Recall = 1.0, Aging Rate = 0.5748549323017408, Precision = 0.9993270524899058, f1 = 0.9996634129922585\n",
      "Test Loss = 0.002872286047390167, Recall = 1.0, Aging Rate = 0.5748549323017408, precision = 0.9993270524899058\n",
      "Model in epoch 55 is saved.\n",
      "\n",
      "Epoch 56: Train Loss = 0.0031134368315865095, Recall = 1.0, Aging Rate = 0.5756286266924565, Precision = 0.9979838709677419, f1 = 0.9989909182643794\n",
      "Epoch 57: Train Loss = 0.0030714323095224322, Recall = 1.0, Aging Rate = 0.5752417794970986, Precision = 0.9986550100874243, f1 = 0.9993270524899057\n",
      "Epoch 58: Train Loss = 0.0029578539526641254, Recall = 1.0, Aging Rate = 0.5752417794970986, Precision = 0.9986550100874243, f1 = 0.9993270524899057\n",
      "Epoch 59: Train Loss = 0.002842532573862279, Recall = 1.0, Aging Rate = 0.5748549323017408, Precision = 0.9993270524899058, f1 = 0.9996634129922585\n",
      "Epoch 60: Train Loss = 0.0028647928427530155, Recall = 1.0, Aging Rate = 0.5748549323017408, Precision = 0.9993270524899058, f1 = 0.9996634129922585\n",
      "Test Loss = 0.002428961175942444, Recall = 1.0, Aging Rate = 0.5748549323017408, precision = 0.9993270524899058\n",
      "\n",
      "Epoch 61: Train Loss = 0.0026995319228194205, Recall = 1.0, Aging Rate = 0.5752417794970986, Precision = 0.9986550100874243, f1 = 0.9993270524899057\n",
      "Epoch 62: Train Loss = 0.0024911859308727937, Recall = 1.0, Aging Rate = 0.5748549323017408, Precision = 0.9993270524899058, f1 = 0.9996634129922585\n",
      "Epoch 63: Train Loss = 0.002818407595060348, Recall = 1.0, Aging Rate = 0.5748549323017408, Precision = 0.9993270524899058, f1 = 0.9996634129922585\n",
      "Epoch 64: Train Loss = 0.0024667624767862506, Recall = 1.0, Aging Rate = 0.5748549323017408, Precision = 0.9993270524899058, f1 = 0.9996634129922585\n",
      "Epoch 65: Train Loss = 0.0025890076842124805, Recall = 1.0, Aging Rate = 0.5748549323017408, Precision = 0.9993270524899058, f1 = 0.9996634129922585\n",
      "Test Loss = 0.0021022606342022145, Recall = 1.0, Aging Rate = 0.5748549323017408, precision = 0.9993270524899058\n",
      "\n",
      "Epoch 66: Train Loss = 0.002507959938305475, Recall = 1.0, Aging Rate = 0.5748549323017408, Precision = 0.9993270524899058, f1 = 0.9996634129922585\n",
      "Epoch 67: Train Loss = 0.002327661543392812, Recall = 1.0, Aging Rate = 0.5748549323017408, Precision = 0.9993270524899058, f1 = 0.9996634129922585\n",
      "Epoch 68: Train Loss = 0.002388013421381757, Recall = 1.0, Aging Rate = 0.5748549323017408, Precision = 0.9993270524899058, f1 = 0.9996634129922585\n",
      "Epoch 69: Train Loss = 0.0026517204640386354, Recall = 1.0, Aging Rate = 0.5748549323017408, Precision = 0.9993270524899058, f1 = 0.9996634129922585\n",
      "Epoch 70: Train Loss = 0.0024629844901128536, Recall = 1.0, Aging Rate = 0.5748549323017408, Precision = 0.9993270524899058, f1 = 0.9996634129922585\n",
      "Test Loss = 0.0018987176569657872, Recall = 1.0, Aging Rate = 0.5748549323017408, precision = 0.9993270524899058\n",
      "\n",
      "Epoch 71: Train Loss = 0.0020907385548580315, Recall = 1.0, Aging Rate = 0.5748549323017408, Precision = 0.9993270524899058, f1 = 0.9996634129922585\n",
      "Epoch 72: Train Loss = 0.002193879203715972, Recall = 1.0, Aging Rate = 0.5748549323017408, Precision = 0.9993270524899058, f1 = 0.9996634129922585\n",
      "Epoch 73: Train Loss = 0.002199300275881355, Recall = 1.0, Aging Rate = 0.5748549323017408, Precision = 0.9993270524899058, f1 = 0.9996634129922585\n",
      "Epoch 74: Train Loss = 0.002364767656969609, Recall = 1.0, Aging Rate = 0.5748549323017408, Precision = 0.9993270524899058, f1 = 0.9996634129922585\n",
      "Epoch 75: Train Loss = 0.0019602469220393604, Recall = 1.0, Aging Rate = 0.5748549323017408, Precision = 0.9993270524899058, f1 = 0.9996634129922585\n",
      "Test Loss = 0.0018013506299569282, Recall = 1.0, Aging Rate = 0.5748549323017408, precision = 0.9993270524899058\n",
      "\n",
      "Epoch 76: Train Loss = 0.001975513858688235, Recall = 1.0, Aging Rate = 0.5748549323017408, Precision = 0.9993270524899058, f1 = 0.9996634129922585\n",
      "Epoch 77: Train Loss = 0.001968400511796977, Recall = 1.0, Aging Rate = 0.5748549323017408, Precision = 0.9993270524899058, f1 = 0.9996634129922585\n",
      "Epoch 78: Train Loss = 0.00205117665682478, Recall = 1.0, Aging Rate = 0.5748549323017408, Precision = 0.9993270524899058, f1 = 0.9996634129922585\n",
      "Epoch 79: Train Loss = 0.001957923124185844, Recall = 1.0, Aging Rate = 0.5748549323017408, Precision = 0.9993270524899058, f1 = 0.9996634129922585\n",
      "Epoch 80: Train Loss = 0.001990070233816854, Recall = 1.0, Aging Rate = 0.574468085106383, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0015912515501044979, Recall = 1.0, Aging Rate = 0.5748549323017408, precision = 0.9993270524899058\n",
      "\n",
      "Epoch 81: Train Loss = 0.0019691615779429306, Recall = 1.0, Aging Rate = 0.5748549323017408, Precision = 0.9993270524899058, f1 = 0.9996634129922585\n",
      "Epoch 82: Train Loss = 0.0017281121754031663, Recall = 1.0, Aging Rate = 0.574468085106383, Precision = 0, f1 = 0.0\n",
      "Epoch 83: Train Loss = 0.001749032233752548, Recall = 1.0, Aging Rate = 0.5748549323017408, Precision = 0.9993270524899058, f1 = 0.9996634129922585\n",
      "Epoch 84: Train Loss = 0.0019464263233592162, Recall = 1.0, Aging Rate = 0.5748549323017408, Precision = 0.9993270524899058, f1 = 0.9996634129922585\n",
      "Epoch 85: Train Loss = 0.0018696977501119012, Recall = 1.0, Aging Rate = 0.5748549323017408, Precision = 0.9993270524899058, f1 = 0.9996634129922585\n",
      "Test Loss = 0.0017537730380287485, Recall = 1.0, Aging Rate = 0.5748549323017408, precision = 0.9993270524899058\n",
      "\n",
      "Epoch 86: Train Loss = 0.0017318393513145974, Recall = 1.0, Aging Rate = 0.5748549323017408, Precision = 0.9993270524899058, f1 = 0.9996634129922585\n",
      "Epoch 87: Train Loss = 0.001863649028386719, Recall = 1.0, Aging Rate = 0.5748549323017408, Precision = 0.9993270524899058, f1 = 0.9996634129922585\n",
      "Epoch 88: Train Loss = 0.0017387829483639832, Recall = 1.0, Aging Rate = 0.5748549323017408, Precision = 0.9993270524899058, f1 = 0.9996634129922585\n",
      "Epoch 89: Train Loss = 0.0016879276168484032, Recall = 1.0, Aging Rate = 0.574468085106383, Precision = 0, f1 = 0.0\n",
      "Epoch 90: Train Loss = 0.001581709374127841, Recall = 1.0, Aging Rate = 0.5748549323017408, Precision = 0.9993270524899058, f1 = 0.9996634129922585\n",
      "Test Loss = 0.0017249641291944876, Recall = 1.0, Aging Rate = 0.574468085106383, precision = 1.0\n",
      "Model in epoch 90 is saved.\n",
      "\n",
      "Epoch 91: Train Loss = 0.0019546703109427624, Recall = 1.0, Aging Rate = 0.5748549323017408, Precision = 0.9993270524899058, f1 = 0.9996634129922585\n",
      "Epoch 92: Train Loss = 0.0016679628767033523, Recall = 1.0, Aging Rate = 0.5748549323017408, Precision = 0.9993270524899058, f1 = 0.9996634129922585\n",
      "Epoch 93: Train Loss = 0.001673787418794341, Recall = 1.0, Aging Rate = 0.574468085106383, Precision = 0, f1 = 0.0\n",
      "Epoch 94: Train Loss = 0.00171114822635265, Recall = 1.0, Aging Rate = 0.5748549323017408, Precision = 0.9993270524899058, f1 = 0.9996634129922585\n",
      "Epoch 95: Train Loss = 0.00198477376117308, Recall = 1.0, Aging Rate = 0.5748549323017408, Precision = 0.9993270524899058, f1 = 0.9996634129922585\n",
      "Test Loss = 0.0017498493342294685, Recall = 1.0, Aging Rate = 0.5748549323017408, precision = 0.9993270524899058\n",
      "\n",
      "Epoch 96: Train Loss = 0.0017836948917958908, Recall = 1.0, Aging Rate = 0.5748549323017408, Precision = 0.9993270524899058, f1 = 0.9996634129922585\n",
      "Epoch 97: Train Loss = 0.0016997333283322671, Recall = 1.0, Aging Rate = 0.574468085106383, Precision = 0, f1 = 0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 98: Train Loss = 0.001895399718064404, Recall = 1.0, Aging Rate = 0.5748549323017408, Precision = 0.9993270524899058, f1 = 0.9996634129922585\n",
      "Epoch 99: Train Loss = 0.0018757971983330462, Recall = 1.0, Aging Rate = 0.574468085106383, Precision = 0, f1 = 0.0\n",
      "Epoch 100: Train Loss = 0.0016483218087346384, Recall = 1.0, Aging Rate = 0.5748549323017408, Precision = 0.9993270524899058, f1 = 0.9996634129922585\n",
      "Test Loss = 0.001369215027119323, Recall = 1.0, Aging Rate = 0.574468085106383, precision = 1.0\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b7bb9e30222645b0ad800bdaa3050058",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "08e3131c76684636a82bc30ee0482d36",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss = 0.3488600528149894, Recall = 0.9242424242424242, Aging Rate = 0.6590909090909091, Precision = 0.7011494252873564, f1 = 0.7973856209150327\n",
      "Epoch 2: Train Loss = 0.12010692823113817, Recall = 0.9696969696969697, Aging Rate = 0.5212121212121212, Precision = 0.9302325581395349, f1 = 0.9495548961424333\n",
      "Epoch 3: Train Loss = 0.0539840363417611, Recall = 0.9863636363636363, Aging Rate = 0.503030303030303, Precision = 0.9804216867469879, f1 = 0.9833836858006042\n",
      "Epoch 4: Train Loss = 0.04104331266699415, Recall = 0.9939393939393939, Aging Rate = 0.503030303030303, Precision = 0.9879518072289156, f1 = 0.9909365558912386\n",
      "Epoch 5: Train Loss = 0.024384359160268848, Recall = 0.996969696969697, Aging Rate = 0.5, Precision = 0.996969696969697, f1 = 0.996969696969697\n",
      "Test Loss = 0.0057955347184994906, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "Model in epoch 5 is saved.\n",
      "\n",
      "Epoch 6: Train Loss = 0.005080815003902623, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 7: Train Loss = 0.0022594266796879697, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 8: Train Loss = 0.0016561339581103035, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 9: Train Loss = 0.00141950307597378, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 10: Train Loss = 0.0011847009974052056, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0010472314608650226, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 11: Train Loss = 0.0010797435269606385, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 12: Train Loss = 0.0009879239658458214, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 13: Train Loss = 0.0009334160597063601, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 14: Train Loss = 0.0008860115681520917, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 15: Train Loss = 0.0008462797377653646, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0007991620740953791, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 16: Train Loss = 0.0008503672497516329, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 17: Train Loss = 0.000820658356304083, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 18: Train Loss = 0.0008054692128842527, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 19: Train Loss = 0.0008224834659785935, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 20: Train Loss = 0.0007947283634690172, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0007392173962822804, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 21: Train Loss = 0.0008004024857655168, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 22: Train Loss = 0.0008362728026413331, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 23: Train Loss = 0.0008022553458541745, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 24: Train Loss = 0.0007798273504401247, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 25: Train Loss = 0.0007810889369328365, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0007209585804957896, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 26: Train Loss = 0.0008441067738176295, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 27: Train Loss = 0.000777759892993014, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 28: Train Loss = 0.0007902161966106205, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 29: Train Loss = 0.0007876944364838753, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 30: Train Loss = 0.0007764451657280777, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0006931456373863373, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 31: Train Loss = 0.0007441725151500467, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 32: Train Loss = 0.0007482185439474768, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 33: Train Loss = 0.0007762409291568805, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 34: Train Loss = 0.0007688857322191876, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 35: Train Loss = 0.00078037033813554, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0006923677648459984, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 36: Train Loss = 0.0007748345404362418, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 37: Train Loss = 0.0007497875217461225, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 38: Train Loss = 0.0008407774049291303, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 39: Train Loss = 0.0007236309127289463, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 40: Train Loss = 0.0007269813310510168, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0006359182541597296, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 41: Train Loss = 0.0007009981235376362, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 42: Train Loss = 0.0007131623097159194, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 43: Train Loss = 0.0007487660690182538, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 44: Train Loss = 0.0007556579774245619, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 45: Train Loss = 0.0007457413876457422, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0006543147596389507, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 46: Train Loss = 0.0007012910659382628, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 47: Train Loss = 0.0006880801619086979, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 48: Train Loss = 0.0007523389508467958, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 49: Train Loss = 0.0007599122201402982, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 50: Train Loss = 0.0006960982964797453, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.000629023874926409, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 51: Train Loss = 0.0007441617816573743, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 52: Train Loss = 0.0007830418013106806, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 53: Train Loss = 0.0006865601651511635, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 54: Train Loss = 0.0006797620211727917, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 55: Train Loss = 0.0006945975188335235, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0006270556858825413, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Training Finished at epoch 55.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2bcb46e11abd4a439dab905abdefb3cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss = 0.3447285824730283, Recall = 0.9228571428571428, Aging Rate = 0.6057142857142858, Precision = 0.7617924528301887, f1 = 0.834625322997416\n",
      "Epoch 2: Train Loss = 0.12577050028812317, Recall = 0.9542857142857143, Aging Rate = 0.5, Precision = 0.9542857142857143, f1 = 0.9542857142857143\n",
      "Epoch 3: Train Loss = 0.05216234726565225, Recall = 0.9895238095238095, Aging Rate = 0.5009523809523809, Precision = 0.9876425855513308, f1 = 0.9885823025689819\n",
      "Epoch 4: Train Loss = 0.04152183029978048, Recall = 0.9866666666666667, Aging Rate = 0.5009523809523809, Precision = 0.9847908745247148, f1 = 0.9857278782112274\n",
      "Epoch 5: Train Loss = 0.024364784037073452, Recall = 0.9942857142857143, Aging Rate = 0.5004761904761905, Precision = 0.9933396764985728, f1 = 0.9938124702522608\n",
      "Test Loss = 0.008284812007276784, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "Model in epoch 5 is saved.\n",
      "\n",
      "Epoch 6: Train Loss = 0.006062433321383737, Recall = 1.0, Aging Rate = 0.5004761904761905, Precision = 0.9990485252140818, f1 = 0.9995240361732509\n",
      "Epoch 7: Train Loss = 0.0029667340544983745, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 8: Train Loss = 0.0019847759635498127, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 9: Train Loss = 0.001574542982326377, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 10: Train Loss = 0.0014146221034406197, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0013599049924163237, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 11: Train Loss = 0.0013327098243115913, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 12: Train Loss = 0.0012366999104796422, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 13: Train Loss = 0.0011958467053426872, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 14: Train Loss = 0.0011577853735625033, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 15: Train Loss = 0.0011292898428759404, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0010418194103320795, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 16: Train Loss = 0.0010845748531366033, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 17: Train Loss = 0.001078870031383953, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 18: Train Loss = 0.0010655716981827503, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 19: Train Loss = 0.0010595390160701105, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 20: Train Loss = 0.0010612281021617708, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0010465935912604134, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 21: Train Loss = 0.0010449774778403696, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 22: Train Loss = 0.0010315082812060912, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 23: Train Loss = 0.0010070240253671294, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 24: Train Loss = 0.0010229936024794975, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 25: Train Loss = 0.0010236870213633491, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0009517549543220195, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 26: Train Loss = 0.0010300902303840432, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 27: Train Loss = 0.0010080879498716622, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 28: Train Loss = 0.0010026296044123315, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 29: Train Loss = 0.0010029859734433037, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 30: Train Loss = 0.0010270661270866792, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0008855351568421438, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 31: Train Loss = 0.0010310718051290938, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 32: Train Loss = 0.0009949863377204608, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 33: Train Loss = 0.0009496277941036083, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 34: Train Loss = 0.0009425158301989237, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 35: Train Loss = 0.0009791992363032131, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.000863371277117126, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 36: Train Loss = 0.0009693742186451952, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 37: Train Loss = 0.0010601276323376667, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 38: Train Loss = 0.0010111882978872883, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 39: Train Loss = 0.0009155879351532175, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 40: Train Loss = 0.0008729648392736203, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0007966449934368332, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 41: Train Loss = 0.0009008044721780434, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 42: Train Loss = 0.0009174506446080549, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 43: Train Loss = 0.0011261419362078111, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 44: Train Loss = 0.0010129305862245106, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 45: Train Loss = 0.0008930675390486916, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0008336636793267514, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 46: Train Loss = 0.0008969975764020568, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 47: Train Loss = 0.0008538014214995894, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 48: Train Loss = 0.0008573135280139035, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 49: Train Loss = 0.0008458731242544239, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 50: Train Loss = 0.0009680452160093756, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0007751890605626007, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 51: Train Loss = 0.0009141457420108574, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 52: Train Loss = 0.0014491240169099045, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 53: Train Loss = 0.05855941202136732, Recall = 0.9838095238095238, Aging Rate = 0.5057142857142857, Precision = 0.972693032015066, f1 = 0.9782196969696969\n",
      "Epoch 54: Train Loss = 0.028089220754447437, Recall = 0.9933333333333333, Aging Rate = 0.5023809523809524, Precision = 0.9886255924170616, f1 = 0.9909738717339668\n",
      "Epoch 55: Train Loss = 0.011834101115486452, Recall = 0.9961904761904762, Aging Rate = 0.5014285714285714, Precision = 0.99335232668566, f1 = 0.9947693770803613\n",
      "Test Loss = 0.002667001068475656, Recall = 0.9990476190476191, Aging Rate = 0.49952380952380954, precision = 1.0\n",
      "\n",
      "Training Finished at epoch 55.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "627f2e0b2f3840a8b83617eceffc56d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss = 0.41424257029186595, Recall = 0.9309090909090909, Aging Rate = 0.7004545454545454, Precision = 0.6645035691109669, f1 = 0.775463839454752\n",
      "Epoch 2: Train Loss = 0.17568903413685885, Recall = 0.9645454545454546, Aging Rate = 0.5395454545454546, Precision = 0.8938500421229991, f1 = 0.9278530826410144\n",
      "Epoch 3: Train Loss = 0.10083217830820516, Recall = 0.9781818181818182, Aging Rate = 0.5181818181818182, Precision = 0.9438596491228071, f1 = 0.9607142857142856\n",
      "Epoch 4: Train Loss = 0.061352027749473396, Recall = 0.9881818181818182, Aging Rate = 0.5113636363636364, Precision = 0.9662222222222222, f1 = 0.9770786516853932\n",
      "Epoch 5: Train Loss = 0.049611927914348514, Recall = 0.990909090909091, Aging Rate = 0.5063636363636363, Precision = 0.9784560143626571, f1 = 0.9846431797651309\n",
      "Test Loss = 0.0228201809423891, Recall = 1.0, Aging Rate = 0.505, precision = 0.9900990099009901\n",
      "Model in epoch 5 is saved.\n",
      "\n",
      "Epoch 6: Train Loss = 0.016756142445585945, Recall = 1.0, Aging Rate = 0.5027272727272727, Precision = 0.9945750452079566, f1 = 0.9972801450589301\n",
      "Epoch 7: Train Loss = 0.010264794363386252, Recall = 1.0, Aging Rate = 0.5018181818181818, Precision = 0.9963768115942029, f1 = 0.9981851179673321\n",
      "Epoch 8: Train Loss = 0.006156192506578836, Recall = 1.0, Aging Rate = 0.5004545454545455, Precision = 0.9990917347865577, f1 = 0.999545661063153\n",
      "Epoch 9: Train Loss = 0.0044371519246223295, Recall = 1.0, Aging Rate = 0.5009090909090909, Precision = 0.9981851179673321, f1 = 0.9990917347865577\n",
      "Epoch 10: Train Loss = 0.003898903297429735, Recall = 1.0, Aging Rate = 0.5004545454545455, Precision = 0.9990917347865577, f1 = 0.999545661063153\n",
      "Test Loss = 0.003050125055015087, Recall = 1.0, Aging Rate = 0.5004545454545455, precision = 0.9990917347865577\n",
      "Model in epoch 10 is saved.\n",
      "\n",
      "Epoch 11: Train Loss = 0.003227312346412377, Recall = 1.0, Aging Rate = 0.5004545454545455, Precision = 0.9990917347865577, f1 = 0.999545661063153\n",
      "Epoch 12: Train Loss = 0.002684241790663112, Recall = 1.0, Aging Rate = 0.5004545454545455, Precision = 0.9990917347865577, f1 = 0.999545661063153\n",
      "Epoch 13: Train Loss = 0.0033464187967844985, Recall = 0.9990909090909091, Aging Rate = 0.5, Precision = 0.9990909090909091, f1 = 0.9990909090909091\n",
      "Epoch 14: Train Loss = 0.0021780701755249703, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 15: Train Loss = 0.0021738814549859273, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0019487095188180153, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "Model in epoch 15 is saved.\n",
      "\n",
      "Epoch 16: Train Loss = 0.0024917638589712706, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 17: Train Loss = 0.0018354527906260707, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 18: Train Loss = 0.0017244350182061845, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 19: Train Loss = 0.0016291392065415327, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 20: Train Loss = 0.001708690667186271, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0014728651427536863, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 21: Train Loss = 0.0015394325461238624, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 22: Train Loss = 0.001495426931545477, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 23: Train Loss = 0.0014811669645661658, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 24: Train Loss = 0.001528023484755646, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 25: Train Loss = 0.0015625001468949698, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0016067219677973878, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 26: Train Loss = 0.0015190946065228093, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 27: Train Loss = 0.001508828205987811, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 28: Train Loss = 0.0014079215098172426, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 29: Train Loss = 0.0013862952016378668, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 30: Train Loss = 0.0015770304795693268, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0012828340554948557, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 31: Train Loss = 0.001571182468059388, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 32: Train Loss = 0.001778705531985245, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 33: Train Loss = 0.0013649645443497734, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 34: Train Loss = 0.0012719588497103276, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 35: Train Loss = 0.0014276807454668664, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0011440765133804895, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 36: Train Loss = 0.0012472585307180203, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 37: Train Loss = 0.001514820451001552, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 38: Train Loss = 0.0013919836244630542, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 39: Train Loss = 0.0013172468784349886, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 40: Train Loss = 0.0013796805370260368, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.001114974228072573, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 41: Train Loss = 0.0012376293273303996, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 42: Train Loss = 0.0014513931491158226, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 43: Train Loss = 0.014481593263758854, Recall = 0.9972727272727273, Aging Rate = 0.5027272727272727, Precision = 0.9918625678119349, f1 = 0.9945602901178605\n",
      "Epoch 44: Train Loss = 0.05968944964083758, Recall = 0.9854545454545455, Aging Rate = 0.5072727272727273, Precision = 0.9713261648745519, f1 = 0.9783393501805053\n",
      "Epoch 45: Train Loss = 0.04651535726914351, Recall = 0.9872727272727273, Aging Rate = 0.5118181818181818, Precision = 0.9644760213143873, f1 = 0.9757412398921833\n",
      "Test Loss = 0.013429657923988998, Recall = 0.9936363636363637, Aging Rate = 0.49818181818181817, precision = 0.9972627737226277\n",
      "\n",
      "Epoch 46: Train Loss = 0.010461129707030274, Recall = 0.9972727272727273, Aging Rate = 0.49954545454545457, Precision = 0.9981801637852593, f1 = 0.9977262391996362\n",
      "Epoch 47: Train Loss = 0.003972722200944025, Recall = 1.0, Aging Rate = 0.5009090909090909, Precision = 0.9981851179673321, f1 = 0.9990917347865577\n",
      "Epoch 48: Train Loss = 0.000997671785404567, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 49: Train Loss = 0.000584739167031578, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 50: Train Loss = 0.000534513368355957, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0005110175228169696, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 51: Train Loss = 0.0005716032525312833, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 52: Train Loss = 0.0005758305971341376, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 53: Train Loss = 0.0005858096763999625, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 54: Train Loss = 0.000559740145531991, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 55: Train Loss = 0.0006161236346021972, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0005743637613274834, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 56: Train Loss = 0.0006672380102629011, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 57: Train Loss = 0.0006403596321417188, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 58: Train Loss = 0.0006485968124417757, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 59: Train Loss = 0.0006597282954978503, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 60: Train Loss = 0.0006903846494176171, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0006308342898476191, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 61: Train Loss = 0.0006999652832746506, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 62: Train Loss = 0.0007008109604728154, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 63: Train Loss = 0.0007537175900175829, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 64: Train Loss = 0.0008031618279743601, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 65: Train Loss = 0.0007945034741847352, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0007487002101896162, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Training Finished at epoch 65.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6fb949d630d546f7a1a6d619c6bc5768",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "76d8b76d380b46c3897d678e9afdb232",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss = 0.6811217643997886, Recall = 0.20454545454545456, Aging Rate = 0.15, Precision = 0.6818181818181818, f1 = 0.3146853146853147\n",
      "Epoch 2: Train Loss = 0.6124393289739435, Recall = 0.6272727272727273, Aging Rate = 0.33484848484848484, Precision = 0.9366515837104072, f1 = 0.7513611615245009\n",
      "Epoch 3: Train Loss = 0.5340428113937378, Recall = 0.7742424242424243, Aging Rate = 0.40984848484848485, Precision = 0.944547134935305, f1 = 0.8509575353871773\n",
      "Epoch 4: Train Loss = 0.44732181484049016, Recall = 0.8090909090909091, Aging Rate = 0.43257575757575756, Precision = 0.9352014010507881, f1 = 0.867587327376117\n",
      "Epoch 5: Train Loss = 0.36444237503138455, Recall = 0.8666666666666667, Aging Rate = 0.4621212121212121, Precision = 0.9377049180327869, f1 = 0.9007874015748032\n",
      "Test Loss = 0.3197726878252896, Recall = 0.9363636363636364, Aging Rate = 0.4954545454545455, precision = 0.944954128440367\n",
      "Model in epoch 5 is saved.\n",
      "\n",
      "Epoch 6: Train Loss = 0.292703929272565, Recall = 0.956060606060606, Aging Rate = 0.5045454545454545, Precision = 0.9474474474474475, f1 = 0.9517345399698341\n",
      "Epoch 7: Train Loss = 0.23924316249110483, Recall = 0.9727272727272728, Aging Rate = 0.5068181818181818, Precision = 0.9596412556053812, f1 = 0.9661399548532731\n",
      "Epoch 8: Train Loss = 0.2001158437945626, Recall = 0.9727272727272728, Aging Rate = 0.503030303030303, Precision = 0.9668674698795181, f1 = 0.9697885196374623\n",
      "Epoch 9: Train Loss = 0.1718524672768333, Recall = 0.9727272727272728, Aging Rate = 0.5045454545454545, Precision = 0.963963963963964, f1 = 0.9683257918552037\n",
      "Epoch 10: Train Loss = 0.1505590795115991, Recall = 0.9742424242424242, Aging Rate = 0.4984848484848485, Precision = 0.9772036474164134, f1 = 0.975720789074355\n",
      "Test Loss = 0.14033148776401172, Recall = 0.9772727272727273, Aging Rate = 0.5, precision = 0.9772727272727273\n",
      "Model in epoch 10 is saved.\n",
      "\n",
      "Epoch 11: Train Loss = 0.134883267771114, Recall = 0.9757575757575757, Aging Rate = 0.49924242424242427, Precision = 0.9772382397572079, f1 = 0.976497346474602\n",
      "Epoch 12: Train Loss = 0.12258070016449148, Recall = 0.9803030303030303, Aging Rate = 0.5007575757575757, Precision = 0.9788199697428139, f1 = 0.9795609386828161\n",
      "Epoch 13: Train Loss = 0.11331004134633324, Recall = 0.9787878787878788, Aging Rate = 0.4954545454545455, Precision = 0.9877675840978594, f1 = 0.9832572298325722\n",
      "Epoch 14: Train Loss = 0.10559954223307697, Recall = 0.9803030303030303, Aging Rate = 0.4962121212121212, Precision = 0.9877862595419847, f1 = 0.9840304182509506\n",
      "Epoch 15: Train Loss = 0.09990486014973034, Recall = 0.9787878787878788, Aging Rate = 0.4954545454545455, Precision = 0.9877675840978594, f1 = 0.9832572298325722\n",
      "Test Loss = 0.09704889777031812, Recall = 0.9803030303030303, Aging Rate = 0.4962121212121212, precision = 0.9877862595419847\n",
      "Model in epoch 15 is saved.\n",
      "\n",
      "Epoch 16: Train Loss = 0.0964269142259251, Recall = 0.9772727272727273, Aging Rate = 0.4946969696969697, Precision = 0.9877488514548239, f1 = 0.9824828636709825\n",
      "Epoch 17: Train Loss = 0.09114788662303577, Recall = 0.9818181818181818, Aging Rate = 0.49696969696969695, Precision = 0.9878048780487805, f1 = 0.9848024316109422\n",
      "Epoch 18: Train Loss = 0.08701879355040464, Recall = 0.9818181818181818, Aging Rate = 0.4962121212121212, Precision = 0.9893129770992366, f1 = 0.985551330798479\n",
      "Epoch 19: Train Loss = 0.08401226198131388, Recall = 0.9863636363636363, Aging Rate = 0.49772727272727274, Precision = 0.9908675799086758, f1 = 0.9886104783599089\n",
      "Epoch 20: Train Loss = 0.08138190385970202, Recall = 0.9818181818181818, Aging Rate = 0.4954545454545455, Precision = 0.9908256880733946, f1 = 0.9863013698630138\n",
      "Test Loss = 0.07815244644880295, Recall = 0.9863636363636363, Aging Rate = 0.49772727272727274, precision = 0.9908675799086758\n",
      "Model in epoch 20 is saved.\n",
      "\n",
      "Epoch 21: Train Loss = 0.07870022451335734, Recall = 0.9833333333333333, Aging Rate = 0.4962121212121212, Precision = 0.9908396946564886, f1 = 0.9870722433460075\n",
      "Epoch 22: Train Loss = 0.07568925104357979, Recall = 0.990909090909091, Aging Rate = 0.5, Precision = 0.990909090909091, f1 = 0.990909090909091\n",
      "Epoch 23: Train Loss = 0.07401819879358465, Recall = 0.9833333333333333, Aging Rate = 0.4946969696969697, Precision = 0.9938744257274119, f1 = 0.9885757806549884\n",
      "Epoch 24: Train Loss = 0.07178238447416913, Recall = 0.9924242424242424, Aging Rate = 0.49924242424242427, Precision = 0.9939301972685888, f1 = 0.9931766489764974\n",
      "Epoch 25: Train Loss = 0.07085037461735985, Recall = 0.9893939393939394, Aging Rate = 0.49696969696969695, Precision = 0.9954268292682927, f1 = 0.9924012158054711\n",
      "Test Loss = 0.06899531185626984, Recall = 0.9924242424242424, Aging Rate = 0.5007575757575757, precision = 0.9909228441754917\n",
      "Model in epoch 25 is saved.\n",
      "\n",
      "Epoch 26: Train Loss = 0.0687347408045422, Recall = 0.9893939393939394, Aging Rate = 0.49772727272727274, Precision = 0.9939117199391172, f1 = 0.9916476841305998\n",
      "Epoch 27: Train Loss = 0.06755870418115095, Recall = 0.990909090909091, Aging Rate = 0.49772727272727274, Precision = 0.9954337899543378, f1 = 0.9931662870159453\n",
      "Epoch 28: Train Loss = 0.06621741381558505, Recall = 0.990909090909091, Aging Rate = 0.49696969696969695, Precision = 0.9969512195121951, f1 = 0.993920972644377\n",
      "Epoch 29: Train Loss = 0.06548803110014309, Recall = 0.990909090909091, Aging Rate = 0.4984848484848485, Precision = 0.993920972644377, f1 = 0.9924127465857361\n",
      "Epoch 30: Train Loss = 0.0640631410885941, Recall = 0.990909090909091, Aging Rate = 0.4954545454545455, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.06342722475528717, Recall = 0.9924242424242424, Aging Rate = 0.4984848484848485, precision = 0.9954407294832827\n",
      "Model in epoch 30 is saved.\n",
      "\n",
      "Epoch 31: Train Loss = 0.06352413825013421, Recall = 0.9924242424242424, Aging Rate = 0.4984848484848485, Precision = 0.9954407294832827, f1 = 0.9939301972685887\n",
      "Epoch 32: Train Loss = 0.06230866732922467, Recall = 0.9924242424242424, Aging Rate = 0.49696969696969695, Precision = 0.9984756097560976, f1 = 0.9954407294832827\n",
      "Epoch 33: Train Loss = 0.061845392530614676, Recall = 0.990909090909091, Aging Rate = 0.49696969696969695, Precision = 0.9969512195121951, f1 = 0.993920972644377\n",
      "Epoch 34: Train Loss = 0.060627692599188196, Recall = 0.9924242424242424, Aging Rate = 0.49696969696969695, Precision = 0.9984756097560976, f1 = 0.9954407294832827\n",
      "Epoch 35: Train Loss = 0.06114419211040844, Recall = 0.9893939393939394, Aging Rate = 0.4954545454545455, Precision = 0.9984709480122325, f1 = 0.9939117199391173\n",
      "Test Loss = 0.05844084579836239, Recall = 0.9924242424242424, Aging Rate = 0.4962121212121212, precision = 1.0\n",
      "Model in epoch 35 is saved.\n",
      "\n",
      "Epoch 36: Train Loss = 0.059305962784723804, Recall = 0.990909090909091, Aging Rate = 0.4954545454545455, Precision = 0, f1 = 0.0\n",
      "Epoch 37: Train Loss = 0.0593331897800619, Recall = 0.9893939393939394, Aging Rate = 0.49696969696969695, Precision = 0.9954268292682927, f1 = 0.9924012158054711\n",
      "Epoch 38: Train Loss = 0.05745502290400592, Recall = 0.990909090909091, Aging Rate = 0.4954545454545455, Precision = 0, f1 = 0.0\n",
      "Epoch 39: Train Loss = 0.05740854130549864, Recall = 0.9924242424242424, Aging Rate = 0.4962121212121212, Precision = 0, f1 = 0.0\n",
      "Epoch 40: Train Loss = 0.05690308741547845, Recall = 0.990909090909091, Aging Rate = 0.4954545454545455, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0554852923209017, Recall = 0.9924242424242424, Aging Rate = 0.4962121212121212, precision = 1.0\n",
      "\n",
      "Epoch 41: Train Loss = 0.056404509869488806, Recall = 0.9924242424242424, Aging Rate = 0.4962121212121212, Precision = 0, f1 = 0.0\n",
      "Epoch 42: Train Loss = 0.05675015950744802, Recall = 0.990909090909091, Aging Rate = 0.4954545454545455, Precision = 0, f1 = 0.0\n",
      "Epoch 43: Train Loss = 0.055592505498365925, Recall = 0.9924242424242424, Aging Rate = 0.4962121212121212, Precision = 0, f1 = 0.0\n",
      "Epoch 44: Train Loss = 0.05497109768065539, Recall = 0.9893939393939394, Aging Rate = 0.4946969696969697, Precision = 0, f1 = 0.0\n",
      "Epoch 45: Train Loss = 0.055557977882298555, Recall = 0.9924242424242424, Aging Rate = 0.4962121212121212, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.05449521568688479, Recall = 0.990909090909091, Aging Rate = 0.4954545454545455, precision = 1.0\n",
      "\n",
      "Epoch 46: Train Loss = 0.05423806539990685, Recall = 0.9924242424242424, Aging Rate = 0.4962121212121212, Precision = 0, f1 = 0.0\n",
      "Epoch 47: Train Loss = 0.054387643662366, Recall = 0.9893939393939394, Aging Rate = 0.4946969696969697, Precision = 0, f1 = 0.0\n",
      "Epoch 48: Train Loss = 0.054227351194078274, Recall = 0.9924242424242424, Aging Rate = 0.4962121212121212, Precision = 0, f1 = 0.0\n",
      "Epoch 49: Train Loss = 0.05350852337750522, Recall = 0.990909090909091, Aging Rate = 0.4954545454545455, Precision = 0, f1 = 0.0\n",
      "Epoch 50: Train Loss = 0.05290962193499912, Recall = 0.9924242424242424, Aging Rate = 0.4962121212121212, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.05201841985637491, Recall = 0.9924242424242424, Aging Rate = 0.4962121212121212, precision = 1.0\n",
      "\n",
      "Epoch 51: Train Loss = 0.05333872986110774, Recall = 0.9924242424242424, Aging Rate = 0.49772727272727274, Precision = 0.9969558599695586, f1 = 0.9946848899012908\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 52: Train Loss = 0.05329116718335585, Recall = 0.990909090909091, Aging Rate = 0.4954545454545455, Precision = 0, f1 = 0.0\n",
      "Epoch 53: Train Loss = 0.052802956375208765, Recall = 0.990909090909091, Aging Rate = 0.4954545454545455, Precision = 0, f1 = 0.0\n",
      "Epoch 54: Train Loss = 0.052814883671023626, Recall = 0.9924242424242424, Aging Rate = 0.4962121212121212, Precision = 0, f1 = 0.0\n",
      "Epoch 55: Train Loss = 0.05203068120913072, Recall = 0.9924242424242424, Aging Rate = 0.49696969696969695, Precision = 0.9984756097560976, f1 = 0.9954407294832827\n",
      "Test Loss = 0.05455873493443836, Recall = 0.9924242424242424, Aging Rate = 0.5007575757575757, precision = 0.9909228441754917\n",
      "\n",
      "Epoch 56: Train Loss = 0.053817259723489934, Recall = 0.990909090909091, Aging Rate = 0.4962121212121212, Precision = 0.9984732824427481, f1 = 0.9946768060836502\n",
      "Epoch 57: Train Loss = 0.05191060196269642, Recall = 0.9924242424242424, Aging Rate = 0.4962121212121212, Precision = 0, f1 = 0.0\n",
      "Epoch 58: Train Loss = 0.05148995098742572, Recall = 0.9924242424242424, Aging Rate = 0.4962121212121212, Precision = 0, f1 = 0.0\n",
      "Epoch 59: Train Loss = 0.05134664963592182, Recall = 0.9924242424242424, Aging Rate = 0.4962121212121212, Precision = 0, f1 = 0.0\n",
      "Epoch 60: Train Loss = 0.050757055255499756, Recall = 0.9924242424242424, Aging Rate = 0.4962121212121212, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.049819585951891815, Recall = 0.9924242424242424, Aging Rate = 0.4962121212121212, precision = 1.0\n",
      "\n",
      "Epoch 61: Train Loss = 0.050931379266760564, Recall = 0.9924242424242424, Aging Rate = 0.4962121212121212, Precision = 0, f1 = 0.0\n",
      "Epoch 62: Train Loss = 0.050994494625113226, Recall = 0.990909090909091, Aging Rate = 0.4954545454545455, Precision = 0, f1 = 0.0\n",
      "Epoch 63: Train Loss = 0.0507592999799685, Recall = 0.990909090909091, Aging Rate = 0.4954545454545455, Precision = 0, f1 = 0.0\n",
      "Epoch 64: Train Loss = 0.05083081762899052, Recall = 0.9924242424242424, Aging Rate = 0.4962121212121212, Precision = 0, f1 = 0.0\n",
      "Epoch 65: Train Loss = 0.05082961205731739, Recall = 0.990909090909091, Aging Rate = 0.4954545454545455, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.04949977804314006, Recall = 0.9924242424242424, Aging Rate = 0.4962121212121212, precision = 1.0\n",
      "\n",
      "Epoch 66: Train Loss = 0.05039204873821952, Recall = 0.990909090909091, Aging Rate = 0.4954545454545455, Precision = 0, f1 = 0.0\n",
      "Epoch 67: Train Loss = 0.05042910467494618, Recall = 0.990909090909091, Aging Rate = 0.4954545454545455, Precision = 0, f1 = 0.0\n",
      "Epoch 68: Train Loss = 0.0501783010634509, Recall = 0.9924242424242424, Aging Rate = 0.4962121212121212, Precision = 0, f1 = 0.0\n",
      "Epoch 69: Train Loss = 0.050204871865836054, Recall = 0.9924242424242424, Aging Rate = 0.4962121212121212, Precision = 0, f1 = 0.0\n",
      "Epoch 70: Train Loss = 0.05026190009984103, Recall = 0.9924242424242424, Aging Rate = 0.4962121212121212, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.050884091718630356, Recall = 0.9878787878787879, Aging Rate = 0.49393939393939396, precision = 1.0\n",
      "\n",
      "Epoch 71: Train Loss = 0.050866356898437846, Recall = 0.9924242424242424, Aging Rate = 0.4962121212121212, Precision = 0, f1 = 0.0\n",
      "Epoch 72: Train Loss = 0.050204070860689336, Recall = 0.990909090909091, Aging Rate = 0.4954545454545455, Precision = 0, f1 = 0.0\n",
      "Epoch 73: Train Loss = 0.0505973832173781, Recall = 0.990909090909091, Aging Rate = 0.4954545454545455, Precision = 0, f1 = 0.0\n",
      "Epoch 74: Train Loss = 0.05068773959170688, Recall = 0.9924242424242424, Aging Rate = 0.4962121212121212, Precision = 0, f1 = 0.0\n",
      "Epoch 75: Train Loss = 0.04964593716643073, Recall = 0.9924242424242424, Aging Rate = 0.4962121212121212, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.04841555573723533, Recall = 0.9924242424242424, Aging Rate = 0.4962121212121212, precision = 1.0\n",
      "\n",
      "Epoch 76: Train Loss = 0.049070547724312005, Recall = 0.990909090909091, Aging Rate = 0.4954545454545455, Precision = 0, f1 = 0.0\n",
      "Epoch 77: Train Loss = 0.04998999806967649, Recall = 0.990909090909091, Aging Rate = 0.4954545454545455, Precision = 0, f1 = 0.0\n",
      "Epoch 78: Train Loss = 0.049026949771425944, Recall = 0.990909090909091, Aging Rate = 0.4954545454545455, Precision = 0, f1 = 0.0\n",
      "Epoch 79: Train Loss = 0.05021527368913997, Recall = 0.990909090909091, Aging Rate = 0.4954545454545455, Precision = 0, f1 = 0.0\n",
      "Epoch 80: Train Loss = 0.04947673211043531, Recall = 0.9924242424242424, Aging Rate = 0.4962121212121212, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.04820322753353552, Recall = 0.9924242424242424, Aging Rate = 0.4962121212121212, precision = 1.0\n",
      "\n",
      "Epoch 81: Train Loss = 0.04889615760608153, Recall = 0.9924242424242424, Aging Rate = 0.4962121212121212, Precision = 0, f1 = 0.0\n",
      "Epoch 82: Train Loss = 0.04973776604641567, Recall = 0.990909090909091, Aging Rate = 0.4954545454545455, Precision = 0, f1 = 0.0\n",
      "Epoch 83: Train Loss = 0.04935125085440549, Recall = 0.9924242424242424, Aging Rate = 0.4962121212121212, Precision = 0, f1 = 0.0\n",
      "Epoch 84: Train Loss = 0.048848509111187675, Recall = 0.9924242424242424, Aging Rate = 0.4962121212121212, Precision = 0, f1 = 0.0\n",
      "Epoch 85: Train Loss = 0.04914341968568889, Recall = 0.9924242424242424, Aging Rate = 0.4962121212121212, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.04837085821411826, Recall = 0.9924242424242424, Aging Rate = 0.4962121212121212, precision = 1.0\n",
      "\n",
      "Training Finished at epoch 85.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5055ce4c88014fe889a916eb5b8fa1d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss = 0.3529384676047734, Recall = 0.8904761904761904, Aging Rate = 0.5623809523809524, Precision = 0.7917019475021169, f1 = 0.8381891528462573\n",
      "Epoch 2: Train Loss = 0.11909531572035381, Recall = 0.9685714285714285, Aging Rate = 0.5057142857142857, Precision = 0.9576271186440678, f1 = 0.9630681818181818\n",
      "Epoch 3: Train Loss = 0.06583455402936254, Recall = 0.98, Aging Rate = 0.4976190476190476, Precision = 0.9846889952153111, f1 = 0.9823389021479714\n",
      "Epoch 4: Train Loss = 0.04287961942808969, Recall = 0.9904761904761905, Aging Rate = 0.5, Precision = 0.9904761904761905, f1 = 0.9904761904761905\n",
      "Epoch 5: Train Loss = 0.026754933524699438, Recall = 0.9914285714285714, Aging Rate = 0.49714285714285716, Precision = 0.9971264367816092, f1 = 0.994269340974212\n",
      "Test Loss = 0.01205660631614072, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "Model in epoch 5 is saved.\n",
      "\n",
      "Epoch 6: Train Loss = 0.008948611453885124, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 7: Train Loss = 0.004420422053496752, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 8: Train Loss = 0.0026021474546619825, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 9: Train Loss = 0.0021000051799984205, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 10: Train Loss = 0.0018440444468121443, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0016598411472070786, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 11: Train Loss = 0.0016538449004292488, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 12: Train Loss = 0.0015043642043712593, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 13: Train Loss = 0.001440072955918454, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 14: Train Loss = 0.0013373637594105232, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 15: Train Loss = 0.0012650749713758983, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0011355338839902764, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 16: Train Loss = 0.0012237529039737724, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 17: Train Loss = 0.0012005232007331436, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 18: Train Loss = 0.0011609594429665734, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 19: Train Loss = 0.0011279867895479714, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 20: Train Loss = 0.0010963023842001955, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0010162685303727076, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 21: Train Loss = 0.0010652208066589776, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 22: Train Loss = 0.0010292936606510054, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 23: Train Loss = 0.001048830892846343, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 24: Train Loss = 0.00104525568451555, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 25: Train Loss = 0.0010139870945186842, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0009022398587937156, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 26: Train Loss = 0.0009942547047865533, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 27: Train Loss = 0.0009937004801551146, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 28: Train Loss = 0.000980768276023723, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 29: Train Loss = 0.00106243839332213, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 30: Train Loss = 0.0009625289877433152, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0008423542849985617, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 31: Train Loss = 0.0009247001417956891, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 32: Train Loss = 0.000937880931333417, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 33: Train Loss = 0.0009410455716507775, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 34: Train Loss = 0.0011589174495921248, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 35: Train Loss = 0.006009568556965816, Recall = 0.9990476190476191, Aging Rate = 0.5004761904761905, Precision = 0.9980970504281637, f1 = 0.9985721085197524\n",
      "Test Loss = 0.018855465526382127, Recall = 0.9961904761904762, Aging Rate = 0.4980952380952381, precision = 1.0\n",
      "\n",
      "Epoch 36: Train Loss = 0.03241955738692057, Recall = 0.9914285714285714, Aging Rate = 0.5047619047619047, Precision = 0.9820754716981132, f1 = 0.9867298578199052\n",
      "Epoch 37: Train Loss = 0.02627788411187274, Recall = 0.9923809523809524, Aging Rate = 0.5014285714285714, Precision = 0.9895536562203229, f1 = 0.9909652876842606\n",
      "Epoch 38: Train Loss = 0.00502011255089504, Recall = 0.9990476190476191, Aging Rate = 0.5004761904761905, Precision = 0.9980970504281637, f1 = 0.9985721085197524\n",
      "Epoch 39: Train Loss = 0.0009369954779478056, Recall = 0.9990476190476191, Aging Rate = 0.49952380952380954, Precision = 0, f1 = 0.0\n",
      "Epoch 40: Train Loss = 0.001428099631198815, Recall = 1.0, Aging Rate = 0.5004761904761905, Precision = 0.9990485252140818, f1 = 0.9995240361732509\n",
      "Test Loss = 0.0013111876100966972, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 41: Train Loss = 0.000498961636940727, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 42: Train Loss = 0.00022950477903664466, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 43: Train Loss = 0.00020965683542835037, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 44: Train Loss = 0.00023311152366832608, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 45: Train Loss = 0.00026394686007517437, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0002666471876104229, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 46: Train Loss = 0.0002971370175336709, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 47: Train Loss = 0.0003289278387092054, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 48: Train Loss = 0.0003636976599781996, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 49: Train Loss = 0.0003964034022231187, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 50: Train Loss = 0.00041883548017635587, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.000416704660858072, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 51: Train Loss = 0.00045805589013200783, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 52: Train Loss = 0.0004849170290288471, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 53: Train Loss = 0.0005083080409981665, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 54: Train Loss = 0.0005308514563200464, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 55: Train Loss = 0.0005591130816555094, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.000537680683469045, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Training Finished at epoch 55.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fbcc4459dc4f4fa998be9a32effd7ebc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss = 0.5788045354322954, Recall = 0.6763636363636364, Aging Rate = 0.4068181818181818, Precision = 0.8312849162011173, f1 = 0.7458646616541355\n",
      "Epoch 2: Train Loss = 0.3241219074617733, Recall = 0.9018181818181819, Aging Rate = 0.49636363636363634, Precision = 0.9084249084249084, f1 = 0.905109489051095\n",
      "Epoch 3: Train Loss = 0.19504002993757075, Recall = 0.9318181818181818, Aging Rate = 0.48772727272727273, Precision = 0.9552656104380243, f1 = 0.9433962264150944\n",
      "Epoch 4: Train Loss = 0.1498036893931302, Recall = 0.9572727272727273, Aging Rate = 0.4954545454545455, Precision = 0.9660550458715597, f1 = 0.9616438356164384\n",
      "Epoch 5: Train Loss = 0.1107070822336457, Recall = 0.9636363636363636, Aging Rate = 0.49318181818181817, Precision = 0.9769585253456221, f1 = 0.9702517162471396\n",
      "Test Loss = 0.08918252705173059, Recall = 0.9654545454545455, Aging Rate = 0.49, precision = 0.9851576994434137\n",
      "Model in epoch 5 is saved.\n",
      "\n",
      "Epoch 6: Train Loss = 0.08596343976530162, Recall = 0.97, Aging Rate = 0.49272727272727274, Precision = 0.9843173431734318, f1 = 0.9771062271062272\n",
      "Epoch 7: Train Loss = 0.07048890360377051, Recall = 0.9763636363636363, Aging Rate = 0.495, Precision = 0.9862258953168044, f1 = 0.9812699862951119\n",
      "Epoch 8: Train Loss = 0.057119467522610316, Recall = 0.9790909090909091, Aging Rate = 0.4940909090909091, Precision = 0.9908003679852806, f1 = 0.9849108367626888\n",
      "Epoch 9: Train Loss = 0.04879282530058514, Recall = 0.9845454545454545, Aging Rate = 0.4968181818181818, Precision = 0.9908508691674291, f1 = 0.987688098495212\n",
      "Epoch 10: Train Loss = 0.041129203310067, Recall = 0.9854545454545455, Aging Rate = 0.4959090909090909, Precision = 0.9935838680109991, f1 = 0.9895025102692835\n",
      "Test Loss = 0.03622067001732913, Recall = 0.9854545454545455, Aging Rate = 0.49363636363636365, precision = 0.998158379373849\n",
      "Model in epoch 10 is saved.\n",
      "\n",
      "Epoch 11: Train Loss = 0.035307572267272255, Recall = 0.9872727272727273, Aging Rate = 0.49636363636363634, Precision = 0.9945054945054945, f1 = 0.9908759124087592\n",
      "Epoch 12: Train Loss = 0.030523799007589166, Recall = 0.990909090909091, Aging Rate = 0.49727272727272726, Precision = 0.9963436928702011, f1 = 0.9936189608021878\n",
      "Epoch 13: Train Loss = 0.026442497284574942, Recall = 0.99, Aging Rate = 0.4959090909090909, Precision = 0.998166819431714, f1 = 0.9940666362391601\n",
      "Epoch 14: Train Loss = 0.023078663413497534, Recall = 0.990909090909091, Aging Rate = 0.4968181818181818, Precision = 0.9972552607502287, f1 = 0.9940720474236205\n",
      "Epoch 15: Train Loss = 0.020673290226947177, Recall = 0.9927272727272727, Aging Rate = 0.49772727272727274, Precision = 0.9972602739726028, f1 = 0.99498861047836\n",
      "Test Loss = 0.01769102008505301, Recall = 0.9954545454545455, Aging Rate = 0.49863636363636366, precision = 0.9981768459434822\n",
      "Model in epoch 15 is saved.\n",
      "\n",
      "Epoch 16: Train Loss = 0.017751967319372026, Recall = 0.9936363636363637, Aging Rate = 0.49727272727272726, Precision = 0.9990859232175503, f1 = 0.9963536918869644\n",
      "Epoch 17: Train Loss = 0.015857838124714113, Recall = 0.9963636363636363, Aging Rate = 0.49863636363636366, Precision = 0.9990884229717412, f1 = 0.9977241693218024\n",
      "Epoch 18: Train Loss = 0.014386548523537138, Recall = 0.9963636363636363, Aging Rate = 0.4990909090909091, Precision = 0.9981785063752276, f1 = 0.997270245677889\n",
      "Epoch 19: Train Loss = 0.012794649109921672, Recall = 0.9954545454545455, Aging Rate = 0.49863636363636366, Precision = 0.9981768459434822, f1 = 0.9968138370505234\n",
      "Epoch 20: Train Loss = 0.010781670517542145, Recall = 0.9990909090909091, Aging Rate = 0.5, Precision = 0.9990909090909091, f1 = 0.9990909090909091\n",
      "Test Loss = 0.010742688338187608, Recall = 0.9963636363636363, Aging Rate = 0.49818181818181817, precision = 1.0\n",
      "Model in epoch 20 is saved.\n",
      "\n",
      "Epoch 21: Train Loss = 0.01075278964401646, Recall = 0.9963636363636363, Aging Rate = 0.49818181818181817, Precision = 0, f1 = 0.0\n",
      "Epoch 22: Train Loss = 0.009354105237871408, Recall = 0.9990909090909091, Aging Rate = 0.5, Precision = 0.9990909090909091, f1 = 0.9990909090909091\n",
      "Epoch 23: Train Loss = 0.008845462231812151, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 24: Train Loss = 0.007532893431118943, Recall = 1.0, Aging Rate = 0.5004545454545455, Precision = 0.9990917347865577, f1 = 0.999545661063153\n",
      "Epoch 25: Train Loss = 0.007153745523907922, Recall = 0.9990909090909091, Aging Rate = 0.49954545454545457, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.006212813769551841, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "Model in epoch 25 is saved.\n",
      "\n",
      "Epoch 26: Train Loss = 0.006484884077852422, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 27: Train Loss = 0.006017701379023493, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 28: Train Loss = 0.005870145311240445, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 29: Train Loss = 0.0052356070479039445, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 30: Train Loss = 0.0047914703105661005, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.004374363976107402, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 31: Train Loss = 0.004735048145733096, Recall = 0.9990909090909091, Aging Rate = 0.49954545454545457, Precision = 0, f1 = 0.0\n",
      "Epoch 32: Train Loss = 0.004209975939752026, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 33: Train Loss = 0.004091826624406332, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 34: Train Loss = 0.0038266540513458578, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 35: Train Loss = 0.003506218589926985, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0033061157835816797, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 36: Train Loss = 0.0032751777878200464, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 37: Train Loss = 0.0030758177730339496, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 38: Train Loss = 0.002912557375701991, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 39: Train Loss = 0.002811162481931123, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 40: Train Loss = 0.002565970019945367, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.002475829865698787, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 41: Train Loss = 0.0025525154766033995, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 42: Train Loss = 0.002399363176135177, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 43: Train Loss = 0.002357118856161833, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 44: Train Loss = 0.0023219292890280484, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 45: Train Loss = 0.0021095377460799434, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0019286775009029291, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 46: Train Loss = 0.0020775853340852667, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 47: Train Loss = 0.0019388394095850262, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 48: Train Loss = 0.001984117729589343, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 49: Train Loss = 0.0018672860832884908, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 50: Train Loss = 0.0017705491926013068, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0015714963707564907, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 51: Train Loss = 0.0017211814859712665, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 52: Train Loss = 0.0016151393717154861, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 53: Train Loss = 0.001635175300338729, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 54: Train Loss = 0.0015612056252377277, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 55: Train Loss = 0.0014780674447220834, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0013549279097721657, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 56: Train Loss = 0.0014618492532860149, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 57: Train Loss = 0.001444376207126135, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58: Train Loss = 0.0013863713937726887, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 59: Train Loss = 0.001334304943765429, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 60: Train Loss = 0.001324088424867527, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0012161781255748461, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 61: Train Loss = 0.0013290572695603424, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 62: Train Loss = 0.0012614571485160427, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 63: Train Loss = 0.0012516345773738893, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 64: Train Loss = 0.0011980804679280316, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 65: Train Loss = 0.0011733340440233323, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0012189149772960015, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 66: Train Loss = 0.0012346668435599317, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 67: Train Loss = 0.0011669292779300702, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 68: Train Loss = 0.0011798194256103175, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 69: Train Loss = 0.0011562329769896512, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 70: Train Loss = 0.0012643198791722006, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0010595203447155655, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Epoch 71: Train Loss = 0.001148533487523144, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 72: Train Loss = 0.0010897646977735514, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 73: Train Loss = 0.0011010517332364213, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 74: Train Loss = 0.0010275099899577484, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Epoch 75: Train Loss = 0.0010896511164239862, Recall = 1.0, Aging Rate = 0.5, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0010338618183000521, Recall = 1.0, Aging Rate = 0.5, precision = 1.0\n",
      "\n",
      "Training Finished at epoch 75.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "38852d556884410cb128449dabe54ebf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "80b516a59ca54e0389dcd4fd708bf14b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss = 0.3864830808698638, Recall = 0.10606060606060606, Aging Rate = 0.05509641873278237, Precision = 0.175, f1 = 0.13207547169811318\n",
      "Epoch 2: Train Loss = 0.2542647635641177, Recall = 0.030303030303030304, Aging Rate = 0.0027548209366391185, Precision = 0, f1 = 0.0\n",
      "Epoch 3: Train Loss = 0.18877013544898388, Recall = 0.10606060606060606, Aging Rate = 0.009641873278236915, Precision = 0, f1 = 0.0\n",
      "Epoch 4: Train Loss = 0.14537116959075297, Recall = 0.45454545454545453, Aging Rate = 0.04269972451790634, Precision = 0.967741935483871, f1 = 0.6185567010309277\n",
      "Epoch 5: Train Loss = 0.10973180559548465, Recall = 0.6515151515151515, Aging Rate = 0.05922865013774105, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.08478817716240883, Recall = 0.7878787878787878, Aging Rate = 0.07162534435261708, precision = 1.0\n",
      "Model in epoch 5 is saved.\n",
      "\n",
      "Epoch 6: Train Loss = 0.0793106766833254, Recall = 0.8333333333333334, Aging Rate = 0.081267217630854, Precision = 0.9322033898305084, f1 = 0.8800000000000001\n",
      "Epoch 7: Train Loss = 0.06329501035415437, Recall = 0.8636363636363636, Aging Rate = 0.08264462809917356, Precision = 0.95, f1 = 0.9047619047619048\n",
      "Epoch 8: Train Loss = 0.048469105165852004, Recall = 0.9090909090909091, Aging Rate = 0.08264462809917356, Precision = 0, f1 = 0.0\n",
      "Epoch 9: Train Loss = 0.039589939993028796, Recall = 0.9545454545454546, Aging Rate = 0.08677685950413223, Precision = 0, f1 = 0.0\n",
      "Epoch 10: Train Loss = 0.031543763862414795, Recall = 0.9696969696969697, Aging Rate = 0.0881542699724518, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.025159452710885648, Recall = 0.9696969696969697, Aging Rate = 0.0881542699724518, precision = 1.0\n",
      "Model in epoch 10 is saved.\n",
      "\n",
      "Epoch 11: Train Loss = 0.025288799223451574, Recall = 0.9696969696969697, Aging Rate = 0.0881542699724518, Precision = 0, f1 = 0.0\n",
      "Epoch 12: Train Loss = 0.01804218125675828, Recall = 0.9696969696969697, Aging Rate = 0.0881542699724518, Precision = 0, f1 = 0.0\n",
      "Epoch 13: Train Loss = 0.014456206882634192, Recall = 0.9696969696969697, Aging Rate = 0.0881542699724518, Precision = 0, f1 = 0.0\n",
      "Epoch 14: Train Loss = 0.011201113044892338, Recall = 0.9696969696969697, Aging Rate = 0.0881542699724518, Precision = 0, f1 = 0.0\n",
      "Epoch 15: Train Loss = 0.009154701209049826, Recall = 1.0, Aging Rate = 0.09090909090909091, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.007705915207428134, Recall = 1.0, Aging Rate = 0.09090909090909091, precision = 1.0\n",
      "Model in epoch 15 is saved.\n",
      "\n",
      "Epoch 16: Train Loss = 0.007316561816029312, Recall = 1.0, Aging Rate = 0.09090909090909091, Precision = 0, f1 = 0.0\n",
      "Epoch 17: Train Loss = 0.006370144530607403, Recall = 1.0, Aging Rate = 0.09090909090909091, Precision = 0, f1 = 0.0\n",
      "Epoch 18: Train Loss = 0.005479372735712524, Recall = 1.0, Aging Rate = 0.09090909090909091, Precision = 0, f1 = 0.0\n",
      "Epoch 19: Train Loss = 0.0048638108024789285, Recall = 1.0, Aging Rate = 0.09090909090909091, Precision = 0, f1 = 0.0\n",
      "Epoch 20: Train Loss = 0.004258839842624778, Recall = 1.0, Aging Rate = 0.09090909090909091, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0037829820817136322, Recall = 1.0, Aging Rate = 0.09090909090909091, precision = 1.0\n",
      "\n",
      "Epoch 21: Train Loss = 0.003741452231818487, Recall = 1.0, Aging Rate = 0.09090909090909091, Precision = 0, f1 = 0.0\n",
      "Epoch 22: Train Loss = 0.0034494747884941004, Recall = 1.0, Aging Rate = 0.09090909090909091, Precision = 0, f1 = 0.0\n",
      "Epoch 23: Train Loss = 0.0030565971281564185, Recall = 1.0, Aging Rate = 0.09090909090909091, Precision = 0, f1 = 0.0\n",
      "Epoch 24: Train Loss = 0.00277752424436352, Recall = 1.0, Aging Rate = 0.09090909090909091, Precision = 0, f1 = 0.0\n",
      "Epoch 25: Train Loss = 0.00261005289152203, Recall = 1.0, Aging Rate = 0.09090909090909091, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.002400241430448599, Recall = 1.0, Aging Rate = 0.09090909090909091, precision = 1.0\n",
      "\n",
      "Epoch 26: Train Loss = 0.0023969167320073144, Recall = 1.0, Aging Rate = 0.09090909090909091, Precision = 0, f1 = 0.0\n",
      "Epoch 27: Train Loss = 0.0022486250786003, Recall = 1.0, Aging Rate = 0.09090909090909091, Precision = 0, f1 = 0.0\n",
      "Epoch 28: Train Loss = 0.0021257102604924647, Recall = 1.0, Aging Rate = 0.09090909090909091, Precision = 0, f1 = 0.0\n",
      "Epoch 29: Train Loss = 0.002036441839107674, Recall = 1.0, Aging Rate = 0.09090909090909091, Precision = 0, f1 = 0.0\n",
      "Epoch 30: Train Loss = 0.001926606011573102, Recall = 1.0, Aging Rate = 0.09090909090909091, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0018069022912378153, Recall = 1.0, Aging Rate = 0.09090909090909091, precision = 1.0\n",
      "\n",
      "Epoch 31: Train Loss = 0.001805950052389675, Recall = 1.0, Aging Rate = 0.09090909090909091, Precision = 0, f1 = 0.0\n",
      "Epoch 32: Train Loss = 0.0017423869412746434, Recall = 1.0, Aging Rate = 0.09090909090909091, Precision = 0, f1 = 0.0\n",
      "Epoch 33: Train Loss = 0.0016752311715486745, Recall = 1.0, Aging Rate = 0.09090909090909091, Precision = 0, f1 = 0.0\n",
      "Epoch 34: Train Loss = 0.0015771469276413814, Recall = 1.0, Aging Rate = 0.09090909090909091, Precision = 0, f1 = 0.0\n",
      "Epoch 35: Train Loss = 0.001535496466662273, Recall = 1.0, Aging Rate = 0.09090909090909091, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0014651644496778257, Recall = 1.0, Aging Rate = 0.09090909090909091, precision = 1.0\n",
      "\n",
      "Epoch 36: Train Loss = 0.0014830989751595358, Recall = 1.0, Aging Rate = 0.09090909090909091, Precision = 0, f1 = 0.0\n",
      "Epoch 37: Train Loss = 0.0014931665183129635, Recall = 1.0, Aging Rate = 0.09090909090909091, Precision = 0, f1 = 0.0\n",
      "Epoch 38: Train Loss = 0.0013922457121435768, Recall = 1.0, Aging Rate = 0.09090909090909091, Precision = 0, f1 = 0.0\n",
      "Epoch 39: Train Loss = 0.0013579459964828797, Recall = 1.0, Aging Rate = 0.09090909090909091, Precision = 0, f1 = 0.0\n",
      "Epoch 40: Train Loss = 0.0012874752687182555, Recall = 1.0, Aging Rate = 0.09090909090909091, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0012390032701178892, Recall = 1.0, Aging Rate = 0.09090909090909091, precision = 1.0\n",
      "\n",
      "Epoch 41: Train Loss = 0.0012559795055599992, Recall = 1.0, Aging Rate = 0.09090909090909091, Precision = 0, f1 = 0.0\n",
      "Epoch 42: Train Loss = 0.0012242102457695324, Recall = 1.0, Aging Rate = 0.09090909090909091, Precision = 0, f1 = 0.0\n",
      "Epoch 43: Train Loss = 0.0011983992578076922, Recall = 1.0, Aging Rate = 0.09090909090909091, Precision = 0, f1 = 0.0\n",
      "Epoch 44: Train Loss = 0.001200851048188946, Recall = 1.0, Aging Rate = 0.09090909090909091, Precision = 0, f1 = 0.0\n",
      "Epoch 45: Train Loss = 0.001155220242486574, Recall = 1.0, Aging Rate = 0.09090909090909091, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0011165059644975199, Recall = 1.0, Aging Rate = 0.09090909090909091, precision = 1.0\n",
      "\n",
      "Epoch 46: Train Loss = 0.0011118298140546878, Recall = 1.0, Aging Rate = 0.09090909090909091, Precision = 0, f1 = 0.0\n",
      "Epoch 47: Train Loss = 0.0011103480192255382, Recall = 1.0, Aging Rate = 0.09090909090909091, Precision = 0, f1 = 0.0\n",
      "Epoch 48: Train Loss = 0.0010852773745028564, Recall = 1.0, Aging Rate = 0.09090909090909091, Precision = 0, f1 = 0.0\n",
      "Epoch 49: Train Loss = 0.0010595936015486902, Recall = 1.0, Aging Rate = 0.09090909090909091, Precision = 0, f1 = 0.0\n",
      "Epoch 50: Train Loss = 0.0010924985389848632, Recall = 1.0, Aging Rate = 0.09090909090909091, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0010128499745691488, Recall = 1.0, Aging Rate = 0.09090909090909091, precision = 1.0\n",
      "\n",
      "Epoch 51: Train Loss = 0.001043054392111049, Recall = 1.0, Aging Rate = 0.09090909090909091, Precision = 0, f1 = 0.0\n",
      "Epoch 52: Train Loss = 0.0010278039277061698, Recall = 1.0, Aging Rate = 0.09090909090909091, Precision = 0, f1 = 0.0\n",
      "Epoch 53: Train Loss = 0.0010014107039059735, Recall = 1.0, Aging Rate = 0.09090909090909091, Precision = 0, f1 = 0.0\n",
      "Epoch 54: Train Loss = 0.0009739491328489313, Recall = 1.0, Aging Rate = 0.09090909090909091, Precision = 0, f1 = 0.0\n",
      "Epoch 55: Train Loss = 0.0009748517840615789, Recall = 1.0, Aging Rate = 0.09090909090909091, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0009429040769007334, Recall = 1.0, Aging Rate = 0.09090909090909091, precision = 1.0\n",
      "\n",
      "Epoch 56: Train Loss = 0.0009599389433321997, Recall = 1.0, Aging Rate = 0.09090909090909091, Precision = 0, f1 = 0.0\n",
      "Epoch 57: Train Loss = 0.0009564860061980968, Recall = 1.0, Aging Rate = 0.09090909090909091, Precision = 0, f1 = 0.0\n",
      "Epoch 58: Train Loss = 0.0009407090583108058, Recall = 1.0, Aging Rate = 0.09090909090909091, Precision = 0, f1 = 0.0\n",
      "Epoch 59: Train Loss = 0.0009513604353674619, Recall = 1.0, Aging Rate = 0.09090909090909091, Precision = 0, f1 = 0.0\n",
      "Epoch 60: Train Loss = 0.0009240985824918944, Recall = 1.0, Aging Rate = 0.09090909090909091, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0008983519861536208, Recall = 1.0, Aging Rate = 0.09090909090909091, precision = 1.0\n",
      "\n",
      "Epoch 61: Train Loss = 0.0009230339605253467, Recall = 1.0, Aging Rate = 0.09090909090909091, Precision = 0, f1 = 0.0\n",
      "Epoch 62: Train Loss = 0.0008986512052803492, Recall = 1.0, Aging Rate = 0.09090909090909091, Precision = 0, f1 = 0.0\n",
      "Epoch 63: Train Loss = 0.0008831985669079706, Recall = 1.0, Aging Rate = 0.09090909090909091, Precision = 0, f1 = 0.0\n",
      "Epoch 64: Train Loss = 0.0008838322520648583, Recall = 1.0, Aging Rate = 0.09090909090909091, Precision = 0, f1 = 0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 65: Train Loss = 0.0008795956584571068, Recall = 1.0, Aging Rate = 0.09090909090909091, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0008536087780082522, Recall = 1.0, Aging Rate = 0.09090909090909091, precision = 1.0\n",
      "\n",
      "Training Finished at epoch 65.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "939e12e184634e2795cc3a8e3fc9b05d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss = 0.466792549754118, Recall = 0.009523809523809525, Aging Rate = 0.03722943722943723, Precision = 0.023255813953488372, f1 = 0.013513513513513514\n",
      "Epoch 2: Train Loss = 0.30019413124431266, Recall = 0.2761904761904762, Aging Rate = 0.02943722943722944, Precision = 0.8529411764705882, f1 = 0.4172661870503597\n",
      "Epoch 3: Train Loss = 0.22754336738257439, Recall = 0.6476190476190476, Aging Rate = 0.08311688311688312, Precision = 0.7083333333333334, f1 = 0.6766169154228856\n",
      "Epoch 4: Train Loss = 0.17925861083067857, Recall = 0.7619047619047619, Aging Rate = 0.09264069264069263, Precision = 0.7476635514018691, f1 = 0.7547169811320754\n",
      "Epoch 5: Train Loss = 0.1323761291511647, Recall = 0.8285714285714286, Aging Rate = 0.08484848484848485, Precision = 0.8877551020408163, f1 = 0.8571428571428572\n",
      "Test Loss = 0.10213228318985407, Recall = 0.9333333333333333, Aging Rate = 0.09610389610389611, precision = 0.8828828828828829\n",
      "Model in epoch 5 is saved.\n",
      "\n",
      "Epoch 6: Train Loss = 0.10162592233255409, Recall = 0.8571428571428571, Aging Rate = 0.08398268398268398, Precision = 0.9278350515463918, f1 = 0.8910891089108911\n",
      "Epoch 7: Train Loss = 0.0902798627104078, Recall = 0.9142857142857143, Aging Rate = 0.09350649350649351, Precision = 0.8888888888888888, f1 = 0.9014084507042254\n",
      "Epoch 8: Train Loss = 0.0625683671081221, Recall = 0.9523809523809523, Aging Rate = 0.09350649350649351, Precision = 0.9259259259259259, f1 = 0.9389671361502347\n",
      "Epoch 9: Train Loss = 0.06530134470818878, Recall = 0.9523809523809523, Aging Rate = 0.0987012987012987, Precision = 0.8771929824561403, f1 = 0.9132420091324202\n",
      "Epoch 10: Train Loss = 0.051427435036748646, Recall = 0.9714285714285714, Aging Rate = 0.09437229437229437, Precision = 0.9357798165137615, f1 = 0.9532710280373832\n",
      "Test Loss = 0.03905552319892041, Recall = 0.9714285714285714, Aging Rate = 0.09004329004329005, precision = 0.9807692307692307\n",
      "Model in epoch 10 is saved.\n",
      "\n",
      "Epoch 11: Train Loss = 0.03617494096616646, Recall = 0.9714285714285714, Aging Rate = 0.09090909090909091, Precision = 0.9714285714285714, f1 = 0.9714285714285714\n",
      "Epoch 12: Train Loss = 0.025316552427603393, Recall = 0.9714285714285714, Aging Rate = 0.08831168831168831, Precision = 0, f1 = 0.0\n",
      "Epoch 13: Train Loss = 0.0186627578909521, Recall = 0.9904761904761905, Aging Rate = 0.09090909090909091, Precision = 0.9904761904761905, f1 = 0.9904761904761905\n",
      "Epoch 14: Train Loss = 0.014271378596978529, Recall = 1.0, Aging Rate = 0.09090909090909091, Precision = 0, f1 = 0.0\n",
      "Epoch 15: Train Loss = 0.01115529976799168, Recall = 1.0, Aging Rate = 0.09090909090909091, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.009080985268311841, Recall = 1.0, Aging Rate = 0.09090909090909091, precision = 1.0\n",
      "Model in epoch 15 is saved.\n",
      "\n",
      "Epoch 16: Train Loss = 0.009151093276669634, Recall = 1.0, Aging Rate = 0.09090909090909091, Precision = 0, f1 = 0.0\n",
      "Epoch 17: Train Loss = 0.007143019734845533, Recall = 1.0, Aging Rate = 0.09090909090909091, Precision = 0, f1 = 0.0\n",
      "Epoch 18: Train Loss = 0.007187040827755647, Recall = 1.0, Aging Rate = 0.09177489177489177, Precision = 0.9905660377358491, f1 = 0.9952606635071091\n",
      "Epoch 19: Train Loss = 0.006497072605513979, Recall = 1.0, Aging Rate = 0.09090909090909091, Precision = 0, f1 = 0.0\n",
      "Epoch 20: Train Loss = 0.005826544993883603, Recall = 1.0, Aging Rate = 0.09090909090909091, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.004615357249080168, Recall = 1.0, Aging Rate = 0.09090909090909091, precision = 1.0\n",
      "\n",
      "Epoch 21: Train Loss = 0.005127995570081395, Recall = 1.0, Aging Rate = 0.09090909090909091, Precision = 0, f1 = 0.0\n",
      "Epoch 22: Train Loss = 0.007267477760067234, Recall = 1.0, Aging Rate = 0.09090909090909091, Precision = 0, f1 = 0.0\n",
      "Epoch 23: Train Loss = 0.03063859571158499, Recall = 0.9714285714285714, Aging Rate = 0.08917748917748917, Precision = 0.9902912621359223, f1 = 0.9807692307692307\n",
      "Epoch 24: Train Loss = 0.010930094941724817, Recall = 1.0, Aging Rate = 0.09264069264069263, Precision = 0.9813084112149533, f1 = 0.9905660377358491\n",
      "Epoch 25: Train Loss = 0.009051146640218553, Recall = 1.0, Aging Rate = 0.09177489177489177, Precision = 0.9905660377358491, f1 = 0.9952606635071091\n",
      "Test Loss = 0.00620015598320228, Recall = 1.0, Aging Rate = 0.09177489177489177, precision = 0.9905660377358491\n",
      "\n",
      "Epoch 26: Train Loss = 0.004774045619781752, Recall = 1.0, Aging Rate = 0.09090909090909091, Precision = 0, f1 = 0.0\n",
      "Epoch 27: Train Loss = 0.0038402166275017255, Recall = 1.0, Aging Rate = 0.09090909090909091, Precision = 0, f1 = 0.0\n",
      "Epoch 28: Train Loss = 0.0027146909125874957, Recall = 1.0, Aging Rate = 0.09090909090909091, Precision = 0, f1 = 0.0\n",
      "Epoch 29: Train Loss = 0.002297128476965991, Recall = 1.0, Aging Rate = 0.09090909090909091, Precision = 0, f1 = 0.0\n",
      "Epoch 30: Train Loss = 0.0021242018226630887, Recall = 1.0, Aging Rate = 0.09090909090909091, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0019736377839656705, Recall = 1.0, Aging Rate = 0.09090909090909091, precision = 1.0\n",
      "\n",
      "Epoch 31: Train Loss = 0.00195971647966895, Recall = 1.0, Aging Rate = 0.09090909090909091, Precision = 0, f1 = 0.0\n",
      "Epoch 32: Train Loss = 0.0018725506184235601, Recall = 1.0, Aging Rate = 0.09090909090909091, Precision = 0, f1 = 0.0\n",
      "Epoch 33: Train Loss = 0.0017608224300991943, Recall = 1.0, Aging Rate = 0.09090909090909091, Precision = 0, f1 = 0.0\n",
      "Epoch 34: Train Loss = 0.0016760583063405174, Recall = 1.0, Aging Rate = 0.09090909090909091, Precision = 0, f1 = 0.0\n",
      "Epoch 35: Train Loss = 0.00160639713270372, Recall = 1.0, Aging Rate = 0.09090909090909091, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0015461160140656323, Recall = 1.0, Aging Rate = 0.09090909090909091, precision = 1.0\n",
      "\n",
      "Epoch 36: Train Loss = 0.0015615270744446762, Recall = 1.0, Aging Rate = 0.09090909090909091, Precision = 0, f1 = 0.0\n",
      "Epoch 37: Train Loss = 0.0015156855319124682, Recall = 1.0, Aging Rate = 0.09090909090909091, Precision = 0, f1 = 0.0\n",
      "Epoch 38: Train Loss = 0.0014517486869446846, Recall = 1.0, Aging Rate = 0.09090909090909091, Precision = 0, f1 = 0.0\n",
      "Epoch 39: Train Loss = 0.0014346300517155959, Recall = 1.0, Aging Rate = 0.09090909090909091, Precision = 0, f1 = 0.0\n",
      "Epoch 40: Train Loss = 0.0014042806200828257, Recall = 1.0, Aging Rate = 0.09090909090909091, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0013621674229410006, Recall = 1.0, Aging Rate = 0.09090909090909091, precision = 1.0\n",
      "\n",
      "Epoch 41: Train Loss = 0.0014245967489440266, Recall = 1.0, Aging Rate = 0.09090909090909091, Precision = 0, f1 = 0.0\n",
      "Epoch 42: Train Loss = 0.0013529336549396107, Recall = 1.0, Aging Rate = 0.09090909090909091, Precision = 0, f1 = 0.0\n",
      "Epoch 43: Train Loss = 0.001326820341410575, Recall = 1.0, Aging Rate = 0.09090909090909091, Precision = 0, f1 = 0.0\n",
      "Epoch 44: Train Loss = 0.002011108933782618, Recall = 1.0, Aging Rate = 0.09090909090909091, Precision = 0, f1 = 0.0\n",
      "Epoch 45: Train Loss = 0.001530462217988906, Recall = 1.0, Aging Rate = 0.09090909090909091, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.001396325180601636, Recall = 1.0, Aging Rate = 0.09090909090909091, precision = 1.0\n",
      "\n",
      "Epoch 46: Train Loss = 0.0013669818240617004, Recall = 1.0, Aging Rate = 0.09090909090909091, Precision = 0, f1 = 0.0\n",
      "Epoch 47: Train Loss = 0.0012273784835714024, Recall = 1.0, Aging Rate = 0.09090909090909091, Precision = 0, f1 = 0.0\n",
      "Epoch 48: Train Loss = 0.001432286434528696, Recall = 1.0, Aging Rate = 0.09090909090909091, Precision = 0, f1 = 0.0\n",
      "Epoch 49: Train Loss = 0.0013346396805416164, Recall = 1.0, Aging Rate = 0.09090909090909091, Precision = 0, f1 = 0.0\n",
      "Epoch 50: Train Loss = 0.0012028016355425397, Recall = 1.0, Aging Rate = 0.09090909090909091, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0011178307291676854, Recall = 1.0, Aging Rate = 0.09090909090909091, precision = 1.0\n",
      "\n",
      "Epoch 51: Train Loss = 0.0011177521330522156, Recall = 1.0, Aging Rate = 0.09090909090909091, Precision = 0, f1 = 0.0\n",
      "Epoch 52: Train Loss = 0.0010781716948447676, Recall = 1.0, Aging Rate = 0.09090909090909091, Precision = 0, f1 = 0.0\n",
      "Epoch 53: Train Loss = 0.001125197548890946, Recall = 1.0, Aging Rate = 0.09090909090909091, Precision = 0, f1 = 0.0\n",
      "Epoch 54: Train Loss = 0.00106150980875525, Recall = 1.0, Aging Rate = 0.09090909090909091, Precision = 0, f1 = 0.0\n",
      "Epoch 55: Train Loss = 0.0010296052996093383, Recall = 1.0, Aging Rate = 0.09090909090909091, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0010076128833305404, Recall = 1.0, Aging Rate = 0.09090909090909091, precision = 1.0\n",
      "\n",
      "Epoch 56: Train Loss = 0.001035834000759241, Recall = 1.0, Aging Rate = 0.09090909090909091, Precision = 0, f1 = 0.0\n",
      "Epoch 57: Train Loss = 0.0009857558737996748, Recall = 1.0, Aging Rate = 0.09090909090909091, Precision = 0, f1 = 0.0\n",
      "Epoch 58: Train Loss = 0.0010032842584731445, Recall = 1.0, Aging Rate = 0.09090909090909091, Precision = 0, f1 = 0.0\n",
      "Epoch 59: Train Loss = 0.0010120091079915692, Recall = 1.0, Aging Rate = 0.09090909090909091, Precision = 0, f1 = 0.0\n",
      "Epoch 60: Train Loss = 0.0010320252683614652, Recall = 1.0, Aging Rate = 0.09090909090909091, Precision = 0, f1 = 0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss = 0.0010064686080078027, Recall = 1.0, Aging Rate = 0.09090909090909091, precision = 1.0\n",
      "\n",
      "Epoch 61: Train Loss = 0.0010257735106593258, Recall = 1.0, Aging Rate = 0.09090909090909091, Precision = 0, f1 = 0.0\n",
      "Epoch 62: Train Loss = 0.000983733413801468, Recall = 1.0, Aging Rate = 0.09090909090909091, Precision = 0, f1 = 0.0\n",
      "Epoch 63: Train Loss = 0.0010118611658887042, Recall = 1.0, Aging Rate = 0.09090909090909091, Precision = 0, f1 = 0.0\n",
      "Epoch 64: Train Loss = 0.001048595713929261, Recall = 1.0, Aging Rate = 0.09090909090909091, Precision = 0, f1 = 0.0\n",
      "Epoch 65: Train Loss = 0.0010138346877118403, Recall = 1.0, Aging Rate = 0.09090909090909091, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0009585754114336201, Recall = 1.0, Aging Rate = 0.09090909090909091, precision = 1.0\n",
      "\n",
      "Training Finished at epoch 65.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f4b5e804cd4946fd80445babc0b5322f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss = 0.5296986397632882, Recall = 0.05454545454545454, Aging Rate = 0.05619834710743802, Precision = 0.08823529411764706, f1 = 0.06741573033707865\n",
      "Epoch 2: Train Loss = 0.440920394215702, Recall = 0.0, Aging Rate = 0.0, Precision = 0, f1 = 0\n",
      "Epoch 3: Train Loss = 0.3903938487541577, Recall = 0.03636363636363636, Aging Rate = 0.003305785123966942, Precision = 0, f1 = 0.0\n",
      "Epoch 4: Train Loss = 0.3352051746500425, Recall = 0.18181818181818182, Aging Rate = 0.019008264462809916, Precision = 0.8695652173913043, f1 = 0.30075187969924816\n",
      "Epoch 5: Train Loss = 0.29768807819066956, Recall = 0.39090909090909093, Aging Rate = 0.045454545454545456, Precision = 0.7818181818181819, f1 = 0.5212121212121212\n",
      "Test Loss = 0.2593031784719672, Recall = 0.5363636363636364, Aging Rate = 0.05867768595041322, precision = 0.8309859154929577\n",
      "Model in epoch 5 is saved.\n",
      "\n",
      "Epoch 6: Train Loss = 0.2430054196641465, Recall = 0.5454545454545454, Aging Rate = 0.05867768595041322, Precision = 0.8450704225352113, f1 = 0.6629834254143646\n",
      "Epoch 7: Train Loss = 0.20777037877681825, Recall = 0.6636363636363637, Aging Rate = 0.06611570247933884, Precision = 0.9125, f1 = 0.768421052631579\n",
      "Epoch 8: Train Loss = 0.1824621418290887, Recall = 0.7818181818181819, Aging Rate = 0.08099173553719008, Precision = 0.8775510204081632, f1 = 0.8269230769230769\n",
      "Epoch 9: Train Loss = 0.15621812257392348, Recall = 0.8272727272727273, Aging Rate = 0.08016528925619834, Precision = 0.9381443298969072, f1 = 0.8792270531400965\n",
      "Epoch 10: Train Loss = 0.13591525003560317, Recall = 0.8363636363636363, Aging Rate = 0.0834710743801653, Precision = 0.9108910891089109, f1 = 0.8720379146919431\n",
      "Test Loss = 0.12422552488066933, Recall = 0.8363636363636363, Aging Rate = 0.08016528925619834, precision = 0.9484536082474226\n",
      "Model in epoch 10 is saved.\n",
      "\n",
      "Epoch 11: Train Loss = 0.12322309946964595, Recall = 0.8363636363636363, Aging Rate = 0.08016528925619834, Precision = 0.9484536082474226, f1 = 0.8888888888888888\n",
      "Epoch 12: Train Loss = 0.11163127589201138, Recall = 0.8636363636363636, Aging Rate = 0.08264462809917356, Precision = 0.95, f1 = 0.9047619047619048\n",
      "Epoch 13: Train Loss = 0.10057439171085673, Recall = 0.8818181818181818, Aging Rate = 0.08429752066115702, Precision = 0.9509803921568627, f1 = 0.9150943396226415\n",
      "Epoch 14: Train Loss = 0.08685473228289076, Recall = 0.8818181818181818, Aging Rate = 0.08429752066115702, Precision = 0.9509803921568627, f1 = 0.9150943396226415\n",
      "Epoch 15: Train Loss = 0.07827166466365669, Recall = 0.9090909090909091, Aging Rate = 0.08512396694214876, Precision = 0.970873786407767, f1 = 0.9389671361502346\n",
      "Test Loss = 0.07096071565939376, Recall = 0.9181818181818182, Aging Rate = 0.08429752066115702, precision = 0.9901960784313726\n",
      "Model in epoch 15 is saved.\n",
      "\n",
      "Epoch 16: Train Loss = 0.07127580716590251, Recall = 0.8909090909090909, Aging Rate = 0.08264462809917356, Precision = 0.98, f1 = 0.9333333333333333\n",
      "Epoch 17: Train Loss = 0.06554678279506274, Recall = 0.9181818181818182, Aging Rate = 0.0859504132231405, Precision = 0.9711538461538461, f1 = 0.9439252336448598\n",
      "Epoch 18: Train Loss = 0.059437109997942425, Recall = 0.9363636363636364, Aging Rate = 0.0859504132231405, Precision = 0.9903846153846154, f1 = 0.9626168224299064\n",
      "Epoch 19: Train Loss = 0.05341161537515231, Recall = 0.9818181818181818, Aging Rate = 0.09008264462809917, Precision = 0.9908256880733946, f1 = 0.9863013698630138\n",
      "Epoch 20: Train Loss = 0.05058522846334237, Recall = 0.9545454545454546, Aging Rate = 0.09008264462809917, Precision = 0.963302752293578, f1 = 0.958904109589041\n",
      "Test Loss = 0.04793116788356758, Recall = 0.9818181818181818, Aging Rate = 0.09256198347107437, precision = 0.9642857142857143\n",
      "Model in epoch 20 is saved.\n",
      "\n",
      "Epoch 21: Train Loss = 0.04478718195079772, Recall = 0.9818181818181818, Aging Rate = 0.09090909090909091, Precision = 0.9818181818181818, f1 = 0.9818181818181818\n",
      "Epoch 22: Train Loss = 0.04313511238548874, Recall = 0.9818181818181818, Aging Rate = 0.09008264462809917, Precision = 0.9908256880733946, f1 = 0.9863013698630138\n",
      "Epoch 23: Train Loss = 0.039338263539089396, Recall = 0.9818181818181818, Aging Rate = 0.09090909090909091, Precision = 0.9818181818181818, f1 = 0.9818181818181818\n",
      "Epoch 24: Train Loss = 0.03642958078133173, Recall = 0.9818181818181818, Aging Rate = 0.09173553719008265, Precision = 0.972972972972973, f1 = 0.9773755656108598\n",
      "Epoch 25: Train Loss = 0.03464281855012513, Recall = 0.9818181818181818, Aging Rate = 0.09090909090909091, Precision = 0.9818181818181818, f1 = 0.9818181818181818\n",
      "Test Loss = 0.0318246509910615, Recall = 0.9818181818181818, Aging Rate = 0.09090909090909091, precision = 0.9818181818181818\n",
      "Model in epoch 25 is saved.\n",
      "\n",
      "Epoch 26: Train Loss = 0.03181679876875286, Recall = 0.9818181818181818, Aging Rate = 0.09090909090909091, Precision = 0.9818181818181818, f1 = 0.9818181818181818\n",
      "Epoch 27: Train Loss = 0.029709296516519934, Recall = 0.9818181818181818, Aging Rate = 0.09173553719008265, Precision = 0.972972972972973, f1 = 0.9773755656108598\n",
      "Epoch 28: Train Loss = 0.02808255430403327, Recall = 0.9818181818181818, Aging Rate = 0.09173553719008265, Precision = 0.972972972972973, f1 = 0.9773755656108598\n",
      "Epoch 29: Train Loss = 0.026252682654818227, Recall = 0.9818181818181818, Aging Rate = 0.09173553719008265, Precision = 0.972972972972973, f1 = 0.9773755656108598\n",
      "Epoch 30: Train Loss = 0.02545585225313163, Recall = 0.9818181818181818, Aging Rate = 0.09173553719008265, Precision = 0.972972972972973, f1 = 0.9773755656108598\n",
      "Test Loss = 0.02330248059381631, Recall = 0.9818181818181818, Aging Rate = 0.09090909090909091, precision = 0.9818181818181818\n",
      "\n",
      "Epoch 31: Train Loss = 0.024599132816161006, Recall = 0.9818181818181818, Aging Rate = 0.09090909090909091, Precision = 0.9818181818181818, f1 = 0.9818181818181818\n",
      "Epoch 32: Train Loss = 0.024389191769248197, Recall = 0.9818181818181818, Aging Rate = 0.09090909090909091, Precision = 0.9818181818181818, f1 = 0.9818181818181818\n",
      "Epoch 33: Train Loss = 0.02159426844686516, Recall = 0.990909090909091, Aging Rate = 0.09173553719008265, Precision = 0.9819819819819819, f1 = 0.9864253393665158\n",
      "Epoch 34: Train Loss = 0.021106929021063914, Recall = 0.9818181818181818, Aging Rate = 0.09090909090909091, Precision = 0.9818181818181818, f1 = 0.9818181818181818\n",
      "Epoch 35: Train Loss = 0.02025399972369109, Recall = 0.990909090909091, Aging Rate = 0.09173553719008265, Precision = 0.9819819819819819, f1 = 0.9864253393665158\n",
      "Test Loss = 0.018588805586592226, Recall = 1.0, Aging Rate = 0.09256198347107437, precision = 0.9821428571428571\n",
      "Model in epoch 35 is saved.\n",
      "\n",
      "Epoch 36: Train Loss = 0.019442955416835044, Recall = 1.0, Aging Rate = 0.09256198347107437, Precision = 0.9821428571428571, f1 = 0.9909909909909909\n",
      "Epoch 37: Train Loss = 0.018320635345972273, Recall = 1.0, Aging Rate = 0.09256198347107437, Precision = 0.9821428571428571, f1 = 0.9909909909909909\n",
      "Epoch 38: Train Loss = 0.018034809969427173, Recall = 0.990909090909091, Aging Rate = 0.09173553719008265, Precision = 0.9819819819819819, f1 = 0.9864253393665158\n",
      "Epoch 39: Train Loss = 0.017070467924037255, Recall = 1.0, Aging Rate = 0.09256198347107437, Precision = 0.9821428571428571, f1 = 0.9909909909909909\n",
      "Epoch 40: Train Loss = 0.016864161956901394, Recall = 1.0, Aging Rate = 0.09256198347107437, Precision = 0.9821428571428571, f1 = 0.9909909909909909\n",
      "Test Loss = 0.015858176242837235, Recall = 1.0, Aging Rate = 0.09256198347107437, precision = 0.9821428571428571\n",
      "\n",
      "Epoch 41: Train Loss = 0.015992807929427172, Recall = 1.0, Aging Rate = 0.09256198347107437, Precision = 0.9821428571428571, f1 = 0.9909909909909909\n",
      "Epoch 42: Train Loss = 0.015920366132862806, Recall = 1.0, Aging Rate = 0.09173553719008265, Precision = 0.990990990990991, f1 = 0.9954751131221719\n",
      "Epoch 43: Train Loss = 0.015444108126454116, Recall = 1.0, Aging Rate = 0.09256198347107437, Precision = 0.9821428571428571, f1 = 0.9909909909909909\n",
      "Epoch 44: Train Loss = 0.01483658812786183, Recall = 1.0, Aging Rate = 0.09173553719008265, Precision = 0.990990990990991, f1 = 0.9954751131221719\n",
      "Epoch 45: Train Loss = 0.014993650884914004, Recall = 1.0, Aging Rate = 0.09256198347107437, Precision = 0.9821428571428571, f1 = 0.9909909909909909\n",
      "Test Loss = 0.013381129749550308, Recall = 1.0, Aging Rate = 0.09173553719008265, precision = 0.990990990990991\n",
      "Model in epoch 45 is saved.\n",
      "\n",
      "Epoch 46: Train Loss = 0.014510025037837422, Recall = 1.0, Aging Rate = 0.09173553719008265, Precision = 0.990990990990991, f1 = 0.9954751131221719\n",
      "Epoch 47: Train Loss = 0.013562657874200709, Recall = 1.0, Aging Rate = 0.09173553719008265, Precision = 0.990990990990991, f1 = 0.9954751131221719\n",
      "Epoch 48: Train Loss = 0.01383842653479458, Recall = 1.0, Aging Rate = 0.09256198347107437, Precision = 0.9821428571428571, f1 = 0.9909909909909909\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49: Train Loss = 0.014203802423844161, Recall = 1.0, Aging Rate = 0.09256198347107437, Precision = 0.9821428571428571, f1 = 0.9909909909909909\n",
      "Epoch 50: Train Loss = 0.012968693362656703, Recall = 1.0, Aging Rate = 0.09173553719008265, Precision = 0.990990990990991, f1 = 0.9954751131221719\n",
      "Test Loss = 0.012089895632518225, Recall = 1.0, Aging Rate = 0.09173553719008265, precision = 0.990990990990991\n",
      "\n",
      "Epoch 51: Train Loss = 0.012388013232468574, Recall = 1.0, Aging Rate = 0.09173553719008265, Precision = 0.990990990990991, f1 = 0.9954751131221719\n",
      "Epoch 52: Train Loss = 0.012650239381415785, Recall = 1.0, Aging Rate = 0.09256198347107437, Precision = 0.9821428571428571, f1 = 0.9909909909909909\n",
      "Epoch 53: Train Loss = 0.012172590876536922, Recall = 1.0, Aging Rate = 0.09173553719008265, Precision = 0.990990990990991, f1 = 0.9954751131221719\n",
      "Epoch 54: Train Loss = 0.012276028093597121, Recall = 1.0, Aging Rate = 0.09090909090909091, Precision = 0, f1 = 0.0\n",
      "Epoch 55: Train Loss = 0.012232566994330115, Recall = 1.0, Aging Rate = 0.09173553719008265, Precision = 0.990990990990991, f1 = 0.9954751131221719\n",
      "Test Loss = 0.011070077485320243, Recall = 1.0, Aging Rate = 0.09173553719008265, precision = 0.990990990990991\n",
      "\n",
      "Epoch 56: Train Loss = 0.011246157142772408, Recall = 1.0, Aging Rate = 0.09173553719008265, Precision = 0.990990990990991, f1 = 0.9954751131221719\n",
      "Epoch 57: Train Loss = 0.011334427939496995, Recall = 1.0, Aging Rate = 0.09173553719008265, Precision = 0.990990990990991, f1 = 0.9954751131221719\n",
      "Epoch 58: Train Loss = 0.011859354210540282, Recall = 1.0, Aging Rate = 0.09090909090909091, Precision = 0, f1 = 0.0\n",
      "Epoch 59: Train Loss = 0.011272670291672069, Recall = 1.0, Aging Rate = 0.09090909090909091, Precision = 0, f1 = 0.0\n",
      "Epoch 60: Train Loss = 0.010552679915135064, Recall = 1.0, Aging Rate = 0.09173553719008265, Precision = 0.990990990990991, f1 = 0.9954751131221719\n",
      "Test Loss = 0.010042163940562197, Recall = 1.0, Aging Rate = 0.09173553719008265, precision = 0.990990990990991\n",
      "\n",
      "Epoch 61: Train Loss = 0.010685985189023589, Recall = 1.0, Aging Rate = 0.09173553719008265, Precision = 0.990990990990991, f1 = 0.9954751131221719\n",
      "Epoch 62: Train Loss = 0.010914121712904332, Recall = 1.0, Aging Rate = 0.09090909090909091, Precision = 0, f1 = 0.0\n",
      "Epoch 63: Train Loss = 0.01062369665577392, Recall = 1.0, Aging Rate = 0.09173553719008265, Precision = 0.990990990990991, f1 = 0.9954751131221719\n",
      "Epoch 64: Train Loss = 0.010562474979472554, Recall = 1.0, Aging Rate = 0.09173553719008265, Precision = 0.990990990990991, f1 = 0.9954751131221719\n",
      "Epoch 65: Train Loss = 0.01004796237184489, Recall = 1.0, Aging Rate = 0.09090909090909091, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.009358713580757256, Recall = 1.0, Aging Rate = 0.09090909090909091, precision = 1.0\n",
      "Model in epoch 65 is saved.\n",
      "\n",
      "Epoch 66: Train Loss = 0.010029231365924039, Recall = 1.0, Aging Rate = 0.09173553719008265, Precision = 0.990990990990991, f1 = 0.9954751131221719\n",
      "Epoch 67: Train Loss = 0.010434932697348851, Recall = 1.0, Aging Rate = 0.09173553719008265, Precision = 0.990990990990991, f1 = 0.9954751131221719\n",
      "Epoch 68: Train Loss = 0.010022588048037911, Recall = 1.0, Aging Rate = 0.09090909090909091, Precision = 0, f1 = 0.0\n",
      "Epoch 69: Train Loss = 0.010301409855731263, Recall = 1.0, Aging Rate = 0.09173553719008265, Precision = 0.990990990990991, f1 = 0.9954751131221719\n",
      "Epoch 70: Train Loss = 0.010063936564424806, Recall = 1.0, Aging Rate = 0.09173553719008265, Precision = 0.990990990990991, f1 = 0.9954751131221719\n",
      "Test Loss = 0.009146177200677473, Recall = 1.0, Aging Rate = 0.09090909090909091, precision = 1.0\n",
      "\n",
      "Epoch 71: Train Loss = 0.009958834391210444, Recall = 1.0, Aging Rate = 0.09173553719008265, Precision = 0.990990990990991, f1 = 0.9954751131221719\n",
      "Epoch 72: Train Loss = 0.00997172967600059, Recall = 1.0, Aging Rate = 0.09090909090909091, Precision = 0, f1 = 0.0\n",
      "Epoch 73: Train Loss = 0.010122448169002849, Recall = 1.0, Aging Rate = 0.09090909090909091, Precision = 0, f1 = 0.0\n",
      "Epoch 74: Train Loss = 0.0094149099112573, Recall = 1.0, Aging Rate = 0.09173553719008265, Precision = 0.990990990990991, f1 = 0.9954751131221719\n",
      "Epoch 75: Train Loss = 0.009443273514601563, Recall = 1.0, Aging Rate = 0.09090909090909091, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.008728680220886695, Recall = 1.0, Aging Rate = 0.09090909090909091, precision = 1.0\n",
      "\n",
      "Epoch 76: Train Loss = 0.009131846764732984, Recall = 1.0, Aging Rate = 0.09173553719008265, Precision = 0.990990990990991, f1 = 0.9954751131221719\n",
      "Epoch 77: Train Loss = 0.009399015916711535, Recall = 1.0, Aging Rate = 0.09173553719008265, Precision = 0.990990990990991, f1 = 0.9954751131221719\n",
      "Epoch 78: Train Loss = 0.01001634304373225, Recall = 1.0, Aging Rate = 0.09090909090909091, Precision = 0, f1 = 0.0\n",
      "Epoch 79: Train Loss = 0.00932299543233696, Recall = 1.0, Aging Rate = 0.09090909090909091, Precision = 0, f1 = 0.0\n",
      "Epoch 80: Train Loss = 0.00887818958240846, Recall = 1.0, Aging Rate = 0.09090909090909091, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.008439487910036706, Recall = 1.0, Aging Rate = 0.09090909090909091, precision = 1.0\n",
      "\n",
      "Epoch 81: Train Loss = 0.009228581862046946, Recall = 1.0, Aging Rate = 0.09090909090909091, Precision = 0, f1 = 0.0\n",
      "Epoch 82: Train Loss = 0.009523093737353962, Recall = 1.0, Aging Rate = 0.09173553719008265, Precision = 0.990990990990991, f1 = 0.9954751131221719\n",
      "Epoch 83: Train Loss = 0.009827140917278026, Recall = 1.0, Aging Rate = 0.09090909090909091, Precision = 0, f1 = 0.0\n",
      "Epoch 84: Train Loss = 0.00895518680249364, Recall = 1.0, Aging Rate = 0.09090909090909091, Precision = 0, f1 = 0.0\n",
      "Epoch 85: Train Loss = 0.009027448717566314, Recall = 1.0, Aging Rate = 0.09090909090909091, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.007931830099791535, Recall = 1.0, Aging Rate = 0.09090909090909091, precision = 1.0\n",
      "\n",
      "Epoch 86: Train Loss = 0.009377113277138758, Recall = 1.0, Aging Rate = 0.09173553719008265, Precision = 0.990990990990991, f1 = 0.9954751131221719\n",
      "Epoch 87: Train Loss = 0.008562884904628943, Recall = 1.0, Aging Rate = 0.09090909090909091, Precision = 0, f1 = 0.0\n",
      "Epoch 88: Train Loss = 0.00914581332909913, Recall = 1.0, Aging Rate = 0.09090909090909091, Precision = 0, f1 = 0.0\n",
      "Epoch 89: Train Loss = 0.008624835580987625, Recall = 1.0, Aging Rate = 0.09090909090909091, Precision = 0, f1 = 0.0\n",
      "Epoch 90: Train Loss = 0.008424468790296435, Recall = 1.0, Aging Rate = 0.09090909090909091, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.008006072555445443, Recall = 1.0, Aging Rate = 0.09090909090909091, precision = 1.0\n",
      "\n",
      "Epoch 91: Train Loss = 0.008541392967535937, Recall = 1.0, Aging Rate = 0.09090909090909091, Precision = 0, f1 = 0.0\n",
      "Epoch 92: Train Loss = 0.009094798561062448, Recall = 1.0, Aging Rate = 0.09090909090909091, Precision = 0, f1 = 0.0\n",
      "Epoch 93: Train Loss = 0.008657124073606385, Recall = 1.0, Aging Rate = 0.09090909090909091, Precision = 0, f1 = 0.0\n",
      "Epoch 94: Train Loss = 0.008782826535680816, Recall = 1.0, Aging Rate = 0.09090909090909091, Precision = 0, f1 = 0.0\n",
      "Epoch 95: Train Loss = 0.00882673234609533, Recall = 1.0, Aging Rate = 0.09090909090909091, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.0076602433785057265, Recall = 1.0, Aging Rate = 0.09090909090909091, precision = 1.0\n",
      "\n",
      "Epoch 96: Train Loss = 0.009110328628997173, Recall = 1.0, Aging Rate = 0.09090909090909091, Precision = 0, f1 = 0.0\n",
      "Epoch 97: Train Loss = 0.009195689730777229, Recall = 1.0, Aging Rate = 0.09173553719008265, Precision = 0.990990990990991, f1 = 0.9954751131221719\n",
      "Epoch 98: Train Loss = 0.009205554733591631, Recall = 1.0, Aging Rate = 0.09090909090909091, Precision = 0, f1 = 0.0\n",
      "Epoch 99: Train Loss = 0.008388307021761483, Recall = 1.0, Aging Rate = 0.09090909090909091, Precision = 0, f1 = 0.0\n",
      "Epoch 100: Train Loss = 0.008370339843513798, Recall = 1.0, Aging Rate = 0.09090909090909091, Precision = 0, f1 = 0.0\n",
      "Test Loss = 0.007451371016550409, Recall = 1.0, Aging Rate = 0.09090909090909091, precision = 1.0\n",
      "\n",
      "\n",
      "Labels of  10 datasets are divided.\n",
      "\n",
      "Labels of  10 datasets are divided.\n"
     ]
    }
   ],
   "source": [
    "train_firstC = transform_train(run_train,  \n",
    "                               mode = 'C', \n",
    "                               base_param = base_param_monthC, \n",
    "                               cv = 5)\n",
    "test_firstC = transform_test(data_dict,\n",
    "                             run_test, \n",
    "                             mode = 'C', \n",
    "                             base_param = base_param_monthC)\n",
    "train_firstC_x, train_firstC_y = train_set(train_firstC)\n",
    "test_firstC_x, test_firstC_y = train_set(test_firstC) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Meta Learner"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Search for The Best Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-05T10:30:27.002440Z",
     "start_time": "2021-12-05T10:23:50.434660Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf7264939c5646a08c13bc4847439bd9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "``multivariate`` option is an experimental feature. The interface can change in the future.\n",
      "\u001b[32m[I 2021-12-05 18:23:50,452]\u001b[0m A new study created in memory with name: no-name-86bfe390-53da-4e73-9119-5b4348a4269f\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset0 :\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress bar is experimental (supported from v1.2.0). The interface can change in the future.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "539a8c86cefc4d69bcdb86a6b6adc8ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.847457627118644 \n",
      "Recall: 0.704225352112676 \n",
      "Aging Rate: 0.00150173080838933\n",
      "Precision: 0.9032258064516129 \n",
      "Recall: 0.7887323943661971 \n",
      "Aging Rate: 0.0015780900020362452\n",
      "Precision: 0.8888888888888888 \n",
      "Recall: 0.676056338028169 \n",
      "Aging Rate: 0.0013744654856444715\n",
      "\u001b[32m[I 2021-12-05 18:23:54,765]\u001b[0m Trial 0 finished with value: 2.482719576475111 and parameters: {'meta_learner': 'ExtraTrees', 'n_estimators': 300, 'min_samples_split': 27, 'max_depth': 9}. Best is trial 0 with value: 2.482719576475111.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.9444444444444444 \n",
      "Recall: 0.7183098591549296 \n",
      "Aging Rate: 0.0013744654856444715\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.9074074074074074 \n",
      "Recall: 0.6901408450704225 \n",
      "Aging Rate: 0.0013744654856444715\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.90625 \n",
      "Recall: 0.8169014084507042 \n",
      "Aging Rate: 0.0016289961311341885\n",
      "\u001b[32m[I 2021-12-05 18:23:59,745]\u001b[0m Trial 1 finished with value: 2.58051860545992 and parameters: {'meta_learner': 'LogisticRegression', 'C': 100, 'penalty': 'none'}. Best is trial 1 with value: 2.58051860545992.\u001b[0m\n",
      "Precision: 0.8833333333333333 \n",
      "Recall: 0.7464788732394366 \n",
      "Aging Rate: 0.0015271838729383018\n",
      "Precision: 0.8947368421052632 \n",
      "Recall: 0.7183098591549296 \n",
      "Aging Rate: 0.0014508246792913867\n",
      "Precision: 0.8888888888888888 \n",
      "Recall: 0.7887323943661971 \n",
      "Aging Rate: 0.001603543066585217\n",
      "\u001b[32m[I 2021-12-05 18:24:02,198]\u001b[0m Trial 2 finished with value: 2.5291464184718446 and parameters: {'meta_learner': 'ExtraTrees', 'n_estimators': 100, 'min_samples_split': 27, 'max_depth': 21}. Best is trial 1 with value: 2.58051860545992.\u001b[0m\n",
      "Precision: 0.9821428571428571 \n",
      "Recall: 0.7746478873239436 \n",
      "Aging Rate: 0.0014253716147424149\n",
      "Precision: 0.9 \n",
      "Recall: 0.7605633802816901 \n",
      "Aging Rate: 0.0015271838729383018\n",
      "Precision: 0.9285714285714286 \n",
      "Recall: 0.7323943661971831 \n",
      "Aging Rate: 0.0014253716147424149\n",
      "\u001b[32m[I 2021-12-05 18:24:05,972]\u001b[0m Trial 3 finished with value: 2.629678068410463 and parameters: {'meta_learner': 'ExtraTrees', 'n_estimators': 300, 'min_samples_split': 2, 'max_depth': 9}. Best is trial 3 with value: 2.629678068410463.\u001b[0m\n",
      "Precision: 0.9298245614035088 \n",
      "Recall: 0.7464788732394366 \n",
      "Aging Rate: 0.0014508246792913867\n",
      "Precision: 0.9019607843137255 \n",
      "Recall: 0.647887323943662 \n",
      "Aging Rate: 0.0012981062919975566\n",
      "Precision: 0.8679245283018868 \n",
      "Recall: 0.647887323943662 \n",
      "Aging Rate: 0.0013490124210955\n",
      "\u001b[32m[I 2021-12-05 18:24:10,615]\u001b[0m Trial 4 finished with value: 2.4805577563883343 and parameters: {'meta_learner': 'ExtraTrees', 'n_estimators': 500, 'min_samples_split': 2, 'max_depth': 3}. Best is trial 3 with value: 2.629678068410463.\u001b[0m\n",
      "Precision: 0.9807692307692307 \n",
      "Recall: 0.7183098591549296 \n",
      "Aging Rate: 0.0013235593565465282\n",
      "Precision: 0.9285714285714286 \n",
      "Recall: 0.7323943661971831 \n",
      "Aging Rate: 0.0014253716147424149\n",
      "Precision: 0.9782608695652174 \n",
      "Recall: 0.6338028169014085 \n",
      "Aging Rate: 0.001170840969252698\n",
      "\u001b[32m[I 2021-12-05 18:24:12,583]\u001b[0m Trial 5 finished with value: 2.619903366688425 and parameters: {'meta_learner': 'ExtraTrees', 'n_estimators': 100, 'min_samples_split': 12, 'max_depth': 9}. Best is trial 3 with value: 2.629678068410463.\u001b[0m\n",
      "Precision: 0.8983050847457628 \n",
      "Recall: 0.7464788732394366 \n",
      "Aging Rate: 0.00150173080838933\n",
      "Precision: 0.9180327868852459 \n",
      "Recall: 0.7887323943661971 \n",
      "Aging Rate: 0.0015526369374872734\n",
      "Precision: 0.9821428571428571 \n",
      "Recall: 0.7746478873239436 \n",
      "Aging Rate: 0.0014253716147424149\n",
      "\u001b[32m[I 2021-12-05 18:24:16,347]\u001b[0m Trial 6 finished with value: 2.63560687082577 and parameters: {'meta_learner': 'ExtraTrees', 'n_estimators': 300, 'min_samples_split': 12, 'max_depth': 9}. Best is trial 6 with value: 2.63560687082577.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.9056603773584906 \n",
      "Recall: 0.676056338028169 \n",
      "Aging Rate: 0.0013490124210955\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.8679245283018868 \n",
      "Recall: 0.647887323943662 \n",
      "Aging Rate: 0.0013490124210955\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.9152542372881356 \n",
      "Recall: 0.7605633802816901 \n",
      "Aging Rate: 0.00150173080838933\n",
      "\u001b[32m[I 2021-12-05 18:24:20,000]\u001b[0m Trial 7 finished with value: 2.4873951093835154 and parameters: {'meta_learner': 'LogisticRegression', 'C': 100, 'penalty': 'none'}. Best is trial 6 with value: 2.63560687082577.\u001b[0m\n",
      "Precision: 0.9122807017543859 \n",
      "Recall: 0.7323943661971831 \n",
      "Aging Rate: 0.0014508246792913867\n",
      "Precision: 0.9259259259259259 \n",
      "Recall: 0.704225352112676 \n",
      "Aging Rate: 0.0013744654856444715\n",
      "Precision: 0.9344262295081968 \n",
      "Recall: 0.8028169014084507 \n",
      "Aging Rate: 0.0015526369374872734\n",
      "\u001b[32m[I 2021-12-05 18:24:23,801]\u001b[0m Trial 8 finished with value: 2.594900778031776 and parameters: {'meta_learner': 'LogisticRegression', 'C': 1, 'penalty': 'none'}. Best is trial 6 with value: 2.63560687082577.\u001b[0m\n",
      "Precision: 0.9152542372881356 \n",
      "Recall: 0.7605633802816901 \n",
      "Aging Rate: 0.00150173080838933\n",
      "Precision: 0.9642857142857143 \n",
      "Recall: 0.7605633802816901 \n",
      "Aging Rate: 0.0014253716147424149\n",
      "Precision: 0.9166666666666666 \n",
      "Recall: 0.7746478873239436 \n",
      "Aging Rate: 0.0015271838729383018\n",
      "\u001b[32m[I 2021-12-05 18:24:25,800]\u001b[0m Trial 9 finished with value: 2.6293959614561193 and parameters: {'meta_learner': 'ExtraTrees', 'n_estimators': 100, 'min_samples_split': 17, 'max_depth': 9}. Best is trial 6 with value: 2.63560687082577.\u001b[0m\n",
      "Precision: 0.9803921568627451 \n",
      "Recall: 0.704225352112676 \n",
      "Aging Rate: 0.0012981062919975566\n",
      "Precision: 0.9 \n",
      "Recall: 0.6338028169014085 \n",
      "Aging Rate: 0.0012726532274485848\n",
      "Precision: 0.8870967741935484 \n",
      "Recall: 0.7746478873239436 \n",
      "Aging Rate: 0.0015780900020362452\n",
      "\u001b[32m[I 2021-12-05 18:24:30,507]\u001b[0m Trial 10 finished with value: 2.5492179728168716 and parameters: {'meta_learner': 'LogisticRegression', 'C': 10, 'penalty': 'l2'}. Best is trial 6 with value: 2.63560687082577.\u001b[0m\n",
      "Precision: 0.9130434782608695 \n",
      "Recall: 0.5915492957746479 \n",
      "Aging Rate: 0.001170840969252698\n",
      "Precision: 0.9464285714285714 \n",
      "Recall: 0.7464788732394366 \n",
      "Aging Rate: 0.0014253716147424149\n",
      "Precision: 0.9074074074074074 \n",
      "Recall: 0.6901408450704225 \n",
      "Aging Rate: 0.0013744654856444715\n",
      "\u001b[32m[I 2021-12-05 18:24:35,270]\u001b[0m Trial 11 finished with value: 2.5206426427594013 and parameters: {'meta_learner': 'ExtraTrees', 'n_estimators': 300, 'min_samples_split': 2, 'max_depth': 15}. Best is trial 6 with value: 2.63560687082577.\u001b[0m\n",
      "Precision: 0.86 \n",
      "Recall: 0.6056338028169014 \n",
      "Aging Rate: 0.0012726532274485848\n",
      "Precision: 0.8723404255319149 \n",
      "Recall: 0.5774647887323944 \n",
      "Aging Rate: 0.0011962940338016697\n",
      "Precision: 0.9038461538461539 \n",
      "Recall: 0.6619718309859155 \n",
      "Aging Rate: 0.0013235593565465282\n",
      "\u001b[32m[I 2021-12-05 18:24:39,806]\u001b[0m Trial 12 finished with value: 2.372481193763783 and parameters: {'meta_learner': 'ExtraTrees', 'n_estimators': 500, 'min_samples_split': 12, 'max_depth': 3}. Best is trial 6 with value: 2.63560687082577.\u001b[0m\n",
      "Precision: 0.9285714285714286 \n",
      "Recall: 0.7323943661971831 \n",
      "Aging Rate: 0.0014253716147424149\n",
      "Precision: 0.8928571428571429 \n",
      "Recall: 0.704225352112676 \n",
      "Aging Rate: 0.0014253716147424149\n",
      "Precision: 0.9 \n",
      "Recall: 0.6338028169014085 \n",
      "Aging Rate: 0.0012726532274485848\n",
      "\u001b[32m[I 2021-12-05 18:24:43,921]\u001b[0m Trial 13 finished with value: 2.504426559356137 and parameters: {'meta_learner': 'ExtraTrees', 'n_estimators': 300, 'min_samples_split': 7, 'max_depth': 12}. Best is trial 6 with value: 2.63560687082577.\u001b[0m\n",
      "Precision: 0.9310344827586207 \n",
      "Recall: 0.7605633802816901 \n",
      "Aging Rate: 0.0014762777438403585\n",
      "Precision: 0.9508196721311475 \n",
      "Recall: 0.8169014084507042 \n",
      "Aging Rate: 0.0015526369374872734\n",
      "Precision: 0.9285714285714286 \n",
      "Recall: 0.7323943661971831 \n",
      "Aging Rate: 0.0014253716147424149\n",
      "\u001b[32m[I 2021-12-05 18:24:47,370]\u001b[0m Trial 14 finished with value: 2.64357010728399 and parameters: {'meta_learner': 'ExtraTrees', 'n_estimators': 300, 'min_samples_split': 17, 'max_depth': 6}. Best is trial 14 with value: 2.64357010728399.\u001b[0m\n",
      "Precision: 0.9019607843137255 \n",
      "Recall: 0.647887323943662 \n",
      "Aging Rate: 0.0012981062919975566\n",
      "Precision: 0.8846153846153846 \n",
      "Recall: 0.647887323943662 \n",
      "Aging Rate: 0.0013235593565465282\n",
      "Precision: 0.8771929824561403 \n",
      "Recall: 0.704225352112676 \n",
      "Aging Rate: 0.0014508246792913867\n",
      "\u001b[32m[I 2021-12-05 18:24:51,904]\u001b[0m Trial 15 finished with value: 2.4425127675901668 and parameters: {'meta_learner': 'ExtraTrees', 'n_estimators': 500, 'min_samples_split': 17, 'max_depth': 3}. Best is trial 14 with value: 2.64357010728399.\u001b[0m\n",
      "Precision: 0.9090909090909091 \n",
      "Recall: 0.704225352112676 \n",
      "Aging Rate: 0.0013999185501934433\n",
      "Precision: 0.8813559322033898 \n",
      "Recall: 0.7323943661971831 \n",
      "Aging Rate: 0.00150173080838933\n",
      "Precision: 0.9122807017543859 \n",
      "Recall: 0.7323943661971831 \n",
      "Aging Rate: 0.0014508246792913867\n",
      "\u001b[32m[I 2021-12-05 18:24:55,383]\u001b[0m Trial 16 finished with value: 2.524823056868137 and parameters: {'meta_learner': 'ExtraTrees', 'n_estimators': 300, 'min_samples_split': 22, 'max_depth': 6}. Best is trial 14 with value: 2.64357010728399.\u001b[0m\n",
      "Precision: 0.859375 \n",
      "Recall: 0.7746478873239436 \n",
      "Aging Rate: 0.0016289961311341885\n",
      "Precision: 0.9259259259259259 \n",
      "Recall: 0.704225352112676 \n",
      "Aging Rate: 0.0013744654856444715\n",
      "Precision: 0.9122807017543859 \n",
      "Recall: 0.7323943661971831 \n",
      "Aging Rate: 0.0014508246792913867\n",
      "\u001b[32m[I 2021-12-05 18:25:00,251]\u001b[0m Trial 17 finished with value: 2.5354769536648085 and parameters: {'meta_learner': 'ExtraTrees', 'n_estimators': 300, 'min_samples_split': 12, 'max_depth': 18}. Best is trial 14 with value: 2.64357010728399.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0 \n",
      "Recall: 0.0 \n",
      "Aging Rate: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0 \n",
      "Recall: 0.0 \n",
      "Aging Rate: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0 \n",
      "Recall: 0.0 \n",
      "Aging Rate: 0.0\n",
      "\u001b[32m[I 2021-12-05 18:25:03,424]\u001b[0m Trial 18 finished with value: 0.0 and parameters: {'meta_learner': 'LogisticRegression', 'C': 0.01, 'penalty': 'l2'}. Best is trial 14 with value: 2.64357010728399.\u001b[0m\n",
      "Precision: 0.8888888888888888 \n",
      "Recall: 0.676056338028169 \n",
      "Aging Rate: 0.0013744654856444715\n",
      "Precision: 0.9152542372881356 \n",
      "Recall: 0.7605633802816901 \n",
      "Aging Rate: 0.00150173080838933\n",
      "Precision: 0.9433962264150944 \n",
      "Recall: 0.704225352112676 \n",
      "Aging Rate: 0.0013490124210955\n",
      "\u001b[32m[I 2021-12-05 18:25:09,015]\u001b[0m Trial 19 finished with value: 2.5453079252022577 and parameters: {'meta_learner': 'ExtraTrees', 'n_estimators': 500, 'min_samples_split': 22, 'max_depth': 6}. Best is trial 14 with value: 2.64357010728399.\u001b[0m\n",
      "Precision: 0.9574468085106383 \n",
      "Recall: 0.6338028169014085 \n",
      "Aging Rate: 0.0011962940338016697\n",
      "Precision: 0.9824561403508771 \n",
      "Recall: 0.7887323943661971 \n",
      "Aging Rate: 0.0014508246792913867\n",
      "Precision: 0.96 \n",
      "Recall: 0.676056338028169 \n",
      "Aging Rate: 0.0012726532274485848\n",
      "\u001b[32m[I 2021-12-05 18:25:11,374]\u001b[0m Trial 20 finished with value: 2.6327991490062685 and parameters: {'meta_learner': 'ExtraTrees', 'n_estimators': 100, 'min_samples_split': 7, 'max_depth': 12}. Best is trial 14 with value: 2.64357010728399.\u001b[0m\n",
      "Precision: 0.9642857142857143 \n",
      "Recall: 0.7605633802816901 \n",
      "Aging Rate: 0.0014253716147424149\n",
      "Precision: 0.9333333333333333 \n",
      "Recall: 0.7887323943661971 \n",
      "Aging Rate: 0.0015271838729383018\n",
      "Precision: 0.9016393442622951 \n",
      "Recall: 0.7746478873239436 \n",
      "Aging Rate: 0.0015526369374872734\n",
      "\u001b[32m[I 2021-12-05 18:25:14,031]\u001b[0m Trial 21 finished with value: 2.640820148578172 and parameters: {'meta_learner': 'ExtraTrees', 'n_estimators': 100, 'min_samples_split': 7, 'max_depth': 12}. Best is trial 14 with value: 2.64357010728399.\u001b[0m\n",
      "Precision: 0.9464285714285714 \n",
      "Recall: 0.7464788732394366 \n",
      "Aging Rate: 0.0014253716147424149\n",
      "Precision: 0.9074074074074074 \n",
      "Recall: 0.6901408450704225 \n",
      "Aging Rate: 0.0013744654856444715\n",
      "Precision: 0.9642857142857143 \n",
      "Recall: 0.7605633802816901 \n",
      "Aging Rate: 0.0014253716147424149\n",
      "\u001b[32m[I 2021-12-05 18:25:18,724]\u001b[0m Trial 22 finished with value: 2.6111421616116455 and parameters: {'meta_learner': 'ExtraTrees', 'n_estimators': 300, 'min_samples_split': 7, 'max_depth': 15}. Best is trial 14 with value: 2.64357010728399.\u001b[0m\n",
      "Precision: 0.9038461538461539 \n",
      "Recall: 0.6619718309859155 \n",
      "Aging Rate: 0.0013235593565465282\n",
      "Precision: 0.9152542372881356 \n",
      "Recall: 0.7605633802816901 \n",
      "Aging Rate: 0.00150173080838933\n",
      "Precision: 0.9032258064516129 \n",
      "Recall: 0.7887323943661971 \n",
      "Aging Rate: 0.0015780900020362452\n",
      "\u001b[32m[I 2021-12-05 18:25:20,708]\u001b[0m Trial 23 finished with value: 2.551973333601869 and parameters: {'meta_learner': 'ExtraTrees', 'n_estimators': 100, 'min_samples_split': 12, 'max_depth': 6}. Best is trial 14 with value: 2.64357010728399.\u001b[0m\n",
      "Precision: 0.8545454545454545 \n",
      "Recall: 0.6619718309859155 \n",
      "Aging Rate: 0.0013999185501934433\n",
      "Precision: 0.9516129032258065 \n",
      "Recall: 0.8309859154929577 \n",
      "Aging Rate: 0.0015780900020362452\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "``multivariate`` option is an experimental feature. The interface can change in the future.\n",
      "\u001b[32m[I 2021-12-05 18:25:25,263]\u001b[0m A new study created in memory with name: no-name-7b3d88b1-96d2-40b1-a08c-a41604029661\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.9649122807017544 \n",
      "Recall: 0.7746478873239436 \n",
      "Aging Rate: 0.0014508246792913867\n",
      "\u001b[32m[I 2021-12-05 18:25:25,174]\u001b[0m Trial 24 finished with value: 2.603248970249616 and parameters: {'meta_learner': 'ExtraTrees', 'n_estimators': 300, 'min_samples_split': 17, 'max_depth': 15}. Best is trial 14 with value: 2.64357010728399.\u001b[0m\n",
      "Sampler is TPESampler\n",
      "Dataset1 :\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress bar is experimental (supported from v1.2.0). The interface can change in the future.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "48da734c0e504071b979416c19a731cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.9942112879884226 \n",
      "Recall: 0.9956521739130435 \n",
      "Aging Rate: 0.5007246376811594\n",
      "Precision: 0.9970631424375918 \n",
      "Recall: 0.9840579710144928 \n",
      "Aging Rate: 0.4934782608695652\n",
      "Precision: 0.9941775836972343 \n",
      "Recall: 0.9898550724637681 \n",
      "Aging Rate: 0.49782608695652175\n",
      "\u001b[32m[I 2021-12-05 18:25:26,382]\u001b[0m Trial 0 finished with value: 2.9801564152126008 and parameters: {'meta_learner': 'ExtraTrees', 'n_estimators': 100, 'min_samples_split': 12, 'max_depth': 15}. Best is trial 0 with value: 2.9801564152126008.\u001b[0m\n",
      "Precision: 0.997093023255814 \n",
      "Recall: 0.9942028985507246 \n",
      "Aging Rate: 0.4985507246376812\n",
      "Precision: 0.9941434846266471 \n",
      "Recall: 0.9840579710144928 \n",
      "Aging Rate: 0.49492753623188407\n",
      "Precision: 0.9956395348837209 \n",
      "Recall: 0.9927536231884058 \n",
      "Aging Rate: 0.4985507246376812\n",
      "\u001b[32m[I 2021-12-05 18:25:28,287]\u001b[0m Trial 1 finished with value: 2.981588859428662 and parameters: {'meta_learner': 'ExtraTrees', 'n_estimators': 300, 'min_samples_split': 2, 'max_depth': 9}. Best is trial 1 with value: 2.981588859428662.\u001b[0m\n",
      "Precision: 0.9970845481049563 \n",
      "Recall: 0.991304347826087 \n",
      "Aging Rate: 0.4971014492753623\n",
      "Precision: 0.9970972423802612 \n",
      "Recall: 0.9956521739130435 \n",
      "Aging Rate: 0.49927536231884057\n",
      "Precision: 0.9985401459854014 \n",
      "Recall: 0.991304347826087 \n",
      "Aging Rate: 0.4963768115942029\n",
      "\u001b[32m[I 2021-12-05 18:25:29,604]\u001b[0m Trial 2 finished with value: 2.987901580835485 and parameters: {'meta_learner': 'ExtraTrees', 'n_estimators': 100, 'min_samples_split': 12, 'max_depth': 9}. Best is trial 2 with value: 2.987901580835485.\u001b[0m\n",
      "Precision: 0.9912790697674418 \n",
      "Recall: 0.9884057971014493 \n",
      "Aging Rate: 0.4985507246376812\n",
      "Precision: 0.9927325581395349 \n",
      "Recall: 0.9898550724637681 \n",
      "Aging Rate: 0.4985507246376812\n",
      "Precision: 0.9941944847605225 \n",
      "Recall: 0.9927536231884058 \n",
      "Aging Rate: 0.49927536231884057\n",
      "\u001b[32m[I 2021-12-05 18:25:31,118]\u001b[0m Trial 3 finished with value: 2.9758089060295405 and parameters: {'meta_learner': 'LogisticRegression', 'C': 100, 'penalty': 'l2'}. Best is trial 2 with value: 2.987901580835485.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.9956331877729258 \n",
      "Recall: 0.991304347826087 \n",
      "Aging Rate: 0.49782608695652175\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.9927536231884058 \n",
      "Recall: 0.9927536231884058 \n",
      "Aging Rate: 0.5\n",
      "Precision: 0.9956521739130435 \n",
      "Recall: 0.9956521739130435 \n",
      "Aging Rate: 0.5\n",
      "\u001b[32m[I 2021-12-05 18:25:32,202]\u001b[0m Trial 4 finished with value: 2.9825960382254286 and parameters: {'meta_learner': 'LogisticRegression', 'C': 10, 'penalty': 'none'}. Best is trial 2 with value: 2.987901580835485.\u001b[0m\n",
      "Precision: 0.9956458635703919 \n",
      "Recall: 0.9942028985507246 \n",
      "Aging Rate: 0.49927536231884057\n",
      "Precision: 0.9941944847605225 \n",
      "Recall: 0.9927536231884058 \n",
      "Aging Rate: 0.49927536231884057\n",
      "Precision: 0.9941944847605225 \n",
      "Recall: 0.9927536231884058 \n",
      "Aging Rate: 0.49927536231884057\n",
      "\u001b[32m[I 2021-12-05 18:25:32,358]\u001b[0m Trial 5 finished with value: 2.9825932703701366 and parameters: {'meta_learner': 'LogisticRegression', 'C': 0.1, 'penalty': 'l2'}. Best is trial 2 with value: 2.987901580835485.\u001b[0m\n",
      "Precision: 0.9956331877729258 \n",
      "Recall: 0.991304347826087 \n",
      "Aging Rate: 0.49782608695652175\n",
      "Precision: 0.9927641099855282 \n",
      "Recall: 0.9942028985507246 \n",
      "Aging Rate: 0.5007246376811594\n",
      "Precision: 0.9941860465116279 \n",
      "Recall: 0.991304347826087 \n",
      "Aging Rate: 0.4985507246376812\n",
      "\u001b[32m[I 2021-12-05 18:25:34,552]\u001b[0m Trial 6 finished with value: 2.9806594275810205 and parameters: {'meta_learner': 'ExtraTrees', 'n_estimators': 500, 'min_samples_split': 32, 'max_depth': 6}. Best is trial 2 with value: 2.987901580835485.\u001b[0m\n",
      "Precision: 0.9985358711566618 \n",
      "Recall: 0.9884057971014493 \n",
      "Aging Rate: 0.49492753623188407\n",
      "Precision: 0.9941775836972343 \n",
      "Recall: 0.9898550724637681 \n",
      "Aging Rate: 0.49782608695652175\n",
      "Precision: 0.9956331877729258 \n",
      "Recall: 0.991304347826087 \n",
      "Aging Rate: 0.49782608695652175\n",
      "\u001b[32m[I 2021-12-05 18:25:36,299]\u001b[0m Trial 7 finished with value: 2.982086167548316 and parameters: {'meta_learner': 'ExtraTrees', 'n_estimators': 300, 'min_samples_split': 27, 'max_depth': 21}. Best is trial 2 with value: 2.987901580835485.\u001b[0m\n",
      "Precision: 0.998546511627907 \n",
      "Recall: 0.9956521739130435 \n",
      "Aging Rate: 0.4985507246376812\n",
      "Precision: 0.9941944847605225 \n",
      "Recall: 0.9927536231884058 \n",
      "Aging Rate: 0.49927536231884057\n",
      "Precision: 0.9985401459854014 \n",
      "Recall: 0.991304347826087 \n",
      "Aging Rate: 0.4963768115942029\n",
      "\u001b[32m[I 2021-12-05 18:25:38,398]\u001b[0m Trial 8 finished with value: 2.9874241432250663 and parameters: {'meta_learner': 'ExtraTrees', 'n_estimators': 300, 'min_samples_split': 2, 'max_depth': 9}. Best is trial 2 with value: 2.987901580835485.\u001b[0m\n",
      "Precision: 1.0 \n",
      "Recall: 0.9884057971014493 \n",
      "Aging Rate: 0.49420289855072463\n",
      "Precision: 0.9956331877729258 \n",
      "Recall: 0.991304347826087 \n",
      "Aging Rate: 0.49782608695652175\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.9956204379562044 \n",
      "Recall: 0.9884057971014493 \n",
      "Aging Rate: 0.4963768115942029\n",
      "\u001b[32m[I 2021-12-05 18:25:39,594]\u001b[0m Trial 9 finished with value: 2.9835410644957485 and parameters: {'meta_learner': 'ExtraTrees', 'n_estimators': 100, 'min_samples_split': 12, 'max_depth': 12}. Best is trial 2 with value: 2.987901580835485.\u001b[0m\n",
      "Precision: 0.9956268221574344 \n",
      "Recall: 0.9898550724637681 \n",
      "Aging Rate: 0.4971014492753623\n",
      "Precision: 0.9970674486803519 \n",
      "Recall: 0.9855072463768116 \n",
      "Aging Rate: 0.49420289855072463\n",
      "Precision: 0.9927325581395349 \n",
      "Recall: 0.9898550724637681 \n",
      "Aging Rate: 0.4985507246376812\n",
      "\u001b[32m[I 2021-12-05 18:25:39,754]\u001b[0m Trial 10 finished with value: 2.9786903497529966 and parameters: {'meta_learner': 'LogisticRegression', 'C': 0.01, 'penalty': 'none'}. Best is trial 2 with value: 2.987901580835485.\u001b[0m\n",
      "Precision: 0.9970845481049563 \n",
      "Recall: 0.991304347826087 \n",
      "Aging Rate: 0.4971014492753623\n",
      "Precision: 0.9956395348837209 \n",
      "Recall: 0.9927536231884058 \n",
      "Aging Rate: 0.4985507246376812\n",
      "Precision: 0.9956268221574344 \n",
      "Recall: 0.9898550724637681 \n",
      "Aging Rate: 0.4971014492753623\n",
      "\u001b[32m[I 2021-12-05 18:25:41,479]\u001b[0m Trial 11 finished with value: 2.983538284590161 and parameters: {'meta_learner': 'ExtraTrees', 'n_estimators': 300, 'min_samples_split': 2, 'max_depth': 3}. Best is trial 2 with value: 2.987901580835485.\u001b[0m\n",
      "Precision: 0.9970760233918129 \n",
      "Recall: 0.9884057971014493 \n",
      "Aging Rate: 0.4956521739130435\n",
      "Precision: 0.9970544918998527 \n",
      "Recall: 0.981159420289855 \n",
      "Aging Rate: 0.4920289855072464\n",
      "Precision: 0.9985294117647059 \n",
      "Recall: 0.9840579710144928 \n",
      "Aging Rate: 0.4927536231884058\n",
      "\u001b[32m[I 2021-12-05 18:25:43,678]\u001b[0m Trial 12 finished with value: 2.979647680839513 and parameters: {'meta_learner': 'ExtraTrees', 'n_estimators': 500, 'min_samples_split': 17, 'max_depth': 9}. Best is trial 2 with value: 2.987901580835485.\u001b[0m\n",
      "Precision: 0.9970760233918129 \n",
      "Recall: 0.9884057971014493 \n",
      "Aging Rate: 0.4956521739130435\n",
      "Precision: 1.0 \n",
      "Recall: 0.9898550724637681 \n",
      "Aging Rate: 0.49492753623188407\n",
      "Precision: 0.9985422740524781 \n",
      "Recall: 0.9927536231884058 \n",
      "Aging Rate: 0.4971014492753623\n",
      "\u001b[32m[I 2021-12-05 18:25:44,908]\u001b[0m Trial 13 finished with value: 2.9874170292140683 and parameters: {'meta_learner': 'ExtraTrees', 'n_estimators': 100, 'min_samples_split': 7, 'max_depth': 15}. Best is trial 2 with value: 2.987901580835485.\u001b[0m\n",
      "Precision: 0.9884559884559885 \n",
      "Recall: 0.9927536231884058 \n",
      "Aging Rate: 0.5021739130434782\n",
      "Precision: 0.9956331877729258 \n",
      "Recall: 0.991304347826087 \n",
      "Aging Rate: 0.49782608695652175\n",
      "Precision: 0.997093023255814 \n",
      "Recall: 0.9942028985507246 \n",
      "Aging Rate: 0.4985507246376812\n",
      "\u001b[32m[I 2021-12-05 18:25:46,917]\u001b[0m Trial 14 finished with value: 2.9802084228448913 and parameters: {'meta_learner': 'ExtraTrees', 'n_estimators': 300, 'min_samples_split': 22, 'max_depth': 3}. Best is trial 2 with value: 2.987901580835485.\u001b[0m\n",
      "Precision: 0.9941944847605225 \n",
      "Recall: 0.9927536231884058 \n",
      "Aging Rate: 0.49927536231884057\n",
      "Precision: 0.9956268221574344 \n",
      "Recall: 0.9898550724637681 \n",
      "Aging Rate: 0.4971014492753623\n",
      "Precision: 0.9942279942279942 \n",
      "Recall: 0.9985507246376811 \n",
      "Aging Rate: 0.5021739130434782\n",
      "\u001b[32m[I 2021-12-05 18:25:48,107]\u001b[0m Trial 15 finished with value: 2.983086007527252 and parameters: {'meta_learner': 'ExtraTrees', 'n_estimators': 100, 'min_samples_split': 7, 'max_depth': 9}. Best is trial 2 with value: 2.987901580835485.\u001b[0m\n",
      "Precision: 0.9941434846266471 \n",
      "Recall: 0.9840579710144928 \n",
      "Aging Rate: 0.49492753623188407\n",
      "Precision: 0.9956331877729258 \n",
      "Recall: 0.991304347826087 \n",
      "Aging Rate: 0.49782608695652175\n",
      "Precision: 0.9956331877729258 \n",
      "Recall: 0.991304347826087 \n",
      "Aging Rate: 0.49782608695652175\n",
      "\u001b[32m[I 2021-12-05 18:25:50,304]\u001b[0m Trial 16 finished with value: 2.9791621290038877 and parameters: {'meta_learner': 'ExtraTrees', 'n_estimators': 500, 'min_samples_split': 7, 'max_depth': 12}. Best is trial 2 with value: 2.987901580835485.\u001b[0m\n",
      "Precision: 0.9956204379562044 \n",
      "Recall: 0.9884057971014493 \n",
      "Aging Rate: 0.4963768115942029\n",
      "Precision: 1.0 \n",
      "Recall: 0.9840579710144928 \n",
      "Aging Rate: 0.4920289855072464\n",
      "Precision: 0.9898550724637681 \n",
      "Recall: 0.9898550724637681 \n",
      "Aging Rate: 0.5\n",
      "\u001b[32m[I 2021-12-05 18:25:51,977]\u001b[0m Trial 17 finished with value: 2.9777566204732184 and parameters: {'meta_learner': 'ExtraTrees', 'n_estimators': 300, 'min_samples_split': 17, 'max_depth': 6}. Best is trial 2 with value: 2.987901580835485.\u001b[0m\n",
      "Precision: 0.9985401459854014 \n",
      "Recall: 0.991304347826087 \n",
      "Aging Rate: 0.4963768115942029\n",
      "Precision: 0.9956331877729258 \n",
      "Recall: 0.991304347826087 \n",
      "Aging Rate: 0.49782608695652175\n",
      "Precision: 0.9956268221574344 \n",
      "Recall: 0.9898550724637681 \n",
      "Aging Rate: 0.4971014492753623\n",
      "\u001b[32m[I 2021-12-05 18:25:52,189]\u001b[0m Trial 18 finished with value: 2.9840213599824885 and parameters: {'meta_learner': 'LogisticRegression', 'C': 1, 'penalty': 'l2'}. Best is trial 2 with value: 2.987901580835485.\u001b[0m\n",
      "Precision: 0.9956521739130435 \n",
      "Recall: 0.9956521739130435 \n",
      "Aging Rate: 0.5\n",
      "Precision: 0.9970845481049563 \n",
      "Recall: 0.991304347826087 \n",
      "Aging Rate: 0.4971014492753623\n",
      "Precision: 0.9927325581395349 \n",
      "Recall: 0.9898550724637681 \n",
      "Aging Rate: 0.4985507246376812\n",
      "\u001b[32m[I 2021-12-05 18:25:53,512]\u001b[0m Trial 19 finished with value: 2.9825833848393226 and parameters: {'meta_learner': 'ExtraTrees', 'n_estimators': 100, 'min_samples_split': 2, 'max_depth': 15}. Best is trial 2 with value: 2.987901580835485.\u001b[0m\n",
      "Precision: 0.9956395348837209 \n",
      "Recall: 0.9927536231884058 \n",
      "Aging Rate: 0.4985507246376812\n",
      "Precision: 0.9941944847605225 \n",
      "Recall: 0.9927536231884058 \n",
      "Aging Rate: 0.49927536231884057\n",
      "Precision: 0.997080291970803 \n",
      "Recall: 0.9898550724637681 \n",
      "Aging Rate: 0.4963768115942029\n",
      "\u001b[32m[I 2021-12-05 18:25:55,409]\u001b[0m Trial 20 finished with value: 2.983063647356891 and parameters: {'meta_learner': 'ExtraTrees', 'n_estimators': 300, 'min_samples_split': 12, 'max_depth': 6}. Best is trial 2 with value: 2.987901580835485.\u001b[0m\n",
      "Precision: 0.9971056439942113 \n",
      "Recall: 0.9985507246376811 \n",
      "Aging Rate: 0.5007246376811594\n",
      "Precision: 0.9970972423802612 \n",
      "Recall: 0.9956521739130435 \n",
      "Aging Rate: 0.49927536231884057\n",
      "Precision: 0.9970887918486172 \n",
      "Recall: 0.9927536231884058 \n",
      "Aging Rate: 0.49782608695652175\n",
      "\u001b[32m[I 2021-12-05 18:25:56,632]\u001b[0m Trial 21 finished with value: 2.9898466260617695 and parameters: {'meta_learner': 'ExtraTrees', 'n_estimators': 100, 'min_samples_split': 7, 'max_depth': 15}. Best is trial 21 with value: 2.9898466260617695.\u001b[0m\n",
      "Precision: 0.9941860465116279 \n",
      "Recall: 0.991304347826087 \n",
      "Aging Rate: 0.4985507246376812\n",
      "Precision: 0.998546511627907 \n",
      "Recall: 0.9956521739130435 \n",
      "Aging Rate: 0.4985507246376812\n",
      "Precision: 0.9985358711566618 \n",
      "Recall: 0.9884057971014493 \n",
      "Aging Rate: 0.49492753623188407\n",
      "\u001b[32m[I 2021-12-05 18:25:57,848]\u001b[0m Trial 22 finished with value: 2.9859663924776583 and parameters: {'meta_learner': 'ExtraTrees', 'n_estimators': 100, 'min_samples_split': 7, 'max_depth': 18}. Best is trial 21 with value: 2.9898466260617695.\u001b[0m\n",
      "Precision: 0.9970972423802612 \n",
      "Recall: 0.9956521739130435 \n",
      "Aging Rate: 0.49927536231884057\n",
      "Precision: 0.9956458635703919 \n",
      "Recall: 0.9942028985507246 \n",
      "Aging Rate: 0.49927536231884057\n",
      "Precision: 0.9956458635703919 \n",
      "Recall: 0.9942028985507246 \n",
      "Aging Rate: 0.49927536231884057\n",
      "\u001b[32m[I 2021-12-05 18:25:59,072]\u001b[0m Trial 23 finished with value: 2.986945303352194 and parameters: {'meta_learner': 'ExtraTrees', 'n_estimators': 100, 'min_samples_split': 12, 'max_depth': 12}. Best is trial 21 with value: 2.9898466260617695.\u001b[0m\n",
      "Precision: 0.9927745664739884 \n",
      "Recall: 0.9956521739130435 \n",
      "Aging Rate: 0.5014492753623189\n",
      "Precision: 0.9970845481049563 \n",
      "Recall: 0.991304347826087 \n",
      "Aging Rate: 0.4971014492753623\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "``multivariate`` option is an experimental feature. The interface can change in the future.\n",
      "\u001b[32m[I 2021-12-05 18:26:00,992]\u001b[0m A new study created in memory with name: no-name-7ea0e4ef-8a16-4ba3-b741-ef59dfd61d4a\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.9941520467836257 \n",
      "Recall: 0.9855072463768116 \n",
      "Aging Rate: 0.4956521739130435\n",
      "\u001b[32m[I 2021-12-05 18:26:00,846]\u001b[0m Trial 24 finished with value: 2.9801620302803613 and parameters: {'meta_learner': 'ExtraTrees', 'n_estimators': 300, 'min_samples_split': 2, 'max_depth': 9}. Best is trial 21 with value: 2.9898466260617695.\u001b[0m\n",
      "Sampler is TPESampler\n",
      "Dataset2 :\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress bar is experimental (supported from v1.2.0). The interface can change in the future.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "25739d79ea1d4832b9d5177ba7b0360e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.9946865037194474 \n",
      "Recall: 0.9915254237288136 \n",
      "Aging Rate: 0.4984110169491525\n",
      "Precision: 0.9883843717001056 \n",
      "Recall: 0.9915254237288136 \n",
      "Aging Rate: 0.5015889830508474\n",
      "Precision: 0.9915343915343915 \n",
      "Recall: 0.9925847457627118 \n",
      "Aging Rate: 0.5005296610169492\n",
      "\u001b[32m[I 2021-12-05 18:26:03,450]\u001b[0m Trial 0 finished with value: 2.9749487090427427 and parameters: {'meta_learner': 'ExtraTrees', 'n_estimators': 500, 'min_samples_split': 2, 'max_depth': 6}. Best is trial 0 with value: 2.9749487090427427.\u001b[0m\n",
      "Precision: 0.9873150105708245 \n",
      "Recall: 0.989406779661017 \n",
      "Aging Rate: 0.5010593220338984\n",
      "Precision: 0.9862579281183932 \n",
      "Recall: 0.9883474576271186 \n",
      "Aging Rate: 0.5010593220338984\n",
      "Precision: 0.9893730074388948 \n",
      "Recall: 0.986228813559322 \n",
      "Aging Rate: 0.4984110169491525\n",
      "\u001b[32m[I 2021-12-05 18:26:05,620]\u001b[0m Trial 1 finished with value: 2.963291647701227 and parameters: {'meta_learner': 'ExtraTrees', 'n_estimators': 500, 'min_samples_split': 2, 'max_depth': 3}. Best is trial 0 with value: 2.9749487090427427.\u001b[0m\n",
      "Precision: 0.9904661016949152 \n",
      "Recall: 0.9904661016949152 \n",
      "Aging Rate: 0.5\n",
      "Precision: 0.9946751863684771 \n",
      "Recall: 0.989406779661017 \n",
      "Aging Rate: 0.4973516949152542\n",
      "Precision: 0.9904357066950054 \n",
      "Recall: 0.9872881355932204 \n",
      "Aging Rate: 0.4984110169491525\n",
      "\u001b[32m[I 2021-12-05 18:26:05,799]\u001b[0m Trial 2 finished with value: 2.972771668821983 and parameters: {'meta_learner': 'LogisticRegression', 'C': 0.1, 'penalty': 'none'}. Best is trial 0 with value: 2.9749487090427427.\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Precision: 0.9883843717001056 \n",
      "Recall: 0.9915254237288136 \n",
      "Aging Rate: 0.5015889830508474\n",
      "Precision: 0.9904661016949152 \n",
      "Recall: 0.9904661016949152 \n",
      "Aging Rate: 0.5\n",
      "Precision: 0.9873551106427819 \n",
      "Recall: 0.9925847457627118 \n",
      "Aging Rate: 0.5026483050847458\n",
      "\u001b[32m[I 2021-12-05 18:26:05,962]\u001b[0m Trial 3 finished with value: 2.9689958130873486 and parameters: {'meta_learner': 'LogisticRegression', 'C': 1, 'penalty': 'none'}. Best is trial 0 with value: 2.9749487090427427.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.9852941176470589 \n",
      "Recall: 0.9936440677966102 \n",
      "Aging Rate: 0.5042372881355932\n",
      "Precision: 0.9873684210526316 \n",
      "Recall: 0.9936440677966102 \n",
      "Aging Rate: 0.503177966101695\n",
      "Precision: 0.9863301787592008 \n",
      "Recall: 0.9936440677966102 \n",
      "Aging Rate: 0.503707627118644\n",
      "\u001b[32m[I 2021-12-05 18:26:06,130]\u001b[0m Trial 4 finished with value: 2.9663058794358705 and parameters: {'meta_learner': 'LogisticRegression', 'C': 10, 'penalty': 'none'}. Best is trial 0 with value: 2.9749487090427427.\u001b[0m\n",
      "Precision: 0.9852941176470589 \n",
      "Recall: 0.9936440677966102 \n",
      "Aging Rate: 0.5042372881355932\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.9852164730728616 \n",
      "Recall: 0.9883474576271186 \n",
      "Aging Rate: 0.5015889830508474\n",
      "Precision: 0.986272439281943 \n",
      "Recall: 0.989406779661017 \n",
      "Aging Rate: 0.5015889830508474\n",
      "\u001b[32m[I 2021-12-05 18:26:06,307]\u001b[0m Trial 5 finished with value: 2.9616547883628246 and parameters: {'meta_learner': 'LogisticRegression', 'C': 0.01, 'penalty': 'none'}. Best is trial 0 with value: 2.9749487090427427.\u001b[0m\n",
      "Precision: 0.9894179894179894 \n",
      "Recall: 0.9904661016949152 \n",
      "Aging Rate: 0.5005296610169492\n",
      "Precision: 0.9893842887473461 \n",
      "Recall: 0.9872881355932204 \n",
      "Aging Rate: 0.4989406779661017\n",
      "Precision: 0.9925768822905621 \n",
      "Recall: 0.9915254237288136 \n",
      "Aging Rate: 0.4994703389830508\n",
      "\u001b[32m[I 2021-12-05 18:26:06,460]\u001b[0m Trial 6 finished with value: 2.9706793273095813 and parameters: {'meta_learner': 'LogisticRegression', 'C': 0.1, 'penalty': 'l2'}. Best is trial 0 with value: 2.9749487090427427.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.9893955461293743 \n",
      "Recall: 0.9883474576271186 \n",
      "Aging Rate: 0.4994703389830508\n",
      "Precision: 0.9946524064171123 \n",
      "Recall: 0.9851694915254238 \n",
      "Aging Rate: 0.4952330508474576\n",
      "Precision: 0.9915343915343915 \n",
      "Recall: 0.9925847457627118 \n",
      "Aging Rate: 0.5005296610169492\n",
      "\u001b[32m[I 2021-12-05 18:26:06,644]\u001b[0m Trial 7 finished with value: 2.972422127692337 and parameters: {'meta_learner': 'LogisticRegression', 'C': 0.1, 'penalty': 'none'}. Best is trial 0 with value: 2.9749487090427427.\u001b[0m\n",
      "Precision: 0.9914802981895634 \n",
      "Recall: 0.986228813559322 \n",
      "Aging Rate: 0.4973516949152542\n",
      "Precision: 0.9832109129066107 \n",
      "Recall: 0.9925847457627118 \n",
      "Aging Rate: 0.5047669491525424\n",
      "Precision: 0.991462113127001 \n",
      "Recall: 0.9841101694915254 \n",
      "Aging Rate: 0.4962923728813559\n",
      "\u001b[32m[I 2021-12-05 18:26:08,311]\u001b[0m Trial 8 finished with value: 2.9650767924199695 and parameters: {'meta_learner': 'ExtraTrees', 'n_estimators': 300, 'min_samples_split': 32, 'max_depth': 6}. Best is trial 0 with value: 2.9749487090427427.\u001b[0m\n",
      "Precision: 0.9862579281183932 \n",
      "Recall: 0.9883474576271186 \n",
      "Aging Rate: 0.5010593220338984\n",
      "Precision: 0.9936238044633369 \n",
      "Recall: 0.9904661016949152 \n",
      "Aging Rate: 0.4984110169491525\n",
      "Precision: 0.9863013698630136 \n",
      "Recall: 0.9915254237288136 \n",
      "Aging Rate: 0.5026483050847458\n",
      "\u001b[32m[I 2021-12-05 18:26:10,537]\u001b[0m Trial 9 finished with value: 2.9675683959801114 and parameters: {'meta_learner': 'ExtraTrees', 'n_estimators': 500, 'min_samples_split': 22, 'max_depth': 15}. Best is trial 0 with value: 2.9749487090427427.\u001b[0m\n",
      "Precision: 0.9915522703273495 \n",
      "Recall: 0.9947033898305084 \n",
      "Aging Rate: 0.5015889830508474\n",
      "Precision: 0.9863013698630136 \n",
      "Recall: 0.9915254237288136 \n",
      "Aging Rate: 0.5026483050847458\n",
      "Precision: 0.9925611052072264 \n",
      "Recall: 0.989406779661017 \n",
      "Aging Rate: 0.4984110169491525\n",
      "\u001b[32m[I 2021-12-05 18:26:11,776]\u001b[0m Trial 10 finished with value: 2.9721550280051727 and parameters: {'meta_learner': 'ExtraTrees', 'n_estimators': 100, 'min_samples_split': 2, 'max_depth': 9}. Best is trial 0 with value: 2.9749487090427427.\u001b[0m\n",
      "Precision: 0.9915164369034994 \n",
      "Recall: 0.9904661016949152 \n",
      "Aging Rate: 0.4994703389830508\n",
      "Precision: 0.9946695095948828 \n",
      "Recall: 0.9883474576271186 \n",
      "Aging Rate: 0.4968220338983051\n",
      "Precision: 0.9978586723768736 \n",
      "Recall: 0.9872881355932204 \n",
      "Aging Rate: 0.4947033898305085\n",
      "\u001b[32m[I 2021-12-05 18:26:14,166]\u001b[0m Trial 11 finished with value: 2.978063644221922 and parameters: {'meta_learner': 'ExtraTrees', 'n_estimators': 500, 'min_samples_split': 12, 'max_depth': 21}. Best is trial 11 with value: 2.978063644221922.\u001b[0m\n",
      "Precision: 0.9904761904761905 \n",
      "Recall: 0.9915254237288136 \n",
      "Aging Rate: 0.5005296610169492\n",
      "Precision: 0.9894291754756871 \n",
      "Recall: 0.9915254237288136 \n",
      "Aging Rate: 0.5010593220338984\n",
      "Precision: 0.9904761904761905 \n",
      "Recall: 0.9915254237288136 \n",
      "Aging Rate: 0.5005296610169492\n",
      "\u001b[32m[I 2021-12-05 18:26:16,361]\u001b[0m Trial 12 finished with value: 2.971779794680859 and parameters: {'meta_learner': 'ExtraTrees', 'n_estimators': 500, 'min_samples_split': 12, 'max_depth': 21}. Best is trial 11 with value: 2.978063644221922.\u001b[0m\n",
      "Precision: 0.9936440677966102 \n",
      "Recall: 0.9936440677966102 \n",
      "Aging Rate: 0.5\n",
      "Precision: 0.9832109129066107 \n",
      "Recall: 0.9925847457627118 \n",
      "Aging Rate: 0.5047669491525424\n",
      "Precision: 0.9936034115138592 \n",
      "Recall: 0.9872881355932204 \n",
      "Aging Rate: 0.4968220338983051\n",
      "\u001b[32m[I 2021-12-05 18:26:18,072]\u001b[0m Trial 13 finished with value: 2.9714779111955676 and parameters: {'meta_learner': 'ExtraTrees', 'n_estimators': 300, 'min_samples_split': 12, 'max_depth': 21}. Best is trial 11 with value: 2.978063644221922.\u001b[0m\n",
      "Precision: 0.9915433403805497 \n",
      "Recall: 0.9936440677966102 \n",
      "Aging Rate: 0.5010593220338984\n",
      "Precision: 0.9925690021231423 \n",
      "Recall: 0.9904661016949152 \n",
      "Aging Rate: 0.4989406779661017\n",
      "Precision: 0.991462113127001 \n",
      "Recall: 0.9841101694915254 \n",
      "Aging Rate: 0.4962923728813559\n",
      "\u001b[32m[I 2021-12-05 18:26:20,266]\u001b[0m Trial 14 finished with value: 2.973123083414812 and parameters: {'meta_learner': 'ExtraTrees', 'n_estimators': 500, 'min_samples_split': 7, 'max_depth': 15}. Best is trial 11 with value: 2.978063644221922.\u001b[0m\n",
      "Precision: 0.9957264957264957 \n",
      "Recall: 0.9872881355932204 \n",
      "Aging Rate: 0.4957627118644068\n",
      "Precision: 0.9915074309978769 \n",
      "Recall: 0.989406779661017 \n",
      "Aging Rate: 0.4989406779661017\n",
      "Precision: 0.9862579281183932 \n",
      "Recall: 0.9883474576271186 \n",
      "Aging Rate: 0.5010593220338984\n",
      "\u001b[32m[I 2021-12-05 18:26:22,013]\u001b[0m Trial 15 finished with value: 2.9706753608556293 and parameters: {'meta_learner': 'ExtraTrees', 'n_estimators': 300, 'min_samples_split': 22, 'max_depth': 3}. Best is trial 11 with value: 2.978063644221922.\u001b[0m\n",
      "Precision: 0.9904661016949152 \n",
      "Recall: 0.9904661016949152 \n",
      "Aging Rate: 0.5\n",
      "Precision: 0.9893842887473461 \n",
      "Recall: 0.9872881355932204 \n",
      "Aging Rate: 0.4989406779661017\n",
      "Precision: 0.989406779661017 \n",
      "Recall: 0.989406779661017 \n",
      "Aging Rate: 0.5\n",
      "\u001b[32m[I 2021-12-05 18:26:24,267]\u001b[0m Trial 16 finished with value: 2.968558452385236 and parameters: {'meta_learner': 'ExtraTrees', 'n_estimators': 500, 'min_samples_split': 12, 'max_depth': 12}. Best is trial 11 with value: 2.978063644221922.\u001b[0m\n",
      "Precision: 0.9883597883597883 \n",
      "Recall: 0.989406779661017 \n",
      "Aging Rate: 0.5005296610169492\n",
      "Precision: 0.9893617021276596 \n",
      "Recall: 0.9851694915254238 \n",
      "Aging Rate: 0.4978813559322034\n",
      "Precision: 0.9914802981895634 \n",
      "Recall: 0.986228813559322 \n",
      "Aging Rate: 0.4973516949152542\n",
      "\u001b[32m[I 2021-12-05 18:26:25,470]\u001b[0m Trial 17 finished with value: 2.966402887366595 and parameters: {'meta_learner': 'ExtraTrees', 'n_estimators': 100, 'min_samples_split': 2, 'max_depth': 9}. Best is trial 11 with value: 2.978063644221922.\u001b[0m\n",
      "Precision: 0.9841605068637803 \n",
      "Recall: 0.9872881355932204 \n",
      "Aging Rate: 0.5015889830508474\n",
      "Precision: 0.9883474576271186 \n",
      "Recall: 0.9883474576271186 \n",
      "Aging Rate: 0.5\n",
      "Precision: 0.9914712153518124 \n",
      "Recall: 0.9851694915254238 \n",
      "Aging Rate: 0.4968220338983051\n",
      "\u001b[32m[I 2021-12-05 18:26:27,629]\u001b[0m Trial 18 finished with value: 2.9629211481437285 and parameters: {'meta_learner': 'ExtraTrees', 'n_estimators': 500, 'min_samples_split': 17, 'max_depth': 18}. Best is trial 11 with value: 2.978063644221922.\u001b[0m\n",
      "Precision: 0.9915254237288136 \n",
      "Recall: 0.9915254237288136 \n",
      "Aging Rate: 0.5\n",
      "Precision: 0.985200845665962 \n",
      "Recall: 0.9872881355932204 \n",
      "Aging Rate: 0.5010593220338984\n",
      "Precision: 0.991462113127001 \n",
      "Recall: 0.9841101694915254 \n",
      "Aging Rate: 0.4962923728813559\n",
      "\u001b[32m[I 2021-12-05 18:26:29,327]\u001b[0m Trial 19 finished with value: 2.9664334979523708 and parameters: {'meta_learner': 'ExtraTrees', 'n_estimators': 300, 'min_samples_split': 7, 'max_depth': 6}. Best is trial 11 with value: 2.978063644221922.\u001b[0m\n",
      "Precision: 0.9883227176220807 \n",
      "Recall: 0.986228813559322 \n",
      "Aging Rate: 0.4989406779661017\n",
      "Precision: 0.990405117270789 \n",
      "Recall: 0.9841101694915254 \n",
      "Aging Rate: 0.4968220338983051\n",
      "Precision: 0.9936034115138592 \n",
      "Recall: 0.9872881355932204 \n",
      "Aging Rate: 0.4968220338983051\n",
      "\u001b[32m[I 2021-12-05 18:26:31,552]\u001b[0m Trial 20 finished with value: 2.967429870485842 and parameters: {'meta_learner': 'ExtraTrees', 'n_estimators': 500, 'min_samples_split': 32, 'max_depth': 9}. Best is trial 11 with value: 2.978063644221922.\u001b[0m\n",
      "Precision: 0.9873015873015873 \n",
      "Recall: 0.9883474576271186 \n",
      "Aging Rate: 0.5005296610169492\n",
      "Precision: 0.9915164369034994 \n",
      "Recall: 0.9904661016949152 \n",
      "Aging Rate: 0.4994703389830508\n",
      "Precision: 0.9915611814345991 \n",
      "Recall: 0.9957627118644068 \n",
      "Aging Rate: 0.5021186440677966\n",
      "\u001b[32m[I 2021-12-05 18:26:33,902]\u001b[0m Trial 21 finished with value: 2.971778227488604 and parameters: {'meta_learner': 'ExtraTrees', 'n_estimators': 500, 'min_samples_split': 7, 'max_depth': 15}. Best is trial 11 with value: 2.978063644221922.\u001b[0m\n",
      "Precision: 0.9935965848452508 \n",
      "Recall: 0.986228813559322 \n",
      "Aging Rate: 0.4962923728813559\n",
      "Precision: 0.9914984059511158 \n",
      "Recall: 0.9883474576271186 \n",
      "Aging Rate: 0.4984110169491525\n",
      "Precision: 0.9883351007423118 \n",
      "Recall: 0.9872881355932204 \n",
      "Aging Rate: 0.4994703389830508\n",
      "\u001b[32m[I 2021-12-05 18:26:36,138]\u001b[0m Trial 22 finished with value: 2.9695748632856724 and parameters: {'meta_learner': 'ExtraTrees', 'n_estimators': 500, 'min_samples_split': 7, 'max_depth': 18}. Best is trial 11 with value: 2.978063644221922.\u001b[0m\n",
      "Precision: 0.9925768822905621 \n",
      "Recall: 0.9915254237288136 \n",
      "Aging Rate: 0.4994703389830508\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.9893842887473461 \n",
      "Recall: 0.9872881355932204 \n",
      "Aging Rate: 0.4989406779661017\n",
      "Precision: 0.9904559915164369 \n",
      "Recall: 0.989406779661017 \n",
      "Aging Rate: 0.4994703389830508\n",
      "\u001b[32m[I 2021-12-05 18:26:38,313]\u001b[0m Trial 23 finished with value: 2.9710182213639134 and parameters: {'meta_learner': 'ExtraTrees', 'n_estimators': 500, 'min_samples_split': 7, 'max_depth': 15}. Best is trial 11 with value: 2.978063644221922.\u001b[0m\n",
      "Precision: 0.9914984059511158 \n",
      "Recall: 0.9883474576271186 \n",
      "Aging Rate: 0.4984110169491525\n",
      "Precision: 0.9884088514225501 \n",
      "Recall: 0.9936440677966102 \n",
      "Aging Rate: 0.5026483050847458\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "``multivariate`` option is an experimental feature. The interface can change in the future.\n",
      "\u001b[32m[I 2021-12-05 18:26:40,581]\u001b[0m A new study created in memory with name: no-name-e7cd99d6-4154-4294-991e-b7a7eae51806\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.9914893617021276 \n",
      "Recall: 0.9872881355932204 \n",
      "Aging Rate: 0.4978813559322034\n",
      "\u001b[32m[I 2021-12-05 18:26:40,494]\u001b[0m Trial 24 finished with value: 2.970690966389512 and parameters: {'meta_learner': 'ExtraTrees', 'n_estimators': 500, 'min_samples_split': 17, 'max_depth': 18}. Best is trial 11 with value: 2.978063644221922.\u001b[0m\n",
      "Sampler is TPESampler\n",
      "Dataset3 :\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress bar is experimental (supported from v1.2.0). The interface can change in the future.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c61ea85cdfed4f3696356ce068668bf5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.9974025974025974 \n",
      "Recall: 0.9961089494163424 \n",
      "Aging Rate: 0.4993514915693904\n",
      "Precision: 0.9987012987012988 \n",
      "Recall: 0.9974059662775616 \n",
      "Aging Rate: 0.4993514915693904\n",
      "Precision: 0.9961139896373057 \n",
      "Recall: 0.9974059662775616 \n",
      "Aging Rate: 0.5006485084306096\n",
      "\u001b[32m[I 2021-12-05 18:26:41,714]\u001b[0m Trial 0 finished with value: 2.9917855511512896 and parameters: {'meta_learner': 'ExtraTrees', 'n_estimators': 100, 'min_samples_split': 2, 'max_depth': 15}. Best is trial 0 with value: 2.9917855511512896.\u001b[0m\n",
      "Precision: 1.0 \n",
      "Recall: 0.9922178988326849 \n",
      "Aging Rate: 0.4961089494163424\n",
      "Precision: 0.9974093264248705 \n",
      "Recall: 0.9987029831387808 \n",
      "Aging Rate: 0.5006485084306096\n",
      "Precision: 0.9974059662775616 \n",
      "Recall: 0.9974059662775616 \n",
      "Aging Rate: 0.5\n",
      "\u001b[32m[I 2021-12-05 18:26:42,915]\u001b[0m Trial 1 finished with value: 2.9926524778846306 and parameters: {'meta_learner': 'ExtraTrees', 'n_estimators': 100, 'min_samples_split': 12, 'max_depth': 3}. Best is trial 1 with value: 2.9926524778846306.\u001b[0m\n",
      "Precision: 0.9974059662775616 \n",
      "Recall: 0.9974059662775616 \n",
      "Aging Rate: 0.5\n",
      "Precision: 0.9961089494163424 \n",
      "Recall: 0.9961089494163424 \n",
      "Aging Rate: 0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.9973958333333334 \n",
      "Recall: 0.993514915693904 \n",
      "Aging Rate: 0.4980544747081712\n",
      "\u001b[32m[I 2021-12-05 18:26:43,132]\u001b[0m Trial 2 finished with value: 2.9896171098140947 and parameters: {'meta_learner': 'LogisticRegression', 'C': 0.1, 'penalty': 'none'}. Best is trial 1 with value: 2.9926524778846306.\u001b[0m\n",
      "Precision: 0.9986979166666666 \n",
      "Recall: 0.9948119325551232 \n",
      "Aging Rate: 0.4980544747081712\n",
      "Precision: 0.9973958333333334 \n",
      "Recall: 0.993514915693904 \n",
      "Aging Rate: 0.4980544747081712\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.9961089494163424 \n",
      "Recall: 0.9961089494163424 \n",
      "Aging Rate: 0.5\n",
      "\u001b[32m[I 2021-12-05 18:26:43,348]\u001b[0m Trial 3 finished with value: 2.9896137321660183 and parameters: {'meta_learner': 'LogisticRegression', 'C': 100, 'penalty': 'none'}. Best is trial 1 with value: 2.9926524778846306.\u001b[0m\n",
      "Precision: 1.0 \n",
      "Recall: 0.9948119325551232 \n",
      "Aging Rate: 0.4974059662775616\n",
      "Precision: 0.9974059662775616 \n",
      "Recall: 0.9974059662775616 \n",
      "Aging Rate: 0.5\n",
      "Precision: 0.9961089494163424 \n",
      "Recall: 0.9961089494163424 \n",
      "Aging Rate: 0.5\n",
      "\u001b[32m[I 2021-12-05 18:26:43,535]\u001b[0m Trial 4 finished with value: 2.991785559878945 and parameters: {'meta_learner': 'LogisticRegression', 'C': 0.01, 'penalty': 'l2'}. Best is trial 1 with value: 2.9926524778846306.\u001b[0m\n",
      "Precision: 0.9974093264248705 \n",
      "Recall: 0.9987029831387808 \n",
      "Aging Rate: 0.5006485084306096\n",
      "Precision: 0.9986945169712794 \n",
      "Recall: 0.9922178988326849 \n",
      "Aging Rate: 0.496757457846952\n",
      "Precision: 0.9974025974025974 \n",
      "Recall: 0.9961089494163424 \n",
      "Aging Rate: 0.4993514915693904\n",
      "\u001b[32m[I 2021-12-05 18:26:45,757]\u001b[0m Trial 5 finished with value: 2.9913475709951007 and parameters: {'meta_learner': 'ExtraTrees', 'n_estimators': 500, 'min_samples_split': 7, 'max_depth': 3}. Best is trial 1 with value: 2.9926524778846306.\u001b[0m\n",
      "Precision: 0.9948119325551232 \n",
      "Recall: 0.9948119325551232 \n",
      "Aging Rate: 0.5\n",
      "Precision: 0.9974126778783958 \n",
      "Recall: 1.0 \n",
      "Aging Rate: 0.5012970168612192\n",
      "Precision: 0.990990990990991 \n",
      "Recall: 0.9987029831387808 \n",
      "Aging Rate: 0.5038910505836576\n",
      "\u001b[32m[I 2021-12-05 18:26:47,933]\u001b[0m Trial 6 finished with value: 2.9866487061809743 and parameters: {'meta_learner': 'ExtraTrees', 'n_estimators': 500, 'min_samples_split': 17, 'max_depth': 3}. Best is trial 1 with value: 2.9926524778846306.\u001b[0m\n",
      "Precision: 0.9909560723514211 \n",
      "Recall: 0.9948119325551232 \n",
      "Aging Rate: 0.5019455252918288\n",
      "Precision: 0.9961139896373057 \n",
      "Recall: 0.9974059662775616 \n",
      "Aging Rate: 0.5006485084306096\n",
      "Precision: 0.9961190168175937 \n",
      "Recall: 0.9987029831387808 \n",
      "Aging Rate: 0.5012970168612192\n",
      "\u001b[32m[I 2021-12-05 18:26:48,110]\u001b[0m Trial 7 finished with value: 2.985766346528036 and parameters: {'meta_learner': 'LogisticRegression', 'C': 10, 'penalty': 'none'}. Best is trial 1 with value: 2.9926524778846306.\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Precision: 0.9986945169712794 \n",
      "Recall: 0.9922178988326849 \n",
      "Aging Rate: 0.496757457846952\n",
      "Precision: 0.9935400516795866 \n",
      "Recall: 0.9974059662775616 \n",
      "Aging Rate: 0.5019455252918288\n",
      "Precision: 0.9884020618556701 \n",
      "Recall: 0.9948119325551232 \n",
      "Aging Rate: 0.503242542153048\n",
      "\u001b[32m[I 2021-12-05 18:26:48,274]\u001b[0m Trial 8 finished with value: 2.9819030195594807 and parameters: {'meta_learner': 'LogisticRegression', 'C': 1, 'penalty': 'l2'}. Best is trial 1 with value: 2.9926524778846306.\u001b[0m\n",
      "Precision: 0.9947916666666666 \n",
      "Recall: 0.9909208819714657 \n",
      "Aging Rate: 0.4980544747081712\n",
      "Precision: 1.0 \n",
      "Recall: 0.9922178988326849 \n",
      "Aging Rate: 0.4961089494163424\n",
      "Precision: 0.9974025974025974 \n",
      "Recall: 0.9961089494163424 \n",
      "Aging Rate: 0.4993514915693904\n",
      "\u001b[32m[I 2021-12-05 18:26:48,416]\u001b[0m Trial 9 finished with value: 2.98787875278634 and parameters: {'meta_learner': 'LogisticRegression', 'C': 0.01, 'penalty': 'l2'}. Best is trial 1 with value: 2.9926524778846306.\u001b[0m\n",
      "Precision: 0.9961139896373057 \n",
      "Recall: 0.9974059662775616 \n",
      "Aging Rate: 0.5006485084306096\n",
      "Precision: 0.990979381443299 \n",
      "Recall: 0.9974059662775616 \n",
      "Aging Rate: 0.503242542153048\n",
      "Precision: 0.9961038961038962 \n",
      "Recall: 0.9948119325551232 \n",
      "Aging Rate: 0.4993514915693904\n",
      "\u001b[32m[I 2021-12-05 18:26:49,626]\u001b[0m Trial 10 finished with value: 2.9853394664930826 and parameters: {'meta_learner': 'ExtraTrees', 'n_estimators': 100, 'min_samples_split': 32, 'max_depth': 9}. Best is trial 1 with value: 2.9926524778846306.\u001b[0m\n",
      "Precision: 0.9961089494163424 \n",
      "Recall: 0.9961089494163424 \n",
      "Aging Rate: 0.5\n",
      "Precision: 0.9961240310077519 \n",
      "Recall: 1.0 \n",
      "Aging Rate: 0.5019455252918288\n",
      "Precision: 0.9987029831387808 \n",
      "Recall: 0.9987029831387808 \n",
      "Aging Rate: 0.5\n",
      "\u001b[32m[I 2021-12-05 18:26:50,830]\u001b[0m Trial 11 finished with value: 2.992227953226958 and parameters: {'meta_learner': 'ExtraTrees', 'n_estimators': 100, 'min_samples_split': 17, 'max_depth': 21}. Best is trial 1 with value: 2.9926524778846306.\u001b[0m\n",
      "Precision: 0.9973992197659298 \n",
      "Recall: 0.9948119325551232 \n",
      "Aging Rate: 0.4987029831387808\n",
      "Precision: 0.9961190168175937 \n",
      "Recall: 0.9987029831387808 \n",
      "Aging Rate: 0.5012970168612192\n",
      "Precision: 0.9973958333333334 \n",
      "Recall: 0.993514915693904 \n",
      "Aging Rate: 0.4980544747081712\n",
      "\u001b[32m[I 2021-12-05 18:26:52,036]\u001b[0m Trial 12 finished with value: 2.989619323740507 and parameters: {'meta_learner': 'ExtraTrees', 'n_estimators': 100, 'min_samples_split': 17, 'max_depth': 21}. Best is trial 1 with value: 2.9926524778846306.\u001b[0m\n",
      "Precision: 0.9948253557567918 \n",
      "Recall: 0.9974059662775616 \n",
      "Aging Rate: 0.5012970168612192\n",
      "Precision: 0.9961139896373057 \n",
      "Recall: 0.9974059662775616 \n",
      "Aging Rate: 0.5006485084306096\n",
      "Precision: 0.9973958333333334 \n",
      "Recall: 0.993514915693904 \n",
      "Aging Rate: 0.4980544747081712\n",
      "\u001b[32m[I 2021-12-05 18:26:53,717]\u001b[0m Trial 13 finished with value: 2.988332401901296 and parameters: {'meta_learner': 'ExtraTrees', 'n_estimators': 300, 'min_samples_split': 12, 'max_depth': 21}. Best is trial 1 with value: 2.9926524778846306.\u001b[0m\n",
      "Precision: 0.9974093264248705 \n",
      "Recall: 0.9987029831387808 \n",
      "Aging Rate: 0.5006485084306096\n",
      "Precision: 0.9935316946959897 \n",
      "Recall: 0.9961089494163424 \n",
      "Aging Rate: 0.5012970168612192\n",
      "Precision: 0.9961139896373057 \n",
      "Recall: 0.9974059662775616 \n",
      "Aging Rate: 0.5006485084306096\n",
      "\u001b[32m[I 2021-12-05 18:26:55,509]\u001b[0m Trial 14 finished with value: 2.988775973449672 and parameters: {'meta_learner': 'ExtraTrees', 'n_estimators': 300, 'min_samples_split': 22, 'max_depth': 12}. Best is trial 1 with value: 2.9926524778846306.\u001b[0m\n",
      "Precision: 0.9948320413436692 \n",
      "Recall: 0.9987029831387808 \n",
      "Aging Rate: 0.5019455252918288\n",
      "Precision: 0.9961139896373057 \n",
      "Recall: 0.9974059662775616 \n",
      "Aging Rate: 0.5006485084306096\n",
      "Precision: 0.9986996098829649 \n",
      "Recall: 0.9961089494163424 \n",
      "Aging Rate: 0.4987029831387808\n",
      "\u001b[32m[I 2021-12-05 18:26:56,731]\u001b[0m Trial 15 finished with value: 2.9905030601868545 and parameters: {'meta_learner': 'ExtraTrees', 'n_estimators': 100, 'min_samples_split': 27, 'max_depth': 18}. Best is trial 1 with value: 2.9926524778846306.\u001b[0m\n",
      "Precision: 0.9948253557567918 \n",
      "Recall: 0.9974059662775616 \n",
      "Aging Rate: 0.5012970168612192\n",
      "Precision: 0.9986962190352021 \n",
      "Recall: 0.993514915693904 \n",
      "Aging Rate: 0.4974059662775616\n",
      "Precision: 0.9986996098829649 \n",
      "Recall: 0.9961089494163424 \n",
      "Aging Rate: 0.4987029831387808\n",
      "\u001b[32m[I 2021-12-05 18:26:58,438]\u001b[0m Trial 16 finished with value: 2.9904907335792417 and parameters: {'meta_learner': 'ExtraTrees', 'n_estimators': 300, 'min_samples_split': 12, 'max_depth': 9}. Best is trial 1 with value: 2.9926524778846306.\u001b[0m\n",
      "Precision: 1.0 \n",
      "Recall: 1.0 \n",
      "Aging Rate: 0.5\n",
      "Precision: 0.9948253557567918 \n",
      "Recall: 0.9974059662775616 \n",
      "Aging Rate: 0.5012970168612192\n",
      "Precision: 0.9935316946959897 \n",
      "Recall: 0.9961089494163424 \n",
      "Aging Rate: 0.5012970168612192\n",
      "\u001b[32m[I 2021-12-05 18:26:59,645]\u001b[0m Trial 17 finished with value: 2.990076338866489 and parameters: {'meta_learner': 'ExtraTrees', 'n_estimators': 100, 'min_samples_split': 7, 'max_depth': 6}. Best is trial 1 with value: 2.9926524778846306.\u001b[0m\n",
      "Precision: 0.9961139896373057 \n",
      "Recall: 0.9974059662775616 \n",
      "Aging Rate: 0.5006485084306096\n",
      "Precision: 1.0 \n",
      "Recall: 0.9974059662775616 \n",
      "Aging Rate: 0.4987029831387808\n",
      "Precision: 0.9974025974025974 \n",
      "Recall: 0.9961089494163424 \n",
      "Aging Rate: 0.4993514915693904\n",
      "\u001b[32m[I 2021-12-05 18:27:00,835]\u001b[0m Trial 18 finished with value: 2.99265135201709 and parameters: {'meta_learner': 'ExtraTrees', 'n_estimators': 100, 'min_samples_split': 22, 'max_depth': 15}. Best is trial 1 with value: 2.9926524778846306.\u001b[0m\n",
      "Precision: 0.9935483870967742 \n",
      "Recall: 0.9987029831387808 \n",
      "Aging Rate: 0.5025940337224384\n",
      "Precision: 0.9973992197659298 \n",
      "Recall: 0.9948119325551232 \n",
      "Aging Rate: 0.4987029831387808\n",
      "Precision: 0.9948186528497409 \n",
      "Recall: 0.9961089494163424 \n",
      "Aging Rate: 0.5006485084306096\n",
      "\u001b[32m[I 2021-12-05 18:27:02,599]\u001b[0m Trial 19 finished with value: 2.987052128178379 and parameters: {'meta_learner': 'ExtraTrees', 'n_estimators': 300, 'min_samples_split': 27, 'max_depth': 15}. Best is trial 1 with value: 2.9926524778846306.\u001b[0m\n",
      "Precision: 0.9948387096774194 \n",
      "Recall: 1.0 \n",
      "Aging Rate: 0.5025940337224384\n",
      "Precision: 0.9987029831387808 \n",
      "Recall: 0.9987029831387808 \n",
      "Aging Rate: 0.5\n",
      "Precision: 1.0 \n",
      "Recall: 0.9909208819714657 \n",
      "Aging Rate: 0.49546044098573283\n",
      "\u001b[32m[I 2021-12-05 18:27:03,866]\u001b[0m Trial 20 finished with value: 2.992235750247549 and parameters: {'meta_learner': 'ExtraTrees', 'n_estimators': 100, 'min_samples_split': 22, 'max_depth': 15}. Best is trial 1 with value: 2.9926524778846306.\u001b[0m\n",
      "Precision: 0.9986945169712794 \n",
      "Recall: 0.9922178988326849 \n",
      "Aging Rate: 0.496757457846952\n",
      "Precision: 0.9961089494163424 \n",
      "Recall: 0.9961089494163424 \n",
      "Aging Rate: 0.5\n",
      "Precision: 0.9974059662775616 \n",
      "Recall: 0.9974059662775616 \n",
      "Aging Rate: 0.5\n",
      "\u001b[32m[I 2021-12-05 18:27:05,085]\u001b[0m Trial 21 finished with value: 2.990050559952319 and parameters: {'meta_learner': 'ExtraTrees', 'n_estimators': 100, 'min_samples_split': 22, 'max_depth': 15}. Best is trial 1 with value: 2.9926524778846306.\u001b[0m\n",
      "Precision: 0.9948320413436692 \n",
      "Recall: 0.9987029831387808 \n",
      "Aging Rate: 0.5019455252918288\n",
      "Precision: 0.9987012987012988 \n",
      "Recall: 0.9974059662775616 \n",
      "Aging Rate: 0.4993514915693904\n",
      "Precision: 0.9986962190352021 \n",
      "Recall: 0.993514915693904 \n",
      "Aging Rate: 0.4974059662775616\n",
      "\u001b[32m[I 2021-12-05 18:27:06,308]\u001b[0m Trial 22 finished with value: 2.991360994423529 and parameters: {'meta_learner': 'ExtraTrees', 'n_estimators': 100, 'min_samples_split': 22, 'max_depth': 12}. Best is trial 1 with value: 2.9926524778846306.\u001b[0m\n",
      "Precision: 0.9986945169712794 \n",
      "Recall: 0.9922178988326849 \n",
      "Aging Rate: 0.496757457846952\n",
      "Precision: 0.9986996098829649 \n",
      "Recall: 0.9961089494163424 \n",
      "Aging Rate: 0.4987029831387808\n",
      "Precision: 0.9948320413436692 \n",
      "Recall: 0.9987029831387808 \n",
      "Aging Rate: 0.5019455252918288\n",
      "\u001b[32m[I 2021-12-05 18:27:07,508]\u001b[0m Trial 23 finished with value: 2.990494055927878 and parameters: {'meta_learner': 'ExtraTrees', 'n_estimators': 100, 'min_samples_split': 27, 'max_depth': 18}. Best is trial 1 with value: 2.9926524778846306.\u001b[0m\n",
      "Precision: 0.9961089494163424 \n",
      "Recall: 0.9961089494163424 \n",
      "Aging Rate: 0.5\n",
      "Precision: 0.9974025974025974 \n",
      "Recall: 0.9961089494163424 \n",
      "Aging Rate: 0.4993514915693904\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "``multivariate`` option is an experimental feature. The interface can change in the future.\n",
      "\u001b[32m[I 2021-12-05 18:27:08,818]\u001b[0m A new study created in memory with name: no-name-81273dd5-134f-469a-8340-d0d085c1aa9d\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.9935400516795866 \n",
      "Recall: 0.9974059662775616 \n",
      "Aging Rate: 0.5019455252918288\n",
      "\u001b[32m[I 2021-12-05 18:27:08,717]\u001b[0m Trial 24 finished with value: 2.9879090207024332 and parameters: {'meta_learner': 'ExtraTrees', 'n_estimators': 100, 'min_samples_split': 12, 'max_depth': 18}. Best is trial 1 with value: 2.9926524778846306.\u001b[0m\n",
      "Sampler is TPESampler\n",
      "Dataset4 :\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress bar is experimental (supported from v1.2.0). The interface can change in the future.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ada89fab9c54645b3650a26ebe84928",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.9956958393113343 \n",
      "Recall: 0.9871977240398293 \n",
      "Aging Rate: 0.4957325746799431\n",
      "Precision: 0.9956584659913169 \n",
      "Recall: 0.9786628733997155 \n",
      "Aging Rate: 0.4914651493598862\n",
      "Precision: 0.9957142857142857 \n",
      "Recall: 0.9914651493598862 \n",
      "Aging Rate: 0.49786628733997157\n",
      "\u001b[32m[I 2021-12-05 18:27:09,953]\u001b[0m Trial 0 finished with value: 2.9771543096111017 and parameters: {'meta_learner': 'ExtraTrees', 'n_estimators': 100, 'min_samples_split': 2, 'max_depth': 3}. Best is trial 0 with value: 2.9771543096111017.\u001b[0m\n",
      "Precision: 0.99568345323741 \n",
      "Recall: 0.984352773826458 \n",
      "Aging Rate: 0.49431009957325744\n",
      "Precision: 0.9971223021582734 \n",
      "Recall: 0.9857752489331437 \n",
      "Aging Rate: 0.49431009957325744\n",
      "Precision: 0.9971181556195965 \n",
      "Recall: 0.984352773826458 \n",
      "Aging Rate: 0.49359886201991465\n",
      "\u001b[32m[I 2021-12-05 18:27:10,118]\u001b[0m Trial 1 finished with value: 2.9781095395388726 and parameters: {'meta_learner': 'LogisticRegression', 'C': 1, 'penalty': 'none'}. Best is trial 1 with value: 2.9781095395388726.\u001b[0m\n",
      "Precision: 0.9956958393113343 \n",
      "Recall: 0.9871977240398293 \n",
      "Aging Rate: 0.4957325746799431\n",
      "Precision: 0.9886363636363636 \n",
      "Recall: 0.9900426742532006 \n",
      "Aging Rate: 0.5007112375533428\n",
      "Precision: 0.992816091954023 \n",
      "Recall: 0.9829302987197724 \n",
      "Aging Rate: 0.4950213371266003\n",
      "\u001b[32m[I 2021-12-05 18:27:11,832]\u001b[0m Trial 2 finished with value: 2.9714890956054147 and parameters: {'meta_learner': 'ExtraTrees', 'n_estimators': 300, 'min_samples_split': 2, 'max_depth': 12}. Best is trial 1 with value: 2.9781095395388726.\u001b[0m\n",
      "Precision: 0.9928469241773963 \n",
      "Recall: 0.9871977240398293 \n",
      "Aging Rate: 0.4971550497866287\n",
      "Precision: 0.9956772334293948 \n",
      "Recall: 0.9829302987197724 \n",
      "Aging Rate: 0.49359886201991465\n",
      "Precision: 0.9971139971139971 \n",
      "Recall: 0.9829302987197724 \n",
      "Aging Rate: 0.49288762446657186\n",
      "\u001b[32m[I 2021-12-05 18:27:13,629]\u001b[0m Trial 3 finished with value: 2.9747782103069835 and parameters: {'meta_learner': 'ExtraTrees', 'n_estimators': 300, 'min_samples_split': 7, 'max_depth': 3}. Best is trial 1 with value: 2.9781095395388726.\u001b[0m\n",
      "Precision: 0.994277539341917 \n",
      "Recall: 0.9886201991465149 \n",
      "Aging Rate: 0.4971550497866287\n",
      "Precision: 0.9956896551724138 \n",
      "Recall: 0.9857752489331437 \n",
      "Aging Rate: 0.4950213371266003\n",
      "Precision: 0.9971428571428571 \n",
      "Recall: 0.9928876244665719 \n",
      "Aging Rate: 0.49786628733997157\n",
      "\u001b[32m[I 2021-12-05 18:27:15,805]\u001b[0m Trial 4 finished with value: 2.9805010586202023 and parameters: {'meta_learner': 'ExtraTrees', 'n_estimators': 500, 'min_samples_split': 12, 'max_depth': 18}. Best is trial 4 with value: 2.9805010586202023.\u001b[0m\n",
      "Precision: 0.9971098265895953 \n",
      "Recall: 0.9815078236130867 \n",
      "Aging Rate: 0.492176386913229\n",
      "Precision: 0.9942446043165467 \n",
      "Recall: 0.9829302987197724 \n",
      "Aging Rate: 0.49431009957325744\n",
      "Precision: 0.9985611510791367 \n",
      "Recall: 0.9871977240398293 \n",
      "Aging Rate: 0.49431009957325744\n",
      "\u001b[32m[I 2021-12-05 18:27:15,963]\u001b[0m Trial 5 finished with value: 2.9771556701144157 and parameters: {'meta_learner': 'LogisticRegression', 'C': 1, 'penalty': 'l2'}. Best is trial 4 with value: 2.9805010586202023.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.9928057553956835 \n",
      "Recall: 0.9815078236130867 \n",
      "Aging Rate: 0.49431009957325744\n",
      "Precision: 0.9971181556195965 \n",
      "Recall: 0.984352773826458 \n",
      "Aging Rate: 0.49359886201991465\n",
      "Precision: 0.9886201991465149 \n",
      "Recall: 0.9886201991465149 \n",
      "Aging Rate: 0.5\n",
      "\u001b[32m[I 2021-12-05 18:27:16,129]\u001b[0m Trial 6 finished with value: 2.9705230056365495 and parameters: {'meta_learner': 'LogisticRegression', 'C': 100, 'penalty': 'none'}. Best is trial 4 with value: 2.9805010586202023.\u001b[0m\n",
      "Precision: 0.9913793103448276 \n",
      "Recall: 0.9815078236130867 \n",
      "Aging Rate: 0.4950213371266003\n",
      "Precision: 0.9985590778097982 \n",
      "Recall: 0.9857752489331437 \n",
      "Aging Rate: 0.49359886201991465\n",
      "Precision: 0.9943019943019943 \n",
      "Recall: 0.9928876244665719 \n",
      "Aging Rate: 0.4992887624466572\n",
      "\u001b[32m[I 2021-12-05 18:27:17,832]\u001b[0m Trial 7 finished with value: 2.976217153975348 and parameters: {'meta_learner': 'ExtraTrees', 'n_estimators': 300, 'min_samples_split': 12, 'max_depth': 3}. Best is trial 4 with value: 2.9805010586202023.\u001b[0m\n",
      "Precision: 0.992816091954023 \n",
      "Recall: 0.9829302987197724 \n",
      "Aging Rate: 0.4950213371266003\n",
      "Precision: 0.9914407988587732 \n",
      "Recall: 0.9886201991465149 \n",
      "Aging Rate: 0.49857752489331436\n",
      "Precision: 0.9928876244665719 \n",
      "Recall: 0.9928876244665719 \n",
      "Aging Rate: 0.5\n",
      "\u001b[32m[I 2021-12-05 18:27:18,000]\u001b[0m Trial 8 finished with value: 2.972909050963865 and parameters: {'meta_learner': 'LogisticRegression', 'C': 1, 'penalty': 'none'}. Best is trial 4 with value: 2.9805010586202023.\u001b[0m\n",
      "Precision: 0.9956896551724138 \n",
      "Recall: 0.9857752489331437 \n",
      "Aging Rate: 0.4950213371266003\n",
      "Precision: 0.9957142857142857 \n",
      "Recall: 0.9914651493598862 \n",
      "Aging Rate: 0.49786628733997157\n",
      "Precision: 0.99568345323741 \n",
      "Recall: 0.984352773826458 \n",
      "Aging Rate: 0.49431009957325744\n",
      "\u001b[32m[I 2021-12-05 18:27:19,207]\u001b[0m Trial 9 finished with value: 2.9785893201225693 and parameters: {'meta_learner': 'ExtraTrees', 'n_estimators': 100, 'min_samples_split': 12, 'max_depth': 15}. Best is trial 4 with value: 2.9805010586202023.\u001b[0m\n",
      "Precision: 0.9971014492753624 \n",
      "Recall: 0.9786628733997155 \n",
      "Aging Rate: 0.4907539118065434\n",
      "Precision: 0.9971223021582734 \n",
      "Recall: 0.9857752489331437 \n",
      "Aging Rate: 0.49431009957325744\n",
      "Precision: 0.9928263988522238 \n",
      "Recall: 0.984352773826458 \n",
      "Aging Rate: 0.4957325746799431\n",
      "\u001b[32m[I 2021-12-05 18:27:21,415]\u001b[0m Trial 10 finished with value: 2.9742970655770122 and parameters: {'meta_learner': 'ExtraTrees', 'n_estimators': 500, 'min_samples_split': 27, 'max_depth': 21}. Best is trial 4 with value: 2.9805010586202023.\u001b[0m\n",
      "Precision: 0.9928571428571429 \n",
      "Recall: 0.9886201991465149 \n",
      "Aging Rate: 0.49786628733997157\n",
      "Precision: 0.9928571428571429 \n",
      "Recall: 0.9886201991465149 \n",
      "Aging Rate: 0.49786628733997157\n",
      "Precision: 0.992867332382311 \n",
      "Recall: 0.9900426742532006 \n",
      "Aging Rate: 0.49857752489331436\n",
      "\u001b[32m[I 2021-12-05 18:27:22,681]\u001b[0m Trial 11 finished with value: 2.9748154362464745 and parameters: {'meta_learner': 'ExtraTrees', 'n_estimators': 100, 'min_samples_split': 22, 'max_depth': 18}. Best is trial 4 with value: 2.9805010586202023.\u001b[0m\n",
      "Precision: 0.9985569985569985 \n",
      "Recall: 0.984352773826458 \n",
      "Aging Rate: 0.49288762446657186\n",
      "Precision: 0.997134670487106 \n",
      "Recall: 0.9900426742532006 \n",
      "Aging Rate: 0.49644381223328593\n",
      "Precision: 0.9914040114613181 \n",
      "Recall: 0.984352773826458 \n",
      "Aging Rate: 0.49644381223328593\n",
      "\u001b[32m[I 2021-12-05 18:27:24,897]\u001b[0m Trial 12 finished with value: 2.977646527638987 and parameters: {'meta_learner': 'ExtraTrees', 'n_estimators': 500, 'min_samples_split': 17, 'max_depth': 15}. Best is trial 4 with value: 2.9805010586202023.\u001b[0m\n",
      "Precision: 0.9914163090128756 \n",
      "Recall: 0.9857752489331437 \n",
      "Aging Rate: 0.4971550497866287\n",
      "Precision: 0.9942446043165467 \n",
      "Recall: 0.9829302987197724 \n",
      "Aging Rate: 0.49431009957325744\n",
      "Precision: 0.9971181556195965 \n",
      "Recall: 0.984352773826458 \n",
      "Aging Rate: 0.49359886201991465\n",
      "\u001b[32m[I 2021-12-05 18:27:26,119]\u001b[0m Trial 13 finished with value: 2.9728721531258038 and parameters: {'meta_learner': 'ExtraTrees', 'n_estimators': 100, 'min_samples_split': 12, 'max_depth': 21}. Best is trial 4 with value: 2.9805010586202023.\u001b[0m\n",
      "Precision: 0.9985569985569985 \n",
      "Recall: 0.984352773826458 \n",
      "Aging Rate: 0.49288762446657186\n",
      "Precision: 0.997134670487106 \n",
      "Recall: 0.9900426742532006 \n",
      "Aging Rate: 0.49644381223328593\n",
      "Precision: 0.992867332382311 \n",
      "Recall: 0.9900426742532006 \n",
      "Aging Rate: 0.49857752489331436\n",
      "\u001b[32m[I 2021-12-05 18:27:28,287]\u001b[0m Trial 14 finished with value: 2.9805187083952305 and parameters: {'meta_learner': 'ExtraTrees', 'n_estimators': 500, 'min_samples_split': 12, 'max_depth': 9}. Best is trial 14 with value: 2.9805187083952305.\u001b[0m\n",
      "Precision: 0.9971223021582734 \n",
      "Recall: 0.9857752489331437 \n",
      "Aging Rate: 0.49431009957325744\n",
      "Precision: 0.9872159090909091 \n",
      "Recall: 0.9886201991465149 \n",
      "Aging Rate: 0.5007112375533428\n",
      "Precision: 0.9985569985569985 \n",
      "Recall: 0.984352773826458 \n",
      "Aging Rate: 0.49288762446657186\n",
      "\u001b[32m[I 2021-12-05 18:27:30,485]\u001b[0m Trial 15 finished with value: 2.974846213839493 and parameters: {'meta_learner': 'ExtraTrees', 'n_estimators': 500, 'min_samples_split': 17, 'max_depth': 9}. Best is trial 14 with value: 2.9805187083952305.\u001b[0m\n",
      "Precision: 0.9957081545064378 \n",
      "Recall: 0.9900426742532006 \n",
      "Aging Rate: 0.4971550497866287\n",
      "Precision: 0.994261119081779 \n",
      "Recall: 0.9857752489331437 \n",
      "Aging Rate: 0.4957325746799431\n",
      "Precision: 0.9971139971139971 \n",
      "Recall: 0.9829302987197724 \n",
      "Aging Rate: 0.49288762446657186\n",
      "\u001b[32m[I 2021-12-05 18:27:32,825]\u001b[0m Trial 16 finished with value: 2.977638254436848 and parameters: {'meta_learner': 'ExtraTrees', 'n_estimators': 500, 'min_samples_split': 7, 'max_depth': 9}. Best is trial 14 with value: 2.9805187083952305.\u001b[0m\n",
      "Precision: 0.9928057553956835 \n",
      "Recall: 0.9815078236130867 \n",
      "Aging Rate: 0.49431009957325744\n",
      "Precision: 0.9956896551724138 \n",
      "Recall: 0.9857752489331437 \n",
      "Aging Rate: 0.4950213371266003\n",
      "Precision: 0.9943019943019943 \n",
      "Recall: 0.9928876244665719 \n",
      "Aging Rate: 0.4992887624466572\n",
      "\u001b[32m[I 2021-12-05 18:27:35,029]\u001b[0m Trial 17 finished with value: 2.9752551689176614 and parameters: {'meta_learner': 'ExtraTrees', 'n_estimators': 500, 'min_samples_split': 32, 'max_depth': 9}. Best is trial 14 with value: 2.9805187083952305.\u001b[0m\n",
      "Precision: 0.9899569583931134 \n",
      "Recall: 0.9815078236130867 \n",
      "Aging Rate: 0.4957325746799431\n",
      "Precision: 0.9942528735632183 \n",
      "Recall: 0.984352773826458 \n",
      "Aging Rate: 0.4950213371266003\n",
      "Precision: 0.9971098265895953 \n",
      "Recall: 0.9815078236130867 \n",
      "Aging Rate: 0.492176386913229\n",
      "\u001b[32m[I 2021-12-05 18:27:35,185]\u001b[0m Trial 18 finished with value: 2.9700025793814953 and parameters: {'meta_learner': 'LogisticRegression', 'C': 10, 'penalty': 'l2'}. Best is trial 14 with value: 2.9805187083952305.\u001b[0m\n",
      "Precision: 0.9928977272727273 \n",
      "Recall: 0.9943100995732574 \n",
      "Aging Rate: 0.5007112375533428\n",
      "Precision: 0.997134670487106 \n",
      "Recall: 0.9900426742532006 \n",
      "Aging Rate: 0.49644381223328593\n",
      "Precision: 0.9914529914529915 \n",
      "Recall: 0.9900426742532006 \n",
      "Aging Rate: 0.4992887624466572\n",
      "\u001b[32m[I 2021-12-05 18:27:37,415]\u001b[0m Trial 19 finished with value: 2.979122075501769 and parameters: {'meta_learner': 'ExtraTrees', 'n_estimators': 500, 'min_samples_split': 22, 'max_depth': 6}. Best is trial 14 with value: 2.9805187083952305.\u001b[0m\n",
      "Precision: 0.99568345323741 \n",
      "Recall: 0.984352773826458 \n",
      "Aging Rate: 0.49431009957325744\n",
      "Precision: 0.9985611510791367 \n",
      "Recall: 0.9871977240398293 \n",
      "Aging Rate: 0.49431009957325744\n",
      "Precision: 0.9971509971509972 \n",
      "Recall: 0.9957325746799431 \n",
      "Aging Rate: 0.4992887624466572\n",
      "\u001b[32m[I 2021-12-05 18:27:39,105]\u001b[0m Trial 20 finished with value: 2.9833580918271063 and parameters: {'meta_learner': 'ExtraTrees', 'n_estimators': 300, 'min_samples_split': 7, 'max_depth': 15}. Best is trial 20 with value: 2.9833580918271063.\u001b[0m\n",
      "Precision: 0.9985611510791367 \n",
      "Recall: 0.9871977240398293 \n",
      "Aging Rate: 0.49431009957325744\n",
      "Precision: 1.0 \n",
      "Recall: 0.9871977240398293 \n",
      "Aging Rate: 0.49359886201991465\n",
      "Precision: 0.9943100995732574 \n",
      "Recall: 0.9943100995732574 \n",
      "Aging Rate: 0.5\n",
      "\u001b[32m[I 2021-12-05 18:27:40,823]\u001b[0m Trial 21 finished with value: 2.9848160163192348 and parameters: {'meta_learner': 'ExtraTrees', 'n_estimators': 300, 'min_samples_split': 7, 'max_depth': 15}. Best is trial 21 with value: 2.9848160163192348.\u001b[0m\n",
      "Precision: 0.9971098265895953 \n",
      "Recall: 0.9815078236130867 \n",
      "Aging Rate: 0.492176386913229\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.994261119081779 \n",
      "Recall: 0.9857752489331437 \n",
      "Aging Rate: 0.4957325746799431\n",
      "Precision: 0.9985611510791367 \n",
      "Recall: 0.9871977240398293 \n",
      "Aging Rate: 0.49431009957325744\n",
      "\u001b[32m[I 2021-12-05 18:27:42,601]\u001b[0m Trial 22 finished with value: 2.978114996695694 and parameters: {'meta_learner': 'ExtraTrees', 'n_estimators': 300, 'min_samples_split': 7, 'max_depth': 15}. Best is trial 21 with value: 2.9848160163192348.\u001b[0m\n",
      "Precision: 0.9914772727272727 \n",
      "Recall: 0.9928876244665719 \n",
      "Aging Rate: 0.5007112375533428\n",
      "Precision: 0.9985693848354793 \n",
      "Recall: 0.9928876244665719 \n",
      "Aging Rate: 0.4971550497866287\n",
      "Precision: 0.9957142857142857 \n",
      "Recall: 0.9914651493598862 \n",
      "Aging Rate: 0.49786628733997157\n",
      "\u001b[32m[I 2021-12-05 18:27:44,327]\u001b[0m Trial 23 finished with value: 2.9829207616157016 and parameters: {'meta_learner': 'ExtraTrees', 'n_estimators': 300, 'min_samples_split': 2, 'max_depth': 12}. Best is trial 21 with value: 2.9848160163192348.\u001b[0m\n",
      "Precision: 0.9928571428571429 \n",
      "Recall: 0.9886201991465149 \n",
      "Aging Rate: 0.49786628733997157\n",
      "Precision: 0.9985611510791367 \n",
      "Recall: 0.9871977240398293 \n",
      "Aging Rate: 0.49431009957325744\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "``multivariate`` option is an experimental feature. The interface can change in the future.\n",
      "\u001b[32m[I 2021-12-05 18:27:46,147]\u001b[0m A new study created in memory with name: no-name-11f5407e-34bf-40f3-8622-f2393bdaed7b\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.9985590778097982 \n",
      "Recall: 0.9857752489331437 \n",
      "Aging Rate: 0.49359886201991465\n",
      "\u001b[32m[I 2021-12-05 18:27:46,042]\u001b[0m Trial 24 finished with value: 2.9805159718705476 and parameters: {'meta_learner': 'ExtraTrees', 'n_estimators': 300, 'min_samples_split': 2, 'max_depth': 12}. Best is trial 21 with value: 2.9848160163192348.\u001b[0m\n",
      "Sampler is TPESampler\n",
      "Dataset5 :\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress bar is experimental (supported from v1.2.0). The interface can change in the future.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6bdb4f7311da4199ba6f141aaee94ccf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.9927745664739884 \n",
      "Recall: 0.9870689655172413 \n",
      "Aging Rate: 0.49463902787705505\n",
      "Precision: 0.9942028985507246 \n",
      "Recall: 0.985632183908046 \n",
      "Aging Rate: 0.49320943531093636\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.9942196531791907 \n",
      "Recall: 0.9885057471264368 \n",
      "Aging Rate: 0.49463902787705505\n",
      "\u001b[32m[I 2021-12-05 18:27:46,234]\u001b[0m Trial 0 finished with value: 2.97453371098651 and parameters: {'meta_learner': 'LogisticRegression', 'C': 0.01, 'penalty': 'none'}. Best is trial 0 with value: 2.97453371098651.\u001b[0m\n",
      "Precision: 0.9914285714285714 \n",
      "Recall: 0.9971264367816092 \n",
      "Aging Rate: 0.5003573981415297\n",
      "Precision: 0.9899425287356322 \n",
      "Recall: 0.9899425287356322 \n",
      "Aging Rate: 0.49749821300929237\n",
      "Precision: 0.9956584659913169 \n",
      "Recall: 0.9885057471264368 \n",
      "Aging Rate: 0.49392423159399573\n",
      "\u001b[32m[I 2021-12-05 18:27:46,397]\u001b[0m Trial 1 finished with value: 2.976544614984906 and parameters: {'meta_learner': 'LogisticRegression', 'C': 10, 'penalty': 'l2'}. Best is trial 1 with value: 2.976544614984906.\u001b[0m\n",
      "Precision: 0.9928469241773963 \n",
      "Recall: 0.9971264367816092 \n",
      "Aging Rate: 0.4996426018584703\n",
      "Precision: 0.9942196531791907 \n",
      "Recall: 0.9885057471264368 \n",
      "Aging Rate: 0.49463902787705505\n",
      "Precision: 0.9971056439942113 \n",
      "Recall: 0.9899425287356322 \n",
      "Aging Rate: 0.49392423159399573\n",
      "\u001b[32m[I 2021-12-05 18:27:46,560]\u001b[0m Trial 2 finished with value: 2.9813063851150914 and parameters: {'meta_learner': 'LogisticRegression', 'C': 1, 'penalty': 'l2'}. Best is trial 2 with value: 2.9813063851150914.\u001b[0m\n",
      "Precision: 0.9913669064748202 \n",
      "Recall: 0.9899425287356322 \n",
      "Aging Rate: 0.496783416726233\n",
      "Precision: 0.9899280575539569 \n",
      "Recall: 0.9885057471264368 \n",
      "Aging Rate: 0.496783416726233\n",
      "Precision: 0.9857752489331437 \n",
      "Recall: 0.9956896551724138 \n",
      "Aging Rate: 0.5025017869907077\n",
      "\u001b[32m[I 2021-12-05 18:27:46,722]\u001b[0m Trial 3 finished with value: 2.969426118986108 and parameters: {'meta_learner': 'LogisticRegression', 'C': 0.1, 'penalty': 'l2'}. Best is trial 2 with value: 2.9813063851150914.\u001b[0m\n",
      "Precision: 0.9985528219971056 \n",
      "Recall: 0.9913793103448276 \n",
      "Aging Rate: 0.49392423159399573\n",
      "Precision: 0.9956584659913169 \n",
      "Recall: 0.9885057471264368 \n",
      "Aging Rate: 0.49392423159399573\n",
      "Precision: 0.9914163090128756 \n",
      "Recall: 0.9956896551724138 \n",
      "Aging Rate: 0.4996426018584703\n",
      "\u001b[32m[I 2021-12-05 18:27:46,866]\u001b[0m Trial 4 finished with value: 2.9822766355487578 and parameters: {'meta_learner': 'LogisticRegression', 'C': 0.1, 'penalty': 'l2'}. Best is trial 4 with value: 2.9822766355487578.\u001b[0m\n",
      "Precision: 0.9956521739130435 \n",
      "Recall: 0.9870689655172413 \n",
      "Aging Rate: 0.49320943531093636\n",
      "Precision: 0.9942446043165467 \n",
      "Recall: 0.992816091954023 \n",
      "Aging Rate: 0.496783416726233\n",
      "Precision: 0.9956772334293948 \n",
      "Recall: 0.992816091954023 \n",
      "Aging Rate: 0.4960686204431737\n",
      "\u001b[32m[I 2021-12-05 18:27:47,032]\u001b[0m Trial 5 finished with value: 2.9812830575810856 and parameters: {'meta_learner': 'LogisticRegression', 'C': 100, 'penalty': 'l2'}. Best is trial 4 with value: 2.9822766355487578.\u001b[0m\n",
      "Precision: 0.9971223021582734 \n",
      "Recall: 0.9956896551724138 \n",
      "Aging Rate: 0.496783416726233\n",
      "Precision: 0.9942028985507246 \n",
      "Recall: 0.985632183908046 \n",
      "Aging Rate: 0.49320943531093636\n",
      "Precision: 0.9971139971139971 \n",
      "Recall: 0.992816091954023 \n",
      "Aging Rate: 0.49535382416011436\n",
      "\u001b[32m[I 2021-12-05 18:27:48,700]\u001b[0m Trial 6 finished with value: 2.9836721088934905 and parameters: {'meta_learner': 'ExtraTrees', 'n_estimators': 300, 'min_samples_split': 2, 'max_depth': 3}. Best is trial 6 with value: 2.9836721088934905.\u001b[0m\n",
      "Precision: 0.9985549132947977 \n",
      "Recall: 0.992816091954023 \n",
      "Aging Rate: 0.49463902787705505\n",
      "Precision: 0.9971098265895953 \n",
      "Recall: 0.9913793103448276 \n",
      "Aging Rate: 0.49463902787705505\n",
      "Precision: 0.9956958393113343 \n",
      "Recall: 0.9971264367816092 \n",
      "Aging Rate: 0.4982130092923517\n",
      "\u001b[32m[I 2021-12-05 18:27:49,905]\u001b[0m Trial 7 finished with value: 2.988014332490638 and parameters: {'meta_learner': 'ExtraTrees', 'n_estimators': 100, 'min_samples_split': 27, 'max_depth': 15}. Best is trial 7 with value: 2.988014332490638.\u001b[0m\n",
      "Precision: 0.9985422740524781 \n",
      "Recall: 0.9841954022988506 \n",
      "Aging Rate: 0.49035025017869904\n",
      "Precision: 0.9971056439942113 \n",
      "Recall: 0.9899425287356322 \n",
      "Aging Rate: 0.49392423159399573\n",
      "Precision: 1.0 \n",
      "Recall: 0.992816091954023 \n",
      "Aging Rate: 0.49392423159399573\n",
      "\u001b[32m[I 2021-12-05 18:27:51,608]\u001b[0m Trial 8 finished with value: 2.9860832863606284 and parameters: {'meta_learner': 'ExtraTrees', 'n_estimators': 300, 'min_samples_split': 17, 'max_depth': 12}. Best is trial 7 with value: 2.988014332490638.\u001b[0m\n",
      "Precision: 0.9985507246376811 \n",
      "Recall: 0.9899425287356322 \n",
      "Aging Rate: 0.49320943531093636\n",
      "Precision: 0.9971098265895953 \n",
      "Recall: 0.9913793103448276 \n",
      "Aging Rate: 0.49463902787705505\n",
      "Precision: 1.0 \n",
      "Recall: 0.9841954022988506 \n",
      "Aging Rate: 0.4896354538956397\n",
      "\u001b[32m[I 2021-12-05 18:27:53,816]\u001b[0m Trial 9 finished with value: 2.985612781277954 and parameters: {'meta_learner': 'ExtraTrees', 'n_estimators': 500, 'min_samples_split': 17, 'max_depth': 18}. Best is trial 7 with value: 2.988014332490638.\u001b[0m\n",
      "Precision: 0.9985507246376811 \n",
      "Recall: 0.9899425287356322 \n",
      "Aging Rate: 0.49320943531093636\n",
      "Precision: 0.99568345323741 \n",
      "Recall: 0.9942528735632183 \n",
      "Aging Rate: 0.496783416726233\n",
      "Precision: 0.9985590778097982 \n",
      "Recall: 0.9956896551724138 \n",
      "Aging Rate: 0.4960686204431737\n",
      "\u001b[32m[I 2021-12-05 18:27:55,026]\u001b[0m Trial 10 finished with value: 2.9884905229470142 and parameters: {'meta_learner': 'ExtraTrees', 'n_estimators': 100, 'min_samples_split': 32, 'max_depth': 21}. Best is trial 10 with value: 2.9884905229470142.\u001b[0m\n",
      "Precision: 0.99568345323741 \n",
      "Recall: 0.9942528735632183 \n",
      "Aging Rate: 0.496783416726233\n",
      "Precision: 0.9985443959243085 \n",
      "Recall: 0.985632183908046 \n",
      "Aging Rate: 0.4910650464617584\n",
      "Precision: 0.9971014492753624 \n",
      "Recall: 0.9885057471264368 \n",
      "Aging Rate: 0.49320943531093636\n",
      "\u001b[32m[I 2021-12-05 18:27:56,218]\u001b[0m Trial 11 finished with value: 2.9836831338239542 and parameters: {'meta_learner': 'ExtraTrees', 'n_estimators': 100, 'min_samples_split': 32, 'max_depth': 21}. Best is trial 10 with value: 2.9884905229470142.\u001b[0m\n",
      "Precision: 0.9985443959243085 \n",
      "Recall: 0.985632183908046 \n",
      "Aging Rate: 0.4910650464617584\n",
      "Precision: 0.9971139971139971 \n",
      "Recall: 0.992816091954023 \n",
      "Aging Rate: 0.49535382416011436\n",
      "Precision: 0.9985486211901307 \n",
      "Recall: 0.9885057471264368 \n",
      "Aging Rate: 0.49249463902787705\n",
      "\u001b[32m[I 2021-12-05 18:27:57,421]\u001b[0m Trial 12 finished with value: 2.9851226838151264 and parameters: {'meta_learner': 'ExtraTrees', 'n_estimators': 100, 'min_samples_split': 32, 'max_depth': 15}. Best is trial 10 with value: 2.9884905229470142.\u001b[0m\n",
      "Precision: 0.9971181556195965 \n",
      "Recall: 0.9942528735632183 \n",
      "Aging Rate: 0.4960686204431737\n",
      "Precision: 0.9970887918486172 \n",
      "Recall: 0.9841954022988506 \n",
      "Aging Rate: 0.4910650464617584\n",
      "Precision: 0.9985590778097982 \n",
      "Recall: 0.9956896551724138 \n",
      "Aging Rate: 0.4960686204431737\n",
      "\u001b[32m[I 2021-12-05 18:27:58,624]\u001b[0m Trial 13 finished with value: 2.986556660530169 and parameters: {'meta_learner': 'ExtraTrees', 'n_estimators': 100, 'min_samples_split': 27, 'max_depth': 6}. Best is trial 10 with value: 2.9884905229470142.\u001b[0m\n",
      "Precision: 0.9985569985569985 \n",
      "Recall: 0.9942528735632183 \n",
      "Aging Rate: 0.49535382416011436\n",
      "Precision: 0.9971014492753624 \n",
      "Recall: 0.9885057471264368 \n",
      "Aging Rate: 0.49320943531093636\n",
      "Precision: 1.0 \n",
      "Recall: 0.9885057471264368 \n",
      "Aging Rate: 0.49177984274481773\n",
      "\u001b[32m[I 2021-12-05 18:27:59,812]\u001b[0m Trial 14 finished with value: 2.987527087826938 and parameters: {'meta_learner': 'ExtraTrees', 'n_estimators': 100, 'min_samples_split': 27, 'max_depth': 21}. Best is trial 10 with value: 2.9884905229470142.\u001b[0m\n",
      "Precision: 0.9971014492753624 \n",
      "Recall: 0.9885057471264368 \n",
      "Aging Rate: 0.49320943531093636\n",
      "Precision: 1.0 \n",
      "Recall: 0.9942528735632183 \n",
      "Aging Rate: 0.49463902787705505\n",
      "Precision: 0.9985486211901307 \n",
      "Recall: 0.9885057471264368 \n",
      "Aging Rate: 0.49249463902787705\n",
      "\u001b[32m[I 2021-12-05 18:28:01,532]\u001b[0m Trial 15 finished with value: 2.9875215029156927 and parameters: {'meta_learner': 'ExtraTrees', 'n_estimators': 300, 'min_samples_split': 27, 'max_depth': 15}. Best is trial 10 with value: 2.9884905229470142.\u001b[0m\n",
      "Precision: 0.9985549132947977 \n",
      "Recall: 0.992816091954023 \n",
      "Aging Rate: 0.49463902787705505\n",
      "Precision: 0.9956521739130435 \n",
      "Recall: 0.9870689655172413 \n",
      "Aging Rate: 0.49320943531093636\n",
      "Precision: 0.9985590778097982 \n",
      "Recall: 0.9956896551724138 \n",
      "Aging Rate: 0.4960686204431737\n",
      "\u001b[32m[I 2021-12-05 18:28:02,819]\u001b[0m Trial 16 finished with value: 2.9870356808929857 and parameters: {'meta_learner': 'ExtraTrees', 'n_estimators': 100, 'min_samples_split': 22, 'max_depth': 9}. Best is trial 10 with value: 2.9884905229470142.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 1.0 \n",
      "Recall: 0.985632183908046 \n",
      "Aging Rate: 0.49035025017869904\n",
      "Precision: 0.9971056439942113 \n",
      "Recall: 0.9899425287356322 \n",
      "Aging Rate: 0.49392423159399573\n",
      "Precision: 0.9956709956709957 \n",
      "Recall: 0.9913793103448276 \n",
      "Aging Rate: 0.49535382416011436\n",
      "\u001b[32m[I 2021-12-05 18:28:05,055]\u001b[0m Trial 17 finished with value: 2.9841691007729736 and parameters: {'meta_learner': 'ExtraTrees', 'n_estimators': 500, 'min_samples_split': 7, 'max_depth': 18}. Best is trial 10 with value: 2.9884905229470142.\u001b[0m\n",
      "Precision: 0.9971264367816092 \n",
      "Recall: 0.9971264367816092 \n",
      "Aging Rate: 0.49749821300929237\n",
      "Precision: 1.0 \n",
      "Recall: 0.9942528735632183 \n",
      "Aging Rate: 0.49463902787705505\n",
      "Precision: 0.9985590778097982 \n",
      "Recall: 0.9956896551724138 \n",
      "Aging Rate: 0.4960686204431737\n",
      "\u001b[32m[I 2021-12-05 18:28:06,258]\u001b[0m Trial 18 finished with value: 2.9928133315666856 and parameters: {'meta_learner': 'ExtraTrees', 'n_estimators': 100, 'min_samples_split': 32, 'max_depth': 18}. Best is trial 18 with value: 2.9928133315666856.\u001b[0m\n",
      "Precision: 0.9985507246376811 \n",
      "Recall: 0.9899425287356322 \n",
      "Aging Rate: 0.49320943531093636\n",
      "Precision: 0.9970972423802612 \n",
      "Recall: 0.9870689655172413 \n",
      "Aging Rate: 0.49249463902787705\n",
      "Precision: 1.0 \n",
      "Recall: 0.9870689655172413 \n",
      "Aging Rate: 0.4910650464617584\n",
      "\u001b[32m[I 2021-12-05 18:28:07,937]\u001b[0m Trial 19 finished with value: 2.9851254646019996 and parameters: {'meta_learner': 'ExtraTrees', 'n_estimators': 300, 'min_samples_split': 32, 'max_depth': 21}. Best is trial 18 with value: 2.9928133315666856.\u001b[0m\n",
      "Precision: 0.9970887918486172 \n",
      "Recall: 0.9841954022988506 \n",
      "Aging Rate: 0.4910650464617584\n",
      "Precision: 1.0 \n",
      "Recall: 0.9956896551724138 \n",
      "Aging Rate: 0.49535382416011436\n",
      "Precision: 1.0 \n",
      "Recall: 0.9841954022988506 \n",
      "Aging Rate: 0.4896354538956397\n",
      "\u001b[32m[I 2021-12-05 18:28:09,158]\u001b[0m Trial 20 finished with value: 2.9860860144891164 and parameters: {'meta_learner': 'ExtraTrees', 'n_estimators': 100, 'min_samples_split': 12, 'max_depth': 18}. Best is trial 18 with value: 2.9928133315666856.\u001b[0m\n",
      "Precision: 0.9985486211901307 \n",
      "Recall: 0.9885057471264368 \n",
      "Aging Rate: 0.49249463902787705\n",
      "Precision: 0.9942363112391931 \n",
      "Recall: 0.9913793103448276 \n",
      "Aging Rate: 0.4960686204431737\n",
      "Precision: 0.9942196531791907 \n",
      "Recall: 0.9885057471264368 \n",
      "Aging Rate: 0.49463902787705505\n",
      "\u001b[32m[I 2021-12-05 18:28:10,382]\u001b[0m Trial 21 finished with value: 2.9807999919382433 and parameters: {'meta_learner': 'ExtraTrees', 'n_estimators': 100, 'min_samples_split': 32, 'max_depth': 15}. Best is trial 18 with value: 2.9928133315666856.\u001b[0m\n",
      "Precision: 0.9985569985569985 \n",
      "Recall: 0.9942528735632183 \n",
      "Aging Rate: 0.49535382416011436\n",
      "Precision: 0.9985590778097982 \n",
      "Recall: 0.9956896551724138 \n",
      "Aging Rate: 0.4960686204431737\n",
      "Precision: 0.998546511627907 \n",
      "Recall: 0.9870689655172413 \n",
      "Aging Rate: 0.49177984274481773\n",
      "\u001b[32m[I 2021-12-05 18:28:11,611]\u001b[0m Trial 22 finished with value: 2.9894455567474267 and parameters: {'meta_learner': 'ExtraTrees', 'n_estimators': 100, 'min_samples_split': 22, 'max_depth': 18}. Best is trial 18 with value: 2.9928133315666856.\u001b[0m\n",
      "Precision: 1.0 \n",
      "Recall: 0.9885057471264368 \n",
      "Aging Rate: 0.49177984274481773\n",
      "Precision: 0.9985549132947977 \n",
      "Recall: 0.992816091954023 \n",
      "Aging Rate: 0.49463902787705505\n",
      "Precision: 0.9985528219971056 \n",
      "Recall: 0.9913793103448276 \n",
      "Aging Rate: 0.49392423159399573\n",
      "\u001b[32m[I 2021-12-05 18:28:12,811]\u001b[0m Trial 23 finished with value: 2.988972206669698 and parameters: {'meta_learner': 'ExtraTrees', 'n_estimators': 100, 'min_samples_split': 22, 'max_depth': 21}. Best is trial 18 with value: 2.9928133315666856.\u001b[0m\n",
      "Precision: 1.0 \n",
      "Recall: 0.992816091954023 \n",
      "Aging Rate: 0.49392423159399573\n",
      "Precision: 0.9942528735632183 \n",
      "Recall: 0.9942528735632183 \n",
      "Aging Rate: 0.49749821300929237\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "``multivariate`` option is an experimental feature. The interface can change in the future.\n",
      "\u001b[32m[I 2021-12-05 18:28:14,140]\u001b[0m A new study created in memory with name: no-name-4a68318e-c1f2-4ecb-abf1-bcbf55ccb88e\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.9928571428571429 \n",
      "Recall: 0.9985632183908046 \n",
      "Aging Rate: 0.5003573981415297\n",
      "\u001b[32m[I 2021-12-05 18:28:14,028]\u001b[0m Trial 24 finished with value: 2.9866174055829227 and parameters: {'meta_learner': 'ExtraTrees', 'n_estimators': 100, 'min_samples_split': 22, 'max_depth': 18}. Best is trial 18 with value: 2.9928133315666856.\u001b[0m\n",
      "Sampler is TPESampler\n",
      "Dataset6 :\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress bar is experimental (supported from v1.2.0). The interface can change in the future.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb7029a6c5b049e086b4fe7136a77760",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.9860788863109049 \n",
      "Recall: 0.9918319719953326 \n",
      "Aging Rate: 0.5525641025641026\n",
      "Precision: 0.9952941176470588 \n",
      "Recall: 0.9871645274212368 \n",
      "Aging Rate: 0.5448717948717948\n",
      "Precision: 0.9941520467836257 \n",
      "Recall: 0.9918319719953326 \n",
      "Aging Rate: 0.5480769230769231\n",
      "\u001b[32m[I 2021-12-05 18:28:15,772]\u001b[0m Trial 0 finished with value: 2.9739595242983605 and parameters: {'meta_learner': 'ExtraTrees', 'n_estimators': 300, 'min_samples_split': 22, 'max_depth': 21}. Best is trial 0 with value: 2.9739595242983605.\u001b[0m\n",
      "Precision: 0.9860950173812283 \n",
      "Recall: 0.9929988331388565 \n",
      "Aging Rate: 0.5532051282051282\n",
      "Precision: 0.989522700814901 \n",
      "Recall: 0.9918319719953326 \n",
      "Aging Rate: 0.5506410256410257\n",
      "Precision: 0.9918319719953326 \n",
      "Recall: 0.9918319719953326 \n",
      "Aging Rate: 0.5493589743589744\n",
      "\u001b[32m[I 2021-12-05 18:28:17,475]\u001b[0m Trial 1 finished with value: 2.9705207191708154 and parameters: {'meta_learner': 'ExtraTrees', 'n_estimators': 300, 'min_samples_split': 2, 'max_depth': 18}. Best is trial 0 with value: 2.9739595242983605.\u001b[0m\n",
      "Precision: 0.9883449883449883 \n",
      "Recall: 0.9894982497082847 \n",
      "Aging Rate: 0.55\n",
      "Precision: 0.9895104895104895 \n",
      "Recall: 0.9906651108518086 \n",
      "Aging Rate: 0.55\n",
      "Precision: 0.991812865497076 \n",
      "Recall: 0.9894982497082847 \n",
      "Aging Rate: 0.5480769230769231\n",
      "\u001b[32m[I 2021-12-05 18:28:17,636]\u001b[0m Trial 2 finished with value: 2.969666098991162 and parameters: {'meta_learner': 'LogisticRegression', 'C': 0.01, 'penalty': 'l2'}. Best is trial 0 with value: 2.9739595242983605.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.9894982497082847 \n",
      "Recall: 0.9894982497082847 \n",
      "Aging Rate: 0.5493589743589744\n",
      "Precision: 0.9860950173812283 \n",
      "Recall: 0.9929988331388565 \n",
      "Aging Rate: 0.5532051282051282\n",
      "Precision: 0.9860627177700348 \n",
      "Recall: 0.9906651108518086 \n",
      "Aging Rate: 0.551923076923077\n",
      "\u001b[32m[I 2021-12-05 18:28:17,792]\u001b[0m Trial 3 finished with value: 2.965491387806015 and parameters: {'meta_learner': 'LogisticRegression', 'C': 0.01, 'penalty': 'none'}. Best is trial 0 with value: 2.9739595242983605.\u001b[0m\n",
      "Precision: 0.9918319719953326 \n",
      "Recall: 0.9918319719953326 \n",
      "Aging Rate: 0.5493589743589744\n",
      "Precision: 0.9883040935672515 \n",
      "Recall: 0.9859976662777129 \n",
      "Aging Rate: 0.5480769230769231\n",
      "Precision: 0.9849710982658959 \n",
      "Recall: 0.9941656942823804 \n",
      "Aging Rate: 0.5544871794871795\n",
      "\u001b[32m[I 2021-12-05 18:28:17,958]\u001b[0m Trial 4 finished with value: 2.967403220070795 and parameters: {'meta_learner': 'LogisticRegression', 'C': 100, 'penalty': 'l2'}. Best is trial 0 with value: 2.9739595242983605.\u001b[0m\n",
      "Precision: 0.9860950173812283 \n",
      "Recall: 0.9929988331388565 \n",
      "Aging Rate: 0.5532051282051282\n",
      "Precision: 0.9906103286384976 \n",
      "Recall: 0.9848308051341891 \n",
      "Aging Rate: 0.5461538461538461\n",
      "Precision: 0.9929824561403509 \n",
      "Recall: 0.9906651108518086 \n",
      "Aging Rate: 0.5480769230769231\n",
      "\u001b[32m[I 2021-12-05 18:28:20,151]\u001b[0m Trial 5 finished with value: 2.9692901178150026 and parameters: {'meta_learner': 'ExtraTrees', 'n_estimators': 500, 'min_samples_split': 32, 'max_depth': 18}. Best is trial 0 with value: 2.9739595242983605.\u001b[0m\n",
      "Precision: 0.9883177570093458 \n",
      "Recall: 0.9871645274212368 \n",
      "Aging Rate: 0.5487179487179488\n",
      "Precision: 0.9895348837209302 \n",
      "Recall: 0.9929988331388565 \n",
      "Aging Rate: 0.5512820512820513\n",
      "Precision: 0.9941520467836257 \n",
      "Recall: 0.9918319719953326 \n",
      "Aging Rate: 0.5480769230769231\n",
      "\u001b[32m[I 2021-12-05 18:28:21,358]\u001b[0m Trial 6 finished with value: 2.97200156919441 and parameters: {'meta_learner': 'ExtraTrees', 'n_estimators': 100, 'min_samples_split': 2, 'max_depth': 6}. Best is trial 0 with value: 2.9739595242983605.\u001b[0m\n",
      "Precision: 0.9906542056074766 \n",
      "Recall: 0.9894982497082847 \n",
      "Aging Rate: 0.5487179487179488\n",
      "Precision: 0.9907084785133565 \n",
      "Recall: 0.9953325554259043 \n",
      "Aging Rate: 0.551923076923077\n",
      "Precision: 0.9906542056074766 \n",
      "Recall: 0.9894982497082847 \n",
      "Aging Rate: 0.5487179487179488\n",
      "\u001b[32m[I 2021-12-05 18:28:21,527]\u001b[0m Trial 7 finished with value: 2.9727876114330307 and parameters: {'meta_learner': 'LogisticRegression', 'C': 1, 'penalty': 'l2'}. Best is trial 0 with value: 2.9739595242983605.\u001b[0m\n",
      "Precision: 0.9871794871794872 \n",
      "Recall: 0.9883313885647608 \n",
      "Aging Rate: 0.55\n",
      "Precision: 0.9849710982658959 \n",
      "Recall: 0.9941656942823804 \n",
      "Aging Rate: 0.5544871794871795\n",
      "Precision: 0.9838150289017341 \n",
      "Recall: 0.9929988331388565 \n",
      "Aging Rate: 0.5544871794871795\n",
      "\u001b[32m[I 2021-12-05 18:28:21,670]\u001b[0m Trial 8 finished with value: 2.96247571489341 and parameters: {'meta_learner': 'LogisticRegression', 'C': 0.01, 'penalty': 'l2'}. Best is trial 0 with value: 2.9739595242983605.\u001b[0m\n",
      "Precision: 0.9883855981416957 \n",
      "Recall: 0.9929988331388565 \n",
      "Aging Rate: 0.551923076923077\n",
      "Precision: 0.9895348837209302 \n",
      "Recall: 0.9929988331388565 \n",
      "Aging Rate: 0.5512820512820513\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.9918319719953326 \n",
      "Recall: 0.9918319719953326 \n",
      "Aging Rate: 0.5493589743589744\n",
      "\u001b[32m[I 2021-12-05 18:28:21,828]\u001b[0m Trial 9 finished with value: 2.972444848662987 and parameters: {'meta_learner': 'LogisticRegression', 'C': 10, 'penalty': 'none'}. Best is trial 0 with value: 2.9739595242983605.\u001b[0m\n",
      "Precision: 0.9918032786885246 \n",
      "Recall: 0.9883313885647608 \n",
      "Aging Rate: 0.5474358974358975\n",
      "Precision: 0.9838150289017341 \n",
      "Recall: 0.9929988331388565 \n",
      "Aging Rate: 0.5544871794871795\n",
      "Precision: 0.9895591647331786 \n",
      "Recall: 0.9953325554259043 \n",
      "Aging Rate: 0.5525641025641026\n",
      "\u001b[32m[I 2021-12-05 18:28:23,522]\u001b[0m Trial 10 finished with value: 2.969005907258799 and parameters: {'meta_learner': 'ExtraTrees', 'n_estimators': 300, 'min_samples_split': 22, 'max_depth': 21}. Best is trial 0 with value: 2.9739595242983605.\u001b[0m\n",
      "Precision: 0.991812865497076 \n",
      "Recall: 0.9894982497082847 \n",
      "Aging Rate: 0.5480769230769231\n",
      "Precision: 0.9872389791183295 \n",
      "Recall: 0.9929988331388565 \n",
      "Aging Rate: 0.5525641025641026\n",
      "Precision: 0.9860788863109049 \n",
      "Recall: 0.9918319719953326 \n",
      "Aging Rate: 0.5525641025641026\n",
      "\u001b[32m[I 2021-12-05 18:28:25,661]\u001b[0m Trial 11 finished with value: 2.968196838898365 and parameters: {'meta_learner': 'ExtraTrees', 'n_estimators': 500, 'min_samples_split': 17, 'max_depth': 9}. Best is trial 0 with value: 2.9739595242983605.\u001b[0m\n",
      "Precision: 0.9941520467836257 \n",
      "Recall: 0.9918319719953326 \n",
      "Aging Rate: 0.5480769230769231\n",
      "Precision: 0.9906759906759907 \n",
      "Recall: 0.9918319719953326 \n",
      "Aging Rate: 0.55\n",
      "Precision: 0.9918509895227008 \n",
      "Recall: 0.9941656942823804 \n",
      "Aging Rate: 0.5506410256410257\n",
      "\u001b[32m[I 2021-12-05 18:28:25,837]\u001b[0m Trial 12 finished with value: 2.977062564079226 and parameters: {'meta_learner': 'LogisticRegression', 'C': 1, 'penalty': 'l2'}. Best is trial 12 with value: 2.977062564079226.\u001b[0m\n",
      "Precision: 0.9929906542056075 \n",
      "Recall: 0.9918319719953326 \n",
      "Aging Rate: 0.5487179487179488\n",
      "Precision: 0.9826789838337182 \n",
      "Recall: 0.9929988331388565 \n",
      "Aging Rate: 0.5551282051282052\n",
      "Precision: 0.9929245283018868 \n",
      "Recall: 0.9824970828471412 \n",
      "Aging Rate: 0.5435897435897435\n",
      "\u001b[32m[I 2021-12-05 18:28:27,088]\u001b[0m Trial 13 finished with value: 2.968172073554585 and parameters: {'meta_learner': 'ExtraTrees', 'n_estimators': 100, 'min_samples_split': 32, 'max_depth': 15}. Best is trial 12 with value: 2.977062564079226.\u001b[0m\n",
      "Precision: 0.9883177570093458 \n",
      "Recall: 0.9871645274212368 \n",
      "Aging Rate: 0.5487179487179488\n",
      "Precision: 0.9872093023255814 \n",
      "Recall: 0.9906651108518086 \n",
      "Aging Rate: 0.5512820512820513\n",
      "Precision: 0.986046511627907 \n",
      "Recall: 0.9894982497082847 \n",
      "Aging Rate: 0.5512820512820513\n",
      "\u001b[32m[I 2021-12-05 18:28:27,296]\u001b[0m Trial 14 finished with value: 2.963491676635666 and parameters: {'meta_learner': 'LogisticRegression', 'C': 0.1, 'penalty': 'l2'}. Best is trial 12 with value: 2.977062564079226.\u001b[0m\n",
      "Precision: 0.9872093023255814 \n",
      "Recall: 0.9906651108518086 \n",
      "Aging Rate: 0.5512820512820513\n",
      "Precision: 0.9860788863109049 \n",
      "Recall: 0.9918319719953326 \n",
      "Aging Rate: 0.5525641025641026\n",
      "Precision: 0.9895591647331786 \n",
      "Recall: 0.9953325554259043 \n",
      "Aging Rate: 0.5525641025641026\n",
      "\u001b[32m[I 2021-12-05 18:28:29,138]\u001b[0m Trial 15 finished with value: 2.967841448337458 and parameters: {'meta_learner': 'ExtraTrees', 'n_estimators': 300, 'min_samples_split': 22, 'max_depth': 3}. Best is trial 12 with value: 2.977062564079226.\u001b[0m\n",
      "Precision: 0.986046511627907 \n",
      "Recall: 0.9894982497082847 \n",
      "Aging Rate: 0.5512820512820513\n",
      "Precision: 0.9883313885647608 \n",
      "Recall: 0.9883313885647608 \n",
      "Aging Rate: 0.5493589743589744\n",
      "Precision: 0.9952941176470588 \n",
      "Recall: 0.9871645274212368 \n",
      "Aging Rate: 0.5448717948717948\n",
      "\u001b[32m[I 2021-12-05 18:28:29,298]\u001b[0m Trial 16 finished with value: 2.9681127337912456 and parameters: {'meta_learner': 'LogisticRegression', 'C': 1, 'penalty': 'l2'}. Best is trial 12 with value: 2.977062564079226.\u001b[0m\n",
      "Precision: 0.9883449883449883 \n",
      "Recall: 0.9894982497082847 \n",
      "Aging Rate: 0.55\n",
      "Precision: 0.9894982497082847 \n",
      "Recall: 0.9894982497082847 \n",
      "Aging Rate: 0.5493589743589744\n",
      "Precision: 0.9883449883449883 \n",
      "Recall: 0.9894982497082847 \n",
      "Aging Rate: 0.55\n",
      "\u001b[32m[I 2021-12-05 18:28:30,558]\u001b[0m Trial 17 finished with value: 2.9669570673071255 and parameters: {'meta_learner': 'ExtraTrees', 'n_estimators': 100, 'min_samples_split': 12, 'max_depth': 21}. Best is trial 12 with value: 2.977062564079226.\u001b[0m\n",
      "Precision: 0.9906976744186047 \n",
      "Recall: 0.9941656942823804 \n",
      "Aging Rate: 0.5512820512820513\n",
      "Precision: 0.9861271676300578 \n",
      "Recall: 0.9953325554259043 \n",
      "Aging Rate: 0.5544871794871795\n",
      "Precision: 0.9872389791183295 \n",
      "Recall: 0.9929988331388565 \n",
      "Aging Rate: 0.5525641025641026\n",
      "\u001b[32m[I 2021-12-05 18:28:30,724]\u001b[0m Trial 18 finished with value: 2.9702082417270415 and parameters: {'meta_learner': 'LogisticRegression', 'C': 1, 'penalty': 'none'}. Best is trial 12 with value: 2.977062564079226.\u001b[0m\n",
      "Precision: 0.9929824561403509 \n",
      "Recall: 0.9906651108518086 \n",
      "Aging Rate: 0.5480769230769231\n",
      "Precision: 0.9918509895227008 \n",
      "Recall: 0.9941656942823804 \n",
      "Aging Rate: 0.5506410256410257\n",
      "Precision: 0.9976387249114522 \n",
      "Recall: 0.9859976662777129 \n",
      "Aging Rate: 0.5429487179487179\n",
      "\u001b[32m[I 2021-12-05 18:28:32,885]\u001b[0m Trial 19 finished with value: 2.9785909375203032 and parameters: {'meta_learner': 'ExtraTrees', 'n_estimators': 500, 'min_samples_split': 27, 'max_depth': 12}. Best is trial 19 with value: 2.9785909375203032.\u001b[0m\n",
      "Precision: 0.9918319719953326 \n",
      "Recall: 0.9918319719953326 \n",
      "Aging Rate: 0.5493589743589744\n",
      "Precision: 0.988399071925754 \n",
      "Recall: 0.9941656942823804 \n",
      "Aging Rate: 0.5525641025641026\n",
      "Precision: 0.9906759906759907 \n",
      "Recall: 0.9918319719953326 \n",
      "Aging Rate: 0.55\n",
      "\u001b[32m[I 2021-12-05 18:28:33,030]\u001b[0m Trial 20 finished with value: 2.9732145691557332 and parameters: {'meta_learner': 'LogisticRegression', 'C': 0.1, 'penalty': 'l2'}. Best is trial 19 with value: 2.9785909375203032.\u001b[0m\n",
      "Precision: 0.9953271028037384 \n",
      "Recall: 0.9941656942823804 \n",
      "Aging Rate: 0.5487179487179488\n",
      "Precision: 0.9906868451688009 \n",
      "Recall: 0.9929988331388565 \n",
      "Aging Rate: 0.5506410256410257\n",
      "Precision: 0.9906759906759907 \n",
      "Recall: 0.9918319719953326 \n",
      "Aging Rate: 0.55\n",
      "\u001b[32m[I 2021-12-05 18:28:35,192]\u001b[0m Trial 21 finished with value: 2.977458792237877 and parameters: {'meta_learner': 'ExtraTrees', 'n_estimators': 500, 'min_samples_split': 27, 'max_depth': 12}. Best is trial 19 with value: 2.9785909375203032.\u001b[0m\n",
      "Precision: 0.9918319719953326 \n",
      "Recall: 0.9918319719953326 \n",
      "Aging Rate: 0.5493589743589744\n",
      "Precision: 0.9872832369942196 \n",
      "Recall: 0.9964994165694282 \n",
      "Aging Rate: 0.5544871794871795\n",
      "Precision: 0.9918319719953326 \n",
      "Recall: 0.9918319719953326 \n",
      "Aging Rate: 0.5493589743589744\n",
      "\u001b[32m[I 2021-12-05 18:28:37,387]\u001b[0m Trial 22 finished with value: 2.974019240843288 and parameters: {'meta_learner': 'ExtraTrees', 'n_estimators': 500, 'min_samples_split': 32, 'max_depth': 12}. Best is trial 19 with value: 2.9785909375203032.\u001b[0m\n",
      "Precision: 0.9918414918414918 \n",
      "Recall: 0.9929988331388565 \n",
      "Aging Rate: 0.55\n",
      "Precision: 0.9906542056074766 \n",
      "Recall: 0.9894982497082847 \n",
      "Aging Rate: 0.5487179487179488\n",
      "Precision: 0.9929660023446659 \n",
      "Recall: 0.9883313885647608 \n",
      "Aging Rate: 0.5467948717948717\n",
      "\u001b[32m[I 2021-12-05 18:28:39,532]\u001b[0m Trial 23 finished with value: 2.973917290333057 and parameters: {'meta_learner': 'ExtraTrees', 'n_estimators': 500, 'min_samples_split': 27, 'max_depth': 12}. Best is trial 19 with value: 2.9785909375203032.\u001b[0m\n",
      "Precision: 0.9895712630359212 \n",
      "Recall: 0.9964994165694282 \n",
      "Aging Rate: 0.5532051282051282\n",
      "Precision: 0.9906432748538012 \n",
      "Recall: 0.9883313885647608 \n",
      "Aging Rate: 0.5480769230769231\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "``multivariate`` option is an experimental feature. The interface can change in the future.\n",
      "\u001b[32m[I 2021-12-05 18:28:41,809]\u001b[0m A new study created in memory with name: no-name-3ee19a91-54f2-4064-864a-8320cd5f3e4b\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.9861111111111112 \n",
      "Recall: 0.9941656942823804 \n",
      "Aging Rate: 0.5538461538461539\n",
      "\u001b[32m[I 2021-12-05 18:28:41,712]\u001b[0m Trial 24 finished with value: 2.970549265806079 and parameters: {'meta_learner': 'ExtraTrees', 'n_estimators': 500, 'min_samples_split': 27, 'max_depth': 9}. Best is trial 19 with value: 2.9785909375203032.\u001b[0m\n",
      "Sampler is TPESampler\n",
      "Dataset7 :\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress bar is experimental (supported from v1.2.0). The interface can change in the future.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "040fbd41d12c4af7a28e5b6f1f8b60f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.9971590909090909 \n",
      "Recall: 0.9985775248933144 \n",
      "Aging Rate: 0.5007112375533428\n",
      "Precision: 0.9957325746799431 \n",
      "Recall: 0.9957325746799431 \n",
      "Aging Rate: 0.5\n",
      "Precision: 0.9971428571428571 \n",
      "Recall: 0.9928876244665719 \n",
      "Aging Rate: 0.49786628733997157\n",
      "\u001b[32m[I 2021-12-05 18:28:41,883]\u001b[0m Trial 0 finished with value: 2.9890889231678712 and parameters: {'meta_learner': 'LogisticRegression', 'C': 0.1, 'penalty': 'l2'}. Best is trial 0 with value: 2.9890889231678712.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.9929078014184397 \n",
      "Recall: 0.9957325746799431 \n",
      "Aging Rate: 0.5014224751066856\n",
      "Precision: 0.9971509971509972 \n",
      "Recall: 0.9957325746799431 \n",
      "Aging Rate: 0.4992887624466572\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.9985754985754985 \n",
      "Recall: 0.9971550497866287 \n",
      "Aging Rate: 0.4992887624466572\n",
      "\u001b[32m[I 2021-12-05 18:28:42,047]\u001b[0m Trial 1 finished with value: 2.9886295978121287 and parameters: {'meta_learner': 'LogisticRegression', 'C': 10, 'penalty': 'none'}. Best is trial 0 with value: 2.9890889231678712.\u001b[0m\n",
      "Precision: 0.9957386363636364 \n",
      "Recall: 0.9971550497866287 \n",
      "Aging Rate: 0.5007112375533428\n",
      "Precision: 0.9971550497866287 \n",
      "Recall: 0.9971550497866287 \n",
      "Aging Rate: 0.5\n",
      "Precision: 0.9957325746799431 \n",
      "Recall: 0.9957325746799431 \n",
      "Aging Rate: 0.5\n",
      "\u001b[32m[I 2021-12-05 18:28:43,245]\u001b[0m Trial 2 finished with value: 2.989098398637872 and parameters: {'meta_learner': 'ExtraTrees', 'n_estimators': 100, 'min_samples_split': 7, 'max_depth': 12}. Best is trial 2 with value: 2.989098398637872.\u001b[0m\n",
      "Precision: 0.9957325746799431 \n",
      "Recall: 0.9957325746799431 \n",
      "Aging Rate: 0.5\n",
      "Precision: 0.9985714285714286 \n",
      "Recall: 0.9943100995732574 \n",
      "Aging Rate: 0.49786628733997157\n",
      "Precision: 1.0 \n",
      "Recall: 0.9943100995732574 \n",
      "Aging Rate: 0.4971550497866287\n",
      "\u001b[32m[I 2021-12-05 18:28:43,396]\u001b[0m Trial 3 finished with value: 2.990986926776401 and parameters: {'meta_learner': 'LogisticRegression', 'C': 0.1, 'penalty': 'l2'}. Best is trial 3 with value: 2.990986926776401.\u001b[0m\n",
      "Precision: 0.9971550497866287 \n",
      "Recall: 0.9971550497866287 \n",
      "Aging Rate: 0.5\n",
      "Precision: 0.9957507082152974 \n",
      "Recall: 1.0 \n",
      "Aging Rate: 0.5021337126600285\n",
      "Precision: 1.0 \n",
      "Recall: 0.9957325746799431 \n",
      "Aging Rate: 0.49786628733997157\n",
      "\u001b[32m[I 2021-12-05 18:28:44,576]\u001b[0m Trial 4 finished with value: 2.992899713490141 and parameters: {'meta_learner': 'ExtraTrees', 'n_estimators': 100, 'min_samples_split': 17, 'max_depth': 6}. Best is trial 4 with value: 2.992899713490141.\u001b[0m\n",
      "Precision: 0.9985714285714286 \n",
      "Recall: 0.9943100995732574 \n",
      "Aging Rate: 0.49786628733997157\n",
      "Precision: 1.0 \n",
      "Recall: 0.9971550497866287 \n",
      "Aging Rate: 0.49857752489331436\n",
      "Precision: 0.9971550497866287 \n",
      "Recall: 0.9971550497866287 \n",
      "Aging Rate: 0.5\n",
      "\u001b[32m[I 2021-12-05 18:28:45,785]\u001b[0m Trial 5 finished with value: 2.9933577186208766 and parameters: {'meta_learner': 'ExtraTrees', 'n_estimators': 100, 'min_samples_split': 27, 'max_depth': 12}. Best is trial 5 with value: 2.9933577186208766.\u001b[0m\n",
      "Precision: 0.9957386363636364 \n",
      "Recall: 0.9971550497866287 \n",
      "Aging Rate: 0.5007112375533428\n",
      "Precision: 0.9943100995732574 \n",
      "Recall: 0.9943100995732574 \n",
      "Aging Rate: 0.5\n",
      "Precision: 0.9914772727272727 \n",
      "Recall: 0.9928876244665719 \n",
      "Aging Rate: 0.5007112375533428\n",
      "\u001b[32m[I 2021-12-05 18:28:45,944]\u001b[0m Trial 6 finished with value: 2.9824682637182636 and parameters: {'meta_learner': 'LogisticRegression', 'C': 10, 'penalty': 'l2'}. Best is trial 5 with value: 2.9933577186208766.\u001b[0m\n",
      "Precision: 0.9985734664764622 \n",
      "Recall: 0.9957325746799431 \n",
      "Aging Rate: 0.49857752489331436\n",
      "Precision: 0.9985714285714286 \n",
      "Recall: 0.9943100995732574 \n",
      "Aging Rate: 0.49786628733997157\n",
      "Precision: 0.9971428571428571 \n",
      "Recall: 0.9928876244665719 \n",
      "Aging Rate: 0.49786628733997157\n",
      "\u001b[32m[I 2021-12-05 18:28:46,115]\u001b[0m Trial 7 finished with value: 2.99050193436709 and parameters: {'meta_learner': 'LogisticRegression', 'C': 10, 'penalty': 'l2'}. Best is trial 5 with value: 2.9933577186208766.\u001b[0m\n",
      "Precision: 0.9929378531073446 \n",
      "Recall: 1.0 \n",
      "Aging Rate: 0.5035561877667141\n",
      "Precision: 0.9985734664764622 \n",
      "Recall: 0.9957325746799431 \n",
      "Aging Rate: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.49857752489331436\n",
      "Precision: 0.9943422913719944 \n",
      "Recall: 1.0 \n",
      "Aging Rate: 0.5028449502133713\n",
      "\u001b[32m[I 2021-12-05 18:28:46,277]\u001b[0m Trial 8 finished with value: 2.9891465988638486 and parameters: {'meta_learner': 'LogisticRegression', 'C': 0.1, 'penalty': 'none'}. Best is trial 5 with value: 2.9933577186208766.\u001b[0m\n",
      "Precision: 0.9985734664764622 \n",
      "Recall: 0.9957325746799431 \n",
      "Aging Rate: 0.49857752489331436\n",
      "Precision: 0.9971550497866287 \n",
      "Recall: 0.9971550497866287 \n",
      "Aging Rate: 0.5\n",
      "Precision: 1.0 \n",
      "Recall: 0.9985775248933144 \n",
      "Aging Rate: 0.4992887624466572\n",
      "\u001b[32m[I 2021-12-05 18:28:48,697]\u001b[0m Trial 9 finished with value: 2.9943073939620226 and parameters: {'meta_learner': 'ExtraTrees', 'n_estimators': 500, 'min_samples_split': 12, 'max_depth': 21}. Best is trial 9 with value: 2.9943073939620226.\u001b[0m\n",
      "Precision: 0.9915134370579916 \n",
      "Recall: 0.9971550497866287 \n",
      "Aging Rate: 0.5028449502133713\n",
      "Precision: 0.9985714285714286 \n",
      "Recall: 0.9943100995732574 \n",
      "Aging Rate: 0.49786628733997157\n",
      "Precision: 0.9985775248933144 \n",
      "Recall: 0.9985775248933144 \n",
      "Aging Rate: 0.5\n",
      "\u001b[32m[I 2021-12-05 18:28:50,954]\u001b[0m Trial 10 finished with value: 2.9891224850995566 and parameters: {'meta_learner': 'ExtraTrees', 'n_estimators': 500, 'min_samples_split': 2, 'max_depth': 21}. Best is trial 9 with value: 2.9943073939620226.\u001b[0m\n",
      "Precision: 0.9943422913719944 \n",
      "Recall: 1.0 \n",
      "Aging Rate: 0.5028449502133713\n",
      "Precision: 0.9985754985754985 \n",
      "Recall: 0.9971550497866287 \n",
      "Aging Rate: 0.4992887624466572\n",
      "Precision: 0.9957446808510638 \n",
      "Recall: 0.9985775248933144 \n",
      "Aging Rate: 0.5014224751066856\n",
      "\u001b[32m[I 2021-12-05 18:28:53,148]\u001b[0m Trial 11 finished with value: 2.991019172092352 and parameters: {'meta_learner': 'ExtraTrees', 'n_estimators': 500, 'min_samples_split': 32, 'max_depth': 21}. Best is trial 9 with value: 2.9943073939620226.\u001b[0m\n",
      "Precision: 0.9957325746799431 \n",
      "Recall: 0.9957325746799431 \n",
      "Aging Rate: 0.5\n",
      "Precision: 0.9985754985754985 \n",
      "Recall: 0.9971550497866287 \n",
      "Aging Rate: 0.4992887624466572\n",
      "Precision: 0.9957325746799431 \n",
      "Recall: 0.9957325746799431 \n",
      "Aging Rate: 0.5\n",
      "\u001b[32m[I 2021-12-05 18:28:54,858]\u001b[0m Trial 12 finished with value: 2.9895671650057616 and parameters: {'meta_learner': 'ExtraTrees', 'n_estimators': 300, 'min_samples_split': 22, 'max_depth': 12}. Best is trial 9 with value: 2.9943073939620226.\u001b[0m\n",
      "Precision: 0.9957446808510638 \n",
      "Recall: 0.9985775248933144 \n",
      "Aging Rate: 0.5014224751066856\n",
      "Precision: 0.9971509971509972 \n",
      "Recall: 0.9957325746799431 \n",
      "Aging Rate: 0.4992887624466572\n",
      "Precision: 0.9957446808510638 \n",
      "Recall: 0.9985775248933144 \n",
      "Aging Rate: 0.5014224751066856\n",
      "\u001b[32m[I 2021-12-05 18:28:56,544]\u001b[0m Trial 13 finished with value: 2.9900561140576074 and parameters: {'meta_learner': 'ExtraTrees', 'n_estimators': 300, 'min_samples_split': 32, 'max_depth': 18}. Best is trial 9 with value: 2.9943073939620226.\u001b[0m\n",
      "Precision: 0.9985734664764622 \n",
      "Recall: 0.9957325746799431 \n",
      "Aging Rate: 0.49857752489331436\n",
      "Precision: 0.9915014164305949 \n",
      "Recall: 0.9957325746799431 \n",
      "Aging Rate: 0.5021337126600285\n",
      "Precision: 0.9985734664764622 \n",
      "Recall: 0.9957325746799431 \n",
      "Aging Rate: 0.49857752489331436\n",
      "\u001b[32m[I 2021-12-05 18:28:57,754]\u001b[0m Trial 14 finished with value: 2.9881648076022898 and parameters: {'meta_learner': 'ExtraTrees', 'n_estimators': 100, 'min_samples_split': 12, 'max_depth': 3}. Best is trial 9 with value: 2.9943073939620226.\u001b[0m\n",
      "Precision: 0.9957264957264957 \n",
      "Recall: 0.9943100995732574 \n",
      "Aging Rate: 0.4992887624466572\n",
      "Precision: 0.9971590909090909 \n",
      "Recall: 0.9985775248933144 \n",
      "Aging Rate: 0.5007112375533428\n",
      "Precision: 0.9985754985754985 \n",
      "Recall: 0.9971550497866287 \n",
      "Aging Rate: 0.4992887624466572\n",
      "\u001b[32m[I 2021-12-05 18:28:59,926]\u001b[0m Trial 15 finished with value: 2.9909882815584568 and parameters: {'meta_learner': 'ExtraTrees', 'n_estimators': 500, 'min_samples_split': 22, 'max_depth': 15}. Best is trial 9 with value: 2.9943073939620226.\u001b[0m\n",
      "Precision: 1.0 \n",
      "Recall: 0.9971550497866287 \n",
      "Aging Rate: 0.49857752489331436\n",
      "Precision: 0.9985775248933144 \n",
      "Recall: 0.9985775248933144 \n",
      "Aging Rate: 0.5\n",
      "Precision: 0.9971550497866287 \n",
      "Recall: 0.9971550497866287 \n",
      "Aging Rate: 0.5\n",
      "\u001b[32m[I 2021-12-05 18:29:01,606]\u001b[0m Trial 16 finished with value: 2.9947842579421526 and parameters: {'meta_learner': 'ExtraTrees', 'n_estimators': 300, 'min_samples_split': 27, 'max_depth': 6}. Best is trial 16 with value: 2.9947842579421526.\u001b[0m\n",
      "Precision: 0.9971428571428571 \n",
      "Recall: 0.9928876244665719 \n",
      "Aging Rate: 0.49786628733997157\n",
      "Precision: 0.998567335243553 \n",
      "Recall: 0.9914651493598862 \n",
      "Aging Rate: 0.49644381223328593\n",
      "Precision: 0.9985693848354793 \n",
      "Recall: 0.9928876244665719 \n",
      "Aging Rate: 0.4971550497866287\n",
      "\u001b[32m[I 2021-12-05 18:29:03,283]\u001b[0m Trial 17 finished with value: 2.9885998509122693 and parameters: {'meta_learner': 'ExtraTrees', 'n_estimators': 300, 'min_samples_split': 12, 'max_depth': 6}. Best is trial 16 with value: 2.9947842579421526.\u001b[0m\n",
      "Precision: 0.9957386363636364 \n",
      "Recall: 0.9971550497866287 \n",
      "Aging Rate: 0.5007112375533428\n",
      "Precision: 0.9985775248933144 \n",
      "Recall: 0.9985775248933144 \n",
      "Aging Rate: 0.5\n",
      "Precision: 0.9971550497866287 \n",
      "Recall: 0.9971550497866287 \n",
      "Aging Rate: 0.5\n",
      "\u001b[32m[I 2021-12-05 18:29:05,450]\u001b[0m Trial 18 finished with value: 2.9919433488512435 and parameters: {'meta_learner': 'ExtraTrees', 'n_estimators': 500, 'min_samples_split': 17, 'max_depth': 6}. Best is trial 16 with value: 2.9947842579421526.\u001b[0m\n",
      "Precision: 0.9985611510791367 \n",
      "Recall: 0.9871977240398293 \n",
      "Aging Rate: 0.49431009957325744\n",
      "Precision: 0.9985754985754985 \n",
      "Recall: 0.9971550497866287 \n",
      "Aging Rate: 0.4992887624466572\n",
      "Precision: 0.9971509971509972 \n",
      "Recall: 0.9957325746799431 \n",
      "Aging Rate: 0.4992887624466572\n",
      "\u001b[32m[I 2021-12-05 18:29:07,149]\u001b[0m Trial 19 finished with value: 2.989553547372555 and parameters: {'meta_learner': 'ExtraTrees', 'n_estimators': 300, 'min_samples_split': 2, 'max_depth': 3}. Best is trial 16 with value: 2.9947842579421526.\u001b[0m\n",
      "Precision: 0.997134670487106 \n",
      "Recall: 0.9900426742532006 \n",
      "Aging Rate: 0.49644381223328593\n",
      "Precision: 0.9943262411347518 \n",
      "Recall: 0.9971550497866287 \n",
      "Aging Rate: 0.5014224751066856\n",
      "Precision: 0.9985754985754985 \n",
      "Recall: 0.9971550497866287 \n",
      "Aging Rate: 0.4992887624466572\n",
      "\u001b[32m[I 2021-12-05 18:29:09,591]\u001b[0m Trial 20 finished with value: 2.98814186474039 and parameters: {'meta_learner': 'ExtraTrees', 'n_estimators': 500, 'min_samples_split': 27, 'max_depth': 9}. Best is trial 16 with value: 2.9947842579421526.\u001b[0m\n",
      "Precision: 0.9985754985754985 \n",
      "Recall: 0.9971550497866287 \n",
      "Aging Rate: 0.4992887624466572\n",
      "Precision: 0.9985775248933144 \n",
      "Recall: 0.9985775248933144 \n",
      "Aging Rate: 0.5\n",
      "Precision: 1.0 \n",
      "Recall: 0.9943100995732574 \n",
      "Aging Rate: 0.4971550497866287\n",
      "\u001b[32m[I 2021-12-05 18:29:10,866]\u001b[0m Trial 21 finished with value: 2.994782907063609 and parameters: {'meta_learner': 'ExtraTrees', 'n_estimators': 100, 'min_samples_split': 27, 'max_depth': 15}. Best is trial 16 with value: 2.9947842579421526.\u001b[0m\n",
      "Precision: 1.0 \n",
      "Recall: 0.9971550497866287 \n",
      "Aging Rate: 0.49857752489331436\n",
      "Precision: 0.9985734664764622 \n",
      "Recall: 0.9957325746799431 \n",
      "Aging Rate: 0.49857752489331436\n",
      "Precision: 0.9971509971509972 \n",
      "Recall: 0.9957325746799431 \n",
      "Aging Rate: 0.4992887624466572\n",
      "\u001b[32m[I 2021-12-05 18:29:12,621]\u001b[0m Trial 22 finished with value: 2.9933563754671453 and parameters: {'meta_learner': 'ExtraTrees', 'n_estimators': 300, 'min_samples_split': 27, 'max_depth': 18}. Best is trial 16 with value: 2.9947842579421526.\u001b[0m\n",
      "Precision: 0.9943342776203966 \n",
      "Recall: 0.9985775248933144 \n",
      "Aging Rate: 0.5021337126600285\n",
      "Precision: 0.9957386363636364 \n",
      "Recall: 0.9971550497866287 \n",
      "Aging Rate: 0.5007112375533428\n",
      "Precision: 0.9971509971509972 \n",
      "Recall: 0.9957325746799431 \n",
      "Aging Rate: 0.4992887624466572\n",
      "\u001b[32m[I 2021-12-05 18:29:13,805]\u001b[0m Trial 23 finished with value: 2.9886376572099826 and parameters: {'meta_learner': 'ExtraTrees', 'n_estimators': 100, 'min_samples_split': 22, 'max_depth': 18}. Best is trial 16 with value: 2.9947842579421526.\u001b[0m\n",
      "Precision: 0.9957325746799431 \n",
      "Recall: 0.9957325746799431 \n",
      "Aging Rate: 0.5\n",
      "Precision: 1.0 \n",
      "Recall: 0.9971550497866287 \n",
      "Aging Rate: 0.49857752489331436\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "``multivariate`` option is an experimental feature. The interface can change in the future.\n",
      "\u001b[32m[I 2021-12-05 18:29:15,604]\u001b[0m A new study created in memory with name: no-name-852e0c18-76a8-4af0-aef2-14ba2abd237c\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.9985714285714286 \n",
      "Recall: 0.9943100995732574 \n",
      "Aging Rate: 0.49786628733997157\n",
      "\u001b[32m[I 2021-12-05 18:29:15,516]\u001b[0m Trial 24 finished with value: 2.9919352435141913 and parameters: {'meta_learner': 'ExtraTrees', 'n_estimators': 300, 'min_samples_split': 12, 'max_depth': 15}. Best is trial 16 with value: 2.9947842579421526.\u001b[0m\n",
      "Sampler is TPESampler\n",
      "Dataset8 :\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress bar is experimental (supported from v1.2.0). The interface can change in the future.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad91dd3b7f944178aaca0fe56629cf7c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.9928469241773963 \n",
      "Recall: 0.9871977240398293 \n",
      "Aging Rate: 0.4971550497866287\n",
      "Precision: 0.9942938659058488 \n",
      "Recall: 0.9914651493598862 \n",
      "Aging Rate: 0.49857752489331436\n",
      "Precision: 0.9942857142857143 \n",
      "Recall: 0.9900426742532006 \n",
      "Aging Rate: 0.49786628733997157\n",
      "\u001b[32m[I 2021-12-05 18:29:15,695]\u001b[0m Trial 0 finished with value: 2.9771861854636117 and parameters: {'meta_learner': 'LogisticRegression', 'C': 100, 'penalty': 'none'}. Best is trial 0 with value: 2.9771861854636117.\u001b[0m\n",
      "Precision: 0.9971305595408895 \n",
      "Recall: 0.9886201991465149 \n",
      "Aging Rate: 0.4957325746799431\n",
      "Precision: 0.9914651493598862 \n",
      "Recall: 0.9914651493598862 \n",
      "Aging Rate: 0.5\n",
      "Precision: 0.9956958393113343 \n",
      "Recall: 0.9871977240398293 \n",
      "Aging Rate: 0.4957325746799431\n",
      "\u001b[32m[I 2021-12-05 18:29:15,857]\u001b[0m Trial 1 finished with value: 2.9786220563234838 and parameters: {'meta_learner': 'LogisticRegression', 'C': 10, 'penalty': 'l2'}. Best is trial 1 with value: 2.9786220563234838.\u001b[0m\n",
      "Precision: 0.995702005730659 \n",
      "Recall: 0.9886201991465149 \n",
      "Aging Rate: 0.49644381223328593\n",
      "Precision: 1.0 \n",
      "Recall: 0.9829302987197724 \n",
      "Aging Rate: 0.4914651493598862\n",
      "Precision: 0.994277539341917 \n",
      "Recall: 0.9886201991465149 \n",
      "Aging Rate: 0.4971550497866287\n",
      "\u001b[32m[I 2021-12-05 18:29:18,021]\u001b[0m Trial 2 finished with value: 2.9800432623859847 and parameters: {'meta_learner': 'ExtraTrees', 'n_estimators': 500, 'min_samples_split': 17, 'max_depth': 15}. Best is trial 2 with value: 2.9800432623859847.\u001b[0m\n",
      "Precision: 0.9957142857142857 \n",
      "Recall: 0.9914651493598862 \n",
      "Aging Rate: 0.49786628733997157\n",
      "Precision: 0.998567335243553 \n",
      "Recall: 0.9914651493598862 \n",
      "Aging Rate: 0.49644381223328593\n",
      "Precision: 0.9885222381635581 \n",
      "Recall: 0.9800853485064012 \n",
      "Aging Rate: 0.4957325746799431\n",
      "\u001b[32m[I 2021-12-05 18:29:18,179]\u001b[0m Trial 3 finished with value: 2.976207788489656 and parameters: {'meta_learner': 'LogisticRegression', 'C': 1, 'penalty': 'none'}. Best is trial 2 with value: 2.9800432623859847.\u001b[0m\n",
      "Precision: 0.9885550786838341 \n",
      "Recall: 0.9829302987197724 \n",
      "Aging Rate: 0.4971550497866287\n",
      "Precision: 1.0 \n",
      "Recall: 0.9772403982930299 \n",
      "Aging Rate: 0.48862019914651494\n",
      "Precision: 0.997134670487106 \n",
      "Recall: 0.9900426742532006 \n",
      "Aging Rate: 0.49644381223328593\n",
      "\u001b[32m[I 2021-12-05 18:29:19,871]\u001b[0m Trial 4 finished with value: 2.973864289869294 and parameters: {'meta_learner': 'ExtraTrees', 'n_estimators': 300, 'min_samples_split': 22, 'max_depth': 21}. Best is trial 2 with value: 2.9800432623859847.\u001b[0m\n",
      "Precision: 0.9971305595408895 \n",
      "Recall: 0.9886201991465149 \n",
      "Aging Rate: 0.4957325746799431\n",
      "Precision: 0.9985569985569985 \n",
      "Recall: 0.984352773826458 \n",
      "Aging Rate: 0.49288762446657186\n",
      "Precision: 1.0 \n",
      "Recall: 0.9886201991465149 \n",
      "Aging Rate: 0.49431009957325744\n",
      "\u001b[32m[I 2021-12-05 18:29:21,059]\u001b[0m Trial 5 finished with value: 2.9843227627717543 and parameters: {'meta_learner': 'ExtraTrees', 'n_estimators': 100, 'min_samples_split': 22, 'max_depth': 9}. Best is trial 5 with value: 2.9843227627717543.\u001b[0m\n",
      "Precision: 0.9971305595408895 \n",
      "Recall: 0.9886201991465149 \n",
      "Aging Rate: 0.4957325746799431\n",
      "Precision: 0.9970972423802612 \n",
      "Recall: 0.9772403982930299 \n",
      "Aging Rate: 0.4900426742532006\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.9956958393113343 \n",
      "Recall: 0.9871977240398293 \n",
      "Aging Rate: 0.4957325746799431\n",
      "\u001b[32m[I 2021-12-05 18:29:22,249]\u001b[0m Trial 6 finished with value: 2.9776352013147815 and parameters: {'meta_learner': 'ExtraTrees', 'n_estimators': 100, 'min_samples_split': 2, 'max_depth': 9}. Best is trial 5 with value: 2.9843227627717543.\u001b[0m\n",
      "Precision: 0.9928469241773963 \n",
      "Recall: 0.9871977240398293 \n",
      "Aging Rate: 0.4971550497866287\n",
      "Precision: 0.9928774928774928 \n",
      "Recall: 0.9914651493598862 \n",
      "Aging Rate: 0.4992887624466572\n",
      "Precision: 0.9971098265895953 \n",
      "Recall: 0.9815078236130867 \n",
      "Aging Rate: 0.492176386913229\n",
      "\u001b[32m[I 2021-12-05 18:29:22,413]\u001b[0m Trial 7 finished with value: 2.9752797281005905 and parameters: {'meta_learner': 'LogisticRegression', 'C': 0.01, 'penalty': 'none'}. Best is trial 5 with value: 2.9843227627717543.\u001b[0m\n",
      "Precision: 0.994277539341917 \n",
      "Recall: 0.9886201991465149 \n",
      "Aging Rate: 0.4971550497866287\n",
      "Precision: 0.9928263988522238 \n",
      "Recall: 0.984352773826458 \n",
      "Aging Rate: 0.4957325746799431\n",
      "Precision: 0.9971428571428571 \n",
      "Recall: 0.9928876244665719 \n",
      "Aging Rate: 0.49786628733997157\n",
      "\u001b[32m[I 2021-12-05 18:29:23,597]\u001b[0m Trial 8 finished with value: 2.978118062704514 and parameters: {'meta_learner': 'ExtraTrees', 'n_estimators': 100, 'min_samples_split': 32, 'max_depth': 3}. Best is trial 5 with value: 2.9843227627717543.\u001b[0m\n",
      "Precision: 0.9942446043165467 \n",
      "Recall: 0.9829302987197724 \n",
      "Aging Rate: 0.49431009957325744\n",
      "Precision: 0.995702005730659 \n",
      "Recall: 0.9886201991465149 \n",
      "Aging Rate: 0.49644381223328593\n",
      "Precision: 0.9985590778097982 \n",
      "Recall: 0.9857752489331437 \n",
      "Aging Rate: 0.49359886201991465\n",
      "\u001b[32m[I 2021-12-05 18:29:25,791]\u001b[0m Trial 9 finished with value: 2.9781123741711464 and parameters: {'meta_learner': 'ExtraTrees', 'n_estimators': 500, 'min_samples_split': 17, 'max_depth': 21}. Best is trial 5 with value: 2.9843227627717543.\u001b[0m\n",
      "Precision: 1.0 \n",
      "Recall: 0.9857752489331437 \n",
      "Aging Rate: 0.49288762446657186\n",
      "Precision: 0.9971181556195965 \n",
      "Recall: 0.984352773826458 \n",
      "Aging Rate: 0.49359886201991465\n",
      "Precision: 0.995702005730659 \n",
      "Recall: 0.9886201991465149 \n",
      "Aging Rate: 0.49644381223328593\n",
      "\u001b[32m[I 2021-12-05 18:29:27,097]\u001b[0m Trial 10 finished with value: 2.9814628482022094 and parameters: {'meta_learner': 'ExtraTrees', 'n_estimators': 100, 'min_samples_split': 32, 'max_depth': 6}. Best is trial 5 with value: 2.9843227627717543.\u001b[0m\n",
      "Precision: 0.9971139971139971 \n",
      "Recall: 0.9829302987197724 \n",
      "Aging Rate: 0.49288762446657186\n",
      "Precision: 0.9956709956709957 \n",
      "Recall: 0.9815078236130867 \n",
      "Aging Rate: 0.49288762446657186\n",
      "Precision: 0.9971014492753624 \n",
      "Recall: 0.9786628733997155 \n",
      "Aging Rate: 0.4907539118065434\n",
      "\u001b[32m[I 2021-12-05 18:29:28,430]\u001b[0m Trial 11 finished with value: 2.9742912932844283 and parameters: {'meta_learner': 'ExtraTrees', 'n_estimators': 100, 'min_samples_split': 32, 'max_depth': 6}. Best is trial 5 with value: 2.9843227627717543.\u001b[0m\n",
      "Precision: 0.9985549132947977 \n",
      "Recall: 0.9829302987197724 \n",
      "Aging Rate: 0.492176386913229\n",
      "Precision: 0.994277539341917 \n",
      "Recall: 0.9886201991465149 \n",
      "Aging Rate: 0.4971550497866287\n",
      "Precision: 1.0 \n",
      "Recall: 0.984352773826458 \n",
      "Aging Rate: 0.492176386913229\n",
      "\u001b[32m[I 2021-12-05 18:29:30,210]\u001b[0m Trial 12 finished with value: 2.980522725655392 and parameters: {'meta_learner': 'ExtraTrees', 'n_estimators': 300, 'min_samples_split': 27, 'max_depth': 12}. Best is trial 5 with value: 2.9843227627717543.\u001b[0m\n",
      "Precision: 0.9971181556195965 \n",
      "Recall: 0.984352773826458 \n",
      "Aging Rate: 0.49359886201991465\n",
      "Precision: 0.9956395348837209 \n",
      "Recall: 0.9743954480796586 \n",
      "Aging Rate: 0.48933143669985774\n",
      "Precision: 0.9985569985569985 \n",
      "Recall: 0.984352773826458 \n",
      "Aging Rate: 0.49288762446657186\n",
      "\u001b[32m[I 2021-12-05 18:29:31,404]\u001b[0m Trial 13 finished with value: 2.9752434579510685 and parameters: {'meta_learner': 'ExtraTrees', 'n_estimators': 100, 'min_samples_split': 7, 'max_depth': 3}. Best is trial 5 with value: 2.9843227627717543.\u001b[0m\n",
      "Precision: 0.9956521739130435 \n",
      "Recall: 0.9772403982930299 \n",
      "Aging Rate: 0.4907539118065434\n",
      "Precision: 0.9985611510791367 \n",
      "Recall: 0.9871977240398293 \n",
      "Aging Rate: 0.49431009957325744\n",
      "Precision: 0.9971139971139971 \n",
      "Recall: 0.9829302987197724 \n",
      "Aging Rate: 0.49288762446657186\n",
      "\u001b[32m[I 2021-12-05 18:29:33,106]\u001b[0m Trial 14 finished with value: 2.976674355088329 and parameters: {'meta_learner': 'ExtraTrees', 'n_estimators': 300, 'min_samples_split': 27, 'max_depth': 9}. Best is trial 5 with value: 2.9843227627717543.\u001b[0m\n",
      "Precision: 0.9928571428571429 \n",
      "Recall: 0.9886201991465149 \n",
      "Aging Rate: 0.49786628733997157\n",
      "Precision: 0.9942857142857143 \n",
      "Recall: 0.9900426742532006 \n",
      "Aging Rate: 0.49786628733997157\n",
      "Precision: 1.0 \n",
      "Recall: 0.9800853485064012 \n",
      "Aging Rate: 0.4900426742532006\n",
      "\u001b[32m[I 2021-12-05 18:29:34,325]\u001b[0m Trial 15 finished with value: 2.9776779787306107 and parameters: {'meta_learner': 'ExtraTrees', 'n_estimators': 100, 'min_samples_split': 12, 'max_depth': 6}. Best is trial 5 with value: 2.9843227627717543.\u001b[0m\n",
      "Precision: 0.997093023255814 \n",
      "Recall: 0.9758179231863442 \n",
      "Aging Rate: 0.48933143669985774\n",
      "Precision: 0.9985611510791367 \n",
      "Recall: 0.9871977240398293 \n",
      "Aging Rate: 0.49431009957325744\n",
      "Precision: 0.9971139971139971 \n",
      "Recall: 0.9829302987197724 \n",
      "Aging Rate: 0.49288762446657186\n",
      "\u001b[32m[I 2021-12-05 18:29:35,543]\u001b[0m Trial 16 finished with value: 2.9771607629479475 and parameters: {'meta_learner': 'ExtraTrees', 'n_estimators': 100, 'min_samples_split': 27, 'max_depth': 15}. Best is trial 5 with value: 2.9843227627717543.\u001b[0m\n",
      "Precision: 0.99568345323741 \n",
      "Recall: 0.984352773826458 \n",
      "Aging Rate: 0.49431009957325744\n",
      "Precision: 0.9956709956709957 \n",
      "Recall: 0.9815078236130867 \n",
      "Aging Rate: 0.49288762446657186\n",
      "Precision: 0.9971139971139971 \n",
      "Recall: 0.9829302987197724 \n",
      "Aging Rate: 0.49288762446657186\n",
      "\u001b[32m[I 2021-12-05 18:29:37,254]\u001b[0m Trial 17 finished with value: 2.975242596068041 and parameters: {'meta_learner': 'ExtraTrees', 'n_estimators': 300, 'min_samples_split': 22, 'max_depth': 9}. Best is trial 5 with value: 2.9843227627717543.\u001b[0m\n",
      "Precision: 0.9943100995732574 \n",
      "Recall: 0.9943100995732574 \n",
      "Aging Rate: 0.5\n",
      "Precision: 0.9971223021582734 \n",
      "Recall: 0.9857752489331437 \n",
      "Aging Rate: 0.49431009957325744\n",
      "Precision: 0.9928366762177651 \n",
      "Recall: 0.9857752489331437 \n",
      "Aging Rate: 0.49644381223328593\n",
      "\u001b[32m[I 2021-12-05 18:29:37,413]\u001b[0m Trial 18 finished with value: 2.9781329177793787 and parameters: {'meta_learner': 'LogisticRegression', 'C': 0.1, 'penalty': 'l2'}. Best is trial 5 with value: 2.9843227627717543.\u001b[0m\n",
      "Precision: 0.994261119081779 \n",
      "Recall: 0.9857752489331437 \n",
      "Aging Rate: 0.4957325746799431\n",
      "Precision: 0.9957264957264957 \n",
      "Recall: 0.9943100995732574 \n",
      "Aging Rate: 0.4992887624466572\n",
      "Precision: 0.9956958393113343 \n",
      "Recall: 0.9871977240398293 \n",
      "Aging Rate: 0.4957325746799431\n",
      "\u001b[32m[I 2021-12-05 18:29:38,623]\u001b[0m Trial 19 finished with value: 2.9795499935951497 and parameters: {'meta_learner': 'ExtraTrees', 'n_estimators': 100, 'min_samples_split': 32, 'max_depth': 6}. Best is trial 5 with value: 2.9843227627717543.\u001b[0m\n",
      "Precision: 0.9971098265895953 \n",
      "Recall: 0.9815078236130867 \n",
      "Aging Rate: 0.492176386913229\n",
      "Precision: 0.9956647398843931 \n",
      "Recall: 0.9800853485064012 \n",
      "Aging Rate: 0.492176386913229\n",
      "Precision: 0.9985507246376811 \n",
      "Recall: 0.9800853485064012 \n",
      "Aging Rate: 0.4907539118065434\n",
      "\u001b[32m[I 2021-12-05 18:29:40,335]\u001b[0m Trial 20 finished with value: 2.974776367616409 and parameters: {'meta_learner': 'ExtraTrees', 'n_estimators': 300, 'min_samples_split': 22, 'max_depth': 12}. Best is trial 5 with value: 2.9843227627717543.\u001b[0m\n",
      "Precision: 0.9971305595408895 \n",
      "Recall: 0.9886201991465149 \n",
      "Aging Rate: 0.4957325746799431\n",
      "Precision: 0.9971181556195965 \n",
      "Recall: 0.984352773826458 \n",
      "Aging Rate: 0.49359886201991465\n",
      "Precision: 0.9985569985569985 \n",
      "Recall: 0.984352773826458 \n",
      "Aging Rate: 0.49288762446657186\n",
      "\u001b[32m[I 2021-12-05 18:29:42,036]\u001b[0m Trial 21 finished with value: 2.9809790580781335 and parameters: {'meta_learner': 'ExtraTrees', 'n_estimators': 300, 'min_samples_split': 27, 'max_depth': 12}. Best is trial 5 with value: 2.9843227627717543.\u001b[0m\n",
      "Precision: 1.0 \n",
      "Recall: 0.9871977240398293 \n",
      "Aging Rate: 0.49359886201991465\n",
      "Precision: 0.9971139971139971 \n",
      "Recall: 0.9829302987197724 \n",
      "Aging Rate: 0.49288762446657186\n",
      "Precision: 0.9971056439942113 \n",
      "Recall: 0.9800853485064012 \n",
      "Aging Rate: 0.4914651493598862\n",
      "\u001b[32m[I 2021-12-05 18:29:43,887]\u001b[0m Trial 22 finished with value: 2.97955088449414 and parameters: {'meta_learner': 'ExtraTrees', 'n_estimators': 300, 'min_samples_split': 27, 'max_depth': 15}. Best is trial 5 with value: 2.9843227627717543.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.99568345323741 \n",
      "Recall: 0.984352773826458 \n",
      "Aging Rate: 0.49431009957325744\n",
      "Precision: 0.9971139971139971 \n",
      "Recall: 0.9829302987197724 \n",
      "Aging Rate: 0.49288762446657186\n",
      "Precision: 0.9971264367816092 \n",
      "Recall: 0.9871977240398293 \n",
      "Aging Rate: 0.4950213371266003\n",
      "\u001b[32m[I 2021-12-05 18:29:46,079]\u001b[0m Trial 23 finished with value: 2.978109523617364 and parameters: {'meta_learner': 'ExtraTrees', 'n_estimators': 500, 'min_samples_split': 22, 'max_depth': 9}. Best is trial 5 with value: 2.9843227627717543.\u001b[0m\n",
      "Precision: 0.9914163090128756 \n",
      "Recall: 0.9857752489331437 \n",
      "Aging Rate: 0.4971550497866287\n",
      "Precision: 0.9971139971139971 \n",
      "Recall: 0.9829302987197724 \n",
      "Aging Rate: 0.49288762446657186\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "``multivariate`` option is an experimental feature. The interface can change in the future.\n",
      "\u001b[32m[I 2021-12-05 18:29:47,889]\u001b[0m A new study created in memory with name: no-name-9917f890-3b7d-48b3-8f91-450abb2dd4e9\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.9914040114613181 \n",
      "Recall: 0.984352773826458 \n",
      "Aging Rate: 0.49644381223328593\n",
      "\u001b[32m[I 2021-12-05 18:29:47,781]\u001b[0m Trial 24 finished with value: 2.9709756522185855 and parameters: {'meta_learner': 'ExtraTrees', 'n_estimators': 300, 'min_samples_split': 32, 'max_depth': 12}. Best is trial 5 with value: 2.9843227627717543.\u001b[0m\n",
      "Sampler is TPESampler\n",
      "Dataset9 :\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress bar is experimental (supported from v1.2.0). The interface can change in the future.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0cdaf3affd6b4b70bcf41bf3af21faa7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.9545454545454546 \n",
      "Recall: 0.8873239436619719 \n",
      "Aging Rate: 0.08527131782945736\n",
      "Precision: 0.9838709677419355 \n",
      "Recall: 0.8591549295774648 \n",
      "Aging Rate: 0.08010335917312661\n",
      "Precision: 0.953125 \n",
      "Recall: 0.8591549295774648 \n",
      "Aging Rate: 0.082687338501292\n",
      "\u001b[32m[I 2021-12-05 18:29:47,978]\u001b[0m Trial 0 finished with value: 2.796238882463894 and parameters: {'meta_learner': 'LogisticRegression', 'C': 10, 'penalty': 'none'}. Best is trial 0 with value: 2.796238882463894.\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Precision: 0.9846153846153847 \n",
      "Recall: 0.9014084507042254 \n",
      "Aging Rate: 0.08397932816537468\n",
      "Precision: 0.9565217391304348 \n",
      "Recall: 0.9295774647887324 \n",
      "Aging Rate: 0.08914728682170543\n",
      "Precision: 0.9846153846153847 \n",
      "Recall: 0.9014084507042254 \n",
      "Aging Rate: 0.08397932816537468\n",
      "\u001b[32m[I 2021-12-05 18:29:48,142]\u001b[0m Trial 1 finished with value: 2.8612997943065306 and parameters: {'meta_learner': 'LogisticRegression', 'C': 10, 'penalty': 'l2'}. Best is trial 1 with value: 2.8612997943065306.\u001b[0m\n",
      "Precision: 0.984375 \n",
      "Recall: 0.8873239436619719 \n",
      "Aging Rate: 0.082687338501292\n",
      "Precision: 0.9285714285714286 \n",
      "Recall: 0.9154929577464789 \n",
      "Aging Rate: 0.09043927648578812\n",
      "Precision: 0.9846153846153847 \n",
      "Recall: 0.9014084507042254 \n",
      "Aging Rate: 0.08397932816537468\n",
      "\u001b[32m[I 2021-12-05 18:29:49,346]\u001b[0m Trial 2 finished with value: 2.833116326162101 and parameters: {'meta_learner': 'ExtraTrees', 'n_estimators': 100, 'min_samples_split': 2, 'max_depth': 6}. Best is trial 1 with value: 2.8612997943065306.\u001b[0m\n",
      "Precision: 0.9852941176470589 \n",
      "Recall: 0.9436619718309859 \n",
      "Aging Rate: 0.08785529715762273\n",
      "Precision: 0.953125 \n",
      "Recall: 0.8591549295774648 \n",
      "Aging Rate: 0.082687338501292\n",
      "Precision: 0.9852941176470589 \n",
      "Recall: 0.9436619718309859 \n",
      "Aging Rate: 0.08785529715762273\n",
      "\u001b[32m[I 2021-12-05 18:29:51,050]\u001b[0m Trial 3 finished with value: 2.8646351146092237 and parameters: {'meta_learner': 'ExtraTrees', 'n_estimators': 300, 'min_samples_split': 2, 'max_depth': 12}. Best is trial 3 with value: 2.8646351146092237.\u001b[0m\n",
      "Precision: 0.9041095890410958 \n",
      "Recall: 0.9295774647887324 \n",
      "Aging Rate: 0.09431524547803617\n",
      "Precision: 0.9701492537313433 \n",
      "Recall: 0.9154929577464789 \n",
      "Aging Rate: 0.08656330749354005\n",
      "Precision: 1.0 \n",
      "Recall: 0.8591549295774648 \n",
      "Aging Rate: 0.07881136950904392\n",
      "\u001b[32m[I 2021-12-05 18:29:52,731]\u001b[0m Trial 4 finished with value: 2.8175810125525182 and parameters: {'meta_learner': 'ExtraTrees', 'n_estimators': 300, 'min_samples_split': 27, 'max_depth': 6}. Best is trial 3 with value: 2.8646351146092237.\u001b[0m\n",
      "Precision: 0.984375 \n",
      "Recall: 0.8873239436619719 \n",
      "Aging Rate: 0.082687338501292\n",
      "Precision: 0.9411764705882353 \n",
      "Recall: 0.9014084507042254 \n",
      "Aging Rate: 0.08785529715762273\n",
      "Precision: 0.96875 \n",
      "Recall: 0.8732394366197183 \n",
      "Aging Rate: 0.082687338501292\n",
      "\u001b[32m[I 2021-12-05 18:29:52,906]\u001b[0m Trial 5 finished with value: 2.8168582573874623 and parameters: {'meta_learner': 'LogisticRegression', 'C': 100, 'penalty': 'l2'}. Best is trial 3 with value: 2.8646351146092237.\u001b[0m\n",
      "Precision: 0.9552238805970149 \n",
      "Recall: 0.9014084507042254 \n",
      "Aging Rate: 0.08656330749354005\n",
      "Precision: 0.9705882352941176 \n",
      "Recall: 0.9295774647887324 \n",
      "Aging Rate: 0.08785529715762273\n",
      "Precision: 0.9855072463768116 \n",
      "Recall: 0.9577464788732394 \n",
      "Aging Rate: 0.08914728682170543\n",
      "\u001b[32m[I 2021-12-05 18:29:55,080]\u001b[0m Trial 6 finished with value: 2.870457039634028 and parameters: {'meta_learner': 'ExtraTrees', 'n_estimators': 500, 'min_samples_split': 2, 'max_depth': 15}. Best is trial 6 with value: 2.870457039634028.\u001b[0m\n",
      "Precision: 0.9701492537313433 \n",
      "Recall: 0.9154929577464789 \n",
      "Aging Rate: 0.08656330749354005\n",
      "Precision: 0.984375 \n",
      "Recall: 0.8873239436619719 \n",
      "Aging Rate: 0.082687338501292\n",
      "Precision: 0.96875 \n",
      "Recall: 0.8732394366197183 \n",
      "Aging Rate: 0.082687338501292\n",
      "\u001b[32m[I 2021-12-05 18:29:55,223]\u001b[0m Trial 7 finished with value: 2.8408682818302853 and parameters: {'meta_learner': 'LogisticRegression', 'C': 0.1, 'penalty': 'l2'}. Best is trial 6 with value: 2.870457039634028.\u001b[0m\n",
      "Precision: 0.9428571428571428 \n",
      "Recall: 0.9295774647887324 \n",
      "Aging Rate: 0.09043927648578812\n",
      "Precision: 0.9841269841269841 \n",
      "Recall: 0.8732394366197183 \n",
      "Aging Rate: 0.08139534883720931\n",
      "Precision: 0.9558823529411765 \n",
      "Recall: 0.9154929577464789 \n",
      "Aging Rate: 0.08785529715762273\n",
      "\u001b[32m[I 2021-12-05 18:29:56,432]\u001b[0m Trial 8 finished with value: 2.828014273001845 and parameters: {'meta_learner': 'ExtraTrees', 'n_estimators': 100, 'min_samples_split': 17, 'max_depth': 15}. Best is trial 6 with value: 2.870457039634028.\u001b[0m\n",
      "Precision: 0.9558823529411765 \n",
      "Recall: 0.9154929577464789 \n",
      "Aging Rate: 0.08785529715762273\n",
      "Precision: 1.0 \n",
      "Recall: 0.9014084507042254 \n",
      "Aging Rate: 0.082687338501292\n",
      "Precision: 0.9701492537313433 \n",
      "Recall: 0.9154929577464789 \n",
      "Aging Rate: 0.08656330749354005\n",
      "\u001b[32m[I 2021-12-05 18:29:58,209]\u001b[0m Trial 9 finished with value: 2.8614858598474076 and parameters: {'meta_learner': 'ExtraTrees', 'n_estimators': 300, 'min_samples_split': 22, 'max_depth': 15}. Best is trial 6 with value: 2.870457039634028.\u001b[0m\n",
      "Precision: 1.0 \n",
      "Recall: 0.9436619718309859 \n",
      "Aging Rate: 0.08656330749354005\n",
      "Precision: 0.9722222222222222 \n",
      "Recall: 0.9859154929577465 \n",
      "Aging Rate: 0.09302325581395349\n",
      "Precision: 1.0 \n",
      "Recall: 0.9154929577464789 \n",
      "Aging Rate: 0.08397932816537468\n",
      "\u001b[32m[I 2021-12-05 18:30:00,580]\u001b[0m Trial 10 finished with value: 2.9298382889932184 and parameters: {'meta_learner': 'ExtraTrees', 'n_estimators': 500, 'min_samples_split': 7, 'max_depth': 21}. Best is trial 10 with value: 2.9298382889932184.\u001b[0m\n",
      "Precision: 0.9850746268656716 \n",
      "Recall: 0.9295774647887324 \n",
      "Aging Rate: 0.08656330749354005\n",
      "Precision: 0.9838709677419355 \n",
      "Recall: 0.8591549295774648 \n",
      "Aging Rate: 0.08010335917312661\n",
      "Precision: 0.9558823529411765 \n",
      "Recall: 0.9154929577464789 \n",
      "Aging Rate: 0.08785529715762273\n",
      "\u001b[32m[I 2021-12-05 18:30:02,787]\u001b[0m Trial 11 finished with value: 2.851293749070081 and parameters: {'meta_learner': 'ExtraTrees', 'n_estimators': 500, 'min_samples_split': 7, 'max_depth': 21}. Best is trial 10 with value: 2.9298382889932184.\u001b[0m\n",
      "Precision: 1.0 \n",
      "Recall: 0.9295774647887324 \n",
      "Aging Rate: 0.08527131782945736\n",
      "Precision: 0.9841269841269841 \n",
      "Recall: 0.8732394366197183 \n",
      "Aging Rate: 0.08139534883720931\n",
      "Precision: 0.9402985074626866 \n",
      "Recall: 0.8873239436619719 \n",
      "Aging Rate: 0.08656330749354005\n",
      "\u001b[32m[I 2021-12-05 18:30:04,958]\u001b[0m Trial 12 finished with value: 2.846330609416588 and parameters: {'meta_learner': 'ExtraTrees', 'n_estimators': 500, 'min_samples_split': 7, 'max_depth': 21}. Best is trial 10 with value: 2.9298382889932184.\u001b[0m\n",
      "Precision: 1.0 \n",
      "Recall: 0.9014084507042254 \n",
      "Aging Rate: 0.082687338501292\n",
      "Precision: 0.9855072463768116 \n",
      "Recall: 0.9577464788732394 \n",
      "Aging Rate: 0.08914728682170543\n",
      "Precision: 0.953125 \n",
      "Recall: 0.8591549295774648 \n",
      "Aging Rate: 0.082687338501292\n",
      "\u001b[32m[I 2021-12-05 18:30:07,167]\u001b[0m Trial 13 finished with value: 2.865191450636184 and parameters: {'meta_learner': 'ExtraTrees', 'n_estimators': 500, 'min_samples_split': 12, 'max_depth': 18}. Best is trial 10 with value: 2.9298382889932184.\u001b[0m\n",
      "Precision: 0.9285714285714286 \n",
      "Recall: 0.9154929577464789 \n",
      "Aging Rate: 0.09043927648578812\n",
      "Precision: 0.9714285714285714 \n",
      "Recall: 0.9577464788732394 \n",
      "Aging Rate: 0.09043927648578812\n",
      "Precision: 0.96875 \n",
      "Recall: 0.8732394366197183 \n",
      "Aging Rate: 0.082687338501292\n",
      "\u001b[32m[I 2021-12-05 18:30:09,361]\u001b[0m Trial 14 finished with value: 2.827992957746479 and parameters: {'meta_learner': 'ExtraTrees', 'n_estimators': 500, 'min_samples_split': 2, 'max_depth': 21}. Best is trial 10 with value: 2.9298382889932184.\u001b[0m\n",
      "Precision: 0.9838709677419355 \n",
      "Recall: 0.8591549295774648 \n",
      "Aging Rate: 0.08010335917312661\n",
      "Precision: 0.9565217391304348 \n",
      "Recall: 0.9295774647887324 \n",
      "Aging Rate: 0.08914728682170543\n",
      "Precision: 0.9545454545454546 \n",
      "Recall: 0.8873239436619719 \n",
      "Aging Rate: 0.08527131782945736\n",
      "\u001b[32m[I 2021-12-05 18:30:11,885]\u001b[0m Trial 15 finished with value: 2.8219775536212732 and parameters: {'meta_learner': 'ExtraTrees', 'n_estimators': 500, 'min_samples_split': 12, 'max_depth': 12}. Best is trial 10 with value: 2.9298382889932184.\u001b[0m\n",
      "Precision: 0.9850746268656716 \n",
      "Recall: 0.9295774647887324 \n",
      "Aging Rate: 0.08656330749354005\n",
      "Precision: 0.9855072463768116 \n",
      "Recall: 0.9577464788732394 \n",
      "Aging Rate: 0.08914728682170543\n",
      "Precision: 1.0 \n",
      "Recall: 0.9436619718309859 \n",
      "Aging Rate: 0.08656330749354005\n",
      "\u001b[32m[I 2021-12-05 18:30:14,113]\u001b[0m Trial 16 finished with value: 2.9240498873259746 and parameters: {'meta_learner': 'ExtraTrees', 'n_estimators': 500, 'min_samples_split': 7, 'max_depth': 18}. Best is trial 10 with value: 2.9298382889932184.\u001b[0m\n",
      "Precision: 0.9565217391304348 \n",
      "Recall: 0.9295774647887324 \n",
      "Aging Rate: 0.08914728682170543\n",
      "Precision: 0.9393939393939394 \n",
      "Recall: 0.8732394366197183 \n",
      "Aging Rate: 0.08527131782945736\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.9850746268656716 \n",
      "Recall: 0.9295774647887324 \n",
      "Aging Rate: 0.08656330749354005\n",
      "\u001b[32m[I 2021-12-05 18:30:15,799]\u001b[0m Trial 17 finished with value: 2.8314583256590917 and parameters: {'meta_learner': 'ExtraTrees', 'n_estimators': 300, 'min_samples_split': 12, 'max_depth': 18}. Best is trial 10 with value: 2.9298382889932184.\u001b[0m\n",
      "Precision: 0.9696969696969697 \n",
      "Recall: 0.9014084507042254 \n",
      "Aging Rate: 0.08527131782945736\n",
      "Precision: 0.9836065573770492 \n",
      "Recall: 0.8450704225352113 \n",
      "Aging Rate: 0.07881136950904392\n",
      "Precision: 0.9710144927536232 \n",
      "Recall: 0.9436619718309859 \n",
      "Aging Rate: 0.08914728682170543\n",
      "\u001b[32m[I 2021-12-05 18:30:15,950]\u001b[0m Trial 18 finished with value: 2.8462589615752356 and parameters: {'meta_learner': 'LogisticRegression', 'C': 1, 'penalty': 'none'}. Best is trial 10 with value: 2.9298382889932184.\u001b[0m\n",
      "Precision: 0.9682539682539683 \n",
      "Recall: 0.8591549295774648 \n",
      "Aging Rate: 0.08139534883720931\n",
      "Precision: 0.984375 \n",
      "Recall: 0.8873239436619719 \n",
      "Aging Rate: 0.082687338501292\n",
      "Precision: 0.9836065573770492 \n",
      "Recall: 0.8450704225352113 \n",
      "Aging Rate: 0.07881136950904392\n",
      "\u001b[32m[I 2021-12-05 18:30:18,133]\u001b[0m Trial 19 finished with value: 2.8213401156788946 and parameters: {'meta_learner': 'ExtraTrees', 'n_estimators': 500, 'min_samples_split': 7, 'max_depth': 18}. Best is trial 10 with value: 2.9298382889932184.\u001b[0m\n",
      "Precision: 0.9846153846153847 \n",
      "Recall: 0.9014084507042254 \n",
      "Aging Rate: 0.08397932816537468\n",
      "Precision: 0.9850746268656716 \n",
      "Recall: 0.9295774647887324 \n",
      "Aging Rate: 0.08656330749354005\n",
      "Precision: 0.9848484848484849 \n",
      "Recall: 0.9154929577464789 \n",
      "Aging Rate: 0.08527131782945736\n",
      "\u001b[32m[I 2021-12-05 18:30:19,832]\u001b[0m Trial 20 finished with value: 2.8851852886328397 and parameters: {'meta_learner': 'ExtraTrees', 'n_estimators': 300, 'min_samples_split': 17, 'max_depth': 21}. Best is trial 10 with value: 2.9298382889932184.\u001b[0m\n",
      "Precision: 0.9848484848484849 \n",
      "Recall: 0.9154929577464789 \n",
      "Aging Rate: 0.08527131782945736\n",
      "Precision: 0.9838709677419355 \n",
      "Recall: 0.8591549295774648 \n",
      "Aging Rate: 0.08010335917312661\n",
      "Precision: 0.9692307692307692 \n",
      "Recall: 0.8873239436619719 \n",
      "Aging Rate: 0.08397932816537468\n",
      "\u001b[32m[I 2021-12-05 18:30:21,034]\u001b[0m Trial 21 finished with value: 2.8459574248760986 and parameters: {'meta_learner': 'ExtraTrees', 'n_estimators': 100, 'min_samples_split': 17, 'max_depth': 21}. Best is trial 10 with value: 2.9298382889932184.\u001b[0m\n",
      "Precision: 0.9565217391304348 \n",
      "Recall: 0.9295774647887324 \n",
      "Aging Rate: 0.08914728682170543\n",
      "Precision: 0.9841269841269841 \n",
      "Recall: 0.8732394366197183 \n",
      "Aging Rate: 0.08139534883720931\n",
      "Precision: 1.0 \n",
      "Recall: 0.9436619718309859 \n",
      "Aging Rate: 0.08656330749354005\n",
      "\u001b[32m[I 2021-12-05 18:30:22,754]\u001b[0m Trial 22 finished with value: 2.875925439918092 and parameters: {'meta_learner': 'ExtraTrees', 'n_estimators': 300, 'min_samples_split': 22, 'max_depth': 18}. Best is trial 10 with value: 2.9298382889932184.\u001b[0m\n",
      "Precision: 0.9701492537313433 \n",
      "Recall: 0.9154929577464789 \n",
      "Aging Rate: 0.08656330749354005\n",
      "Precision: 0.9508196721311475 \n",
      "Recall: 0.8169014084507042 \n",
      "Aging Rate: 0.07881136950904392\n",
      "Precision: 0.9545454545454546 \n",
      "Recall: 0.8873239436619719 \n",
      "Aging Rate: 0.08527131782945736\n",
      "\u001b[32m[I 2021-12-05 18:30:25,186]\u001b[0m Trial 23 finished with value: 2.790249023558349 and parameters: {'meta_learner': 'ExtraTrees', 'n_estimators': 500, 'min_samples_split': 12, 'max_depth': 21}. Best is trial 10 with value: 2.9298382889932184.\u001b[0m\n",
      "Precision: 0.9710144927536232 \n",
      "Recall: 0.9436619718309859 \n",
      "Aging Rate: 0.08914728682170543\n",
      "Precision: 0.9696969696969697 \n",
      "Recall: 0.9014084507042254 \n",
      "Aging Rate: 0.08527131782945736\n",
      "Precision: 0.9848484848484849 \n",
      "Recall: 0.9154929577464789 \n",
      "Aging Rate: 0.08527131782945736\n",
      "\u001b[32m[I 2021-12-05 18:30:26,910]\u001b[0m Trial 24 finished with value: 2.8705610916266155 and parameters: {'meta_learner': 'ExtraTrees', 'n_estimators': 300, 'min_samples_split': 22, 'max_depth': 18}. Best is trial 10 with value: 2.9298382889932184.\u001b[0m\n",
      "Sampler is TPESampler\n"
     ]
    }
   ],
   "source": [
    "best_paramC, _ = all_optuna(all_data = train_firstC, \n",
    "                            mode = 'C', \n",
    "                            TPE_multi = False, \n",
    "                            n_iter = 10,\n",
    "                            filename = f'runhist_array_m2m4_m5_3criteria_StackingCV2',\n",
    "                            creator = stackingCV_creator\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Importance of Meta Learner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-03T04:04:52.390259Z",
     "start_time": "2021-12-03T04:04:42.393632Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "rank_importance(train_firstC['set7'], mode = 'C')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-05T10:30:44.861699Z",
     "start_time": "2021-12-05T10:30:30.364452Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2937684b6d0b41bdb2e39871d3e9ea1e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Dataset 0:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0 \n",
      "Recall: 0.0 \n",
      "Aging Rate: 0.0\n",
      "\n",
      " Dataset 1:\n",
      "Precision: 0.0012916717923483823 \n",
      "Recall: 0.4117647058823529 \n",
      "Aging Rate: 0.3341898086291599\n",
      "\n",
      " Dataset 2:\n",
      "Precision: 0.0012715293029707548 \n",
      "Recall: 0.43137254901960786 \n",
      "Aging Rate: 0.3556496536413904\n",
      "\n",
      " Dataset 3:\n",
      "Precision: 0.0011632133769538349 \n",
      "Recall: 0.6274509803921569 \n",
      "Aging Rate: 0.5654792493165327\n",
      "\n",
      " Dataset 4:\n",
      "Precision: 0.0015664373765579241 \n",
      "Recall: 0.45098039215686275 \n",
      "Aging Rate: 0.30181504244691565\n",
      "\n",
      " Dataset 5:\n",
      "Precision: 0.0016381693457561176 \n",
      "Recall: 0.3137254901960784 \n",
      "Aging Rate: 0.20076466114411395\n",
      "\n",
      " Dataset 6:\n",
      "Precision: 0.0013071262587141751 \n",
      "Recall: 0.5294117647058824 \n",
      "Aging Rate: 0.42459248905424574\n",
      "\n",
      " Dataset 7:\n",
      "Precision: 0.0013667992047713719 \n",
      "Recall: 0.6470588235294118 \n",
      "Aging Rate: 0.49628974901847933\n",
      "\n",
      " Dataset 8:\n",
      "Precision: 0.001261431725007884 \n",
      "Recall: 0.39215686274509803 \n",
      "Aging Rate: 0.32590597956792533\n",
      "\n",
      " Dataset 9:\n",
      "Precision: 0.001168664706325869 \n",
      "Recall: 0.6078431372549019 \n",
      "Aging Rate: 0.5452527287302925\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x576 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "table_setC, coefC = runall_LR(train_firstC_x, test_firstC_x, train_firstC_y, test_firstC_y, best_paramC)\n",
    "line_chart(table_setC, title = 'StackingCV Classifier (Scheme 2)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-05T10:30:48.480028Z",
     "start_time": "2021-12-05T10:30:48.449111Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Balance Ratio</th>\n",
       "      <th>Train_OK</th>\n",
       "      <th>Train_NG</th>\n",
       "      <th>TP</th>\n",
       "      <th>FP</th>\n",
       "      <th>FN</th>\n",
       "      <th>TN</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Aging Rate</th>\n",
       "      <th>Efficiency</th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>dataset 0</th>\n",
       "      <td>558.245552</td>\n",
       "      <td>156867.0</td>\n",
       "      <td>281.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>48598.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dataset 1</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>2758.0</td>\n",
       "      <td>2758.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>16237.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>32361.0</td>\n",
       "      <td>0.001292</td>\n",
       "      <td>0.411765</td>\n",
       "      <td>0.334190</td>\n",
       "      <td>1.232128</td>\n",
       "      <td>0.330629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dataset 2</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>3775.0</td>\n",
       "      <td>3775.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>17280.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>31318.0</td>\n",
       "      <td>0.001272</td>\n",
       "      <td>0.431373</td>\n",
       "      <td>0.355650</td>\n",
       "      <td>1.212914</td>\n",
       "      <td>0.342644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dataset 3</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>3084.0</td>\n",
       "      <td>3084.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>27478.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>21120.0</td>\n",
       "      <td>0.001163</td>\n",
       "      <td>0.627451</td>\n",
       "      <td>0.565479</td>\n",
       "      <td>1.109592</td>\n",
       "      <td>0.468389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dataset 4</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>2809.0</td>\n",
       "      <td>2809.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>14660.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>33938.0</td>\n",
       "      <td>0.001566</td>\n",
       "      <td>0.450980</td>\n",
       "      <td>0.301815</td>\n",
       "      <td>1.494228</td>\n",
       "      <td>0.412187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dataset 5</th>\n",
       "      <td>1.009339</td>\n",
       "      <td>2810.0</td>\n",
       "      <td>2784.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>9751.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>38847.0</td>\n",
       "      <td>0.001638</td>\n",
       "      <td>0.313725</td>\n",
       "      <td>0.200765</td>\n",
       "      <td>1.562653</td>\n",
       "      <td>0.295229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dataset 6</th>\n",
       "      <td>0.820198</td>\n",
       "      <td>2810.0</td>\n",
       "      <td>3426.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>20629.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>27969.0</td>\n",
       "      <td>0.001307</td>\n",
       "      <td>0.529412</td>\n",
       "      <td>0.424592</td>\n",
       "      <td>1.246870</td>\n",
       "      <td>0.428579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dataset 7</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>2810.0</td>\n",
       "      <td>2810.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>24111.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>24487.0</td>\n",
       "      <td>0.001367</td>\n",
       "      <td>0.647059</td>\n",
       "      <td>0.496290</td>\n",
       "      <td>1.303792</td>\n",
       "      <td>0.540007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dataset 8</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>2810.0</td>\n",
       "      <td>2810.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>15835.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>32763.0</td>\n",
       "      <td>0.001261</td>\n",
       "      <td>0.392157</td>\n",
       "      <td>0.325906</td>\n",
       "      <td>1.203282</td>\n",
       "      <td>0.309784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dataset 9</th>\n",
       "      <td>10.000000</td>\n",
       "      <td>2810.0</td>\n",
       "      <td>281.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>26495.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>22103.0</td>\n",
       "      <td>0.001169</td>\n",
       "      <td>0.607843</td>\n",
       "      <td>0.545253</td>\n",
       "      <td>1.114792</td>\n",
       "      <td>0.455248</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Balance Ratio  Train_OK  Train_NG    TP       FP    FN       TN  \\\n",
       "dataset 0     558.245552  156867.0     281.0   0.0      0.0  51.0  48598.0   \n",
       "dataset 1       1.000000    2758.0    2758.0  21.0  16237.0  30.0  32361.0   \n",
       "dataset 2       1.000000    3775.0    3775.0  22.0  17280.0  29.0  31318.0   \n",
       "dataset 3       1.000000    3084.0    3084.0  32.0  27478.0  19.0  21120.0   \n",
       "dataset 4       1.000000    2809.0    2809.0  23.0  14660.0  28.0  33938.0   \n",
       "dataset 5       1.009339    2810.0    2784.0  16.0   9751.0  35.0  38847.0   \n",
       "dataset 6       0.820198    2810.0    3426.0  27.0  20629.0  24.0  27969.0   \n",
       "dataset 7       1.000000    2810.0    2810.0  33.0  24111.0  18.0  24487.0   \n",
       "dataset 8       1.000000    2810.0    2810.0  20.0  15835.0  31.0  32763.0   \n",
       "dataset 9      10.000000    2810.0     281.0  31.0  26495.0  20.0  22103.0   \n",
       "\n",
       "           Precision    Recall  Aging Rate  Efficiency     Score  \n",
       "dataset 0   0.000000  0.000000    0.000000    0.000000       NaN  \n",
       "dataset 1   0.001292  0.411765    0.334190    1.232128  0.330629  \n",
       "dataset 2   0.001272  0.431373    0.355650    1.212914  0.342644  \n",
       "dataset 3   0.001163  0.627451    0.565479    1.109592  0.468389  \n",
       "dataset 4   0.001566  0.450980    0.301815    1.494228  0.412187  \n",
       "dataset 5   0.001638  0.313725    0.200765    1.562653  0.295229  \n",
       "dataset 6   0.001307  0.529412    0.424592    1.246870  0.428579  \n",
       "dataset 7   0.001367  0.647059    0.496290    1.303792  0.540007  \n",
       "dataset 8   0.001261  0.392157    0.325906    1.203282  0.309784  \n",
       "dataset 9   0.001169  0.607843    0.545253    1.114792  0.455248  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table_setC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-05T10:30:55.777521Z",
     "start_time": "2021-12-05T10:30:55.571074Z"
    }
   },
   "outputs": [],
   "source": [
    "savedate = '20220315'\n",
    "TPE_multi = False\n",
    "\n",
    "table_setC['sampler'] = 'multivariate-TPE' if TPE_multi else 'univariate-TPE'\n",
    "table_setC['model'] = 'StackingCV2'\n",
    "with pd.ExcelWriter(f'{savedate}_Classifier.xlsx', mode = 'a') as writer:\n",
    "    table_setC.to_excel(writer, sheet_name = 'StackingCV2')"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python [conda env:aging]",
   "language": "python",
   "name": "conda-env-aging-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
