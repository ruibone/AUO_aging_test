{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-06T12:22:49.122904Z",
     "start_time": "2021-11-06T12:22:47.821214Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\user\\\\Desktop\\\\Darui_R08621110'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.auto import tqdm\n",
    "import pickle\n",
    "import plotly\n",
    "\n",
    "from sklearn.ensemble import AdaBoostClassifier, AdaBoostRegressor\n",
    "from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor\n",
    "import optuna\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from library.Data_Preprocessing import Balance_Ratio\n",
    "from library.Imbalance_Sampling import label_divide\n",
    "from library.Aging_Score_Contour import score1\n",
    "\n",
    "os.chdir('C:/Users/user/Desktop/Darui_R08621110')  \n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load multiple dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-06T12:22:51.593611Z",
     "start_time": "2021-11-06T12:22:51.576854Z"
    }
   },
   "outputs": [],
   "source": [
    "def multiple_month(month_list, num_set, filename = 'dataset'):\n",
    "    \n",
    "    month_dict = {}\n",
    "    for i in month_list:\n",
    "        print(f'\\nMonth {i}:\\n')\n",
    "        month_dict[f'm{i}'] = multiple_set(num_set = num_set, filename = f'm{i}_{filename}')\n",
    "        trainset_x, trainset_y = train_set(month_dict[f'm{i}'], num_set = num_set)\n",
    "        \n",
    "    return month_dict, trainset_x, trainset_y\n",
    "\n",
    "\n",
    "def multiple_set(num_set, filename = 'dataset'):\n",
    "    \n",
    "    data_dict = {}\n",
    "    for i in range(num_set):\n",
    "        data_dict[f'set{i}'] = pd.read_csv(f'{filename}_{i}.csv').iloc[:, 1:]\n",
    "        print('Dimension of dataset', i, ':', data_dict[f'set{i}'].shape, ' balance ratio:', \\\n",
    "              Balance_Ratio(data_dict[f'set{i}']))\n",
    "    \n",
    "    print('\\n', num_set, 'datasets are loaded.')\n",
    "    return data_dict\n",
    "\n",
    "\n",
    "def train_set(data_dict, num_set, label = 'GB'):\n",
    "    \n",
    "    trainset_x = {}\n",
    "    trainset_y = {}\n",
    "    \n",
    "    for i in range(num_set):\n",
    "        X, Y = label_divide(data_dict[f'set{i}'], None, label, train_only = True)\n",
    "        trainset_x[f'set{i}'] = X\n",
    "        trainset_y[f'set{i}'] = Y\n",
    "        \n",
    "    print('\\nLabels of ', num_set, 'datasets are divided.')\n",
    "    return trainset_x, trainset_y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### for classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-06T12:22:53.669091Z",
     "start_time": "2021-11-06T12:22:53.661100Z"
    }
   },
   "outputs": [],
   "source": [
    "def cf_matrix(predict, train_y):\n",
    "    \n",
    "    # confusion matrix\n",
    "    mask_FP = predict['predict'] > predict['truth']\n",
    "    mask_FN = predict['predict'] < predict['truth']\n",
    "    mask_TP = (predict['predict'] == predict['truth']) * (predict['predict'] == 1)\n",
    "    mask_TN = (predict['predict'] == predict['truth']) * (predict['predict'] == 0)\n",
    "    TP = mask_TP.sum()\n",
    "    FP = mask_FP.sum()\n",
    "    FN = mask_FN.sum()\n",
    "    TN = mask_TN.sum()\n",
    "    \n",
    "    #balance ratio, train OK & NG\n",
    "    train_OK = sum(train_y < 0.5)\n",
    "    train_NG = len(train_y) - train_OK\n",
    "    br = train_OK / train_NG\n",
    "    \n",
    "    #precision, recall, aging rate, efficiency, score\n",
    "    num_pd = TP + FP\n",
    "    if num_pd != 0:\n",
    "        precision = TP / num_pd\n",
    "    else:\n",
    "        precision = 0\n",
    "    \n",
    "    recall = TP / (TP + FN)\n",
    "    ar = (TP + FP) / (TP + FP + FN + TN)\n",
    "    eff = recall / ar\n",
    "    score = score1(recall, ar)\n",
    "    \n",
    "    table = pd.Series({'Balance Ratio': br, 'Train_OK': train_OK, 'Train_NG': train_NG, 'TP': TP, 'FP': FP, 'FN': FN, \\\n",
    "                       'TN': TN, 'Precision': precision, 'Recall': recall, 'Aging Rate': ar, 'Efficiency': eff, \\\n",
    "                       'Score': score})\n",
    "    table = pd.DataFrame(table).T\n",
    "    \n",
    "    print('Precision:', precision, '\\nRecall:', recall, '\\nAging Rate:', ar)\n",
    "    return  table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### for regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-06T12:22:56.310236Z",
     "start_time": "2021-11-06T12:22:56.298263Z"
    }
   },
   "outputs": [],
   "source": [
    "def PR_matrix(predict, train_y, prob = 0.5):\n",
    "    \n",
    "    Y_new = predict.sort_values(['predict', 'truth'], ascending = [False, True]).reset_index(drop = True)\n",
    "    Y_new.loc[Y_new['truth'] != 1, 'truth'] = 0\n",
    "    \n",
    "    matrix = pd.DataFrame(Y_new.groupby('predict').sum()).rename(columns = {'truth': 'Bad_Count'})\n",
    "    matrix = matrix.sort_index(ascending = False)\n",
    "    matrix['All_Count'] = Y_new.groupby('predict').count()\n",
    "    matrix['Class_Prob'] = matrix.index\n",
    "    \n",
    "    matrix['train_OK'] = sum(train_y < 0.5)\n",
    "    matrix['train_NG'] = len(train_y) - matrix['train_OK'].values[0]\n",
    "    matrix['Balance Ratio'] = matrix['train_OK'] / matrix['train_NG']\n",
    "    \n",
    "    matrix['TP'] = matrix['Bad_Count'].cumsum()\n",
    "    matrix['FP'] = matrix['All_Count'].cumsum() - matrix['TP']\n",
    "    matrix['FN'] = matrix['TP'].values[-1] - matrix['TP']\n",
    "    matrix['TN'] = matrix['FP'].values[-1] - matrix['FP']\n",
    "    \n",
    "    matrix['Precision'] = matrix['TP'] / (matrix['TP'] + matrix['FP'])\n",
    "    matrix['Recall'] = matrix['TP'] / (matrix['TP'] + matrix['FN'])\n",
    "    matrix['Aging Rate'] = (matrix['TP'] + matrix['FP']) / (matrix['TP'] + matrix['FP'] + matrix['FN'] + matrix['TN'])\n",
    "    matrix['Efficiency'] = matrix['Recall'] / matrix['Aging Rate']\n",
    "    matrix['Score'] = score1(matrix['Recall'], matrix['Aging Rate'])\n",
    "              \n",
    "    matrix = matrix.drop(columns = ['Bad_Count', 'All_Count']).reset_index(drop = True)\n",
    "    \n",
    "    return matrix\n",
    "\n",
    "\n",
    "def best_threshold(pr_matrix, target, threshold = False):\n",
    "    \n",
    "    # input threshold, or find maximum\n",
    "    if threshold:\n",
    "        index = pr_matrix[pr_matrix[target] >= threshold].head(1).index.values[0]\n",
    "    else:\n",
    "        index = pr_matrix[target].idxmax()\n",
    "        \n",
    "    best_data = pr_matrix.loc[index]\n",
    "    best_thres = best_data['Class_Prob']\n",
    "    best_data = pd.DataFrame(best_data).T\n",
    "    print('Best Threshold:', best_thres, '\\n')\n",
    "    print('Recall:', best_data['Recall'].values, ',   Precision:', best_data['Precision'].values, \\\n",
    "          ',   Aging Rate:', best_data['Aging Rate'].values)\n",
    "\n",
    "    return best_data, best_thres"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-06T12:22:57.653039Z",
     "start_time": "2021-11-06T12:22:57.627096Z"
    }
   },
   "outputs": [],
   "source": [
    "def line_chart(table_set, title):\n",
    "    \n",
    "    plt.style.use('seaborn-dark-palette')\n",
    "    \n",
    "    x = list(range(len(table_set)))\n",
    "    fig, ax1 = plt.subplots(figsize = (15,8))\n",
    "    ax2 = ax1.twinx()\n",
    "    \n",
    "    plt.title(title, fontsize = 16)\n",
    "    plt.xticks(range(1,13,1))\n",
    "    ax1.plot(x, table_set['Aging Rate'], 'b--', linewidth = 1, label = 'Aging Rate')\n",
    "    ax1.plot(x, table_set['Aging Rate'], 'b.', markersize = 15)\n",
    "    ax1.plot(x, table_set['Recall'], 'r-', linewidth = 1, label = 'Recall')\n",
    "    ax1.plot(x, table_set['Recall'], 'r.', markersize = 15)\n",
    "    ax2.plot(x, table_set['Precision'], 'g--', linewidth = 1, label = 'Precision')\n",
    "    ax2.plot(x, table_set['Precision'], 'g.', markersize = 15)\n",
    "    ax1.set_xlabel('\\nDataset', fontsize = 12)\n",
    "    ax1.set_ylabel('Recall & Aging Rate', color = 'b')\n",
    "    ax2.set_ylabel('Precision', color = 'g')\n",
    "    \n",
    "    ax1.legend(loc = 'upper left', frameon = False)\n",
    "    ax2.legend(loc = 'upper right', frameon = False)\n",
    "    \n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "def AUC(x, y):\n",
    "    \n",
    "    area = 0\n",
    "    left = x[0]*y[0]\n",
    "    right = (1 - x[len(x)-1])*y[len(x)-1]\n",
    "    \n",
    "    for i in range(1, len(x)):\n",
    "        wide = x[i] - x[i-1]\n",
    "        height = (y[i-1] + y[i])/2\n",
    "        area = area + wide*height\n",
    "        \n",
    "    area = left + area + right\n",
    "    \n",
    "    return area\n",
    "\n",
    "\n",
    "def PR_curve(pr_matrix, best_data, title = 'PR_curve'):\n",
    "    \n",
    "    plt.plot(pr_matrix['Recall'], pr_matrix['Precision'], 'b-')\n",
    "    plt.plot(pr_matrix['Recall'], pr_matrix['Precision'], 'r.')\n",
    "    plt.plot(best_data['Recall'], best_data['Precision'], 'go', markersize = 10)\n",
    "    print('Precision, Recall, Aging Rate:', best_data['Precision'].values, best_data['Recall'].values, \n",
    "          best_data['Aging Rate'].values)\n",
    "    plt.xlabel('Recall')\n",
    "    plt.ylabel('Precision')\n",
    "    plt.title(f'{title}')\n",
    "    plt.show()\n",
    "    auc = AUC(pr_matrix['Recall'].values, pr_matrix['Precision'].values)\n",
    "    print('AUC: ', auc, '\\n')\n",
    "    \n",
    "    \n",
    "def multiple_curve(row_num, col_num, pr_dict, table_set, target = 'Aging Rate'):\n",
    "    \n",
    "    fig, axs = plt.subplots(row_num, col_num, sharex = False, sharey = False, figsize = (row_num*8 + 1, col_num*6))\n",
    "    plt.suptitle(f'{target} & Recall Curve of Dataset 0 - {len(table_set)}', y = 0.94, fontsize = 30)\n",
    "    \n",
    "    for row in range(row_num):\n",
    "        for col in range(col_num):\n",
    "            \n",
    "            index = col_num*row + col\n",
    "            if index < len(table_set) :\n",
    "                auc = AUC(pr_dict[f'set{index}']['Recall'].values, pr_dict[f'set{index}'][target].values).round(5)\n",
    "                ar = table_set[\"Aging Rate\"][index].round(3)\n",
    "                recall = table_set[\"Recall\"][index].round(3)\n",
    "                precision = table_set[\"Precision\"][index].round(5)\n",
    "\n",
    "                axs[row, col].plot(pr_dict[f'set{index}']['Recall'], pr_dict[f'set{index}'][target], 'b-')\n",
    "                axs[row, col].plot(pr_dict[f'set{index}']['Recall'], pr_dict[f'set{index}'][target], 'r.', markersize = 10)\n",
    "                axs[row, col].plot(table_set['Recall'][index], table_set[target][index], 'go', markersize = 15)\n",
    "                axs[row, col].set_xlabel('Recall')\n",
    "                axs[row, col].set_ylabel(target)\n",
    "\n",
    "                if target == 'Aging Rate':\n",
    "                    axs[row, col].set_title(f'dataset {index}, AUC = {auc}, Aging Rate = {ar}, Recall = {recall}, Precision = {precision}')\n",
    "                elif target == 'Precision':\n",
    "                    axs[row, col].set_title(f'dataset {index}, AUC = {auc}, Aging Rate = {ar}, Recall = {recall}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### adaboost "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-06T12:22:58.997087Z",
     "start_time": "2021-11-06T12:22:58.977141Z"
    }
   },
   "outputs": [],
   "source": [
    "def AdaBoostC(train_x, test_x, train_y, test_y, config):\n",
    "    \n",
    "    clf = AdaBoostClassifier(**config)\n",
    "    clf.fit(train_x, train_y)\n",
    "    predict_y = clf.predict(test_x)\n",
    "    result = pd.DataFrame({'truth': test_y, 'predict': predict_y})\n",
    "    \n",
    "    return result\n",
    "\n",
    "\n",
    "def AdaBoostR(train_x, test_x, train_y, test_y, config) :\n",
    "    \n",
    "    reg = AdaBoostRegressor(**config)\n",
    "    reg.fit(train_x, train_y)\n",
    "    predict_y = reg.predict(test_x)\n",
    "    result = pd.DataFrame({'truth': test_y, 'predict': predict_y})\n",
    "    \n",
    "    return result\n",
    "\n",
    "\n",
    "def runall_AdaBoostC(num_set, trainset_x, test_x, trainset_y, test_y, config):\n",
    "    \n",
    "    table_set = pd.DataFrame()\n",
    "    bad_set = pd.DataFrame()\n",
    "    judge = list(config.keys())[0]\n",
    "\n",
    "    for i in tqdm(range(num_set)):\n",
    "        print('\\n', f'Dataset {i}:')\n",
    "        \n",
    "        if isinstance(config[judge], dict) :\n",
    "            best_config = config[f'set{i}']\n",
    "        else :\n",
    "            best_config = config\n",
    "            \n",
    "        # seperate the decision tree hyperparameter and adaboost hyperparameter\n",
    "        tree_param = {'base_estimator': DecisionTreeClassifier(max_depth = best_config['max_depth'])}\n",
    "        boost_param = dict((key, best_config[key]) for key in ['learning_rate', 'n_estimators'] if key in best_config)\n",
    "        boost_param.update(tree_param)\n",
    "\n",
    "        result = AdaBoostC(trainset_x[f'set{i}'], test_x, trainset_y[f'set{i}'], test_y, boost_param)\n",
    "        table = cf_matrix(result, trainset_y[f'set{i}'])\n",
    "        table_set = pd.concat([table_set, table]).rename(index = {0: f'dataset {i}'})\n",
    "    \n",
    "    return table_set\n",
    "\n",
    "\n",
    "def runall_AdaBoostR(num_set, trainset_x, test_x, trainset_y, test_y, config, thres_target = 'Recall', threshold = False):\n",
    "    \n",
    "    table_set = pd.DataFrame()\n",
    "    bad_set = pd.DataFrame()\n",
    "    pr_dict = {}\n",
    "    judge = list(config.keys())[0]\n",
    "\n",
    "    for i in range(num_set):\n",
    "        print('\\n', f'Dataset {i}:')\n",
    "        \n",
    "        if isinstance(config[judge], dict) :\n",
    "            best_config = config[f'set{i}']\n",
    "        else :\n",
    "            best_config = config\n",
    "            \n",
    "        # seperate the decision tree hyperparameter and adaboost hyperparameter\n",
    "        tree_param = {'base_estimator': DecisionTreeRegressor(max_depth = best_config['max_depth'])}\n",
    "        boost_param = dict((key, best_config[key]) for key in ['learning_rate', 'n_estimators'] if key in best_config)\n",
    "        boost_param.update(tree_param)\n",
    "\n",
    "        predict = AdaBoostR(trainset_x[f'set{i}'], test_x, trainset_y[f'set{i}'], test_y, boost_param)\n",
    "        pr_matrix = PR_matrix(predict, trainset_y[f'set{i}'])\n",
    "        pr_dict[f'set{i}'] = pr_matrix\n",
    "        \n",
    "        best_data, best_thres = best_threshold(pr_matrix, target = thres_target, threshold = threshold)\n",
    "        table_set = pd.concat([table_set, best_data]).rename(index = {best_data.index.values[0]: f'dataset {i}'})\n",
    "        \n",
    "    return pr_dict, table_set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-06T12:23:00.454008Z",
     "start_time": "2021-11-06T12:23:00.425960Z"
    }
   },
   "outputs": [],
   "source": [
    "def AdaBoost_creator(train_data, mode, num_valid = 3):\n",
    "    \n",
    "    def objective(trial) :\n",
    "\n",
    "        tree_param = {\n",
    "            'max_depth': trial.suggest_int('max_depth', 1, 3)\n",
    "        }\n",
    "        \n",
    "        param = {\n",
    "            'n_estimators': trial.suggest_int('n_estimators', 100, 300, step = 50),\n",
    "            'learning_rate': trial.suggest_float('learning_rate', 0.025, 0.825, step = 0.05),\n",
    "        }\n",
    "        if mode == 'C':\n",
    "            base = {'base_estimator': DecisionTreeClassifier(**tree_param)}\n",
    "        elif mode == 'R':\n",
    "            base = {'base_estimator': DecisionTreeRegressor(**tree_param)}\n",
    "        param.update(base)\n",
    "\n",
    "\n",
    "        result_list = []\n",
    "        for i in range(num_valid):\n",
    "\n",
    "            train_x, train_y = label_divide(train_data, None, 'GB', train_only = True)\n",
    "            train_x, valid_x, train_y, valid_y = train_test_split(train_x, train_y, test_size = 0.25)\n",
    "\n",
    "            if mode == 'C':\n",
    "                result = AdaBoostC(train_x, valid_x, train_y, valid_y, param)\n",
    "                table = cf_matrix(result, valid_y)\n",
    "                recall = table['Recall']\n",
    "                aging = table['Aging Rate']\n",
    "                effi = table['Efficiency']\n",
    "                result_list.append(recall - 0.1*aging)\n",
    "                \n",
    "            elif mode == 'R':\n",
    "                result = AdaBoostR(train_x, valid_x, train_y, valid_y, param)\n",
    "                pr_matrix = PR_matrix(result, valid_y)\n",
    "                auc = AUC(pr_matrix['Recall'], pr_matrix['Aging Rate'])\n",
    "                result_list.append((-1)*auc)\n",
    "\n",
    "        return np.mean(result_list)\n",
    "    \n",
    "    return objective\n",
    "\n",
    "\n",
    "def all_optuna(num_set, all_data, mode, TPE_multi, n_iter, filename, creator, num_valid = 3, return_addition = True):\n",
    "\n",
    "    best_param = {}\n",
    "    all_score = {}\n",
    "    for i in tqdm(range(num_set)) :\n",
    "        \n",
    "        ##### define objective function and change optimized target dataset in each loop #####\n",
    "        objective = creator(train_data = all_data[f'set{i}'], mode = mode, num_valid = num_valid)\n",
    "        \n",
    "        ##### optimize one dataset in each loop #####\n",
    "        print(f'Dataset{i} :')\n",
    "        \n",
    "        study = optuna.create_study(sampler = optuna.samplers.TPESampler(multivariate = TPE_multi), \n",
    "                                       direction = 'maximize')\n",
    "        study.optimize(objective, n_trials = n_iter, show_progress_bar = True, gc_after_trial = True)\n",
    "        #n_trials or timeout\n",
    "        best_param[f'set{i}'] = study.best_trial.params\n",
    "        \n",
    "        ##### return score and entire params for score plot or feature importance\n",
    "        if return_addition :\n",
    "            collect_score = []\n",
    "            [collect_score.append(x.values) for x in study.trials]\n",
    "            all_score[f'set{i}'] = collect_score \n",
    "        \n",
    "        print(f\"Sampler is {study.sampler.__class__.__name__}\")\n",
    "    \n",
    "    ##### store the best hyperparameters #####\n",
    "    multi_mode = 'multivariate-TPE' if TPE_multi else 'univariate-TPE'\n",
    "    with open(f'{filename}{mode}_{multi_mode}_{n_iter}.data', 'wb') as f:\n",
    "        pickle.dump(best_param, f)\n",
    "    \n",
    "    if return_addition :\n",
    "        return best_param, all_score\n",
    "    else :\n",
    "        return best_param\n",
    "    \n",
    "\n",
    "def optuna_history(best_param, all_score, num_row, num_col, model):\n",
    "\n",
    "    fig, axs = plt.subplots(num_row, num_col, figsize = (num_row*10, num_col*5))\n",
    "    plt.suptitle(f'Optimization History of {model}', y = 0.94, fontsize = 25)    \n",
    "    for row in range(num_row):\n",
    "        for col in range(num_col):\n",
    "            index = num_col*row + col\n",
    "            \n",
    "            if index < len(best_param) :\n",
    "                axs[row, col].plot(range(len(all_score[f'set{index}'])), all_score[f'set{index}'], 'r-', linewidth = 1)\n",
    "                axs[row, col].set_title(f'Dataset {index}')\n",
    "                axs[row, col].set_xlabel('Iterations')\n",
    "                axs[row, col].set_ylabel('Values')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### loading training & testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-06T12:23:31.888170Z",
     "start_time": "2021-11-06T12:23:27.515817Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Month 1:\n",
      "\n",
      "Dimension of dataset 0 : (17735, 84)  balance ratio: 1181.0\n",
      "Dimension of dataset 1 : (444, 84)  balance ratio: 2.0\n",
      "Dimension of dataset 2 : (642, 84)  balance ratio: 2.0\n",
      "Dimension of dataset 3 : (492, 84)  balance ratio: 2.0\n",
      "Dimension of dataset 4 : (450, 84)  balance ratio: 2.0\n",
      "Dimension of dataset 5 : (448, 84)  balance ratio: 2.0\n",
      "Dimension of dataset 6 : (511, 84)  balance ratio: 1.0\n",
      "Dimension of dataset 7 : (457, 84)  balance ratio: 2.0\n",
      "Dimension of dataset 8 : (450, 84)  balance ratio: 2.0\n",
      "Dimension of dataset 9 : (165, 84)  balance ratio: 10.0\n",
      "\n",
      " 10 datasets are loaded.\n",
      "\n",
      "Labels of  10 datasets are divided.\n",
      "\n",
      "Month 2:\n",
      "\n",
      "Dimension of dataset 0 : (39009, 90)  balance ratio: 533.0\n",
      "Dimension of dataset 1 : (2190, 90)  balance ratio: 2.0\n",
      "Dimension of dataset 2 : (2820, 90)  balance ratio: 2.0\n",
      "Dimension of dataset 3 : (2406, 90)  balance ratio: 2.0\n",
      "Dimension of dataset 4 : (2190, 90)  balance ratio: 2.0\n",
      "Dimension of dataset 5 : (2190, 90)  balance ratio: 2.0\n",
      "Dimension of dataset 6 : (2414, 90)  balance ratio: 2.0\n",
      "Dimension of dataset 7 : (2226, 90)  balance ratio: 2.0\n",
      "Dimension of dataset 8 : (2190, 90)  balance ratio: 2.0\n",
      "Dimension of dataset 9 : (803, 90)  balance ratio: 10.0\n",
      "\n",
      " 10 datasets are loaded.\n",
      "\n",
      "Labels of  10 datasets are divided.\n",
      "\n",
      "Month 3:\n",
      "\n",
      "Dimension of dataset 0 : (60396, 92)  balance ratio: 443.0\n",
      "Dimension of dataset 1 : (4104, 92)  balance ratio: 2.0\n",
      "Dimension of dataset 2 : (5733, 92)  balance ratio: 2.0\n",
      "Dimension of dataset 3 : (4479, 92)  balance ratio: 2.0\n",
      "Dimension of dataset 4 : (4080, 92)  balance ratio: 2.0\n",
      "Dimension of dataset 5 : (4081, 92)  balance ratio: 2.0\n",
      "Dimension of dataset 6 : (4618, 92)  balance ratio: 1.0\n",
      "Dimension of dataset 7 : (4148, 92)  balance ratio: 2.0\n",
      "Dimension of dataset 8 : (4080, 92)  balance ratio: 2.0\n",
      "Dimension of dataset 9 : (1496, 92)  balance ratio: 10.0\n",
      "\n",
      " 10 datasets are loaded.\n",
      "\n",
      "Labels of  10 datasets are divided.\n",
      "\n",
      "Month 4:\n",
      "\n",
      "Dimension of dataset 0 : (57743, 99)  balance ratio: 433.0\n",
      "Dimension of dataset 1 : (3900, 99)  balance ratio: 2.0\n",
      "Dimension of dataset 2 : (4617, 99)  balance ratio: 2.0\n",
      "Dimension of dataset 3 : (4380, 99)  balance ratio: 2.0\n",
      "Dimension of dataset 4 : (3990, 99)  balance ratio: 2.0\n",
      "Dimension of dataset 5 : (3988, 99)  balance ratio: 2.0\n",
      "Dimension of dataset 6 : (4205, 99)  balance ratio: 2.0\n",
      "Dimension of dataset 7 : (4056, 99)  balance ratio: 2.0\n",
      "Dimension of dataset 8 : (3990, 99)  balance ratio: 2.0\n",
      "Dimension of dataset 9 : (1463, 99)  balance ratio: 10.0\n",
      "\n",
      " 10 datasets are loaded.\n",
      "\n",
      "Labels of  10 datasets are divided.\n",
      "\n",
      "Month 5:\n",
      "\n",
      "Dimension of dataset 0 : (48649, 93)  balance ratio: 415.0\n",
      "Dimension of dataset 1 : (3474, 93)  balance ratio: 2.0\n",
      "Dimension of dataset 2 : (4830, 93)  balance ratio: 2.0\n",
      "Dimension of dataset 3 : (3849, 93)  balance ratio: 2.0\n",
      "Dimension of dataset 4 : (3507, 93)  balance ratio: 2.0\n",
      "Dimension of dataset 5 : (3528, 93)  balance ratio: 2.0\n",
      "Dimension of dataset 6 : (3941, 93)  balance ratio: 1.0\n",
      "Dimension of dataset 7 : (3568, 93)  balance ratio: 2.0\n",
      "Dimension of dataset 8 : (3510, 93)  balance ratio: 2.0\n",
      "Dimension of dataset 9 : (1287, 93)  balance ratio: 10.0\n",
      "\n",
      " 10 datasets are loaded.\n",
      "\n",
      "Labels of  10 datasets are divided.\n",
      "\n",
      "Month 6:\n",
      "\n",
      "Dimension of dataset 0 : (7792, 71)  balance ratio: 1112.0\n",
      "Dimension of dataset 1 : (210, 71)  balance ratio: 2.0\n",
      "Dimension of dataset 2 : (255, 71)  balance ratio: 2.0\n",
      "Dimension of dataset 3 : (228, 71)  balance ratio: 2.0\n",
      "Dimension of dataset 4 : (210, 71)  balance ratio: 2.0\n",
      "Dimension of dataset 5 : (210, 71)  balance ratio: 2.0\n",
      "Dimension of dataset 6 : (223, 71)  balance ratio: 2.0\n",
      "Dimension of dataset 7 : (213, 71)  balance ratio: 2.0\n",
      "Dimension of dataset 8 : (210, 71)  balance ratio: 2.0\n",
      "Dimension of dataset 9 : (77, 71)  balance ratio: 10.0\n",
      "\n",
      " 10 datasets are loaded.\n",
      "\n",
      "Labels of  10 datasets are divided.\n",
      "\n",
      "Combined training data:\n",
      "\n",
      "Dimension of dataset 0 : (231324, 134)  balance ratio: 480.0\n",
      "Dimension of dataset 1 : (14322, 134)  balance ratio: 2.0\n",
      "Dimension of dataset 2 : (18897, 134)  balance ratio: 2.0\n",
      "Dimension of dataset 3 : (15834, 134)  balance ratio: 2.0\n",
      "Dimension of dataset 4 : (14427, 134)  balance ratio: 2.0\n",
      "Dimension of dataset 5 : (14445, 134)  balance ratio: 2.0\n",
      "Dimension of dataset 6 : (15912, 134)  balance ratio: 2.0\n",
      "Dimension of dataset 7 : (14668, 134)  balance ratio: 2.0\n",
      "Dimension of dataset 8 : (14430, 134)  balance ratio: 2.0\n",
      "Dimension of dataset 9 : (5291, 134)  balance ratio: 10.0\n",
      "\n",
      " 10 datasets are loaded.\n",
      "\n",
      "Labels of  10 datasets are divided.\n",
      "\n",
      " Dimension of testing data: (43243, 134)\n"
     ]
    }
   ],
   "source": [
    "### training data ### \n",
    "training_month = range(1, 7)\n",
    "\n",
    "data_dict, trainset_x, trainset_y = multiple_month(training_month, num_set = 10, filename = 'dataset')\n",
    "\n",
    "print('\\nCombined training data:\\n')\n",
    "run_train = multiple_set(num_set = 10)\n",
    "run_train_x, run_train_y = train_set(run_train, num_set = 10)\n",
    "\n",
    "### testing data ###\n",
    "run_test = pd.read_csv('test_runhist.csv').iloc[:, 2:]\n",
    "run_test_x, run_test_y = label_divide(run_test, None, 'GB', train_only = True)\n",
    "print('\\n', 'Dimension of testing data:', run_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### search for best hyperparameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-15T03:57:31.766174Z",
     "start_time": "2021-10-15T02:05:40.894251Z"
    }
   },
   "outputs": [],
   "source": [
    "best_paramC, all_scoreC = all_optuna(num_set = 10, \n",
    "                                     all_data = run_train, \n",
    "                                     mode = 'C', \n",
    "                                     TPE_multi = True, \n",
    "                                     n_iter = 25, \n",
    "                                     filename = 'runhist_array_m2m5_4selection_AdaBoost',\n",
    "                                     creator = AdaBoost_creator\n",
    "                                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-15T04:46:54.967209Z",
     "start_time": "2021-10-15T03:57:32.566126Z"
    }
   },
   "outputs": [],
   "source": [
    "best_paramR, all_scoreR = all_optuna(num_set = 10, \n",
    "                                     all_data = run_train, \n",
    "                                     mode = 'R', \n",
    "                                     TPE_multi = True, \n",
    "                                     n_iter = 25,\n",
    "                                     filename = 'runhist_array_m2m5_4selection_AdaBoost',\n",
    "                                     creator = AdaBoost_creator\n",
    "                                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### optimization history plot #####\n",
    "optuna_history(best_paramC, all_scoreC, num_row = 4, num_col = 3, model = 'AdaBoost Classifier')\n",
    "            \n",
    "##### best hyperparameter table #####\n",
    "param_table = pd.DataFrame(best_paramC).T\n",
    "param_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### constructing ......... #####\n",
    "study = optuna.create_study(sampler = optuna.samplers.TPESampler(multivariate = False), direction = 'maximize') \n",
    "#TPE, Random, Grid, CmaEs#\n",
    "objective = objective_creator(train_data = data_dict['set6'], mode = 'C', num_valid = 3)\n",
    "study.optimize(objective, n_trials = 5, show_progress_bar = True, gc_after_trial = True)\n",
    "\n",
    "\n",
    "##### hyperparameter importance #####\n",
    "#importances = optuna.importance.get_param_importances(study)\n",
    "#importances.optuna.importance.get_param_importances(study, evaluator = optuna.importance.FanovaImportanceEvaluator())\n",
    "importance_fig = optuna.visualization.plot_param_importances(study)\n",
    "slice_fig = optuna.visualization.plot_slice(study)\n",
    "importance_fig.show()\n",
    "slice_fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-15T04:50:15.861823Z",
     "start_time": "2021-10-15T04:46:55.782403Z"
    }
   },
   "outputs": [],
   "source": [
    "table_setC = runall_AdaBoostC(10, run_train_x, run_test_x, run_train_y, run_test_y, best_paramC)\n",
    "line_chart(table_setC, title = 'AdaBoost Classifier')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-15T04:50:16.711017Z",
     "start_time": "2021-10-15T04:50:16.695395Z"
    }
   },
   "outputs": [],
   "source": [
    "table_setC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-15T15:28:21.485694Z",
     "start_time": "2021-10-15T15:27:48.208319Z"
    }
   },
   "outputs": [],
   "source": [
    "pr_dict, table_setR = runall_AdaBoostR(10, run_train_x, run_test_x, run_train_y, run_test_y, best_paramR,\n",
    "                                      thres_target = 'Recall', threshold = 0.7)\n",
    "line_chart(table_setR, title = 'AdaBoost Regressor')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-15T15:29:31.012535Z",
     "start_time": "2021-10-15T15:29:29.203379Z"
    }
   },
   "outputs": [],
   "source": [
    "multiple_curve(4, 3, pr_dict, table_setR, target = 'Aging Rate')\n",
    "multiple_curve(4, 3, pr_dict, table_setR, target = 'Precision')\n",
    "table_setR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-15T04:51:03.479926Z",
     "start_time": "2021-10-15T04:51:03.073770Z"
    }
   },
   "outputs": [],
   "source": [
    "savedate = '20211019'\n",
    "TPE_multi = True\n",
    "\n",
    "table_setC['sampler'] = 'multivariate-TPE' if TPE_multi else 'univariate-TPE'\n",
    "table_setR['sampler'] = 'multivariate-TPE' if TPE_multi else 'univariate-TPE'\n",
    "table_setC['model'] = 'AdaBoost'\n",
    "table_setR['model'] = 'AdaBoost'\n",
    "with pd.ExcelWriter(f'{savedate}_Classifier.xlsx', mode = 'a') as writer:\n",
    "    table_setC.to_excel(writer, sheet_name = 'AdaBoost')\n",
    "with pd.ExcelWriter(f'{savedate}_Regressor.xlsx', mode = 'a') as writer:\n",
    "    table_setR.to_excel(writer, sheet_name = 'AdaBoost')"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python [conda env:aging]",
   "language": "python",
   "name": "conda-env-aging-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
