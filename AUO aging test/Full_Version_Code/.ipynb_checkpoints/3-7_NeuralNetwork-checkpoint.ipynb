{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-09T04:31:48.584447Z",
     "start_time": "2021-10-09T04:31:46.248350Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\user\\\\Desktop\\\\Darui_R08621110'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "import optuna\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader, Dataset, random_split\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "from library.Data_Preprocessing import Balance_Ratio\n",
    "from library.Imbalance_Sampling import label_divide\n",
    "from library.Aging_Score_Contour import score1\n",
    "from library.AdaBoost import train_set, multiple_set, multiple_month, line_chart, cf_matrix, AUC, PR_curve, \\\n",
    "     multiple_curve, PR_matrix, best_threshold, all_optuna, optuna_history \n",
    "\n",
    "os.chdir('C:/Users/user/Desktop/Darui_R08621110')  \n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-20T14:19:12.413119Z",
     "start_time": "2021-09-20T14:19:12.399160Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n"
     ]
    }
   ],
   "source": [
    "##### GPU ??? #####\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print('Using {} device'.format(device))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-20T14:19:16.224291Z",
     "start_time": "2021-09-20T14:19:16.207914Z"
    }
   },
   "outputs": [],
   "source": [
    "class RunhistSet(Dataset):\n",
    "    \n",
    "    def __init__(self, train_x, train_y):\n",
    "        self.x = torch.tensor(train_x.values.astype(np.float32))\n",
    "        self.y = torch.tensor(train_y.values.astype(np.float32)).long()\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.x)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return [self.x[idx], self.y[idx]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-20T14:19:17.801766Z",
     "start_time": "2021-09-20T14:19:17.779824Z"
    }
   },
   "outputs": [],
   "source": [
    "class NeuralNetwork(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        self.stack = nn.Sequential(\n",
    "            nn.Linear(140, 64),\n",
    "            nn.Sigmoid(),\n",
    "            nn.Dropout(0.25),\n",
    "            nn.Linear(64, 32),\n",
    "            nn.Sigmoid(),\n",
    "            nn.Dropout(0.25),\n",
    "            nn.Linear(32, 2)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        logits = self.stack(x)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-20T14:19:20.021066Z",
     "start_time": "2021-09-20T14:19:19.992779Z"
    }
   },
   "outputs": [],
   "source": [
    "def training(network, trainloader, validloader, optimizer, criterion, epoch, filename, early_stop = 10):\n",
    "    \n",
    "    network.train()\n",
    "    best_model = network\n",
    "    best_objective = 0\n",
    "    stop_trigger = 0\n",
    "    \n",
    "    for i in tqdm(range(epoch)):\n",
    "        total_loss = 0\n",
    "        TP = 0\n",
    "        TN = 0\n",
    "        FP = 0\n",
    "        FN = 0\n",
    "        \n",
    "        for x, y in trainloader:\n",
    "            \n",
    "            x = x.to(device)\n",
    "            y = y.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            output = network(x)\n",
    "            loss = criterion(output, y)\n",
    "            \n",
    "            _, predicted = torch.max(output.data, 1)\n",
    "            TP += torch.dot((predicted == y).to(torch.float32), (y == 1).to(torch.float32)).sum().item()\n",
    "            TN += torch.dot((predicted == y).to(torch.float32), (y == 0).to(torch.float32)).sum().item()\n",
    "            FN += torch.dot((predicted != y).to(torch.float32), (y == 1).to(torch.float32)).sum().item()\n",
    "            FP += torch.dot((predicted != y).to(torch.float32), (y == 0).to(torch.float32)).sum().item()\n",
    "            total_loss += loss.item()*len(y)\n",
    "            \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "        recall = TP / (TP + FN)\n",
    "        aging = (TP + FP) / (TP + TN + FP + FN)\n",
    "            \n",
    "        print(f'Epoch {i+1}: Train Loss = {total_loss / (TP + TN + FP + FN)}, Recall = {recall}, Aging Rate = {aging}')\n",
    "        \n",
    "        if ((i+1) % 5 == 0):\n",
    "            valid_recall, _ = testing(network, validloader, criterion)\n",
    "            \n",
    "            if valid_recall > best_objective:\n",
    "                best_objective = valid_recall\n",
    "                best_model = network\n",
    "                print(f'Model in epoch {i+1} is saved.\\n')\n",
    "                stop_trigger = 0\n",
    "            else:\n",
    "                stop_trigger += 1\n",
    "                print('')\n",
    "                \n",
    "            if stop_trigger == 10:\n",
    "                print(f'Training Finished at epoch {i+1}.')\n",
    "                return network\n",
    "\n",
    "    torch.save(best_model, f'{filename}_nn_{epoch}.ckpt')\n",
    "            \n",
    "    return network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-20T14:19:22.567986Z",
     "start_time": "2021-09-20T14:19:22.543845Z"
    }
   },
   "outputs": [],
   "source": [
    "def testing(network, dataloader, criterion):\n",
    "    \n",
    "    network.eval()\n",
    "    total_loss = 0\n",
    "    TP = 0\n",
    "    TN = 0\n",
    "    FP = 0\n",
    "    FN = 0\n",
    "    \n",
    "    for x, y in dataloader:\n",
    "        \n",
    "        x = x.to(device)\n",
    "        y = y.to(device)\n",
    "        output = network(x)\n",
    "        loss = criterion(output, y)\n",
    "        \n",
    "        _, predicted = torch.max(output.data, 1)\n",
    "        TP += torch.dot((predicted == y).to(torch.float32), (y == 1).to(torch.float32)).sum().item()\n",
    "        TN += torch.dot((predicted == y).to(torch.float32), (y == 0).to(torch.float32)).sum().item()\n",
    "        FN += torch.dot((predicted != y).to(torch.float32), (y == 1).to(torch.float32)).sum().item()\n",
    "        FP += torch.dot((predicted != y).to(torch.float32), (y == 0).to(torch.float32)).sum().item()\n",
    "        total_loss += loss.item()*len(y)\n",
    "        \n",
    "    recall = TP / (TP + FN)\n",
    "    aging = (TP + FP) / (TP + TN + FP + FN)\n",
    "    if (TP + FP) != 0:\n",
    "        precision = TP / (TP + FP)\n",
    "    else:\n",
    "        precision = 0\n",
    "    if aging != 0:\n",
    "        efficiency = recall / aging\n",
    "        score = score1(recall, aging)\n",
    "    else:\n",
    "        efficiency = 0\n",
    "        score = 0\n",
    "        \n",
    "    print(f'Test Loss = {total_loss / (TP + TN + FP + FN)}, Recall = {recall}, Aging Rate = {aging}, Efficiency = {recall / (aging + 1e-8)}')\n",
    "    \n",
    "    valid_objective = recall - 0.1*aging\n",
    "    table = pd.Series({'TP': TP, 'FP': FP, 'FN': FN, 'TN': TN, 'Precision': precision, 'Recall': recall, 'Aging Rate': aging,\\\n",
    "                       'Efficiency': efficiency, 'Score': score})\n",
    "    table = pd.DataFrame(table).T\n",
    "    \n",
    "    return valid_objective, table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run all datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-20T15:01:26.801804Z",
     "start_time": "2021-09-20T15:01:26.770789Z"
    }
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "EOL while scanning string literal (<ipython-input-21-1b93406d91a6>, line 5)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-21-1b93406d91a6>\"\u001b[1;36m, line \u001b[1;32m5\u001b[0m\n\u001b[1;33m    print(f'\\nStarting training Dataset {i}:)\u001b[0m\n\u001b[1;37m                                             ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m EOL while scanning string literal\n"
     ]
    }
   ],
   "source": [
    "def runall_nn(num_set, train_x, train_y, test_x, test_y, n_epoch, batch_size, model, optimizer, criterion, filename, train_ratio = 0.75, early_stop = 10):\n",
    "    \n",
    "    result_table = pd.DataFrame()\n",
    "    for i in tqdm(range(num_set)):\n",
    "        print(f'\\nStarting training Dataset {i}:)\n",
    "        \n",
    "        # data preparation\n",
    "        train_ratio = train_ratio\n",
    "        train_data = RunhistSet(train_x[f'set{i}'], train_y[f'set{i}'])\n",
    "        test_data = RunhistSet(test_x, test_y)\n",
    "        train_size = int(len(train_data)*train_ratio)\n",
    "        valid_size = len(train_data) - train_size\n",
    "        train_data, valid_data = random_split(train_data, [train_size, valid_size])\n",
    "        \n",
    "        train_loader = DataLoader(train_data, batch_size = batch_size, shuffle = True)\n",
    "        valid_loader = DataLoader(valid_data, batch_size = batch_size, shuffle = False)\n",
    "        test_loader = DataLoader(test_data, batch_size = batch_size, shuffle = False)\n",
    "        \n",
    "        # training\n",
    "        done_model = training(network = model, \n",
    "                      trainloader = train_loader, \n",
    "                      validloader = valid_loader, \n",
    "                      optimizer = optimizer, \n",
    "                      criterion = criterion, \n",
    "                      epoch = n_epoch, \n",
    "                      filename = filename, \n",
    "                      early_stop = early_stop)\n",
    "        \n",
    "        # testing\n",
    "        _, table = testing(done_model, test_loader, criterion)\n",
    "        result_table = pd.concat([result_table, table], axis = 0).rename({0: f'dataset {i}'})\n",
    "        \n",
    "    return result_table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### loading training & testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-20T14:21:14.197046Z",
     "start_time": "2021-09-20T14:21:12.328970Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimension of dataset 0 : (80518, 141)  balance ratio: 1101.9863\n",
      "Dimension of dataset 1 : (1634, 141)  balance ratio: 1.0\n",
      "Dimension of dataset 2 : (1498, 141)  balance ratio: 1.0\n",
      "Dimension of dataset 3 : (1752, 141)  balance ratio: 1.0\n",
      "Dimension of dataset 4 : (1608, 141)  balance ratio: 1.0\n",
      "Dimension of dataset 5 : (1618, 141)  balance ratio: 1.00496\n",
      "Dimension of dataset 6 : (1558, 141)  balance ratio: 1.08568\n",
      "Dimension of dataset 7 : (1622, 141)  balance ratio: 1.0\n",
      "Dimension of dataset 8 : (1622, 141)  balance ratio: 1.0\n",
      "Dimension of dataset 9 : (803, 141)  balance ratio: 10.0\n",
      "\n",
      " 10 datasets are loaded.\n",
      "\n",
      "Labels of  10 datasets are divided.\n",
      "\n",
      " Dimension of run test: (47725, 141)\n"
     ]
    }
   ],
   "source": [
    "### training data ### \n",
    "training_month = [2, 3, 4]\n",
    "\n",
    "data_dict, trainset_x, trainset_y = multiple_month(training_month, num_set = 10, filename = 'dataset')\n",
    "\n",
    "print('\\nCombined training data:\\n')\n",
    "run_train = multiple_set(num_set = 10)\n",
    "run_train_x, run_train_y = train_set(run_train, num_set = 10)\n",
    "\n",
    "### testing data ###\n",
    "run_test = pd.read_csv('test_runhist.csv').iloc[:, 2:]\n",
    "run_test_x, run_test_y = label_divide(run_test, None, 'GB', train_only = True)\n",
    "print('\\n', 'Dimension of testing data:', run_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For one dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-20T09:18:00.270342Z",
     "start_time": "2021-09-20T09:18:00.237432Z"
    }
   },
   "outputs": [],
   "source": [
    "##### data preparation #####\n",
    "train_data = RunhistSet(trainset_x['set4'], trainset_y['set4'])\n",
    "test_data = RunhistSet(run_test_x, run_test_y)\n",
    "train_ratio = 0.75\n",
    "train_size = int(len(train_data)*train_ratio)\n",
    "valid_size = len(train_data) - train_size\n",
    "train_data, valid_data = random_split(train_data, [train_size, valid_size])\n",
    "\n",
    "train_loader = DataLoader(train_data, batch_size = 64, shuffle = True)\n",
    "valid_loader = DataLoader(valid_data, batch_size = 64, shuffle = False)\n",
    "test_loader = DataLoader(test_data, batch_size = 64, shuffle = False)\n",
    "\n",
    "##### model preparation #####\n",
    "model = NeuralNetwork().to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = 0.001, weight_decay = 0.01)\n",
    "criterion = nn.CrossEntropyLoss(weight = torch.tensor([0.4, 0.6])).to(device)\n",
    "# hyperparameter: learning rate, weight decay, weight, label smoothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-20T09:18:14.111320Z",
     "start_time": "2021-09-20T09:18:11.623022Z"
    }
   },
   "outputs": [],
   "source": [
    "##### training #####\n",
    "done_model = training(network = model, \n",
    "                      trainloader = train_loader, \n",
    "                      validloader = valid_loader, \n",
    "                      optimizer = optimizer, \n",
    "                      criterion = criterion, \n",
    "                      epoch = 100, \n",
    "                      filename = 'tamama', \n",
    "                      early_stop = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-20T09:18:21.552099Z",
     "start_time": "2021-09-20T09:18:21.038205Z"
    }
   },
   "outputs": [],
   "source": [
    "##### testing #####\n",
    "_, result_table = testing(done_model, test_loader, criterion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For multiple datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-20T14:29:11.248775Z",
     "start_time": "2021-09-20T14:26:32.120227Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "277c8d8dbb444203889fe4459040b87a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training Dataset 0:\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "06fd2f23dcb64fb78be844a53254a871",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss = 0.08120626934756583, Recall = 0.0, Aging Rate = 0.008528184407498179\n",
      "Epoch 2: Train Loss = 0.024503601836866635, Recall = 0.0, Aging Rate = 0.0\n",
      "Epoch 3: Train Loss = 0.023910821019007156, Recall = 0.0, Aging Rate = 0.0\n",
      "Epoch 4: Train Loss = 0.023943725075172242, Recall = 0.0, Aging Rate = 0.0\n",
      "Epoch 5: Train Loss = 0.023874877245759044, Recall = 0.0, Aging Rate = 0.0\n",
      "Test Loss = 0.02391693502982872, Recall = 0.0, Aging Rate = 0.0, Efficiency = 0.0\n",
      "\n",
      "Epoch 6: Train Loss = 0.02302818769778946, Recall = 0.0, Aging Rate = 0.0\n",
      "Epoch 7: Train Loss = 0.023009763543724207, Recall = 0.0, Aging Rate = 0.0\n",
      "Epoch 8: Train Loss = 0.023067923232857744, Recall = 0.0, Aging Rate = 0.0\n",
      "Epoch 9: Train Loss = 0.023060421110770873, Recall = 0.0, Aging Rate = 0.0\n",
      "Epoch 10: Train Loss = 0.02304975494568183, Recall = 0.0, Aging Rate = 0.0\n",
      "Test Loss = 0.024789820548000763, Recall = 0.0, Aging Rate = 0.0, Efficiency = 0.0\n",
      "\n",
      "Test Loss = 0.02292120341236926, Recall = 0.0, Aging Rate = 0.0, Efficiency = 0.0\n",
      "Starting training Dataset 1:\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "070d88915f8c42398eec4f204b965343",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss = 1.3293751692771911, Recall = 0.0, Aging Rate = 0.0\n",
      "Epoch 2: Train Loss = 0.7366520606741613, Recall = 0.0, Aging Rate = 0.0\n",
      "Epoch 3: Train Loss = 0.7006878937993731, Recall = 0.0, Aging Rate = 0.0\n",
      "Epoch 4: Train Loss = 0.6927377773790944, Recall = 0.7623762376237624, Aging Rate = 0.7428571428571429\n",
      "Epoch 5: Train Loss = 0.6960785944121225, Recall = 1.0, Aging Rate = 1.0\n",
      "Test Loss = 0.6926573182667963, Recall = 1.0, Aging Rate = 1.0, Efficiency = 0.9999999900000002\n",
      "Model in epoch 5 is saved.\n",
      "\n",
      "Epoch 6: Train Loss = 0.6939183115959168, Recall = 0.31683168316831684, Aging Rate = 0.313469387755102\n",
      "Epoch 7: Train Loss = 0.6933628146015868, Recall = 0.0, Aging Rate = 0.0\n",
      "Epoch 8: Train Loss = 0.6932164643735301, Recall = 0.698019801980198, Aging Rate = 0.686530612244898\n",
      "Epoch 9: Train Loss = 0.6938128023731466, Recall = 0.8316831683168316, Aging Rate = 0.8359183673469388\n",
      "Epoch 10: Train Loss = 0.693139838588481, Recall = 0.0, Aging Rate = 0.0\n",
      "Test Loss = 0.6938727503883809, Recall = 0.0, Aging Rate = 0.0, Efficiency = 0.0\n",
      "\n",
      "Test Loss = 0.6755015383883257, Recall = 0.0, Aging Rate = 0.0, Efficiency = 0.0\n",
      "Starting training Dataset 2:\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "78676c5d66f04f588c5abd0485991872",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss = 0.6932177067546046, Recall = 0.0, Aging Rate = 0.0\n",
      "Epoch 2: Train Loss = 0.6932647598182529, Recall = 0.009009009009009009, Aging Rate = 0.008014247551202136\n",
      "Epoch 3: Train Loss = 0.6930421267039841, Recall = 0.2972972972972973, Aging Rate = 0.3045414069456812\n",
      "Epoch 4: Train Loss = 0.6933903227081707, Recall = 0.13693693693693693, Aging Rate = 0.13535173642030277\n",
      "Epoch 5: Train Loss = 0.69305076322063, Recall = 0.0018018018018018018, Aging Rate = 0.0008904719501335708\n",
      "Test Loss = 0.6938710454305013, Recall = 0.0, Aging Rate = 0.0, Efficiency = 0.0\n",
      "\n",
      "Epoch 6: Train Loss = 0.6937687322165641, Recall = 0.0, Aging Rate = 0.0\n",
      "Epoch 7: Train Loss = 0.6931140774716678, Recall = 0.1981981981981982, Aging Rate = 0.20213713268032057\n",
      "Epoch 8: Train Loss = 0.6932623735624875, Recall = 0.6792792792792792, Aging Rate = 0.6838824577025824\n",
      "Epoch 9: Train Loss = 0.6931705440884707, Recall = 0.436036036036036, Aging Rate = 0.45592163846838824\n",
      "Epoch 10: Train Loss = 0.6931973094400931, Recall = 0.0, Aging Rate = 0.0\n",
      "Test Loss = 0.6941812974611918, Recall = 0.0, Aging Rate = 0.0, Efficiency = 0.0\n",
      "\n",
      "Test Loss = 0.6709162119710051, Recall = 0.0, Aging Rate = 0.0, Efficiency = 0.0\n",
      "Starting training Dataset 3:\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f6041f5f3b18419e8ca91314dc3f8533",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss = 0.6935590572734583, Recall = 0.1386748844375963, Aging Rate = 0.15144596651445966\n",
      "Epoch 2: Train Loss = 0.6937540156293315, Recall = 0.030816640986132512, Aging Rate = 0.0273972602739726\n",
      "Epoch 3: Train Loss = 0.6932435896661546, Recall = 0.0, Aging Rate = 0.0\n",
      "Epoch 4: Train Loss = 0.6939739011556953, Recall = 0.0, Aging Rate = 0.0\n",
      "Epoch 5: Train Loss = 0.6935711097499552, Recall = 0.39599383667180277, Aging Rate = 0.408675799086758\n",
      "Test Loss = 0.6930101636337908, Recall = 1.0, Aging Rate = 1.0, Efficiency = 0.9999999900000002\n",
      "Model in epoch 5 is saved.\n",
      "\n",
      "Epoch 6: Train Loss = 0.6930881036471014, Recall = 0.20184899845916796, Aging Rate = 0.1948249619482496\n",
      "Epoch 7: Train Loss = 0.6933013873013187, Recall = 0.0, Aging Rate = 0.0\n",
      "Epoch 8: Train Loss = 0.6931481528318455, Recall = 0.0, Aging Rate = 0.0\n",
      "Epoch 9: Train Loss = 0.6935530102597706, Recall = 0.4576271186440678, Aging Rate = 0.487062404870624\n",
      "Epoch 10: Train Loss = 0.6931863141386476, Recall = 0.0, Aging Rate = 0.0\n",
      "Test Loss = 0.6937188269340828, Recall = 0.0, Aging Rate = 0.0, Efficiency = 0.0\n",
      "\n",
      "Test Loss = 0.6800078519543408, Recall = 0.0, Aging Rate = 0.0, Efficiency = 0.0\n",
      "Starting training Dataset 4:\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5add28290d9946f2b3578b8bb6c041ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss = 0.6935633382393946, Recall = 0.03782894736842105, Aging Rate = 0.0439469320066335\n",
      "Epoch 2: Train Loss = 0.6935376965782141, Recall = 0.712171052631579, Aging Rate = 0.7330016583747927\n",
      "Epoch 3: Train Loss = 0.6931895290441181, Recall = 0.9736842105263158, Aging Rate = 0.9709784411276948\n",
      "Epoch 4: Train Loss = 0.6936511600986247, Recall = 0.40789473684210525, Aging Rate = 0.43532338308457713\n",
      "Epoch 5: Train Loss = 0.6932200314986765, Recall = 0.3092105263157895, Aging Rate = 0.3208955223880597\n",
      "Test Loss = 0.6935137498438062, Recall = 1.0, Aging Rate = 1.0, Efficiency = 0.9999999900000002\n",
      "Model in epoch 5 is saved.\n",
      "\n",
      "Epoch 6: Train Loss = 0.6931842455816506, Recall = 1.0, Aging Rate = 1.0\n",
      "Epoch 7: Train Loss = 0.6932170799320214, Recall = 0.9457236842105263, Aging Rate = 0.9552238805970149\n",
      "Epoch 8: Train Loss = 0.6932892239904325, Recall = 0.8914473684210527, Aging Rate = 0.8938640132669984\n",
      "Epoch 9: Train Loss = 0.6932631976173489, Recall = 1.0, Aging Rate = 1.0\n",
      "Epoch 10: Train Loss = 0.693409264680758, Recall = 1.0, Aging Rate = 1.0\n",
      "Test Loss = 0.6934839709481196, Recall = 1.0, Aging Rate = 1.0, Efficiency = 0.9999999900000002\n",
      "\n",
      "Test Loss = 0.7042660295420008, Recall = 1.0, Aging Rate = 1.0, Efficiency = 0.9999999900000002\n",
      "Starting training Dataset 5:\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d2a1c480835549a99e5b7a8eb42755c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss = 0.6930341990841192, Recall = 0.7303182579564489, Aging Rate = 0.708161582852432\n",
      "Epoch 2: Train Loss = 0.6935087209482972, Recall = 0.0, Aging Rate = 0.0\n",
      "Epoch 3: Train Loss = 0.6932817414980336, Recall = 0.0, Aging Rate = 0.0008244023083264633\n",
      "Epoch 4: Train Loss = 0.6933527557395847, Recall = 0.3065326633165829, Aging Rate = 0.32481450948062657\n",
      "Epoch 5: Train Loss = 0.6931057924194367, Recall = 0.1574539363484087, Aging Rate = 0.15828524319868095\n",
      "Test Loss = 0.6944774530552051, Recall = 0.0, Aging Rate = 0.0, Efficiency = 0.0\n",
      "\n",
      "Epoch 6: Train Loss = 0.6932917674120457, Recall = 0.0, Aging Rate = 0.0\n",
      "Epoch 7: Train Loss = 0.6932042526589478, Recall = 0.0, Aging Rate = 0.0\n",
      "Epoch 8: Train Loss = 0.6933774467057073, Recall = 0.0, Aging Rate = 0.0\n",
      "Epoch 9: Train Loss = 0.6931721850160911, Recall = 0.0, Aging Rate = 0.0\n",
      "Epoch 10: Train Loss = 0.693617131428982, Recall = 0.0, Aging Rate = 0.0\n",
      "Test Loss = 0.6950308760007222, Recall = 0.0, Aging Rate = 0.0, Efficiency = 0.0\n",
      "\n",
      "Test Loss = 0.6591450787677136, Recall = 0.0, Aging Rate = 0.0, Efficiency = 0.0\n",
      "Starting training Dataset 6:\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb12b84036db4578878a74fefdb8b07d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss = 0.6922384222892866, Recall = 0.0, Aging Rate = 0.0\n",
      "Epoch 2: Train Loss = 0.6928022650823201, Recall = 0.0, Aging Rate = 0.0\n",
      "Epoch 3: Train Loss = 0.6924758210574111, Recall = 0.0, Aging Rate = 0.0\n",
      "Epoch 4: Train Loss = 0.6921786919032058, Recall = 0.0, Aging Rate = 0.0\n",
      "Epoch 5: Train Loss = 0.6919488449619241, Recall = 0.0, Aging Rate = 0.0\n",
      "Test Loss = 0.6942097908411271, Recall = 0.0, Aging Rate = 0.0, Efficiency = 0.0\n",
      "\n",
      "Epoch 6: Train Loss = 0.6926004445716126, Recall = 0.0, Aging Rate = 0.0\n",
      "Epoch 7: Train Loss = 0.6931256611053258, Recall = 0.0, Aging Rate = 0.0\n",
      "Epoch 8: Train Loss = 0.6921175032445829, Recall = 0.0, Aging Rate = 0.0\n",
      "Epoch 9: Train Loss = 0.692041278701939, Recall = 0.0, Aging Rate = 0.0\n",
      "Epoch 10: Train Loss = 0.6924666868497248, Recall = 0.0, Aging Rate = 0.0\n",
      "Test Loss = 0.6929368068010379, Recall = 0.0, Aging Rate = 0.0, Efficiency = 0.0\n",
      "\n",
      "Test Loss = 0.6730382628138618, Recall = 0.0, Aging Rate = 0.0, Efficiency = 0.0\n",
      "Starting training Dataset 7:\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ab57232a1564c1b8af45300a0d06464",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss = 0.6948743242966501, Recall = 0.004838709677419355, Aging Rate = 0.004111842105263158\n",
      "Epoch 2: Train Loss = 0.6940555886218422, Recall = 0.10967741935483871, Aging Rate = 0.11842105263157894\n",
      "Epoch 3: Train Loss = 0.6926850770649157, Recall = 0.9887096774193549, Aging Rate = 0.9901315789473685\n",
      "Epoch 4: Train Loss = 0.6935339789641531, Recall = 1.0, Aging Rate = 1.0\n",
      "Epoch 5: Train Loss = 0.6931254330434298, Recall = 1.0, Aging Rate = 1.0\n",
      "Test Loss = 0.6947571749757664, Recall = 1.0, Aging Rate = 1.0, Efficiency = 0.9999999900000002\n",
      "Model in epoch 5 is saved.\n",
      "\n",
      "Epoch 6: Train Loss = 0.6933192673482393, Recall = 1.0, Aging Rate = 1.0\n",
      "Epoch 7: Train Loss = 0.6930209115931862, Recall = 1.0, Aging Rate = 1.0\n",
      "Epoch 8: Train Loss = 0.6931095687966597, Recall = 1.0, Aging Rate = 1.0\n",
      "Epoch 9: Train Loss = 0.6932464932140551, Recall = 1.0, Aging Rate = 1.0\n",
      "Epoch 10: Train Loss = 0.6930036011495089, Recall = 1.0, Aging Rate = 1.0\n",
      "Test Loss = 0.6949865568447583, Recall = 1.0, Aging Rate = 1.0, Efficiency = 0.9999999900000002\n",
      "\n",
      "Test Loss = 0.7190197373960204, Recall = 1.0, Aging Rate = 1.0, Efficiency = 0.9999999900000002\n",
      "Starting training Dataset 8:\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4232f90781a4c93aca12ca767dff21f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss = 0.6939975964395624, Recall = 0.8580968280467446, Aging Rate = 0.8708881578947368\n",
      "Epoch 2: Train Loss = 0.6932883074409083, Recall = 0.17195325542570952, Aging Rate = 0.16858552631578946\n",
      "Epoch 3: Train Loss = 0.6929301305821067, Recall = 0.01001669449081803, Aging Rate = 0.007401315789473684\n",
      "Epoch 4: Train Loss = 0.6935923726935136, Recall = 0.0, Aging Rate = 0.0\n",
      "Epoch 5: Train Loss = 0.6931231523814955, Recall = 0.0, Aging Rate = 0.0\n",
      "Test Loss = 0.6939398564141372, Recall = 0.0, Aging Rate = 0.0, Efficiency = 0.0\n",
      "\n",
      "Epoch 6: Train Loss = 0.6931489455072504, Recall = 0.0, Aging Rate = 0.0\n",
      "Epoch 7: Train Loss = 0.6935467406323081, Recall = 0.7696160267111853, Aging Rate = 0.7894736842105263\n",
      "Epoch 8: Train Loss = 0.6932713954072249, Recall = 0.19365609348914858, Aging Rate = 0.21052631578947367\n",
      "Epoch 9: Train Loss = 0.6931200121578417, Recall = 0.0, Aging Rate = 0.0\n",
      "Epoch 10: Train Loss = 0.693215853289554, Recall = 0.0, Aging Rate = 0.0\n",
      "Test Loss = 0.6933373139409597, Recall = 0.0, Aging Rate = 0.0, Efficiency = 0.0\n",
      "\n",
      "Test Loss = 0.6890613430941398, Recall = 0.0, Aging Rate = 0.0, Efficiency = 0.0\n",
      "Starting training Dataset 9:\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a626b407c0ca4717b2dec2d48d83e603",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss = 0.6539677351812192, Recall = 0.10909090909090909, Aging Rate = 0.046511627906976744\n",
      "Epoch 2: Train Loss = 0.5020678382973338, Recall = 0.0, Aging Rate = 0.0\n",
      "Epoch 3: Train Loss = 0.37581106267894226, Recall = 0.0, Aging Rate = 0.0\n",
      "Epoch 4: Train Loss = 0.3209249127742856, Recall = 0.0, Aging Rate = 0.0\n",
      "Epoch 5: Train Loss = 0.311672672876884, Recall = 0.0, Aging Rate = 0.0\n",
      "Test Loss = 0.3018885214826954, Recall = 0.0, Aging Rate = 0.0, Efficiency = 0.0\n",
      "\n",
      "Epoch 6: Train Loss = 0.3064177812531937, Recall = 0.0, Aging Rate = 0.0\n",
      "Epoch 7: Train Loss = 0.3056437766235136, Recall = 0.0, Aging Rate = 0.0\n",
      "Epoch 8: Train Loss = 0.3056016832689114, Recall = 0.0, Aging Rate = 0.0\n",
      "Epoch 9: Train Loss = 0.30594213816810684, Recall = 0.0, Aging Rate = 0.0\n",
      "Epoch 10: Train Loss = 0.3061885410963103, Recall = 0.0, Aging Rate = 0.0\n",
      "Test Loss = 0.3019727779858148, Recall = 0.0, Aging Rate = 0.0, Efficiency = 0.0\n",
      "\n",
      "Test Loss = 0.10539291895188356, Recall = 0.0, Aging Rate = 0.0, Efficiency = 0.0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TP</th>\n",
       "      <th>FP</th>\n",
       "      <th>FN</th>\n",
       "      <th>TN</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Aging Rate</th>\n",
       "      <th>Efficiency</th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>dataset 0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>47691.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dataset 1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>47691.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dataset 2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>47691.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dataset 3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>47691.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dataset 4</th>\n",
       "      <td>34.0</td>\n",
       "      <td>47691.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000712</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dataset 5</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>47691.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dataset 6</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>47691.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dataset 7</th>\n",
       "      <td>34.0</td>\n",
       "      <td>47691.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000712</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dataset 8</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>47691.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dataset 9</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>47691.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             TP       FP    FN       TN  Precision  Recall  Aging Rate  \\\n",
       "dataset 0   0.0      0.0  34.0  47691.0   0.000000     0.0         0.0   \n",
       "dataset 1   0.0      0.0  34.0  47691.0   0.000000     0.0         0.0   \n",
       "dataset 2   0.0      0.0  34.0  47691.0   0.000000     0.0         0.0   \n",
       "dataset 3   0.0      0.0  34.0  47691.0   0.000000     0.0         0.0   \n",
       "dataset 4  34.0  47691.0   0.0      0.0   0.000712     1.0         1.0   \n",
       "dataset 5   0.0      0.0  34.0  47691.0   0.000000     0.0         0.0   \n",
       "dataset 6   0.0      0.0  34.0  47691.0   0.000000     0.0         0.0   \n",
       "dataset 7  34.0  47691.0   0.0      0.0   0.000712     1.0         1.0   \n",
       "dataset 8   0.0      0.0  34.0  47691.0   0.000000     0.0         0.0   \n",
       "dataset 9   0.0      0.0  34.0  47691.0   0.000000     0.0         0.0   \n",
       "\n",
       "           Efficiency  Score  \n",
       "dataset 0         0.0    0.0  \n",
       "dataset 1         0.0    0.0  \n",
       "dataset 2         0.0    0.0  \n",
       "dataset 3         0.0    0.0  \n",
       "dataset 4         1.0    0.0  \n",
       "dataset 5         0.0    0.0  \n",
       "dataset 6         0.0    0.0  \n",
       "dataset 7         1.0    0.0  \n",
       "dataset 8         0.0    0.0  \n",
       "dataset 9         0.0    0.0  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "runall_model = NeuralNetwork().to(device)\n",
    "runall_optimizer = torch.optim.Adam(runall_model.parameters(), lr = 0.001, weight_decay = 0.1)\n",
    "runall_criterion = nn.CrossEntropyLoss(weight = torch.tensor([0.5, 0.5])).to(device)\n",
    "\n",
    "runall_nn(num_set = 10, \n",
    "          train_x = trainset_x, \n",
    "          train_y = trainset_y, \n",
    "          test_x = run_test_x, \n",
    "          test_y = run_test_y, \n",
    "          n_epoch = 10, \n",
    "          batch_size = 128,\n",
    "          model = runall_model,\n",
    "          optimizer = runall_optimizer, \n",
    "          criterion = runall_criterion, \n",
    "          filename = 'tamama_desu', \n",
    "          train_ratio = 0.75, \n",
    "          early_stop = 10)"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python [conda env:aging]",
   "language": "python",
   "name": "conda-env-aging-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
