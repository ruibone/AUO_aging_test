{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-04T07:11:20.573270Z",
     "start_time": "2022-01-04T07:11:20.557649Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\user\\\\Desktop\\\\Darui_R08621110'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import random\n",
    "from tqdm.auto import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from lightgbm import LGBMClassifier\n",
    "import optuna\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from library.Data_Preprocessing import Balance_Ratio\n",
    "from library.Imbalance_Sampling import label_divide\n",
    "from library.Aging_Score_Contour import score1\n",
    "from library.AdaBoost import train_set, multiple_set, multiple_month, line_chart, cf_matrix\n",
    "\n",
    "os.chdir('C:/Users/user/Desktop/Darui_R08621110') \n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### balance cascade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-04T07:09:11.099558Z",
     "start_time": "2022-01-04T07:09:11.087592Z"
    }
   },
   "outputs": [],
   "source": [
    "def cascade_training(train_data, clf_config, classifier = 'LightGBM', num_iter = 10):\n",
    "  \n",
    "    good = train_data[train_data.GB == 0]\n",
    "    bad = train_data[train_data.GB == 1]\n",
    "    br = len(bad)/len(good)\n",
    "    false_rate = br**(1/(num_iter - 1))\n",
    "    \n",
    "    keep_good = {}\n",
    "    clf_threshold = []\n",
    "    clf_cascade = {}\n",
    "    for j, i in enumerate(range(num_iter)):\n",
    "        keep_good[j] = good\n",
    "        if j != (num_iter - 1):\n",
    "            draw = random.sample(good.index.to_list(), len(bad))\n",
    "            train_g = good.loc[draw]\n",
    "            train_b = bad.copy()\n",
    "            train_combine = pd.concat([train_g, train_b], axis = 0)\n",
    "        elif j == (num_iter - 1):\n",
    "            train_combine = pd.concat([good, bad], axis = 0)\n",
    "\n",
    "        valid_g = good.copy()\n",
    "        train_x, train_y, valid_x, valid_y = label_divide(train_combine, valid_g, 'GB', train_only = False)\n",
    "        if classifier == 'LightGBM':\n",
    "            clf = LGBMClassifier(**clf_config)\n",
    "        elif classifier == 'RandomForest':\n",
    "            clf = RandomForestClassifier(**clf_config)\n",
    "        clf.fit(train_x, train_y)\n",
    "        predict = clf.predict_proba(valid_x)[:, 1]\n",
    "        predict_df = pd.DataFrame(dict(predict = predict), index = valid_x.index)\n",
    "        predict_df = predict_df.sort_values(by = 'predict', ascending = False)\n",
    "        keep_num = int(len(predict_df)*false_rate)\n",
    "        keep_index = predict_df.index[:keep_num]\n",
    "        threshold = predict_df.loc[keep_index[-1]].values[0]\n",
    "        clf_threshold.append(threshold)\n",
    "        clf_cascade[j] = clf\n",
    "\n",
    "        if j != (num_iter - 1):\n",
    "            good = good.loc[keep_index]\n",
    "        \n",
    "        return clf_cascade, clf_threshold, keep_good\n",
    "    \n",
    "    \n",
    "def cascade_testing(test_data, clf_cascade, clf_threshold):\n",
    "    \n",
    "    if isinstance(clf_threshold, int):\n",
    "        clf_threshold = [clf_threshold]*len(clf_cascade)\n",
    "    \n",
    "    test_x, test_y = label_divide(test_data, 'GB', train_only = True)\n",
    "    predict_df = pd.DataFrame()\n",
    "    for i in range(len(clf_cascade)):\n",
    "        clf = clf_cascade[i]\n",
    "        predict = clf.predict_proba(test_x)[:, 1]\n",
    "        answer = (predict > clf_threshold[i]).astype(int)\n",
    "        predict = pd.DataFrame({str(i): answer})\n",
    "        predict_df = pd.concat([predict_df, predict], axis = 1)\n",
    "    predict_y = (predict_df.apply(sum, axis = 1) == len(clf_cascade)).astype(int)\n",
    "    result = pd.DataFrame(dict(predict = predict_y, truth = test_y))\n",
    "    \n",
    "    return result\n",
    "\n",
    "\n",
    "def runall_cascade(train_set, test_data, config, classifier = 'LightGBM', num_iter = 10):\n",
    "    \n",
    "    num_set = len(train_set)\n",
    "    table_set = pd.DataFrame()\n",
    "    for i in range(num_set):\n",
    "        print('\\n', f'Dataset {i}:')\n",
    "        clf_cascade, clf_threshold, _ = cascade_training(train_set[f'set{i}'], config[f'set{i}'], classifier = classifier,\n",
    "                                                        num_iter = num_iter)\n",
    "        result = cascade_testing(test_data, clf_cascade, clf_threshold)\n",
    "        table = cf_matrix(result, train_set[f'set{i}'].GB)\n",
    "        table_set = pd.concat([table_set, table]).rename(index = {0: f'dataset {i}'})\n",
    "    \n",
    "    return table_set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### loading hyperparameters & datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-04T07:09:12.896199Z",
     "start_time": "2022-01-04T07:09:12.865215Z"
    }
   },
   "outputs": [],
   "source": [
    "TPE_multi= False\n",
    "base_learner = 'LightGBM'\n",
    "\n",
    "iteration = 200 if base_learner == 'LightGBM' else 50\n",
    "TPE = 'multivariate-TPE' if TPE_multi else 'univariate-TPE'\n",
    "with open(f'hyperparameter/20211221/runhist_array_m2m4_m5_3criteria_{base_learner}C_{TPE}_{iteration}.data', 'rb') as f:\n",
    "    best_paramC = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-04T07:09:16.959554Z",
     "start_time": "2022-01-04T07:09:14.580059Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Month 2:\n",
      "\n",
      "Dimension of dataset 0 : (39009, 88)  balance ratio: 564.35\n",
      "Dimension of dataset 1 : (1404, 88)  balance ratio: 1.0\n",
      "Dimension of dataset 2 : (1928, 88)  balance ratio: 1.0\n",
      "Dimension of dataset 3 : (1514, 88)  balance ratio: 1.0\n",
      "Dimension of dataset 4 : (1378, 88)  balance ratio: 1.0\n",
      "Dimension of dataset 5 : (1370, 88)  balance ratio: 1.01\n",
      "Dimension of dataset 6 : (1659, 88)  balance ratio: 0.71\n",
      "Dimension of dataset 7 : (1380, 88)  balance ratio: 1.0\n",
      "Dimension of dataset 8 : (1380, 88)  balance ratio: 1.0\n",
      "Dimension of dataset 9 : (759, 88)  balance ratio: 10.0\n",
      "\n",
      " 10 datasets are loaded.\n",
      "\n",
      "Labels of  10 datasets are divided.\n",
      "\n",
      "Month 3:\n",
      "\n",
      "Dimension of dataset 0 : (60396, 97)  balance ratio: 533.48\n",
      "Dimension of dataset 1 : (2304, 97)  balance ratio: 1.0\n",
      "Dimension of dataset 2 : (3132, 97)  balance ratio: 1.0\n",
      "Dimension of dataset 3 : (2480, 97)  balance ratio: 1.0\n",
      "Dimension of dataset 4 : (2258, 97)  balance ratio: 1.0\n",
      "Dimension of dataset 5 : (2271, 97)  balance ratio: 0.99\n",
      "Dimension of dataset 6 : (2693, 97)  balance ratio: 0.72\n",
      "Dimension of dataset 7 : (2260, 97)  balance ratio: 1.0\n",
      "Dimension of dataset 8 : (2260, 97)  balance ratio: 1.0\n",
      "Dimension of dataset 9 : (1243, 97)  balance ratio: 10.0\n",
      "\n",
      " 10 datasets are loaded.\n",
      "\n",
      "Labels of  10 datasets are divided.\n",
      "\n",
      "Month 4:\n",
      "\n",
      "Dimension of dataset 0 : (57743, 100)  balance ratio: 472.3\n",
      "Dimension of dataset 1 : (2426, 100)  balance ratio: 1.0\n",
      "Dimension of dataset 2 : (3372, 100)  balance ratio: 1.0\n",
      "Dimension of dataset 3 : (2678, 100)  balance ratio: 1.0\n",
      "Dimension of dataset 4 : (2440, 100)  balance ratio: 1.0\n",
      "Dimension of dataset 5 : (2419, 100)  balance ratio: 1.02\n",
      "Dimension of dataset 6 : (2894, 100)  balance ratio: 0.73\n",
      "Dimension of dataset 7 : (2440, 100)  balance ratio: 1.0\n",
      "Dimension of dataset 8 : (2440, 100)  balance ratio: 1.0\n",
      "Dimension of dataset 9 : (1342, 100)  balance ratio: 10.0\n",
      "\n",
      " 10 datasets are loaded.\n",
      "\n",
      "Labels of  10 datasets are divided.\n",
      "\n",
      "Combined training data:\n",
      "\n",
      "Dimension of dataset 0 : (157148, 128)  balance ratio: 515.93\n",
      "Dimension of dataset 1 : (6134, 128)  balance ratio: 1.0\n",
      "Dimension of dataset 2 : (8432, 128)  balance ratio: 1.0\n",
      "Dimension of dataset 3 : (6672, 128)  balance ratio: 1.0\n",
      "Dimension of dataset 4 : (6076, 128)  balance ratio: 1.0\n",
      "Dimension of dataset 5 : (6060, 128)  balance ratio: 1.01\n",
      "Dimension of dataset 6 : (7246, 128)  balance ratio: 0.72\n",
      "Dimension of dataset 7 : (6080, 128)  balance ratio: 1.0\n",
      "Dimension of dataset 8 : (6080, 128)  balance ratio: 1.0\n",
      "Dimension of dataset 9 : (3344, 128)  balance ratio: 10.0\n",
      "\n",
      " 10 datasets are loaded.\n",
      "\n",
      "Labels of  10 datasets are divided.\n",
      "\n",
      " Dimension of testing data: (48649, 128)\n"
     ]
    }
   ],
   "source": [
    "### training data ###\n",
    "training_month = range(2, 5)\n",
    "\n",
    "data_dict, trainset_x, trainset_y = multiple_month(training_month, num_set = 10, filename = 'dataset')\n",
    "\n",
    "print('\\nCombined training data:\\n')\n",
    "run_train = multiple_set(num_set = 10)\n",
    "run_train_x, run_train_y = train_set(run_train, num_set = 10)\n",
    "\n",
    "### testing data ###\n",
    "run_test = pd.read_csv('test_runhist.csv').iloc[:, 2:]\n",
    "run_test_x, run_test_y = label_divide(run_test, None, 'GB', train_only = True)\n",
    "print('\\n', 'Dimension of testing data:', run_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-04T07:09:22.321841Z",
     "start_time": "2022-01-04T07:09:18.480594Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Dataset 0:\n",
      "Precision: 0.0010122277107458093 \n",
      "Recall: 0.49019607843137253 \n",
      "Aging Rate: 0.5076774445517893\n",
      "\n",
      " Dataset 1:\n",
      "Precision: 0.0010483257620917182 \n",
      "Recall: 1.0 \n",
      "Aging Rate: 1.0\n",
      "\n",
      " Dataset 2:\n",
      "Precision: 0.0010486706557275925 \n",
      "Recall: 1.0 \n",
      "Aging Rate: 0.9996711134864026\n",
      "\n",
      " Dataset 3:\n",
      "Precision: 0.0010483257620917182 \n",
      "Recall: 1.0 \n",
      "Aging Rate: 1.0\n",
      "\n",
      " Dataset 4:\n",
      "Precision: 0.0010484766251387689 \n",
      "Recall: 1.0 \n",
      "Aging Rate: 0.9998561121503011\n",
      "\n",
      " Dataset 5:\n",
      "Precision: 0.0010488863295148386 \n",
      "Recall: 1.0 \n",
      "Aging Rate: 0.9994655594154043\n",
      "\n",
      " Dataset 6:\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Sample larger than population or is negative",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-15344603a2bc>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtable_setC\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrunall_cascade\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrun_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbest_paramC\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclassifier\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbase_learner\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_iter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mline_chart\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtable_setC\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtitle\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'Balance Cascade Classifier (LightGBM)'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-2-da69ce7219c6>\u001b[0m in \u001b[0;36mrunall_cascade\u001b[1;34m(train_set, test_data, config, classifier, num_iter)\u001b[0m\n\u001b[0;32m     67\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'\\n'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34mf'Dataset {i}:'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     68\u001b[0m         clf_cascade, clf_threshold, _ = cascade_training(train_set[f'set{i}'], config[f'set{i}'], classifier = classifier,\n\u001b[1;32m---> 69\u001b[1;33m                                                         num_iter = num_iter)\n\u001b[0m\u001b[0;32m     70\u001b[0m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcascade_testing\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclf_cascade\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclf_threshold\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     71\u001b[0m         \u001b[0mtable\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcf_matrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_set\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34mf'set{i}'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mGB\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-2-da69ce7219c6>\u001b[0m in \u001b[0;36mcascade_training\u001b[1;34m(train_data, clf_config, classifier, num_iter)\u001b[0m\n\u001b[0;32m     12\u001b[0m         \u001b[0mkeep_good\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgood\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mj\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mnum_iter\u001b[0m \u001b[1;33m-\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m             \u001b[0mdraw\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msample\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgood\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbad\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m             \u001b[0mtrain_g\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgood\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdraw\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m             \u001b[0mtrain_b\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbad\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\aging\\lib\\random.py\u001b[0m in \u001b[0;36msample\u001b[1;34m(self, population, k)\u001b[0m\n\u001b[0;32m    319\u001b[0m         \u001b[0mn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpopulation\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    320\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;36m0\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[0mk\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[0mn\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 321\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Sample larger than population or is negative\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    322\u001b[0m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    323\u001b[0m         \u001b[0msetsize\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m21\u001b[0m        \u001b[1;31m# size of a small set minus size of an empty list\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Sample larger than population or is negative"
     ]
    }
   ],
   "source": [
    "table_setC = runall_cascade(run_train, run_test, best_paramC, classifier = base_learner, num_iter = 10)\n",
    "line_chart(table_setC, title = 'Balance Cascade Classifier (LightGBM)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table_setC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "savedate = '20211130'\n",
    "TPE_multi = False\n",
    "\n",
    "table_setC['sampler'] = 'multivariate-TPE' if TPE_multi else 'univariate-TPE'\n",
    "table_setC['model'] = 'BalanceCascade'\n",
    "with pd.ExcelWriter(f'{savedate}_Classifier.xlsx', mode = 'a') as writer:\n",
    "    table_setC.to_excel(writer, sheet_name = 'BalanceCascade')"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python [conda env:aging]",
   "language": "python",
   "name": "conda-env-aging-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
