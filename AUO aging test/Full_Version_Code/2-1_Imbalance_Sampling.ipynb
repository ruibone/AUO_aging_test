{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-26T09:53:14.756377Z",
     "start_time": "2022-03-26T09:53:13.579052Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\user\\\\Desktop\\\\Darui_R08621110'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import math\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.auto import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import smote_variants as sv\n",
    "from imblearn.under_sampling import RandomUnderSampler, TomekLinks, InstanceHardnessThreshold, NearMiss\n",
    "from imblearn.over_sampling import ADASYN, SMOTEN\n",
    "\n",
    "from library.Data_Preprocessing import Balance_Ratio, training_def\n",
    "from library.Training_Data_Processing import Corner, Kind\n",
    "\n",
    "os.chdir('C:/Users/user/Desktop/Darui_R08621110')\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-08T12:46:06.585171Z",
     "start_time": "2021-10-08T12:46:06.581097Z"
    }
   },
   "source": [
    "## "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-26T09:53:14.863255Z",
     "start_time": "2022-03-26T09:53:14.849504Z"
    }
   },
   "outputs": [],
   "source": [
    "# seperate a dataset into X & Y\n",
    "def label_divide(train, test, label = 'GB', train_only = False):\n",
    "    \n",
    "    train_x = train.drop(columns = label)\n",
    "    train_y = train[label]\n",
    "    \n",
    "    if not train_only:\n",
    "        test_x = test.drop(columns = label)\n",
    "        test_y = test[label]    \n",
    "        return train_x, train_y, test_x, test_y\n",
    "    else:\n",
    "        return train_x, train_y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Self-Defined Oversampling (Modified Border)\n",
    "first writen by ChungCheng Huang, and then modified "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-26T09:53:16.176055Z",
     "start_time": "2022-03-26T09:53:16.154105Z"
    }
   },
   "outputs": [],
   "source": [
    "# distance between instances\n",
    "def distance_matrix(data1, data2, triangle = False):\n",
    "    \n",
    "    data1 = np.array(data1.iloc[:, :-1])\n",
    "    data2 = np.array(data2.iloc[:, :-1])\n",
    "    dis_mat = pd.DataFrame((data1[:, None, :] != data2).sum(2))\n",
    "    if triangle:\n",
    "        dis_mat = dis_mat.where(np.triu(np.ones(dis_mat.shape)).astype(bool))\n",
    "    \n",
    "    return dis_mat\n",
    "\n",
    "\n",
    "# find the (row, col) given the dataframe & distance\n",
    "def get_indexes(dis_mat, value):\n",
    "\n",
    "    pos_list = []\n",
    "    # Get bool dataframe with True at positions where the given value exists\n",
    "    result = dis_mat.isin([value])\n",
    "    # Get list of columns that contains the value\n",
    "    col_target = result.any()\n",
    "    colnames = list(col_target[col_target == True].index)\n",
    "    # Iterate over list of columns and fetch the rows indexes where value exists\n",
    "    for col in colnames:\n",
    "        rows = list(result[col][result[col] == True].index)\n",
    "        for row in rows:\n",
    "            pos_list.append((row, col))\n",
    "    \n",
    "    return pos_list\n",
    "\n",
    "\n",
    "# smote between two given bad instances\n",
    "def perm(point_smote, cols_diff, num_over, farthest_generate = 3):\n",
    "    \n",
    "    generate_df = pd.DataFrame()\n",
    "    for i in range(num_over): # synthesize a new instances in every iteration\n",
    "        new_data = point_smote.copy()\n",
    "        change_num = random.sample(range(1, farthest_generate+1), 1)[0]\n",
    "        diff_index = cols_diff[cols_diff == True].index.tolist()\n",
    "        change_index = random.sample(diff_index, change_num)\n",
    "        for j in change_index: # change the index randomly selected based on central instance\n",
    "            new_data[j] = 1 if point_smote[j] == 0 else 0\n",
    "        new_df = pd.DataFrame(new_data).T\n",
    "        generate_df = pd.concat([generate_df, new_df], axis = 0)\n",
    "            \n",
    "    return generate_df\n",
    "\n",
    "\n",
    "# modified-border main function\n",
    "def Border(data, kind, max_distance, num_over, over_ratio = 1):\n",
    "    \n",
    "    good_num = len(data[data.GB == 0])\n",
    "    bad_num = len(data[data.GB == 1])\n",
    "    bad_kind = kind[kind.GB == 1]\n",
    "    full_kind = kind.iloc[:, :-1].copy()\n",
    "    training_df = pd.DataFrame()\n",
    "    \n",
    "    bad_dis = distance_matrix(bad_kind, bad_kind) # calculate the distance between bad instances\n",
    "    for dis in range(1, max_distance+1):\n",
    "        print(f'Distance = {dis} ...')\n",
    "        done = False\n",
    "        bad_indexes = get_indexes(bad_dis, dis) # given the specific distance and find the pair of bad instances\n",
    "        \n",
    "        smote_df = pd.DataFrame()\n",
    "        if len(bad_indexes) != 0:   \n",
    "            total_num = 0\n",
    "            for pair in bad_indexes:\n",
    "                point_0, point_1 = pair\n",
    "                point_smote = full_kind.loc[point_0].copy() # let point_0 be the initially central point of synthetic data\n",
    "                cols_diff = (full_kind.loc[point_0] != full_kind.loc[point_1]) # find the different cols between two bad\n",
    "                perm_df = perm(point_smote, cols_diff, int(num_over/2)) # generate new instances\n",
    "                smote_df = pd.concat([smote_df, perm_df], axis = 0)\n",
    "                total_num += len(perm_df)\n",
    "                \n",
    "                if (total_num + len(training_df) + bad_num) >= good_num*over_ratio: # synthetic bad instances are enough\n",
    "                    print(f'# over: {total_num}')\n",
    "                    done = True\n",
    "                    break\n",
    "            print(f'# over: {total_num}')\n",
    "                \n",
    "        training_df = pd.concat([training_df, smote_df], axis = 0)\n",
    "        training_df = training_df.drop_duplicates().reset_index(drop = True)\n",
    "        if done:\n",
    "            break\n",
    "    training_df['GB'] = 1\n",
    "    \n",
    "    return training_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-26T09:53:17.339454Z",
     "start_time": "2022-03-26T09:53:17.321491Z"
    }
   },
   "outputs": [],
   "source": [
    "# oversampling preparation\n",
    "def before_over(dataset, label = 'GB'):\n",
    "    \n",
    "    colnames = dataset.columns\n",
    "    Y = dataset[label]\n",
    "    Y = Y.reset_index(drop = True)\n",
    "    Y = np.array(Y)\n",
    "    X = dataset.drop(columns = [label])\n",
    "    X = X.reset_index(drop = True)\n",
    "    X = X.to_numpy()\n",
    "    \n",
    "    return X, Y, colnames\n",
    "\n",
    "\n",
    "# processing data afer oversampling\n",
    "def after_over(X, Y, colnames, back_to_category = False):\n",
    "    \n",
    "    colnames = colnames[:X.shape[1]]\n",
    "    X = pd.DataFrame(X, columns = colnames)\n",
    "    \n",
    "    if back_to_category:\n",
    "        for j in tqdm(range(X.shape[1])):\n",
    "            colvalue = X.iloc[:, j]\n",
    "            upper = np.array(colvalue[colvalue < 1])\n",
    "            lower = np.array(upper[upper > 0])\n",
    "            colmean = np.mean(lower)\n",
    "            \n",
    "            mask = colvalue >= colmean\n",
    "            X.iloc[mask, j] = 1\n",
    "            X.iloc[~mask, j] = 0\n",
    "    \n",
    "    Y = pd.Series(Y)\n",
    "    \n",
    "    return X, Y\n",
    "\n",
    "\n",
    "# apply oversampling methods\n",
    "def over_sample(X, Y, method, ratio, n_neighbors = 5, *args):\n",
    "    \n",
    "    method_list = ['NoSMOTE', 'SMOTE', 'MSMOTE', 'ROSE', 'SMOTEN', 'ADASYN']\n",
    "    if method not in method_list:\n",
    "        raise Exception('Invalid method !')\n",
    "    \n",
    "    if method == method_list[0]:\n",
    "        over_sampler = sv.NoSMOTE()\n",
    "    elif method == method_list[1]:\n",
    "        over_sampler = sv.SMOTE(ratio, n_neighbors)\n",
    "    elif method == method_list[2]:\n",
    "        over_sampler = sv.MSMOTE(ratio, n_neighbors)\n",
    "    elif method == method_list[3]:\n",
    "        over_sampler = sv.ROSE(ratio)   \n",
    "    elif method == method_list[4]:\n",
    "        over_sampler = SMOTEN(sampling_strategy = ratio, k_neighbors = n_neighbors)\n",
    "    elif method == method_list[5]:\n",
    "        over_sampler = ADASYN(sampling_strategy = ratio, n_neighbors = n_neighbors)    \n",
    "    \n",
    "    if method in method_list[0:4]:\n",
    "        over_X, over_Y = over_sampler.sample(X, Y)\n",
    "    else:\n",
    "        over_X, over_Y = over_sampler.fit_resample(X, Y)\n",
    "    \n",
    "    return over_X, over_Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Undersampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-26T09:53:18.504810Z",
     "start_time": "2022-03-26T09:53:18.497791Z"
    }
   },
   "outputs": [],
   "source": [
    "# undersampling preparation\n",
    "def before_under(dataset, label = 'GB'):\n",
    "    \n",
    "    Y = dataset[label]\n",
    "    X = dataset.drop(columns = [label])\n",
    "    \n",
    "    return X, Y\n",
    "\n",
    "\n",
    "# apply undersampling methods\n",
    "def under_sample(X, Y, method, ratio, *args):\n",
    "    \n",
    "    method_list = [None, 'random', 'Tomek', 'IHT', 'NM', 'one-sided', 'r-one-sided']\n",
    "    if method not in method_list:\n",
    "        raise Exception('Invalid method !')\n",
    "    \n",
    "    if method == method_list[0]:\n",
    "        return X, Y\n",
    "        \n",
    "    elif method == method_list[1]:\n",
    "        under_sampler = RandomUnderSampler(sampling_strategy = ratio)    \n",
    "    elif method == method_list[2]:\n",
    "        under_sampler = TomekLinks(sampling_strategy = 'majority')\n",
    "    elif method == method_list[3]:\n",
    "        under_sampler = InstanceHardnessThreshold(sampling_strategy = ratio, cv = 5, n_jobs = -1)\n",
    "    elif method in (method_list[4] + method_list[5]):\n",
    "        under_sampler = NearMiss(sampling_strategy = ratio, version = 2, n_jobs = -1)\n",
    "    elif method == method_list[6]:\n",
    "        under_sampler = InstanceHardnessThreshold(sampling_strategy = 1, cv = 5, n_jobs = -1)\n",
    "    \n",
    "    under_X, under_Y = under_sampler.fit_resample(X, Y)\n",
    "    \n",
    "    if method == method_list[5]:\n",
    "        second_sampler = InstanceHardnessThreshold(sampling_strategy = 1, cv = 5, n_jobs = -1)\n",
    "        under_X, under_Y = second_sampler.fit_resample(under_X, under_Y)\n",
    "    elif method == method_list[6]:\n",
    "        second_sampler = NearMiss(sampling_strategy = ratio, version = 2, n_jobs = -1)\n",
    "        under_X, under_Y = second_sampler.fit_resample(under_X, under_Y)\n",
    "    \n",
    "    return under_X, under_Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Protocol to Generate Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-26T09:53:19.662041Z",
     "start_time": "2022-03-26T09:53:19.650071Z"
    }
   },
   "outputs": [],
   "source": [
    "# resampling combination (undersampling first) \n",
    "def under_over(dataset, over_method, under_method, over_ratio, under_ratio, label = 'GB'):\n",
    "    \n",
    "    # undersampling\n",
    "    if under_method != None:\n",
    "        X, Y = before_under(dataset, label)\n",
    "        Y = Y.astype(int)\n",
    "        print('Size before Undersampling:', len(Y))\n",
    "        under_X, under_Y = under_sample(X, Y, under_method, under_ratio)\n",
    "        dataset = pd.concat([under_X, under_Y], axis = 1)\n",
    "        print('Size after Undersampling:', len(under_Y))\n",
    "    \n",
    "    # oversampling\n",
    "    temp_X, temp_Y, colnames = before_over(dataset, label)\n",
    "    print('Size before Oversampling:', len(temp_Y))\n",
    "    over_X, over_Y = over_sample(temp_X, temp_Y, over_method, over_ratio)\n",
    "    X, Y = after_over(over_X, over_Y, colnames)\n",
    "    print('Size after Oversampling:', len(Y))\n",
    "        \n",
    "    return X, Y\n",
    "\n",
    "\n",
    "# resampling combination (oversampling first)\n",
    "def over_under(dataset, over_method, under_method, over_ratio, under_ratio, label = 'GB') :\n",
    "    \n",
    "    # oversampling\n",
    "    if over_method != None :\n",
    "        X, Y, colnames = before_over(dataset, label)\n",
    "        print('Size before Oversampling:', len(Y))\n",
    "        temp_X, temp_Y = over_sample(X, Y, over_method, over_ratio)\n",
    "        over_X, over_Y = after_over(temp_X, temp_Y, colnames)\n",
    "        print('Size after Oversampling:', len(over_Y))\n",
    "        over_dataset = pd.concat([over_X, over_Y], axis = 1)\n",
    "        dataset = over_dataset.rename(columns = {0 : label})\n",
    "\n",
    "    # undersampling\n",
    "    X, Y = before_under(dataset, label)\n",
    "    Y = Y.astype(int)\n",
    "    under_X, under_Y = under_sample(X, Y, under_method, under_ratio)\n",
    "    print('Size after Undersampling:', len(under_Y))\n",
    "    \n",
    "    return under_X, under_Y\n",
    "    \n",
    "# main function to generating a resampling dataset\n",
    "def generate_set(train_data, over_method, under_method, index, over_ratio, under_ratio, order, label = 'GB'):\n",
    "    \n",
    "    print('\\n', f'Generating Dataset {index}')\n",
    "    if order == 'under' :\n",
    "        train_x, train_y = under_over(train_data, over_method, under_method, over_ratio, under_ratio, label)\n",
    "    elif order == 'over' :\n",
    "        train_x, train_y = over_under(train_data, over_method, under_method, over_ratio, under_ratio, label)\n",
    "        \n",
    "    train = pd.concat([train_x, train_y], axis = 1)\n",
    "    train = train.rename(columns = {0: label})\n",
    "    \n",
    "    return train\n",
    "\n",
    "\n",
    "# main function to generate a resampling dataset with border and undersampling technique\n",
    "def border_set(train_data, kind_data, under_method, index, num_over, over_ratio, under_ratio, order):\n",
    "    \n",
    "    ##### oversampling first #####\n",
    "    if order == 'over':\n",
    "        print('Size before Border:', len(train_data))    \n",
    "        OS_B = Border(train_data, kind_data, 25, num_over, over_ratio = over_ratio)\n",
    "        self_runhist = pd.concat([train_data, OS_B], axis = 0).reset_index(drop = True)\n",
    "        print('Size after Border:', len(self_runhist))\n",
    "        \n",
    "        dataset = generate_set(self_runhist, None, under_method, index, over_ratio = None, under_ratio = under_ratio, \n",
    "                               order = 'over')\n",
    "        print(f'Size after Undersampling:', dataset.shape, ', Balance Ratio:', Balance_Ratio(dataset))\n",
    "        \n",
    "        return dataset\n",
    "    \n",
    "    ##### undersampling first #####\n",
    "    elif order == 'under':\n",
    "        print('Size before Undersampling:', len(train_data))\n",
    "        self_under = generate_set(train_data, None, under_method, index, over_ratio = None, under_ratio = under_ratio, \n",
    "                                  order = 'over')\n",
    "        print('Size after Undersampling:', len(self_under))\n",
    "        \n",
    "        corner_overlap = Corner(self_under)\n",
    "        under_kind = Kind(corner_overlap).iloc[:, :-3]\n",
    "        US_B = Border(self_under, under_kind, 25, num_over, over_ratio = over_ratio)\n",
    "        dataset = pd.concat([self_under, US_B], axis = 0).reset_index(drop = True)\n",
    "        print('Size after Border:', dataset.shape, ', Balance Ratio:', Balance_Ratio(dataset))\n",
    "        \n",
    "        return dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading Relabeled Training Data & Kind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-26T09:53:22.802331Z",
     "start_time": "2022-03-26T09:53:21.537868Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Month 2:\n",
      "Dimension: (39009, 88) , # Bad: 69\n",
      "Month 3:\n",
      "Dimension: (60396, 97) , # Bad: 113\n",
      "Month 4:\n",
      "Dimension: (57743, 100) , # Bad: 122\n",
      "All Runhist Data:\n",
      " Dimension of : (157148, 128) , # Bad: 304 \n",
      "\n",
      "Month 2:\n",
      "# kinds: 23088\n",
      "Month 3:\n",
      "# kinds: 33754\n",
      "Month 4:\n",
      "# kinds: 32861\n"
     ]
    }
   ],
   "source": [
    "##### training data #####\n",
    "training_month = range(2, 5)\n",
    "\n",
    "runhist = {}\n",
    "for i in training_month:\n",
    "    runhist[f'm{i}'] = pd.read_csv(f'relabel_runhist_m{i}.csv', index_col = 'id').iloc[:, 1:]\n",
    "    print(f'Month {i}:')\n",
    "    print(f'Dimension:', runhist[f'm{i}'].shape, ', # Bad:', sum(runhist[f'm{i}'].GB))\n",
    "runhist['all'] = training_def(runhist, training_month)\n",
    "print('All Runhist Data:\\n', 'Dimension of :', runhist['all'].shape, ', # Bad:', sum(runhist['all'].GB), '\\n')\n",
    "\n",
    "##### kind data (for border only) #####\n",
    "kinds = {}\n",
    "for i in training_month:\n",
    "    kinds[f'm{i}'] = pd.read_csv(f'kind_m{i}.csv').iloc[:, 2:-3]\n",
    "    print(f'Month {i}:')\n",
    "    print(f'# kinds:', len(kinds[f'm{i}']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Oversampling & Undersampling Combination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-28T03:45:11.177098Z",
     "start_time": "2022-03-28T03:43:24.786747Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1441f71bd68c4ec9b8fe5af2d3ee6f90",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Month 2:\n",
      "# bad: 69\n",
      "Size before Border: 39009\n",
      "Distance = 1 ...\n",
      "Distance = 2 ...\n",
      "Distance = 3 ...\n",
      "Distance = 4 ...\n",
      "Distance = 5 ...\n",
      "Distance = 6 ...\n",
      "Distance = 7 ...\n",
      "Distance = 8 ...\n",
      "# over: 10\n",
      "Distance = 9 ...\n",
      "# over: 10\n",
      "Distance = 10 ...\n",
      "# over: 10\n",
      "Distance = 11 ...\n",
      "# over: 50\n",
      "Distance = 12 ...\n",
      "# over: 30\n",
      "Distance = 13 ...\n",
      "# over: 70\n",
      "Distance = 14 ...\n",
      "# over: 70\n",
      "Distance = 15 ...\n",
      "# over: 240\n",
      "Distance = 16 ...\n",
      "# over: 155\n",
      "# over: 155\n",
      "Size after Border: 39623\n",
      "\n",
      " Generating Dataset 2\n",
      "Size after Undersampling: 1366\n",
      "Size after Undersampling: (1366, 88) , Balance Ratio: 1.0\n",
      "Size before Undersampling: 39009\n",
      "\n",
      " Generating Dataset 6\n",
      "Size after Undersampling: 759\n",
      "Size after Undersampling: 759\n",
      "Distance = 1 ...\n",
      "Distance = 2 ...\n",
      "Distance = 3 ...\n",
      "Distance = 4 ...\n",
      "Distance = 5 ...\n",
      "Distance = 6 ...\n",
      "Distance = 7 ...\n",
      "Distance = 8 ...\n",
      "# over: 10\n",
      "Distance = 9 ...\n",
      "# over: 10\n",
      "Distance = 10 ...\n",
      "# over: 10\n",
      "Distance = 11 ...\n",
      "# over: 50\n",
      "Distance = 12 ...\n",
      "# over: 30\n",
      "Distance = 13 ...\n",
      "# over: 70\n",
      "Distance = 14 ...\n",
      "# over: 70\n",
      "Distance = 15 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-28 11:43:29,005:INFO:NoSMOTE: Running sampling via ('NoSMOTE', '{}')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# over: 240\n",
      "Distance = 16 ...\n",
      "# over: 160\n",
      "# over: 160\n",
      "Size after Border: (1379, 88) , Balance Ratio: 1.0\n",
      "\n",
      " Generating Dataset 0\n",
      "Size before Oversampling: 39009\n",
      "Size after Oversampling: 39009\n",
      "Size after Undersampling: 39009\n",
      "\n",
      " Generating Dataset 1\n",
      "Size before Oversampling: 39009\n",
      "Size after Oversampling: 39642\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-28 11:43:31,067:INFO:ROSE: Running sampling via ('ROSE', \"{'proportion': 0.01594755027908213, 'random_state': None}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size after Undersampling: 1404\n",
      "\n",
      " Generating Dataset 3\n",
      "Size before Oversampling: 39009\n",
      "Size after Oversampling: 39628\n",
      "Size after Undersampling: 1376\n",
      "\n",
      " Generating Dataset 4\n",
      "Size before Oversampling: 39009\n",
      "Size after Oversampling: 39629\n",
      "Size after Undersampling: 1378\n",
      "\n",
      " Generating Dataset 5\n",
      "Size before Undersampling: 39009\n",
      "Size after Undersampling: 759\n",
      "Size before Oversampling: 759\n",
      "Size after Oversampling: 1370\n",
      "\n",
      " Generating Dataset 7\n",
      "Size before Undersampling: 39009\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-28 11:43:37,398:INFO:ROSE: Running sampling via ('ROSE', \"{'proportion': 0.9, 'random_state': None}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size after Undersampling: 759\n",
      "Size before Oversampling: 759\n",
      "Size after Oversampling: 1317\n",
      "\n",
      " Generating Dataset 8\n",
      "Size before Undersampling: 39009\n",
      "Size after Undersampling: 759\n",
      "Size before Oversampling: 759\n",
      "Size after Oversampling: 1380\n",
      "\n",
      " Generating Dataset 9\n",
      "Size after Undersampling: 759\n",
      "Month 3:\n",
      "# bad: 113\n",
      "Size before Border: 60396\n",
      "Distance = 1 ...\n",
      "Distance = 2 ...\n",
      "Distance = 3 ...\n",
      "Distance = 4 ...\n",
      "Distance = 5 ...\n",
      "# over: 20\n",
      "Distance = 6 ...\n",
      "Distance = 7 ...\n",
      "Distance = 8 ...\n",
      "Distance = 9 ...\n",
      "# over: 20\n",
      "Distance = 10 ...\n",
      "# over: 10\n",
      "Distance = 11 ...\n",
      "# over: 10\n",
      "Distance = 12 ...\n",
      "# over: 50\n",
      "Distance = 13 ...\n",
      "# over: 110\n",
      "Distance = 14 ...\n",
      "# over: 100\n",
      "Distance = 15 ...\n",
      "# over: 170\n",
      "Distance = 16 ...\n",
      "# over: 310\n",
      "Distance = 17 ...\n",
      "# over: 260\n",
      "# over: 260\n",
      "Size after Border: 61405\n",
      "\n",
      " Generating Dataset 2\n",
      "Size after Undersampling: 2244\n",
      "Size after Undersampling: (2244, 97) , Balance Ratio: 1.0\n",
      "Size before Undersampling: 60396\n",
      "\n",
      " Generating Dataset 6\n",
      "Size after Undersampling: 1243\n",
      "Size after Undersampling: 1243\n",
      "Distance = 1 ...\n",
      "Distance = 2 ...\n",
      "Distance = 3 ...\n",
      "Distance = 4 ...\n",
      "Distance = 5 ...\n",
      "# over: 20\n",
      "Distance = 6 ...\n",
      "Distance = 7 ...\n",
      "Distance = 8 ...\n",
      "Distance = 9 ...\n",
      "# over: 20\n",
      "Distance = 10 ...\n",
      "# over: 10\n",
      "Distance = 11 ...\n",
      "# over: 10\n",
      "Distance = 12 ...\n",
      "# over: 50\n",
      "Distance = 13 ...\n",
      "# over: 110\n",
      "Distance = 14 ...\n",
      "# over: 100\n",
      "Distance = 15 ...\n",
      "# over: 170\n",
      "Distance = 16 ...\n",
      "# over: 310\n",
      "Distance = 17 ...\n",
      "# over: 265\n",
      "# over: 265\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-28 11:43:50,845:INFO:NoSMOTE: Running sampling via ('NoSMOTE', '{}')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size after Border: (2245, 97) , Balance Ratio: 1.01\n",
      "\n",
      " Generating Dataset 0\n",
      "Size before Oversampling: 60396\n",
      "Size after Oversampling: 60396\n",
      "Size after Undersampling: 60396\n",
      "\n",
      " Generating Dataset 1\n",
      "Size before Oversampling: 60396\n",
      "Size after Oversampling: 61435\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-28 11:43:56,564:INFO:ROSE: Running sampling via ('ROSE', \"{'proportion': 0.016870360650821023, 'random_state': None}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size after Undersampling: 2304\n",
      "\n",
      " Generating Dataset 3\n",
      "Size before Oversampling: 60396\n",
      "Size after Oversampling: 61411\n",
      "Size after Undersampling: 2256\n",
      "\n",
      " Generating Dataset 4\n",
      "Size before Oversampling: 60396\n",
      "Size after Oversampling: 61412\n",
      "Size after Undersampling: 2258\n",
      "\n",
      " Generating Dataset 5\n",
      "Size before Undersampling: 60396\n",
      "Size after Undersampling: 1243\n",
      "Size before Oversampling: 1243\n",
      "Size after Oversampling: 2271\n",
      "\n",
      " Generating Dataset 7\n",
      "Size before Undersampling: 60396\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-28 11:44:13,018:INFO:ROSE: Running sampling via ('ROSE', \"{'proportion': 0.9, 'random_state': None}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size after Undersampling: 1243\n",
      "Size before Oversampling: 1243\n",
      "Size after Oversampling: 2158\n",
      "\n",
      " Generating Dataset 8\n",
      "Size before Undersampling: 60396\n",
      "Size after Undersampling: 1243\n",
      "Size before Oversampling: 1243\n",
      "Size after Oversampling: 2260\n",
      "\n",
      " Generating Dataset 9\n",
      "Size after Undersampling: 1243\n",
      "Month 4:\n",
      "# bad: 122\n",
      "Size before Border: 57743\n",
      "Distance = 1 ...\n",
      "Distance = 2 ...\n",
      "Distance = 3 ...\n",
      "Distance = 4 ...\n",
      "Distance = 5 ...\n",
      "Distance = 6 ...\n",
      "Distance = 7 ...\n",
      "Distance = 8 ...\n",
      "# over: 20\n",
      "Distance = 9 ...\n",
      "Distance = 10 ...\n",
      "Distance = 11 ...\n",
      "# over: 80\n",
      "Distance = 12 ...\n",
      "# over: 100\n",
      "Distance = 13 ...\n",
      "# over: 130\n",
      "Distance = 14 ...\n",
      "# over: 220\n",
      "Distance = 15 ...\n",
      "# over: 310\n",
      "Distance = 16 ...\n",
      "# over: 285\n",
      "# over: 285\n",
      "Size after Border: 58820\n",
      "\n",
      " Generating Dataset 2\n",
      "Size after Undersampling: 2398\n",
      "Size after Undersampling: (2398, 100) , Balance Ratio: 1.0\n",
      "Size before Undersampling: 57743\n",
      "\n",
      " Generating Dataset 6\n",
      "Size after Undersampling: 1342\n",
      "Size after Undersampling: 1342\n",
      "Distance = 1 ...\n",
      "Distance = 2 ...\n",
      "Distance = 3 ...\n",
      "Distance = 4 ...\n",
      "Distance = 5 ...\n",
      "Distance = 6 ...\n",
      "Distance = 7 ...\n",
      "Distance = 8 ...\n",
      "# over: 20\n",
      "Distance = 9 ...\n",
      "Distance = 10 ...\n",
      "Distance = 11 ...\n",
      "# over: 80\n",
      "Distance = 12 ...\n",
      "# over: 100\n",
      "Distance = 13 ...\n",
      "# over: 130\n",
      "Distance = 14 ...\n",
      "# over: 220\n",
      "Distance = 15 ...\n",
      "# over: 310\n",
      "Distance = 16 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-28 11:44:31,692:INFO:NoSMOTE: Running sampling via ('NoSMOTE', '{}')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# over: 270\n",
      "# over: 270\n",
      "Size after Border: (2420, 100) , Balance Ratio: 1.02\n",
      "\n",
      " Generating Dataset 0\n",
      "Size before Oversampling: 57743\n",
      "Size after Oversampling: 57743\n",
      "Size after Undersampling: 57743\n",
      "\n",
      " Generating Dataset 1\n",
      "Size before Oversampling: 57743\n",
      "Size after Oversampling: 58834\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-28 11:44:37,724:INFO:ROSE: Running sampling via ('ROSE', \"{'proportion': 0.019055684946008893, 'random_state': None}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size after Undersampling: 2426\n",
      "\n",
      " Generating Dataset 3\n",
      "Size before Oversampling: 57743\n",
      "Size after Oversampling: 58838\n",
      "Size after Undersampling: 2434\n",
      "\n",
      " Generating Dataset 4\n",
      "Size before Oversampling: 57743\n",
      "Size after Oversampling: 58841\n",
      "Size after Undersampling: 2440\n",
      "\n",
      " Generating Dataset 5\n",
      "Size before Undersampling: 57743\n",
      "Size after Undersampling: 1342\n",
      "Size before Oversampling: 1342\n",
      "Size after Oversampling: 2419\n",
      "\n",
      " Generating Dataset 7\n",
      "Size before Undersampling: 57743\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-28 11:44:55,895:INFO:ROSE: Running sampling via ('ROSE', \"{'proportion': 0.9, 'random_state': None}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size after Undersampling: 1342\n",
      "Size before Oversampling: 1342\n",
      "Size after Oversampling: 2330\n",
      "\n",
      " Generating Dataset 8\n",
      "Size before Undersampling: 57743\n",
      "Size after Undersampling: 1342\n",
      "Size before Oversampling: 1342\n",
      "Size after Oversampling: 2440\n",
      "\n",
      " Generating Dataset 9\n",
      "Size after Undersampling: 1342\n"
     ]
    }
   ],
   "source": [
    "##### main function for generating all resampling datasets #####\n",
    "dataset = {}\n",
    "combine_dataset = {}\n",
    "for i in range(10):\n",
    "    combine_dataset[i] = pd.DataFrame()\n",
    "\n",
    "for i in tqdm(training_month):\n",
    "    \n",
    "    print(f'Month {i}:')\n",
    "    print('# bad:', sum(runhist[f'm{i}'].GB))\n",
    "    br = Balance_Ratio(runhist[f'm{i}'])\n",
    "    final_br = 1\n",
    "    num_os = 10\n",
    "    over_br = num_os / br\n",
    "    under_br = final_br / num_os\n",
    "    \n",
    "    \n",
    "    dataset[2] = border_set(runhist[f'm{i}'], kinds[f'm{i}'], 'NM', 2, num_over = num_os, over_ratio = over_br, \n",
    "                            under_ratio = final_br, order = 'over')\n",
    "    dataset[6] = border_set(runhist[f'm{i}'], kinds[f'm{i}'], 'NM', 6, num_over = num_os, over_ratio = final_br, \n",
    "                            under_ratio = under_br, order = 'under')\n",
    "    \n",
    "    dataset[0] = generate_set(runhist[f'm{i}'], 'NoSMOTE', None, 0, over_ratio = None, under_ratio = None, order = 'over')\n",
    "\n",
    "    dataset[1] = generate_set(runhist[f'm{i}'], 'ADASYN', 'NM', 1, over_ratio = over_br, under_ratio = final_br, \n",
    "                              order = 'over')\n",
    "    dataset[3] = generate_set(runhist[f'm{i}'], 'ROSE', 'NM', 3, over_ratio = over_br*(1-1/num_os), under_ratio = final_br,\n",
    "                              order = 'over')\n",
    "    dataset[4] = generate_set(runhist[f'm{i}'], 'SMOTEN', 'NM', 4, over_ratio = over_br, under_ratio = final_br, \n",
    "                              order = 'over')\n",
    "\n",
    "    dataset[5] = generate_set(runhist[f'm{i}'], 'ADASYN', 'NM', 5, over_ratio = final_br, under_ratio = under_br, \n",
    "                              order = 'under')\n",
    "    dataset[7] = generate_set(runhist[f'm{i}'], 'ROSE', 'NM', 7, over_ratio = (final_br*(1-1/num_os)), \n",
    "                              under_ratio = under_br, order = 'under')\n",
    "    dataset[8] = generate_set(runhist[f'm{i}'], 'SMOTEN', 'NM', 8, over_ratio = final_br, under_ratio = under_br, \n",
    "                              order = 'under')\n",
    "    \n",
    "    special = final_br if final_br <0.1 else 0.1\n",
    "    dataset[9] = generate_set(runhist[f'm{i}'], None, 'NM', 9, over_ratio = None, under_ratio = special, order = 'over')\n",
    "    \n",
    "    ### combine all training data after sampling by each month and save data files ###\n",
    "    for j in range(10):\n",
    "        temp_combine = pd.concat([combine_dataset[j], dataset[j]], axis = 0).fillna(0)\n",
    "        temp_cols = temp_combine.columns.to_list()\n",
    "        GB_pos = temp_cols.index('GB')\n",
    "        fine_cols = temp_cols[: GB_pos] + temp_cols[GB_pos+1: ] + temp_cols[GB_pos: GB_pos+1]\n",
    "        combine_dataset[j] = temp_combine[fine_cols]\n",
    "        \n",
    "        dataset[j].to_csv(f'm{i}_dataset_{j}.csv')\n",
    "        combine_dataset[j].to_csv(f'dataset_{j}.csv')"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python [conda env:smote_variants]",
   "language": "python",
   "name": "conda-env-smote_variants-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
