{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-11T01:49:42.110984Z",
     "start_time": "2022-05-11T01:49:39.272439Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import random\n",
    "from tqdm.auto import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from lightgbm import LGBMClassifier\n",
    "import optuna\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from library.Data_Preprocessing import Balance_Ratio\n",
    "from library.Imbalance_Sampling import label_divide, under_over, over_under, resampling_dataset\n",
    "from library.Aging_Score_Contour import score1\n",
    "from library.AdaBoost import train_set, multiple_set, multiple_month, line_chart, cf_matrix, all_optuna, optuna_history\n",
    "\n",
    "os.chdir('C:/Users/user/Desktop/Darui_R08621110') \n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function Definition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Balance Cascade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-11T01:49:43.931685Z",
     "start_time": "2022-05-11T01:49:43.907716Z"
    }
   },
   "outputs": [],
   "source": [
    "# train & test of balance cascade (scheme 1 & 2)\n",
    "class BalanceCascade:\n",
    "    \n",
    "    def __init__(self, base_clf = 'LightGBM', num_iter = 10, over_method = None, under_method = 'NM', \n",
    "                 over_num = 5, verbose = True):\n",
    "        self.classifier = base_clf\n",
    "        self.num_iter = num_iter\n",
    "        self.over_method = over_method\n",
    "        self.under_method = under_method\n",
    "        self.over_num = over_num if over_method else 1\n",
    "        self.verbose = verbose\n",
    "        if over_method not in ['ADASYN', 'SMOTEN', None]:\n",
    "            raise Exception(f'{over_method} is not implemented !') \n",
    "        if under_method not in ['NM', 'random']:\n",
    "            raise Exception(f'{under_method} is not implemented !') \n",
    "        if base_clf not in ['LightGBM', 'RandomForest']:\n",
    "            raise Exception(f'{base_clf} is not implemented !') \n",
    "    \n",
    "    \n",
    "    def training(self, train_data, clf_config):\n",
    "        origin_good = train_data[train_data.GB == 0]\n",
    "        origin_bad = train_data[train_data.GB == 1] \n",
    "        br_0 = (len(origin_bad)*self.over_num) / len(origin_good)\n",
    "        false_rate = br_0**(1/(self.num_iter - 1))\n",
    "        \n",
    "        keep_bad = origin_bad.copy()\n",
    "        keep_good = {0: origin_good.copy()}\n",
    "        br_list = []\n",
    "        clf_threshold = []\n",
    "        clf_cascade = {}\n",
    "        for j in range(self.num_iter):\n",
    "            temp_train = pd.concat([keep_good[j], keep_bad], axis = 0)\n",
    "            temp_br = len(keep_bad) / len(keep_good[j])\n",
    "            br_list.append(temp_br)\n",
    "            print(f'\\nIteration {j+1}:')\n",
    "            \n",
    "            # oversampling\n",
    "            if all([self.over_method, temp_br < 1]):\n",
    "                over_ratio = temp_br*self.over_num\n",
    "                over_X, over_Y = under_over(temp_train, self.over_method, None, over_ratio, 0)\n",
    "                over_sample = pd.concat([over_X, over_Y], axis = 1)\n",
    "                over_sample = over_sample.rename({0: 'GB'}, axis = 'columns')\n",
    "                over_bad = over_sample[over_sample.GB == 1]\n",
    "            else:\n",
    "                over_bad = keep_bad.copy()\n",
    "                if all([self.verbose, not self.over_method]):\n",
    "                    print('Stop Oversampling !')\n",
    "            \n",
    "            # undersampling\n",
    "            if all([j != self.num_iter - 1, len(keep_good[j]) > len(over_bad)]):\n",
    "                under_ratio = 1/self.over_num\n",
    "                under_X, under_Y = over_under(temp_train, None, self.under_method, 0, under_ratio)\n",
    "                under_sample = pd.concat([under_X, under_Y], axis = 1)\n",
    "                under_good = under_sample[under_sample.GB == 0]\n",
    "            else:\n",
    "                under_good = keep_good[j].copy()\n",
    "                if self.verbose:\n",
    "                    print('Stop Undersampling !')\n",
    "            train_combine = pd.concat([over_bad, under_good], axis = 0)\n",
    "            \n",
    "            # train the base learner, find the threshold, and discard the redundant good instances\n",
    "            valid_good = keep_good[j].copy()\n",
    "            train_x, train_y, valid_x, valid_y = label_divide(train_combine, valid_good, 'GB', train_only = False)\n",
    "            if self.classifier == 'LightGBM':\n",
    "                clf = LGBMClassifier(**clf_config)\n",
    "            elif self.classifier == 'RandomForest':\n",
    "                clf = RandomForestClassifier(**clf_config)\n",
    "            clf.fit(train_x, train_y)\n",
    "            predict = clf.predict_proba(valid_x)[:, 1]\n",
    "            predict_df = pd.DataFrame(dict(predict = predict), index = valid_x.index)\n",
    "            predict_df = predict_df.sort_values(by = 'predict', ascending = False)\n",
    "            keep_num = int(len(predict_df)*false_rate) + 1\n",
    "            keep_index = predict_df.index[:keep_num]\n",
    "            threshold = predict_df.loc[keep_index[-1]].values[0]\n",
    "            clf_threshold.append(threshold)\n",
    "            clf_cascade[j] = clf\n",
    "            \n",
    "            if j != (self.num_iter - 1):\n",
    "                keep_good[j+1] = keep_good[j].loc[keep_index].copy()        \n",
    "        self.good_data = keep_good\n",
    "        self.bad_data = keep_bad\n",
    "        self.threshold = clf_threshold\n",
    "        self.cascade = clf_cascade\n",
    "        self.balance_ratio = br_list\n",
    "    \n",
    "    \n",
    "    def testing(self, test_data):\n",
    "        clf_cascade = self.cascade\n",
    "        if isinstance(self.threshold, int):\n",
    "            clf_threshold = [self.threshold]*len(clf_cascade)\n",
    "        else:\n",
    "            clf_threshold = self.threshold\n",
    "\n",
    "        test_x, test_y = label_divide(test_data, 'GB', train_only = True)\n",
    "        predict_df = pd.DataFrame()\n",
    "        for i in range(len(clf_cascade)):\n",
    "            clf = clf_cascade[i]\n",
    "            predict = clf.predict_proba(test_x)[:, 1]\n",
    "            answer = (predict > clf_threshold[i]).astype(int)\n",
    "            predict = pd.DataFrame({str(i): answer})\n",
    "            predict_df = pd.concat([predict_df, predict], axis = 1)\n",
    "        predict_y = (predict_df.apply(sum, axis = 1) == len(clf_cascade)).astype(int)\n",
    "        result = pd.DataFrame(dict(predict = predict_y, truth = test_y))\n",
    "\n",
    "        return result\n",
    "\n",
    "\n",
    "# run all resampling datasets\n",
    "def runall_cascade(train_set, test_data, base_config, base_clf = 'LightGBM', num_iter = 10, meta_config = None):\n",
    "    \n",
    "    num_set = len(train_set)\n",
    "    table_set = pd.DataFrame()\n",
    "    for i in range(1, num_set):\n",
    "        print('\\n', f'Dataset {i}:')\n",
    "        if isinstance(meta_config, dict):\n",
    "            BC = BalanceCascade(base_clf = base_clf, **meta_config[f'set{i}'])\n",
    "        else:\n",
    "            BC = BalanceCascade(base_clf = base_clf, num_iter = num_iter)\n",
    "        BC.training(train_set[f'set{i}'], base_config[f'set{i}'])\n",
    "        result = BC.testing(test_data)\n",
    "        table = cf_matrix(result, train_set[f'set{i}'].GB)\n",
    "        table_set = pd.concat([table_set, table]).rename(index = {0: f'dataset {i}'})\n",
    "    \n",
    "    return table_set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-12T01:40:26.893137Z",
     "start_time": "2022-05-12T01:40:26.870148Z"
    }
   },
   "outputs": [],
   "source": [
    "# creator of optuna study for balance cascade\n",
    "def BalanceCascade_creator(train_data, mode, num_valid = 3, label = 'GB') :\n",
    "\n",
    "    def objective(trial) :\n",
    "    \n",
    "        base_param = {\n",
    "            'n_estimators': trial.suggest_categorical('n_estimators', [100, 300, 500, 1000]),\n",
    "            'learning_rate': trial.suggest_float('learning_rate', 0.025, 0.325, step = 0.05),\n",
    "            'max_depth': trial.suggest_int('max_depth', 3, 12, step = 3),\n",
    "            'num_leaves': trial.suggest_int('num_leaves', 10, 130, step = 20),\n",
    "            'min_child_samples': trial.suggest_categorical('min_child_samples', [10, 50, 100, 500, 1000, 5000]),\n",
    "            'min_split_gain': trial.suggest_int('min_split_gain', 0, 12, step = 2),\n",
    "            'colsample_bytree': trial.suggest_float('colsample_bytree', 0.3, 0.9, step = 0.2),\n",
    "            'subsample': trial.suggest_float('subsample', 0.3, 0.9, step = 0.2),\n",
    "            'reg_alpha': trial.suggest_loguniform('reg_alpha', 1e-2, 10), # alpha\n",
    "            'reg_lambda': trial.suggest_loguniform('reg_lambda', 1e-2, 10) # lambda\n",
    "        }\n",
    "        \n",
    "        num_iter = 10 if mode == 1 else 15\n",
    "        over_num = 5\n",
    "        meta_param = {\n",
    "            'num_iter': trial.suggest_int('num_iter', num_iter, num_iter, step = 5),\n",
    "            'over_num': trial.suggest_int('over_num', over_num, over_num, step = 5),\n",
    "            'over_method': trial.suggest_categorical('over_method', ['ADASYN']),\n",
    "            'under_method': trial.suggest_categorical('under_method', ['NM'])\n",
    "        }  \n",
    "\n",
    "        result_list = []\n",
    "        for i in range(num_valid):\n",
    "\n",
    "            train_good = train_data[train_data.GB == 0]\n",
    "            train_bad = train_data[train_data.GB == 1]\n",
    "            train_good_x, train_good_y = label_divide(train_good, None, label, train_only = True)\n",
    "            train_bad_x, train_bad_y = label_divide(train_bad, None, label, train_only = True)\n",
    "            train_g_x, valid_g_x, train_g_y, valid_g_y = train_test_split(train_good_x, train_good_y, test_size = 0.25)\n",
    "            train_b_x, valid_b_x, train_b_y, valid_b_y = train_test_split(train_bad_x, train_bad_y, test_size = 0.25)\n",
    "            train_x = pd.concat([train_g_x, train_b_x], axis = 0)\n",
    "            train_y = pd.concat([train_g_y, train_b_y], axis = 0)\n",
    "            valid_x = pd.concat([valid_g_x, valid_b_x], axis = 0)\n",
    "            valid_y = pd.concat([valid_g_y, valid_b_y], axis = 0)\n",
    "            all_train = pd.concat([train_x, train_y], axis = 1)\n",
    "            all_valid = pd.concat([valid_x, valid_y], axis = 1)\n",
    "\n",
    "            if mode == 1:\n",
    "                BC = BalanceCascade(num_iter = meta_param['num_iter'], under_method = meta_param['under_method'])\n",
    "            elif mode == 2:\n",
    "                BC = BalanceCascade(num_iter = meta_param['num_iter'], over_method = meta_param['over_method'], \n",
    "                                    under_method = meta_param['under_method'], over_num = meta_param['over_num'])\n",
    "            BC.training(all_train, base_param)\n",
    "            result = BC.testing(all_valid)\n",
    "            table = cf_matrix(result, valid_y)\n",
    "            recall = table['Recall'].values\n",
    "            precision = table['Precision'].values\n",
    "            beta = 1\n",
    "            if recall > 0:\n",
    "                fscore = ((1+beta**2)*recall*precision) / (recall+(beta**2)*precision) \n",
    "            else:\n",
    "                fscore = 0\n",
    "            result_list.append(fscore)\n",
    "\n",
    "        return np.mean(result_list)\n",
    "    return objective"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Full Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-12T01:40:30.751879Z",
     "start_time": "2022-05-12T01:40:30.736218Z"
    }
   },
   "outputs": [],
   "source": [
    "def full_balancecascade(train_month, times, scheme):\n",
    "    prob_dict = dict()\n",
    "    result_df = pd.DataFrame()\n",
    "\n",
    "    # load relabel datasets\n",
    "    runhist = {}\n",
    "    kinds = {}\n",
    "    for i in train_month:\n",
    "        runhist[f'm{i}'] = pd.read_csv(f'relabel_runhist_m{i}.csv', index_col = 'id').iloc[:, 1:]\n",
    "        kinds[f'm{i}'] = pd.read_csv(f'kind_m{i}.csv').iloc[:, 2:-3]\n",
    "\n",
    "    # do several times to average the random effect of resampling\n",
    "    for i in tqdm(range(times)):\n",
    "        # generate resampled datasets\n",
    "        if scheme == 1:\n",
    "            final_br, num_os = 0.1, 5\n",
    "        elif scheme == 2:\n",
    "            final_br, num_os = 0.05, 5\n",
    "        resampling_dataset(runhist = runhist, kinds = kinds, train_month = train_month, \n",
    "                           final_br = final_br, num_os = num_os)\n",
    "\n",
    "        # load & prepare the resampled datasets \n",
    "        all_train = multiple_set(num_set = 10)\n",
    "        all_train_x, all_train_y = train_set(all_train)\n",
    "        all_test = pd.read_csv('test_runhist.csv').iloc[:, 2:]\n",
    "        all_test_x, all_test_y = label_divide(all_test, None, 'GB', train_only = True)\n",
    "        \n",
    "        # searching for hyperparameters\n",
    "        best_param, _ = all_optuna(all_data = all_train, \n",
    "                                   mode = scheme, \n",
    "                                   TPE_multi = False, \n",
    "                                   n_iter = 25,\n",
    "                                   filename = f'runhist_array_m2m4_m5_3criteria_BalanceCascade{scheme}-{i}',\n",
    "                                   creator = BalanceCascade_creator\n",
    "                                  )\n",
    "\n",
    "        meta_item = ['num_iter', 'over_num', 'over_method', 'under_method']\n",
    "        base_param, meta_param = {}, {}\n",
    "        for k in range(1, len(all_train)):\n",
    "            base_param.update({f'set{k}': {}})\n",
    "            meta_param.update({f'set{k}': {}})\n",
    "            [base_param[f'set{k}'].update({a: b}) for (a, b) in best_param[f'set{k}'].items() if a not in meta_item]\n",
    "            [meta_param[f'set{k}'].update({a: b}) for (a, b) in best_param[f'set{k}'].items() if a in meta_item]\n",
    "        \n",
    "        # store the probability predicted by the classifier \n",
    "        for j in best_param.keys():\n",
    "            if i == 0:\n",
    "                prob_dict[j] = pd.DataFrame()\n",
    "            \n",
    "            if scheme == 1:\n",
    "                BC = BalanceCascade(num_iter = meta_param[j]['num_iter'], over_method = None, over_num = 5,\n",
    "                                    under_method = meta_param[j]['under_method'])\n",
    "            elif scheme == 2:\n",
    "                BC = BalanceCascade(num_iter = meta_param[j]['num_iter'], over_method = meta_param[j]['over_method'], \n",
    "                                    under_method = meta_param[j]['under_method'], over_num = meta_param[j]['over_num'])\n",
    "            BC.training(all_train[j], base_param[j])\n",
    "            table = BC.testing(all_test)\n",
    "            prob_dict[j] = pd.concat([prob_dict[j], table[['predict']]], axis = 1)\n",
    "            \n",
    "    # average to get final prediction\n",
    "    for j in best_param.keys():\n",
    "        prediction = (prob_dict[j].apply(np.sum, axis = 1) >= times*0.5).astype(int)\n",
    "        result = pd.DataFrame(dict(truth = all_test_y, predict = prediction))\n",
    "        table = cf_matrix(result, all_train_y[j])\n",
    "        result_df = pd.concat([result_df, table]).rename(index = {0: f'data{j}'})\n",
    "        \n",
    "    return result_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Full Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-12T03:29:29.286664Z",
     "start_time": "2022-05-12T01:40:35.326143Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "scheme = 1\n",
    "training_month = range(2, 5)\n",
    "\n",
    "table_setC = full_balancecascade(training_month, times = 3, scheme = scheme)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-12T03:29:29.520981Z",
     "start_time": "2022-05-12T03:29:29.302284Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "line_chart(table_setC, title = f'Balance Cascade Classifier Scheme {scheme}')\n",
    "table_setC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-12T03:29:29.692815Z",
     "start_time": "2022-05-12T03:29:29.536603Z"
    }
   },
   "outputs": [],
   "source": [
    "savedate = '20220601'\n",
    "TPE_multi = False\n",
    "\n",
    "table_setC['sampler'] = 'multivariate-TPE' if TPE_multi else 'univariate-TPE'\n",
    "table_setC['model'] = f'BalanceCascade{scheme}'\n",
    "with pd.ExcelWriter(f'{savedate}_Classifier.xlsx', mode = 'a') as writer:\n",
    "    table_setC.to_excel(writer, sheet_name = f'BalanceCascade{scheme}')"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python [conda env:aging]",
   "language": "python",
   "name": "conda-env-aging-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
